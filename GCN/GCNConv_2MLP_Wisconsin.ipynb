{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af88d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx import ego_graph\n",
    "\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "\n",
    "#from logger import Logger\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import WebKB\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7babc9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "print(data)\n",
    "#split_idx = dataset.get_idx_split()\n",
    "#train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91fdcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "800\n",
      "510\n"
     ]
    }
   ],
   "source": [
    "train_index = np.where(data.train_mask)[0]\n",
    "print(len(train_index))\n",
    "valid_index = np.where(data.val_mask)[0]\n",
    "print(len(valid_index))\n",
    "test_index = np.where(data.test_mask)[0]\n",
    "print(len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0b82f",
   "metadata": {},
   "source": [
    "# GCN using only domain Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9ef33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, runs, info=None):\n",
    "        self.info = info\n",
    "        self.results = [[] for _ in range(runs)]\n",
    "\n",
    "    def add_result(self, run, result):\n",
    "        assert len(result) == 3\n",
    "        assert run >= 0 and run < len(self.results)\n",
    "        self.results[run].append(result)\n",
    "\n",
    "    def print_statistics(self, run=None):\n",
    "        if run is not None:\n",
    "            result = 100 * torch.tensor(self.results[run])\n",
    "            argmax = result[:, 1].argmax().item()\n",
    "            print(f'Run {run + 1:02d}:')\n",
    "            print(f'Highest Train: {result[:, 0].max():.2f}')\n",
    "            print(f'Highest Valid: {result[:, 1].max():.2f}')\n",
    "            print(f'  Final Train: {result[argmax, 0]:.2f}')\n",
    "            print(f'   Final Test: {result[argmax, 2]:.2f}')\n",
    "        else:\n",
    "            result = 100 * torch.tensor(self.results)\n",
    "\n",
    "            best_results = []\n",
    "            for r in result:\n",
    "                train1 = r[:, 0].max().item()\n",
    "                valid = r[:, 1].max().item()\n",
    "                train2 = r[r[:, 1].argmax(), 0].item()\n",
    "                test = r[r[:, 1].argmax(), 2].item()\n",
    "                best_results.append((train1, valid, train2, test))\n",
    "\n",
    "            best_result = torch.tensor(best_results)\n",
    "\n",
    "            print(f'All runs:')\n",
    "            r = best_result[:, 0]\n",
    "            print(f'Highest Train: {r.mean():.2f} Â± {r.std():.2f}')\n",
    "            r = best_result[:, 1]\n",
    "            print(f'Highest Valid: {r.mean():.2f} Â± {r.std():.2f}')\n",
    "            r = best_result[:, 2]\n",
    "            print(f'  Final Train: {r.mean():.2f} Â± {r.std():.2f}')\n",
    "            r = best_result[:, 3]\n",
    "            print(f'   Final Test: {r.mean():.2f} Â± {r.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47468ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout,heads):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.heads=heads\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            #x=F.softmax(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(len(out))\n",
    "    #print(data.y.squeeze(1)[train_idx])\n",
    "    loss = F.nll_loss(out, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.adj_t)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e19e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4   5   8  11  13  15  17  21  24  25  26  27  28  32  33  34  36  38\n",
      "  40  41  46  47  48  49  50  52  55  62  63  65  67  68  69  71  73  77\n",
      "  78  80  82  84  86  87  88  89  97 100 102 104 107 109 110 111 113 115\n",
      " 117 118 119 121 122 124 125 127 128 131 133 135 136 137 141 142 145 146\n",
      " 148 149 153 156 157 158 159 160 162 163 166 167 169 173 176 178 181]\n"
     ]
    }
   ],
   "source": [
    "idx=[data.train_mask[i][0] for i in range(183)]\n",
    "train_index = np.where(idx)[0]\n",
    "print(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b23796d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 01, Loss: 2.3904, Train: 24.17%, Valid: 16.25% Test: 5.88%\n",
      "Run: 01, Epoch: 02, Loss: 1.8516, Train: 30.83%, Valid: 15.00% Test: 11.76%\n",
      "Run: 01, Epoch: 03, Loss: 1.5139, Train: 55.83%, Valid: 43.75% Test: 31.37%\n",
      "Run: 01, Epoch: 04, Loss: 1.2444, Train: 63.33%, Valid: 51.25% Test: 45.10%\n",
      "Run: 01, Epoch: 05, Loss: 1.1097, Train: 72.50%, Valid: 55.00% Test: 47.06%\n",
      "Run: 01, Epoch: 06, Loss: 1.0159, Train: 71.67%, Valid: 62.50% Test: 49.02%\n",
      "Run: 01, Epoch: 07, Loss: 0.9255, Train: 71.67%, Valid: 62.50% Test: 50.98%\n",
      "Run: 01, Epoch: 08, Loss: 0.8810, Train: 71.67%, Valid: 61.25% Test: 54.90%\n",
      "Run: 01, Epoch: 09, Loss: 0.8432, Train: 72.50%, Valid: 58.75% Test: 54.90%\n",
      "Run: 01, Epoch: 10, Loss: 0.7929, Train: 75.00%, Valid: 56.25% Test: 50.98%\n",
      "Run: 01, Epoch: 11, Loss: 0.7609, Train: 77.50%, Valid: 61.25% Test: 52.94%\n",
      "Run: 01, Epoch: 12, Loss: 0.7220, Train: 76.67%, Valid: 58.75% Test: 50.98%\n",
      "Run: 01, Epoch: 13, Loss: 0.6858, Train: 76.67%, Valid: 57.50% Test: 49.02%\n",
      "Run: 01, Epoch: 14, Loss: 0.6603, Train: 77.50%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 15, Loss: 0.6371, Train: 78.33%, Valid: 56.25% Test: 45.10%\n",
      "Run: 01, Epoch: 16, Loss: 0.6116, Train: 80.00%, Valid: 56.25% Test: 45.10%\n",
      "Run: 01, Epoch: 17, Loss: 0.5859, Train: 82.50%, Valid: 55.00% Test: 45.10%\n",
      "Run: 01, Epoch: 18, Loss: 0.5616, Train: 83.33%, Valid: 56.25% Test: 45.10%\n",
      "Run: 01, Epoch: 19, Loss: 0.5387, Train: 84.17%, Valid: 56.25% Test: 47.06%\n",
      "Run: 01, Epoch: 20, Loss: 0.5163, Train: 84.17%, Valid: 57.50% Test: 47.06%\n",
      "Run: 01, Epoch: 21, Loss: 0.4962, Train: 84.17%, Valid: 57.50% Test: 47.06%\n",
      "Run: 01, Epoch: 22, Loss: 0.4775, Train: 84.17%, Valid: 57.50% Test: 47.06%\n",
      "Run: 01, Epoch: 23, Loss: 0.4591, Train: 84.17%, Valid: 56.25% Test: 47.06%\n",
      "Run: 01, Epoch: 24, Loss: 0.4425, Train: 83.33%, Valid: 57.50% Test: 47.06%\n",
      "Run: 01, Epoch: 25, Loss: 0.4218, Train: 84.17%, Valid: 57.50% Test: 47.06%\n",
      "Run: 01, Epoch: 26, Loss: 0.4094, Train: 84.17%, Valid: 57.50% Test: 47.06%\n",
      "Run: 01, Epoch: 27, Loss: 0.3891, Train: 83.33%, Valid: 57.50% Test: 49.02%\n",
      "Run: 01, Epoch: 28, Loss: 0.3810, Train: 85.83%, Valid: 57.50% Test: 45.10%\n",
      "Run: 01, Epoch: 29, Loss: 0.3608, Train: 85.83%, Valid: 52.50% Test: 45.10%\n",
      "Run: 01, Epoch: 30, Loss: 0.3539, Train: 86.67%, Valid: 53.75% Test: 45.10%\n",
      "Run: 01, Epoch: 31, Loss: 0.3376, Train: 86.67%, Valid: 56.25% Test: 45.10%\n",
      "Run: 01, Epoch: 32, Loss: 0.3301, Train: 87.50%, Valid: 55.00% Test: 45.10%\n",
      "Run: 01, Epoch: 33, Loss: 0.3146, Train: 89.17%, Valid: 51.25% Test: 45.10%\n",
      "Run: 01, Epoch: 34, Loss: 0.3101, Train: 88.33%, Valid: 55.00% Test: 45.10%\n",
      "Run: 01, Epoch: 35, Loss: 0.2971, Train: 87.50%, Valid: 56.25% Test: 45.10%\n",
      "Run: 01, Epoch: 36, Loss: 0.2942, Train: 88.33%, Valid: 57.50% Test: 45.10%\n",
      "Run: 01, Epoch: 37, Loss: 0.2813, Train: 90.83%, Valid: 57.50% Test: 45.10%\n",
      "Run: 01, Epoch: 38, Loss: 0.2739, Train: 90.83%, Valid: 57.50% Test: 47.06%\n",
      "Run: 01, Epoch: 39, Loss: 0.2654, Train: 90.83%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 40, Loss: 0.2564, Train: 90.83%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 41, Loss: 0.2520, Train: 91.67%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 42, Loss: 0.2415, Train: 92.50%, Valid: 62.50% Test: 45.10%\n",
      "Run: 01, Epoch: 43, Loss: 0.2381, Train: 92.50%, Valid: 62.50% Test: 45.10%\n",
      "Run: 01, Epoch: 44, Loss: 0.2298, Train: 92.50%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 45, Loss: 0.2236, Train: 91.67%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 46, Loss: 0.2200, Train: 92.50%, Valid: 60.00% Test: 45.10%\n",
      "Run: 01, Epoch: 47, Loss: 0.2127, Train: 93.33%, Valid: 62.50% Test: 45.10%\n",
      "Run: 01, Epoch: 48, Loss: 0.2078, Train: 93.33%, Valid: 61.25% Test: 45.10%\n",
      "Run: 01, Epoch: 49, Loss: 0.2011, Train: 93.33%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 50, Loss: 0.1999, Train: 94.17%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 51, Loss: 0.1936, Train: 94.17%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 52, Loss: 0.1898, Train: 94.17%, Valid: 62.50% Test: 47.06%\n",
      "Run: 01, Epoch: 53, Loss: 0.1860, Train: 94.17%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 54, Loss: 0.1814, Train: 94.17%, Valid: 62.50% Test: 47.06%\n",
      "Run: 01, Epoch: 55, Loss: 0.1774, Train: 94.17%, Valid: 62.50% Test: 47.06%\n",
      "Run: 01, Epoch: 56, Loss: 0.1734, Train: 94.17%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 57, Loss: 0.1659, Train: 93.33%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 58, Loss: 0.1651, Train: 93.33%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 59, Loss: 0.1603, Train: 93.33%, Valid: 61.25% Test: 45.10%\n",
      "Run: 01, Epoch: 60, Loss: 0.1547, Train: 93.33%, Valid: 60.00% Test: 45.10%\n",
      "Run: 01, Epoch: 61, Loss: 0.1523, Train: 94.17%, Valid: 60.00% Test: 45.10%\n",
      "Run: 01, Epoch: 62, Loss: 0.1504, Train: 94.17%, Valid: 58.75% Test: 45.10%\n",
      "Run: 01, Epoch: 63, Loss: 0.1478, Train: 95.83%, Valid: 58.75% Test: 45.10%\n",
      "Run: 01, Epoch: 64, Loss: 0.1461, Train: 95.00%, Valid: 58.75% Test: 45.10%\n",
      "Run: 01, Epoch: 65, Loss: 0.1427, Train: 95.00%, Valid: 58.75% Test: 45.10%\n",
      "Run: 01, Epoch: 66, Loss: 0.1424, Train: 95.83%, Valid: 58.75% Test: 45.10%\n",
      "Run: 01, Epoch: 67, Loss: 0.1390, Train: 95.00%, Valid: 58.75% Test: 45.10%\n",
      "Run: 01, Epoch: 68, Loss: 0.1378, Train: 95.00%, Valid: 58.75% Test: 45.10%\n",
      "Run: 01, Epoch: 69, Loss: 0.1351, Train: 95.00%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 70, Loss: 0.1359, Train: 95.00%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 71, Loss: 0.1321, Train: 95.00%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 72, Loss: 0.1304, Train: 95.00%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 73, Loss: 0.1286, Train: 95.83%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 74, Loss: 0.1274, Train: 95.83%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 75, Loss: 0.1254, Train: 95.83%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 76, Loss: 0.1238, Train: 94.17%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 77, Loss: 0.1217, Train: 93.33%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 78, Loss: 0.1203, Train: 94.17%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 79, Loss: 0.1205, Train: 95.00%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 80, Loss: 0.1208, Train: 94.17%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 81, Loss: 0.1169, Train: 94.17%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 82, Loss: 0.1161, Train: 94.17%, Valid: 60.00% Test: 45.10%\n",
      "Run: 01, Epoch: 83, Loss: 0.1182, Train: 94.17%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 84, Loss: 0.1126, Train: 95.83%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 85, Loss: 0.1144, Train: 95.00%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 86, Loss: 0.1133, Train: 95.83%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 87, Loss: 0.1099, Train: 95.83%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 88, Loss: 0.1127, Train: 95.83%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 89, Loss: 0.1088, Train: 95.83%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 90, Loss: 0.1084, Train: 95.83%, Valid: 60.00% Test: 47.06%\n",
      "Run: 01, Epoch: 91, Loss: 0.1114, Train: 95.83%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 92, Loss: 0.1114, Train: 95.83%, Valid: 61.25% Test: 45.10%\n",
      "Run: 01, Epoch: 93, Loss: 0.1069, Train: 95.00%, Valid: 62.50% Test: 45.10%\n",
      "Run: 01, Epoch: 94, Loss: 0.1106, Train: 95.83%, Valid: 62.50% Test: 47.06%\n",
      "Run: 01, Epoch: 95, Loss: 0.1064, Train: 95.00%, Valid: 62.50% Test: 47.06%\n",
      "Run: 01, Epoch: 96, Loss: 0.1068, Train: 95.83%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 97, Loss: 0.1088, Train: 95.83%, Valid: 61.25% Test: 45.10%\n",
      "Run: 01, Epoch: 98, Loss: 0.1047, Train: 95.83%, Valid: 61.25% Test: 49.02%\n",
      "Run: 01, Epoch: 99, Loss: 0.1048, Train: 95.83%, Valid: 60.00% Test: 49.02%\n",
      "Run: 01, Epoch: 100, Loss: 0.1047, Train: 95.83%, Valid: 61.25% Test: 49.02%\n",
      "Run 01:\n",
      "Highest Train: 95.83\n",
      "Highest Valid: 62.50\n",
      "  Final Train: 71.67\n",
      "   Final Test: 49.02\n",
      "Run: 02, Epoch: 01, Loss: 1.8448, Train: 14.17%, Valid: 13.75% Test: 7.84%\n",
      "Run: 02, Epoch: 02, Loss: 1.2050, Train: 18.33%, Valid: 13.75% Test: 13.73%\n",
      "Run: 02, Epoch: 03, Loss: 1.0227, Train: 30.83%, Valid: 17.50% Test: 13.73%\n",
      "Run: 02, Epoch: 04, Loss: 0.9125, Train: 42.50%, Valid: 25.00% Test: 27.45%\n",
      "Run: 02, Epoch: 05, Loss: 0.8261, Train: 51.67%, Valid: 28.75% Test: 31.37%\n",
      "Run: 02, Epoch: 06, Loss: 0.7557, Train: 61.67%, Valid: 33.75% Test: 37.25%\n",
      "Run: 02, Epoch: 07, Loss: 0.6987, Train: 68.33%, Valid: 41.25% Test: 43.14%\n",
      "Run: 02, Epoch: 08, Loss: 0.6522, Train: 76.67%, Valid: 41.25% Test: 47.06%\n",
      "Run: 02, Epoch: 09, Loss: 0.6121, Train: 80.83%, Valid: 43.75% Test: 49.02%\n",
      "Run: 02, Epoch: 10, Loss: 0.5774, Train: 81.67%, Valid: 43.75% Test: 50.98%\n",
      "Run: 02, Epoch: 11, Loss: 0.5471, Train: 81.67%, Valid: 45.00% Test: 52.94%\n",
      "Run: 02, Epoch: 12, Loss: 0.5201, Train: 83.33%, Valid: 45.00% Test: 54.90%\n",
      "Run: 02, Epoch: 13, Loss: 0.4952, Train: 82.50%, Valid: 45.00% Test: 54.90%\n",
      "Run: 02, Epoch: 14, Loss: 0.4724, Train: 83.33%, Valid: 45.00% Test: 56.86%\n",
      "Run: 02, Epoch: 15, Loss: 0.4514, Train: 83.33%, Valid: 45.00% Test: 56.86%\n",
      "Run: 02, Epoch: 16, Loss: 0.4327, Train: 82.50%, Valid: 43.75% Test: 56.86%\n",
      "Run: 02, Epoch: 17, Loss: 0.4145, Train: 85.00%, Valid: 43.75% Test: 56.86%\n",
      "Run: 02, Epoch: 18, Loss: 0.3968, Train: 86.67%, Valid: 45.00% Test: 58.82%\n",
      "Run: 02, Epoch: 19, Loss: 0.3795, Train: 86.67%, Valid: 45.00% Test: 60.78%\n",
      "Run: 02, Epoch: 20, Loss: 0.3628, Train: 86.67%, Valid: 45.00% Test: 60.78%\n",
      "Run: 02, Epoch: 21, Loss: 0.3455, Train: 87.50%, Valid: 45.00% Test: 60.78%\n",
      "Run: 02, Epoch: 22, Loss: 0.3287, Train: 88.33%, Valid: 43.75% Test: 58.82%\n",
      "Run: 02, Epoch: 23, Loss: 0.3121, Train: 88.33%, Valid: 43.75% Test: 60.78%\n",
      "Run: 02, Epoch: 24, Loss: 0.2952, Train: 89.17%, Valid: 45.00% Test: 60.78%\n",
      "Run: 02, Epoch: 25, Loss: 0.2791, Train: 91.67%, Valid: 46.25% Test: 60.78%\n",
      "Run: 02, Epoch: 26, Loss: 0.2647, Train: 92.50%, Valid: 46.25% Test: 60.78%\n",
      "Run: 02, Epoch: 27, Loss: 0.2518, Train: 91.67%, Valid: 47.50% Test: 60.78%\n",
      "Run: 02, Epoch: 28, Loss: 0.2370, Train: 92.50%, Valid: 45.00% Test: 60.78%\n",
      "Run: 02, Epoch: 29, Loss: 0.2227, Train: 92.50%, Valid: 47.50% Test: 60.78%\n",
      "Run: 02, Epoch: 30, Loss: 0.2107, Train: 93.33%, Valid: 47.50% Test: 58.82%\n",
      "Run: 02, Epoch: 31, Loss: 0.2005, Train: 93.33%, Valid: 47.50% Test: 58.82%\n",
      "Run: 02, Epoch: 32, Loss: 0.1901, Train: 93.33%, Valid: 47.50% Test: 62.75%\n",
      "Run: 02, Epoch: 33, Loss: 0.1789, Train: 94.17%, Valid: 48.75% Test: 62.75%\n",
      "Run: 02, Epoch: 34, Loss: 0.1684, Train: 94.17%, Valid: 48.75% Test: 62.75%\n",
      "Run: 02, Epoch: 35, Loss: 0.1588, Train: 95.00%, Valid: 48.75% Test: 62.75%\n",
      "Run: 02, Epoch: 36, Loss: 0.1496, Train: 95.83%, Valid: 48.75% Test: 60.78%\n",
      "Run: 02, Epoch: 37, Loss: 0.1428, Train: 95.00%, Valid: 47.50% Test: 60.78%\n",
      "Run: 02, Epoch: 38, Loss: 0.1364, Train: 95.00%, Valid: 47.50% Test: 60.78%\n",
      "Run: 02, Epoch: 39, Loss: 0.1292, Train: 95.83%, Valid: 46.25% Test: 60.78%\n",
      "Run: 02, Epoch: 40, Loss: 0.1238, Train: 95.83%, Valid: 47.50% Test: 54.90%\n",
      "Run: 02, Epoch: 41, Loss: 0.1335, Train: 98.33%, Valid: 46.25% Test: 56.86%\n",
      "Run: 02, Epoch: 42, Loss: 0.1119, Train: 97.50%, Valid: 45.00% Test: 54.90%\n",
      "Run: 02, Epoch: 43, Loss: 0.1152, Train: 98.33%, Valid: 45.00% Test: 56.86%\n",
      "Run: 02, Epoch: 44, Loss: 0.1068, Train: 98.33%, Valid: 45.00% Test: 56.86%\n",
      "Run: 02, Epoch: 45, Loss: 0.1013, Train: 97.50%, Valid: 46.25% Test: 56.86%\n",
      "Run: 02, Epoch: 46, Loss: 0.0973, Train: 98.33%, Valid: 47.50% Test: 56.86%\n",
      "Run: 02, Epoch: 47, Loss: 0.0954, Train: 97.50%, Valid: 46.25% Test: 56.86%\n",
      "Run: 02, Epoch: 48, Loss: 0.0921, Train: 97.50%, Valid: 46.25% Test: 56.86%\n",
      "Run: 02, Epoch: 49, Loss: 0.0904, Train: 98.33%, Valid: 46.25% Test: 56.86%\n",
      "Run: 02, Epoch: 50, Loss: 0.0873, Train: 97.50%, Valid: 46.25% Test: 56.86%\n",
      "Run: 02, Epoch: 51, Loss: 0.0816, Train: 97.50%, Valid: 45.00% Test: 56.86%\n",
      "Run: 02, Epoch: 52, Loss: 0.0740, Train: 98.33%, Valid: 45.00% Test: 58.82%\n",
      "Run: 02, Epoch: 53, Loss: 0.0687, Train: 98.33%, Valid: 45.00% Test: 58.82%\n",
      "Run: 02, Epoch: 54, Loss: 0.0640, Train: 98.33%, Valid: 45.00% Test: 58.82%\n",
      "Run: 02, Epoch: 55, Loss: 0.0609, Train: 99.17%, Valid: 45.00% Test: 58.82%\n",
      "Run: 02, Epoch: 56, Loss: 0.0581, Train: 99.17%, Valid: 45.00% Test: 58.82%\n",
      "Run: 02, Epoch: 57, Loss: 0.0552, Train: 99.17%, Valid: 45.00% Test: 56.86%\n",
      "Run: 02, Epoch: 58, Loss: 0.0527, Train: 99.17%, Valid: 46.25% Test: 54.90%\n",
      "Run: 02, Epoch: 59, Loss: 0.0509, Train: 99.17%, Valid: 45.00% Test: 54.90%\n",
      "Run: 02, Epoch: 60, Loss: 0.0494, Train: 99.17%, Valid: 47.50% Test: 54.90%\n",
      "Run: 02, Epoch: 61, Loss: 0.0475, Train: 99.17%, Valid: 47.50% Test: 54.90%\n",
      "Run: 02, Epoch: 62, Loss: 0.0474, Train: 98.33%, Valid: 47.50% Test: 54.90%\n",
      "Run: 02, Epoch: 63, Loss: 0.0468, Train: 99.17%, Valid: 46.25% Test: 54.90%\n",
      "Run: 02, Epoch: 64, Loss: 0.0482, Train: 98.33%, Valid: 46.25% Test: 54.90%\n",
      "Run: 02, Epoch: 65, Loss: 0.0436, Train: 99.17%, Valid: 46.25% Test: 54.90%\n",
      "Run: 02, Epoch: 66, Loss: 0.0402, Train: 99.17%, Valid: 46.25% Test: 54.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 67, Loss: 0.0386, Train: 99.17%, Valid: 47.50% Test: 54.90%\n",
      "Run: 02, Epoch: 68, Loss: 0.0384, Train: 99.17%, Valid: 47.50% Test: 54.90%\n",
      "Run: 02, Epoch: 69, Loss: 0.0392, Train: 98.33%, Valid: 46.25% Test: 54.90%\n",
      "Run: 02, Epoch: 70, Loss: 0.0392, Train: 99.17%, Valid: 45.00% Test: 54.90%\n",
      "Run: 02, Epoch: 71, Loss: 0.0371, Train: 99.17%, Valid: 45.00% Test: 54.90%\n",
      "Run: 02, Epoch: 72, Loss: 0.0343, Train: 99.17%, Valid: 45.00% Test: 54.90%\n",
      "Run: 02, Epoch: 73, Loss: 0.0338, Train: 99.17%, Valid: 45.00% Test: 54.90%\n",
      "Run: 02, Epoch: 74, Loss: 0.0344, Train: 99.17%, Valid: 45.00% Test: 54.90%\n",
      "Run: 02, Epoch: 75, Loss: 0.0341, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 02, Epoch: 76, Loss: 0.0331, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 02, Epoch: 77, Loss: 0.0315, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 02, Epoch: 78, Loss: 0.0302, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 79, Loss: 0.0299, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 80, Loss: 0.0295, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 81, Loss: 0.0286, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 82, Loss: 0.0281, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 83, Loss: 0.0278, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 84, Loss: 0.0271, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 85, Loss: 0.0266, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 86, Loss: 0.0262, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 87, Loss: 0.0256, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 88, Loss: 0.0252, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 89, Loss: 0.0247, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 02, Epoch: 90, Loss: 0.0243, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 02, Epoch: 91, Loss: 0.0238, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 92, Loss: 0.0234, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 93, Loss: 0.0230, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 94, Loss: 0.0227, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 95, Loss: 0.0224, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 96, Loss: 0.0221, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 97, Loss: 0.0218, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 98, Loss: 0.0216, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run: 02, Epoch: 99, Loss: 0.0214, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 02, Epoch: 100, Loss: 0.0212, Train: 99.17%, Valid: 42.50% Test: 54.90%\n",
      "Run 02:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 48.75\n",
      "  Final Train: 94.17\n",
      "   Final Test: 62.75\n",
      "Run: 03, Epoch: 01, Loss: 1.7189, Train: 48.33%, Valid: 25.00% Test: 27.45%\n",
      "Run: 03, Epoch: 02, Loss: 1.0402, Train: 44.17%, Valid: 23.75% Test: 21.57%\n",
      "Run: 03, Epoch: 03, Loss: 0.9190, Train: 42.50%, Valid: 26.25% Test: 23.53%\n",
      "Run: 03, Epoch: 04, Loss: 0.8126, Train: 50.83%, Valid: 30.00% Test: 21.57%\n",
      "Run: 03, Epoch: 05, Loss: 0.7711, Train: 58.33%, Valid: 30.00% Test: 25.49%\n",
      "Run: 03, Epoch: 06, Loss: 0.7251, Train: 66.67%, Valid: 35.00% Test: 29.41%\n",
      "Run: 03, Epoch: 07, Loss: 0.6797, Train: 74.17%, Valid: 43.75% Test: 39.22%\n",
      "Run: 03, Epoch: 08, Loss: 0.6389, Train: 80.00%, Valid: 50.00% Test: 45.10%\n",
      "Run: 03, Epoch: 09, Loss: 0.6023, Train: 81.67%, Valid: 53.75% Test: 50.98%\n",
      "Run: 03, Epoch: 10, Loss: 0.5714, Train: 84.17%, Valid: 56.25% Test: 50.98%\n",
      "Run: 03, Epoch: 11, Loss: 0.5424, Train: 85.00%, Valid: 57.50% Test: 50.98%\n",
      "Run: 03, Epoch: 12, Loss: 0.5141, Train: 85.00%, Valid: 56.25% Test: 52.94%\n",
      "Run: 03, Epoch: 13, Loss: 0.4876, Train: 85.83%, Valid: 53.75% Test: 54.90%\n",
      "Run: 03, Epoch: 14, Loss: 0.4625, Train: 86.67%, Valid: 53.75% Test: 52.94%\n",
      "Run: 03, Epoch: 15, Loss: 0.4386, Train: 87.50%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 16, Loss: 0.4160, Train: 88.33%, Valid: 53.75% Test: 52.94%\n",
      "Run: 03, Epoch: 17, Loss: 0.3944, Train: 88.33%, Valid: 55.00% Test: 52.94%\n",
      "Run: 03, Epoch: 18, Loss: 0.3745, Train: 90.00%, Valid: 55.00% Test: 52.94%\n",
      "Run: 03, Epoch: 19, Loss: 0.3559, Train: 90.00%, Valid: 55.00% Test: 52.94%\n",
      "Run: 03, Epoch: 20, Loss: 0.3379, Train: 90.00%, Valid: 52.50% Test: 54.90%\n",
      "Run: 03, Epoch: 21, Loss: 0.3208, Train: 90.00%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 22, Loss: 0.3056, Train: 90.83%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 23, Loss: 0.2914, Train: 91.67%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 24, Loss: 0.2772, Train: 91.67%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 25, Loss: 0.2634, Train: 92.50%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 26, Loss: 0.2507, Train: 92.50%, Valid: 48.75% Test: 54.90%\n",
      "Run: 03, Epoch: 27, Loss: 0.2394, Train: 92.50%, Valid: 47.50% Test: 54.90%\n",
      "Run: 03, Epoch: 28, Loss: 0.2287, Train: 92.50%, Valid: 47.50% Test: 54.90%\n",
      "Run: 03, Epoch: 29, Loss: 0.2192, Train: 93.33%, Valid: 48.75% Test: 54.90%\n",
      "Run: 03, Epoch: 30, Loss: 0.2093, Train: 92.50%, Valid: 47.50% Test: 56.86%\n",
      "Run: 03, Epoch: 31, Loss: 0.1998, Train: 93.33%, Valid: 47.50% Test: 56.86%\n",
      "Run: 03, Epoch: 32, Loss: 0.1906, Train: 93.33%, Valid: 47.50% Test: 56.86%\n",
      "Run: 03, Epoch: 33, Loss: 0.1823, Train: 93.33%, Valid: 48.75% Test: 56.86%\n",
      "Run: 03, Epoch: 34, Loss: 0.1745, Train: 93.33%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 35, Loss: 0.1676, Train: 93.33%, Valid: 48.75% Test: 56.86%\n",
      "Run: 03, Epoch: 36, Loss: 0.1612, Train: 95.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 03, Epoch: 37, Loss: 0.1547, Train: 95.00%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 38, Loss: 0.1486, Train: 95.00%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 39, Loss: 0.1430, Train: 95.00%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 40, Loss: 0.1378, Train: 95.83%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 41, Loss: 0.1332, Train: 95.00%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 42, Loss: 0.1290, Train: 95.83%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 43, Loss: 0.1246, Train: 95.00%, Valid: 52.50% Test: 54.90%\n",
      "Run: 03, Epoch: 44, Loss: 0.1196, Train: 95.83%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 45, Loss: 0.1151, Train: 96.67%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 46, Loss: 0.1116, Train: 95.83%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 47, Loss: 0.1073, Train: 95.83%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 48, Loss: 0.1033, Train: 96.67%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 49, Loss: 0.1003, Train: 96.67%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 50, Loss: 0.0967, Train: 95.83%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 51, Loss: 0.0935, Train: 96.67%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 52, Loss: 0.0899, Train: 96.67%, Valid: 48.75% Test: 54.90%\n",
      "Run: 03, Epoch: 53, Loss: 0.0873, Train: 95.83%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 54, Loss: 0.0842, Train: 95.83%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 55, Loss: 0.0818, Train: 95.83%, Valid: 48.75% Test: 54.90%\n",
      "Run: 03, Epoch: 56, Loss: 0.0791, Train: 96.67%, Valid: 48.75% Test: 54.90%\n",
      "Run: 03, Epoch: 57, Loss: 0.0767, Train: 95.83%, Valid: 48.75% Test: 54.90%\n",
      "Run: 03, Epoch: 58, Loss: 0.0743, Train: 96.67%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 59, Loss: 0.0720, Train: 97.50%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 60, Loss: 0.0698, Train: 98.33%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 61, Loss: 0.0675, Train: 98.33%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 62, Loss: 0.0656, Train: 99.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 63, Loss: 0.0635, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 64, Loss: 0.0614, Train: 99.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 65, Loss: 0.0595, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 66, Loss: 0.0574, Train: 100.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 67, Loss: 0.0554, Train: 100.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 68, Loss: 0.0533, Train: 100.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 69, Loss: 0.0513, Train: 100.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 70, Loss: 0.0493, Train: 100.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 71, Loss: 0.0474, Train: 100.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 72, Loss: 0.0457, Train: 100.00%, Valid: 50.00% Test: 52.94%\n",
      "Run: 03, Epoch: 73, Loss: 0.0436, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 74, Loss: 0.0415, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 75, Loss: 0.0397, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 76, Loss: 0.0379, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 77, Loss: 0.0360, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 78, Loss: 0.0342, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 79, Loss: 0.0324, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 80, Loss: 0.0307, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 81, Loss: 0.0290, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 82, Loss: 0.0275, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 83, Loss: 0.0262, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 84, Loss: 0.0254, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 85, Loss: 0.0260, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 86, Loss: 0.0255, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 87, Loss: 0.0218, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 88, Loss: 0.0227, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 89, Loss: 0.0204, Train: 100.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 90, Loss: 0.0183, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 91, Loss: 0.0191, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 92, Loss: 0.0185, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 93, Loss: 0.0181, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 94, Loss: 0.0169, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 95, Loss: 0.0162, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 96, Loss: 0.0151, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 97, Loss: 0.0144, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 98, Loss: 0.0135, Train: 100.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 99, Loss: 0.0131, Train: 100.00%, Valid: 52.50% Test: 50.98%\n",
      "Run: 03, Epoch: 100, Loss: 0.0121, Train: 100.00%, Valid: 52.50% Test: 50.98%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 57.50\n",
      "  Final Train: 85.00\n",
      "   Final Test: 50.98\n",
      "Run: 04, Epoch: 01, Loss: 1.6122, Train: 60.83%, Valid: 33.75% Test: 37.25%\n",
      "Run: 04, Epoch: 02, Loss: 1.1138, Train: 65.00%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 03, Loss: 0.8922, Train: 70.00%, Valid: 60.00% Test: 54.90%\n",
      "Run: 04, Epoch: 04, Loss: 0.7827, Train: 74.17%, Valid: 58.75% Test: 54.90%\n",
      "Run: 04, Epoch: 05, Loss: 0.7185, Train: 75.83%, Valid: 56.25% Test: 56.86%\n",
      "Run: 04, Epoch: 06, Loss: 0.6698, Train: 79.17%, Valid: 56.25% Test: 56.86%\n",
      "Run: 04, Epoch: 07, Loss: 0.6267, Train: 80.00%, Valid: 55.00% Test: 52.94%\n",
      "Run: 04, Epoch: 08, Loss: 0.5879, Train: 81.67%, Valid: 53.75% Test: 49.02%\n",
      "Run: 04, Epoch: 09, Loss: 0.5534, Train: 81.67%, Valid: 52.50% Test: 49.02%\n",
      "Run: 04, Epoch: 10, Loss: 0.5206, Train: 81.67%, Valid: 53.75% Test: 49.02%\n",
      "Run: 04, Epoch: 11, Loss: 0.4904, Train: 84.17%, Valid: 53.75% Test: 49.02%\n",
      "Run: 04, Epoch: 12, Loss: 0.4641, Train: 87.50%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 13, Loss: 0.4395, Train: 88.33%, Valid: 55.00% Test: 47.06%\n",
      "Run: 04, Epoch: 14, Loss: 0.4160, Train: 87.50%, Valid: 53.75% Test: 47.06%\n",
      "Run: 04, Epoch: 15, Loss: 0.3922, Train: 89.17%, Valid: 51.25% Test: 47.06%\n",
      "Run: 04, Epoch: 16, Loss: 0.3697, Train: 89.17%, Valid: 51.25% Test: 47.06%\n",
      "Run: 04, Epoch: 17, Loss: 0.3480, Train: 87.50%, Valid: 53.75% Test: 47.06%\n",
      "Run: 04, Epoch: 18, Loss: 0.3268, Train: 88.33%, Valid: 53.75% Test: 47.06%\n",
      "Run: 04, Epoch: 19, Loss: 0.3072, Train: 89.17%, Valid: 55.00% Test: 47.06%\n",
      "Run: 04, Epoch: 20, Loss: 0.2893, Train: 91.67%, Valid: 56.25% Test: 47.06%\n",
      "Run: 04, Epoch: 21, Loss: 0.2728, Train: 92.50%, Valid: 57.50% Test: 47.06%\n",
      "Run: 04, Epoch: 22, Loss: 0.2567, Train: 93.33%, Valid: 57.50% Test: 49.02%\n",
      "Run: 04, Epoch: 23, Loss: 0.2423, Train: 93.33%, Valid: 56.25% Test: 50.98%\n",
      "Run: 04, Epoch: 24, Loss: 0.2295, Train: 93.33%, Valid: 57.50% Test: 50.98%\n",
      "Run: 04, Epoch: 25, Loss: 0.2171, Train: 94.17%, Valid: 58.75% Test: 50.98%\n",
      "Run: 04, Epoch: 26, Loss: 0.2057, Train: 95.00%, Valid: 57.50% Test: 50.98%\n",
      "Run: 04, Epoch: 27, Loss: 0.1950, Train: 95.83%, Valid: 57.50% Test: 50.98%\n",
      "Run: 04, Epoch: 28, Loss: 0.1847, Train: 95.83%, Valid: 57.50% Test: 50.98%\n",
      "Run: 04, Epoch: 29, Loss: 0.1753, Train: 95.83%, Valid: 56.25% Test: 50.98%\n",
      "Run: 04, Epoch: 30, Loss: 0.1668, Train: 95.83%, Valid: 56.25% Test: 50.98%\n",
      "Run: 04, Epoch: 31, Loss: 0.1590, Train: 95.83%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 32, Loss: 0.1523, Train: 95.83%, Valid: 55.00% Test: 49.02%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 33, Loss: 0.1452, Train: 95.83%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 34, Loss: 0.1375, Train: 95.83%, Valid: 52.50% Test: 47.06%\n",
      "Run: 04, Epoch: 35, Loss: 0.1294, Train: 95.83%, Valid: 52.50% Test: 47.06%\n",
      "Run: 04, Epoch: 36, Loss: 0.1215, Train: 95.83%, Valid: 53.75% Test: 45.10%\n",
      "Run: 04, Epoch: 37, Loss: 0.1140, Train: 96.67%, Valid: 53.75% Test: 43.14%\n",
      "Run: 04, Epoch: 38, Loss: 0.1074, Train: 97.50%, Valid: 52.50% Test: 43.14%\n",
      "Run: 04, Epoch: 39, Loss: 0.1018, Train: 97.50%, Valid: 51.25% Test: 43.14%\n",
      "Run: 04, Epoch: 40, Loss: 0.0972, Train: 97.50%, Valid: 51.25% Test: 45.10%\n",
      "Run: 04, Epoch: 41, Loss: 0.0931, Train: 97.50%, Valid: 51.25% Test: 45.10%\n",
      "Run: 04, Epoch: 42, Loss: 0.0889, Train: 97.50%, Valid: 48.75% Test: 45.10%\n",
      "Run: 04, Epoch: 43, Loss: 0.0850, Train: 97.50%, Valid: 48.75% Test: 45.10%\n",
      "Run: 04, Epoch: 44, Loss: 0.0818, Train: 97.50%, Valid: 48.75% Test: 45.10%\n",
      "Run: 04, Epoch: 45, Loss: 0.0793, Train: 97.50%, Valid: 48.75% Test: 45.10%\n",
      "Run: 04, Epoch: 46, Loss: 0.0763, Train: 97.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 47, Loss: 0.0740, Train: 97.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 48, Loss: 0.0717, Train: 97.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 49, Loss: 0.0697, Train: 97.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 50, Loss: 0.0680, Train: 97.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 51, Loss: 0.0663, Train: 97.50%, Valid: 47.50% Test: 43.14%\n",
      "Run: 04, Epoch: 52, Loss: 0.0647, Train: 97.50%, Valid: 46.25% Test: 43.14%\n",
      "Run: 04, Epoch: 53, Loss: 0.0633, Train: 97.50%, Valid: 46.25% Test: 43.14%\n",
      "Run: 04, Epoch: 54, Loss: 0.0619, Train: 97.50%, Valid: 46.25% Test: 43.14%\n",
      "Run: 04, Epoch: 55, Loss: 0.0605, Train: 97.50%, Valid: 45.00% Test: 43.14%\n",
      "Run: 04, Epoch: 56, Loss: 0.0592, Train: 97.50%, Valid: 45.00% Test: 43.14%\n",
      "Run: 04, Epoch: 57, Loss: 0.0580, Train: 97.50%, Valid: 46.25% Test: 43.14%\n",
      "Run: 04, Epoch: 58, Loss: 0.0568, Train: 97.50%, Valid: 46.25% Test: 43.14%\n",
      "Run: 04, Epoch: 59, Loss: 0.0558, Train: 97.50%, Valid: 46.25% Test: 43.14%\n",
      "Run: 04, Epoch: 60, Loss: 0.0548, Train: 97.50%, Valid: 45.00% Test: 43.14%\n",
      "Run: 04, Epoch: 61, Loss: 0.0538, Train: 97.50%, Valid: 46.25% Test: 43.14%\n",
      "Run: 04, Epoch: 62, Loss: 0.0528, Train: 97.50%, Valid: 46.25% Test: 43.14%\n",
      "Run: 04, Epoch: 63, Loss: 0.0531, Train: 97.50%, Valid: 46.25% Test: 43.14%\n",
      "Run: 04, Epoch: 64, Loss: 0.0520, Train: 97.50%, Valid: 45.00% Test: 43.14%\n",
      "Run: 04, Epoch: 65, Loss: 0.0522, Train: 97.50%, Valid: 45.00% Test: 43.14%\n",
      "Run: 04, Epoch: 66, Loss: 0.0511, Train: 98.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 67, Loss: 0.0497, Train: 98.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 68, Loss: 0.0491, Train: 98.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 69, Loss: 0.0484, Train: 98.33%, Valid: 47.50% Test: 45.10%\n",
      "Run: 04, Epoch: 70, Loss: 0.0480, Train: 98.33%, Valid: 47.50% Test: 45.10%\n",
      "Run: 04, Epoch: 71, Loss: 0.0474, Train: 98.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 72, Loss: 0.0466, Train: 98.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 73, Loss: 0.0457, Train: 99.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 74, Loss: 0.0450, Train: 99.17%, Valid: 45.00% Test: 45.10%\n",
      "Run: 04, Epoch: 75, Loss: 0.0444, Train: 99.17%, Valid: 45.00% Test: 45.10%\n",
      "Run: 04, Epoch: 76, Loss: 0.0438, Train: 99.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 77, Loss: 0.0431, Train: 99.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 78, Loss: 0.0425, Train: 99.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 79, Loss: 0.0418, Train: 99.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 80, Loss: 0.0411, Train: 98.33%, Valid: 45.00% Test: 45.10%\n",
      "Run: 04, Epoch: 81, Loss: 0.0404, Train: 98.33%, Valid: 45.00% Test: 45.10%\n",
      "Run: 04, Epoch: 82, Loss: 0.0397, Train: 98.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 83, Loss: 0.0391, Train: 98.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 84, Loss: 0.0384, Train: 99.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 04, Epoch: 85, Loss: 0.0378, Train: 99.17%, Valid: 48.75% Test: 45.10%\n",
      "Run: 04, Epoch: 86, Loss: 0.0371, Train: 99.17%, Valid: 45.00% Test: 45.10%\n",
      "Run: 04, Epoch: 87, Loss: 0.0364, Train: 99.17%, Valid: 45.00% Test: 45.10%\n",
      "Run: 04, Epoch: 88, Loss: 0.0357, Train: 99.17%, Valid: 43.75% Test: 45.10%\n",
      "Run: 04, Epoch: 89, Loss: 0.0350, Train: 99.17%, Valid: 42.50% Test: 45.10%\n",
      "Run: 04, Epoch: 90, Loss: 0.0343, Train: 99.17%, Valid: 43.75% Test: 45.10%\n",
      "Run: 04, Epoch: 91, Loss: 0.0336, Train: 99.17%, Valid: 43.75% Test: 45.10%\n",
      "Run: 04, Epoch: 92, Loss: 0.0330, Train: 99.17%, Valid: 43.75% Test: 45.10%\n",
      "Run: 04, Epoch: 93, Loss: 0.0324, Train: 99.17%, Valid: 43.75% Test: 47.06%\n",
      "Run: 04, Epoch: 94, Loss: 0.0315, Train: 99.17%, Valid: 43.75% Test: 47.06%\n",
      "Run: 04, Epoch: 95, Loss: 0.0307, Train: 99.17%, Valid: 43.75% Test: 47.06%\n",
      "Run: 04, Epoch: 96, Loss: 0.0310, Train: 99.17%, Valid: 43.75% Test: 45.10%\n",
      "Run: 04, Epoch: 97, Loss: 0.0299, Train: 99.17%, Valid: 42.50% Test: 45.10%\n",
      "Run: 04, Epoch: 98, Loss: 0.0303, Train: 99.17%, Valid: 42.50% Test: 45.10%\n",
      "Run: 04, Epoch: 99, Loss: 0.0298, Train: 99.17%, Valid: 42.50% Test: 45.10%\n",
      "Run: 04, Epoch: 100, Loss: 0.0283, Train: 99.17%, Valid: 42.50% Test: 45.10%\n",
      "Run 04:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 60.00\n",
      "  Final Train: 70.00\n",
      "   Final Test: 54.90\n",
      "Run: 05, Epoch: 01, Loss: 1.4923, Train: 61.67%, Valid: 57.50% Test: 56.86%\n",
      "Run: 05, Epoch: 02, Loss: 0.8946, Train: 65.83%, Valid: 56.25% Test: 58.82%\n",
      "Run: 05, Epoch: 03, Loss: 0.7749, Train: 74.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 05, Epoch: 04, Loss: 0.7039, Train: 77.50%, Valid: 52.50% Test: 58.82%\n",
      "Run: 05, Epoch: 05, Loss: 0.6603, Train: 78.33%, Valid: 47.50% Test: 54.90%\n",
      "Run: 05, Epoch: 06, Loss: 0.6239, Train: 80.00%, Valid: 45.00% Test: 52.94%\n",
      "Run: 05, Epoch: 07, Loss: 0.5940, Train: 81.67%, Valid: 45.00% Test: 52.94%\n",
      "Run: 05, Epoch: 08, Loss: 0.5640, Train: 80.83%, Valid: 46.25% Test: 54.90%\n",
      "Run: 05, Epoch: 09, Loss: 0.5372, Train: 82.50%, Valid: 46.25% Test: 56.86%\n",
      "Run: 05, Epoch: 10, Loss: 0.5135, Train: 84.17%, Valid: 45.00% Test: 56.86%\n",
      "Run: 05, Epoch: 11, Loss: 0.4910, Train: 85.00%, Valid: 45.00% Test: 52.94%\n",
      "Run: 05, Epoch: 12, Loss: 0.4684, Train: 85.83%, Valid: 42.50% Test: 54.90%\n",
      "Run: 05, Epoch: 13, Loss: 0.4460, Train: 88.33%, Valid: 41.25% Test: 56.86%\n",
      "Run: 05, Epoch: 14, Loss: 0.4245, Train: 87.50%, Valid: 41.25% Test: 58.82%\n",
      "Run: 05, Epoch: 15, Loss: 0.4033, Train: 86.67%, Valid: 40.00% Test: 58.82%\n",
      "Run: 05, Epoch: 16, Loss: 0.3828, Train: 87.50%, Valid: 40.00% Test: 60.78%\n",
      "Run: 05, Epoch: 17, Loss: 0.3656, Train: 87.50%, Valid: 40.00% Test: 62.75%\n",
      "Run: 05, Epoch: 18, Loss: 0.3500, Train: 88.33%, Valid: 40.00% Test: 60.78%\n",
      "Run: 05, Epoch: 19, Loss: 0.3343, Train: 88.33%, Valid: 41.25% Test: 60.78%\n",
      "Run: 05, Epoch: 20, Loss: 0.3197, Train: 88.33%, Valid: 41.25% Test: 60.78%\n",
      "Run: 05, Epoch: 21, Loss: 0.3062, Train: 90.00%, Valid: 41.25% Test: 60.78%\n",
      "Run: 05, Epoch: 22, Loss: 0.2940, Train: 90.00%, Valid: 41.25% Test: 60.78%\n",
      "Run: 05, Epoch: 23, Loss: 0.2820, Train: 89.17%, Valid: 41.25% Test: 58.82%\n",
      "Run: 05, Epoch: 24, Loss: 0.2704, Train: 89.17%, Valid: 38.75% Test: 58.82%\n",
      "Run: 05, Epoch: 25, Loss: 0.2595, Train: 90.00%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 26, Loss: 0.2493, Train: 90.00%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 27, Loss: 0.2394, Train: 90.83%, Valid: 36.25% Test: 58.82%\n",
      "Run: 05, Epoch: 28, Loss: 0.2300, Train: 91.67%, Valid: 36.25% Test: 58.82%\n",
      "Run: 05, Epoch: 29, Loss: 0.2214, Train: 92.50%, Valid: 36.25% Test: 58.82%\n",
      "Run: 05, Epoch: 30, Loss: 0.2133, Train: 92.50%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 31, Loss: 0.2057, Train: 92.50%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 32, Loss: 0.1982, Train: 92.50%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 33, Loss: 0.1909, Train: 91.67%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 34, Loss: 0.1836, Train: 92.50%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 35, Loss: 0.1766, Train: 92.50%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 36, Loss: 0.1694, Train: 93.33%, Valid: 38.75% Test: 58.82%\n",
      "Run: 05, Epoch: 37, Loss: 0.1626, Train: 93.33%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 38, Loss: 0.1559, Train: 93.33%, Valid: 37.50% Test: 60.78%\n",
      "Run: 05, Epoch: 39, Loss: 0.1497, Train: 94.17%, Valid: 35.00% Test: 56.86%\n",
      "Run: 05, Epoch: 40, Loss: 0.1442, Train: 96.67%, Valid: 33.75% Test: 56.86%\n",
      "Run: 05, Epoch: 41, Loss: 0.1389, Train: 96.67%, Valid: 33.75% Test: 56.86%\n",
      "Run: 05, Epoch: 42, Loss: 0.1342, Train: 96.67%, Valid: 35.00% Test: 56.86%\n",
      "Run: 05, Epoch: 43, Loss: 0.1294, Train: 96.67%, Valid: 33.75% Test: 56.86%\n",
      "Run: 05, Epoch: 44, Loss: 0.1245, Train: 96.67%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 45, Loss: 0.1199, Train: 96.67%, Valid: 33.75% Test: 56.86%\n",
      "Run: 05, Epoch: 46, Loss: 0.1151, Train: 96.67%, Valid: 33.75% Test: 58.82%\n",
      "Run: 05, Epoch: 47, Loss: 0.1104, Train: 97.50%, Valid: 33.75% Test: 58.82%\n",
      "Run: 05, Epoch: 48, Loss: 0.1057, Train: 97.50%, Valid: 33.75% Test: 58.82%\n",
      "Run: 05, Epoch: 49, Loss: 0.1014, Train: 97.50%, Valid: 35.00% Test: 58.82%\n",
      "Run: 05, Epoch: 50, Loss: 0.0973, Train: 97.50%, Valid: 35.00% Test: 58.82%\n",
      "Run: 05, Epoch: 51, Loss: 0.0933, Train: 97.50%, Valid: 36.25% Test: 58.82%\n",
      "Run: 05, Epoch: 52, Loss: 0.0893, Train: 97.50%, Valid: 36.25% Test: 58.82%\n",
      "Run: 05, Epoch: 53, Loss: 0.0854, Train: 97.50%, Valid: 36.25% Test: 58.82%\n",
      "Run: 05, Epoch: 54, Loss: 0.0815, Train: 97.50%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 55, Loss: 0.0776, Train: 97.50%, Valid: 37.50% Test: 58.82%\n",
      "Run: 05, Epoch: 56, Loss: 0.0739, Train: 97.50%, Valid: 36.25% Test: 58.82%\n",
      "Run: 05, Epoch: 57, Loss: 0.0704, Train: 97.50%, Valid: 33.75% Test: 58.82%\n",
      "Run: 05, Epoch: 58, Loss: 0.0672, Train: 97.50%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 59, Loss: 0.0644, Train: 97.50%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 60, Loss: 0.0619, Train: 97.50%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 61, Loss: 0.0596, Train: 97.50%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 62, Loss: 0.0565, Train: 97.50%, Valid: 35.00% Test: 54.90%\n",
      "Run: 05, Epoch: 63, Loss: 0.0534, Train: 98.33%, Valid: 36.25% Test: 54.90%\n",
      "Run: 05, Epoch: 64, Loss: 0.0505, Train: 98.33%, Valid: 37.50% Test: 54.90%\n",
      "Run: 05, Epoch: 65, Loss: 0.0481, Train: 98.33%, Valid: 37.50% Test: 52.94%\n",
      "Run: 05, Epoch: 66, Loss: 0.0461, Train: 98.33%, Valid: 37.50% Test: 52.94%\n",
      "Run: 05, Epoch: 67, Loss: 0.0447, Train: 98.33%, Valid: 37.50% Test: 52.94%\n",
      "Run: 05, Epoch: 68, Loss: 0.0433, Train: 98.33%, Valid: 37.50% Test: 52.94%\n",
      "Run: 05, Epoch: 69, Loss: 0.0417, Train: 98.33%, Valid: 37.50% Test: 50.98%\n",
      "Run: 05, Epoch: 70, Loss: 0.0400, Train: 98.33%, Valid: 36.25% Test: 50.98%\n",
      "Run: 05, Epoch: 71, Loss: 0.0383, Train: 98.33%, Valid: 36.25% Test: 50.98%\n",
      "Run: 05, Epoch: 72, Loss: 0.0368, Train: 98.33%, Valid: 35.00% Test: 50.98%\n",
      "Run: 05, Epoch: 73, Loss: 0.0355, Train: 98.33%, Valid: 35.00% Test: 50.98%\n",
      "Run: 05, Epoch: 74, Loss: 0.0343, Train: 98.33%, Valid: 35.00% Test: 52.94%\n",
      "Run: 05, Epoch: 75, Loss: 0.0332, Train: 98.33%, Valid: 35.00% Test: 54.90%\n",
      "Run: 05, Epoch: 76, Loss: 0.0321, Train: 98.33%, Valid: 35.00% Test: 54.90%\n",
      "Run: 05, Epoch: 77, Loss: 0.0309, Train: 98.33%, Valid: 35.00% Test: 54.90%\n",
      "Run: 05, Epoch: 78, Loss: 0.0298, Train: 98.33%, Valid: 35.00% Test: 54.90%\n",
      "Run: 05, Epoch: 79, Loss: 0.0291, Train: 98.33%, Valid: 35.00% Test: 54.90%\n",
      "Run: 05, Epoch: 80, Loss: 0.0307, Train: 99.17%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 81, Loss: 0.0307, Train: 98.33%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 82, Loss: 0.0292, Train: 99.17%, Valid: 32.50% Test: 54.90%\n",
      "Run: 05, Epoch: 83, Loss: 0.0266, Train: 99.17%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 84, Loss: 0.0271, Train: 99.17%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 85, Loss: 0.0260, Train: 99.17%, Valid: 33.75% Test: 56.86%\n",
      "Run: 05, Epoch: 86, Loss: 0.0252, Train: 99.17%, Valid: 32.50% Test: 56.86%\n",
      "Run: 05, Epoch: 87, Loss: 0.0252, Train: 99.17%, Valid: 33.75% Test: 56.86%\n",
      "Run: 05, Epoch: 88, Loss: 0.0243, Train: 99.17%, Valid: 33.75% Test: 56.86%\n",
      "Run: 05, Epoch: 89, Loss: 0.0237, Train: 99.17%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 90, Loss: 0.0232, Train: 99.17%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 91, Loss: 0.0224, Train: 99.17%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 92, Loss: 0.0221, Train: 99.17%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 93, Loss: 0.0219, Train: 99.17%, Valid: 33.75% Test: 54.90%\n",
      "Run: 05, Epoch: 94, Loss: 0.0216, Train: 99.17%, Valid: 35.00% Test: 54.90%\n",
      "Run: 05, Epoch: 95, Loss: 0.0211, Train: 99.17%, Valid: 35.00% Test: 54.90%\n",
      "Run: 05, Epoch: 96, Loss: 0.0207, Train: 99.17%, Valid: 35.00% Test: 54.90%\n",
      "Run: 05, Epoch: 97, Loss: 0.0206, Train: 99.17%, Valid: 35.00% Test: 54.90%\n",
      "Run: 05, Epoch: 98, Loss: 0.0202, Train: 99.17%, Valid: 35.00% Test: 56.86%\n",
      "Run: 05, Epoch: 99, Loss: 0.0199, Train: 99.17%, Valid: 35.00% Test: 56.86%\n",
      "Run: 05, Epoch: 100, Loss: 0.0195, Train: 99.17%, Valid: 35.00% Test: 56.86%\n",
      "Run 05:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 57.50\n",
      "  Final Train: 61.67\n",
      "   Final Test: 56.86\n",
      "Run: 06, Epoch: 01, Loss: 1.6838, Train: 60.00%, Valid: 51.25% Test: 47.06%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 02, Loss: 1.0297, Train: 60.83%, Valid: 46.25% Test: 41.18%\n",
      "Run: 06, Epoch: 03, Loss: 0.8672, Train: 60.83%, Valid: 45.00% Test: 41.18%\n",
      "Run: 06, Epoch: 04, Loss: 0.7891, Train: 63.33%, Valid: 46.25% Test: 41.18%\n",
      "Run: 06, Epoch: 05, Loss: 0.7283, Train: 62.50%, Valid: 43.75% Test: 43.14%\n",
      "Run: 06, Epoch: 06, Loss: 0.6777, Train: 65.00%, Valid: 42.50% Test: 45.10%\n",
      "Run: 06, Epoch: 07, Loss: 0.6309, Train: 69.17%, Valid: 45.00% Test: 45.10%\n",
      "Run: 06, Epoch: 08, Loss: 0.5873, Train: 70.83%, Valid: 46.25% Test: 45.10%\n",
      "Run: 06, Epoch: 09, Loss: 0.5467, Train: 75.83%, Valid: 47.50% Test: 41.18%\n",
      "Run: 06, Epoch: 10, Loss: 0.5094, Train: 80.83%, Valid: 46.25% Test: 45.10%\n",
      "Run: 06, Epoch: 11, Loss: 0.4749, Train: 85.00%, Valid: 46.25% Test: 47.06%\n",
      "Run: 06, Epoch: 12, Loss: 0.4428, Train: 85.00%, Valid: 45.00% Test: 47.06%\n",
      "Run: 06, Epoch: 13, Loss: 0.4140, Train: 85.83%, Valid: 47.50% Test: 47.06%\n",
      "Run: 06, Epoch: 14, Loss: 0.3878, Train: 86.67%, Valid: 48.75% Test: 49.02%\n",
      "Run: 06, Epoch: 15, Loss: 0.3632, Train: 86.67%, Valid: 51.25% Test: 49.02%\n",
      "Run: 06, Epoch: 16, Loss: 0.3398, Train: 88.33%, Valid: 51.25% Test: 49.02%\n",
      "Run: 06, Epoch: 17, Loss: 0.3172, Train: 89.17%, Valid: 48.75% Test: 49.02%\n",
      "Run: 06, Epoch: 18, Loss: 0.2954, Train: 90.83%, Valid: 48.75% Test: 50.98%\n",
      "Run: 06, Epoch: 19, Loss: 0.2750, Train: 91.67%, Valid: 47.50% Test: 50.98%\n",
      "Run: 06, Epoch: 20, Loss: 0.2573, Train: 91.67%, Valid: 47.50% Test: 50.98%\n",
      "Run: 06, Epoch: 21, Loss: 0.2451, Train: 94.17%, Valid: 50.00% Test: 50.98%\n",
      "Run: 06, Epoch: 22, Loss: 0.2234, Train: 94.17%, Valid: 50.00% Test: 50.98%\n",
      "Run: 06, Epoch: 23, Loss: 0.2078, Train: 94.17%, Valid: 50.00% Test: 50.98%\n",
      "Run: 06, Epoch: 24, Loss: 0.1985, Train: 94.17%, Valid: 50.00% Test: 49.02%\n",
      "Run: 06, Epoch: 25, Loss: 0.1833, Train: 95.83%, Valid: 50.00% Test: 49.02%\n",
      "Run: 06, Epoch: 26, Loss: 0.1721, Train: 95.00%, Valid: 50.00% Test: 49.02%\n",
      "Run: 06, Epoch: 27, Loss: 0.1617, Train: 95.00%, Valid: 50.00% Test: 49.02%\n",
      "Run: 06, Epoch: 28, Loss: 0.1485, Train: 94.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 06, Epoch: 29, Loss: 0.1390, Train: 94.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 06, Epoch: 30, Loss: 0.1292, Train: 95.00%, Valid: 50.00% Test: 54.90%\n",
      "Run: 06, Epoch: 31, Loss: 0.1174, Train: 96.67%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 32, Loss: 0.1079, Train: 96.67%, Valid: 50.00% Test: 54.90%\n",
      "Run: 06, Epoch: 33, Loss: 0.0992, Train: 98.33%, Valid: 50.00% Test: 54.90%\n",
      "Run: 06, Epoch: 34, Loss: 0.0897, Train: 97.50%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 35, Loss: 0.0818, Train: 98.33%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 36, Loss: 0.0745, Train: 98.33%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 37, Loss: 0.0669, Train: 99.17%, Valid: 46.25% Test: 54.90%\n",
      "Run: 06, Epoch: 38, Loss: 0.0612, Train: 99.17%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 39, Loss: 0.0561, Train: 99.17%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 40, Loss: 0.0509, Train: 98.33%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 41, Loss: 0.0474, Train: 98.33%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 42, Loss: 0.0436, Train: 99.17%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 43, Loss: 0.0403, Train: 99.17%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 44, Loss: 0.0376, Train: 98.33%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 45, Loss: 0.0349, Train: 98.33%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 46, Loss: 0.0331, Train: 99.17%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 47, Loss: 0.0311, Train: 99.17%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 48, Loss: 0.0294, Train: 99.17%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 49, Loss: 0.0279, Train: 99.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 50, Loss: 0.0268, Train: 99.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 51, Loss: 0.0254, Train: 99.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 52, Loss: 0.0245, Train: 99.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 53, Loss: 0.0232, Train: 99.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 54, Loss: 0.0223, Train: 99.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 06, Epoch: 55, Loss: 0.0211, Train: 99.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 06, Epoch: 56, Loss: 0.0203, Train: 99.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 57, Loss: 0.0193, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 58, Loss: 0.0186, Train: 99.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 59, Loss: 0.0178, Train: 99.17%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 60, Loss: 0.0172, Train: 99.17%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 61, Loss: 0.0167, Train: 100.00%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 62, Loss: 0.0160, Train: 100.00%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 63, Loss: 0.0155, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 64, Loss: 0.0148, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 65, Loss: 0.0143, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 66, Loss: 0.0137, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 67, Loss: 0.0132, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 68, Loss: 0.0126, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 69, Loss: 0.0121, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 70, Loss: 0.0118, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 71, Loss: 0.0114, Train: 100.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 72, Loss: 0.0107, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 73, Loss: 0.0106, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 74, Loss: 0.0100, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 75, Loss: 0.0097, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 76, Loss: 0.0092, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 77, Loss: 0.0097, Train: 99.17%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 78, Loss: 0.0105, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 79, Loss: 0.0093, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 80, Loss: 0.0087, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 81, Loss: 0.0094, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 82, Loss: 0.0083, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 83, Loss: 0.0073, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 84, Loss: 0.0075, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 85, Loss: 0.0072, Train: 100.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 86, Loss: 0.0068, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 87, Loss: 0.0061, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 88, Loss: 0.0061, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 89, Loss: 0.0060, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 90, Loss: 0.0058, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 91, Loss: 0.0053, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 92, Loss: 0.0050, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 93, Loss: 0.0048, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 94, Loss: 0.0047, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 95, Loss: 0.0045, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 96, Loss: 0.0043, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 97, Loss: 0.0041, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 98, Loss: 0.0040, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 99, Loss: 0.0039, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 06, Epoch: 100, Loss: 0.0038, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run 06:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 51.25\n",
      "  Final Train: 60.00\n",
      "   Final Test: 47.06\n",
      "Run: 07, Epoch: 01, Loss: 1.6318, Train: 56.67%, Valid: 42.50% Test: 47.06%\n",
      "Run: 07, Epoch: 02, Loss: 1.1906, Train: 41.67%, Valid: 37.50% Test: 33.33%\n",
      "Run: 07, Epoch: 03, Loss: 1.4380, Train: 60.83%, Valid: 47.50% Test: 41.18%\n",
      "Run: 07, Epoch: 04, Loss: 1.0155, Train: 58.33%, Valid: 40.00% Test: 41.18%\n",
      "Run: 07, Epoch: 05, Loss: 0.9751, Train: 57.50%, Valid: 41.25% Test: 43.14%\n",
      "Run: 07, Epoch: 06, Loss: 0.9306, Train: 57.50%, Valid: 45.00% Test: 43.14%\n",
      "Run: 07, Epoch: 07, Loss: 0.8868, Train: 58.33%, Valid: 43.75% Test: 41.18%\n",
      "Run: 07, Epoch: 08, Loss: 0.8529, Train: 60.00%, Valid: 43.75% Test: 41.18%\n",
      "Run: 07, Epoch: 09, Loss: 0.8216, Train: 61.67%, Valid: 42.50% Test: 43.14%\n",
      "Run: 07, Epoch: 10, Loss: 0.7934, Train: 63.33%, Valid: 43.75% Test: 43.14%\n",
      "Run: 07, Epoch: 11, Loss: 0.7666, Train: 64.17%, Valid: 42.50% Test: 41.18%\n",
      "Run: 07, Epoch: 12, Loss: 0.7451, Train: 64.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 07, Epoch: 13, Loss: 0.7238, Train: 67.50%, Valid: 40.00% Test: 39.22%\n",
      "Run: 07, Epoch: 14, Loss: 0.7044, Train: 68.33%, Valid: 40.00% Test: 39.22%\n",
      "Run: 07, Epoch: 15, Loss: 0.6880, Train: 70.83%, Valid: 40.00% Test: 39.22%\n",
      "Run: 07, Epoch: 16, Loss: 0.6724, Train: 71.67%, Valid: 38.75% Test: 39.22%\n",
      "Run: 07, Epoch: 17, Loss: 0.6564, Train: 73.33%, Valid: 45.00% Test: 39.22%\n",
      "Run: 07, Epoch: 18, Loss: 0.6401, Train: 72.50%, Valid: 46.25% Test: 41.18%\n",
      "Run: 07, Epoch: 19, Loss: 0.6230, Train: 73.33%, Valid: 47.50% Test: 41.18%\n",
      "Run: 07, Epoch: 20, Loss: 0.6051, Train: 73.33%, Valid: 46.25% Test: 43.14%\n",
      "Run: 07, Epoch: 21, Loss: 0.5897, Train: 76.67%, Valid: 45.00% Test: 43.14%\n",
      "Run: 07, Epoch: 22, Loss: 0.5761, Train: 76.67%, Valid: 46.25% Test: 45.10%\n",
      "Run: 07, Epoch: 23, Loss: 0.5638, Train: 75.83%, Valid: 47.50% Test: 45.10%\n",
      "Run: 07, Epoch: 24, Loss: 0.5486, Train: 76.67%, Valid: 45.00% Test: 43.14%\n",
      "Run: 07, Epoch: 25, Loss: 0.5349, Train: 78.33%, Valid: 46.25% Test: 43.14%\n",
      "Run: 07, Epoch: 26, Loss: 0.5237, Train: 78.33%, Valid: 45.00% Test: 43.14%\n",
      "Run: 07, Epoch: 27, Loss: 0.5107, Train: 79.17%, Valid: 46.25% Test: 43.14%\n",
      "Run: 07, Epoch: 28, Loss: 0.4983, Train: 79.17%, Valid: 46.25% Test: 41.18%\n",
      "Run: 07, Epoch: 29, Loss: 0.4859, Train: 79.17%, Valid: 46.25% Test: 39.22%\n",
      "Run: 07, Epoch: 30, Loss: 0.4730, Train: 79.17%, Valid: 46.25% Test: 39.22%\n",
      "Run: 07, Epoch: 31, Loss: 0.4612, Train: 79.17%, Valid: 47.50% Test: 37.25%\n",
      "Run: 07, Epoch: 32, Loss: 0.4496, Train: 79.17%, Valid: 47.50% Test: 39.22%\n",
      "Run: 07, Epoch: 33, Loss: 0.4378, Train: 80.00%, Valid: 48.75% Test: 39.22%\n",
      "Run: 07, Epoch: 34, Loss: 0.4259, Train: 81.67%, Valid: 46.25% Test: 39.22%\n",
      "Run: 07, Epoch: 35, Loss: 0.4147, Train: 81.67%, Valid: 46.25% Test: 39.22%\n",
      "Run: 07, Epoch: 36, Loss: 0.4048, Train: 82.50%, Valid: 48.75% Test: 39.22%\n",
      "Run: 07, Epoch: 37, Loss: 0.3948, Train: 82.50%, Valid: 48.75% Test: 39.22%\n",
      "Run: 07, Epoch: 38, Loss: 0.3867, Train: 82.50%, Valid: 47.50% Test: 39.22%\n",
      "Run: 07, Epoch: 39, Loss: 0.3774, Train: 82.50%, Valid: 48.75% Test: 37.25%\n",
      "Run: 07, Epoch: 40, Loss: 0.3693, Train: 81.67%, Valid: 48.75% Test: 37.25%\n",
      "Run: 07, Epoch: 41, Loss: 0.3609, Train: 84.17%, Valid: 47.50% Test: 39.22%\n",
      "Run: 07, Epoch: 42, Loss: 0.3536, Train: 83.33%, Valid: 48.75% Test: 39.22%\n",
      "Run: 07, Epoch: 43, Loss: 0.3491, Train: 83.33%, Valid: 47.50% Test: 41.18%\n",
      "Run: 07, Epoch: 44, Loss: 0.3869, Train: 85.00%, Valid: 45.00% Test: 33.33%\n",
      "Run: 07, Epoch: 45, Loss: 0.3657, Train: 85.83%, Valid: 48.75% Test: 33.33%\n",
      "Run: 07, Epoch: 46, Loss: 0.3430, Train: 86.67%, Valid: 47.50% Test: 35.29%\n",
      "Run: 07, Epoch: 47, Loss: 0.3262, Train: 87.50%, Valid: 46.25% Test: 35.29%\n",
      "Run: 07, Epoch: 48, Loss: 0.3169, Train: 86.67%, Valid: 47.50% Test: 33.33%\n",
      "Run: 07, Epoch: 49, Loss: 0.3191, Train: 86.67%, Valid: 47.50% Test: 33.33%\n",
      "Run: 07, Epoch: 50, Loss: 0.3076, Train: 87.50%, Valid: 47.50% Test: 33.33%\n",
      "Run: 07, Epoch: 51, Loss: 0.3069, Train: 87.50%, Valid: 48.75% Test: 33.33%\n",
      "Run: 07, Epoch: 52, Loss: 0.2978, Train: 87.50%, Valid: 48.75% Test: 35.29%\n",
      "Run: 07, Epoch: 53, Loss: 0.2927, Train: 87.50%, Valid: 48.75% Test: 37.25%\n",
      "Run: 07, Epoch: 54, Loss: 0.2877, Train: 87.50%, Valid: 47.50% Test: 35.29%\n",
      "Run: 07, Epoch: 55, Loss: 0.2806, Train: 87.50%, Valid: 50.00% Test: 31.37%\n",
      "Run: 07, Epoch: 56, Loss: 0.2779, Train: 88.33%, Valid: 50.00% Test: 31.37%\n",
      "Run: 07, Epoch: 57, Loss: 0.2742, Train: 88.33%, Valid: 51.25% Test: 31.37%\n",
      "Run: 07, Epoch: 58, Loss: 0.2712, Train: 88.33%, Valid: 51.25% Test: 31.37%\n",
      "Run: 07, Epoch: 59, Loss: 0.2696, Train: 88.33%, Valid: 51.25% Test: 29.41%\n",
      "Run: 07, Epoch: 60, Loss: 0.2665, Train: 88.33%, Valid: 51.25% Test: 27.45%\n",
      "Run: 07, Epoch: 61, Loss: 0.2617, Train: 88.33%, Valid: 51.25% Test: 31.37%\n",
      "Run: 07, Epoch: 62, Loss: 0.2563, Train: 89.17%, Valid: 51.25% Test: 31.37%\n",
      "Run: 07, Epoch: 63, Loss: 0.2483, Train: 89.17%, Valid: 51.25% Test: 37.25%\n",
      "Run: 07, Epoch: 64, Loss: 0.2335, Train: 87.50%, Valid: 52.50% Test: 37.25%\n",
      "Run: 07, Epoch: 65, Loss: 0.2286, Train: 87.50%, Valid: 50.00% Test: 37.25%\n",
      "Run: 07, Epoch: 66, Loss: 0.2267, Train: 88.33%, Valid: 48.75% Test: 41.18%\n",
      "Run: 07, Epoch: 67, Loss: 0.2250, Train: 86.67%, Valid: 48.75% Test: 41.18%\n",
      "Run: 07, Epoch: 68, Loss: 0.2214, Train: 89.17%, Valid: 48.75% Test: 41.18%\n",
      "Run: 07, Epoch: 69, Loss: 0.2191, Train: 88.33%, Valid: 47.50% Test: 41.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 70, Loss: 0.2157, Train: 89.17%, Valid: 47.50% Test: 41.18%\n",
      "Run: 07, Epoch: 71, Loss: 0.2153, Train: 90.00%, Valid: 48.75% Test: 41.18%\n",
      "Run: 07, Epoch: 72, Loss: 0.2227, Train: 89.17%, Valid: 48.75% Test: 39.22%\n",
      "Run: 07, Epoch: 73, Loss: 0.2176, Train: 89.17%, Valid: 47.50% Test: 39.22%\n",
      "Run: 07, Epoch: 74, Loss: 0.2223, Train: 89.17%, Valid: 47.50% Test: 39.22%\n",
      "Run: 07, Epoch: 75, Loss: 0.2150, Train: 89.17%, Valid: 48.75% Test: 41.18%\n",
      "Run: 07, Epoch: 76, Loss: 0.2096, Train: 89.17%, Valid: 48.75% Test: 41.18%\n",
      "Run: 07, Epoch: 77, Loss: 0.2048, Train: 90.00%, Valid: 48.75% Test: 41.18%\n",
      "Run: 07, Epoch: 78, Loss: 0.2019, Train: 89.17%, Valid: 48.75% Test: 41.18%\n",
      "Run: 07, Epoch: 79, Loss: 0.2012, Train: 89.17%, Valid: 48.75% Test: 43.14%\n",
      "Run: 07, Epoch: 80, Loss: 0.2019, Train: 89.17%, Valid: 47.50% Test: 45.10%\n",
      "Run: 07, Epoch: 81, Loss: 0.2015, Train: 89.17%, Valid: 50.00% Test: 45.10%\n",
      "Run: 07, Epoch: 82, Loss: 0.1999, Train: 89.17%, Valid: 50.00% Test: 45.10%\n",
      "Run: 07, Epoch: 83, Loss: 0.1956, Train: 89.17%, Valid: 50.00% Test: 45.10%\n",
      "Run: 07, Epoch: 84, Loss: 0.1932, Train: 90.83%, Valid: 50.00% Test: 45.10%\n",
      "Run: 07, Epoch: 85, Loss: 0.1919, Train: 90.83%, Valid: 50.00% Test: 45.10%\n",
      "Run: 07, Epoch: 86, Loss: 0.1899, Train: 91.67%, Valid: 48.75% Test: 45.10%\n",
      "Run: 07, Epoch: 87, Loss: 0.1874, Train: 90.83%, Valid: 48.75% Test: 45.10%\n",
      "Run: 07, Epoch: 88, Loss: 0.1867, Train: 90.83%, Valid: 50.00% Test: 43.14%\n",
      "Run: 07, Epoch: 89, Loss: 0.1848, Train: 90.00%, Valid: 48.75% Test: 43.14%\n",
      "Run: 07, Epoch: 90, Loss: 0.1835, Train: 90.83%, Valid: 48.75% Test: 43.14%\n",
      "Run: 07, Epoch: 91, Loss: 0.1813, Train: 92.50%, Valid: 50.00% Test: 43.14%\n",
      "Run: 07, Epoch: 92, Loss: 0.1803, Train: 90.83%, Valid: 50.00% Test: 39.22%\n",
      "Run: 07, Epoch: 93, Loss: 0.1781, Train: 90.83%, Valid: 50.00% Test: 39.22%\n",
      "Run: 07, Epoch: 94, Loss: 0.1769, Train: 92.50%, Valid: 50.00% Test: 41.18%\n",
      "Run: 07, Epoch: 95, Loss: 0.1744, Train: 91.67%, Valid: 50.00% Test: 41.18%\n",
      "Run: 07, Epoch: 96, Loss: 0.1751, Train: 92.50%, Valid: 51.25% Test: 41.18%\n",
      "Run: 07, Epoch: 97, Loss: 0.1747, Train: 92.50%, Valid: 51.25% Test: 41.18%\n",
      "Run: 07, Epoch: 98, Loss: 0.1716, Train: 91.67%, Valid: 48.75% Test: 45.10%\n",
      "Run: 07, Epoch: 99, Loss: 0.1672, Train: 94.17%, Valid: 48.75% Test: 43.14%\n",
      "Run: 07, Epoch: 100, Loss: 0.1644, Train: 95.83%, Valid: 48.75% Test: 47.06%\n",
      "Run 07:\n",
      "Highest Train: 95.83\n",
      "Highest Valid: 52.50\n",
      "  Final Train: 87.50\n",
      "   Final Test: 37.25\n",
      "Run: 08, Epoch: 01, Loss: 1.7660, Train: 35.83%, Valid: 30.00% Test: 35.29%\n",
      "Run: 08, Epoch: 02, Loss: 1.5449, Train: 53.33%, Valid: 48.75% Test: 45.10%\n",
      "Run: 08, Epoch: 03, Loss: 1.2203, Train: 59.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 08, Epoch: 04, Loss: 1.0528, Train: 56.67%, Valid: 41.25% Test: 52.94%\n",
      "Run: 08, Epoch: 05, Loss: 0.9407, Train: 55.83%, Valid: 40.00% Test: 49.02%\n",
      "Run: 08, Epoch: 06, Loss: 0.8752, Train: 60.00%, Valid: 38.75% Test: 47.06%\n",
      "Run: 08, Epoch: 07, Loss: 0.8269, Train: 63.33%, Valid: 41.25% Test: 49.02%\n",
      "Run: 08, Epoch: 08, Loss: 0.7876, Train: 65.83%, Valid: 45.00% Test: 54.90%\n",
      "Run: 08, Epoch: 09, Loss: 0.7532, Train: 67.50%, Valid: 42.50% Test: 60.78%\n",
      "Run: 08, Epoch: 10, Loss: 0.7232, Train: 71.67%, Valid: 47.50% Test: 60.78%\n",
      "Run: 08, Epoch: 11, Loss: 0.6987, Train: 75.83%, Valid: 48.75% Test: 60.78%\n",
      "Run: 08, Epoch: 12, Loss: 0.6754, Train: 75.83%, Valid: 50.00% Test: 60.78%\n",
      "Run: 08, Epoch: 13, Loss: 0.6535, Train: 75.83%, Valid: 48.75% Test: 62.75%\n",
      "Run: 08, Epoch: 14, Loss: 0.6328, Train: 77.50%, Valid: 48.75% Test: 64.71%\n",
      "Run: 08, Epoch: 15, Loss: 0.6128, Train: 79.17%, Valid: 50.00% Test: 64.71%\n",
      "Run: 08, Epoch: 16, Loss: 0.5935, Train: 80.00%, Valid: 50.00% Test: 64.71%\n",
      "Run: 08, Epoch: 17, Loss: 0.5743, Train: 81.67%, Valid: 51.25% Test: 64.71%\n",
      "Run: 08, Epoch: 18, Loss: 0.5558, Train: 81.67%, Valid: 52.50% Test: 64.71%\n",
      "Run: 08, Epoch: 19, Loss: 0.5376, Train: 85.83%, Valid: 51.25% Test: 64.71%\n",
      "Run: 08, Epoch: 20, Loss: 0.5201, Train: 86.67%, Valid: 50.00% Test: 66.67%\n",
      "Run: 08, Epoch: 21, Loss: 0.5031, Train: 86.67%, Valid: 50.00% Test: 66.67%\n",
      "Run: 08, Epoch: 22, Loss: 0.4846, Train: 89.17%, Valid: 48.75% Test: 66.67%\n",
      "Run: 08, Epoch: 23, Loss: 0.4643, Train: 89.17%, Valid: 48.75% Test: 66.67%\n",
      "Run: 08, Epoch: 24, Loss: 0.4454, Train: 90.00%, Valid: 48.75% Test: 66.67%\n",
      "Run: 08, Epoch: 25, Loss: 0.4274, Train: 90.00%, Valid: 48.75% Test: 66.67%\n",
      "Run: 08, Epoch: 26, Loss: 0.4101, Train: 90.83%, Valid: 50.00% Test: 64.71%\n",
      "Run: 08, Epoch: 27, Loss: 0.3917, Train: 90.83%, Valid: 48.75% Test: 66.67%\n",
      "Run: 08, Epoch: 28, Loss: 0.3736, Train: 90.00%, Valid: 52.50% Test: 68.63%\n",
      "Run: 08, Epoch: 29, Loss: 0.3569, Train: 90.83%, Valid: 53.75% Test: 66.67%\n",
      "Run: 08, Epoch: 30, Loss: 0.3431, Train: 91.67%, Valid: 55.00% Test: 64.71%\n",
      "Run: 08, Epoch: 31, Loss: 0.3286, Train: 91.67%, Valid: 55.00% Test: 64.71%\n",
      "Run: 08, Epoch: 32, Loss: 0.3152, Train: 92.50%, Valid: 52.50% Test: 64.71%\n",
      "Run: 08, Epoch: 33, Loss: 0.2998, Train: 95.00%, Valid: 51.25% Test: 64.71%\n",
      "Run: 08, Epoch: 34, Loss: 0.2851, Train: 95.00%, Valid: 51.25% Test: 62.75%\n",
      "Run: 08, Epoch: 35, Loss: 0.2715, Train: 95.00%, Valid: 51.25% Test: 62.75%\n",
      "Run: 08, Epoch: 36, Loss: 0.2606, Train: 93.33%, Valid: 51.25% Test: 60.78%\n",
      "Run: 08, Epoch: 37, Loss: 0.2505, Train: 92.50%, Valid: 51.25% Test: 60.78%\n",
      "Run: 08, Epoch: 38, Loss: 0.2407, Train: 93.33%, Valid: 51.25% Test: 60.78%\n",
      "Run: 08, Epoch: 39, Loss: 0.2271, Train: 93.33%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 40, Loss: 0.2193, Train: 94.17%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 41, Loss: 0.2028, Train: 94.17%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 42, Loss: 0.1976, Train: 95.00%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 43, Loss: 0.1891, Train: 95.83%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 44, Loss: 0.1800, Train: 95.83%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 45, Loss: 0.1719, Train: 96.67%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 46, Loss: 0.1639, Train: 96.67%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 47, Loss: 0.1556, Train: 96.67%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 48, Loss: 0.1471, Train: 96.67%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 49, Loss: 0.1424, Train: 97.50%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 50, Loss: 0.1336, Train: 97.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 08, Epoch: 51, Loss: 0.1260, Train: 97.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 08, Epoch: 52, Loss: 0.1190, Train: 97.50%, Valid: 53.75% Test: 56.86%\n",
      "Run: 08, Epoch: 53, Loss: 0.1121, Train: 98.33%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 54, Loss: 0.1055, Train: 98.33%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 55, Loss: 0.1007, Train: 98.33%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 56, Loss: 0.0967, Train: 98.33%, Valid: 51.25% Test: 54.90%\n",
      "Run: 08, Epoch: 57, Loss: 0.0917, Train: 99.17%, Valid: 51.25% Test: 54.90%\n",
      "Run: 08, Epoch: 58, Loss: 0.0868, Train: 99.17%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 59, Loss: 0.0823, Train: 99.17%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 60, Loss: 0.0783, Train: 99.17%, Valid: 53.75% Test: 56.86%\n",
      "Run: 08, Epoch: 61, Loss: 0.0742, Train: 99.17%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 62, Loss: 0.0704, Train: 99.17%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 63, Loss: 0.0672, Train: 99.17%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 64, Loss: 0.0645, Train: 99.17%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 65, Loss: 0.0623, Train: 99.17%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 66, Loss: 0.0597, Train: 99.17%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 67, Loss: 0.0577, Train: 99.17%, Valid: 50.00% Test: 56.86%\n",
      "Run: 08, Epoch: 68, Loss: 0.0557, Train: 99.17%, Valid: 50.00% Test: 56.86%\n",
      "Run: 08, Epoch: 69, Loss: 0.0527, Train: 98.33%, Valid: 50.00% Test: 56.86%\n",
      "Run: 08, Epoch: 70, Loss: 0.0495, Train: 99.17%, Valid: 50.00% Test: 56.86%\n",
      "Run: 08, Epoch: 71, Loss: 0.0476, Train: 99.17%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 72, Loss: 0.0459, Train: 99.17%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 73, Loss: 0.0444, Train: 99.17%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 74, Loss: 0.0425, Train: 99.17%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 75, Loss: 0.0409, Train: 99.17%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 76, Loss: 0.0403, Train: 98.33%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 77, Loss: 0.0469, Train: 98.33%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 78, Loss: 0.0442, Train: 97.50%, Valid: 52.50% Test: 52.94%\n",
      "Run: 08, Epoch: 79, Loss: 0.0432, Train: 98.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 08, Epoch: 80, Loss: 0.0457, Train: 98.33%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 81, Loss: 0.0471, Train: 98.33%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 82, Loss: 0.0479, Train: 98.33%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 83, Loss: 0.0473, Train: 98.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 08, Epoch: 84, Loss: 0.0463, Train: 98.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 08, Epoch: 85, Loss: 0.0448, Train: 99.17%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 86, Loss: 0.0435, Train: 99.17%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 87, Loss: 0.0429, Train: 98.33%, Valid: 53.75% Test: 52.94%\n",
      "Run: 08, Epoch: 88, Loss: 0.0423, Train: 99.17%, Valid: 53.75% Test: 52.94%\n",
      "Run: 08, Epoch: 89, Loss: 0.0413, Train: 98.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 90, Loss: 0.0404, Train: 98.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 91, Loss: 0.0401, Train: 98.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 92, Loss: 0.0399, Train: 98.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 93, Loss: 0.0387, Train: 99.17%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 94, Loss: 0.0378, Train: 98.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 95, Loss: 0.0380, Train: 98.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 96, Loss: 0.0381, Train: 99.17%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 97, Loss: 0.0357, Train: 98.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 98, Loss: 0.0352, Train: 98.33%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 99, Loss: 0.0346, Train: 98.33%, Valid: 51.25% Test: 54.90%\n",
      "Run: 08, Epoch: 100, Loss: 0.0337, Train: 98.33%, Valid: 51.25% Test: 54.90%\n",
      "Run 08:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 55.00\n",
      "  Final Train: 91.67\n",
      "   Final Test: 64.71\n",
      "Run: 09, Epoch: 01, Loss: 1.7860, Train: 35.00%, Valid: 32.50% Test: 27.45%\n",
      "Run: 09, Epoch: 02, Loss: 1.4120, Train: 51.67%, Valid: 38.75% Test: 39.22%\n",
      "Run: 09, Epoch: 03, Loss: 1.1080, Train: 62.50%, Valid: 36.25% Test: 41.18%\n",
      "Run: 09, Epoch: 04, Loss: 1.0030, Train: 65.00%, Valid: 36.25% Test: 41.18%\n",
      "Run: 09, Epoch: 05, Loss: 0.9316, Train: 60.83%, Valid: 41.25% Test: 47.06%\n",
      "Run: 09, Epoch: 06, Loss: 0.8628, Train: 60.83%, Valid: 43.75% Test: 45.10%\n",
      "Run: 09, Epoch: 07, Loss: 0.8091, Train: 61.67%, Valid: 42.50% Test: 45.10%\n",
      "Run: 09, Epoch: 08, Loss: 0.7658, Train: 61.67%, Valid: 42.50% Test: 43.14%\n",
      "Run: 09, Epoch: 09, Loss: 0.7279, Train: 62.50%, Valid: 41.25% Test: 43.14%\n",
      "Run: 09, Epoch: 10, Loss: 0.6927, Train: 65.83%, Valid: 42.50% Test: 43.14%\n",
      "Run: 09, Epoch: 11, Loss: 0.6603, Train: 66.67%, Valid: 42.50% Test: 43.14%\n",
      "Run: 09, Epoch: 12, Loss: 0.6310, Train: 68.33%, Valid: 43.75% Test: 45.10%\n",
      "Run: 09, Epoch: 13, Loss: 0.6035, Train: 70.83%, Valid: 46.25% Test: 47.06%\n",
      "Run: 09, Epoch: 14, Loss: 0.5774, Train: 75.00%, Valid: 46.25% Test: 49.02%\n",
      "Run: 09, Epoch: 15, Loss: 0.5539, Train: 77.50%, Valid: 47.50% Test: 49.02%\n",
      "Run: 09, Epoch: 16, Loss: 0.5325, Train: 78.33%, Valid: 48.75% Test: 50.98%\n",
      "Run: 09, Epoch: 17, Loss: 0.5121, Train: 79.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 09, Epoch: 18, Loss: 0.4929, Train: 80.83%, Valid: 50.00% Test: 50.98%\n",
      "Run: 09, Epoch: 19, Loss: 0.4741, Train: 80.83%, Valid: 50.00% Test: 49.02%\n",
      "Run: 09, Epoch: 20, Loss: 0.4565, Train: 81.67%, Valid: 48.75% Test: 49.02%\n",
      "Run: 09, Epoch: 21, Loss: 0.4408, Train: 83.33%, Valid: 48.75% Test: 47.06%\n",
      "Run: 09, Epoch: 22, Loss: 0.4262, Train: 85.00%, Valid: 48.75% Test: 49.02%\n",
      "Run: 09, Epoch: 23, Loss: 0.4114, Train: 85.83%, Valid: 48.75% Test: 49.02%\n",
      "Run: 09, Epoch: 24, Loss: 0.3963, Train: 85.83%, Valid: 48.75% Test: 49.02%\n",
      "Run: 09, Epoch: 25, Loss: 0.3818, Train: 85.83%, Valid: 47.50% Test: 49.02%\n",
      "Run: 09, Epoch: 26, Loss: 0.3677, Train: 85.00%, Valid: 48.75% Test: 45.10%\n",
      "Run: 09, Epoch: 27, Loss: 0.3540, Train: 85.83%, Valid: 50.00% Test: 45.10%\n",
      "Run: 09, Epoch: 28, Loss: 0.3403, Train: 88.33%, Valid: 47.50% Test: 47.06%\n",
      "Run: 09, Epoch: 29, Loss: 0.3279, Train: 88.33%, Valid: 46.25% Test: 47.06%\n",
      "Run: 09, Epoch: 30, Loss: 0.3161, Train: 90.00%, Valid: 47.50% Test: 45.10%\n",
      "Run: 09, Epoch: 31, Loss: 0.3047, Train: 90.83%, Valid: 47.50% Test: 45.10%\n",
      "Run: 09, Epoch: 32, Loss: 0.2933, Train: 93.33%, Valid: 47.50% Test: 45.10%\n",
      "Run: 09, Epoch: 33, Loss: 0.2820, Train: 93.33%, Valid: 48.75% Test: 45.10%\n",
      "Run: 09, Epoch: 34, Loss: 0.2711, Train: 94.17%, Valid: 48.75% Test: 47.06%\n",
      "Run: 09, Epoch: 35, Loss: 0.2602, Train: 93.33%, Valid: 47.50% Test: 47.06%\n",
      "Run: 09, Epoch: 36, Loss: 0.2501, Train: 94.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 09, Epoch: 37, Loss: 0.2406, Train: 94.17%, Valid: 43.75% Test: 45.10%\n",
      "Run: 09, Epoch: 38, Loss: 0.2310, Train: 94.17%, Valid: 42.50% Test: 45.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 39, Loss: 0.2208, Train: 94.17%, Valid: 41.25% Test: 43.14%\n",
      "Run: 09, Epoch: 40, Loss: 0.2093, Train: 95.00%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 41, Loss: 0.1979, Train: 94.17%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 42, Loss: 0.1895, Train: 95.00%, Valid: 41.25% Test: 37.25%\n",
      "Run: 09, Epoch: 43, Loss: 0.1805, Train: 95.00%, Valid: 41.25% Test: 39.22%\n",
      "Run: 09, Epoch: 44, Loss: 0.1711, Train: 95.83%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 45, Loss: 0.1616, Train: 95.83%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 46, Loss: 0.1548, Train: 95.83%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 47, Loss: 0.1466, Train: 95.83%, Valid: 43.75% Test: 43.14%\n",
      "Run: 09, Epoch: 48, Loss: 0.1393, Train: 96.67%, Valid: 42.50% Test: 43.14%\n",
      "Run: 09, Epoch: 49, Loss: 0.1317, Train: 96.67%, Valid: 43.75% Test: 43.14%\n",
      "Run: 09, Epoch: 50, Loss: 0.1239, Train: 96.67%, Valid: 43.75% Test: 45.10%\n",
      "Run: 09, Epoch: 51, Loss: 0.1174, Train: 97.50%, Valid: 43.75% Test: 45.10%\n",
      "Run: 09, Epoch: 52, Loss: 0.1099, Train: 96.67%, Valid: 43.75% Test: 45.10%\n",
      "Run: 09, Epoch: 53, Loss: 0.1038, Train: 97.50%, Valid: 43.75% Test: 45.10%\n",
      "Run: 09, Epoch: 54, Loss: 0.0966, Train: 98.33%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 55, Loss: 0.0906, Train: 98.33%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 56, Loss: 0.0850, Train: 98.33%, Valid: 42.50% Test: 43.14%\n",
      "Run: 09, Epoch: 57, Loss: 0.0801, Train: 98.33%, Valid: 42.50% Test: 43.14%\n",
      "Run: 09, Epoch: 58, Loss: 0.0759, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 59, Loss: 0.0724, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 60, Loss: 0.0687, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 61, Loss: 0.0655, Train: 98.33%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 62, Loss: 0.0635, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 63, Loss: 0.0600, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 64, Loss: 0.0572, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 65, Loss: 0.0549, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 66, Loss: 0.0526, Train: 98.33%, Valid: 41.25% Test: 39.22%\n",
      "Run: 09, Epoch: 67, Loss: 0.0498, Train: 98.33%, Valid: 42.50% Test: 39.22%\n",
      "Run: 09, Epoch: 68, Loss: 0.0483, Train: 98.33%, Valid: 43.75% Test: 39.22%\n",
      "Run: 09, Epoch: 69, Loss: 0.0462, Train: 98.33%, Valid: 43.75% Test: 39.22%\n",
      "Run: 09, Epoch: 70, Loss: 0.0442, Train: 98.33%, Valid: 43.75% Test: 39.22%\n",
      "Run: 09, Epoch: 71, Loss: 0.0429, Train: 98.33%, Valid: 43.75% Test: 41.18%\n",
      "Run: 09, Epoch: 72, Loss: 0.0411, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 73, Loss: 0.0398, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 74, Loss: 0.0388, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 75, Loss: 0.0380, Train: 99.17%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 76, Loss: 0.0363, Train: 99.17%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 77, Loss: 0.0355, Train: 99.17%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 78, Loss: 0.0350, Train: 99.17%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 79, Loss: 0.0339, Train: 99.17%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 80, Loss: 0.0327, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 81, Loss: 0.0323, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 82, Loss: 0.0328, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 83, Loss: 0.0329, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 84, Loss: 0.0310, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 85, Loss: 0.0305, Train: 99.17%, Valid: 40.00% Test: 41.18%\n",
      "Run: 09, Epoch: 86, Loss: 0.0302, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 87, Loss: 0.0332, Train: 97.50%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 88, Loss: 0.0405, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 89, Loss: 0.0383, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 90, Loss: 0.0372, Train: 98.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 91, Loss: 0.0395, Train: 98.33%, Valid: 41.25% Test: 39.22%\n",
      "Run: 09, Epoch: 92, Loss: 0.0363, Train: 98.33%, Valid: 41.25% Test: 37.25%\n",
      "Run: 09, Epoch: 93, Loss: 0.0406, Train: 99.17%, Valid: 41.25% Test: 37.25%\n",
      "Run: 09, Epoch: 94, Loss: 0.0368, Train: 99.17%, Valid: 41.25% Test: 37.25%\n",
      "Run: 09, Epoch: 95, Loss: 0.0417, Train: 99.17%, Valid: 42.50% Test: 39.22%\n",
      "Run: 09, Epoch: 96, Loss: 0.0343, Train: 99.17%, Valid: 42.50% Test: 39.22%\n",
      "Run: 09, Epoch: 97, Loss: 0.0345, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 98, Loss: 0.0392, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 99, Loss: 0.0340, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 100, Loss: 0.0410, Train: 99.17%, Valid: 41.25% Test: 41.18%\n",
      "Run 09:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 50.00\n",
      "  Final Train: 80.83\n",
      "   Final Test: 50.98\n",
      "Run: 10, Epoch: 01, Loss: 2.1139, Train: 37.50%, Valid: 22.50% Test: 23.53%\n",
      "Run: 10, Epoch: 02, Loss: 1.4566, Train: 38.33%, Valid: 25.00% Test: 21.57%\n",
      "Run: 10, Epoch: 03, Loss: 1.2789, Train: 61.67%, Valid: 42.50% Test: 39.22%\n",
      "Run: 10, Epoch: 04, Loss: 1.0249, Train: 65.83%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 05, Loss: 0.9463, Train: 68.33%, Valid: 53.75% Test: 50.98%\n",
      "Run: 10, Epoch: 06, Loss: 0.8543, Train: 70.83%, Valid: 58.75% Test: 52.94%\n",
      "Run: 10, Epoch: 07, Loss: 0.8196, Train: 73.33%, Valid: 55.00% Test: 54.90%\n",
      "Run: 10, Epoch: 08, Loss: 0.7292, Train: 74.17%, Valid: 55.00% Test: 60.78%\n",
      "Run: 10, Epoch: 09, Loss: 0.7054, Train: 75.83%, Valid: 55.00% Test: 62.75%\n",
      "Run: 10, Epoch: 10, Loss: 0.6710, Train: 76.67%, Valid: 57.50% Test: 62.75%\n",
      "Run: 10, Epoch: 11, Loss: 0.6375, Train: 75.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 10, Epoch: 12, Loss: 0.6064, Train: 77.50%, Valid: 58.75% Test: 56.86%\n",
      "Run: 10, Epoch: 13, Loss: 0.5759, Train: 78.33%, Valid: 57.50% Test: 58.82%\n",
      "Run: 10, Epoch: 14, Loss: 0.5454, Train: 80.00%, Valid: 57.50% Test: 58.82%\n",
      "Run: 10, Epoch: 15, Loss: 0.5159, Train: 80.83%, Valid: 57.50% Test: 56.86%\n",
      "Run: 10, Epoch: 16, Loss: 0.4933, Train: 83.33%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 17, Loss: 0.4730, Train: 84.17%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 18, Loss: 0.4541, Train: 85.83%, Valid: 55.00% Test: 56.86%\n",
      "Run: 10, Epoch: 19, Loss: 0.4349, Train: 86.67%, Valid: 53.75% Test: 56.86%\n",
      "Run: 10, Epoch: 20, Loss: 0.4182, Train: 84.17%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 21, Loss: 0.4034, Train: 85.00%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 22, Loss: 0.3902, Train: 85.83%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 23, Loss: 0.3775, Train: 85.83%, Valid: 57.50% Test: 58.82%\n",
      "Run: 10, Epoch: 24, Loss: 0.3652, Train: 86.67%, Valid: 56.25% Test: 60.78%\n",
      "Run: 10, Epoch: 25, Loss: 0.3536, Train: 87.50%, Valid: 56.25% Test: 60.78%\n",
      "Run: 10, Epoch: 26, Loss: 0.3422, Train: 86.67%, Valid: 56.25% Test: 60.78%\n",
      "Run: 10, Epoch: 27, Loss: 0.3314, Train: 89.17%, Valid: 56.25% Test: 62.75%\n",
      "Run: 10, Epoch: 28, Loss: 0.3206, Train: 90.00%, Valid: 56.25% Test: 62.75%\n",
      "Run: 10, Epoch: 29, Loss: 0.3106, Train: 91.67%, Valid: 56.25% Test: 62.75%\n",
      "Run: 10, Epoch: 30, Loss: 0.3012, Train: 90.83%, Valid: 56.25% Test: 62.75%\n",
      "Run: 10, Epoch: 31, Loss: 0.2920, Train: 89.17%, Valid: 55.00% Test: 62.75%\n",
      "Run: 10, Epoch: 32, Loss: 0.2842, Train: 90.00%, Valid: 55.00% Test: 62.75%\n",
      "Run: 10, Epoch: 33, Loss: 0.2763, Train: 90.83%, Valid: 55.00% Test: 62.75%\n",
      "Run: 10, Epoch: 34, Loss: 0.2686, Train: 90.83%, Valid: 55.00% Test: 60.78%\n",
      "Run: 10, Epoch: 35, Loss: 0.2614, Train: 90.83%, Valid: 55.00% Test: 60.78%\n",
      "Run: 10, Epoch: 36, Loss: 0.2543, Train: 90.83%, Valid: 53.75% Test: 60.78%\n",
      "Run: 10, Epoch: 37, Loss: 0.2466, Train: 90.00%, Valid: 53.75% Test: 60.78%\n",
      "Run: 10, Epoch: 38, Loss: 0.2394, Train: 90.83%, Valid: 53.75% Test: 60.78%\n",
      "Run: 10, Epoch: 39, Loss: 0.2325, Train: 91.67%, Valid: 55.00% Test: 60.78%\n",
      "Run: 10, Epoch: 40, Loss: 0.2258, Train: 92.50%, Valid: 55.00% Test: 60.78%\n",
      "Run: 10, Epoch: 41, Loss: 0.2195, Train: 94.17%, Valid: 55.00% Test: 60.78%\n",
      "Run: 10, Epoch: 42, Loss: 0.2128, Train: 93.33%, Valid: 55.00% Test: 60.78%\n",
      "Run: 10, Epoch: 43, Loss: 0.2063, Train: 94.17%, Valid: 52.50% Test: 62.75%\n",
      "Run: 10, Epoch: 44, Loss: 0.2004, Train: 95.00%, Valid: 52.50% Test: 62.75%\n",
      "Run: 10, Epoch: 45, Loss: 0.1931, Train: 94.17%, Valid: 52.50% Test: 62.75%\n",
      "Run: 10, Epoch: 46, Loss: 0.2680, Train: 95.00%, Valid: 51.25% Test: 62.75%\n",
      "Run: 10, Epoch: 47, Loss: 0.1864, Train: 95.00%, Valid: 53.75% Test: 62.75%\n",
      "Run: 10, Epoch: 48, Loss: 0.1865, Train: 94.17%, Valid: 51.25% Test: 62.75%\n",
      "Run: 10, Epoch: 49, Loss: 0.1864, Train: 94.17%, Valid: 52.50% Test: 62.75%\n",
      "Run: 10, Epoch: 50, Loss: 0.1830, Train: 93.33%, Valid: 52.50% Test: 62.75%\n",
      "Run: 10, Epoch: 51, Loss: 0.1788, Train: 94.17%, Valid: 55.00% Test: 60.78%\n",
      "Run: 10, Epoch: 52, Loss: 0.1715, Train: 95.83%, Valid: 53.75% Test: 60.78%\n",
      "Run: 10, Epoch: 53, Loss: 0.1646, Train: 96.67%, Valid: 53.75% Test: 60.78%\n",
      "Run: 10, Epoch: 54, Loss: 0.1582, Train: 96.67%, Valid: 55.00% Test: 60.78%\n",
      "Run: 10, Epoch: 55, Loss: 0.1513, Train: 97.50%, Valid: 52.50% Test: 62.75%\n",
      "Run: 10, Epoch: 56, Loss: 0.1459, Train: 97.50%, Valid: 53.75% Test: 62.75%\n",
      "Run: 10, Epoch: 57, Loss: 0.1408, Train: 98.33%, Valid: 52.50% Test: 62.75%\n",
      "Run: 10, Epoch: 58, Loss: 0.1355, Train: 98.33%, Valid: 52.50% Test: 60.78%\n",
      "Run: 10, Epoch: 59, Loss: 0.1309, Train: 99.17%, Valid: 52.50% Test: 60.78%\n",
      "Run: 10, Epoch: 60, Loss: 0.1257, Train: 99.17%, Valid: 52.50% Test: 60.78%\n",
      "Run: 10, Epoch: 61, Loss: 0.1208, Train: 99.17%, Valid: 52.50% Test: 60.78%\n",
      "Run: 10, Epoch: 62, Loss: 0.1169, Train: 99.17%, Valid: 52.50% Test: 60.78%\n",
      "Run: 10, Epoch: 63, Loss: 0.1114, Train: 98.33%, Valid: 51.25% Test: 60.78%\n",
      "Run: 10, Epoch: 64, Loss: 0.1067, Train: 98.33%, Valid: 51.25% Test: 60.78%\n",
      "Run: 10, Epoch: 65, Loss: 0.1019, Train: 98.33%, Valid: 50.00% Test: 60.78%\n",
      "Run: 10, Epoch: 66, Loss: 0.0979, Train: 98.33%, Valid: 48.75% Test: 60.78%\n",
      "Run: 10, Epoch: 67, Loss: 0.0933, Train: 99.17%, Valid: 48.75% Test: 60.78%\n",
      "Run: 10, Epoch: 68, Loss: 0.0910, Train: 99.17%, Valid: 47.50% Test: 60.78%\n",
      "Run: 10, Epoch: 69, Loss: 0.0860, Train: 99.17%, Valid: 46.25% Test: 60.78%\n",
      "Run: 10, Epoch: 70, Loss: 0.0812, Train: 99.17%, Valid: 45.00% Test: 60.78%\n",
      "Run: 10, Epoch: 71, Loss: 0.0789, Train: 98.33%, Valid: 45.00% Test: 60.78%\n",
      "Run: 10, Epoch: 72, Loss: 0.0749, Train: 99.17%, Valid: 45.00% Test: 60.78%\n",
      "Run: 10, Epoch: 73, Loss: 0.0743, Train: 99.17%, Valid: 46.25% Test: 60.78%\n",
      "Run: 10, Epoch: 74, Loss: 0.0751, Train: 99.17%, Valid: 46.25% Test: 56.86%\n",
      "Run: 10, Epoch: 75, Loss: 0.0695, Train: 98.33%, Valid: 46.25% Test: 54.90%\n",
      "Run: 10, Epoch: 76, Loss: 0.0659, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 10, Epoch: 77, Loss: 0.0639, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 10, Epoch: 78, Loss: 0.0593, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 10, Epoch: 79, Loss: 0.0580, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 10, Epoch: 80, Loss: 0.0531, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 10, Epoch: 81, Loss: 0.0513, Train: 99.17%, Valid: 45.00% Test: 54.90%\n",
      "Run: 10, Epoch: 82, Loss: 0.0486, Train: 99.17%, Valid: 46.25% Test: 54.90%\n",
      "Run: 10, Epoch: 83, Loss: 0.0469, Train: 99.17%, Valid: 46.25% Test: 54.90%\n",
      "Run: 10, Epoch: 84, Loss: 0.0458, Train: 99.17%, Valid: 43.75% Test: 54.90%\n",
      "Run: 10, Epoch: 85, Loss: 0.0432, Train: 100.00%, Valid: 45.00% Test: 54.90%\n",
      "Run: 10, Epoch: 86, Loss: 0.0414, Train: 100.00%, Valid: 45.00% Test: 54.90%\n",
      "Run: 10, Epoch: 87, Loss: 0.0400, Train: 100.00%, Valid: 45.00% Test: 54.90%\n",
      "Run: 10, Epoch: 88, Loss: 0.0385, Train: 100.00%, Valid: 45.00% Test: 54.90%\n",
      "Run: 10, Epoch: 89, Loss: 0.0370, Train: 100.00%, Valid: 45.00% Test: 54.90%\n",
      "Run: 10, Epoch: 90, Loss: 0.0354, Train: 100.00%, Valid: 45.00% Test: 54.90%\n",
      "Run: 10, Epoch: 91, Loss: 0.0344, Train: 100.00%, Valid: 45.00% Test: 54.90%\n",
      "Run: 10, Epoch: 92, Loss: 0.0332, Train: 100.00%, Valid: 46.25% Test: 54.90%\n",
      "Run: 10, Epoch: 93, Loss: 0.0321, Train: 100.00%, Valid: 46.25% Test: 54.90%\n",
      "Run: 10, Epoch: 94, Loss: 0.0308, Train: 100.00%, Valid: 46.25% Test: 54.90%\n",
      "Run: 10, Epoch: 95, Loss: 0.0296, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 10, Epoch: 96, Loss: 0.0287, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 10, Epoch: 97, Loss: 0.0277, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 10, Epoch: 98, Loss: 0.0268, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 10, Epoch: 99, Loss: 0.0258, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 10, Epoch: 100, Loss: 0.0248, Train: 100.00%, Valid: 47.50% Test: 54.90%\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 58.75\n",
      "  Final Train: 70.83\n",
      "   Final Test: 52.94\n",
      "All runs:\n",
      "Highest Train: 98.75 Â± 1.58\n",
      "Highest Valid: 55.38 Â± 4.60\n",
      "  Final Train: 77.33 Â± 12.19\n",
      "   Final Test: 52.75 Â± 7.87\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 8, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.0, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin',transform=T.ToSparseTensor())\n",
    "    data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = GAT(data.num_features, args.hidden_channels, dataset.num_classes, args.num_layers,\n",
    "                    args.dropout,args.heads)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52f151",
   "metadata": {},
   "source": [
    "# Wise Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a09514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f82a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "      <th>1701</th>\n",
       "      <th>1702</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 1704 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  1694  1695  1696  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "   1697  1698  1699  1700  1701  1702  class  \n",
       "0   0.0   0.0   0.0   0.0   1.0   0.0      1  \n",
       "1   0.0   0.0   0.0   0.0   1.0   0.0      2  \n",
       "2   0.0   0.0   0.0   0.0   1.0   0.0      2  \n",
       "3   0.0   0.0   0.0   0.0   1.0   0.0      2  \n",
       "4   0.0   0.0   0.0   0.0   1.0   0.0      1  \n",
       "\n",
       "[5 rows x 1704 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Domain_Fec=pd.DataFrame(data.x.numpy())\n",
    "label=pd.DataFrame(data.y.numpy(),columns =['class'])\n",
    "Data=pd.concat([Domain_Fec,label], axis=1)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2642b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_nodes=len(data.y)\n",
    "fe_len=len(data.x[0])\n",
    "catagories=Data['class'].to_numpy()\n",
    "data_by_class = {cls: Data.loc[Data['class'] == cls].drop(['class'], axis=1) for cls in range(max(catagories) + 1)}\n",
    "basis = [[max(df[i]) for i in range(len(df.columns))] for df in data_by_class.values()]\n",
    "sel_basis = [[int(list(df[i].to_numpy()).count(1) >= int(len(df[i].index)*0.2)) \n",
    "              for i in range(len(df.columns))]\n",
    "             for df in data_by_class.values()]\n",
    "feature_names = [ii for ii in range(fe_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4db5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fec=[]\n",
    "for i in range(Number_nodes):\n",
    "    vec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=0\n",
    "    count1=0\n",
    "    count2=0\n",
    "    count3=0\n",
    "    count4=0\n",
    "    for j in range(fe_len):\n",
    "        if f[j]==1 and basis[0][j]==1:\n",
    "            count=count+1;\n",
    "        if f[j]==1 and basis[1][j]==1:\n",
    "            count1=count1+1;\n",
    "        if f[j]==1 and basis[2][j]==1:\n",
    "            count2=count2+1;\n",
    "        if f[j]==1 and basis[3][j]==1:\n",
    "            count3=count3+1;\n",
    "        if f[j]==1 and basis[4][j]==1:\n",
    "            count4=count4+1;\n",
    "    vec.append(count)\n",
    "    vec.append(count1)\n",
    "    vec.append(count2)\n",
    "    vec.append(count3)\n",
    "    vec.append(count4)\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    Fec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084212fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Fec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a920e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFec=[]\n",
    "for i in range(Number_nodes):\n",
    "    Svec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=0\n",
    "    count1=0\n",
    "    count2=0\n",
    "    count3=0\n",
    "    count4=0\n",
    "    for j in range(fe_len):\n",
    "        if f[j]==1 and sel_basis[0][j]==1:\n",
    "            count=count+1;\n",
    "        if f[j]==1 and sel_basis[1][j]==1:\n",
    "            count1=count1+1;\n",
    "        if f[j]==1 and sel_basis[2][j]==1:\n",
    "            count2=count2+1;\n",
    "        if f[j]==1 and sel_basis[3][j]==1:\n",
    "            count3=count3+1;\n",
    "        if f[j]==1 and sel_basis[4][j]==1:\n",
    "            count4=count4+1;\n",
    "    Svec.append(count)\n",
    "    Svec.append(count1)\n",
    "    Svec.append(count2)\n",
    "    Svec.append(count3)\n",
    "    Svec.append(count4)\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    SFec.append(Svec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SFec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054ee569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[46., 72., 68.,  ..., 26., 42., 38.],\n",
      "        [39., 47., 49.,  ..., 34., 39., 32.],\n",
      "        [42., 48., 51.,  ..., 34., 39., 35.],\n",
      "        ...,\n",
      "        [22., 29., 34.,  ..., 18., 23., 22.],\n",
      "        [53., 86., 77.,  ..., 24., 38., 29.],\n",
      "        [50., 72., 86.,  ..., 21., 27., 26.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inc_fe=torch.tensor(Fec)\n",
    "sel_fe=torch.tensor(SFec)\n",
    "CC_domain=torch.cat((Inc_fe, sel_fe), 1).float()\n",
    "print(CC_domain)\n",
    "CC_domain.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f7d51",
   "metadata": {},
   "source": [
    "# W-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c6fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 10], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4763ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x1528f2a70>\n",
      "Run: 01, Epoch: 01, Loss: 2.1641, Train: 4.17%, Valid: 6.25% Test: 1.96%\n",
      "Run: 01, Epoch: 02, Loss: 2.0564, Train: 4.17%, Valid: 6.25% Test: 1.96%\n",
      "Run: 01, Epoch: 03, Loss: 1.8671, Train: 3.33%, Valid: 7.50% Test: 1.96%\n",
      "Run: 01, Epoch: 04, Loss: 1.7917, Train: 3.33%, Valid: 7.50% Test: 1.96%\n",
      "Run: 01, Epoch: 05, Loss: 1.6677, Train: 2.50%, Valid: 7.50% Test: 3.92%\n",
      "Run: 01, Epoch: 06, Loss: 1.6619, Train: 3.33%, Valid: 6.25% Test: 7.84%\n",
      "Run: 01, Epoch: 07, Loss: 1.6273, Train: 8.33%, Valid: 10.00% Test: 19.61%\n",
      "Run: 01, Epoch: 08, Loss: 1.5613, Train: 14.17%, Valid: 11.25% Test: 17.65%\n",
      "Run: 01, Epoch: 09, Loss: 1.5361, Train: 14.17%, Valid: 11.25% Test: 17.65%\n",
      "Run: 01, Epoch: 10, Loss: 1.4813, Train: 15.00%, Valid: 11.25% Test: 17.65%\n",
      "Run: 01, Epoch: 11, Loss: 1.4084, Train: 16.67%, Valid: 17.50% Test: 15.69%\n",
      "Run: 01, Epoch: 12, Loss: 1.5021, Train: 20.00%, Valid: 20.00% Test: 21.57%\n",
      "Run: 01, Epoch: 13, Loss: 1.4471, Train: 21.67%, Valid: 21.25% Test: 25.49%\n",
      "Run: 01, Epoch: 14, Loss: 1.5170, Train: 22.50%, Valid: 22.50% Test: 25.49%\n",
      "Run: 01, Epoch: 15, Loss: 1.3844, Train: 24.17%, Valid: 27.50% Test: 25.49%\n",
      "Run: 01, Epoch: 16, Loss: 1.4025, Train: 26.67%, Valid: 30.00% Test: 27.45%\n",
      "Run: 01, Epoch: 17, Loss: 1.3740, Train: 30.83%, Valid: 32.50% Test: 35.29%\n",
      "Run: 01, Epoch: 18, Loss: 1.3442, Train: 36.67%, Valid: 46.25% Test: 39.22%\n",
      "Run: 01, Epoch: 19, Loss: 1.4625, Train: 41.67%, Valid: 50.00% Test: 43.14%\n",
      "Run: 01, Epoch: 20, Loss: 1.3602, Train: 40.00%, Valid: 53.75% Test: 39.22%\n",
      "Run: 01, Epoch: 21, Loss: 1.3088, Train: 41.67%, Valid: 52.50% Test: 50.98%\n",
      "Run: 01, Epoch: 22, Loss: 1.3069, Train: 45.00%, Valid: 55.00% Test: 49.02%\n",
      "Run: 01, Epoch: 23, Loss: 1.4003, Train: 45.83%, Valid: 55.00% Test: 49.02%\n",
      "Run: 01, Epoch: 24, Loss: 1.3452, Train: 45.83%, Valid: 55.00% Test: 49.02%\n",
      "Run: 01, Epoch: 25, Loss: 1.4432, Train: 45.00%, Valid: 53.75% Test: 49.02%\n",
      "Run: 01, Epoch: 26, Loss: 1.3569, Train: 46.67%, Valid: 53.75% Test: 50.98%\n",
      "Run: 01, Epoch: 27, Loss: 1.3749, Train: 45.83%, Valid: 53.75% Test: 50.98%\n",
      "Run: 01, Epoch: 28, Loss: 1.3309, Train: 45.00%, Valid: 53.75% Test: 50.98%\n",
      "Run: 01, Epoch: 29, Loss: 1.3322, Train: 45.83%, Valid: 53.75% Test: 50.98%\n",
      "Run: 01, Epoch: 30, Loss: 1.3129, Train: 46.67%, Valid: 53.75% Test: 52.94%\n",
      "Run: 01, Epoch: 31, Loss: 1.3353, Train: 50.00%, Valid: 53.75% Test: 52.94%\n",
      "Run: 01, Epoch: 32, Loss: 1.3295, Train: 50.83%, Valid: 53.75% Test: 52.94%\n",
      "Run: 01, Epoch: 33, Loss: 1.2856, Train: 50.00%, Valid: 53.75% Test: 50.98%\n",
      "Run: 01, Epoch: 34, Loss: 1.3165, Train: 50.00%, Valid: 53.75% Test: 52.94%\n",
      "Run: 01, Epoch: 35, Loss: 1.2606, Train: 50.00%, Valid: 53.75% Test: 52.94%\n",
      "Run: 01, Epoch: 36, Loss: 1.2654, Train: 50.83%, Valid: 52.50% Test: 54.90%\n",
      "Run: 01, Epoch: 37, Loss: 1.3139, Train: 50.00%, Valid: 52.50% Test: 54.90%\n",
      "Run: 01, Epoch: 38, Loss: 1.3625, Train: 50.00%, Valid: 52.50% Test: 54.90%\n",
      "Run: 01, Epoch: 39, Loss: 1.2805, Train: 50.00%, Valid: 51.25% Test: 54.90%\n",
      "Run: 01, Epoch: 40, Loss: 1.2576, Train: 50.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 41, Loss: 1.2637, Train: 50.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 42, Loss: 1.2934, Train: 48.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 43, Loss: 1.2503, Train: 48.33%, Valid: 52.50% Test: 54.90%\n",
      "Run: 01, Epoch: 44, Loss: 1.2548, Train: 49.17%, Valid: 52.50% Test: 54.90%\n",
      "Run: 01, Epoch: 45, Loss: 1.2344, Train: 49.17%, Valid: 56.25% Test: 56.86%\n",
      "Run: 01, Epoch: 46, Loss: 1.2614, Train: 50.83%, Valid: 56.25% Test: 56.86%\n",
      "Run: 01, Epoch: 47, Loss: 1.2474, Train: 50.00%, Valid: 56.25% Test: 56.86%\n",
      "Run: 01, Epoch: 48, Loss: 1.3126, Train: 49.17%, Valid: 55.00% Test: 56.86%\n",
      "Run: 01, Epoch: 49, Loss: 1.2748, Train: 49.17%, Valid: 53.75% Test: 56.86%\n",
      "Run: 01, Epoch: 50, Loss: 1.3052, Train: 50.83%, Valid: 53.75% Test: 56.86%\n",
      "Run: 01, Epoch: 51, Loss: 1.2212, Train: 51.67%, Valid: 53.75% Test: 54.90%\n",
      "Run: 01, Epoch: 52, Loss: 1.2146, Train: 50.00%, Valid: 53.75% Test: 54.90%\n",
      "Run: 01, Epoch: 53, Loss: 1.2116, Train: 50.00%, Valid: 53.75% Test: 54.90%\n",
      "Run: 01, Epoch: 54, Loss: 1.1887, Train: 50.00%, Valid: 53.75% Test: 54.90%\n",
      "Run: 01, Epoch: 55, Loss: 1.2697, Train: 50.00%, Valid: 53.75% Test: 54.90%\n",
      "Run: 01, Epoch: 56, Loss: 1.2418, Train: 49.17%, Valid: 53.75% Test: 54.90%\n",
      "Run: 01, Epoch: 57, Loss: 1.2385, Train: 50.00%, Valid: 55.00% Test: 54.90%\n",
      "Run: 01, Epoch: 58, Loss: 1.1845, Train: 51.67%, Valid: 55.00% Test: 54.90%\n",
      "Run: 01, Epoch: 59, Loss: 1.2165, Train: 51.67%, Valid: 55.00% Test: 54.90%\n",
      "Run: 01, Epoch: 60, Loss: 1.2674, Train: 51.67%, Valid: 55.00% Test: 54.90%\n",
      "Run: 01, Epoch: 61, Loss: 1.1821, Train: 52.50%, Valid: 55.00% Test: 54.90%\n",
      "Run: 01, Epoch: 62, Loss: 1.2029, Train: 51.67%, Valid: 56.25% Test: 54.90%\n",
      "Run: 01, Epoch: 63, Loss: 1.2574, Train: 52.50%, Valid: 58.75% Test: 54.90%\n",
      "Run: 01, Epoch: 64, Loss: 1.2252, Train: 52.50%, Valid: 58.75% Test: 56.86%\n",
      "Run: 01, Epoch: 65, Loss: 1.2599, Train: 54.17%, Valid: 58.75% Test: 58.82%\n",
      "Run: 01, Epoch: 66, Loss: 1.1421, Train: 55.00%, Valid: 61.25% Test: 56.86%\n",
      "Run: 01, Epoch: 67, Loss: 1.2020, Train: 52.50%, Valid: 63.75% Test: 56.86%\n",
      "Run: 01, Epoch: 68, Loss: 1.1333, Train: 51.67%, Valid: 63.75% Test: 58.82%\n",
      "Run: 01, Epoch: 69, Loss: 1.2032, Train: 51.67%, Valid: 63.75% Test: 58.82%\n",
      "Run: 01, Epoch: 70, Loss: 1.1701, Train: 52.50%, Valid: 63.75% Test: 58.82%\n",
      "Run: 01, Epoch: 71, Loss: 1.1937, Train: 52.50%, Valid: 63.75% Test: 58.82%\n",
      "Run: 01, Epoch: 72, Loss: 1.1367, Train: 52.50%, Valid: 63.75% Test: 58.82%\n",
      "Run: 01, Epoch: 73, Loss: 1.1787, Train: 52.50%, Valid: 63.75% Test: 58.82%\n",
      "Run: 01, Epoch: 74, Loss: 1.1404, Train: 52.50%, Valid: 63.75% Test: 58.82%\n",
      "Run: 01, Epoch: 75, Loss: 1.2134, Train: 52.50%, Valid: 63.75% Test: 58.82%\n",
      "Run: 01, Epoch: 76, Loss: 1.2275, Train: 52.50%, Valid: 63.75% Test: 56.86%\n",
      "Run: 01, Epoch: 77, Loss: 1.1714, Train: 52.50%, Valid: 63.75% Test: 56.86%\n",
      "Run: 01, Epoch: 78, Loss: 1.1538, Train: 51.67%, Valid: 63.75% Test: 56.86%\n",
      "Run: 01, Epoch: 79, Loss: 1.2065, Train: 54.17%, Valid: 65.00% Test: 56.86%\n",
      "Run: 01, Epoch: 80, Loss: 1.2706, Train: 53.33%, Valid: 66.25% Test: 56.86%\n",
      "Run: 01, Epoch: 81, Loss: 1.1654, Train: 50.83%, Valid: 63.75% Test: 56.86%\n",
      "Run: 01, Epoch: 82, Loss: 1.1745, Train: 52.50%, Valid: 65.00% Test: 56.86%\n",
      "Run: 01, Epoch: 83, Loss: 1.2302, Train: 53.33%, Valid: 65.00% Test: 56.86%\n",
      "Run: 01, Epoch: 84, Loss: 1.0418, Train: 54.17%, Valid: 63.75% Test: 56.86%\n",
      "Run: 01, Epoch: 85, Loss: 1.1179, Train: 55.00%, Valid: 63.75% Test: 56.86%\n",
      "Run: 01, Epoch: 86, Loss: 1.2145, Train: 54.17%, Valid: 63.75% Test: 56.86%\n",
      "Run: 01, Epoch: 87, Loss: 1.2151, Train: 52.50%, Valid: 66.25% Test: 56.86%\n",
      "Run: 01, Epoch: 88, Loss: 1.1290, Train: 53.33%, Valid: 66.25% Test: 56.86%\n",
      "Run: 01, Epoch: 89, Loss: 1.1214, Train: 53.33%, Valid: 66.25% Test: 56.86%\n",
      "Run: 01, Epoch: 90, Loss: 1.1594, Train: 53.33%, Valid: 66.25% Test: 56.86%\n",
      "Run: 01, Epoch: 91, Loss: 1.1286, Train: 55.00%, Valid: 67.50% Test: 56.86%\n",
      "Run: 01, Epoch: 92, Loss: 1.1413, Train: 55.83%, Valid: 67.50% Test: 56.86%\n",
      "Run: 01, Epoch: 93, Loss: 1.1314, Train: 55.83%, Valid: 67.50% Test: 56.86%\n",
      "Run: 01, Epoch: 94, Loss: 1.0774, Train: 55.83%, Valid: 67.50% Test: 54.90%\n",
      "Run: 01, Epoch: 95, Loss: 1.1679, Train: 55.00%, Valid: 68.75% Test: 56.86%\n",
      "Run: 01, Epoch: 96, Loss: 1.0818, Train: 55.83%, Valid: 68.75% Test: 54.90%\n",
      "Run: 01, Epoch: 97, Loss: 1.0890, Train: 55.00%, Valid: 68.75% Test: 54.90%\n",
      "Run: 01, Epoch: 98, Loss: 1.1202, Train: 55.83%, Valid: 67.50% Test: 54.90%\n",
      "Run: 01, Epoch: 99, Loss: 1.1311, Train: 55.83%, Valid: 66.25% Test: 50.98%\n",
      "Run: 01, Epoch: 100, Loss: 1.0899, Train: 53.33%, Valid: 66.25% Test: 52.94%\n",
      "Run 01:\n",
      "Highest Train: 55.83\n",
      "Highest Valid: 68.75\n",
      "  Final Train: 55.00\n",
      "   Final Test: 56.86\n",
      "Run: 02, Epoch: 01, Loss: 1.7175, Train: 31.67%, Valid: 26.25% Test: 31.37%\n",
      "Run: 02, Epoch: 02, Loss: 1.6190, Train: 24.17%, Valid: 12.50% Test: 15.69%\n",
      "Run: 02, Epoch: 03, Loss: 1.5064, Train: 18.33%, Valid: 12.50% Test: 7.84%\n",
      "Run: 02, Epoch: 04, Loss: 1.5692, Train: 23.33%, Valid: 16.25% Test: 19.61%\n",
      "Run: 02, Epoch: 05, Loss: 1.4353, Train: 23.33%, Valid: 25.00% Test: 29.41%\n",
      "Run: 02, Epoch: 06, Loss: 1.3713, Train: 31.67%, Valid: 31.25% Test: 35.29%\n",
      "Run: 02, Epoch: 07, Loss: 1.3271, Train: 34.17%, Valid: 32.50% Test: 35.29%\n",
      "Run: 02, Epoch: 08, Loss: 1.4083, Train: 33.33%, Valid: 28.75% Test: 35.29%\n",
      "Run: 02, Epoch: 09, Loss: 1.3373, Train: 31.67%, Valid: 31.25% Test: 37.25%\n",
      "Run: 02, Epoch: 10, Loss: 1.2947, Train: 43.33%, Valid: 35.00% Test: 47.06%\n",
      "Run: 02, Epoch: 11, Loss: 1.3023, Train: 45.83%, Valid: 40.00% Test: 52.94%\n",
      "Run: 02, Epoch: 12, Loss: 1.2884, Train: 46.67%, Valid: 41.25% Test: 54.90%\n",
      "Run: 02, Epoch: 13, Loss: 1.3477, Train: 49.17%, Valid: 42.50% Test: 58.82%\n",
      "Run: 02, Epoch: 14, Loss: 1.2273, Train: 51.67%, Valid: 41.25% Test: 58.82%\n",
      "Run: 02, Epoch: 15, Loss: 1.2364, Train: 51.67%, Valid: 46.25% Test: 64.71%\n",
      "Run: 02, Epoch: 16, Loss: 1.2236, Train: 50.00%, Valid: 48.75% Test: 64.71%\n",
      "Run: 02, Epoch: 17, Loss: 1.2204, Train: 53.33%, Valid: 48.75% Test: 66.67%\n",
      "Run: 02, Epoch: 18, Loss: 1.3452, Train: 51.67%, Valid: 45.00% Test: 64.71%\n",
      "Run: 02, Epoch: 19, Loss: 1.1995, Train: 50.00%, Valid: 45.00% Test: 62.75%\n",
      "Run: 02, Epoch: 20, Loss: 1.2511, Train: 49.17%, Valid: 46.25% Test: 62.75%\n",
      "Run: 02, Epoch: 21, Loss: 1.2597, Train: 50.00%, Valid: 45.00% Test: 62.75%\n",
      "Run: 02, Epoch: 22, Loss: 1.2634, Train: 50.83%, Valid: 43.75% Test: 62.75%\n",
      "Run: 02, Epoch: 23, Loss: 1.2555, Train: 50.83%, Valid: 45.00% Test: 62.75%\n",
      "Run: 02, Epoch: 24, Loss: 1.1880, Train: 51.67%, Valid: 43.75% Test: 62.75%\n",
      "Run: 02, Epoch: 25, Loss: 1.1967, Train: 52.50%, Valid: 43.75% Test: 62.75%\n",
      "Run: 02, Epoch: 26, Loss: 1.1425, Train: 53.33%, Valid: 43.75% Test: 62.75%\n",
      "Run: 02, Epoch: 27, Loss: 1.1147, Train: 53.33%, Valid: 42.50% Test: 62.75%\n",
      "Run: 02, Epoch: 28, Loss: 1.2585, Train: 53.33%, Valid: 42.50% Test: 62.75%\n",
      "Run: 02, Epoch: 29, Loss: 1.1665, Train: 53.33%, Valid: 42.50% Test: 62.75%\n",
      "Run: 02, Epoch: 30, Loss: 1.1765, Train: 53.33%, Valid: 43.75% Test: 62.75%\n",
      "Run: 02, Epoch: 31, Loss: 1.1294, Train: 53.33%, Valid: 43.75% Test: 64.71%\n",
      "Run: 02, Epoch: 32, Loss: 1.2058, Train: 50.83%, Valid: 43.75% Test: 64.71%\n",
      "Run: 02, Epoch: 33, Loss: 1.1336, Train: 50.83%, Valid: 43.75% Test: 64.71%\n",
      "Run: 02, Epoch: 34, Loss: 1.1581, Train: 52.50%, Valid: 43.75% Test: 64.71%\n",
      "Run: 02, Epoch: 35, Loss: 1.1390, Train: 53.33%, Valid: 42.50% Test: 64.71%\n",
      "Run: 02, Epoch: 36, Loss: 1.1371, Train: 55.00%, Valid: 42.50% Test: 62.75%\n",
      "Run: 02, Epoch: 37, Loss: 1.1371, Train: 55.00%, Valid: 43.75% Test: 66.67%\n",
      "Run: 02, Epoch: 38, Loss: 1.0668, Train: 56.67%, Valid: 46.25% Test: 70.59%\n",
      "Run: 02, Epoch: 39, Loss: 1.1028, Train: 56.67%, Valid: 45.00% Test: 66.67%\n",
      "Run: 02, Epoch: 40, Loss: 1.0897, Train: 60.00%, Valid: 46.25% Test: 66.67%\n",
      "Run: 02, Epoch: 41, Loss: 1.0831, Train: 62.50%, Valid: 47.50% Test: 66.67%\n",
      "Run: 02, Epoch: 42, Loss: 1.1359, Train: 62.50%, Valid: 47.50% Test: 66.67%\n",
      "Run: 02, Epoch: 43, Loss: 1.1397, Train: 60.83%, Valid: 48.75% Test: 64.71%\n",
      "Run: 02, Epoch: 44, Loss: 1.1315, Train: 60.83%, Valid: 48.75% Test: 64.71%\n",
      "Run: 02, Epoch: 45, Loss: 1.0543, Train: 60.00%, Valid: 47.50% Test: 64.71%\n",
      "Run: 02, Epoch: 46, Loss: 1.1196, Train: 60.83%, Valid: 47.50% Test: 64.71%\n",
      "Run: 02, Epoch: 47, Loss: 1.1209, Train: 60.00%, Valid: 47.50% Test: 64.71%\n",
      "Run: 02, Epoch: 48, Loss: 1.1436, Train: 60.00%, Valid: 47.50% Test: 64.71%\n",
      "Run: 02, Epoch: 49, Loss: 1.1187, Train: 58.33%, Valid: 46.25% Test: 64.71%\n",
      "Run: 02, Epoch: 50, Loss: 1.0850, Train: 58.33%, Valid: 46.25% Test: 64.71%\n",
      "Run: 02, Epoch: 51, Loss: 1.0812, Train: 59.17%, Valid: 47.50% Test: 64.71%\n",
      "Run: 02, Epoch: 52, Loss: 1.0591, Train: 60.00%, Valid: 52.50% Test: 66.67%\n",
      "Run: 02, Epoch: 53, Loss: 1.1364, Train: 63.33%, Valid: 52.50% Test: 66.67%\n",
      "Run: 02, Epoch: 54, Loss: 1.1650, Train: 62.50%, Valid: 51.25% Test: 66.67%\n",
      "Run: 02, Epoch: 55, Loss: 1.0710, Train: 57.50%, Valid: 46.25% Test: 66.67%\n",
      "Run: 02, Epoch: 56, Loss: 1.0782, Train: 56.67%, Valid: 45.00% Test: 72.55%\n",
      "Run: 02, Epoch: 57, Loss: 1.0445, Train: 55.83%, Valid: 46.25% Test: 72.55%\n",
      "Run: 02, Epoch: 58, Loss: 1.0463, Train: 55.83%, Valid: 45.00% Test: 70.59%\n",
      "Run: 02, Epoch: 59, Loss: 1.0255, Train: 56.67%, Valid: 45.00% Test: 72.55%\n",
      "Run: 02, Epoch: 60, Loss: 1.0476, Train: 56.67%, Valid: 46.25% Test: 66.67%\n",
      "Run: 02, Epoch: 61, Loss: 1.1256, Train: 63.33%, Valid: 51.25% Test: 66.67%\n",
      "Run: 02, Epoch: 62, Loss: 1.0840, Train: 64.17%, Valid: 52.50% Test: 64.71%\n",
      "Run: 02, Epoch: 63, Loss: 1.0773, Train: 63.33%, Valid: 51.25% Test: 64.71%\n",
      "Run: 02, Epoch: 64, Loss: 1.0873, Train: 62.50%, Valid: 50.00% Test: 60.78%\n",
      "Run: 02, Epoch: 65, Loss: 1.0429, Train: 63.33%, Valid: 50.00% Test: 62.75%\n",
      "Run: 02, Epoch: 66, Loss: 0.9804, Train: 62.50%, Valid: 50.00% Test: 66.67%\n",
      "Run: 02, Epoch: 67, Loss: 1.0179, Train: 61.67%, Valid: 48.75% Test: 66.67%\n",
      "Run: 02, Epoch: 68, Loss: 1.0336, Train: 63.33%, Valid: 48.75% Test: 66.67%\n",
      "Run: 02, Epoch: 69, Loss: 0.9827, Train: 64.17%, Valid: 51.25% Test: 62.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 70, Loss: 1.0252, Train: 65.00%, Valid: 50.00% Test: 60.78%\n",
      "Run: 02, Epoch: 71, Loss: 0.9969, Train: 65.00%, Valid: 51.25% Test: 62.75%\n",
      "Run: 02, Epoch: 72, Loss: 1.1449, Train: 65.00%, Valid: 50.00% Test: 62.75%\n",
      "Run: 02, Epoch: 73, Loss: 1.0968, Train: 62.50%, Valid: 51.25% Test: 64.71%\n",
      "Run: 02, Epoch: 74, Loss: 1.0080, Train: 61.67%, Valid: 51.25% Test: 64.71%\n",
      "Run: 02, Epoch: 75, Loss: 1.0747, Train: 58.33%, Valid: 46.25% Test: 64.71%\n",
      "Run: 02, Epoch: 76, Loss: 1.0041, Train: 56.67%, Valid: 45.00% Test: 64.71%\n",
      "Run: 02, Epoch: 77, Loss: 1.0806, Train: 58.33%, Valid: 46.25% Test: 64.71%\n",
      "Run: 02, Epoch: 78, Loss: 1.0197, Train: 60.83%, Valid: 48.75% Test: 66.67%\n",
      "Run: 02, Epoch: 79, Loss: 0.9663, Train: 60.83%, Valid: 48.75% Test: 66.67%\n",
      "Run: 02, Epoch: 80, Loss: 1.0440, Train: 61.67%, Valid: 50.00% Test: 66.67%\n",
      "Run: 02, Epoch: 81, Loss: 1.1113, Train: 62.50%, Valid: 50.00% Test: 66.67%\n",
      "Run: 02, Epoch: 82, Loss: 1.0265, Train: 63.33%, Valid: 52.50% Test: 64.71%\n",
      "Run: 02, Epoch: 83, Loss: 1.0410, Train: 61.67%, Valid: 52.50% Test: 66.67%\n",
      "Run: 02, Epoch: 84, Loss: 0.9946, Train: 60.83%, Valid: 52.50% Test: 66.67%\n",
      "Run: 02, Epoch: 85, Loss: 1.0457, Train: 61.67%, Valid: 50.00% Test: 66.67%\n",
      "Run: 02, Epoch: 86, Loss: 0.9890, Train: 64.17%, Valid: 50.00% Test: 66.67%\n",
      "Run: 02, Epoch: 87, Loss: 1.0616, Train: 63.33%, Valid: 50.00% Test: 66.67%\n",
      "Run: 02, Epoch: 88, Loss: 0.9935, Train: 63.33%, Valid: 50.00% Test: 66.67%\n",
      "Run: 02, Epoch: 89, Loss: 1.0102, Train: 62.50%, Valid: 50.00% Test: 66.67%\n",
      "Run: 02, Epoch: 90, Loss: 1.0695, Train: 65.83%, Valid: 50.00% Test: 68.63%\n",
      "Run: 02, Epoch: 91, Loss: 1.0031, Train: 65.83%, Valid: 50.00% Test: 64.71%\n",
      "Run: 02, Epoch: 92, Loss: 1.0159, Train: 66.67%, Valid: 50.00% Test: 64.71%\n",
      "Run: 02, Epoch: 93, Loss: 0.9822, Train: 66.67%, Valid: 50.00% Test: 64.71%\n",
      "Run: 02, Epoch: 94, Loss: 0.9817, Train: 64.17%, Valid: 52.50% Test: 62.75%\n",
      "Run: 02, Epoch: 95, Loss: 1.0136, Train: 64.17%, Valid: 52.50% Test: 64.71%\n",
      "Run: 02, Epoch: 96, Loss: 0.9571, Train: 63.33%, Valid: 52.50% Test: 62.75%\n",
      "Run: 02, Epoch: 97, Loss: 1.0361, Train: 63.33%, Valid: 52.50% Test: 64.71%\n",
      "Run: 02, Epoch: 98, Loss: 1.0023, Train: 64.17%, Valid: 53.75% Test: 64.71%\n",
      "Run: 02, Epoch: 99, Loss: 0.9398, Train: 65.00%, Valid: 53.75% Test: 64.71%\n",
      "Run: 02, Epoch: 100, Loss: 0.9609, Train: 65.00%, Valid: 52.50% Test: 64.71%\n",
      "Run 02:\n",
      "Highest Train: 66.67\n",
      "Highest Valid: 53.75\n",
      "  Final Train: 64.17\n",
      "   Final Test: 64.71\n",
      "Run: 03, Epoch: 01, Loss: 3.6029, Train: 9.17%, Valid: 8.75% Test: 9.80%\n",
      "Run: 03, Epoch: 02, Loss: 2.0819, Train: 14.17%, Valid: 13.75% Test: 11.76%\n",
      "Run: 03, Epoch: 03, Loss: 3.2181, Train: 20.83%, Valid: 21.25% Test: 27.45%\n",
      "Run: 03, Epoch: 04, Loss: 2.0178, Train: 17.50%, Valid: 22.50% Test: 25.49%\n",
      "Run: 03, Epoch: 05, Loss: 3.0369, Train: 45.00%, Valid: 52.50% Test: 49.02%\n",
      "Run: 03, Epoch: 06, Loss: 3.6660, Train: 46.67%, Valid: 52.50% Test: 43.14%\n",
      "Run: 03, Epoch: 07, Loss: 1.6582, Train: 49.17%, Valid: 51.25% Test: 45.10%\n",
      "Run: 03, Epoch: 08, Loss: 2.1613, Train: 50.00%, Valid: 51.25% Test: 45.10%\n",
      "Run: 03, Epoch: 09, Loss: 1.5504, Train: 49.17%, Valid: 51.25% Test: 45.10%\n",
      "Run: 03, Epoch: 10, Loss: 1.4889, Train: 50.00%, Valid: 50.00% Test: 45.10%\n",
      "Run: 03, Epoch: 11, Loss: 1.8993, Train: 52.50%, Valid: 50.00% Test: 43.14%\n",
      "Run: 03, Epoch: 12, Loss: 1.3679, Train: 54.17%, Valid: 48.75% Test: 43.14%\n",
      "Run: 03, Epoch: 13, Loss: 1.4217, Train: 52.50%, Valid: 43.75% Test: 43.14%\n",
      "Run: 03, Epoch: 14, Loss: 1.3321, Train: 52.50%, Valid: 43.75% Test: 45.10%\n",
      "Run: 03, Epoch: 15, Loss: 1.4670, Train: 44.17%, Valid: 36.25% Test: 35.29%\n",
      "Run: 03, Epoch: 16, Loss: 1.3305, Train: 41.67%, Valid: 36.25% Test: 33.33%\n",
      "Run: 03, Epoch: 17, Loss: 1.2037, Train: 43.33%, Valid: 36.25% Test: 31.37%\n",
      "Run: 03, Epoch: 18, Loss: 1.3084, Train: 42.50%, Valid: 38.75% Test: 31.37%\n",
      "Run: 03, Epoch: 19, Loss: 1.4551, Train: 44.17%, Valid: 37.50% Test: 33.33%\n",
      "Run: 03, Epoch: 20, Loss: 1.3164, Train: 43.33%, Valid: 36.25% Test: 31.37%\n",
      "Run: 03, Epoch: 21, Loss: 1.4351, Train: 50.83%, Valid: 41.25% Test: 33.33%\n",
      "Run: 03, Epoch: 22, Loss: 1.2917, Train: 50.00%, Valid: 41.25% Test: 33.33%\n",
      "Run: 03, Epoch: 23, Loss: 1.3928, Train: 49.17%, Valid: 43.75% Test: 33.33%\n",
      "Run: 03, Epoch: 24, Loss: 1.2720, Train: 51.67%, Valid: 50.00% Test: 33.33%\n",
      "Run: 03, Epoch: 25, Loss: 1.2874, Train: 48.33%, Valid: 50.00% Test: 35.29%\n",
      "Run: 03, Epoch: 26, Loss: 1.1610, Train: 50.83%, Valid: 50.00% Test: 39.22%\n",
      "Run: 03, Epoch: 27, Loss: 1.2912, Train: 49.17%, Valid: 50.00% Test: 39.22%\n",
      "Run: 03, Epoch: 28, Loss: 1.4295, Train: 50.00%, Valid: 48.75% Test: 41.18%\n",
      "Run: 03, Epoch: 29, Loss: 1.2863, Train: 50.00%, Valid: 48.75% Test: 41.18%\n",
      "Run: 03, Epoch: 30, Loss: 1.2378, Train: 50.00%, Valid: 48.75% Test: 43.14%\n",
      "Run: 03, Epoch: 31, Loss: 1.1653, Train: 50.00%, Valid: 48.75% Test: 43.14%\n",
      "Run: 03, Epoch: 32, Loss: 1.2307, Train: 50.00%, Valid: 50.00% Test: 41.18%\n",
      "Run: 03, Epoch: 33, Loss: 1.0860, Train: 50.00%, Valid: 50.00% Test: 37.25%\n",
      "Run: 03, Epoch: 34, Loss: 1.3001, Train: 49.17%, Valid: 51.25% Test: 39.22%\n",
      "Run: 03, Epoch: 35, Loss: 1.1498, Train: 51.67%, Valid: 52.50% Test: 35.29%\n",
      "Run: 03, Epoch: 36, Loss: 1.1911, Train: 49.17%, Valid: 50.00% Test: 33.33%\n",
      "Run: 03, Epoch: 37, Loss: 1.1170, Train: 49.17%, Valid: 47.50% Test: 35.29%\n",
      "Run: 03, Epoch: 38, Loss: 1.1687, Train: 50.00%, Valid: 47.50% Test: 35.29%\n",
      "Run: 03, Epoch: 39, Loss: 1.2341, Train: 53.33%, Valid: 48.75% Test: 35.29%\n",
      "Run: 03, Epoch: 40, Loss: 1.0666, Train: 51.67%, Valid: 48.75% Test: 31.37%\n",
      "Run: 03, Epoch: 41, Loss: 1.1455, Train: 50.83%, Valid: 47.50% Test: 33.33%\n",
      "Run: 03, Epoch: 42, Loss: 1.1434, Train: 52.50%, Valid: 51.25% Test: 37.25%\n",
      "Run: 03, Epoch: 43, Loss: 1.1663, Train: 50.00%, Valid: 53.75% Test: 35.29%\n",
      "Run: 03, Epoch: 44, Loss: 1.1838, Train: 50.83%, Valid: 51.25% Test: 35.29%\n",
      "Run: 03, Epoch: 45, Loss: 1.3088, Train: 49.17%, Valid: 50.00% Test: 39.22%\n",
      "Run: 03, Epoch: 46, Loss: 1.1778, Train: 50.83%, Valid: 50.00% Test: 41.18%\n",
      "Run: 03, Epoch: 47, Loss: 1.0522, Train: 49.17%, Valid: 50.00% Test: 43.14%\n",
      "Run: 03, Epoch: 48, Loss: 1.1227, Train: 49.17%, Valid: 50.00% Test: 43.14%\n",
      "Run: 03, Epoch: 49, Loss: 1.1225, Train: 49.17%, Valid: 50.00% Test: 43.14%\n",
      "Run: 03, Epoch: 50, Loss: 1.7434, Train: 49.17%, Valid: 50.00% Test: 43.14%\n",
      "Run: 03, Epoch: 51, Loss: 1.1009, Train: 49.17%, Valid: 50.00% Test: 43.14%\n",
      "Run: 03, Epoch: 52, Loss: 1.1318, Train: 49.17%, Valid: 50.00% Test: 43.14%\n",
      "Run: 03, Epoch: 53, Loss: 1.0891, Train: 48.33%, Valid: 51.25% Test: 41.18%\n",
      "Run: 03, Epoch: 54, Loss: 1.0662, Train: 50.83%, Valid: 51.25% Test: 31.37%\n",
      "Run: 03, Epoch: 55, Loss: 1.2759, Train: 48.33%, Valid: 51.25% Test: 37.25%\n",
      "Run: 03, Epoch: 56, Loss: 1.1554, Train: 45.83%, Valid: 53.75% Test: 37.25%\n",
      "Run: 03, Epoch: 57, Loss: 1.1287, Train: 48.33%, Valid: 52.50% Test: 41.18%\n",
      "Run: 03, Epoch: 58, Loss: 1.1441, Train: 48.33%, Valid: 52.50% Test: 41.18%\n",
      "Run: 03, Epoch: 59, Loss: 1.0632, Train: 51.67%, Valid: 53.75% Test: 39.22%\n",
      "Run: 03, Epoch: 60, Loss: 1.0452, Train: 52.50%, Valid: 53.75% Test: 39.22%\n",
      "Run: 03, Epoch: 61, Loss: 1.0700, Train: 53.33%, Valid: 53.75% Test: 43.14%\n",
      "Run: 03, Epoch: 62, Loss: 1.1324, Train: 52.50%, Valid: 51.25% Test: 45.10%\n",
      "Run: 03, Epoch: 63, Loss: 1.0680, Train: 54.17%, Valid: 52.50% Test: 47.06%\n",
      "Run: 03, Epoch: 64, Loss: 1.0993, Train: 55.83%, Valid: 52.50% Test: 49.02%\n",
      "Run: 03, Epoch: 65, Loss: 1.0330, Train: 55.00%, Valid: 51.25% Test: 47.06%\n",
      "Run: 03, Epoch: 66, Loss: 1.0537, Train: 55.00%, Valid: 51.25% Test: 47.06%\n",
      "Run: 03, Epoch: 67, Loss: 1.2498, Train: 55.00%, Valid: 51.25% Test: 47.06%\n",
      "Run: 03, Epoch: 68, Loss: 1.1500, Train: 55.83%, Valid: 51.25% Test: 47.06%\n",
      "Run: 03, Epoch: 69, Loss: 0.9782, Train: 55.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 70, Loss: 0.9863, Train: 54.17%, Valid: 52.50% Test: 49.02%\n",
      "Run: 03, Epoch: 71, Loss: 1.0419, Train: 55.00%, Valid: 51.25% Test: 45.10%\n",
      "Run: 03, Epoch: 72, Loss: 1.0078, Train: 56.67%, Valid: 51.25% Test: 41.18%\n",
      "Run: 03, Epoch: 73, Loss: 1.0350, Train: 53.33%, Valid: 52.50% Test: 37.25%\n",
      "Run: 03, Epoch: 74, Loss: 1.2660, Train: 52.50%, Valid: 53.75% Test: 33.33%\n",
      "Run: 03, Epoch: 75, Loss: 1.1529, Train: 55.00%, Valid: 51.25% Test: 39.22%\n",
      "Run: 03, Epoch: 76, Loss: 1.0261, Train: 53.33%, Valid: 52.50% Test: 39.22%\n",
      "Run: 03, Epoch: 77, Loss: 1.1493, Train: 52.50%, Valid: 51.25% Test: 41.18%\n",
      "Run: 03, Epoch: 78, Loss: 1.0646, Train: 52.50%, Valid: 51.25% Test: 41.18%\n",
      "Run: 03, Epoch: 79, Loss: 1.0456, Train: 50.00%, Valid: 50.00% Test: 37.25%\n",
      "Run: 03, Epoch: 80, Loss: 0.9437, Train: 50.00%, Valid: 52.50% Test: 39.22%\n",
      "Run: 03, Epoch: 81, Loss: 1.1000, Train: 53.33%, Valid: 52.50% Test: 39.22%\n",
      "Run: 03, Epoch: 82, Loss: 1.0085, Train: 52.50%, Valid: 52.50% Test: 39.22%\n",
      "Run: 03, Epoch: 83, Loss: 1.0042, Train: 53.33%, Valid: 52.50% Test: 41.18%\n",
      "Run: 03, Epoch: 84, Loss: 0.9240, Train: 52.50%, Valid: 52.50% Test: 41.18%\n",
      "Run: 03, Epoch: 85, Loss: 0.9823, Train: 52.50%, Valid: 52.50% Test: 41.18%\n",
      "Run: 03, Epoch: 86, Loss: 1.0037, Train: 53.33%, Valid: 51.25% Test: 41.18%\n",
      "Run: 03, Epoch: 87, Loss: 1.0148, Train: 54.17%, Valid: 51.25% Test: 41.18%\n",
      "Run: 03, Epoch: 88, Loss: 0.9464, Train: 52.50%, Valid: 50.00% Test: 41.18%\n",
      "Run: 03, Epoch: 89, Loss: 0.9541, Train: 50.83%, Valid: 50.00% Test: 39.22%\n",
      "Run: 03, Epoch: 90, Loss: 0.9866, Train: 50.00%, Valid: 48.75% Test: 41.18%\n",
      "Run: 03, Epoch: 91, Loss: 0.9892, Train: 50.00%, Valid: 48.75% Test: 41.18%\n",
      "Run: 03, Epoch: 92, Loss: 1.0519, Train: 50.83%, Valid: 48.75% Test: 41.18%\n",
      "Run: 03, Epoch: 93, Loss: 0.9791, Train: 50.83%, Valid: 50.00% Test: 39.22%\n",
      "Run: 03, Epoch: 94, Loss: 0.9266, Train: 51.67%, Valid: 50.00% Test: 39.22%\n",
      "Run: 03, Epoch: 95, Loss: 1.0125, Train: 52.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 03, Epoch: 96, Loss: 0.9625, Train: 52.50%, Valid: 51.25% Test: 41.18%\n",
      "Run: 03, Epoch: 97, Loss: 0.9882, Train: 53.33%, Valid: 51.25% Test: 41.18%\n",
      "Run: 03, Epoch: 98, Loss: 1.0127, Train: 53.33%, Valid: 52.50% Test: 41.18%\n",
      "Run: 03, Epoch: 99, Loss: 1.0102, Train: 53.33%, Valid: 52.50% Test: 39.22%\n",
      "Run: 03, Epoch: 100, Loss: 0.9679, Train: 55.00%, Valid: 52.50% Test: 35.29%\n",
      "Run 03:\n",
      "Highest Train: 56.67\n",
      "Highest Valid: 53.75\n",
      "  Final Train: 50.00\n",
      "   Final Test: 35.29\n",
      "Run: 04, Epoch: 01, Loss: 1.7552, Train: 19.17%, Valid: 8.75% Test: 9.80%\n",
      "Run: 04, Epoch: 02, Loss: 1.5288, Train: 19.17%, Valid: 8.75% Test: 9.80%\n",
      "Run: 04, Epoch: 03, Loss: 1.5561, Train: 19.17%, Valid: 6.25% Test: 9.80%\n",
      "Run: 04, Epoch: 04, Loss: 1.6430, Train: 20.83%, Valid: 6.25% Test: 9.80%\n",
      "Run: 04, Epoch: 05, Loss: 1.4549, Train: 25.00%, Valid: 7.50% Test: 9.80%\n",
      "Run: 04, Epoch: 06, Loss: 1.4012, Train: 25.83%, Valid: 8.75% Test: 13.73%\n",
      "Run: 04, Epoch: 07, Loss: 1.3719, Train: 24.17%, Valid: 10.00% Test: 13.73%\n",
      "Run: 04, Epoch: 08, Loss: 1.3584, Train: 25.83%, Valid: 10.00% Test: 17.65%\n",
      "Run: 04, Epoch: 09, Loss: 1.3659, Train: 23.33%, Valid: 11.25% Test: 15.69%\n",
      "Run: 04, Epoch: 10, Loss: 1.4213, Train: 23.33%, Valid: 13.75% Test: 15.69%\n",
      "Run: 04, Epoch: 11, Loss: 1.4274, Train: 35.00%, Valid: 16.25% Test: 15.69%\n",
      "Run: 04, Epoch: 12, Loss: 1.5757, Train: 38.33%, Valid: 21.25% Test: 21.57%\n",
      "Run: 04, Epoch: 13, Loss: 1.3972, Train: 44.17%, Valid: 25.00% Test: 29.41%\n",
      "Run: 04, Epoch: 14, Loss: 1.3206, Train: 46.67%, Valid: 31.25% Test: 33.33%\n",
      "Run: 04, Epoch: 15, Loss: 1.3696, Train: 50.83%, Valid: 35.00% Test: 35.29%\n",
      "Run: 04, Epoch: 16, Loss: 1.2587, Train: 50.00%, Valid: 36.25% Test: 39.22%\n",
      "Run: 04, Epoch: 17, Loss: 1.3140, Train: 51.67%, Valid: 36.25% Test: 43.14%\n",
      "Run: 04, Epoch: 18, Loss: 1.3110, Train: 48.33%, Valid: 40.00% Test: 43.14%\n",
      "Run: 04, Epoch: 19, Loss: 1.3368, Train: 50.83%, Valid: 41.25% Test: 45.10%\n",
      "Run: 04, Epoch: 20, Loss: 1.2847, Train: 51.67%, Valid: 42.50% Test: 45.10%\n",
      "Run: 04, Epoch: 21, Loss: 1.2658, Train: 51.67%, Valid: 43.75% Test: 45.10%\n",
      "Run: 04, Epoch: 22, Loss: 1.2639, Train: 51.67%, Valid: 43.75% Test: 45.10%\n",
      "Run: 04, Epoch: 23, Loss: 1.2510, Train: 50.00%, Valid: 46.25% Test: 49.02%\n",
      "Run: 04, Epoch: 24, Loss: 1.2321, Train: 48.33%, Valid: 46.25% Test: 47.06%\n",
      "Run: 04, Epoch: 25, Loss: 1.2337, Train: 51.67%, Valid: 42.50% Test: 47.06%\n",
      "Run: 04, Epoch: 26, Loss: 1.2393, Train: 51.67%, Valid: 37.50% Test: 41.18%\n",
      "Run: 04, Epoch: 27, Loss: 1.2225, Train: 52.50%, Valid: 37.50% Test: 41.18%\n",
      "Run: 04, Epoch: 28, Loss: 1.2346, Train: 52.50%, Valid: 36.25% Test: 41.18%\n",
      "Run: 04, Epoch: 29, Loss: 1.2637, Train: 51.67%, Valid: 41.25% Test: 39.22%\n",
      "Run: 04, Epoch: 30, Loss: 1.2341, Train: 50.00%, Valid: 42.50% Test: 41.18%\n",
      "Run: 04, Epoch: 31, Loss: 1.2763, Train: 52.50%, Valid: 35.00% Test: 37.25%\n",
      "Run: 04, Epoch: 32, Loss: 1.2177, Train: 51.67%, Valid: 35.00% Test: 37.25%\n",
      "Run: 04, Epoch: 33, Loss: 1.2609, Train: 50.83%, Valid: 35.00% Test: 33.33%\n",
      "Run: 04, Epoch: 34, Loss: 1.1952, Train: 50.83%, Valid: 33.75% Test: 31.37%\n",
      "Run: 04, Epoch: 35, Loss: 1.2500, Train: 50.00%, Valid: 33.75% Test: 31.37%\n",
      "Run: 04, Epoch: 36, Loss: 1.2812, Train: 49.17%, Valid: 33.75% Test: 31.37%\n",
      "Run: 04, Epoch: 37, Loss: 1.2228, Train: 50.00%, Valid: 36.25% Test: 35.29%\n",
      "Run: 04, Epoch: 38, Loss: 1.1867, Train: 49.17%, Valid: 36.25% Test: 39.22%\n",
      "Run: 04, Epoch: 39, Loss: 1.1959, Train: 50.00%, Valid: 35.00% Test: 39.22%\n",
      "Run: 04, Epoch: 40, Loss: 1.1736, Train: 48.33%, Valid: 38.75% Test: 39.22%\n",
      "Run: 04, Epoch: 41, Loss: 1.1727, Train: 48.33%, Valid: 47.50% Test: 41.18%\n",
      "Run: 04, Epoch: 42, Loss: 1.2721, Train: 47.50%, Valid: 47.50% Test: 43.14%\n",
      "Run: 04, Epoch: 43, Loss: 1.1958, Train: 47.50%, Valid: 50.00% Test: 43.14%\n",
      "Run: 04, Epoch: 44, Loss: 1.2019, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 45, Loss: 1.2425, Train: 46.67%, Valid: 48.75% Test: 41.18%\n",
      "Run: 04, Epoch: 46, Loss: 1.3131, Train: 45.00%, Valid: 51.25% Test: 39.22%\n",
      "Run: 04, Epoch: 47, Loss: 1.2314, Train: 44.17%, Valid: 53.75% Test: 41.18%\n",
      "Run: 04, Epoch: 48, Loss: 1.3771, Train: 45.00%, Valid: 55.00% Test: 41.18%\n",
      "Run: 04, Epoch: 49, Loss: 1.2723, Train: 45.83%, Valid: 56.25% Test: 43.14%\n",
      "Run: 04, Epoch: 50, Loss: 1.2457, Train: 46.67%, Valid: 53.75% Test: 37.25%\n",
      "Run: 04, Epoch: 51, Loss: 1.3057, Train: 47.50%, Valid: 50.00% Test: 39.22%\n",
      "Run: 04, Epoch: 52, Loss: 1.2804, Train: 47.50%, Valid: 48.75% Test: 39.22%\n",
      "Run: 04, Epoch: 53, Loss: 1.3207, Train: 45.83%, Valid: 47.50% Test: 37.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 54, Loss: 1.2708, Train: 48.33%, Valid: 50.00% Test: 35.29%\n",
      "Run: 04, Epoch: 55, Loss: 1.2899, Train: 46.67%, Valid: 53.75% Test: 39.22%\n",
      "Run: 04, Epoch: 56, Loss: 1.2857, Train: 45.83%, Valid: 60.00% Test: 41.18%\n",
      "Run: 04, Epoch: 57, Loss: 1.2492, Train: 46.67%, Valid: 58.75% Test: 37.25%\n",
      "Run: 04, Epoch: 58, Loss: 1.2505, Train: 49.17%, Valid: 55.00% Test: 37.25%\n",
      "Run: 04, Epoch: 59, Loss: 1.2422, Train: 49.17%, Valid: 51.25% Test: 45.10%\n",
      "Run: 04, Epoch: 60, Loss: 1.2126, Train: 50.83%, Valid: 40.00% Test: 47.06%\n",
      "Run: 04, Epoch: 61, Loss: 1.1779, Train: 54.17%, Valid: 38.75% Test: 43.14%\n",
      "Run: 04, Epoch: 62, Loss: 1.1859, Train: 53.33%, Valid: 33.75% Test: 37.25%\n",
      "Run: 04, Epoch: 63, Loss: 1.1309, Train: 52.50%, Valid: 33.75% Test: 37.25%\n",
      "Run: 04, Epoch: 64, Loss: 1.1465, Train: 51.67%, Valid: 38.75% Test: 39.22%\n",
      "Run: 04, Epoch: 65, Loss: 1.1482, Train: 50.83%, Valid: 32.50% Test: 37.25%\n",
      "Run: 04, Epoch: 66, Loss: 1.1824, Train: 52.50%, Valid: 32.50% Test: 39.22%\n",
      "Run: 04, Epoch: 67, Loss: 1.1804, Train: 52.50%, Valid: 32.50% Test: 39.22%\n",
      "Run: 04, Epoch: 68, Loss: 1.1797, Train: 50.00%, Valid: 32.50% Test: 39.22%\n",
      "Run: 04, Epoch: 69, Loss: 1.1403, Train: 49.17%, Valid: 33.75% Test: 37.25%\n",
      "Run: 04, Epoch: 70, Loss: 1.1149, Train: 48.33%, Valid: 35.00% Test: 39.22%\n",
      "Run: 04, Epoch: 71, Loss: 1.1656, Train: 49.17%, Valid: 35.00% Test: 39.22%\n",
      "Run: 04, Epoch: 72, Loss: 1.1111, Train: 49.17%, Valid: 38.75% Test: 39.22%\n",
      "Run: 04, Epoch: 73, Loss: 1.1594, Train: 47.50%, Valid: 48.75% Test: 41.18%\n",
      "Run: 04, Epoch: 74, Loss: 1.0895, Train: 50.00%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 75, Loss: 1.1201, Train: 50.00%, Valid: 50.00% Test: 45.10%\n",
      "Run: 04, Epoch: 76, Loss: 1.0644, Train: 49.17%, Valid: 52.50% Test: 47.06%\n",
      "Run: 04, Epoch: 77, Loss: 1.1676, Train: 47.50%, Valid: 57.50% Test: 47.06%\n",
      "Run: 04, Epoch: 78, Loss: 1.1591, Train: 49.17%, Valid: 61.25% Test: 52.94%\n",
      "Run: 04, Epoch: 79, Loss: 1.1229, Train: 49.17%, Valid: 60.00% Test: 50.98%\n",
      "Run: 04, Epoch: 80, Loss: 1.1468, Train: 49.17%, Valid: 60.00% Test: 52.94%\n",
      "Run: 04, Epoch: 81, Loss: 1.1490, Train: 50.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 04, Epoch: 82, Loss: 1.1086, Train: 48.33%, Valid: 50.00% Test: 45.10%\n",
      "Run: 04, Epoch: 83, Loss: 1.0451, Train: 48.33%, Valid: 51.25% Test: 45.10%\n",
      "Run: 04, Epoch: 84, Loss: 1.1214, Train: 48.33%, Valid: 51.25% Test: 45.10%\n",
      "Run: 04, Epoch: 85, Loss: 1.1548, Train: 49.17%, Valid: 51.25% Test: 45.10%\n",
      "Run: 04, Epoch: 86, Loss: 1.1179, Train: 49.17%, Valid: 51.25% Test: 45.10%\n",
      "Run: 04, Epoch: 87, Loss: 1.1430, Train: 48.33%, Valid: 50.00% Test: 45.10%\n",
      "Run: 04, Epoch: 88, Loss: 1.1222, Train: 48.33%, Valid: 50.00% Test: 45.10%\n",
      "Run: 04, Epoch: 89, Loss: 1.0979, Train: 44.17%, Valid: 50.00% Test: 45.10%\n",
      "Run: 04, Epoch: 90, Loss: 1.2099, Train: 44.17%, Valid: 50.00% Test: 45.10%\n",
      "Run: 04, Epoch: 91, Loss: 1.1454, Train: 48.33%, Valid: 50.00% Test: 45.10%\n",
      "Run: 04, Epoch: 92, Loss: 1.1098, Train: 48.33%, Valid: 51.25% Test: 45.10%\n",
      "Run: 04, Epoch: 93, Loss: 1.0953, Train: 48.33%, Valid: 47.50% Test: 41.18%\n",
      "Run: 04, Epoch: 94, Loss: 1.0860, Train: 48.33%, Valid: 50.00% Test: 41.18%\n",
      "Run: 04, Epoch: 95, Loss: 1.1549, Train: 50.00%, Valid: 55.00% Test: 47.06%\n",
      "Run: 04, Epoch: 96, Loss: 1.1335, Train: 50.00%, Valid: 60.00% Test: 45.10%\n",
      "Run: 04, Epoch: 97, Loss: 1.1641, Train: 50.00%, Valid: 60.00% Test: 47.06%\n",
      "Run: 04, Epoch: 98, Loss: 1.1105, Train: 50.00%, Valid: 58.75% Test: 43.14%\n",
      "Run: 04, Epoch: 99, Loss: 1.0967, Train: 50.00%, Valid: 58.75% Test: 43.14%\n",
      "Run: 04, Epoch: 100, Loss: 1.1250, Train: 50.00%, Valid: 57.50% Test: 41.18%\n",
      "Run 04:\n",
      "Highest Train: 54.17\n",
      "Highest Valid: 61.25\n",
      "  Final Train: 49.17\n",
      "   Final Test: 52.94\n",
      "Run: 05, Epoch: 01, Loss: 2.1330, Train: 16.67%, Valid: 12.50% Test: 9.80%\n",
      "Run: 05, Epoch: 02, Loss: 2.0257, Train: 25.00%, Valid: 22.50% Test: 21.57%\n",
      "Run: 05, Epoch: 03, Loss: 1.9402, Train: 29.17%, Valid: 21.25% Test: 31.37%\n",
      "Run: 05, Epoch: 04, Loss: 1.8024, Train: 25.83%, Valid: 21.25% Test: 29.41%\n",
      "Run: 05, Epoch: 05, Loss: 1.7049, Train: 27.50%, Valid: 20.00% Test: 27.45%\n",
      "Run: 05, Epoch: 06, Loss: 1.6169, Train: 20.83%, Valid: 13.75% Test: 19.61%\n",
      "Run: 05, Epoch: 07, Loss: 1.5849, Train: 18.33%, Valid: 12.50% Test: 19.61%\n",
      "Run: 05, Epoch: 08, Loss: 1.4801, Train: 24.17%, Valid: 16.25% Test: 27.45%\n",
      "Run: 05, Epoch: 09, Loss: 1.3859, Train: 27.50%, Valid: 22.50% Test: 35.29%\n",
      "Run: 05, Epoch: 10, Loss: 1.4887, Train: 29.17%, Valid: 22.50% Test: 35.29%\n",
      "Run: 05, Epoch: 11, Loss: 1.4998, Train: 30.00%, Valid: 23.75% Test: 39.22%\n",
      "Run: 05, Epoch: 12, Loss: 1.3237, Train: 30.83%, Valid: 23.75% Test: 39.22%\n",
      "Run: 05, Epoch: 13, Loss: 1.2552, Train: 30.83%, Valid: 22.50% Test: 39.22%\n",
      "Run: 05, Epoch: 14, Loss: 1.3579, Train: 31.67%, Valid: 21.25% Test: 39.22%\n",
      "Run: 05, Epoch: 15, Loss: 1.2548, Train: 34.17%, Valid: 26.25% Test: 41.18%\n",
      "Run: 05, Epoch: 16, Loss: 1.3522, Train: 33.33%, Valid: 28.75% Test: 47.06%\n",
      "Run: 05, Epoch: 17, Loss: 1.3421, Train: 32.50%, Valid: 30.00% Test: 49.02%\n",
      "Run: 05, Epoch: 18, Loss: 1.3707, Train: 34.17%, Valid: 30.00% Test: 45.10%\n",
      "Run: 05, Epoch: 19, Loss: 1.3014, Train: 38.33%, Valid: 32.50% Test: 45.10%\n",
      "Run: 05, Epoch: 20, Loss: 1.2905, Train: 40.00%, Valid: 36.25% Test: 41.18%\n",
      "Run: 05, Epoch: 21, Loss: 1.2457, Train: 44.17%, Valid: 38.75% Test: 41.18%\n",
      "Run: 05, Epoch: 22, Loss: 1.2835, Train: 49.17%, Valid: 47.50% Test: 49.02%\n",
      "Run: 05, Epoch: 23, Loss: 1.2006, Train: 49.17%, Valid: 52.50% Test: 49.02%\n",
      "Run: 05, Epoch: 24, Loss: 1.2459, Train: 53.33%, Valid: 52.50% Test: 49.02%\n",
      "Run: 05, Epoch: 25, Loss: 1.2898, Train: 54.17%, Valid: 53.75% Test: 47.06%\n",
      "Run: 05, Epoch: 26, Loss: 1.2183, Train: 55.00%, Valid: 53.75% Test: 47.06%\n",
      "Run: 05, Epoch: 27, Loss: 1.1822, Train: 57.50%, Valid: 51.25% Test: 47.06%\n",
      "Run: 05, Epoch: 28, Loss: 1.2139, Train: 56.67%, Valid: 50.00% Test: 45.10%\n",
      "Run: 05, Epoch: 29, Loss: 1.1482, Train: 56.67%, Valid: 53.75% Test: 43.14%\n",
      "Run: 05, Epoch: 30, Loss: 1.2677, Train: 55.00%, Valid: 53.75% Test: 45.10%\n",
      "Run: 05, Epoch: 31, Loss: 1.1932, Train: 55.00%, Valid: 52.50% Test: 47.06%\n",
      "Run: 05, Epoch: 32, Loss: 1.2399, Train: 54.17%, Valid: 51.25% Test: 45.10%\n",
      "Run: 05, Epoch: 33, Loss: 1.2202, Train: 53.33%, Valid: 51.25% Test: 45.10%\n",
      "Run: 05, Epoch: 34, Loss: 1.1393, Train: 53.33%, Valid: 51.25% Test: 45.10%\n",
      "Run: 05, Epoch: 35, Loss: 1.1197, Train: 53.33%, Valid: 51.25% Test: 45.10%\n",
      "Run: 05, Epoch: 36, Loss: 1.1884, Train: 53.33%, Valid: 51.25% Test: 45.10%\n",
      "Run: 05, Epoch: 37, Loss: 1.2324, Train: 53.33%, Valid: 51.25% Test: 47.06%\n",
      "Run: 05, Epoch: 38, Loss: 1.1830, Train: 52.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 05, Epoch: 39, Loss: 1.1327, Train: 52.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 05, Epoch: 40, Loss: 1.1936, Train: 52.50%, Valid: 52.50% Test: 49.02%\n",
      "Run: 05, Epoch: 41, Loss: 1.1015, Train: 53.33%, Valid: 52.50% Test: 49.02%\n",
      "Run: 05, Epoch: 42, Loss: 1.1840, Train: 53.33%, Valid: 52.50% Test: 49.02%\n",
      "Run: 05, Epoch: 43, Loss: 1.1763, Train: 52.50%, Valid: 52.50% Test: 49.02%\n",
      "Run: 05, Epoch: 44, Loss: 1.1417, Train: 52.50%, Valid: 53.75% Test: 49.02%\n",
      "Run: 05, Epoch: 45, Loss: 1.1025, Train: 52.50%, Valid: 53.75% Test: 45.10%\n",
      "Run: 05, Epoch: 46, Loss: 1.1053, Train: 52.50%, Valid: 53.75% Test: 45.10%\n",
      "Run: 05, Epoch: 47, Loss: 1.1058, Train: 52.50%, Valid: 53.75% Test: 45.10%\n",
      "Run: 05, Epoch: 48, Loss: 1.1492, Train: 52.50%, Valid: 53.75% Test: 47.06%\n",
      "Run: 05, Epoch: 49, Loss: 1.1222, Train: 55.00%, Valid: 55.00% Test: 47.06%\n",
      "Run: 05, Epoch: 50, Loss: 1.0889, Train: 55.00%, Valid: 53.75% Test: 45.10%\n",
      "Run: 05, Epoch: 51, Loss: 1.1489, Train: 54.17%, Valid: 53.75% Test: 47.06%\n",
      "Run: 05, Epoch: 52, Loss: 1.0610, Train: 54.17%, Valid: 53.75% Test: 47.06%\n",
      "Run: 05, Epoch: 53, Loss: 1.1388, Train: 54.17%, Valid: 55.00% Test: 49.02%\n",
      "Run: 05, Epoch: 54, Loss: 1.1104, Train: 54.17%, Valid: 56.25% Test: 47.06%\n",
      "Run: 05, Epoch: 55, Loss: 1.0689, Train: 55.00%, Valid: 53.75% Test: 47.06%\n",
      "Run: 05, Epoch: 56, Loss: 1.1387, Train: 56.67%, Valid: 53.75% Test: 47.06%\n",
      "Run: 05, Epoch: 57, Loss: 1.1651, Train: 56.67%, Valid: 53.75% Test: 47.06%\n",
      "Run: 05, Epoch: 58, Loss: 1.0792, Train: 56.67%, Valid: 53.75% Test: 45.10%\n",
      "Run: 05, Epoch: 59, Loss: 1.0886, Train: 56.67%, Valid: 55.00% Test: 47.06%\n",
      "Run: 05, Epoch: 60, Loss: 1.1048, Train: 56.67%, Valid: 55.00% Test: 47.06%\n",
      "Run: 05, Epoch: 61, Loss: 1.0604, Train: 56.67%, Valid: 55.00% Test: 45.10%\n",
      "Run: 05, Epoch: 62, Loss: 1.1249, Train: 56.67%, Valid: 55.00% Test: 45.10%\n",
      "Run: 05, Epoch: 63, Loss: 1.1351, Train: 56.67%, Valid: 55.00% Test: 45.10%\n",
      "Run: 05, Epoch: 64, Loss: 1.0706, Train: 55.83%, Valid: 56.25% Test: 45.10%\n",
      "Run: 05, Epoch: 65, Loss: 1.0211, Train: 55.83%, Valid: 56.25% Test: 43.14%\n",
      "Run: 05, Epoch: 66, Loss: 1.0390, Train: 55.83%, Valid: 56.25% Test: 43.14%\n",
      "Run: 05, Epoch: 67, Loss: 1.0368, Train: 55.83%, Valid: 56.25% Test: 45.10%\n",
      "Run: 05, Epoch: 68, Loss: 0.9920, Train: 55.83%, Valid: 56.25% Test: 45.10%\n",
      "Run: 05, Epoch: 69, Loss: 1.0513, Train: 55.83%, Valid: 56.25% Test: 45.10%\n",
      "Run: 05, Epoch: 70, Loss: 1.0648, Train: 57.50%, Valid: 55.00% Test: 45.10%\n",
      "Run: 05, Epoch: 71, Loss: 1.0776, Train: 57.50%, Valid: 55.00% Test: 45.10%\n",
      "Run: 05, Epoch: 72, Loss: 1.0689, Train: 59.17%, Valid: 56.25% Test: 47.06%\n",
      "Run: 05, Epoch: 73, Loss: 1.0471, Train: 60.83%, Valid: 56.25% Test: 47.06%\n",
      "Run: 05, Epoch: 74, Loss: 1.0465, Train: 61.67%, Valid: 55.00% Test: 54.90%\n",
      "Run: 05, Epoch: 75, Loss: 1.0449, Train: 61.67%, Valid: 53.75% Test: 56.86%\n",
      "Run: 05, Epoch: 76, Loss: 1.1015, Train: 60.83%, Valid: 53.75% Test: 56.86%\n",
      "Run: 05, Epoch: 77, Loss: 1.0372, Train: 59.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 05, Epoch: 78, Loss: 1.0137, Train: 59.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 05, Epoch: 79, Loss: 1.1615, Train: 57.50%, Valid: 52.50% Test: 58.82%\n",
      "Run: 05, Epoch: 80, Loss: 1.0824, Train: 59.17%, Valid: 52.50% Test: 58.82%\n",
      "Run: 05, Epoch: 81, Loss: 1.0855, Train: 60.83%, Valid: 52.50% Test: 58.82%\n",
      "Run: 05, Epoch: 82, Loss: 1.0100, Train: 60.83%, Valid: 53.75% Test: 58.82%\n",
      "Run: 05, Epoch: 83, Loss: 1.0755, Train: 61.67%, Valid: 56.25% Test: 58.82%\n",
      "Run: 05, Epoch: 84, Loss: 1.0583, Train: 61.67%, Valid: 56.25% Test: 56.86%\n",
      "Run: 05, Epoch: 85, Loss: 1.0413, Train: 62.50%, Valid: 56.25% Test: 54.90%\n",
      "Run: 05, Epoch: 86, Loss: 1.0233, Train: 62.50%, Valid: 56.25% Test: 52.94%\n",
      "Run: 05, Epoch: 87, Loss: 1.0365, Train: 61.67%, Valid: 56.25% Test: 50.98%\n",
      "Run: 05, Epoch: 88, Loss: 1.0828, Train: 61.67%, Valid: 57.50% Test: 54.90%\n",
      "Run: 05, Epoch: 89, Loss: 1.0444, Train: 60.83%, Valid: 57.50% Test: 56.86%\n",
      "Run: 05, Epoch: 90, Loss: 1.0672, Train: 60.83%, Valid: 60.00% Test: 56.86%\n",
      "Run: 05, Epoch: 91, Loss: 1.0490, Train: 61.67%, Valid: 60.00% Test: 56.86%\n",
      "Run: 05, Epoch: 92, Loss: 1.0221, Train: 61.67%, Valid: 60.00% Test: 56.86%\n",
      "Run: 05, Epoch: 93, Loss: 1.0857, Train: 61.67%, Valid: 58.75% Test: 56.86%\n",
      "Run: 05, Epoch: 94, Loss: 1.0659, Train: 61.67%, Valid: 60.00% Test: 56.86%\n",
      "Run: 05, Epoch: 95, Loss: 1.1243, Train: 61.67%, Valid: 58.75% Test: 54.90%\n",
      "Run: 05, Epoch: 96, Loss: 0.9874, Train: 62.50%, Valid: 57.50% Test: 54.90%\n",
      "Run: 05, Epoch: 97, Loss: 1.0241, Train: 64.17%, Valid: 57.50% Test: 54.90%\n",
      "Run: 05, Epoch: 98, Loss: 1.0717, Train: 63.33%, Valid: 56.25% Test: 54.90%\n",
      "Run: 05, Epoch: 99, Loss: 0.9731, Train: 63.33%, Valid: 56.25% Test: 54.90%\n",
      "Run: 05, Epoch: 100, Loss: 1.0431, Train: 62.50%, Valid: 56.25% Test: 52.94%\n",
      "Run 05:\n",
      "Highest Train: 64.17\n",
      "Highest Valid: 60.00\n",
      "  Final Train: 60.83\n",
      "   Final Test: 56.86\n",
      "Run: 06, Epoch: 01, Loss: 3.0443, Train: 7.50%, Valid: 10.00% Test: 5.88%\n",
      "Run: 06, Epoch: 02, Loss: 2.2668, Train: 8.33%, Valid: 7.50% Test: 11.76%\n",
      "Run: 06, Epoch: 03, Loss: 2.2942, Train: 3.33%, Valid: 2.50% Test: 5.88%\n",
      "Run: 06, Epoch: 04, Loss: 2.1550, Train: 7.50%, Valid: 8.75% Test: 11.76%\n",
      "Run: 06, Epoch: 05, Loss: 1.9340, Train: 17.50%, Valid: 21.25% Test: 27.45%\n",
      "Run: 06, Epoch: 06, Loss: 2.0406, Train: 25.00%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 07, Loss: 1.6189, Train: 25.83%, Valid: 27.50% Test: 31.37%\n",
      "Run: 06, Epoch: 08, Loss: 1.5872, Train: 25.83%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 09, Loss: 1.6794, Train: 26.67%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 10, Loss: 1.5379, Train: 25.83%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 11, Loss: 1.4491, Train: 37.50%, Valid: 38.75% Test: 43.14%\n",
      "Run: 06, Epoch: 12, Loss: 1.4667, Train: 42.50%, Valid: 52.50% Test: 52.94%\n",
      "Run: 06, Epoch: 13, Loss: 1.6024, Train: 39.17%, Valid: 53.75% Test: 50.98%\n",
      "Run: 06, Epoch: 14, Loss: 1.4498, Train: 39.17%, Valid: 51.25% Test: 50.98%\n",
      "Run: 06, Epoch: 15, Loss: 1.4544, Train: 38.33%, Valid: 47.50% Test: 49.02%\n",
      "Run: 06, Epoch: 16, Loss: 1.4554, Train: 39.17%, Valid: 48.75% Test: 49.02%\n",
      "Run: 06, Epoch: 17, Loss: 1.4687, Train: 40.00%, Valid: 46.25% Test: 50.98%\n",
      "Run: 06, Epoch: 18, Loss: 1.4242, Train: 42.50%, Valid: 50.00% Test: 49.02%\n",
      "Run: 06, Epoch: 19, Loss: 1.3910, Train: 44.17%, Valid: 52.50% Test: 49.02%\n",
      "Run: 06, Epoch: 20, Loss: 1.3490, Train: 46.67%, Valid: 50.00% Test: 45.10%\n",
      "Run: 06, Epoch: 21, Loss: 1.3961, Train: 45.00%, Valid: 50.00% Test: 45.10%\n",
      "Run: 06, Epoch: 22, Loss: 1.3948, Train: 45.00%, Valid: 48.75% Test: 47.06%\n",
      "Run: 06, Epoch: 23, Loss: 1.3709, Train: 40.83%, Valid: 43.75% Test: 43.14%\n",
      "Run: 06, Epoch: 24, Loss: 1.2888, Train: 40.83%, Valid: 43.75% Test: 37.25%\n",
      "Run: 06, Epoch: 25, Loss: 1.2926, Train: 40.83%, Valid: 41.25% Test: 33.33%\n",
      "Run: 06, Epoch: 26, Loss: 1.2385, Train: 40.00%, Valid: 40.00% Test: 33.33%\n",
      "Run: 06, Epoch: 27, Loss: 1.2919, Train: 41.67%, Valid: 41.25% Test: 33.33%\n",
      "Run: 06, Epoch: 28, Loss: 1.3053, Train: 43.33%, Valid: 41.25% Test: 37.25%\n",
      "Run: 06, Epoch: 29, Loss: 1.4150, Train: 49.17%, Valid: 38.75% Test: 35.29%\n",
      "Run: 06, Epoch: 30, Loss: 1.2781, Train: 51.67%, Valid: 40.00% Test: 33.33%\n",
      "Run: 06, Epoch: 31, Loss: 1.2910, Train: 50.83%, Valid: 38.75% Test: 39.22%\n",
      "Run: 06, Epoch: 32, Loss: 1.2661, Train: 49.17%, Valid: 40.00% Test: 41.18%\n",
      "Run: 06, Epoch: 33, Loss: 1.3189, Train: 49.17%, Valid: 41.25% Test: 47.06%\n",
      "Run: 06, Epoch: 34, Loss: 1.2855, Train: 47.50%, Valid: 45.00% Test: 50.98%\n",
      "Run: 06, Epoch: 35, Loss: 1.3354, Train: 46.67%, Valid: 47.50% Test: 50.98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 36, Loss: 1.3056, Train: 47.50%, Valid: 48.75% Test: 50.98%\n",
      "Run: 06, Epoch: 37, Loss: 1.2532, Train: 47.50%, Valid: 47.50% Test: 49.02%\n",
      "Run: 06, Epoch: 38, Loss: 1.2379, Train: 47.50%, Valid: 47.50% Test: 49.02%\n",
      "Run: 06, Epoch: 39, Loss: 1.1944, Train: 46.67%, Valid: 46.25% Test: 50.98%\n",
      "Run: 06, Epoch: 40, Loss: 1.2272, Train: 46.67%, Valid: 47.50% Test: 50.98%\n",
      "Run: 06, Epoch: 41, Loss: 1.1795, Train: 47.50%, Valid: 47.50% Test: 50.98%\n",
      "Run: 06, Epoch: 42, Loss: 1.2870, Train: 48.33%, Valid: 47.50% Test: 50.98%\n",
      "Run: 06, Epoch: 43, Loss: 1.1811, Train: 51.67%, Valid: 45.00% Test: 47.06%\n",
      "Run: 06, Epoch: 44, Loss: 1.2291, Train: 50.83%, Valid: 43.75% Test: 47.06%\n",
      "Run: 06, Epoch: 45, Loss: 1.2275, Train: 51.67%, Valid: 43.75% Test: 45.10%\n",
      "Run: 06, Epoch: 46, Loss: 1.1622, Train: 52.50%, Valid: 42.50% Test: 43.14%\n",
      "Run: 06, Epoch: 47, Loss: 1.2316, Train: 51.67%, Valid: 43.75% Test: 43.14%\n",
      "Run: 06, Epoch: 48, Loss: 1.2310, Train: 50.83%, Valid: 45.00% Test: 47.06%\n",
      "Run: 06, Epoch: 49, Loss: 1.2621, Train: 51.67%, Valid: 46.25% Test: 49.02%\n",
      "Run: 06, Epoch: 50, Loss: 1.2947, Train: 48.33%, Valid: 47.50% Test: 47.06%\n",
      "Run: 06, Epoch: 51, Loss: 1.3039, Train: 45.00%, Valid: 47.50% Test: 49.02%\n",
      "Run: 06, Epoch: 52, Loss: 1.2193, Train: 45.00%, Valid: 48.75% Test: 49.02%\n",
      "Run: 06, Epoch: 53, Loss: 1.2271, Train: 45.00%, Valid: 50.00% Test: 49.02%\n",
      "Run: 06, Epoch: 54, Loss: 1.2289, Train: 45.83%, Valid: 52.50% Test: 52.94%\n",
      "Run: 06, Epoch: 55, Loss: 1.2401, Train: 45.83%, Valid: 52.50% Test: 52.94%\n",
      "Run: 06, Epoch: 56, Loss: 1.2935, Train: 46.67%, Valid: 52.50% Test: 52.94%\n",
      "Run: 06, Epoch: 57, Loss: 1.2520, Train: 46.67%, Valid: 52.50% Test: 52.94%\n",
      "Run: 06, Epoch: 58, Loss: 1.2507, Train: 48.33%, Valid: 53.75% Test: 52.94%\n",
      "Run: 06, Epoch: 59, Loss: 1.2940, Train: 49.17%, Valid: 53.75% Test: 52.94%\n",
      "Run: 06, Epoch: 60, Loss: 1.1915, Train: 47.50%, Valid: 53.75% Test: 54.90%\n",
      "Run: 06, Epoch: 61, Loss: 1.1827, Train: 47.50%, Valid: 53.75% Test: 52.94%\n",
      "Run: 06, Epoch: 62, Loss: 1.2057, Train: 50.00%, Valid: 52.50% Test: 54.90%\n",
      "Run: 06, Epoch: 63, Loss: 1.1986, Train: 50.83%, Valid: 51.25% Test: 56.86%\n",
      "Run: 06, Epoch: 64, Loss: 1.1936, Train: 52.50%, Valid: 51.25% Test: 56.86%\n",
      "Run: 06, Epoch: 65, Loss: 1.2178, Train: 53.33%, Valid: 50.00% Test: 56.86%\n",
      "Run: 06, Epoch: 66, Loss: 1.2666, Train: 53.33%, Valid: 50.00% Test: 56.86%\n",
      "Run: 06, Epoch: 67, Loss: 1.1609, Train: 54.17%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 68, Loss: 1.1513, Train: 52.50%, Valid: 48.75% Test: 49.02%\n",
      "Run: 06, Epoch: 69, Loss: 1.2691, Train: 55.00%, Valid: 48.75% Test: 47.06%\n",
      "Run: 06, Epoch: 70, Loss: 1.2317, Train: 55.83%, Valid: 45.00% Test: 45.10%\n",
      "Run: 06, Epoch: 71, Loss: 1.1387, Train: 54.17%, Valid: 45.00% Test: 43.14%\n",
      "Run: 06, Epoch: 72, Loss: 1.2569, Train: 53.33%, Valid: 46.25% Test: 43.14%\n",
      "Run: 06, Epoch: 73, Loss: 1.2224, Train: 57.50%, Valid: 47.50% Test: 45.10%\n",
      "Run: 06, Epoch: 74, Loss: 1.1190, Train: 53.33%, Valid: 48.75% Test: 47.06%\n",
      "Run: 06, Epoch: 75, Loss: 1.2418, Train: 53.33%, Valid: 48.75% Test: 47.06%\n",
      "Run: 06, Epoch: 76, Loss: 1.1714, Train: 51.67%, Valid: 48.75% Test: 54.90%\n",
      "Run: 06, Epoch: 77, Loss: 1.2177, Train: 51.67%, Valid: 51.25% Test: 54.90%\n",
      "Run: 06, Epoch: 78, Loss: 1.1643, Train: 50.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 79, Loss: 1.1720, Train: 50.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 80, Loss: 1.2119, Train: 50.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 81, Loss: 1.1226, Train: 50.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 82, Loss: 1.1542, Train: 50.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 83, Loss: 1.1873, Train: 48.33%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 84, Loss: 1.1147, Train: 52.50%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 85, Loss: 1.1414, Train: 51.67%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 86, Loss: 1.1423, Train: 52.50%, Valid: 52.50% Test: 56.86%\n",
      "Run: 06, Epoch: 87, Loss: 1.1531, Train: 54.17%, Valid: 51.25% Test: 54.90%\n",
      "Run: 06, Epoch: 88, Loss: 1.1286, Train: 55.00%, Valid: 51.25% Test: 54.90%\n",
      "Run: 06, Epoch: 89, Loss: 1.1817, Train: 55.83%, Valid: 50.00% Test: 52.94%\n",
      "Run: 06, Epoch: 90, Loss: 1.1689, Train: 56.67%, Valid: 50.00% Test: 50.98%\n",
      "Run: 06, Epoch: 91, Loss: 1.1676, Train: 52.50%, Valid: 50.00% Test: 49.02%\n",
      "Run: 06, Epoch: 92, Loss: 1.1925, Train: 52.50%, Valid: 50.00% Test: 47.06%\n",
      "Run: 06, Epoch: 93, Loss: 1.2180, Train: 52.50%, Valid: 48.75% Test: 47.06%\n",
      "Run: 06, Epoch: 94, Loss: 1.1934, Train: 53.33%, Valid: 48.75% Test: 49.02%\n",
      "Run: 06, Epoch: 95, Loss: 1.1125, Train: 53.33%, Valid: 50.00% Test: 49.02%\n",
      "Run: 06, Epoch: 96, Loss: 1.1209, Train: 55.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 06, Epoch: 97, Loss: 1.0248, Train: 55.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 06, Epoch: 98, Loss: 1.0868, Train: 55.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 06, Epoch: 99, Loss: 1.2431, Train: 55.83%, Valid: 51.25% Test: 52.94%\n",
      "Run: 06, Epoch: 100, Loss: 1.1531, Train: 56.67%, Valid: 52.50% Test: 52.94%\n",
      "Run 06:\n",
      "Highest Train: 57.50\n",
      "Highest Valid: 53.75\n",
      "  Final Train: 39.17\n",
      "   Final Test: 50.98\n",
      "Run: 07, Epoch: 01, Loss: 2.3800, Train: 43.33%, Valid: 50.00% Test: 45.10%\n",
      "Run: 07, Epoch: 02, Loss: 2.5787, Train: 44.17%, Valid: 52.50% Test: 47.06%\n",
      "Run: 07, Epoch: 03, Loss: 2.0925, Train: 43.33%, Valid: 51.25% Test: 47.06%\n",
      "Run: 07, Epoch: 04, Loss: 1.9437, Train: 41.67%, Valid: 48.75% Test: 47.06%\n",
      "Run: 07, Epoch: 05, Loss: 1.8214, Train: 39.17%, Valid: 48.75% Test: 47.06%\n",
      "Run: 07, Epoch: 06, Loss: 1.6974, Train: 37.50%, Valid: 48.75% Test: 45.10%\n",
      "Run: 07, Epoch: 07, Loss: 1.7074, Train: 38.33%, Valid: 48.75% Test: 45.10%\n",
      "Run: 07, Epoch: 08, Loss: 1.6728, Train: 37.50%, Valid: 47.50% Test: 45.10%\n",
      "Run: 07, Epoch: 09, Loss: 1.5449, Train: 37.50%, Valid: 43.75% Test: 43.14%\n",
      "Run: 07, Epoch: 10, Loss: 1.4992, Train: 38.33%, Valid: 41.25% Test: 43.14%\n",
      "Run: 07, Epoch: 11, Loss: 1.4908, Train: 38.33%, Valid: 40.00% Test: 41.18%\n",
      "Run: 07, Epoch: 12, Loss: 1.4085, Train: 39.17%, Valid: 36.25% Test: 39.22%\n",
      "Run: 07, Epoch: 13, Loss: 1.3906, Train: 40.00%, Valid: 36.25% Test: 43.14%\n",
      "Run: 07, Epoch: 14, Loss: 1.3394, Train: 40.83%, Valid: 36.25% Test: 47.06%\n",
      "Run: 07, Epoch: 15, Loss: 1.3242, Train: 42.50%, Valid: 36.25% Test: 47.06%\n",
      "Run: 07, Epoch: 16, Loss: 1.4344, Train: 44.17%, Valid: 37.50% Test: 47.06%\n",
      "Run: 07, Epoch: 17, Loss: 1.2905, Train: 47.50%, Valid: 38.75% Test: 47.06%\n",
      "Run: 07, Epoch: 18, Loss: 1.3510, Train: 50.83%, Valid: 42.50% Test: 50.98%\n",
      "Run: 07, Epoch: 19, Loss: 1.3311, Train: 54.17%, Valid: 46.25% Test: 50.98%\n",
      "Run: 07, Epoch: 20, Loss: 1.3407, Train: 54.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 07, Epoch: 21, Loss: 1.3542, Train: 55.83%, Valid: 51.25% Test: 52.94%\n",
      "Run: 07, Epoch: 22, Loss: 1.3364, Train: 53.33%, Valid: 52.50% Test: 54.90%\n",
      "Run: 07, Epoch: 23, Loss: 1.3375, Train: 52.50%, Valid: 56.25% Test: 52.94%\n",
      "Run: 07, Epoch: 24, Loss: 1.2120, Train: 53.33%, Valid: 56.25% Test: 52.94%\n",
      "Run: 07, Epoch: 25, Loss: 1.3273, Train: 53.33%, Valid: 58.75% Test: 50.98%\n",
      "Run: 07, Epoch: 26, Loss: 1.2468, Train: 54.17%, Valid: 57.50% Test: 49.02%\n",
      "Run: 07, Epoch: 27, Loss: 1.2932, Train: 54.17%, Valid: 57.50% Test: 49.02%\n",
      "Run: 07, Epoch: 28, Loss: 1.2150, Train: 55.00%, Valid: 57.50% Test: 49.02%\n",
      "Run: 07, Epoch: 29, Loss: 1.2594, Train: 51.67%, Valid: 57.50% Test: 50.98%\n",
      "Run: 07, Epoch: 30, Loss: 1.1945, Train: 50.83%, Valid: 57.50% Test: 50.98%\n",
      "Run: 07, Epoch: 31, Loss: 1.2258, Train: 50.83%, Valid: 58.75% Test: 52.94%\n",
      "Run: 07, Epoch: 32, Loss: 1.2323, Train: 52.50%, Valid: 58.75% Test: 56.86%\n",
      "Run: 07, Epoch: 33, Loss: 1.2694, Train: 56.67%, Valid: 60.00% Test: 54.90%\n",
      "Run: 07, Epoch: 34, Loss: 1.2282, Train: 59.17%, Valid: 60.00% Test: 54.90%\n",
      "Run: 07, Epoch: 35, Loss: 1.2672, Train: 59.17%, Valid: 58.75% Test: 54.90%\n",
      "Run: 07, Epoch: 36, Loss: 1.1998, Train: 59.17%, Valid: 58.75% Test: 54.90%\n",
      "Run: 07, Epoch: 37, Loss: 1.2425, Train: 59.17%, Valid: 58.75% Test: 54.90%\n",
      "Run: 07, Epoch: 38, Loss: 1.2415, Train: 59.17%, Valid: 60.00% Test: 54.90%\n",
      "Run: 07, Epoch: 39, Loss: 1.1420, Train: 58.33%, Valid: 60.00% Test: 54.90%\n",
      "Run: 07, Epoch: 40, Loss: 1.1369, Train: 57.50%, Valid: 60.00% Test: 56.86%\n",
      "Run: 07, Epoch: 41, Loss: 1.2071, Train: 57.50%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 42, Loss: 1.1329, Train: 57.50%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 43, Loss: 1.2438, Train: 58.33%, Valid: 60.00% Test: 56.86%\n",
      "Run: 07, Epoch: 44, Loss: 1.1745, Train: 58.33%, Valid: 60.00% Test: 54.90%\n",
      "Run: 07, Epoch: 45, Loss: 1.1791, Train: 58.33%, Valid: 58.75% Test: 52.94%\n",
      "Run: 07, Epoch: 46, Loss: 1.1794, Train: 57.50%, Valid: 58.75% Test: 50.98%\n",
      "Run: 07, Epoch: 47, Loss: 1.2044, Train: 58.33%, Valid: 58.75% Test: 52.94%\n",
      "Run: 07, Epoch: 48, Loss: 1.1773, Train: 57.50%, Valid: 58.75% Test: 56.86%\n",
      "Run: 07, Epoch: 49, Loss: 1.1798, Train: 58.33%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 50, Loss: 1.1130, Train: 56.67%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 51, Loss: 1.1711, Train: 56.67%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 52, Loss: 1.1571, Train: 56.67%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 53, Loss: 1.1766, Train: 56.67%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 54, Loss: 1.1164, Train: 56.67%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 55, Loss: 1.1308, Train: 57.50%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 56, Loss: 1.1765, Train: 57.50%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 57, Loss: 1.1563, Train: 58.33%, Valid: 57.50% Test: 56.86%\n",
      "Run: 07, Epoch: 58, Loss: 1.1847, Train: 58.33%, Valid: 57.50% Test: 54.90%\n",
      "Run: 07, Epoch: 59, Loss: 1.1694, Train: 60.00%, Valid: 57.50% Test: 54.90%\n",
      "Run: 07, Epoch: 60, Loss: 1.0695, Train: 60.00%, Valid: 57.50% Test: 56.86%\n",
      "Run: 07, Epoch: 61, Loss: 1.1081, Train: 59.17%, Valid: 57.50% Test: 58.82%\n",
      "Run: 07, Epoch: 62, Loss: 1.1271, Train: 59.17%, Valid: 60.00% Test: 58.82%\n",
      "Run: 07, Epoch: 63, Loss: 1.1669, Train: 59.17%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 64, Loss: 1.0766, Train: 60.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 07, Epoch: 65, Loss: 1.0775, Train: 60.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 66, Loss: 1.0789, Train: 59.17%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 67, Loss: 1.0964, Train: 60.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 68, Loss: 1.0702, Train: 59.17%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 69, Loss: 1.1206, Train: 60.83%, Valid: 57.50% Test: 60.78%\n",
      "Run: 07, Epoch: 70, Loss: 1.1502, Train: 61.67%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 71, Loss: 1.1969, Train: 60.83%, Valid: 57.50% Test: 56.86%\n",
      "Run: 07, Epoch: 72, Loss: 1.0845, Train: 60.83%, Valid: 57.50% Test: 60.78%\n",
      "Run: 07, Epoch: 73, Loss: 1.0861, Train: 61.67%, Valid: 58.75% Test: 54.90%\n",
      "Run: 07, Epoch: 74, Loss: 1.0387, Train: 62.50%, Valid: 60.00% Test: 56.86%\n",
      "Run: 07, Epoch: 75, Loss: 1.1186, Train: 61.67%, Valid: 61.25% Test: 54.90%\n",
      "Run: 07, Epoch: 76, Loss: 1.0986, Train: 61.67%, Valid: 62.50% Test: 60.78%\n",
      "Run: 07, Epoch: 77, Loss: 1.1165, Train: 60.00%, Valid: 62.50% Test: 60.78%\n",
      "Run: 07, Epoch: 78, Loss: 1.1354, Train: 60.00%, Valid: 62.50% Test: 58.82%\n",
      "Run: 07, Epoch: 79, Loss: 1.0865, Train: 60.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 80, Loss: 1.0914, Train: 60.00%, Valid: 61.25% Test: 58.82%\n",
      "Run: 07, Epoch: 81, Loss: 1.0814, Train: 60.83%, Valid: 58.75% Test: 56.86%\n",
      "Run: 07, Epoch: 82, Loss: 1.0455, Train: 60.83%, Valid: 57.50% Test: 56.86%\n",
      "Run: 07, Epoch: 83, Loss: 1.0469, Train: 61.67%, Valid: 57.50% Test: 60.78%\n",
      "Run: 07, Epoch: 84, Loss: 1.0764, Train: 61.67%, Valid: 57.50% Test: 60.78%\n",
      "Run: 07, Epoch: 85, Loss: 1.0981, Train: 61.67%, Valid: 58.75% Test: 58.82%\n",
      "Run: 07, Epoch: 86, Loss: 1.0757, Train: 63.33%, Valid: 58.75% Test: 52.94%\n",
      "Run: 07, Epoch: 87, Loss: 1.0405, Train: 63.33%, Valid: 60.00% Test: 52.94%\n",
      "Run: 07, Epoch: 88, Loss: 1.0010, Train: 62.50%, Valid: 60.00% Test: 54.90%\n",
      "Run: 07, Epoch: 89, Loss: 1.0680, Train: 62.50%, Valid: 60.00% Test: 56.86%\n",
      "Run: 07, Epoch: 90, Loss: 1.0567, Train: 62.50%, Valid: 60.00% Test: 58.82%\n",
      "Run: 07, Epoch: 91, Loss: 1.0557, Train: 64.17%, Valid: 60.00% Test: 58.82%\n",
      "Run: 07, Epoch: 92, Loss: 1.0768, Train: 63.33%, Valid: 60.00% Test: 56.86%\n",
      "Run: 07, Epoch: 93, Loss: 1.0703, Train: 63.33%, Valid: 60.00% Test: 56.86%\n",
      "Run: 07, Epoch: 94, Loss: 1.0434, Train: 64.17%, Valid: 58.75% Test: 54.90%\n",
      "Run: 07, Epoch: 95, Loss: 1.0534, Train: 63.33%, Valid: 60.00% Test: 62.75%\n",
      "Run: 07, Epoch: 96, Loss: 1.0286, Train: 63.33%, Valid: 58.75% Test: 62.75%\n",
      "Run: 07, Epoch: 97, Loss: 1.0172, Train: 61.67%, Valid: 57.50% Test: 60.78%\n",
      "Run: 07, Epoch: 98, Loss: 0.9920, Train: 60.83%, Valid: 56.25% Test: 62.75%\n",
      "Run: 07, Epoch: 99, Loss: 1.0680, Train: 61.67%, Valid: 57.50% Test: 60.78%\n",
      "Run: 07, Epoch: 100, Loss: 0.9652, Train: 61.67%, Valid: 57.50% Test: 60.78%\n",
      "Run 07:\n",
      "Highest Train: 64.17\n",
      "Highest Valid: 62.50\n",
      "  Final Train: 61.67\n",
      "   Final Test: 60.78\n",
      "Run: 08, Epoch: 01, Loss: 1.8494, Train: 28.33%, Valid: 27.50% Test: 27.45%\n",
      "Run: 08, Epoch: 02, Loss: 1.8693, Train: 30.83%, Valid: 27.50% Test: 27.45%\n",
      "Run: 08, Epoch: 03, Loss: 1.8404, Train: 26.67%, Valid: 32.50% Test: 19.61%\n",
      "Run: 08, Epoch: 04, Loss: 1.5469, Train: 19.17%, Valid: 26.25% Test: 9.80%\n",
      "Run: 08, Epoch: 05, Loss: 1.5259, Train: 19.17%, Valid: 28.75% Test: 13.73%\n",
      "Run: 08, Epoch: 06, Loss: 1.4239, Train: 25.00%, Valid: 31.25% Test: 21.57%\n",
      "Run: 08, Epoch: 07, Loss: 1.3936, Train: 37.50%, Valid: 46.25% Test: 29.41%\n",
      "Run: 08, Epoch: 08, Loss: 1.4827, Train: 42.50%, Valid: 45.00% Test: 29.41%\n",
      "Run: 08, Epoch: 09, Loss: 1.4083, Train: 41.67%, Valid: 37.50% Test: 37.25%\n",
      "Run: 08, Epoch: 10, Loss: 1.4319, Train: 44.17%, Valid: 43.75% Test: 49.02%\n",
      "Run: 08, Epoch: 11, Loss: 1.3659, Train: 45.00%, Valid: 45.00% Test: 54.90%\n",
      "Run: 08, Epoch: 12, Loss: 1.3568, Train: 45.83%, Valid: 46.25% Test: 52.94%\n",
      "Run: 08, Epoch: 13, Loss: 1.3304, Train: 51.67%, Valid: 53.75% Test: 52.94%\n",
      "Run: 08, Epoch: 14, Loss: 1.3450, Train: 50.83%, Valid: 53.75% Test: 47.06%\n",
      "Run: 08, Epoch: 15, Loss: 1.3275, Train: 52.50%, Valid: 51.25% Test: 45.10%\n",
      "Run: 08, Epoch: 16, Loss: 1.3615, Train: 53.33%, Valid: 51.25% Test: 50.98%\n",
      "Run: 08, Epoch: 17, Loss: 1.3417, Train: 50.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 08, Epoch: 18, Loss: 1.3677, Train: 50.00%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 19, Loss: 1.2694, Train: 49.17%, Valid: 50.00% Test: 50.98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 20, Loss: 1.2901, Train: 47.50%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 21, Loss: 1.2666, Train: 45.00%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 22, Loss: 1.2169, Train: 45.00%, Valid: 50.00% Test: 52.94%\n",
      "Run: 08, Epoch: 23, Loss: 1.2621, Train: 44.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 08, Epoch: 24, Loss: 1.3007, Train: 46.67%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 25, Loss: 1.3867, Train: 46.67%, Valid: 51.25% Test: 54.90%\n",
      "Run: 08, Epoch: 26, Loss: 1.2289, Train: 47.50%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 27, Loss: 1.2319, Train: 46.67%, Valid: 51.25% Test: 54.90%\n",
      "Run: 08, Epoch: 28, Loss: 1.2197, Train: 49.17%, Valid: 50.00% Test: 54.90%\n",
      "Run: 08, Epoch: 29, Loss: 1.3124, Train: 50.00%, Valid: 52.50% Test: 52.94%\n",
      "Run: 08, Epoch: 30, Loss: 1.1891, Train: 50.00%, Valid: 51.25% Test: 49.02%\n",
      "Run: 08, Epoch: 31, Loss: 1.3201, Train: 50.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 08, Epoch: 32, Loss: 1.2957, Train: 47.50%, Valid: 51.25% Test: 50.98%\n",
      "Run: 08, Epoch: 33, Loss: 1.2368, Train: 50.00%, Valid: 51.25% Test: 49.02%\n",
      "Run: 08, Epoch: 34, Loss: 1.1921, Train: 51.67%, Valid: 50.00% Test: 49.02%\n",
      "Run: 08, Epoch: 35, Loss: 1.2598, Train: 51.67%, Valid: 50.00% Test: 50.98%\n",
      "Run: 08, Epoch: 36, Loss: 1.2581, Train: 51.67%, Valid: 50.00% Test: 49.02%\n",
      "Run: 08, Epoch: 37, Loss: 1.3529, Train: 52.50%, Valid: 51.25% Test: 52.94%\n",
      "Run: 08, Epoch: 38, Loss: 1.2313, Train: 52.50%, Valid: 50.00% Test: 54.90%\n",
      "Run: 08, Epoch: 39, Loss: 1.2441, Train: 50.00%, Valid: 50.00% Test: 52.94%\n",
      "Run: 08, Epoch: 40, Loss: 1.2735, Train: 50.83%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 41, Loss: 1.1826, Train: 51.67%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 42, Loss: 1.1880, Train: 51.67%, Valid: 50.00% Test: 49.02%\n",
      "Run: 08, Epoch: 43, Loss: 1.1811, Train: 51.67%, Valid: 50.00% Test: 49.02%\n",
      "Run: 08, Epoch: 44, Loss: 1.1940, Train: 51.67%, Valid: 50.00% Test: 50.98%\n",
      "Run: 08, Epoch: 45, Loss: 1.2086, Train: 50.00%, Valid: 56.25% Test: 50.98%\n",
      "Run: 08, Epoch: 46, Loss: 1.2247, Train: 51.67%, Valid: 55.00% Test: 50.98%\n",
      "Run: 08, Epoch: 47, Loss: 1.1732, Train: 51.67%, Valid: 55.00% Test: 52.94%\n",
      "Run: 08, Epoch: 48, Loss: 1.2319, Train: 50.83%, Valid: 55.00% Test: 50.98%\n",
      "Run: 08, Epoch: 49, Loss: 1.1493, Train: 51.67%, Valid: 53.75% Test: 50.98%\n",
      "Run: 08, Epoch: 50, Loss: 1.1599, Train: 53.33%, Valid: 50.00% Test: 52.94%\n",
      "Run: 08, Epoch: 51, Loss: 1.1377, Train: 52.50%, Valid: 50.00% Test: 50.98%\n",
      "Run: 08, Epoch: 52, Loss: 1.1924, Train: 53.33%, Valid: 50.00% Test: 50.98%\n",
      "Run: 08, Epoch: 53, Loss: 1.1496, Train: 52.50%, Valid: 50.00% Test: 50.98%\n",
      "Run: 08, Epoch: 54, Loss: 1.1731, Train: 51.67%, Valid: 46.25% Test: 50.98%\n",
      "Run: 08, Epoch: 55, Loss: 1.1829, Train: 52.50%, Valid: 46.25% Test: 50.98%\n",
      "Run: 08, Epoch: 56, Loss: 1.1419, Train: 50.83%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 57, Loss: 1.1523, Train: 49.17%, Valid: 47.50% Test: 52.94%\n",
      "Run: 08, Epoch: 58, Loss: 1.1377, Train: 50.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 08, Epoch: 59, Loss: 1.2250, Train: 50.00%, Valid: 45.00% Test: 50.98%\n",
      "Run: 08, Epoch: 60, Loss: 1.1858, Train: 51.67%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 61, Loss: 1.2210, Train: 54.17%, Valid: 47.50% Test: 52.94%\n",
      "Run: 08, Epoch: 62, Loss: 1.1753, Train: 52.50%, Valid: 51.25% Test: 50.98%\n",
      "Run: 08, Epoch: 63, Loss: 1.0770, Train: 51.67%, Valid: 51.25% Test: 50.98%\n",
      "Run: 08, Epoch: 64, Loss: 1.1371, Train: 51.67%, Valid: 51.25% Test: 50.98%\n",
      "Run: 08, Epoch: 65, Loss: 1.0844, Train: 51.67%, Valid: 50.00% Test: 54.90%\n",
      "Run: 08, Epoch: 66, Loss: 1.1448, Train: 51.67%, Valid: 50.00% Test: 54.90%\n",
      "Run: 08, Epoch: 67, Loss: 1.1370, Train: 52.50%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 68, Loss: 1.2304, Train: 52.50%, Valid: 52.50% Test: 50.98%\n",
      "Run: 08, Epoch: 69, Loss: 1.1758, Train: 51.67%, Valid: 52.50% Test: 50.98%\n",
      "Run: 08, Epoch: 70, Loss: 1.1462, Train: 51.67%, Valid: 50.00% Test: 50.98%\n",
      "Run: 08, Epoch: 71, Loss: 1.1438, Train: 52.50%, Valid: 50.00% Test: 50.98%\n",
      "Run: 08, Epoch: 72, Loss: 1.1507, Train: 53.33%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 73, Loss: 1.1173, Train: 53.33%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 74, Loss: 1.1523, Train: 54.17%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 75, Loss: 1.1620, Train: 52.50%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 76, Loss: 1.1421, Train: 53.33%, Valid: 45.00% Test: 50.98%\n",
      "Run: 08, Epoch: 77, Loss: 1.1306, Train: 53.33%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 78, Loss: 1.1254, Train: 54.17%, Valid: 47.50% Test: 49.02%\n",
      "Run: 08, Epoch: 79, Loss: 1.2266, Train: 51.67%, Valid: 48.75% Test: 49.02%\n",
      "Run: 08, Epoch: 80, Loss: 1.1600, Train: 52.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 08, Epoch: 81, Loss: 1.1510, Train: 52.50%, Valid: 52.50% Test: 52.94%\n",
      "Run: 08, Epoch: 82, Loss: 1.2032, Train: 52.50%, Valid: 55.00% Test: 54.90%\n",
      "Run: 08, Epoch: 83, Loss: 1.2054, Train: 52.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 08, Epoch: 84, Loss: 1.0679, Train: 52.50%, Valid: 46.25% Test: 50.98%\n",
      "Run: 08, Epoch: 85, Loss: 1.1394, Train: 53.33%, Valid: 45.00% Test: 47.06%\n",
      "Run: 08, Epoch: 86, Loss: 1.0989, Train: 50.83%, Valid: 43.75% Test: 47.06%\n",
      "Run: 08, Epoch: 87, Loss: 1.1489, Train: 54.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 88, Loss: 1.1581, Train: 52.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 08, Epoch: 89, Loss: 1.0627, Train: 51.67%, Valid: 51.25% Test: 50.98%\n",
      "Run: 08, Epoch: 90, Loss: 1.0911, Train: 52.50%, Valid: 52.50% Test: 50.98%\n",
      "Run: 08, Epoch: 91, Loss: 1.1219, Train: 52.50%, Valid: 52.50% Test: 52.94%\n",
      "Run: 08, Epoch: 92, Loss: 1.1398, Train: 52.50%, Valid: 51.25% Test: 52.94%\n",
      "Run: 08, Epoch: 93, Loss: 1.0572, Train: 52.50%, Valid: 51.25% Test: 52.94%\n",
      "Run: 08, Epoch: 94, Loss: 1.0995, Train: 52.50%, Valid: 52.50% Test: 50.98%\n",
      "Run: 08, Epoch: 95, Loss: 1.0959, Train: 50.00%, Valid: 51.25% Test: 49.02%\n",
      "Run: 08, Epoch: 96, Loss: 1.1304, Train: 50.83%, Valid: 48.75% Test: 52.94%\n",
      "Run: 08, Epoch: 97, Loss: 1.1119, Train: 50.00%, Valid: 46.25% Test: 47.06%\n",
      "Run: 08, Epoch: 98, Loss: 1.1103, Train: 50.00%, Valid: 47.50% Test: 47.06%\n",
      "Run: 08, Epoch: 99, Loss: 1.0522, Train: 51.67%, Valid: 48.75% Test: 49.02%\n",
      "Run: 08, Epoch: 100, Loss: 1.0741, Train: 50.83%, Valid: 50.00% Test: 50.98%\n",
      "Run 08:\n",
      "Highest Train: 54.17\n",
      "Highest Valid: 56.25\n",
      "  Final Train: 50.00\n",
      "   Final Test: 50.98\n",
      "Run: 09, Epoch: 01, Loss: 1.8561, Train: 42.50%, Valid: 26.25% Test: 35.29%\n",
      "Run: 09, Epoch: 02, Loss: 1.7113, Train: 47.50%, Valid: 35.00% Test: 43.14%\n",
      "Run: 09, Epoch: 03, Loss: 1.6568, Train: 48.33%, Valid: 35.00% Test: 45.10%\n",
      "Run: 09, Epoch: 04, Loss: 1.5086, Train: 50.00%, Valid: 35.00% Test: 45.10%\n",
      "Run: 09, Epoch: 05, Loss: 1.5467, Train: 50.00%, Valid: 35.00% Test: 45.10%\n",
      "Run: 09, Epoch: 06, Loss: 1.6016, Train: 50.00%, Valid: 35.00% Test: 45.10%\n",
      "Run: 09, Epoch: 07, Loss: 1.4914, Train: 50.00%, Valid: 35.00% Test: 45.10%\n",
      "Run: 09, Epoch: 08, Loss: 1.5708, Train: 50.00%, Valid: 35.00% Test: 45.10%\n",
      "Run: 09, Epoch: 09, Loss: 1.3121, Train: 50.00%, Valid: 35.00% Test: 45.10%\n",
      "Run: 09, Epoch: 10, Loss: 2.0214, Train: 50.00%, Valid: 35.00% Test: 45.10%\n",
      "Run: 09, Epoch: 11, Loss: 1.3947, Train: 50.00%, Valid: 35.00% Test: 45.10%\n",
      "Run: 09, Epoch: 12, Loss: 1.4074, Train: 51.67%, Valid: 35.00% Test: 45.10%\n",
      "Run: 09, Epoch: 13, Loss: 1.3721, Train: 52.50%, Valid: 35.00% Test: 47.06%\n",
      "Run: 09, Epoch: 14, Loss: 1.2908, Train: 50.83%, Valid: 35.00% Test: 47.06%\n",
      "Run: 09, Epoch: 15, Loss: 1.3922, Train: 50.00%, Valid: 33.75% Test: 47.06%\n",
      "Run: 09, Epoch: 16, Loss: 1.4472, Train: 50.83%, Valid: 33.75% Test: 47.06%\n",
      "Run: 09, Epoch: 17, Loss: 1.3685, Train: 51.67%, Valid: 33.75% Test: 47.06%\n",
      "Run: 09, Epoch: 18, Loss: 1.2503, Train: 52.50%, Valid: 35.00% Test: 49.02%\n",
      "Run: 09, Epoch: 19, Loss: 1.3430, Train: 52.50%, Valid: 38.75% Test: 52.94%\n",
      "Run: 09, Epoch: 20, Loss: 1.2825, Train: 53.33%, Valid: 41.25% Test: 49.02%\n",
      "Run: 09, Epoch: 21, Loss: 1.2075, Train: 52.50%, Valid: 38.75% Test: 47.06%\n",
      "Run: 09, Epoch: 22, Loss: 1.1684, Train: 52.50%, Valid: 37.50% Test: 47.06%\n",
      "Run: 09, Epoch: 23, Loss: 1.1792, Train: 52.50%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 24, Loss: 1.1892, Train: 52.50%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 25, Loss: 1.1979, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 26, Loss: 1.1989, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 27, Loss: 1.1507, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 28, Loss: 1.1580, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 29, Loss: 1.1459, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 30, Loss: 1.1075, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 31, Loss: 1.0989, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 32, Loss: 1.1477, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 33, Loss: 1.0937, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 34, Loss: 1.2326, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 35, Loss: 1.1080, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 36, Loss: 1.1156, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 37, Loss: 1.0520, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 38, Loss: 1.1140, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 39, Loss: 1.1231, Train: 53.33%, Valid: 40.00% Test: 45.10%\n",
      "Run: 09, Epoch: 40, Loss: 1.0807, Train: 53.33%, Valid: 40.00% Test: 47.06%\n",
      "Run: 09, Epoch: 41, Loss: 1.1107, Train: 54.17%, Valid: 40.00% Test: 47.06%\n",
      "Run: 09, Epoch: 42, Loss: 1.0722, Train: 55.83%, Valid: 40.00% Test: 49.02%\n",
      "Run: 09, Epoch: 43, Loss: 1.0819, Train: 57.50%, Valid: 40.00% Test: 49.02%\n",
      "Run: 09, Epoch: 44, Loss: 1.0708, Train: 57.50%, Valid: 41.25% Test: 50.98%\n",
      "Run: 09, Epoch: 45, Loss: 1.0867, Train: 57.50%, Valid: 41.25% Test: 49.02%\n",
      "Run: 09, Epoch: 46, Loss: 1.0080, Train: 57.50%, Valid: 41.25% Test: 49.02%\n",
      "Run: 09, Epoch: 47, Loss: 1.1136, Train: 58.33%, Valid: 40.00% Test: 47.06%\n",
      "Run: 09, Epoch: 48, Loss: 1.1238, Train: 57.50%, Valid: 40.00% Test: 47.06%\n",
      "Run: 09, Epoch: 49, Loss: 1.0274, Train: 54.17%, Valid: 38.75% Test: 47.06%\n",
      "Run: 09, Epoch: 50, Loss: 1.0734, Train: 54.17%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 51, Loss: 1.0377, Train: 56.67%, Valid: 38.75% Test: 49.02%\n",
      "Run: 09, Epoch: 52, Loss: 1.0360, Train: 56.67%, Valid: 40.00% Test: 49.02%\n",
      "Run: 09, Epoch: 53, Loss: 1.0871, Train: 58.33%, Valid: 40.00% Test: 49.02%\n",
      "Run: 09, Epoch: 54, Loss: 1.0837, Train: 57.50%, Valid: 42.50% Test: 49.02%\n",
      "Run: 09, Epoch: 55, Loss: 1.1127, Train: 59.17%, Valid: 42.50% Test: 49.02%\n",
      "Run: 09, Epoch: 56, Loss: 1.0875, Train: 60.00%, Valid: 43.75% Test: 50.98%\n",
      "Run: 09, Epoch: 57, Loss: 1.0546, Train: 60.00%, Valid: 46.25% Test: 50.98%\n",
      "Run: 09, Epoch: 58, Loss: 1.0452, Train: 60.00%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 59, Loss: 1.1488, Train: 60.00%, Valid: 50.00% Test: 54.90%\n",
      "Run: 09, Epoch: 60, Loss: 1.0828, Train: 58.33%, Valid: 50.00% Test: 54.90%\n",
      "Run: 09, Epoch: 61, Loss: 1.0425, Train: 57.50%, Valid: 48.75% Test: 54.90%\n",
      "Run: 09, Epoch: 62, Loss: 1.0515, Train: 57.50%, Valid: 48.75% Test: 56.86%\n",
      "Run: 09, Epoch: 63, Loss: 1.0495, Train: 58.33%, Valid: 50.00% Test: 56.86%\n",
      "Run: 09, Epoch: 64, Loss: 1.0043, Train: 60.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 09, Epoch: 65, Loss: 1.1017, Train: 61.67%, Valid: 48.75% Test: 52.94%\n",
      "Run: 09, Epoch: 66, Loss: 1.0149, Train: 61.67%, Valid: 48.75% Test: 52.94%\n",
      "Run: 09, Epoch: 67, Loss: 1.0681, Train: 61.67%, Valid: 48.75% Test: 52.94%\n",
      "Run: 09, Epoch: 68, Loss: 1.0248, Train: 64.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 69, Loss: 1.0259, Train: 63.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 09, Epoch: 70, Loss: 1.0571, Train: 62.50%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 71, Loss: 1.0167, Train: 62.50%, Valid: 48.75% Test: 50.98%\n",
      "Run: 09, Epoch: 72, Loss: 1.0571, Train: 60.00%, Valid: 45.00% Test: 45.10%\n",
      "Run: 09, Epoch: 73, Loss: 1.0129, Train: 59.17%, Valid: 41.25% Test: 43.14%\n",
      "Run: 09, Epoch: 74, Loss: 1.0480, Train: 56.67%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 75, Loss: 1.0468, Train: 55.00%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 76, Loss: 1.0592, Train: 55.83%, Valid: 37.50% Test: 45.10%\n",
      "Run: 09, Epoch: 77, Loss: 1.0835, Train: 55.83%, Valid: 37.50% Test: 45.10%\n",
      "Run: 09, Epoch: 78, Loss: 0.9707, Train: 55.83%, Valid: 37.50% Test: 45.10%\n",
      "Run: 09, Epoch: 79, Loss: 1.0999, Train: 55.83%, Valid: 37.50% Test: 45.10%\n",
      "Run: 09, Epoch: 80, Loss: 1.1123, Train: 55.83%, Valid: 37.50% Test: 45.10%\n",
      "Run: 09, Epoch: 81, Loss: 1.1044, Train: 55.83%, Valid: 37.50% Test: 45.10%\n",
      "Run: 09, Epoch: 82, Loss: 1.0448, Train: 54.17%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 83, Loss: 0.9941, Train: 55.00%, Valid: 40.00% Test: 45.10%\n",
      "Run: 09, Epoch: 84, Loss: 1.0052, Train: 56.67%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 85, Loss: 0.9946, Train: 60.83%, Valid: 40.00% Test: 47.06%\n",
      "Run: 09, Epoch: 86, Loss: 1.0922, Train: 60.00%, Valid: 43.75% Test: 45.10%\n",
      "Run: 09, Epoch: 87, Loss: 1.0489, Train: 60.83%, Valid: 45.00% Test: 47.06%\n",
      "Run: 09, Epoch: 88, Loss: 0.9879, Train: 60.00%, Valid: 45.00% Test: 49.02%\n",
      "Run: 09, Epoch: 89, Loss: 1.0227, Train: 60.00%, Valid: 47.50% Test: 50.98%\n",
      "Run: 09, Epoch: 90, Loss: 1.0399, Train: 61.67%, Valid: 48.75% Test: 52.94%\n",
      "Run: 09, Epoch: 91, Loss: 1.0295, Train: 62.50%, Valid: 48.75% Test: 52.94%\n",
      "Run: 09, Epoch: 92, Loss: 1.0769, Train: 61.67%, Valid: 48.75% Test: 52.94%\n",
      "Run: 09, Epoch: 93, Loss: 1.0003, Train: 61.67%, Valid: 48.75% Test: 52.94%\n",
      "Run: 09, Epoch: 94, Loss: 1.0578, Train: 62.50%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 95, Loss: 0.9916, Train: 60.83%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 96, Loss: 1.0040, Train: 60.83%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 97, Loss: 0.9266, Train: 59.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 09, Epoch: 98, Loss: 1.0358, Train: 60.83%, Valid: 45.00% Test: 47.06%\n",
      "Run: 09, Epoch: 99, Loss: 0.9958, Train: 61.67%, Valid: 43.75% Test: 47.06%\n",
      "Run: 09, Epoch: 100, Loss: 1.0144, Train: 60.83%, Valid: 45.00% Test: 47.06%\n",
      "Run 09:\n",
      "Highest Train: 64.17\n",
      "Highest Valid: 51.25\n",
      "  Final Train: 63.33\n",
      "   Final Test: 52.94\n",
      "Run: 10, Epoch: 01, Loss: 1.6745, Train: 5.00%, Valid: 10.00% Test: 7.84%\n",
      "Run: 10, Epoch: 02, Loss: 1.5718, Train: 21.67%, Valid: 20.00% Test: 11.76%\n",
      "Run: 10, Epoch: 03, Loss: 1.5867, Train: 35.00%, Valid: 33.75% Test: 33.33%\n",
      "Run: 10, Epoch: 04, Loss: 1.3546, Train: 45.83%, Valid: 42.50% Test: 41.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 05, Loss: 1.4661, Train: 45.83%, Valid: 45.00% Test: 43.14%\n",
      "Run: 10, Epoch: 06, Loss: 1.4836, Train: 45.83%, Valid: 47.50% Test: 47.06%\n",
      "Run: 10, Epoch: 07, Loss: 1.4092, Train: 48.33%, Valid: 50.00% Test: 49.02%\n",
      "Run: 10, Epoch: 08, Loss: 1.3080, Train: 53.33%, Valid: 45.00% Test: 52.94%\n",
      "Run: 10, Epoch: 09, Loss: 1.3207, Train: 48.33%, Valid: 42.50% Test: 52.94%\n",
      "Run: 10, Epoch: 10, Loss: 1.3019, Train: 51.67%, Valid: 40.00% Test: 52.94%\n",
      "Run: 10, Epoch: 11, Loss: 1.3642, Train: 51.67%, Valid: 38.75% Test: 49.02%\n",
      "Run: 10, Epoch: 12, Loss: 1.2711, Train: 51.67%, Valid: 37.50% Test: 50.98%\n",
      "Run: 10, Epoch: 13, Loss: 1.2623, Train: 50.00%, Valid: 40.00% Test: 50.98%\n",
      "Run: 10, Epoch: 14, Loss: 1.3974, Train: 50.83%, Valid: 38.75% Test: 50.98%\n",
      "Run: 10, Epoch: 15, Loss: 1.2885, Train: 50.83%, Valid: 43.75% Test: 49.02%\n",
      "Run: 10, Epoch: 16, Loss: 1.2628, Train: 49.17%, Valid: 43.75% Test: 47.06%\n",
      "Run: 10, Epoch: 17, Loss: 1.3426, Train: 46.67%, Valid: 45.00% Test: 45.10%\n",
      "Run: 10, Epoch: 18, Loss: 1.2508, Train: 46.67%, Valid: 43.75% Test: 45.10%\n",
      "Run: 10, Epoch: 19, Loss: 1.2357, Train: 47.50%, Valid: 47.50% Test: 43.14%\n",
      "Run: 10, Epoch: 20, Loss: 1.2068, Train: 48.33%, Valid: 48.75% Test: 43.14%\n",
      "Run: 10, Epoch: 21, Loss: 1.2132, Train: 47.50%, Valid: 47.50% Test: 43.14%\n",
      "Run: 10, Epoch: 22, Loss: 1.2749, Train: 47.50%, Valid: 47.50% Test: 45.10%\n",
      "Run: 10, Epoch: 23, Loss: 1.3945, Train: 50.00%, Valid: 47.50% Test: 49.02%\n",
      "Run: 10, Epoch: 24, Loss: 1.2354, Train: 50.00%, Valid: 47.50% Test: 49.02%\n",
      "Run: 10, Epoch: 25, Loss: 1.3661, Train: 50.00%, Valid: 47.50% Test: 49.02%\n",
      "Run: 10, Epoch: 26, Loss: 1.1594, Train: 49.17%, Valid: 46.25% Test: 47.06%\n",
      "Run: 10, Epoch: 27, Loss: 1.3330, Train: 50.00%, Valid: 46.25% Test: 47.06%\n",
      "Run: 10, Epoch: 28, Loss: 1.1941, Train: 49.17%, Valid: 46.25% Test: 47.06%\n",
      "Run: 10, Epoch: 29, Loss: 1.1494, Train: 50.00%, Valid: 46.25% Test: 47.06%\n",
      "Run: 10, Epoch: 30, Loss: 1.2104, Train: 50.00%, Valid: 46.25% Test: 47.06%\n",
      "Run: 10, Epoch: 31, Loss: 1.2227, Train: 50.00%, Valid: 46.25% Test: 47.06%\n",
      "Run: 10, Epoch: 32, Loss: 1.1887, Train: 50.00%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 33, Loss: 1.1752, Train: 50.83%, Valid: 45.00% Test: 43.14%\n",
      "Run: 10, Epoch: 34, Loss: 1.2168, Train: 50.83%, Valid: 45.00% Test: 43.14%\n",
      "Run: 10, Epoch: 35, Loss: 1.1867, Train: 51.67%, Valid: 45.00% Test: 45.10%\n",
      "Run: 10, Epoch: 36, Loss: 1.1624, Train: 51.67%, Valid: 45.00% Test: 45.10%\n",
      "Run: 10, Epoch: 37, Loss: 1.1674, Train: 51.67%, Valid: 45.00% Test: 45.10%\n",
      "Run: 10, Epoch: 38, Loss: 1.1387, Train: 50.83%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 39, Loss: 1.1372, Train: 50.83%, Valid: 46.25% Test: 41.18%\n",
      "Run: 10, Epoch: 40, Loss: 1.2296, Train: 47.50%, Valid: 42.50% Test: 37.25%\n",
      "Run: 10, Epoch: 41, Loss: 1.1506, Train: 50.83%, Valid: 43.75% Test: 39.22%\n",
      "Run: 10, Epoch: 42, Loss: 1.2327, Train: 50.00%, Valid: 45.00% Test: 41.18%\n",
      "Run: 10, Epoch: 43, Loss: 1.2231, Train: 54.17%, Valid: 42.50% Test: 41.18%\n",
      "Run: 10, Epoch: 44, Loss: 1.1426, Train: 54.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 45, Loss: 1.1332, Train: 55.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 10, Epoch: 46, Loss: 1.1068, Train: 54.17%, Valid: 48.75% Test: 60.78%\n",
      "Run: 10, Epoch: 47, Loss: 1.1105, Train: 52.50%, Valid: 48.75% Test: 58.82%\n",
      "Run: 10, Epoch: 48, Loss: 1.1502, Train: 56.67%, Valid: 40.00% Test: 54.90%\n",
      "Run: 10, Epoch: 49, Loss: 1.1370, Train: 47.50%, Valid: 40.00% Test: 54.90%\n",
      "Run: 10, Epoch: 50, Loss: 1.0557, Train: 41.67%, Valid: 36.25% Test: 49.02%\n",
      "Run: 10, Epoch: 51, Loss: 1.1357, Train: 41.67%, Valid: 37.50% Test: 49.02%\n",
      "Run: 10, Epoch: 52, Loss: 1.1474, Train: 48.33%, Valid: 41.25% Test: 50.98%\n",
      "Run: 10, Epoch: 53, Loss: 1.0706, Train: 50.83%, Valid: 41.25% Test: 52.94%\n",
      "Run: 10, Epoch: 54, Loss: 1.1616, Train: 57.50%, Valid: 43.75% Test: 56.86%\n",
      "Run: 10, Epoch: 55, Loss: 1.1610, Train: 56.67%, Valid: 52.50% Test: 50.98%\n",
      "Run: 10, Epoch: 56, Loss: 1.1567, Train: 55.83%, Valid: 51.25% Test: 45.10%\n",
      "Run: 10, Epoch: 57, Loss: 1.1096, Train: 52.50%, Valid: 47.50% Test: 45.10%\n",
      "Run: 10, Epoch: 58, Loss: 1.1034, Train: 50.00%, Valid: 48.75% Test: 45.10%\n",
      "Run: 10, Epoch: 59, Loss: 1.0751, Train: 50.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 10, Epoch: 60, Loss: 1.1419, Train: 50.00%, Valid: 52.50% Test: 45.10%\n",
      "Run: 10, Epoch: 61, Loss: 1.1189, Train: 50.00%, Valid: 51.25% Test: 43.14%\n",
      "Run: 10, Epoch: 62, Loss: 1.0480, Train: 49.17%, Valid: 50.00% Test: 43.14%\n",
      "Run: 10, Epoch: 63, Loss: 1.0601, Train: 52.50%, Valid: 50.00% Test: 47.06%\n",
      "Run: 10, Epoch: 64, Loss: 1.0226, Train: 53.33%, Valid: 51.25% Test: 50.98%\n",
      "Run: 10, Epoch: 65, Loss: 1.0825, Train: 52.50%, Valid: 50.00% Test: 49.02%\n",
      "Run: 10, Epoch: 66, Loss: 1.0621, Train: 53.33%, Valid: 48.75% Test: 49.02%\n",
      "Run: 10, Epoch: 67, Loss: 1.0390, Train: 54.17%, Valid: 52.50% Test: 56.86%\n",
      "Run: 10, Epoch: 68, Loss: 1.0392, Train: 54.17%, Valid: 55.00% Test: 54.90%\n",
      "Run: 10, Epoch: 69, Loss: 1.0390, Train: 51.67%, Valid: 51.25% Test: 56.86%\n",
      "Run: 10, Epoch: 70, Loss: 1.1304, Train: 53.33%, Valid: 51.25% Test: 47.06%\n",
      "Run: 10, Epoch: 71, Loss: 1.0425, Train: 53.33%, Valid: 50.00% Test: 41.18%\n",
      "Run: 10, Epoch: 72, Loss: 0.9930, Train: 53.33%, Valid: 50.00% Test: 43.14%\n",
      "Run: 10, Epoch: 73, Loss: 0.9969, Train: 54.17%, Valid: 50.00% Test: 47.06%\n",
      "Run: 10, Epoch: 74, Loss: 1.0708, Train: 53.33%, Valid: 50.00% Test: 49.02%\n",
      "Run: 10, Epoch: 75, Loss: 1.0660, Train: 52.50%, Valid: 52.50% Test: 50.98%\n",
      "Run: 10, Epoch: 76, Loss: 1.0424, Train: 54.17%, Valid: 51.25% Test: 56.86%\n",
      "Run: 10, Epoch: 77, Loss: 1.0232, Train: 55.00%, Valid: 52.50% Test: 54.90%\n",
      "Run: 10, Epoch: 78, Loss: 1.0312, Train: 52.50%, Valid: 48.75% Test: 54.90%\n",
      "Run: 10, Epoch: 79, Loss: 1.0329, Train: 55.00%, Valid: 50.00% Test: 56.86%\n",
      "Run: 10, Epoch: 80, Loss: 1.0614, Train: 53.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 10, Epoch: 81, Loss: 1.0136, Train: 55.00%, Valid: 53.75% Test: 54.90%\n",
      "Run: 10, Epoch: 82, Loss: 1.0467, Train: 60.00%, Valid: 56.25% Test: 62.75%\n",
      "Run: 10, Epoch: 83, Loss: 1.0259, Train: 59.17%, Valid: 52.50% Test: 58.82%\n",
      "Run: 10, Epoch: 84, Loss: 1.0364, Train: 57.50%, Valid: 46.25% Test: 56.86%\n",
      "Run: 10, Epoch: 85, Loss: 1.0041, Train: 55.83%, Valid: 40.00% Test: 47.06%\n",
      "Run: 10, Epoch: 86, Loss: 1.0043, Train: 41.67%, Valid: 40.00% Test: 41.18%\n",
      "Run: 10, Epoch: 87, Loss: 1.1069, Train: 49.17%, Valid: 41.25% Test: 43.14%\n",
      "Run: 10, Epoch: 88, Loss: 1.0116, Train: 51.67%, Valid: 42.50% Test: 47.06%\n",
      "Run: 10, Epoch: 89, Loss: 0.9649, Train: 63.33%, Valid: 46.25% Test: 58.82%\n",
      "Run: 10, Epoch: 90, Loss: 1.0562, Train: 59.17%, Valid: 52.50% Test: 62.75%\n",
      "Run: 10, Epoch: 91, Loss: 1.0189, Train: 55.00%, Valid: 51.25% Test: 52.94%\n",
      "Run: 10, Epoch: 92, Loss: 0.9670, Train: 49.17%, Valid: 53.75% Test: 45.10%\n",
      "Run: 10, Epoch: 93, Loss: 0.9869, Train: 49.17%, Valid: 55.00% Test: 43.14%\n",
      "Run: 10, Epoch: 94, Loss: 0.9815, Train: 49.17%, Valid: 56.25% Test: 49.02%\n",
      "Run: 10, Epoch: 95, Loss: 0.9807, Train: 50.83%, Valid: 56.25% Test: 54.90%\n",
      "Run: 10, Epoch: 96, Loss: 0.9530, Train: 55.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 10, Epoch: 97, Loss: 1.0356, Train: 54.17%, Valid: 57.50% Test: 56.86%\n",
      "Run: 10, Epoch: 98, Loss: 1.0028, Train: 58.33%, Valid: 56.25% Test: 54.90%\n",
      "Run: 10, Epoch: 99, Loss: 1.0347, Train: 60.83%, Valid: 53.75% Test: 62.75%\n",
      "Run: 10, Epoch: 100, Loss: 0.9818, Train: 59.17%, Valid: 53.75% Test: 64.71%\n",
      "Run 10:\n",
      "Highest Train: 63.33\n",
      "Highest Valid: 57.50\n",
      "  Final Train: 55.00\n",
      "   Final Test: 60.78\n",
      "All runs:\n",
      "Highest Train: 60.08 Â± 4.83\n",
      "Highest Valid: 57.88 Â± 5.30\n",
      "  Final Train: 54.83 Â± 7.93\n",
      "   Final Test: 54.31 Â± 8.11\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 8, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = WebKB(root='/tmp/Texas', name='Texas',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    #idx_train=[data.train_mask[i][0] for i in range(len(data.y))]\n",
    "    #train_idx = np.where(idx_train)[0]\n",
    "    #idx_val=[data.val_mask[i][0] for i in range(len(data.y))]\n",
    "    #valid_idx = np.where(idx_val)[0]\n",
    "    #idx_test=[data.test_mask[i][0] for i in range(len(data.y))]\n",
    "    #test_idx = np.where(idx_test)[0]\n",
    "    \n",
    "    model = GAT(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout,args.heads)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085c7fd",
   "metadata": {},
   "source": [
    "# Topological Encodding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e47b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], edge_index=[2, 515], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin')\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52514bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Number_nodes=len(data.y)\n",
    "Edge_idx=data.edge_index.numpy()\n",
    "Node=range(Number_nodes)\n",
    "Edgelist=[]\n",
    "for i in range(len(Edge_idx[1])):\n",
    "    Edgelist.append((Edge_idx[0][i],Edge_idx[1][i]))\n",
    "#print(Edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9d236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a \"plain\" graph is undirected\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# give each a node a 'name', which is a letter in this case.\n",
    "#G.add_node('a')\n",
    "\n",
    "# the add_nodes_from method allows adding nodes from a sequence, in this case a list\n",
    "#nodes_to_add = ['b', 'c', 'd']\n",
    "G.add_nodes_from(Node)\n",
    "\n",
    "# add edge from 'a' to 'b'\n",
    "# since this graph is undirected, the order doesn't matter here\n",
    "#G.add_edge('a', 'b')\n",
    "\n",
    "# just like add_nodes_from, we can add edges from a sequence\n",
    "# edges should be specified as 2-tuples\n",
    "#edges_to_add = [('a', 'c'), ('b', 'c'), ('c', 'd')]\n",
    "G.add_edges_from(Edgelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "781abc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n"
     ]
    }
   ],
   "source": [
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77abd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topological_Feature_subLevel(adj,filtration_fun, Filtration):\n",
    "        betti_0=[]\n",
    "        betti_1=[]\n",
    "        for p in range(len(Filtration)):\n",
    "            n_active = np.where(np.array(filtration_fun) <= Filtration[p])[0].tolist()\n",
    "            Active_node=np.unique(n_active)\n",
    "            if (len(Active_node)==0):\n",
    "                betti_0.append(0)\n",
    "                betti_1.append(0)\n",
    "            else:\n",
    "                b=adj[Active_node,:][:,Active_node]\n",
    "                my_flag=pyflagser.flagser_unweighted(b, min_dimension=0, max_dimension=2, directed=False, coeff=2, approximation=None)\n",
    "                x = my_flag[\"betti\"]\n",
    "                betti_0.append(x[0])\n",
    "                betti_1.append(x[1])\n",
    "            n_active.clear()\n",
    "        return betti_0,betti_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e40cacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Degree_list(Graph):\n",
    "    degree_list = [Graph.degree(node) for node in Graph.nodes]\n",
    "    return np.array(degree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118b65fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  |  59 \n",
      "\n",
      "2  |  53 \n",
      "\n",
      "3  |  47 \n",
      "\n",
      "4  |  27 \n",
      "\n",
      "5  |  21 \n",
      "\n",
      "6  |  17 \n",
      "\n",
      "8  |  4 \n",
      "\n",
      "9  |  5 \n",
      "\n",
      "10  |  4 \n",
      "\n",
      "11  |  5 \n",
      "\n",
      "12  |  3 \n",
      "\n",
      "13  |  2 \n",
      "\n",
      "14  |  1 \n",
      "\n",
      "18  |  1 \n",
      "\n",
      "21  |  1 \n",
      "\n",
      "122  |  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "degree_list=Degree_list(G)\n",
    "unique_list=np.unique(degree_list)\n",
    "for d in unique_list:\n",
    "    count=0\n",
    "    for i in range(len(degree_list)):\n",
    "        if degree_list[i]==d:\n",
    "            count=count+1\n",
    "    print(int(d),\" | \",count,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7080881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 250 (100%)"
     ]
    }
   ],
   "source": [
    "import pyflagser\n",
    "Node_fil=[1,2,3,4,5,6,7,8,9,10,20,100]\n",
    "topo_betti_0=[]\n",
    "topo_betti_1=[]\n",
    "Node_Edge=[]\n",
    "for i in range(Number_nodes):\n",
    "    print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//(Number_nodes-1)), end='', flush=True)\n",
    "    subgraph=ego_graph(G, i, radius=2, center=True, undirected=True, distance=None)\n",
    "    filt=Degree_list(subgraph)\n",
    "    A_sub = nx.to_numpy_array(subgraph)# adjacency matrix of subgraph\n",
    "    fe=Topological_Feature_subLevel(A_sub,filt,Node_fil)\n",
    "    topo_betti_0.append(fe[0])\n",
    "    topo_betti_1.append(fe[1])\n",
    "    Node_Edge.append([subgraph.number_of_nodes(),subgraph.number_of_edges()])\n",
    "    #topo_with_NE.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49a08a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "445f9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_betti0=torch.tensor(topo_betti_0).float()\n",
    "topo_betti1=torch.tensor(topo_betti_1).float()\n",
    "NodeEdge=torch.tensor(Node_Edge).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88134dc7",
   "metadata": {},
   "source": [
    "# Topo-W-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbeea52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 10], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515], topo=[251, 24])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "topo_fe=torch.cat((topo_betti0,topo_betti1),1)\n",
    "data.topo=topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(topo_fe[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4668e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout,heads):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.heads=heads\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "        #return x.log_softmax(dim=-1)\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        #return torch.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "class MLP2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP2, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp2(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "    \n",
    "\n",
    "def train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2):\n",
    "    model.train()\n",
    "    mlp_model.train()\n",
    "    mlp_2.train()\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_mlp.zero_grad()\n",
    "    optimizer_mlp2.zero_grad()\n",
    "    gcn_embedding = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(gcn_embedding)\n",
    "    mlp_embedding = mlp_model(data.topo[train_idx])\n",
    "    #print(mlp_embedding)\n",
    "    combined_embedding = torch.cat((gcn_embedding, mlp_embedding), dim=1)\n",
    "    #print(combined_embedding)\n",
    "    mlp_emb = mlp_2(combined_embedding)\n",
    "    #print(mlp_emb)\n",
    "    loss = F.nll_loss(mlp_emb, data.y.squeeze()[train_idx])\n",
    "    #loss = F.nll_loss(combined_embedding, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer_mlp2.step()\n",
    "    optimizer.step()\n",
    "    optimizer_mlp.step()\n",
    "    \n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "    mlp_model.eval()\n",
    "    mlp_2.eval()\n",
    "\n",
    "    gcn_out = model(data.x, data.adj_t)\n",
    "    #print(gcn_out[0])\n",
    "    mlp_out=mlp_model(data.topo)\n",
    "    #print(mlp_out)\n",
    "    #out=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    Com=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    out=mlp_2(Com)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    #print(y_pred[0])\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef21f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x1478279a0>\n",
      "Run: 01, Epoch: 01, Loss: 1.6350, Train: 41.67%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 02, Loss: 1.4040, Train: 41.67%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 03, Loss: 1.4125, Train: 37.50%, Valid: 41.25% Test: 52.94%\n",
      "Run: 01, Epoch: 04, Loss: 1.3070, Train: 31.67%, Valid: 25.00% Test: 23.53%\n",
      "Run: 01, Epoch: 05, Loss: 1.3713, Train: 31.67%, Valid: 25.00% Test: 23.53%\n",
      "Run: 01, Epoch: 06, Loss: 1.3289, Train: 51.67%, Valid: 50.00% Test: 54.90%\n",
      "Run: 01, Epoch: 07, Loss: 1.3259, Train: 40.00%, Valid: 48.75% Test: 52.94%\n",
      "Run: 01, Epoch: 08, Loss: 1.2617, Train: 41.67%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 09, Loss: 1.2509, Train: 41.67%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 10, Loss: 1.3029, Train: 41.67%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 11, Loss: 1.2718, Train: 41.67%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 12, Loss: 1.2819, Train: 41.67%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 13, Loss: 1.2633, Train: 40.83%, Valid: 50.00% Test: 52.94%\n",
      "Run: 01, Epoch: 14, Loss: 1.2703, Train: 40.00%, Valid: 48.75% Test: 50.98%\n",
      "Run: 01, Epoch: 15, Loss: 1.2097, Train: 40.83%, Valid: 50.00% Test: 50.98%\n",
      "Run: 01, Epoch: 16, Loss: 1.2536, Train: 44.17%, Valid: 51.25% Test: 50.98%\n",
      "Run: 01, Epoch: 17, Loss: 1.2006, Train: 44.17%, Valid: 50.00% Test: 50.98%\n",
      "Run: 01, Epoch: 18, Loss: 1.1896, Train: 44.17%, Valid: 51.25% Test: 50.98%\n",
      "Run: 01, Epoch: 19, Loss: 1.2038, Train: 40.83%, Valid: 48.75% Test: 52.94%\n",
      "Run: 01, Epoch: 20, Loss: 1.2320, Train: 40.83%, Valid: 48.75% Test: 52.94%\n",
      "Run: 01, Epoch: 21, Loss: 1.2226, Train: 41.67%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 22, Loss: 1.1356, Train: 43.33%, Valid: 51.25% Test: 50.98%\n",
      "Run: 01, Epoch: 23, Loss: 1.2315, Train: 44.17%, Valid: 52.50% Test: 49.02%\n",
      "Run: 01, Epoch: 24, Loss: 1.2013, Train: 41.67%, Valid: 51.25% Test: 50.98%\n",
      "Run: 01, Epoch: 25, Loss: 1.1709, Train: 42.50%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 26, Loss: 1.1627, Train: 42.50%, Valid: 47.50% Test: 54.90%\n",
      "Run: 01, Epoch: 27, Loss: 1.1794, Train: 47.50%, Valid: 47.50% Test: 52.94%\n",
      "Run: 01, Epoch: 28, Loss: 1.1446, Train: 46.67%, Valid: 46.25% Test: 52.94%\n",
      "Run: 01, Epoch: 29, Loss: 1.1291, Train: 46.67%, Valid: 43.75% Test: 50.98%\n",
      "Run: 01, Epoch: 30, Loss: 1.1784, Train: 46.67%, Valid: 43.75% Test: 50.98%\n",
      "Run: 01, Epoch: 31, Loss: 1.1396, Train: 47.50%, Valid: 43.75% Test: 52.94%\n",
      "Run: 01, Epoch: 32, Loss: 1.1909, Train: 47.50%, Valid: 43.75% Test: 52.94%\n",
      "Run: 01, Epoch: 33, Loss: 1.1209, Train: 50.83%, Valid: 50.00% Test: 52.94%\n",
      "Run: 01, Epoch: 34, Loss: 1.0695, Train: 55.83%, Valid: 48.75% Test: 50.98%\n",
      "Run: 01, Epoch: 35, Loss: 1.0854, Train: 59.17%, Valid: 51.25% Test: 49.02%\n",
      "Run: 01, Epoch: 36, Loss: 1.0691, Train: 59.17%, Valid: 52.50% Test: 49.02%\n",
      "Run: 01, Epoch: 37, Loss: 1.1264, Train: 56.67%, Valid: 51.25% Test: 49.02%\n",
      "Run: 01, Epoch: 38, Loss: 1.0889, Train: 56.67%, Valid: 51.25% Test: 49.02%\n",
      "Run: 01, Epoch: 39, Loss: 1.1123, Train: 57.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 01, Epoch: 40, Loss: 1.0911, Train: 58.33%, Valid: 50.00% Test: 49.02%\n",
      "Run: 01, Epoch: 41, Loss: 1.0539, Train: 55.83%, Valid: 50.00% Test: 49.02%\n",
      "Run: 01, Epoch: 42, Loss: 1.0725, Train: 55.83%, Valid: 48.75% Test: 50.98%\n",
      "Run: 01, Epoch: 43, Loss: 1.0477, Train: 55.83%, Valid: 50.00% Test: 50.98%\n",
      "Run: 01, Epoch: 44, Loss: 1.0900, Train: 57.50%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 45, Loss: 1.0608, Train: 56.67%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 46, Loss: 1.0686, Train: 57.50%, Valid: 52.50% Test: 52.94%\n",
      "Run: 01, Epoch: 47, Loss: 1.1190, Train: 56.67%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 48, Loss: 1.0286, Train: 57.50%, Valid: 52.50% Test: 49.02%\n",
      "Run: 01, Epoch: 49, Loss: 1.0250, Train: 55.83%, Valid: 52.50% Test: 49.02%\n",
      "Run: 01, Epoch: 50, Loss: 1.0527, Train: 56.67%, Valid: 52.50% Test: 47.06%\n",
      "Run: 01, Epoch: 51, Loss: 1.0135, Train: 56.67%, Valid: 51.25% Test: 47.06%\n",
      "Run: 01, Epoch: 52, Loss: 1.0041, Train: 56.67%, Valid: 51.25% Test: 47.06%\n",
      "Run: 01, Epoch: 53, Loss: 1.0076, Train: 56.67%, Valid: 51.25% Test: 49.02%\n",
      "Run: 01, Epoch: 54, Loss: 1.0409, Train: 56.67%, Valid: 52.50% Test: 52.94%\n",
      "Run: 01, Epoch: 55, Loss: 0.9389, Train: 58.33%, Valid: 55.00% Test: 52.94%\n",
      "Run: 01, Epoch: 56, Loss: 0.9829, Train: 60.00%, Valid: 55.00% Test: 52.94%\n",
      "Run: 01, Epoch: 57, Loss: 1.0484, Train: 60.00%, Valid: 56.25% Test: 52.94%\n",
      "Run: 01, Epoch: 58, Loss: 1.0765, Train: 60.00%, Valid: 57.50% Test: 54.90%\n",
      "Run: 01, Epoch: 59, Loss: 0.9935, Train: 61.67%, Valid: 56.25% Test: 56.86%\n",
      "Run: 01, Epoch: 60, Loss: 1.0254, Train: 60.83%, Valid: 56.25% Test: 52.94%\n",
      "Run: 01, Epoch: 61, Loss: 0.9866, Train: 60.83%, Valid: 56.25% Test: 52.94%\n",
      "Run: 01, Epoch: 62, Loss: 1.0810, Train: 59.17%, Valid: 55.00% Test: 52.94%\n",
      "Run: 01, Epoch: 63, Loss: 0.9521, Train: 60.00%, Valid: 55.00% Test: 52.94%\n",
      "Run: 01, Epoch: 64, Loss: 1.1180, Train: 60.00%, Valid: 55.00% Test: 50.98%\n",
      "Run: 01, Epoch: 65, Loss: 0.9597, Train: 61.67%, Valid: 55.00% Test: 52.94%\n",
      "Run: 01, Epoch: 66, Loss: 0.9334, Train: 61.67%, Valid: 55.00% Test: 52.94%\n",
      "Run: 01, Epoch: 67, Loss: 1.0115, Train: 60.83%, Valid: 57.50% Test: 54.90%\n",
      "Run: 01, Epoch: 68, Loss: 0.9661, Train: 62.50%, Valid: 57.50% Test: 54.90%\n",
      "Run: 01, Epoch: 69, Loss: 0.9671, Train: 63.33%, Valid: 56.25% Test: 54.90%\n",
      "Run: 01, Epoch: 70, Loss: 0.9482, Train: 62.50%, Valid: 57.50% Test: 54.90%\n",
      "Run: 01, Epoch: 71, Loss: 0.9844, Train: 60.83%, Valid: 57.50% Test: 58.82%\n",
      "Run: 01, Epoch: 72, Loss: 1.0221, Train: 61.67%, Valid: 58.75% Test: 54.90%\n",
      "Run: 01, Epoch: 73, Loss: 1.0044, Train: 63.33%, Valid: 58.75% Test: 50.98%\n",
      "Run: 01, Epoch: 74, Loss: 0.9691, Train: 60.83%, Valid: 56.25% Test: 50.98%\n",
      "Run: 01, Epoch: 75, Loss: 1.0242, Train: 60.00%, Valid: 56.25% Test: 52.94%\n",
      "Run: 01, Epoch: 76, Loss: 0.9092, Train: 63.33%, Valid: 58.75% Test: 54.90%\n",
      "Run: 01, Epoch: 77, Loss: 0.9390, Train: 61.67%, Valid: 56.25% Test: 52.94%\n",
      "Run: 01, Epoch: 78, Loss: 0.9446, Train: 60.83%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 79, Loss: 1.0540, Train: 60.83%, Valid: 51.25% Test: 52.94%\n",
      "Run: 01, Epoch: 80, Loss: 0.9961, Train: 59.17%, Valid: 50.00% Test: 50.98%\n",
      "Run: 01, Epoch: 81, Loss: 0.9994, Train: 59.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 01, Epoch: 82, Loss: 0.9757, Train: 57.50%, Valid: 48.75% Test: 54.90%\n",
      "Run: 01, Epoch: 83, Loss: 0.9561, Train: 57.50%, Valid: 45.00% Test: 47.06%\n",
      "Run: 01, Epoch: 84, Loss: 0.9064, Train: 54.17%, Valid: 45.00% Test: 43.14%\n",
      "Run: 01, Epoch: 85, Loss: 0.9815, Train: 55.83%, Valid: 46.25% Test: 47.06%\n",
      "Run: 01, Epoch: 86, Loss: 1.0134, Train: 56.67%, Valid: 51.25% Test: 54.90%\n",
      "Run: 01, Epoch: 87, Loss: 0.9108, Train: 58.33%, Valid: 55.00% Test: 49.02%\n",
      "Run: 01, Epoch: 88, Loss: 0.9199, Train: 61.67%, Valid: 61.25% Test: 54.90%\n",
      "Run: 01, Epoch: 89, Loss: 0.9906, Train: 61.67%, Valid: 58.75% Test: 54.90%\n",
      "Run: 01, Epoch: 90, Loss: 0.9285, Train: 60.83%, Valid: 60.00% Test: 52.94%\n",
      "Run: 01, Epoch: 91, Loss: 0.9545, Train: 59.17%, Valid: 56.25% Test: 52.94%\n",
      "Run: 01, Epoch: 92, Loss: 0.9855, Train: 60.83%, Valid: 57.50% Test: 49.02%\n",
      "Run: 01, Epoch: 93, Loss: 0.9666, Train: 62.50%, Valid: 57.50% Test: 52.94%\n",
      "Run: 01, Epoch: 94, Loss: 0.9525, Train: 63.33%, Valid: 61.25% Test: 52.94%\n",
      "Run: 01, Epoch: 95, Loss: 0.9851, Train: 63.33%, Valid: 58.75% Test: 52.94%\n",
      "Run: 01, Epoch: 96, Loss: 0.9621, Train: 62.50%, Valid: 57.50% Test: 50.98%\n",
      "Run: 01, Epoch: 97, Loss: 0.8935, Train: 65.00%, Valid: 58.75% Test: 45.10%\n",
      "Run: 01, Epoch: 98, Loss: 0.9297, Train: 63.33%, Valid: 60.00% Test: 43.14%\n",
      "Run: 01, Epoch: 99, Loss: 0.9923, Train: 61.67%, Valid: 57.50% Test: 50.98%\n",
      "Run: 01, Epoch: 100, Loss: 0.9319, Train: 61.67%, Valid: 55.00% Test: 50.98%\n",
      "Run: 01, Epoch: 101, Loss: 0.9076, Train: 59.17%, Valid: 55.00% Test: 50.98%\n",
      "Run: 01, Epoch: 102, Loss: 0.9106, Train: 58.33%, Valid: 56.25% Test: 49.02%\n",
      "Run: 01, Epoch: 103, Loss: 0.8803, Train: 57.50%, Valid: 56.25% Test: 47.06%\n",
      "Run: 01, Epoch: 104, Loss: 0.9000, Train: 60.83%, Valid: 57.50% Test: 47.06%\n",
      "Run: 01, Epoch: 105, Loss: 0.9179, Train: 60.83%, Valid: 56.25% Test: 49.02%\n",
      "Run: 01, Epoch: 106, Loss: 0.9225, Train: 60.00%, Valid: 56.25% Test: 49.02%\n",
      "Run: 01, Epoch: 107, Loss: 0.8880, Train: 64.17%, Valid: 58.75% Test: 52.94%\n",
      "Run: 01, Epoch: 108, Loss: 0.8309, Train: 63.33%, Valid: 60.00% Test: 58.82%\n",
      "Run: 01, Epoch: 109, Loss: 0.9058, Train: 62.50%, Valid: 57.50% Test: 52.94%\n",
      "Run: 01, Epoch: 110, Loss: 0.9161, Train: 65.83%, Valid: 58.75% Test: 50.98%\n",
      "Run: 01, Epoch: 111, Loss: 0.8944, Train: 65.83%, Valid: 58.75% Test: 52.94%\n",
      "Run: 01, Epoch: 112, Loss: 0.8973, Train: 65.83%, Valid: 58.75% Test: 50.98%\n",
      "Run: 01, Epoch: 113, Loss: 0.9457, Train: 66.67%, Valid: 57.50% Test: 49.02%\n",
      "Run: 01, Epoch: 114, Loss: 0.9040, Train: 64.17%, Valid: 56.25% Test: 47.06%\n",
      "Run: 01, Epoch: 115, Loss: 0.8561, Train: 63.33%, Valid: 56.25% Test: 54.90%\n",
      "Run: 01, Epoch: 116, Loss: 0.8774, Train: 66.67%, Valid: 55.00% Test: 49.02%\n",
      "Run: 01, Epoch: 117, Loss: 0.9051, Train: 65.83%, Valid: 56.25% Test: 54.90%\n",
      "Run: 01, Epoch: 118, Loss: 0.8631, Train: 66.67%, Valid: 56.25% Test: 54.90%\n",
      "Run: 01, Epoch: 119, Loss: 0.8794, Train: 64.17%, Valid: 56.25% Test: 52.94%\n",
      "Run: 01, Epoch: 120, Loss: 0.9159, Train: 62.50%, Valid: 58.75% Test: 50.98%\n",
      "Run: 01, Epoch: 121, Loss: 0.8767, Train: 65.83%, Valid: 61.25% Test: 50.98%\n",
      "Run: 01, Epoch: 122, Loss: 0.8906, Train: 65.00%, Valid: 63.75% Test: 50.98%\n",
      "Run: 01, Epoch: 123, Loss: 0.9095, Train: 65.00%, Valid: 63.75% Test: 50.98%\n",
      "Run: 01, Epoch: 124, Loss: 0.9276, Train: 65.83%, Valid: 62.50% Test: 49.02%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 125, Loss: 0.9212, Train: 65.83%, Valid: 57.50% Test: 50.98%\n",
      "Run: 01, Epoch: 126, Loss: 0.8554, Train: 69.17%, Valid: 53.75% Test: 49.02%\n",
      "Run: 01, Epoch: 127, Loss: 0.8884, Train: 69.17%, Valid: 52.50% Test: 47.06%\n",
      "Run: 01, Epoch: 128, Loss: 0.8187, Train: 67.50%, Valid: 53.75% Test: 43.14%\n",
      "Run: 01, Epoch: 129, Loss: 0.8610, Train: 61.67%, Valid: 58.75% Test: 41.18%\n",
      "Run: 01, Epoch: 130, Loss: 0.8896, Train: 62.50%, Valid: 61.25% Test: 49.02%\n",
      "Run: 01, Epoch: 131, Loss: 0.8859, Train: 61.67%, Valid: 62.50% Test: 50.98%\n",
      "Run: 01, Epoch: 132, Loss: 0.8138, Train: 63.33%, Valid: 63.75% Test: 47.06%\n",
      "Run: 01, Epoch: 133, Loss: 0.8089, Train: 64.17%, Valid: 61.25% Test: 45.10%\n",
      "Run: 01, Epoch: 134, Loss: 0.8958, Train: 66.67%, Valid: 57.50% Test: 52.94%\n",
      "Run: 01, Epoch: 135, Loss: 0.8512, Train: 65.83%, Valid: 57.50% Test: 50.98%\n",
      "Run: 01, Epoch: 136, Loss: 0.8424, Train: 64.17%, Valid: 58.75% Test: 52.94%\n",
      "Run: 01, Epoch: 137, Loss: 0.8569, Train: 65.00%, Valid: 62.50% Test: 50.98%\n",
      "Run: 01, Epoch: 138, Loss: 0.8635, Train: 63.33%, Valid: 60.00% Test: 50.98%\n",
      "Run: 01, Epoch: 139, Loss: 0.8242, Train: 56.67%, Valid: 62.50% Test: 45.10%\n",
      "Run: 01, Epoch: 140, Loss: 0.8325, Train: 57.50%, Valid: 61.25% Test: 45.10%\n",
      "Run: 01, Epoch: 141, Loss: 0.8827, Train: 60.83%, Valid: 61.25% Test: 49.02%\n",
      "Run: 01, Epoch: 142, Loss: 0.8086, Train: 62.50%, Valid: 62.50% Test: 47.06%\n",
      "Run: 01, Epoch: 143, Loss: 0.8226, Train: 65.00%, Valid: 61.25% Test: 47.06%\n",
      "Run: 01, Epoch: 144, Loss: 0.8980, Train: 67.50%, Valid: 57.50% Test: 50.98%\n",
      "Run: 01, Epoch: 145, Loss: 0.8860, Train: 66.67%, Valid: 56.25% Test: 50.98%\n",
      "Run: 01, Epoch: 146, Loss: 0.8296, Train: 65.00%, Valid: 57.50% Test: 49.02%\n",
      "Run: 01, Epoch: 147, Loss: 0.8378, Train: 65.00%, Valid: 53.75% Test: 47.06%\n",
      "Run: 01, Epoch: 148, Loss: 0.8505, Train: 65.00%, Valid: 53.75% Test: 49.02%\n",
      "Run: 01, Epoch: 149, Loss: 0.8538, Train: 61.67%, Valid: 55.00% Test: 41.18%\n",
      "Run: 01, Epoch: 150, Loss: 0.8443, Train: 64.17%, Valid: 56.25% Test: 43.14%\n",
      "Run: 01, Epoch: 151, Loss: 0.7985, Train: 62.50%, Valid: 56.25% Test: 43.14%\n",
      "Run: 01, Epoch: 152, Loss: 0.7834, Train: 69.17%, Valid: 53.75% Test: 47.06%\n",
      "Run: 01, Epoch: 153, Loss: 0.8878, Train: 73.33%, Valid: 57.50% Test: 52.94%\n",
      "Run: 01, Epoch: 154, Loss: 0.7786, Train: 67.50%, Valid: 57.50% Test: 50.98%\n",
      "Run: 01, Epoch: 155, Loss: 0.7843, Train: 67.50%, Valid: 53.75% Test: 49.02%\n",
      "Run: 01, Epoch: 156, Loss: 0.7856, Train: 67.50%, Valid: 53.75% Test: 47.06%\n",
      "Run: 01, Epoch: 157, Loss: 0.9098, Train: 66.67%, Valid: 60.00% Test: 45.10%\n",
      "Run: 01, Epoch: 158, Loss: 0.7919, Train: 68.33%, Valid: 62.50% Test: 47.06%\n",
      "Run: 01, Epoch: 159, Loss: 0.8538, Train: 67.50%, Valid: 62.50% Test: 43.14%\n",
      "Run: 01, Epoch: 160, Loss: 0.8337, Train: 61.67%, Valid: 60.00% Test: 43.14%\n",
      "Run: 01, Epoch: 161, Loss: 0.9166, Train: 65.00%, Valid: 57.50% Test: 43.14%\n",
      "Run: 01, Epoch: 162, Loss: 0.8069, Train: 65.83%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 163, Loss: 0.8743, Train: 69.17%, Valid: 57.50% Test: 47.06%\n",
      "Run: 01, Epoch: 164, Loss: 0.8184, Train: 68.33%, Valid: 53.75% Test: 50.98%\n",
      "Run: 01, Epoch: 165, Loss: 0.7650, Train: 62.50%, Valid: 50.00% Test: 45.10%\n",
      "Run: 01, Epoch: 166, Loss: 0.7399, Train: 65.83%, Valid: 51.25% Test: 37.25%\n",
      "Run: 01, Epoch: 167, Loss: 0.8675, Train: 67.50%, Valid: 52.50% Test: 43.14%\n",
      "Run: 01, Epoch: 168, Loss: 0.7764, Train: 65.83%, Valid: 51.25% Test: 43.14%\n",
      "Run: 01, Epoch: 169, Loss: 0.7533, Train: 67.50%, Valid: 56.25% Test: 47.06%\n",
      "Run: 01, Epoch: 170, Loss: 0.8723, Train: 66.67%, Valid: 53.75% Test: 45.10%\n",
      "Run: 01, Epoch: 171, Loss: 0.8231, Train: 65.00%, Valid: 57.50% Test: 49.02%\n",
      "Run: 01, Epoch: 172, Loss: 0.8135, Train: 68.33%, Valid: 50.00% Test: 45.10%\n",
      "Run: 01, Epoch: 173, Loss: 0.7546, Train: 67.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 01, Epoch: 174, Loss: 0.8373, Train: 70.83%, Valid: 53.75% Test: 47.06%\n",
      "Run: 01, Epoch: 175, Loss: 0.7838, Train: 72.50%, Valid: 52.50% Test: 47.06%\n",
      "Run: 01, Epoch: 176, Loss: 0.8549, Train: 68.33%, Valid: 52.50% Test: 47.06%\n",
      "Run: 01, Epoch: 177, Loss: 0.7190, Train: 70.00%, Valid: 55.00% Test: 49.02%\n",
      "Run: 01, Epoch: 178, Loss: 0.7321, Train: 65.00%, Valid: 55.00% Test: 50.98%\n",
      "Run: 01, Epoch: 179, Loss: 0.8292, Train: 67.50%, Valid: 56.25% Test: 49.02%\n",
      "Run: 01, Epoch: 180, Loss: 0.7460, Train: 71.67%, Valid: 57.50% Test: 49.02%\n",
      "Run: 01, Epoch: 181, Loss: 0.7413, Train: 68.33%, Valid: 58.75% Test: 47.06%\n",
      "Run: 01, Epoch: 182, Loss: 0.7754, Train: 66.67%, Valid: 56.25% Test: 49.02%\n",
      "Run: 01, Epoch: 183, Loss: 0.7888, Train: 69.17%, Valid: 56.25% Test: 50.98%\n",
      "Run: 01, Epoch: 184, Loss: 0.8330, Train: 70.00%, Valid: 53.75% Test: 52.94%\n",
      "Run: 01, Epoch: 185, Loss: 0.7449, Train: 67.50%, Valid: 55.00% Test: 54.90%\n",
      "Run: 01, Epoch: 186, Loss: 0.8212, Train: 66.67%, Valid: 57.50% Test: 49.02%\n",
      "Run: 01, Epoch: 187, Loss: 0.7394, Train: 63.33%, Valid: 57.50% Test: 50.98%\n",
      "Run: 01, Epoch: 188, Loss: 0.9366, Train: 66.67%, Valid: 58.75% Test: 50.98%\n",
      "Run: 01, Epoch: 189, Loss: 0.7744, Train: 66.67%, Valid: 57.50% Test: 52.94%\n",
      "Run: 01, Epoch: 190, Loss: 0.7961, Train: 65.83%, Valid: 56.25% Test: 54.90%\n",
      "Run: 01, Epoch: 191, Loss: 0.6893, Train: 64.17%, Valid: 53.75% Test: 52.94%\n",
      "Run: 01, Epoch: 192, Loss: 0.8062, Train: 67.50%, Valid: 48.75% Test: 39.22%\n",
      "Run: 01, Epoch: 193, Loss: 0.7931, Train: 64.17%, Valid: 47.50% Test: 41.18%\n",
      "Run: 01, Epoch: 194, Loss: 0.7928, Train: 62.50%, Valid: 50.00% Test: 41.18%\n",
      "Run: 01, Epoch: 195, Loss: 0.7524, Train: 63.33%, Valid: 51.25% Test: 43.14%\n",
      "Run: 01, Epoch: 196, Loss: 0.7913, Train: 65.83%, Valid: 52.50% Test: 43.14%\n",
      "Run: 01, Epoch: 197, Loss: 0.7311, Train: 70.00%, Valid: 50.00% Test: 43.14%\n",
      "Run: 01, Epoch: 198, Loss: 0.7298, Train: 71.67%, Valid: 56.25% Test: 56.86%\n",
      "Run: 01, Epoch: 199, Loss: 0.7434, Train: 68.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 01, Epoch: 200, Loss: 0.7679, Train: 66.67%, Valid: 53.75% Test: 52.94%\n",
      "Run 01:\n",
      "Highest Train: 73.33\n",
      "Highest Valid: 63.75\n",
      "  Final Train: 65.00\n",
      "   Final Test: 50.98\n",
      "Run: 02, Epoch: 01, Loss: 1.6367, Train: 29.17%, Valid: 28.75% Test: 23.53%\n",
      "Run: 02, Epoch: 02, Loss: 1.2885, Train: 40.83%, Valid: 41.25% Test: 41.18%\n",
      "Run: 02, Epoch: 03, Loss: 1.2338, Train: 47.50%, Valid: 42.50% Test: 62.75%\n",
      "Run: 02, Epoch: 04, Loss: 1.2665, Train: 45.83%, Valid: 38.75% Test: 62.75%\n",
      "Run: 02, Epoch: 05, Loss: 1.1884, Train: 45.83%, Valid: 38.75% Test: 62.75%\n",
      "Run: 02, Epoch: 06, Loss: 1.2016, Train: 45.83%, Valid: 38.75% Test: 62.75%\n",
      "Run: 02, Epoch: 07, Loss: 1.1944, Train: 46.67%, Valid: 40.00% Test: 62.75%\n",
      "Run: 02, Epoch: 08, Loss: 1.1335, Train: 50.83%, Valid: 43.75% Test: 62.75%\n",
      "Run: 02, Epoch: 09, Loss: 1.0995, Train: 58.33%, Valid: 47.50% Test: 64.71%\n",
      "Run: 02, Epoch: 10, Loss: 1.0842, Train: 61.67%, Valid: 50.00% Test: 64.71%\n",
      "Run: 02, Epoch: 11, Loss: 1.0590, Train: 57.50%, Valid: 50.00% Test: 58.82%\n",
      "Run: 02, Epoch: 12, Loss: 1.0498, Train: 53.33%, Valid: 48.75% Test: 49.02%\n",
      "Run: 02, Epoch: 13, Loss: 1.0691, Train: 50.00%, Valid: 47.50% Test: 47.06%\n",
      "Run: 02, Epoch: 14, Loss: 1.0846, Train: 48.33%, Valid: 46.25% Test: 47.06%\n",
      "Run: 02, Epoch: 15, Loss: 1.0687, Train: 49.17%, Valid: 45.00% Test: 49.02%\n",
      "Run: 02, Epoch: 16, Loss: 1.0557, Train: 50.00%, Valid: 47.50% Test: 50.98%\n",
      "Run: 02, Epoch: 17, Loss: 1.0457, Train: 54.17%, Valid: 48.75% Test: 49.02%\n",
      "Run: 02, Epoch: 18, Loss: 1.0444, Train: 57.50%, Valid: 50.00% Test: 52.94%\n",
      "Run: 02, Epoch: 19, Loss: 1.0494, Train: 58.33%, Valid: 50.00% Test: 64.71%\n",
      "Run: 02, Epoch: 20, Loss: 0.9711, Train: 60.83%, Valid: 52.50% Test: 66.67%\n",
      "Run: 02, Epoch: 21, Loss: 1.0060, Train: 60.00%, Valid: 52.50% Test: 62.75%\n",
      "Run: 02, Epoch: 22, Loss: 0.9608, Train: 59.17%, Valid: 51.25% Test: 64.71%\n",
      "Run: 02, Epoch: 23, Loss: 1.0326, Train: 59.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 02, Epoch: 24, Loss: 1.0089, Train: 60.00%, Valid: 51.25% Test: 60.78%\n",
      "Run: 02, Epoch: 25, Loss: 1.0566, Train: 60.83%, Valid: 52.50% Test: 62.75%\n",
      "Run: 02, Epoch: 26, Loss: 1.0230, Train: 59.17%, Valid: 52.50% Test: 60.78%\n",
      "Run: 02, Epoch: 27, Loss: 0.9735, Train: 53.33%, Valid: 51.25% Test: 49.02%\n",
      "Run: 02, Epoch: 28, Loss: 1.0537, Train: 50.00%, Valid: 42.50% Test: 45.10%\n",
      "Run: 02, Epoch: 29, Loss: 0.9492, Train: 45.00%, Valid: 40.00% Test: 39.22%\n",
      "Run: 02, Epoch: 30, Loss: 1.0016, Train: 43.33%, Valid: 40.00% Test: 37.25%\n",
      "Run: 02, Epoch: 31, Loss: 1.0426, Train: 44.17%, Valid: 40.00% Test: 41.18%\n",
      "Run: 02, Epoch: 32, Loss: 0.9426, Train: 51.67%, Valid: 45.00% Test: 45.10%\n",
      "Run: 02, Epoch: 33, Loss: 0.9148, Train: 54.17%, Valid: 48.75% Test: 49.02%\n",
      "Run: 02, Epoch: 34, Loss: 1.0271, Train: 60.83%, Valid: 55.00% Test: 56.86%\n",
      "Run: 02, Epoch: 35, Loss: 0.9395, Train: 64.17%, Valid: 56.25% Test: 60.78%\n",
      "Run: 02, Epoch: 36, Loss: 0.9156, Train: 65.83%, Valid: 55.00% Test: 58.82%\n",
      "Run: 02, Epoch: 37, Loss: 0.8899, Train: 66.67%, Valid: 55.00% Test: 66.67%\n",
      "Run: 02, Epoch: 38, Loss: 0.8804, Train: 66.67%, Valid: 56.25% Test: 68.63%\n",
      "Run: 02, Epoch: 39, Loss: 0.8629, Train: 68.33%, Valid: 56.25% Test: 68.63%\n",
      "Run: 02, Epoch: 40, Loss: 0.9522, Train: 67.50%, Valid: 57.50% Test: 66.67%\n",
      "Run: 02, Epoch: 41, Loss: 0.9352, Train: 69.17%, Valid: 55.00% Test: 64.71%\n",
      "Run: 02, Epoch: 42, Loss: 0.9221, Train: 69.17%, Valid: 52.50% Test: 64.71%\n",
      "Run: 02, Epoch: 43, Loss: 0.8954, Train: 67.50%, Valid: 53.75% Test: 64.71%\n",
      "Run: 02, Epoch: 44, Loss: 0.8787, Train: 66.67%, Valid: 55.00% Test: 64.71%\n",
      "Run: 02, Epoch: 45, Loss: 0.8967, Train: 67.50%, Valid: 55.00% Test: 58.82%\n",
      "Run: 02, Epoch: 46, Loss: 0.9270, Train: 67.50%, Valid: 53.75% Test: 56.86%\n",
      "Run: 02, Epoch: 47, Loss: 0.9226, Train: 69.17%, Valid: 50.00% Test: 56.86%\n",
      "Run: 02, Epoch: 48, Loss: 0.8783, Train: 68.33%, Valid: 50.00% Test: 58.82%\n",
      "Run: 02, Epoch: 49, Loss: 0.8388, Train: 67.50%, Valid: 50.00% Test: 58.82%\n",
      "Run: 02, Epoch: 50, Loss: 0.8469, Train: 67.50%, Valid: 50.00% Test: 58.82%\n",
      "Run: 02, Epoch: 51, Loss: 0.8715, Train: 68.33%, Valid: 48.75% Test: 60.78%\n",
      "Run: 02, Epoch: 52, Loss: 0.9076, Train: 66.67%, Valid: 51.25% Test: 60.78%\n",
      "Run: 02, Epoch: 53, Loss: 0.9284, Train: 68.33%, Valid: 51.25% Test: 62.75%\n",
      "Run: 02, Epoch: 54, Loss: 0.8948, Train: 67.50%, Valid: 53.75% Test: 62.75%\n",
      "Run: 02, Epoch: 55, Loss: 0.8721, Train: 66.67%, Valid: 55.00% Test: 64.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 56, Loss: 0.7882, Train: 63.33%, Valid: 53.75% Test: 64.71%\n",
      "Run: 02, Epoch: 57, Loss: 0.9100, Train: 64.17%, Valid: 52.50% Test: 64.71%\n",
      "Run: 02, Epoch: 58, Loss: 0.8512, Train: 64.17%, Valid: 53.75% Test: 64.71%\n",
      "Run: 02, Epoch: 59, Loss: 0.9511, Train: 65.83%, Valid: 53.75% Test: 62.75%\n",
      "Run: 02, Epoch: 60, Loss: 0.8686, Train: 68.33%, Valid: 53.75% Test: 62.75%\n",
      "Run: 02, Epoch: 61, Loss: 0.8515, Train: 68.33%, Valid: 53.75% Test: 62.75%\n",
      "Run: 02, Epoch: 62, Loss: 0.8214, Train: 70.83%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 63, Loss: 0.8629, Train: 70.00%, Valid: 55.00% Test: 58.82%\n",
      "Run: 02, Epoch: 64, Loss: 0.9175, Train: 70.83%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 65, Loss: 0.8245, Train: 70.83%, Valid: 53.75% Test: 58.82%\n",
      "Run: 02, Epoch: 66, Loss: 0.8898, Train: 71.67%, Valid: 52.50% Test: 60.78%\n",
      "Run: 02, Epoch: 67, Loss: 0.8148, Train: 70.00%, Valid: 52.50% Test: 60.78%\n",
      "Run: 02, Epoch: 68, Loss: 0.8615, Train: 70.00%, Valid: 53.75% Test: 62.75%\n",
      "Run: 02, Epoch: 69, Loss: 0.8489, Train: 69.17%, Valid: 56.25% Test: 62.75%\n",
      "Run: 02, Epoch: 70, Loss: 0.8393, Train: 68.33%, Valid: 56.25% Test: 64.71%\n",
      "Run: 02, Epoch: 71, Loss: 0.8969, Train: 70.83%, Valid: 55.00% Test: 62.75%\n",
      "Run: 02, Epoch: 72, Loss: 0.8383, Train: 66.67%, Valid: 52.50% Test: 54.90%\n",
      "Run: 02, Epoch: 73, Loss: 0.7985, Train: 65.83%, Valid: 53.75% Test: 56.86%\n",
      "Run: 02, Epoch: 74, Loss: 0.9061, Train: 65.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 02, Epoch: 75, Loss: 0.8060, Train: 65.83%, Valid: 53.75% Test: 58.82%\n",
      "Run: 02, Epoch: 76, Loss: 0.7523, Train: 64.17%, Valid: 56.25% Test: 60.78%\n",
      "Run: 02, Epoch: 77, Loss: 0.7915, Train: 67.50%, Valid: 55.00% Test: 58.82%\n",
      "Run: 02, Epoch: 78, Loss: 0.7841, Train: 69.17%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 79, Loss: 0.8266, Train: 70.00%, Valid: 55.00% Test: 58.82%\n",
      "Run: 02, Epoch: 80, Loss: 0.8224, Train: 70.00%, Valid: 55.00% Test: 56.86%\n",
      "Run: 02, Epoch: 81, Loss: 0.8083, Train: 70.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 02, Epoch: 82, Loss: 0.7982, Train: 70.00%, Valid: 53.75% Test: 58.82%\n",
      "Run: 02, Epoch: 83, Loss: 0.7782, Train: 70.83%, Valid: 55.00% Test: 56.86%\n",
      "Run: 02, Epoch: 84, Loss: 0.8170, Train: 70.00%, Valid: 53.75% Test: 54.90%\n",
      "Run: 02, Epoch: 85, Loss: 0.8174, Train: 69.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 02, Epoch: 86, Loss: 0.7549, Train: 68.33%, Valid: 53.75% Test: 60.78%\n",
      "Run: 02, Epoch: 87, Loss: 0.7454, Train: 67.50%, Valid: 52.50% Test: 64.71%\n",
      "Run: 02, Epoch: 88, Loss: 0.8163, Train: 69.17%, Valid: 56.25% Test: 56.86%\n",
      "Run: 02, Epoch: 89, Loss: 0.8321, Train: 66.67%, Valid: 56.25% Test: 56.86%\n",
      "Run: 02, Epoch: 90, Loss: 0.8009, Train: 68.33%, Valid: 57.50% Test: 58.82%\n",
      "Run: 02, Epoch: 91, Loss: 0.7942, Train: 69.17%, Valid: 57.50% Test: 60.78%\n",
      "Run: 02, Epoch: 92, Loss: 0.7456, Train: 70.83%, Valid: 55.00% Test: 58.82%\n",
      "Run: 02, Epoch: 93, Loss: 0.8055, Train: 72.50%, Valid: 55.00% Test: 62.75%\n",
      "Run: 02, Epoch: 94, Loss: 0.8133, Train: 73.33%, Valid: 53.75% Test: 64.71%\n",
      "Run: 02, Epoch: 95, Loss: 0.8475, Train: 73.33%, Valid: 52.50% Test: 60.78%\n",
      "Run: 02, Epoch: 96, Loss: 0.7496, Train: 75.83%, Valid: 52.50% Test: 62.75%\n",
      "Run: 02, Epoch: 97, Loss: 0.8327, Train: 74.17%, Valid: 48.75% Test: 62.75%\n",
      "Run: 02, Epoch: 98, Loss: 0.7996, Train: 72.50%, Valid: 48.75% Test: 64.71%\n",
      "Run: 02, Epoch: 99, Loss: 0.7724, Train: 72.50%, Valid: 48.75% Test: 62.75%\n",
      "Run: 02, Epoch: 100, Loss: 0.7405, Train: 68.33%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 101, Loss: 0.8528, Train: 68.33%, Valid: 56.25% Test: 64.71%\n",
      "Run: 02, Epoch: 102, Loss: 0.7569, Train: 69.17%, Valid: 53.75% Test: 62.75%\n",
      "Run: 02, Epoch: 103, Loss: 0.8222, Train: 68.33%, Valid: 55.00% Test: 64.71%\n",
      "Run: 02, Epoch: 104, Loss: 0.8176, Train: 62.50%, Valid: 51.25% Test: 54.90%\n",
      "Run: 02, Epoch: 105, Loss: 0.7630, Train: 61.67%, Valid: 51.25% Test: 54.90%\n",
      "Run: 02, Epoch: 106, Loss: 0.7954, Train: 66.67%, Valid: 50.00% Test: 60.78%\n",
      "Run: 02, Epoch: 107, Loss: 0.7585, Train: 67.50%, Valid: 56.25% Test: 64.71%\n",
      "Run: 02, Epoch: 108, Loss: 0.7956, Train: 67.50%, Valid: 55.00% Test: 64.71%\n",
      "Run: 02, Epoch: 109, Loss: 0.7799, Train: 69.17%, Valid: 55.00% Test: 62.75%\n",
      "Run: 02, Epoch: 110, Loss: 0.7812, Train: 72.50%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 111, Loss: 0.8313, Train: 71.67%, Valid: 56.25% Test: 60.78%\n",
      "Run: 02, Epoch: 112, Loss: 0.8152, Train: 71.67%, Valid: 57.50% Test: 62.75%\n",
      "Run: 02, Epoch: 113, Loss: 0.7893, Train: 69.17%, Valid: 57.50% Test: 62.75%\n",
      "Run: 02, Epoch: 114, Loss: 0.7155, Train: 69.17%, Valid: 57.50% Test: 62.75%\n",
      "Run: 02, Epoch: 115, Loss: 0.7575, Train: 66.67%, Valid: 57.50% Test: 60.78%\n",
      "Run: 02, Epoch: 116, Loss: 0.8256, Train: 65.00%, Valid: 57.50% Test: 62.75%\n",
      "Run: 02, Epoch: 117, Loss: 0.7732, Train: 64.17%, Valid: 57.50% Test: 62.75%\n",
      "Run: 02, Epoch: 118, Loss: 0.8666, Train: 64.17%, Valid: 56.25% Test: 62.75%\n",
      "Run: 02, Epoch: 119, Loss: 0.7200, Train: 69.17%, Valid: 58.75% Test: 58.82%\n",
      "Run: 02, Epoch: 120, Loss: 0.7651, Train: 70.83%, Valid: 60.00% Test: 58.82%\n",
      "Run: 02, Epoch: 121, Loss: 0.7263, Train: 70.00%, Valid: 56.25% Test: 60.78%\n",
      "Run: 02, Epoch: 122, Loss: 0.7367, Train: 70.00%, Valid: 55.00% Test: 58.82%\n",
      "Run: 02, Epoch: 123, Loss: 0.7203, Train: 71.67%, Valid: 53.75% Test: 62.75%\n",
      "Run: 02, Epoch: 124, Loss: 0.6974, Train: 70.00%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 125, Loss: 0.7625, Train: 68.33%, Valid: 55.00% Test: 64.71%\n",
      "Run: 02, Epoch: 126, Loss: 0.7513, Train: 67.50%, Valid: 56.25% Test: 66.67%\n",
      "Run: 02, Epoch: 127, Loss: 0.7982, Train: 68.33%, Valid: 57.50% Test: 66.67%\n",
      "Run: 02, Epoch: 128, Loss: 0.7780, Train: 70.00%, Valid: 58.75% Test: 64.71%\n",
      "Run: 02, Epoch: 129, Loss: 0.7586, Train: 75.00%, Valid: 56.25% Test: 66.67%\n",
      "Run: 02, Epoch: 130, Loss: 0.7091, Train: 72.50%, Valid: 52.50% Test: 62.75%\n",
      "Run: 02, Epoch: 131, Loss: 0.7058, Train: 73.33%, Valid: 52.50% Test: 58.82%\n",
      "Run: 02, Epoch: 132, Loss: 0.6780, Train: 71.67%, Valid: 53.75% Test: 60.78%\n",
      "Run: 02, Epoch: 133, Loss: 0.7789, Train: 72.50%, Valid: 53.75% Test: 56.86%\n",
      "Run: 02, Epoch: 134, Loss: 0.8166, Train: 70.83%, Valid: 53.75% Test: 58.82%\n",
      "Run: 02, Epoch: 135, Loss: 0.7512, Train: 70.00%, Valid: 52.50% Test: 58.82%\n",
      "Run: 02, Epoch: 136, Loss: 0.7079, Train: 68.33%, Valid: 52.50% Test: 60.78%\n",
      "Run: 02, Epoch: 137, Loss: 0.7895, Train: 69.17%, Valid: 56.25% Test: 64.71%\n",
      "Run: 02, Epoch: 138, Loss: 0.7904, Train: 70.83%, Valid: 57.50% Test: 62.75%\n",
      "Run: 02, Epoch: 139, Loss: 0.7529, Train: 72.50%, Valid: 55.00% Test: 62.75%\n",
      "Run: 02, Epoch: 140, Loss: 0.7789, Train: 70.00%, Valid: 53.75% Test: 62.75%\n",
      "Run: 02, Epoch: 141, Loss: 0.6800, Train: 68.33%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 142, Loss: 0.7676, Train: 69.17%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 143, Loss: 0.6998, Train: 70.00%, Valid: 53.75% Test: 58.82%\n",
      "Run: 02, Epoch: 144, Loss: 0.7542, Train: 73.33%, Valid: 55.00% Test: 58.82%\n",
      "Run: 02, Epoch: 145, Loss: 0.8486, Train: 73.33%, Valid: 55.00% Test: 68.63%\n",
      "Run: 02, Epoch: 146, Loss: 0.7452, Train: 72.50%, Valid: 56.25% Test: 64.71%\n",
      "Run: 02, Epoch: 147, Loss: 0.7632, Train: 75.00%, Valid: 53.75% Test: 64.71%\n",
      "Run: 02, Epoch: 148, Loss: 0.7271, Train: 70.83%, Valid: 53.75% Test: 66.67%\n",
      "Run: 02, Epoch: 149, Loss: 0.7810, Train: 66.67%, Valid: 55.00% Test: 68.63%\n",
      "Run: 02, Epoch: 150, Loss: 0.8223, Train: 73.33%, Valid: 50.00% Test: 62.75%\n",
      "Run: 02, Epoch: 151, Loss: 0.7484, Train: 71.67%, Valid: 53.75% Test: 49.02%\n",
      "Run: 02, Epoch: 152, Loss: 0.7434, Train: 65.00%, Valid: 53.75% Test: 47.06%\n",
      "Run: 02, Epoch: 153, Loss: 0.7886, Train: 68.33%, Valid: 51.25% Test: 47.06%\n",
      "Run: 02, Epoch: 154, Loss: 0.6946, Train: 72.50%, Valid: 51.25% Test: 52.94%\n",
      "Run: 02, Epoch: 155, Loss: 0.7170, Train: 74.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 02, Epoch: 156, Loss: 0.8042, Train: 73.33%, Valid: 50.00% Test: 56.86%\n",
      "Run: 02, Epoch: 157, Loss: 0.7824, Train: 71.67%, Valid: 55.00% Test: 56.86%\n",
      "Run: 02, Epoch: 158, Loss: 0.7312, Train: 69.17%, Valid: 57.50% Test: 56.86%\n",
      "Run: 02, Epoch: 159, Loss: 0.6636, Train: 70.00%, Valid: 57.50% Test: 58.82%\n",
      "Run: 02, Epoch: 160, Loss: 0.7118, Train: 71.67%, Valid: 57.50% Test: 60.78%\n",
      "Run: 02, Epoch: 161, Loss: 0.7450, Train: 72.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 02, Epoch: 162, Loss: 0.7210, Train: 72.50%, Valid: 56.25% Test: 64.71%\n",
      "Run: 02, Epoch: 163, Loss: 0.7237, Train: 69.17%, Valid: 58.75% Test: 64.71%\n",
      "Run: 02, Epoch: 164, Loss: 0.7963, Train: 67.50%, Valid: 60.00% Test: 66.67%\n",
      "Run: 02, Epoch: 165, Loss: 0.7195, Train: 67.50%, Valid: 61.25% Test: 68.63%\n",
      "Run: 02, Epoch: 166, Loss: 0.7629, Train: 67.50%, Valid: 60.00% Test: 66.67%\n",
      "Run: 02, Epoch: 167, Loss: 0.7190, Train: 67.50%, Valid: 57.50% Test: 64.71%\n",
      "Run: 02, Epoch: 168, Loss: 0.7418, Train: 66.67%, Valid: 55.00% Test: 66.67%\n",
      "Run: 02, Epoch: 169, Loss: 0.7530, Train: 69.17%, Valid: 52.50% Test: 66.67%\n",
      "Run: 02, Epoch: 170, Loss: 0.7561, Train: 70.83%, Valid: 55.00% Test: 66.67%\n",
      "Run: 02, Epoch: 171, Loss: 0.7379, Train: 72.50%, Valid: 55.00% Test: 66.67%\n",
      "Run: 02, Epoch: 172, Loss: 0.7586, Train: 71.67%, Valid: 55.00% Test: 62.75%\n",
      "Run: 02, Epoch: 173, Loss: 0.6607, Train: 65.83%, Valid: 52.50% Test: 54.90%\n",
      "Run: 02, Epoch: 174, Loss: 0.7306, Train: 67.50%, Valid: 52.50% Test: 49.02%\n",
      "Run: 02, Epoch: 175, Loss: 0.7599, Train: 67.50%, Valid: 56.25% Test: 56.86%\n",
      "Run: 02, Epoch: 176, Loss: 0.7536, Train: 68.33%, Valid: 53.75% Test: 56.86%\n",
      "Run: 02, Epoch: 177, Loss: 0.7607, Train: 72.50%, Valid: 55.00% Test: 64.71%\n",
      "Run: 02, Epoch: 178, Loss: 0.6239, Train: 74.17%, Valid: 58.75% Test: 66.67%\n",
      "Run: 02, Epoch: 179, Loss: 0.6877, Train: 73.33%, Valid: 52.50% Test: 60.78%\n",
      "Run: 02, Epoch: 180, Loss: 0.6964, Train: 70.00%, Valid: 56.25% Test: 62.75%\n",
      "Run: 02, Epoch: 181, Loss: 0.6506, Train: 70.83%, Valid: 56.25% Test: 64.71%\n",
      "Run: 02, Epoch: 182, Loss: 0.6862, Train: 69.17%, Valid: 56.25% Test: 64.71%\n",
      "Run: 02, Epoch: 183, Loss: 0.8078, Train: 71.67%, Valid: 56.25% Test: 64.71%\n",
      "Run: 02, Epoch: 184, Loss: 0.7780, Train: 72.50%, Valid: 55.00% Test: 64.71%\n",
      "Run: 02, Epoch: 185, Loss: 0.8122, Train: 70.83%, Valid: 55.00% Test: 62.75%\n",
      "Run: 02, Epoch: 186, Loss: 0.7971, Train: 68.33%, Valid: 56.25% Test: 62.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 187, Loss: 0.7024, Train: 69.17%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 188, Loss: 0.6377, Train: 69.17%, Valid: 58.75% Test: 60.78%\n",
      "Run: 02, Epoch: 189, Loss: 0.7777, Train: 68.33%, Valid: 56.25% Test: 60.78%\n",
      "Run: 02, Epoch: 190, Loss: 0.7806, Train: 70.00%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 191, Loss: 0.7020, Train: 68.33%, Valid: 56.25% Test: 58.82%\n",
      "Run: 02, Epoch: 192, Loss: 0.6882, Train: 69.17%, Valid: 57.50% Test: 58.82%\n",
      "Run: 02, Epoch: 193, Loss: 0.7261, Train: 69.17%, Valid: 55.00% Test: 60.78%\n",
      "Run: 02, Epoch: 194, Loss: 0.6904, Train: 65.00%, Valid: 55.00% Test: 58.82%\n",
      "Run: 02, Epoch: 195, Loss: 0.7302, Train: 66.67%, Valid: 50.00% Test: 64.71%\n",
      "Run: 02, Epoch: 196, Loss: 0.7396, Train: 70.00%, Valid: 51.25% Test: 64.71%\n",
      "Run: 02, Epoch: 197, Loss: 0.6911, Train: 70.83%, Valid: 55.00% Test: 62.75%\n",
      "Run: 02, Epoch: 198, Loss: 0.6930, Train: 71.67%, Valid: 55.00% Test: 62.75%\n",
      "Run: 02, Epoch: 199, Loss: 0.7282, Train: 70.83%, Valid: 55.00% Test: 62.75%\n",
      "Run: 02, Epoch: 200, Loss: 0.7570, Train: 69.17%, Valid: 57.50% Test: 62.75%\n",
      "Run 02:\n",
      "Highest Train: 75.83\n",
      "Highest Valid: 61.25\n",
      "  Final Train: 67.50\n",
      "   Final Test: 68.63\n",
      "Run: 03, Epoch: 01, Loss: 1.9234, Train: 48.33%, Valid: 48.75% Test: 41.18%\n",
      "Run: 03, Epoch: 02, Loss: 1.3931, Train: 48.33%, Valid: 48.75% Test: 41.18%\n",
      "Run: 03, Epoch: 03, Loss: 1.2565, Train: 50.83%, Valid: 51.25% Test: 39.22%\n",
      "Run: 03, Epoch: 04, Loss: 1.1927, Train: 55.83%, Valid: 52.50% Test: 49.02%\n",
      "Run: 03, Epoch: 05, Loss: 1.1806, Train: 52.50%, Valid: 51.25% Test: 45.10%\n",
      "Run: 03, Epoch: 06, Loss: 1.2591, Train: 50.83%, Valid: 51.25% Test: 41.18%\n",
      "Run: 03, Epoch: 07, Loss: 1.2069, Train: 50.00%, Valid: 51.25% Test: 43.14%\n",
      "Run: 03, Epoch: 08, Loss: 1.2200, Train: 49.17%, Valid: 51.25% Test: 43.14%\n",
      "Run: 03, Epoch: 09, Loss: 1.2158, Train: 48.33%, Valid: 51.25% Test: 43.14%\n",
      "Run: 03, Epoch: 10, Loss: 1.1432, Train: 50.00%, Valid: 51.25% Test: 43.14%\n",
      "Run: 03, Epoch: 11, Loss: 1.1033, Train: 50.00%, Valid: 51.25% Test: 47.06%\n",
      "Run: 03, Epoch: 12, Loss: 1.0254, Train: 50.00%, Valid: 48.75% Test: 45.10%\n",
      "Run: 03, Epoch: 13, Loss: 1.0599, Train: 52.50%, Valid: 46.25% Test: 45.10%\n",
      "Run: 03, Epoch: 14, Loss: 1.1247, Train: 50.83%, Valid: 45.00% Test: 50.98%\n",
      "Run: 03, Epoch: 15, Loss: 1.0163, Train: 58.33%, Valid: 45.00% Test: 49.02%\n",
      "Run: 03, Epoch: 16, Loss: 1.1123, Train: 58.33%, Valid: 46.25% Test: 49.02%\n",
      "Run: 03, Epoch: 17, Loss: 0.9996, Train: 58.33%, Valid: 46.25% Test: 50.98%\n",
      "Run: 03, Epoch: 18, Loss: 1.0050, Train: 57.50%, Valid: 45.00% Test: 50.98%\n",
      "Run: 03, Epoch: 19, Loss: 1.0233, Train: 60.00%, Valid: 45.00% Test: 49.02%\n",
      "Run: 03, Epoch: 20, Loss: 0.9771, Train: 60.83%, Valid: 46.25% Test: 50.98%\n",
      "Run: 03, Epoch: 21, Loss: 0.9260, Train: 62.50%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 22, Loss: 0.9366, Train: 65.83%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 23, Loss: 0.9670, Train: 68.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 03, Epoch: 24, Loss: 0.9315, Train: 66.67%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 25, Loss: 0.9432, Train: 65.83%, Valid: 52.50% Test: 56.86%\n",
      "Run: 03, Epoch: 26, Loss: 0.9281, Train: 64.17%, Valid: 51.25% Test: 58.82%\n",
      "Run: 03, Epoch: 27, Loss: 0.8935, Train: 65.83%, Valid: 51.25% Test: 58.82%\n",
      "Run: 03, Epoch: 28, Loss: 0.9656, Train: 65.00%, Valid: 50.00% Test: 58.82%\n",
      "Run: 03, Epoch: 29, Loss: 0.9156, Train: 67.50%, Valid: 52.50% Test: 58.82%\n",
      "Run: 03, Epoch: 30, Loss: 0.9247, Train: 68.33%, Valid: 52.50% Test: 56.86%\n",
      "Run: 03, Epoch: 31, Loss: 0.9135, Train: 69.17%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 32, Loss: 0.9046, Train: 70.00%, Valid: 52.50% Test: 56.86%\n",
      "Run: 03, Epoch: 33, Loss: 0.9456, Train: 69.17%, Valid: 52.50% Test: 54.90%\n",
      "Run: 03, Epoch: 34, Loss: 0.8908, Train: 70.00%, Valid: 52.50% Test: 50.98%\n",
      "Run: 03, Epoch: 35, Loss: 0.8665, Train: 70.00%, Valid: 52.50% Test: 50.98%\n",
      "Run: 03, Epoch: 36, Loss: 0.9370, Train: 68.33%, Valid: 51.25% Test: 49.02%\n",
      "Run: 03, Epoch: 37, Loss: 0.8863, Train: 68.33%, Valid: 50.00% Test: 49.02%\n",
      "Run: 03, Epoch: 38, Loss: 0.8441, Train: 67.50%, Valid: 50.00% Test: 47.06%\n",
      "Run: 03, Epoch: 39, Loss: 0.8251, Train: 67.50%, Valid: 51.25% Test: 47.06%\n",
      "Run: 03, Epoch: 40, Loss: 0.8614, Train: 67.50%, Valid: 52.50% Test: 47.06%\n",
      "Run: 03, Epoch: 41, Loss: 0.8061, Train: 68.33%, Valid: 52.50% Test: 47.06%\n",
      "Run: 03, Epoch: 42, Loss: 0.8625, Train: 67.50%, Valid: 52.50% Test: 47.06%\n",
      "Run: 03, Epoch: 43, Loss: 0.8469, Train: 65.83%, Valid: 52.50% Test: 49.02%\n",
      "Run: 03, Epoch: 44, Loss: 0.8763, Train: 67.50%, Valid: 52.50% Test: 49.02%\n",
      "Run: 03, Epoch: 45, Loss: 0.8093, Train: 69.17%, Valid: 53.75% Test: 52.94%\n",
      "Run: 03, Epoch: 46, Loss: 0.8923, Train: 70.83%, Valid: 50.00% Test: 50.98%\n",
      "Run: 03, Epoch: 47, Loss: 0.7795, Train: 70.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 48, Loss: 0.8085, Train: 74.17%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 49, Loss: 0.8676, Train: 72.50%, Valid: 48.75% Test: 54.90%\n",
      "Run: 03, Epoch: 50, Loss: 0.7931, Train: 72.50%, Valid: 48.75% Test: 54.90%\n",
      "Run: 03, Epoch: 51, Loss: 0.9089, Train: 74.17%, Valid: 53.75% Test: 54.90%\n",
      "Run: 03, Epoch: 52, Loss: 0.8741, Train: 71.67%, Valid: 52.50% Test: 54.90%\n",
      "Run: 03, Epoch: 53, Loss: 0.8174, Train: 73.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 03, Epoch: 54, Loss: 0.8274, Train: 73.33%, Valid: 52.50% Test: 52.94%\n",
      "Run: 03, Epoch: 55, Loss: 0.7778, Train: 71.67%, Valid: 52.50% Test: 52.94%\n",
      "Run: 03, Epoch: 56, Loss: 0.7503, Train: 71.67%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 57, Loss: 0.7573, Train: 70.83%, Valid: 52.50% Test: 54.90%\n",
      "Run: 03, Epoch: 58, Loss: 0.8545, Train: 70.00%, Valid: 52.50% Test: 52.94%\n",
      "Run: 03, Epoch: 59, Loss: 0.7977, Train: 67.50%, Valid: 52.50% Test: 54.90%\n",
      "Run: 03, Epoch: 60, Loss: 0.7713, Train: 70.00%, Valid: 52.50% Test: 56.86%\n",
      "Run: 03, Epoch: 61, Loss: 0.7030, Train: 71.67%, Valid: 52.50% Test: 54.90%\n",
      "Run: 03, Epoch: 62, Loss: 0.7753, Train: 71.67%, Valid: 61.25% Test: 54.90%\n",
      "Run: 03, Epoch: 63, Loss: 0.8294, Train: 70.00%, Valid: 56.25% Test: 54.90%\n",
      "Run: 03, Epoch: 64, Loss: 0.8174, Train: 71.67%, Valid: 57.50% Test: 54.90%\n",
      "Run: 03, Epoch: 65, Loss: 0.7904, Train: 74.17%, Valid: 55.00% Test: 56.86%\n",
      "Run: 03, Epoch: 66, Loss: 0.8938, Train: 74.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 67, Loss: 0.7910, Train: 72.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 03, Epoch: 68, Loss: 0.7353, Train: 66.67%, Valid: 46.25% Test: 49.02%\n",
      "Run: 03, Epoch: 69, Loss: 0.8218, Train: 67.50%, Valid: 47.50% Test: 49.02%\n",
      "Run: 03, Epoch: 70, Loss: 0.7838, Train: 74.17%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 71, Loss: 0.7865, Train: 73.33%, Valid: 50.00% Test: 52.94%\n",
      "Run: 03, Epoch: 72, Loss: 0.8631, Train: 72.50%, Valid: 52.50% Test: 54.90%\n",
      "Run: 03, Epoch: 73, Loss: 0.7415, Train: 74.17%, Valid: 55.00% Test: 56.86%\n",
      "Run: 03, Epoch: 74, Loss: 0.8148, Train: 72.50%, Valid: 55.00% Test: 56.86%\n",
      "Run: 03, Epoch: 75, Loss: 0.7557, Train: 73.33%, Valid: 60.00% Test: 56.86%\n",
      "Run: 03, Epoch: 76, Loss: 0.7154, Train: 73.33%, Valid: 57.50% Test: 56.86%\n",
      "Run: 03, Epoch: 77, Loss: 0.6945, Train: 75.83%, Valid: 60.00% Test: 56.86%\n",
      "Run: 03, Epoch: 78, Loss: 0.7235, Train: 75.00%, Valid: 57.50% Test: 56.86%\n",
      "Run: 03, Epoch: 79, Loss: 0.6580, Train: 76.67%, Valid: 55.00% Test: 56.86%\n",
      "Run: 03, Epoch: 80, Loss: 0.7231, Train: 74.17%, Valid: 56.25% Test: 54.90%\n",
      "Run: 03, Epoch: 81, Loss: 0.7719, Train: 73.33%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 82, Loss: 0.7240, Train: 73.33%, Valid: 50.00% Test: 60.78%\n",
      "Run: 03, Epoch: 83, Loss: 0.7106, Train: 75.00%, Valid: 50.00% Test: 62.75%\n",
      "Run: 03, Epoch: 84, Loss: 0.7636, Train: 74.17%, Valid: 52.50% Test: 58.82%\n",
      "Run: 03, Epoch: 85, Loss: 0.7511, Train: 73.33%, Valid: 53.75% Test: 60.78%\n",
      "Run: 03, Epoch: 86, Loss: 0.7823, Train: 74.17%, Valid: 55.00% Test: 58.82%\n",
      "Run: 03, Epoch: 87, Loss: 0.7363, Train: 72.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 03, Epoch: 88, Loss: 0.6737, Train: 75.00%, Valid: 56.25% Test: 58.82%\n",
      "Run: 03, Epoch: 89, Loss: 0.7989, Train: 73.33%, Valid: 57.50% Test: 56.86%\n",
      "Run: 03, Epoch: 90, Loss: 0.7668, Train: 74.17%, Valid: 55.00% Test: 56.86%\n",
      "Run: 03, Epoch: 91, Loss: 0.7365, Train: 72.50%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 92, Loss: 0.8542, Train: 72.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 03, Epoch: 93, Loss: 0.6576, Train: 74.17%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 94, Loss: 0.7203, Train: 75.00%, Valid: 55.00% Test: 58.82%\n",
      "Run: 03, Epoch: 95, Loss: 0.7135, Train: 74.17%, Valid: 56.25% Test: 58.82%\n",
      "Run: 03, Epoch: 96, Loss: 0.7322, Train: 75.00%, Valid: 52.50% Test: 58.82%\n",
      "Run: 03, Epoch: 97, Loss: 0.7350, Train: 74.17%, Valid: 55.00% Test: 58.82%\n",
      "Run: 03, Epoch: 98, Loss: 0.7635, Train: 75.83%, Valid: 53.75% Test: 60.78%\n",
      "Run: 03, Epoch: 99, Loss: 0.7145, Train: 77.50%, Valid: 52.50% Test: 58.82%\n",
      "Run: 03, Epoch: 100, Loss: 0.6788, Train: 75.83%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 101, Loss: 0.7177, Train: 77.50%, Valid: 52.50% Test: 56.86%\n",
      "Run: 03, Epoch: 102, Loss: 0.7081, Train: 75.83%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 103, Loss: 0.7214, Train: 74.17%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 104, Loss: 0.7506, Train: 72.50%, Valid: 52.50% Test: 60.78%\n",
      "Run: 03, Epoch: 105, Loss: 0.6310, Train: 73.33%, Valid: 56.25% Test: 60.78%\n",
      "Run: 03, Epoch: 106, Loss: 0.8142, Train: 76.67%, Valid: 50.00% Test: 60.78%\n",
      "Run: 03, Epoch: 107, Loss: 0.6634, Train: 75.83%, Valid: 52.50% Test: 60.78%\n",
      "Run: 03, Epoch: 108, Loss: 0.7417, Train: 70.83%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 109, Loss: 0.6817, Train: 70.83%, Valid: 45.00% Test: 54.90%\n",
      "Run: 03, Epoch: 110, Loss: 0.7465, Train: 70.83%, Valid: 47.50% Test: 54.90%\n",
      "Run: 03, Epoch: 111, Loss: 0.6774, Train: 74.17%, Valid: 48.75% Test: 56.86%\n",
      "Run: 03, Epoch: 112, Loss: 0.6711, Train: 78.33%, Valid: 51.25% Test: 58.82%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 113, Loss: 0.6141, Train: 76.67%, Valid: 52.50% Test: 60.78%\n",
      "Run: 03, Epoch: 114, Loss: 0.6647, Train: 78.33%, Valid: 52.50% Test: 60.78%\n",
      "Run: 03, Epoch: 115, Loss: 0.6632, Train: 75.83%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 116, Loss: 0.6749, Train: 76.67%, Valid: 52.50% Test: 52.94%\n",
      "Run: 03, Epoch: 117, Loss: 0.6962, Train: 69.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 118, Loss: 0.6277, Train: 66.67%, Valid: 45.00% Test: 50.98%\n",
      "Run: 03, Epoch: 119, Loss: 0.6527, Train: 59.17%, Valid: 41.25% Test: 45.10%\n",
      "Run: 03, Epoch: 120, Loss: 0.6522, Train: 52.50%, Valid: 35.00% Test: 37.25%\n",
      "Run: 03, Epoch: 121, Loss: 0.7386, Train: 54.17%, Valid: 35.00% Test: 39.22%\n",
      "Run: 03, Epoch: 122, Loss: 0.6717, Train: 68.33%, Valid: 41.25% Test: 47.06%\n",
      "Run: 03, Epoch: 123, Loss: 0.6944, Train: 72.50%, Valid: 48.75% Test: 52.94%\n",
      "Run: 03, Epoch: 124, Loss: 0.6346, Train: 75.00%, Valid: 50.00% Test: 56.86%\n",
      "Run: 03, Epoch: 125, Loss: 0.6940, Train: 76.67%, Valid: 50.00% Test: 56.86%\n",
      "Run: 03, Epoch: 126, Loss: 0.6505, Train: 78.33%, Valid: 50.00% Test: 58.82%\n",
      "Run: 03, Epoch: 127, Loss: 0.6679, Train: 77.50%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 128, Loss: 0.7144, Train: 75.83%, Valid: 55.00% Test: 54.90%\n",
      "Run: 03, Epoch: 129, Loss: 0.6236, Train: 75.83%, Valid: 53.75% Test: 54.90%\n",
      "Run: 03, Epoch: 130, Loss: 0.7146, Train: 72.50%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 131, Loss: 0.6152, Train: 73.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 03, Epoch: 132, Loss: 0.6412, Train: 75.83%, Valid: 50.00% Test: 54.90%\n",
      "Run: 03, Epoch: 133, Loss: 0.6887, Train: 75.00%, Valid: 52.50% Test: 56.86%\n",
      "Run: 03, Epoch: 134, Loss: 0.6241, Train: 75.83%, Valid: 53.75% Test: 54.90%\n",
      "Run: 03, Epoch: 135, Loss: 0.6188, Train: 76.67%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 136, Loss: 0.7923, Train: 77.50%, Valid: 52.50% Test: 54.90%\n",
      "Run: 03, Epoch: 137, Loss: 0.6557, Train: 79.17%, Valid: 56.25% Test: 56.86%\n",
      "Run: 03, Epoch: 138, Loss: 0.6138, Train: 75.00%, Valid: 53.75% Test: 58.82%\n",
      "Run: 03, Epoch: 139, Loss: 0.6330, Train: 72.50%, Valid: 46.25% Test: 58.82%\n",
      "Run: 03, Epoch: 140, Loss: 0.5909, Train: 75.00%, Valid: 45.00% Test: 58.82%\n",
      "Run: 03, Epoch: 141, Loss: 0.6065, Train: 75.83%, Valid: 51.25% Test: 58.82%\n",
      "Run: 03, Epoch: 142, Loss: 0.6091, Train: 74.17%, Valid: 46.25% Test: 58.82%\n",
      "Run: 03, Epoch: 143, Loss: 0.5908, Train: 75.83%, Valid: 52.50% Test: 58.82%\n",
      "Run: 03, Epoch: 144, Loss: 0.6331, Train: 76.67%, Valid: 56.25% Test: 56.86%\n",
      "Run: 03, Epoch: 145, Loss: 0.7099, Train: 78.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 03, Epoch: 146, Loss: 0.5850, Train: 78.33%, Valid: 56.25% Test: 52.94%\n",
      "Run: 03, Epoch: 147, Loss: 0.6642, Train: 78.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 03, Epoch: 148, Loss: 0.7086, Train: 77.50%, Valid: 56.25% Test: 52.94%\n",
      "Run: 03, Epoch: 149, Loss: 0.5926, Train: 77.50%, Valid: 55.00% Test: 56.86%\n",
      "Run: 03, Epoch: 150, Loss: 0.7018, Train: 79.17%, Valid: 56.25% Test: 60.78%\n",
      "Run: 03, Epoch: 151, Loss: 0.7020, Train: 76.67%, Valid: 57.50% Test: 62.75%\n",
      "Run: 03, Epoch: 152, Loss: 0.6454, Train: 75.83%, Valid: 53.75% Test: 62.75%\n",
      "Run: 03, Epoch: 153, Loss: 0.6484, Train: 70.00%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 154, Loss: 0.6256, Train: 60.83%, Valid: 45.00% Test: 45.10%\n",
      "Run: 03, Epoch: 155, Loss: 0.6326, Train: 60.83%, Valid: 42.50% Test: 45.10%\n",
      "Run: 03, Epoch: 156, Loss: 0.6645, Train: 58.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 03, Epoch: 157, Loss: 0.5994, Train: 53.33%, Valid: 36.25% Test: 43.14%\n",
      "Run: 03, Epoch: 158, Loss: 0.6716, Train: 45.83%, Valid: 33.75% Test: 47.06%\n",
      "Run: 03, Epoch: 159, Loss: 0.6290, Train: 46.67%, Valid: 31.25% Test: 43.14%\n",
      "Run: 03, Epoch: 160, Loss: 0.6745, Train: 43.33%, Valid: 32.50% Test: 47.06%\n",
      "Run: 03, Epoch: 161, Loss: 0.6714, Train: 46.67%, Valid: 33.75% Test: 47.06%\n",
      "Run: 03, Epoch: 162, Loss: 0.6454, Train: 53.33%, Valid: 40.00% Test: 47.06%\n",
      "Run: 03, Epoch: 163, Loss: 0.5887, Train: 65.83%, Valid: 47.50% Test: 52.94%\n",
      "Run: 03, Epoch: 164, Loss: 0.5929, Train: 69.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 03, Epoch: 165, Loss: 0.5535, Train: 72.50%, Valid: 53.75% Test: 62.75%\n",
      "Run: 03, Epoch: 166, Loss: 0.5875, Train: 74.17%, Valid: 55.00% Test: 60.78%\n",
      "Run: 03, Epoch: 167, Loss: 0.6870, Train: 74.17%, Valid: 51.25% Test: 58.82%\n",
      "Run: 03, Epoch: 168, Loss: 0.6416, Train: 80.00%, Valid: 53.75% Test: 58.82%\n",
      "Run: 03, Epoch: 169, Loss: 0.6163, Train: 80.00%, Valid: 52.50% Test: 56.86%\n",
      "Run: 03, Epoch: 170, Loss: 0.6361, Train: 80.00%, Valid: 53.75% Test: 58.82%\n",
      "Run: 03, Epoch: 171, Loss: 0.6464, Train: 77.50%, Valid: 50.00% Test: 56.86%\n",
      "Run: 03, Epoch: 172, Loss: 0.6394, Train: 75.00%, Valid: 48.75% Test: 54.90%\n",
      "Run: 03, Epoch: 173, Loss: 0.5257, Train: 76.67%, Valid: 46.25% Test: 54.90%\n",
      "Run: 03, Epoch: 174, Loss: 0.7224, Train: 74.17%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 175, Loss: 0.6030, Train: 75.00%, Valid: 57.50% Test: 50.98%\n",
      "Run: 03, Epoch: 176, Loss: 0.6526, Train: 78.33%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 177, Loss: 0.5914, Train: 80.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 178, Loss: 0.6369, Train: 80.00%, Valid: 55.00% Test: 58.82%\n",
      "Run: 03, Epoch: 179, Loss: 0.5733, Train: 83.33%, Valid: 55.00% Test: 54.90%\n",
      "Run: 03, Epoch: 180, Loss: 0.6390, Train: 80.83%, Valid: 58.75% Test: 54.90%\n",
      "Run: 03, Epoch: 181, Loss: 0.5477, Train: 82.50%, Valid: 53.75% Test: 54.90%\n",
      "Run: 03, Epoch: 182, Loss: 0.6415, Train: 83.33%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 183, Loss: 0.6314, Train: 83.33%, Valid: 55.00% Test: 58.82%\n",
      "Run: 03, Epoch: 184, Loss: 0.6550, Train: 74.17%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 185, Loss: 0.6042, Train: 71.67%, Valid: 53.75% Test: 60.78%\n",
      "Run: 03, Epoch: 186, Loss: 0.6298, Train: 70.83%, Valid: 52.50% Test: 62.75%\n",
      "Run: 03, Epoch: 187, Loss: 0.6596, Train: 75.83%, Valid: 53.75% Test: 60.78%\n",
      "Run: 03, Epoch: 188, Loss: 0.6308, Train: 78.33%, Valid: 55.00% Test: 54.90%\n",
      "Run: 03, Epoch: 189, Loss: 0.6310, Train: 80.00%, Valid: 51.25% Test: 54.90%\n",
      "Run: 03, Epoch: 190, Loss: 0.5416, Train: 78.33%, Valid: 55.00% Test: 56.86%\n",
      "Run: 03, Epoch: 191, Loss: 0.5678, Train: 75.83%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 192, Loss: 0.6254, Train: 73.33%, Valid: 47.50% Test: 60.78%\n",
      "Run: 03, Epoch: 193, Loss: 0.7875, Train: 70.83%, Valid: 47.50% Test: 56.86%\n",
      "Run: 03, Epoch: 194, Loss: 0.5871, Train: 71.67%, Valid: 47.50% Test: 56.86%\n",
      "Run: 03, Epoch: 195, Loss: 0.5865, Train: 73.33%, Valid: 48.75% Test: 60.78%\n",
      "Run: 03, Epoch: 196, Loss: 0.5153, Train: 71.67%, Valid: 48.75% Test: 62.75%\n",
      "Run: 03, Epoch: 197, Loss: 0.5927, Train: 71.67%, Valid: 50.00% Test: 62.75%\n",
      "Run: 03, Epoch: 198, Loss: 0.6056, Train: 74.17%, Valid: 53.75% Test: 60.78%\n",
      "Run: 03, Epoch: 199, Loss: 0.6109, Train: 72.50%, Valid: 56.25% Test: 64.71%\n",
      "Run: 03, Epoch: 200, Loss: 0.6176, Train: 77.50%, Valid: 57.50% Test: 62.75%\n",
      "Run 03:\n",
      "Highest Train: 83.33\n",
      "Highest Valid: 61.25\n",
      "  Final Train: 71.67\n",
      "   Final Test: 54.90\n",
      "Run: 04, Epoch: 01, Loss: 1.6482, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 02, Loss: 1.3621, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 03, Loss: 1.3002, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 04, Loss: 1.2469, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 05, Loss: 1.2772, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 06, Loss: 1.2581, Train: 48.33%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 07, Loss: 1.2595, Train: 47.50%, Valid: 50.00% Test: 43.14%\n",
      "Run: 04, Epoch: 08, Loss: 1.2514, Train: 47.50%, Valid: 50.00% Test: 43.14%\n",
      "Run: 04, Epoch: 09, Loss: 1.1861, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 10, Loss: 1.2423, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 11, Loss: 1.2254, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 12, Loss: 1.1421, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 13, Loss: 1.1484, Train: 47.50%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 14, Loss: 1.1684, Train: 47.50%, Valid: 51.25% Test: 43.14%\n",
      "Run: 04, Epoch: 15, Loss: 1.1206, Train: 47.50%, Valid: 51.25% Test: 41.18%\n",
      "Run: 04, Epoch: 16, Loss: 1.0673, Train: 47.50%, Valid: 52.50% Test: 41.18%\n",
      "Run: 04, Epoch: 17, Loss: 1.1263, Train: 45.83%, Valid: 52.50% Test: 39.22%\n",
      "Run: 04, Epoch: 18, Loss: 1.1386, Train: 45.00%, Valid: 48.75% Test: 39.22%\n",
      "Run: 04, Epoch: 19, Loss: 1.0533, Train: 45.83%, Valid: 50.00% Test: 41.18%\n",
      "Run: 04, Epoch: 20, Loss: 1.0689, Train: 50.83%, Valid: 47.50% Test: 33.33%\n",
      "Run: 04, Epoch: 21, Loss: 1.0810, Train: 51.67%, Valid: 41.25% Test: 31.37%\n",
      "Run: 04, Epoch: 22, Loss: 1.0681, Train: 45.00%, Valid: 35.00% Test: 27.45%\n",
      "Run: 04, Epoch: 23, Loss: 1.0294, Train: 42.50%, Valid: 32.50% Test: 29.41%\n",
      "Run: 04, Epoch: 24, Loss: 1.0655, Train: 41.67%, Valid: 31.25% Test: 27.45%\n",
      "Run: 04, Epoch: 25, Loss: 1.0648, Train: 42.50%, Valid: 31.25% Test: 27.45%\n",
      "Run: 04, Epoch: 26, Loss: 1.0711, Train: 45.83%, Valid: 36.25% Test: 29.41%\n",
      "Run: 04, Epoch: 27, Loss: 1.0671, Train: 50.83%, Valid: 40.00% Test: 31.37%\n",
      "Run: 04, Epoch: 28, Loss: 1.0964, Train: 53.33%, Valid: 40.00% Test: 35.29%\n",
      "Run: 04, Epoch: 29, Loss: 1.0079, Train: 55.00%, Valid: 42.50% Test: 37.25%\n",
      "Run: 04, Epoch: 30, Loss: 1.0092, Train: 55.00%, Valid: 41.25% Test: 37.25%\n",
      "Run: 04, Epoch: 31, Loss: 1.0370, Train: 57.50%, Valid: 42.50% Test: 35.29%\n",
      "Run: 04, Epoch: 32, Loss: 1.0681, Train: 57.50%, Valid: 41.25% Test: 35.29%\n",
      "Run: 04, Epoch: 33, Loss: 1.0098, Train: 59.17%, Valid: 42.50% Test: 39.22%\n",
      "Run: 04, Epoch: 34, Loss: 1.0141, Train: 57.50%, Valid: 46.25% Test: 41.18%\n",
      "Run: 04, Epoch: 35, Loss: 1.0339, Train: 57.50%, Valid: 47.50% Test: 39.22%\n",
      "Run: 04, Epoch: 36, Loss: 0.9703, Train: 55.83%, Valid: 50.00% Test: 39.22%\n",
      "Run: 04, Epoch: 37, Loss: 1.0507, Train: 58.33%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 38, Loss: 0.9597, Train: 52.50%, Valid: 42.50% Test: 45.10%\n",
      "Run: 04, Epoch: 39, Loss: 1.0037, Train: 37.50%, Valid: 40.00% Test: 37.25%\n",
      "Run: 04, Epoch: 40, Loss: 1.0578, Train: 51.67%, Valid: 47.50% Test: 47.06%\n",
      "Run: 04, Epoch: 41, Loss: 0.9902, Train: 60.00%, Valid: 61.25% Test: 54.90%\n",
      "Run: 04, Epoch: 42, Loss: 1.0429, Train: 60.00%, Valid: 56.25% Test: 54.90%\n",
      "Run: 04, Epoch: 43, Loss: 1.0499, Train: 57.50%, Valid: 57.50% Test: 47.06%\n",
      "Run: 04, Epoch: 44, Loss: 1.0192, Train: 57.50%, Valid: 55.00% Test: 47.06%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 45, Loss: 0.9801, Train: 56.67%, Valid: 56.25% Test: 49.02%\n",
      "Run: 04, Epoch: 46, Loss: 1.0351, Train: 57.50%, Valid: 60.00% Test: 50.98%\n",
      "Run: 04, Epoch: 47, Loss: 0.9828, Train: 55.83%, Valid: 58.75% Test: 52.94%\n",
      "Run: 04, Epoch: 48, Loss: 0.9719, Train: 54.17%, Valid: 55.00% Test: 52.94%\n",
      "Run: 04, Epoch: 49, Loss: 0.9786, Train: 55.00%, Valid: 53.75% Test: 49.02%\n",
      "Run: 04, Epoch: 50, Loss: 1.0113, Train: 53.33%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 51, Loss: 1.0321, Train: 55.00%, Valid: 53.75% Test: 47.06%\n",
      "Run: 04, Epoch: 52, Loss: 0.9942, Train: 57.50%, Valid: 58.75% Test: 49.02%\n",
      "Run: 04, Epoch: 53, Loss: 0.9910, Train: 56.67%, Valid: 60.00% Test: 49.02%\n",
      "Run: 04, Epoch: 54, Loss: 0.9704, Train: 58.33%, Valid: 61.25% Test: 52.94%\n",
      "Run: 04, Epoch: 55, Loss: 1.0186, Train: 60.00%, Valid: 60.00% Test: 54.90%\n",
      "Run: 04, Epoch: 56, Loss: 0.9652, Train: 60.00%, Valid: 61.25% Test: 56.86%\n",
      "Run: 04, Epoch: 57, Loss: 0.9568, Train: 58.33%, Valid: 62.50% Test: 54.90%\n",
      "Run: 04, Epoch: 58, Loss: 1.0042, Train: 57.50%, Valid: 63.75% Test: 54.90%\n",
      "Run: 04, Epoch: 59, Loss: 0.9800, Train: 55.83%, Valid: 58.75% Test: 52.94%\n",
      "Run: 04, Epoch: 60, Loss: 0.9959, Train: 56.67%, Valid: 58.75% Test: 50.98%\n",
      "Run: 04, Epoch: 61, Loss: 0.9368, Train: 57.50%, Valid: 58.75% Test: 49.02%\n",
      "Run: 04, Epoch: 62, Loss: 0.9149, Train: 60.00%, Valid: 61.25% Test: 50.98%\n",
      "Run: 04, Epoch: 63, Loss: 0.9446, Train: 60.00%, Valid: 57.50% Test: 49.02%\n",
      "Run: 04, Epoch: 64, Loss: 0.9290, Train: 61.67%, Valid: 56.25% Test: 47.06%\n",
      "Run: 04, Epoch: 65, Loss: 0.9553, Train: 61.67%, Valid: 51.25% Test: 49.02%\n",
      "Run: 04, Epoch: 66, Loss: 0.9207, Train: 57.50%, Valid: 50.00% Test: 49.02%\n",
      "Run: 04, Epoch: 67, Loss: 0.9740, Train: 55.83%, Valid: 47.50% Test: 45.10%\n",
      "Run: 04, Epoch: 68, Loss: 0.9545, Train: 58.33%, Valid: 51.25% Test: 45.10%\n",
      "Run: 04, Epoch: 69, Loss: 0.9500, Train: 62.50%, Valid: 53.75% Test: 47.06%\n",
      "Run: 04, Epoch: 70, Loss: 0.9134, Train: 64.17%, Valid: 58.75% Test: 54.90%\n",
      "Run: 04, Epoch: 71, Loss: 0.9349, Train: 61.67%, Valid: 58.75% Test: 58.82%\n",
      "Run: 04, Epoch: 72, Loss: 0.8794, Train: 60.83%, Valid: 58.75% Test: 50.98%\n",
      "Run: 04, Epoch: 73, Loss: 0.9111, Train: 60.00%, Valid: 60.00% Test: 56.86%\n",
      "Run: 04, Epoch: 74, Loss: 0.9294, Train: 59.17%, Valid: 62.50% Test: 50.98%\n",
      "Run: 04, Epoch: 75, Loss: 0.9009, Train: 57.50%, Valid: 57.50% Test: 47.06%\n",
      "Run: 04, Epoch: 76, Loss: 0.9028, Train: 58.33%, Valid: 56.25% Test: 49.02%\n",
      "Run: 04, Epoch: 77, Loss: 0.8851, Train: 60.00%, Valid: 56.25% Test: 52.94%\n",
      "Run: 04, Epoch: 78, Loss: 0.9241, Train: 60.00%, Valid: 52.50% Test: 50.98%\n",
      "Run: 04, Epoch: 79, Loss: 0.8963, Train: 59.17%, Valid: 52.50% Test: 49.02%\n",
      "Run: 04, Epoch: 80, Loss: 0.9135, Train: 60.00%, Valid: 52.50% Test: 49.02%\n",
      "Run: 04, Epoch: 81, Loss: 0.9050, Train: 60.00%, Valid: 51.25% Test: 50.98%\n",
      "Run: 04, Epoch: 82, Loss: 0.8829, Train: 61.67%, Valid: 51.25% Test: 50.98%\n",
      "Run: 04, Epoch: 83, Loss: 0.8505, Train: 61.67%, Valid: 53.75% Test: 56.86%\n",
      "Run: 04, Epoch: 84, Loss: 0.9696, Train: 61.67%, Valid: 52.50% Test: 54.90%\n",
      "Run: 04, Epoch: 85, Loss: 0.8635, Train: 64.17%, Valid: 52.50% Test: 50.98%\n",
      "Run: 04, Epoch: 86, Loss: 0.8554, Train: 61.67%, Valid: 52.50% Test: 50.98%\n",
      "Run: 04, Epoch: 87, Loss: 0.8661, Train: 60.00%, Valid: 47.50% Test: 49.02%\n",
      "Run: 04, Epoch: 88, Loss: 0.8875, Train: 59.17%, Valid: 47.50% Test: 49.02%\n",
      "Run: 04, Epoch: 89, Loss: 0.8452, Train: 56.67%, Valid: 48.75% Test: 49.02%\n",
      "Run: 04, Epoch: 90, Loss: 0.8516, Train: 61.67%, Valid: 53.75% Test: 50.98%\n",
      "Run: 04, Epoch: 91, Loss: 0.8609, Train: 61.67%, Valid: 56.25% Test: 50.98%\n",
      "Run: 04, Epoch: 92, Loss: 0.8957, Train: 64.17%, Valid: 55.00% Test: 50.98%\n",
      "Run: 04, Epoch: 93, Loss: 0.8987, Train: 65.00%, Valid: 53.75% Test: 52.94%\n",
      "Run: 04, Epoch: 94, Loss: 0.8437, Train: 65.83%, Valid: 55.00% Test: 52.94%\n",
      "Run: 04, Epoch: 95, Loss: 0.9129, Train: 65.00%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 96, Loss: 0.9368, Train: 65.00%, Valid: 53.75% Test: 49.02%\n",
      "Run: 04, Epoch: 97, Loss: 0.8804, Train: 64.17%, Valid: 55.00% Test: 47.06%\n",
      "Run: 04, Epoch: 98, Loss: 0.8195, Train: 63.33%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 99, Loss: 0.8319, Train: 60.83%, Valid: 56.25% Test: 56.86%\n",
      "Run: 04, Epoch: 100, Loss: 0.9022, Train: 64.17%, Valid: 56.25% Test: 49.02%\n",
      "Run: 04, Epoch: 101, Loss: 0.8880, Train: 62.50%, Valid: 55.00% Test: 50.98%\n",
      "Run: 04, Epoch: 102, Loss: 0.8802, Train: 62.50%, Valid: 53.75% Test: 49.02%\n",
      "Run: 04, Epoch: 103, Loss: 0.8423, Train: 64.17%, Valid: 53.75% Test: 50.98%\n",
      "Run: 04, Epoch: 104, Loss: 0.9214, Train: 66.67%, Valid: 57.50% Test: 54.90%\n",
      "Run: 04, Epoch: 105, Loss: 0.8847, Train: 66.67%, Valid: 58.75% Test: 49.02%\n",
      "Run: 04, Epoch: 106, Loss: 0.8850, Train: 62.50%, Valid: 56.25% Test: 49.02%\n",
      "Run: 04, Epoch: 107, Loss: 0.8688, Train: 60.83%, Valid: 57.50% Test: 49.02%\n",
      "Run: 04, Epoch: 108, Loss: 0.8542, Train: 60.00%, Valid: 60.00% Test: 41.18%\n",
      "Run: 04, Epoch: 109, Loss: 0.8487, Train: 60.83%, Valid: 57.50% Test: 45.10%\n",
      "Run: 04, Epoch: 110, Loss: 0.8837, Train: 62.50%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 111, Loss: 0.8222, Train: 64.17%, Valid: 60.00% Test: 47.06%\n",
      "Run: 04, Epoch: 112, Loss: 0.8125, Train: 63.33%, Valid: 60.00% Test: 47.06%\n",
      "Run: 04, Epoch: 113, Loss: 0.8850, Train: 63.33%, Valid: 57.50% Test: 47.06%\n",
      "Run: 04, Epoch: 114, Loss: 0.8490, Train: 62.50%, Valid: 60.00% Test: 50.98%\n",
      "Run: 04, Epoch: 115, Loss: 0.9202, Train: 62.50%, Valid: 58.75% Test: 52.94%\n",
      "Run: 04, Epoch: 116, Loss: 0.8087, Train: 63.33%, Valid: 58.75% Test: 50.98%\n",
      "Run: 04, Epoch: 117, Loss: 0.8281, Train: 60.83%, Valid: 52.50% Test: 52.94%\n",
      "Run: 04, Epoch: 118, Loss: 0.7877, Train: 59.17%, Valid: 50.00% Test: 50.98%\n",
      "Run: 04, Epoch: 119, Loss: 0.8729, Train: 63.33%, Valid: 56.25% Test: 50.98%\n",
      "Run: 04, Epoch: 120, Loss: 0.8881, Train: 64.17%, Valid: 57.50% Test: 52.94%\n",
      "Run: 04, Epoch: 121, Loss: 0.8533, Train: 60.83%, Valid: 52.50% Test: 45.10%\n",
      "Run: 04, Epoch: 122, Loss: 0.9112, Train: 50.83%, Valid: 43.75% Test: 45.10%\n",
      "Run: 04, Epoch: 123, Loss: 0.8595, Train: 51.67%, Valid: 46.25% Test: 39.22%\n",
      "Run: 04, Epoch: 124, Loss: 0.8672, Train: 53.33%, Valid: 46.25% Test: 41.18%\n",
      "Run: 04, Epoch: 125, Loss: 0.8840, Train: 58.33%, Valid: 55.00% Test: 47.06%\n",
      "Run: 04, Epoch: 126, Loss: 0.8338, Train: 65.83%, Valid: 60.00% Test: 50.98%\n",
      "Run: 04, Epoch: 127, Loss: 0.7879, Train: 64.17%, Valid: 63.75% Test: 47.06%\n",
      "Run: 04, Epoch: 128, Loss: 0.7951, Train: 65.83%, Valid: 61.25% Test: 45.10%\n",
      "Run: 04, Epoch: 129, Loss: 0.8992, Train: 67.50%, Valid: 62.50% Test: 45.10%\n",
      "Run: 04, Epoch: 130, Loss: 0.8081, Train: 70.00%, Valid: 61.25% Test: 50.98%\n",
      "Run: 04, Epoch: 131, Loss: 0.8083, Train: 65.83%, Valid: 61.25% Test: 45.10%\n",
      "Run: 04, Epoch: 132, Loss: 0.7848, Train: 66.67%, Valid: 52.50% Test: 47.06%\n",
      "Run: 04, Epoch: 133, Loss: 0.8731, Train: 62.50%, Valid: 50.00% Test: 45.10%\n",
      "Run: 04, Epoch: 134, Loss: 0.8862, Train: 60.00%, Valid: 42.50% Test: 41.18%\n",
      "Run: 04, Epoch: 135, Loss: 0.8508, Train: 60.00%, Valid: 37.50% Test: 47.06%\n",
      "Run: 04, Epoch: 136, Loss: 0.7701, Train: 60.83%, Valid: 47.50% Test: 50.98%\n",
      "Run: 04, Epoch: 137, Loss: 0.8368, Train: 58.33%, Valid: 56.25% Test: 50.98%\n",
      "Run: 04, Epoch: 138, Loss: 0.7942, Train: 60.83%, Valid: 60.00% Test: 49.02%\n",
      "Run: 04, Epoch: 139, Loss: 0.7581, Train: 63.33%, Valid: 62.50% Test: 52.94%\n",
      "Run: 04, Epoch: 140, Loss: 0.8257, Train: 65.83%, Valid: 63.75% Test: 54.90%\n",
      "Run: 04, Epoch: 141, Loss: 0.8494, Train: 65.83%, Valid: 58.75% Test: 52.94%\n",
      "Run: 04, Epoch: 142, Loss: 0.7486, Train: 64.17%, Valid: 56.25% Test: 50.98%\n",
      "Run: 04, Epoch: 143, Loss: 0.7519, Train: 67.50%, Valid: 63.75% Test: 49.02%\n",
      "Run: 04, Epoch: 144, Loss: 0.9104, Train: 70.00%, Valid: 63.75% Test: 54.90%\n",
      "Run: 04, Epoch: 145, Loss: 0.8043, Train: 67.50%, Valid: 63.75% Test: 54.90%\n",
      "Run: 04, Epoch: 146, Loss: 0.8147, Train: 68.33%, Valid: 66.25% Test: 56.86%\n",
      "Run: 04, Epoch: 147, Loss: 0.7830, Train: 65.00%, Valid: 60.00% Test: 50.98%\n",
      "Run: 04, Epoch: 148, Loss: 0.7411, Train: 65.00%, Valid: 55.00% Test: 43.14%\n",
      "Run: 04, Epoch: 149, Loss: 0.7351, Train: 63.33%, Valid: 56.25% Test: 41.18%\n",
      "Run: 04, Epoch: 150, Loss: 0.8416, Train: 60.83%, Valid: 50.00% Test: 39.22%\n",
      "Run: 04, Epoch: 151, Loss: 0.7667, Train: 61.67%, Valid: 51.25% Test: 41.18%\n",
      "Run: 04, Epoch: 152, Loss: 0.8048, Train: 55.00%, Valid: 42.50% Test: 33.33%\n",
      "Run: 04, Epoch: 153, Loss: 0.7923, Train: 55.00%, Valid: 41.25% Test: 31.37%\n",
      "Run: 04, Epoch: 154, Loss: 0.8237, Train: 55.00%, Valid: 40.00% Test: 35.29%\n",
      "Run: 04, Epoch: 155, Loss: 0.7213, Train: 50.00%, Valid: 32.50% Test: 37.25%\n",
      "Run: 04, Epoch: 156, Loss: 0.7955, Train: 50.00%, Valid: 30.00% Test: 31.37%\n",
      "Run: 04, Epoch: 157, Loss: 0.7701, Train: 51.67%, Valid: 31.25% Test: 37.25%\n",
      "Run: 04, Epoch: 158, Loss: 0.7434, Train: 55.83%, Valid: 32.50% Test: 39.22%\n",
      "Run: 04, Epoch: 159, Loss: 0.7364, Train: 55.83%, Valid: 33.75% Test: 39.22%\n",
      "Run: 04, Epoch: 160, Loss: 0.7966, Train: 57.50%, Valid: 37.50% Test: 39.22%\n",
      "Run: 04, Epoch: 161, Loss: 0.7487, Train: 63.33%, Valid: 40.00% Test: 43.14%\n",
      "Run: 04, Epoch: 162, Loss: 0.7927, Train: 63.33%, Valid: 50.00% Test: 37.25%\n",
      "Run: 04, Epoch: 163, Loss: 0.7420, Train: 65.00%, Valid: 57.50% Test: 47.06%\n",
      "Run: 04, Epoch: 164, Loss: 0.7209, Train: 67.50%, Valid: 61.25% Test: 54.90%\n",
      "Run: 04, Epoch: 165, Loss: 0.7432, Train: 66.67%, Valid: 63.75% Test: 64.71%\n",
      "Run: 04, Epoch: 166, Loss: 0.7036, Train: 65.83%, Valid: 63.75% Test: 62.75%\n",
      "Run: 04, Epoch: 167, Loss: 0.7264, Train: 69.17%, Valid: 61.25% Test: 56.86%\n",
      "Run: 04, Epoch: 168, Loss: 0.7370, Train: 70.00%, Valid: 61.25% Test: 56.86%\n",
      "Run: 04, Epoch: 169, Loss: 0.7558, Train: 70.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 04, Epoch: 170, Loss: 0.7853, Train: 66.67%, Valid: 60.00% Test: 56.86%\n",
      "Run: 04, Epoch: 171, Loss: 0.6896, Train: 68.33%, Valid: 58.75% Test: 47.06%\n",
      "Run: 04, Epoch: 172, Loss: 0.7602, Train: 67.50%, Valid: 61.25% Test: 47.06%\n",
      "Run: 04, Epoch: 173, Loss: 0.6869, Train: 67.50%, Valid: 58.75% Test: 45.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 174, Loss: 0.7264, Train: 65.83%, Valid: 60.00% Test: 45.10%\n",
      "Run: 04, Epoch: 175, Loss: 0.7394, Train: 65.00%, Valid: 57.50% Test: 43.14%\n",
      "Run: 04, Epoch: 176, Loss: 0.7337, Train: 65.00%, Valid: 56.25% Test: 45.10%\n",
      "Run: 04, Epoch: 177, Loss: 0.6911, Train: 66.67%, Valid: 60.00% Test: 45.10%\n",
      "Run: 04, Epoch: 178, Loss: 0.7914, Train: 68.33%, Valid: 62.50% Test: 45.10%\n",
      "Run: 04, Epoch: 179, Loss: 0.7088, Train: 67.50%, Valid: 62.50% Test: 45.10%\n",
      "Run: 04, Epoch: 180, Loss: 0.7666, Train: 66.67%, Valid: 61.25% Test: 45.10%\n",
      "Run: 04, Epoch: 181, Loss: 0.7749, Train: 69.17%, Valid: 58.75% Test: 39.22%\n",
      "Run: 04, Epoch: 182, Loss: 0.7629, Train: 69.17%, Valid: 58.75% Test: 41.18%\n",
      "Run: 04, Epoch: 183, Loss: 0.6651, Train: 65.83%, Valid: 55.00% Test: 37.25%\n",
      "Run: 04, Epoch: 184, Loss: 0.7107, Train: 65.00%, Valid: 55.00% Test: 39.22%\n",
      "Run: 04, Epoch: 185, Loss: 0.7703, Train: 63.33%, Valid: 52.50% Test: 39.22%\n",
      "Run: 04, Epoch: 186, Loss: 0.6836, Train: 57.50%, Valid: 47.50% Test: 37.25%\n",
      "Run: 04, Epoch: 187, Loss: 0.6732, Train: 56.67%, Valid: 46.25% Test: 37.25%\n",
      "Run: 04, Epoch: 188, Loss: 0.7726, Train: 56.67%, Valid: 50.00% Test: 37.25%\n",
      "Run: 04, Epoch: 189, Loss: 0.6589, Train: 59.17%, Valid: 51.25% Test: 37.25%\n",
      "Run: 04, Epoch: 190, Loss: 0.7466, Train: 65.00%, Valid: 55.00% Test: 41.18%\n",
      "Run: 04, Epoch: 191, Loss: 0.7738, Train: 66.67%, Valid: 58.75% Test: 43.14%\n",
      "Run: 04, Epoch: 192, Loss: 0.7358, Train: 70.83%, Valid: 61.25% Test: 45.10%\n",
      "Run: 04, Epoch: 193, Loss: 0.7213, Train: 71.67%, Valid: 63.75% Test: 47.06%\n",
      "Run: 04, Epoch: 194, Loss: 0.6828, Train: 69.17%, Valid: 61.25% Test: 49.02%\n",
      "Run: 04, Epoch: 195, Loss: 0.6970, Train: 73.33%, Valid: 65.00% Test: 47.06%\n",
      "Run: 04, Epoch: 196, Loss: 0.7406, Train: 75.00%, Valid: 58.75% Test: 45.10%\n",
      "Run: 04, Epoch: 197, Loss: 0.7413, Train: 73.33%, Valid: 57.50% Test: 43.14%\n",
      "Run: 04, Epoch: 198, Loss: 0.7175, Train: 68.33%, Valid: 57.50% Test: 45.10%\n",
      "Run: 04, Epoch: 199, Loss: 0.6599, Train: 68.33%, Valid: 58.75% Test: 47.06%\n",
      "Run: 04, Epoch: 200, Loss: 0.6507, Train: 67.50%, Valid: 56.25% Test: 50.98%\n",
      "Run 04:\n",
      "Highest Train: 75.00\n",
      "Highest Valid: 66.25\n",
      "  Final Train: 68.33\n",
      "   Final Test: 56.86\n",
      "Run: 05, Epoch: 01, Loss: 1.5713, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 02, Loss: 1.3457, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 03, Loss: 1.2707, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 04, Loss: 1.2279, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 05, Loss: 1.2735, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 06, Loss: 1.2514, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 07, Loss: 1.2078, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 08, Loss: 1.1738, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 09, Loss: 1.2456, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 10, Loss: 1.2051, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 11, Loss: 1.2185, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 12, Loss: 1.3374, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 13, Loss: 1.1168, Train: 51.67%, Valid: 53.75% Test: 41.18%\n",
      "Run: 05, Epoch: 14, Loss: 1.1383, Train: 53.33%, Valid: 58.75% Test: 47.06%\n",
      "Run: 05, Epoch: 15, Loss: 1.3031, Train: 53.33%, Valid: 53.75% Test: 49.02%\n",
      "Run: 05, Epoch: 16, Loss: 1.1818, Train: 52.50%, Valid: 55.00% Test: 50.98%\n",
      "Run: 05, Epoch: 17, Loss: 1.1876, Train: 53.33%, Valid: 53.75% Test: 52.94%\n",
      "Run: 05, Epoch: 18, Loss: 1.1224, Train: 55.83%, Valid: 53.75% Test: 50.98%\n",
      "Run: 05, Epoch: 19, Loss: 1.1357, Train: 50.83%, Valid: 56.25% Test: 50.98%\n",
      "Run: 05, Epoch: 20, Loss: 1.0947, Train: 53.33%, Valid: 56.25% Test: 43.14%\n",
      "Run: 05, Epoch: 21, Loss: 1.1418, Train: 49.17%, Valid: 52.50% Test: 43.14%\n",
      "Run: 05, Epoch: 22, Loss: 1.1002, Train: 49.17%, Valid: 53.75% Test: 39.22%\n",
      "Run: 05, Epoch: 23, Loss: 1.0795, Train: 50.83%, Valid: 53.75% Test: 41.18%\n",
      "Run: 05, Epoch: 24, Loss: 1.0604, Train: 50.83%, Valid: 55.00% Test: 41.18%\n",
      "Run: 05, Epoch: 25, Loss: 1.0868, Train: 52.50%, Valid: 56.25% Test: 41.18%\n",
      "Run: 05, Epoch: 26, Loss: 1.0714, Train: 51.67%, Valid: 57.50% Test: 39.22%\n",
      "Run: 05, Epoch: 27, Loss: 1.0700, Train: 52.50%, Valid: 56.25% Test: 37.25%\n",
      "Run: 05, Epoch: 28, Loss: 1.0708, Train: 49.17%, Valid: 51.25% Test: 33.33%\n",
      "Run: 05, Epoch: 29, Loss: 1.1344, Train: 50.00%, Valid: 53.75% Test: 33.33%\n",
      "Run: 05, Epoch: 30, Loss: 1.0733, Train: 51.67%, Valid: 57.50% Test: 39.22%\n",
      "Run: 05, Epoch: 31, Loss: 1.0429, Train: 53.33%, Valid: 56.25% Test: 41.18%\n",
      "Run: 05, Epoch: 32, Loss: 1.0331, Train: 53.33%, Valid: 56.25% Test: 45.10%\n",
      "Run: 05, Epoch: 33, Loss: 1.0931, Train: 55.83%, Valid: 55.00% Test: 49.02%\n",
      "Run: 05, Epoch: 34, Loss: 1.0687, Train: 55.00%, Valid: 55.00% Test: 49.02%\n",
      "Run: 05, Epoch: 35, Loss: 1.0362, Train: 55.00%, Valid: 52.50% Test: 49.02%\n",
      "Run: 05, Epoch: 36, Loss: 1.1121, Train: 55.83%, Valid: 53.75% Test: 49.02%\n",
      "Run: 05, Epoch: 37, Loss: 0.9908, Train: 55.00%, Valid: 53.75% Test: 47.06%\n",
      "Run: 05, Epoch: 38, Loss: 0.9957, Train: 55.00%, Valid: 55.00% Test: 43.14%\n",
      "Run: 05, Epoch: 39, Loss: 1.0030, Train: 55.00%, Valid: 53.75% Test: 39.22%\n",
      "Run: 05, Epoch: 40, Loss: 0.9720, Train: 54.17%, Valid: 52.50% Test: 37.25%\n",
      "Run: 05, Epoch: 41, Loss: 1.0859, Train: 54.17%, Valid: 52.50% Test: 37.25%\n",
      "Run: 05, Epoch: 42, Loss: 0.9881, Train: 55.00%, Valid: 53.75% Test: 37.25%\n",
      "Run: 05, Epoch: 43, Loss: 0.9565, Train: 55.83%, Valid: 51.25% Test: 33.33%\n",
      "Run: 05, Epoch: 44, Loss: 0.9205, Train: 56.67%, Valid: 50.00% Test: 37.25%\n",
      "Run: 05, Epoch: 45, Loss: 1.0264, Train: 55.83%, Valid: 50.00% Test: 33.33%\n",
      "Run: 05, Epoch: 46, Loss: 0.9537, Train: 55.83%, Valid: 48.75% Test: 33.33%\n",
      "Run: 05, Epoch: 47, Loss: 1.0229, Train: 57.50%, Valid: 47.50% Test: 33.33%\n",
      "Run: 05, Epoch: 48, Loss: 0.9490, Train: 57.50%, Valid: 52.50% Test: 33.33%\n",
      "Run: 05, Epoch: 49, Loss: 0.9781, Train: 60.83%, Valid: 53.75% Test: 37.25%\n",
      "Run: 05, Epoch: 50, Loss: 0.9962, Train: 58.33%, Valid: 55.00% Test: 39.22%\n",
      "Run: 05, Epoch: 51, Loss: 0.9766, Train: 61.67%, Valid: 57.50% Test: 43.14%\n",
      "Run: 05, Epoch: 52, Loss: 0.9623, Train: 61.67%, Valid: 58.75% Test: 45.10%\n",
      "Run: 05, Epoch: 53, Loss: 1.0210, Train: 61.67%, Valid: 58.75% Test: 49.02%\n",
      "Run: 05, Epoch: 54, Loss: 0.9477, Train: 61.67%, Valid: 57.50% Test: 50.98%\n",
      "Run: 05, Epoch: 55, Loss: 0.9863, Train: 60.83%, Valid: 57.50% Test: 50.98%\n",
      "Run: 05, Epoch: 56, Loss: 0.9626, Train: 60.83%, Valid: 57.50% Test: 50.98%\n",
      "Run: 05, Epoch: 57, Loss: 0.9673, Train: 60.00%, Valid: 56.25% Test: 52.94%\n",
      "Run: 05, Epoch: 58, Loss: 0.9111, Train: 60.00%, Valid: 56.25% Test: 52.94%\n",
      "Run: 05, Epoch: 59, Loss: 0.9274, Train: 58.33%, Valid: 55.00% Test: 56.86%\n",
      "Run: 05, Epoch: 60, Loss: 0.9748, Train: 60.00%, Valid: 60.00% Test: 54.90%\n",
      "Run: 05, Epoch: 61, Loss: 0.9382, Train: 60.00%, Valid: 60.00% Test: 56.86%\n",
      "Run: 05, Epoch: 62, Loss: 0.8832, Train: 60.83%, Valid: 58.75% Test: 56.86%\n",
      "Run: 05, Epoch: 63, Loss: 0.9591, Train: 60.83%, Valid: 56.25% Test: 54.90%\n",
      "Run: 05, Epoch: 64, Loss: 0.9116, Train: 61.67%, Valid: 56.25% Test: 54.90%\n",
      "Run: 05, Epoch: 65, Loss: 0.9689, Train: 60.83%, Valid: 57.50% Test: 52.94%\n",
      "Run: 05, Epoch: 66, Loss: 0.9204, Train: 59.17%, Valid: 55.00% Test: 50.98%\n",
      "Run: 05, Epoch: 67, Loss: 0.9286, Train: 62.50%, Valid: 51.25% Test: 54.90%\n",
      "Run: 05, Epoch: 68, Loss: 0.8714, Train: 60.00%, Valid: 48.75% Test: 43.14%\n",
      "Run: 05, Epoch: 69, Loss: 0.8874, Train: 58.33%, Valid: 53.75% Test: 41.18%\n",
      "Run: 05, Epoch: 70, Loss: 0.8828, Train: 60.83%, Valid: 52.50% Test: 45.10%\n",
      "Run: 05, Epoch: 71, Loss: 0.9197, Train: 61.67%, Valid: 55.00% Test: 56.86%\n",
      "Run: 05, Epoch: 72, Loss: 0.8788, Train: 60.83%, Valid: 52.50% Test: 56.86%\n",
      "Run: 05, Epoch: 73, Loss: 0.8822, Train: 60.83%, Valid: 48.75% Test: 58.82%\n",
      "Run: 05, Epoch: 74, Loss: 0.9692, Train: 63.33%, Valid: 45.00% Test: 52.94%\n",
      "Run: 05, Epoch: 75, Loss: 0.9006, Train: 65.00%, Valid: 45.00% Test: 49.02%\n",
      "Run: 05, Epoch: 76, Loss: 0.8220, Train: 64.17%, Valid: 42.50% Test: 43.14%\n",
      "Run: 05, Epoch: 77, Loss: 0.8878, Train: 63.33%, Valid: 42.50% Test: 41.18%\n",
      "Run: 05, Epoch: 78, Loss: 0.9205, Train: 65.83%, Valid: 41.25% Test: 47.06%\n",
      "Run: 05, Epoch: 79, Loss: 0.9977, Train: 66.67%, Valid: 43.75% Test: 49.02%\n",
      "Run: 05, Epoch: 80, Loss: 0.8880, Train: 64.17%, Valid: 45.00% Test: 49.02%\n",
      "Run: 05, Epoch: 81, Loss: 0.9181, Train: 62.50%, Valid: 43.75% Test: 49.02%\n",
      "Run: 05, Epoch: 82, Loss: 0.8445, Train: 60.83%, Valid: 40.00% Test: 43.14%\n",
      "Run: 05, Epoch: 83, Loss: 0.8486, Train: 59.17%, Valid: 40.00% Test: 35.29%\n",
      "Run: 05, Epoch: 84, Loss: 0.8075, Train: 53.33%, Valid: 45.00% Test: 31.37%\n",
      "Run: 05, Epoch: 85, Loss: 0.8002, Train: 50.83%, Valid: 46.25% Test: 33.33%\n",
      "Run: 05, Epoch: 86, Loss: 0.9424, Train: 51.67%, Valid: 46.25% Test: 33.33%\n",
      "Run: 05, Epoch: 87, Loss: 0.7861, Train: 50.83%, Valid: 46.25% Test: 33.33%\n",
      "Run: 05, Epoch: 88, Loss: 0.9312, Train: 53.33%, Valid: 43.75% Test: 37.25%\n",
      "Run: 05, Epoch: 89, Loss: 0.8038, Train: 61.67%, Valid: 38.75% Test: 39.22%\n",
      "Run: 05, Epoch: 90, Loss: 0.8656, Train: 67.50%, Valid: 42.50% Test: 47.06%\n",
      "Run: 05, Epoch: 91, Loss: 0.8545, Train: 65.00%, Valid: 43.75% Test: 50.98%\n",
      "Run: 05, Epoch: 92, Loss: 0.8802, Train: 63.33%, Valid: 45.00% Test: 50.98%\n",
      "Run: 05, Epoch: 93, Loss: 0.8905, Train: 65.00%, Valid: 42.50% Test: 47.06%\n",
      "Run: 05, Epoch: 94, Loss: 0.9215, Train: 65.00%, Valid: 43.75% Test: 47.06%\n",
      "Run: 05, Epoch: 95, Loss: 0.9267, Train: 60.83%, Valid: 48.75% Test: 50.98%\n",
      "Run: 05, Epoch: 96, Loss: 0.8914, Train: 60.83%, Valid: 50.00% Test: 58.82%\n",
      "Run: 05, Epoch: 97, Loss: 0.8917, Train: 63.33%, Valid: 56.25% Test: 54.90%\n",
      "Run: 05, Epoch: 98, Loss: 0.8279, Train: 57.50%, Valid: 45.00% Test: 45.10%\n",
      "Run: 05, Epoch: 99, Loss: 0.8819, Train: 56.67%, Valid: 48.75% Test: 43.14%\n",
      "Run: 05, Epoch: 100, Loss: 0.9263, Train: 57.50%, Valid: 47.50% Test: 39.22%\n",
      "Run: 05, Epoch: 101, Loss: 0.8707, Train: 56.67%, Valid: 51.25% Test: 35.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 102, Loss: 0.7897, Train: 58.33%, Valid: 56.25% Test: 37.25%\n",
      "Run: 05, Epoch: 103, Loss: 0.8159, Train: 59.17%, Valid: 60.00% Test: 41.18%\n",
      "Run: 05, Epoch: 104, Loss: 0.8885, Train: 60.83%, Valid: 55.00% Test: 41.18%\n",
      "Run: 05, Epoch: 105, Loss: 0.8568, Train: 58.33%, Valid: 42.50% Test: 33.33%\n",
      "Run: 05, Epoch: 106, Loss: 0.8107, Train: 58.33%, Valid: 40.00% Test: 29.41%\n",
      "Run: 05, Epoch: 107, Loss: 0.7869, Train: 56.67%, Valid: 36.25% Test: 33.33%\n",
      "Run: 05, Epoch: 108, Loss: 0.8140, Train: 55.83%, Valid: 37.50% Test: 29.41%\n",
      "Run: 05, Epoch: 109, Loss: 0.8545, Train: 58.33%, Valid: 37.50% Test: 33.33%\n",
      "Run: 05, Epoch: 110, Loss: 0.8496, Train: 59.17%, Valid: 38.75% Test: 33.33%\n",
      "Run: 05, Epoch: 111, Loss: 0.8540, Train: 60.00%, Valid: 41.25% Test: 39.22%\n",
      "Run: 05, Epoch: 112, Loss: 0.8653, Train: 65.00%, Valid: 45.00% Test: 39.22%\n",
      "Run: 05, Epoch: 113, Loss: 0.8348, Train: 65.83%, Valid: 41.25% Test: 49.02%\n",
      "Run: 05, Epoch: 114, Loss: 0.7496, Train: 66.67%, Valid: 43.75% Test: 50.98%\n",
      "Run: 05, Epoch: 115, Loss: 0.7557, Train: 67.50%, Valid: 42.50% Test: 49.02%\n",
      "Run: 05, Epoch: 116, Loss: 0.8682, Train: 65.83%, Valid: 46.25% Test: 49.02%\n",
      "Run: 05, Epoch: 117, Loss: 0.8087, Train: 64.17%, Valid: 48.75% Test: 45.10%\n",
      "Run: 05, Epoch: 118, Loss: 0.8389, Train: 65.00%, Valid: 46.25% Test: 43.14%\n",
      "Run: 05, Epoch: 119, Loss: 0.7440, Train: 67.50%, Valid: 45.00% Test: 47.06%\n",
      "Run: 05, Epoch: 120, Loss: 0.8098, Train: 66.67%, Valid: 45.00% Test: 49.02%\n",
      "Run: 05, Epoch: 121, Loss: 0.9438, Train: 68.33%, Valid: 45.00% Test: 47.06%\n",
      "Run: 05, Epoch: 122, Loss: 0.7940, Train: 68.33%, Valid: 43.75% Test: 45.10%\n",
      "Run: 05, Epoch: 123, Loss: 0.8702, Train: 70.83%, Valid: 43.75% Test: 45.10%\n",
      "Run: 05, Epoch: 124, Loss: 0.7896, Train: 65.83%, Valid: 45.00% Test: 43.14%\n",
      "Run: 05, Epoch: 125, Loss: 0.7539, Train: 68.33%, Valid: 43.75% Test: 45.10%\n",
      "Run: 05, Epoch: 126, Loss: 0.7906, Train: 69.17%, Valid: 43.75% Test: 49.02%\n",
      "Run: 05, Epoch: 127, Loss: 0.8053, Train: 69.17%, Valid: 43.75% Test: 47.06%\n",
      "Run: 05, Epoch: 128, Loss: 0.8610, Train: 68.33%, Valid: 42.50% Test: 35.29%\n",
      "Run: 05, Epoch: 129, Loss: 0.8362, Train: 63.33%, Valid: 42.50% Test: 31.37%\n",
      "Run: 05, Epoch: 130, Loss: 0.7815, Train: 62.50%, Valid: 43.75% Test: 43.14%\n",
      "Run: 05, Epoch: 131, Loss: 0.7807, Train: 60.83%, Valid: 46.25% Test: 39.22%\n",
      "Run: 05, Epoch: 132, Loss: 0.8621, Train: 58.33%, Valid: 43.75% Test: 39.22%\n",
      "Run: 05, Epoch: 133, Loss: 0.8343, Train: 60.00%, Valid: 45.00% Test: 35.29%\n",
      "Run: 05, Epoch: 134, Loss: 0.7612, Train: 59.17%, Valid: 45.00% Test: 33.33%\n",
      "Run: 05, Epoch: 135, Loss: 0.8035, Train: 59.17%, Valid: 43.75% Test: 33.33%\n",
      "Run: 05, Epoch: 136, Loss: 0.8708, Train: 62.50%, Valid: 38.75% Test: 31.37%\n",
      "Run: 05, Epoch: 137, Loss: 0.7977, Train: 64.17%, Valid: 37.50% Test: 35.29%\n",
      "Run: 05, Epoch: 138, Loss: 0.7956, Train: 61.67%, Valid: 38.75% Test: 39.22%\n",
      "Run: 05, Epoch: 139, Loss: 0.8447, Train: 62.50%, Valid: 46.25% Test: 41.18%\n",
      "Run: 05, Epoch: 140, Loss: 0.7408, Train: 62.50%, Valid: 45.00% Test: 47.06%\n",
      "Run: 05, Epoch: 141, Loss: 0.7786, Train: 62.50%, Valid: 48.75% Test: 54.90%\n",
      "Run: 05, Epoch: 142, Loss: 0.8096, Train: 64.17%, Valid: 51.25% Test: 58.82%\n",
      "Run: 05, Epoch: 143, Loss: 0.7798, Train: 67.50%, Valid: 48.75% Test: 56.86%\n",
      "Run: 05, Epoch: 144, Loss: 0.7564, Train: 66.67%, Valid: 41.25% Test: 58.82%\n",
      "Run: 05, Epoch: 145, Loss: 0.8257, Train: 65.83%, Valid: 45.00% Test: 64.71%\n",
      "Run: 05, Epoch: 146, Loss: 0.7802, Train: 61.67%, Valid: 46.25% Test: 56.86%\n",
      "Run: 05, Epoch: 147, Loss: 0.8182, Train: 56.67%, Valid: 47.50% Test: 41.18%\n",
      "Run: 05, Epoch: 148, Loss: 0.8045, Train: 50.00%, Valid: 53.75% Test: 37.25%\n",
      "Run: 05, Epoch: 149, Loss: 0.7214, Train: 50.83%, Valid: 55.00% Test: 43.14%\n",
      "Run: 05, Epoch: 150, Loss: 0.8707, Train: 50.83%, Valid: 55.00% Test: 41.18%\n",
      "Run: 05, Epoch: 151, Loss: 0.7964, Train: 51.67%, Valid: 55.00% Test: 41.18%\n",
      "Run: 05, Epoch: 152, Loss: 0.7494, Train: 55.00%, Valid: 55.00% Test: 43.14%\n",
      "Run: 05, Epoch: 153, Loss: 0.7628, Train: 59.17%, Valid: 56.25% Test: 50.98%\n",
      "Run: 05, Epoch: 154, Loss: 0.7354, Train: 60.83%, Valid: 53.75% Test: 45.10%\n",
      "Run: 05, Epoch: 155, Loss: 0.9091, Train: 58.33%, Valid: 48.75% Test: 41.18%\n",
      "Run: 05, Epoch: 156, Loss: 0.7477, Train: 60.00%, Valid: 47.50% Test: 41.18%\n",
      "Run: 05, Epoch: 157, Loss: 0.7442, Train: 64.17%, Valid: 45.00% Test: 37.25%\n",
      "Run: 05, Epoch: 158, Loss: 0.7533, Train: 66.67%, Valid: 41.25% Test: 33.33%\n",
      "Run: 05, Epoch: 159, Loss: 0.7742, Train: 69.17%, Valid: 42.50% Test: 43.14%\n",
      "Run: 05, Epoch: 160, Loss: 0.9042, Train: 68.33%, Valid: 41.25% Test: 43.14%\n",
      "Run: 05, Epoch: 161, Loss: 0.7666, Train: 66.67%, Valid: 41.25% Test: 37.25%\n",
      "Run: 05, Epoch: 162, Loss: 0.7807, Train: 63.33%, Valid: 41.25% Test: 37.25%\n",
      "Run: 05, Epoch: 163, Loss: 0.8174, Train: 62.50%, Valid: 40.00% Test: 37.25%\n",
      "Run: 05, Epoch: 164, Loss: 0.7238, Train: 63.33%, Valid: 43.75% Test: 45.10%\n",
      "Run: 05, Epoch: 165, Loss: 0.7534, Train: 68.33%, Valid: 46.25% Test: 47.06%\n",
      "Run: 05, Epoch: 166, Loss: 0.8378, Train: 71.67%, Valid: 46.25% Test: 52.94%\n",
      "Run: 05, Epoch: 167, Loss: 0.7543, Train: 65.83%, Valid: 45.00% Test: 49.02%\n",
      "Run: 05, Epoch: 168, Loss: 0.7648, Train: 65.83%, Valid: 42.50% Test: 49.02%\n",
      "Run: 05, Epoch: 169, Loss: 0.7515, Train: 62.50%, Valid: 38.75% Test: 50.98%\n",
      "Run: 05, Epoch: 170, Loss: 0.7282, Train: 58.33%, Valid: 40.00% Test: 49.02%\n",
      "Run: 05, Epoch: 171, Loss: 0.7388, Train: 57.50%, Valid: 40.00% Test: 49.02%\n",
      "Run: 05, Epoch: 172, Loss: 0.7487, Train: 66.67%, Valid: 43.75% Test: 50.98%\n",
      "Run: 05, Epoch: 173, Loss: 0.8982, Train: 70.00%, Valid: 41.25% Test: 50.98%\n",
      "Run: 05, Epoch: 174, Loss: 0.7956, Train: 67.50%, Valid: 45.00% Test: 58.82%\n",
      "Run: 05, Epoch: 175, Loss: 0.7560, Train: 62.50%, Valid: 41.25% Test: 56.86%\n",
      "Run: 05, Epoch: 176, Loss: 0.7853, Train: 65.00%, Valid: 42.50% Test: 58.82%\n",
      "Run: 05, Epoch: 177, Loss: 0.7405, Train: 65.00%, Valid: 45.00% Test: 54.90%\n",
      "Run: 05, Epoch: 178, Loss: 0.7905, Train: 61.67%, Valid: 51.25% Test: 47.06%\n",
      "Run: 05, Epoch: 179, Loss: 0.8618, Train: 59.17%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 180, Loss: 0.8484, Train: 57.50%, Valid: 47.50% Test: 39.22%\n",
      "Run: 05, Epoch: 181, Loss: 0.8739, Train: 58.33%, Valid: 43.75% Test: 35.29%\n",
      "Run: 05, Epoch: 182, Loss: 0.7412, Train: 55.83%, Valid: 46.25% Test: 35.29%\n",
      "Run: 05, Epoch: 183, Loss: 0.6830, Train: 53.33%, Valid: 46.25% Test: 39.22%\n",
      "Run: 05, Epoch: 184, Loss: 0.7264, Train: 52.50%, Valid: 46.25% Test: 39.22%\n",
      "Run: 05, Epoch: 185, Loss: 0.7546, Train: 53.33%, Valid: 46.25% Test: 41.18%\n",
      "Run: 05, Epoch: 186, Loss: 0.7145, Train: 52.50%, Valid: 46.25% Test: 41.18%\n",
      "Run: 05, Epoch: 187, Loss: 0.7852, Train: 55.83%, Valid: 48.75% Test: 37.25%\n",
      "Run: 05, Epoch: 188, Loss: 0.7784, Train: 57.50%, Valid: 52.50% Test: 33.33%\n",
      "Run: 05, Epoch: 189, Loss: 0.7886, Train: 59.17%, Valid: 53.75% Test: 41.18%\n",
      "Run: 05, Epoch: 190, Loss: 0.8028, Train: 60.83%, Valid: 52.50% Test: 43.14%\n",
      "Run: 05, Epoch: 191, Loss: 0.8540, Train: 60.83%, Valid: 52.50% Test: 43.14%\n",
      "Run: 05, Epoch: 192, Loss: 0.7290, Train: 63.33%, Valid: 53.75% Test: 37.25%\n",
      "Run: 05, Epoch: 193, Loss: 0.7258, Train: 67.50%, Valid: 52.50% Test: 41.18%\n",
      "Run: 05, Epoch: 194, Loss: 0.8797, Train: 67.50%, Valid: 50.00% Test: 49.02%\n",
      "Run: 05, Epoch: 195, Loss: 0.7920, Train: 68.33%, Valid: 50.00% Test: 52.94%\n",
      "Run: 05, Epoch: 196, Loss: 0.7693, Train: 70.83%, Valid: 48.75% Test: 54.90%\n",
      "Run: 05, Epoch: 197, Loss: 0.7314, Train: 71.67%, Valid: 47.50% Test: 56.86%\n",
      "Run: 05, Epoch: 198, Loss: 0.7199, Train: 73.33%, Valid: 45.00% Test: 56.86%\n",
      "Run: 05, Epoch: 199, Loss: 0.7414, Train: 72.50%, Valid: 46.25% Test: 50.98%\n",
      "Run: 05, Epoch: 200, Loss: 0.8435, Train: 69.17%, Valid: 46.25% Test: 47.06%\n",
      "Run 05:\n",
      "Highest Train: 73.33\n",
      "Highest Valid: 60.00\n",
      "  Final Train: 60.00\n",
      "   Final Test: 54.90\n",
      "Run: 06, Epoch: 01, Loss: 1.6290, Train: 43.33%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 02, Loss: 1.3135, Train: 43.33%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 03, Loss: 1.2368, Train: 43.33%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 04, Loss: 1.1814, Train: 43.33%, Valid: 48.75% Test: 52.94%\n",
      "Run: 06, Epoch: 05, Loss: 1.1531, Train: 43.33%, Valid: 50.00% Test: 50.98%\n",
      "Run: 06, Epoch: 06, Loss: 1.1098, Train: 45.83%, Valid: 48.75% Test: 50.98%\n",
      "Run: 06, Epoch: 07, Loss: 1.1185, Train: 46.67%, Valid: 50.00% Test: 52.94%\n",
      "Run: 06, Epoch: 08, Loss: 1.0927, Train: 49.17%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 09, Loss: 1.0391, Train: 51.67%, Valid: 55.00% Test: 60.78%\n",
      "Run: 06, Epoch: 10, Loss: 1.0366, Train: 53.33%, Valid: 55.00% Test: 62.75%\n",
      "Run: 06, Epoch: 11, Loss: 1.0535, Train: 55.00%, Valid: 56.25% Test: 62.75%\n",
      "Run: 06, Epoch: 12, Loss: 1.0312, Train: 53.33%, Valid: 53.75% Test: 60.78%\n",
      "Run: 06, Epoch: 13, Loss: 1.0296, Train: 55.83%, Valid: 57.50% Test: 56.86%\n",
      "Run: 06, Epoch: 14, Loss: 0.9789, Train: 55.83%, Valid: 53.75% Test: 58.82%\n",
      "Run: 06, Epoch: 15, Loss: 0.9900, Train: 56.67%, Valid: 55.00% Test: 56.86%\n",
      "Run: 06, Epoch: 16, Loss: 1.0026, Train: 60.83%, Valid: 52.50% Test: 58.82%\n",
      "Run: 06, Epoch: 17, Loss: 0.9821, Train: 61.67%, Valid: 53.75% Test: 62.75%\n",
      "Run: 06, Epoch: 18, Loss: 0.9667, Train: 60.00%, Valid: 53.75% Test: 60.78%\n",
      "Run: 06, Epoch: 19, Loss: 0.9750, Train: 57.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 06, Epoch: 20, Loss: 0.9869, Train: 59.17%, Valid: 55.00% Test: 56.86%\n",
      "Run: 06, Epoch: 21, Loss: 0.9234, Train: 62.50%, Valid: 56.25% Test: 58.82%\n",
      "Run: 06, Epoch: 22, Loss: 0.8848, Train: 63.33%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 23, Loss: 0.9061, Train: 60.83%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 24, Loss: 0.8884, Train: 53.33%, Valid: 33.75% Test: 31.37%\n",
      "Run: 06, Epoch: 25, Loss: 1.0213, Train: 60.83%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 26, Loss: 0.8322, Train: 55.00%, Valid: 52.50% Test: 58.82%\n",
      "Run: 06, Epoch: 27, Loss: 0.9310, Train: 56.67%, Valid: 56.25% Test: 54.90%\n",
      "Run: 06, Epoch: 28, Loss: 0.9044, Train: 63.33%, Valid: 55.00% Test: 62.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 29, Loss: 0.8890, Train: 66.67%, Valid: 56.25% Test: 62.75%\n",
      "Run: 06, Epoch: 30, Loss: 0.9226, Train: 66.67%, Valid: 58.75% Test: 60.78%\n",
      "Run: 06, Epoch: 31, Loss: 0.9774, Train: 65.83%, Valid: 60.00% Test: 64.71%\n",
      "Run: 06, Epoch: 32, Loss: 0.8598, Train: 67.50%, Valid: 60.00% Test: 64.71%\n",
      "Run: 06, Epoch: 33, Loss: 0.7885, Train: 63.33%, Valid: 58.75% Test: 62.75%\n",
      "Run: 06, Epoch: 34, Loss: 0.8935, Train: 61.67%, Valid: 57.50% Test: 58.82%\n",
      "Run: 06, Epoch: 35, Loss: 0.8751, Train: 59.17%, Valid: 56.25% Test: 56.86%\n",
      "Run: 06, Epoch: 36, Loss: 0.7792, Train: 60.83%, Valid: 57.50% Test: 60.78%\n",
      "Run: 06, Epoch: 37, Loss: 0.8532, Train: 66.67%, Valid: 51.25% Test: 60.78%\n",
      "Run: 06, Epoch: 38, Loss: 0.8312, Train: 64.17%, Valid: 46.25% Test: 60.78%\n",
      "Run: 06, Epoch: 39, Loss: 0.8811, Train: 65.83%, Valid: 50.00% Test: 56.86%\n",
      "Run: 06, Epoch: 40, Loss: 0.8449, Train: 68.33%, Valid: 53.75% Test: 56.86%\n",
      "Run: 06, Epoch: 41, Loss: 0.8178, Train: 68.33%, Valid: 55.00% Test: 56.86%\n",
      "Run: 06, Epoch: 42, Loss: 0.9330, Train: 66.67%, Valid: 50.00% Test: 54.90%\n",
      "Run: 06, Epoch: 43, Loss: 0.9139, Train: 67.50%, Valid: 46.25% Test: 47.06%\n",
      "Run: 06, Epoch: 44, Loss: 0.9130, Train: 65.00%, Valid: 46.25% Test: 45.10%\n",
      "Run: 06, Epoch: 45, Loss: 0.8774, Train: 65.83%, Valid: 47.50% Test: 47.06%\n",
      "Run: 06, Epoch: 46, Loss: 0.9525, Train: 66.67%, Valid: 43.75% Test: 47.06%\n",
      "Run: 06, Epoch: 47, Loss: 0.9452, Train: 64.17%, Valid: 42.50% Test: 47.06%\n",
      "Run: 06, Epoch: 48, Loss: 0.9114, Train: 63.33%, Valid: 47.50% Test: 52.94%\n",
      "Run: 06, Epoch: 49, Loss: 0.9713, Train: 63.33%, Valid: 46.25% Test: 52.94%\n",
      "Run: 06, Epoch: 50, Loss: 0.9649, Train: 65.00%, Valid: 48.75% Test: 58.82%\n",
      "Run: 06, Epoch: 51, Loss: 0.8987, Train: 69.17%, Valid: 51.25% Test: 56.86%\n",
      "Run: 06, Epoch: 52, Loss: 0.8680, Train: 71.67%, Valid: 51.25% Test: 60.78%\n",
      "Run: 06, Epoch: 53, Loss: 0.8531, Train: 72.50%, Valid: 55.00% Test: 62.75%\n",
      "Run: 06, Epoch: 54, Loss: 0.9020, Train: 70.83%, Valid: 56.25% Test: 64.71%\n",
      "Run: 06, Epoch: 55, Loss: 0.8751, Train: 70.00%, Valid: 57.50% Test: 66.67%\n",
      "Run: 06, Epoch: 56, Loss: 0.8474, Train: 67.50%, Valid: 55.00% Test: 62.75%\n",
      "Run: 06, Epoch: 57, Loss: 0.8507, Train: 65.00%, Valid: 52.50% Test: 62.75%\n",
      "Run: 06, Epoch: 58, Loss: 0.8471, Train: 64.17%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 59, Loss: 0.8326, Train: 59.17%, Valid: 48.75% Test: 60.78%\n",
      "Run: 06, Epoch: 60, Loss: 0.8473, Train: 56.67%, Valid: 51.25% Test: 58.82%\n",
      "Run: 06, Epoch: 61, Loss: 0.8489, Train: 57.50%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 62, Loss: 0.7623, Train: 57.50%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 63, Loss: 0.8794, Train: 60.83%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 64, Loss: 0.8467, Train: 61.67%, Valid: 55.00% Test: 60.78%\n",
      "Run: 06, Epoch: 65, Loss: 0.8627, Train: 64.17%, Valid: 55.00% Test: 62.75%\n",
      "Run: 06, Epoch: 66, Loss: 0.8955, Train: 65.83%, Valid: 53.75% Test: 62.75%\n",
      "Run: 06, Epoch: 67, Loss: 0.7847, Train: 68.33%, Valid: 55.00% Test: 62.75%\n",
      "Run: 06, Epoch: 68, Loss: 0.8290, Train: 73.33%, Valid: 55.00% Test: 64.71%\n",
      "Run: 06, Epoch: 69, Loss: 0.7974, Train: 67.50%, Valid: 56.25% Test: 68.63%\n",
      "Run: 06, Epoch: 70, Loss: 0.8836, Train: 65.83%, Valid: 58.75% Test: 66.67%\n",
      "Run: 06, Epoch: 71, Loss: 0.7928, Train: 60.83%, Valid: 57.50% Test: 64.71%\n",
      "Run: 06, Epoch: 72, Loss: 0.8328, Train: 60.00%, Valid: 52.50% Test: 56.86%\n",
      "Run: 06, Epoch: 73, Loss: 0.8376, Train: 60.00%, Valid: 52.50% Test: 56.86%\n",
      "Run: 06, Epoch: 74, Loss: 0.8215, Train: 62.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 06, Epoch: 75, Loss: 0.7222, Train: 65.83%, Valid: 55.00% Test: 62.75%\n",
      "Run: 06, Epoch: 76, Loss: 0.8046, Train: 69.17%, Valid: 56.25% Test: 60.78%\n",
      "Run: 06, Epoch: 77, Loss: 0.8021, Train: 68.33%, Valid: 57.50% Test: 58.82%\n",
      "Run: 06, Epoch: 78, Loss: 0.7961, Train: 68.33%, Valid: 55.00% Test: 60.78%\n",
      "Run: 06, Epoch: 79, Loss: 0.8203, Train: 68.33%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 80, Loss: 0.7060, Train: 70.00%, Valid: 53.75% Test: 60.78%\n",
      "Run: 06, Epoch: 81, Loss: 0.8332, Train: 69.17%, Valid: 53.75% Test: 60.78%\n",
      "Run: 06, Epoch: 82, Loss: 0.7415, Train: 68.33%, Valid: 51.25% Test: 60.78%\n",
      "Run: 06, Epoch: 83, Loss: 0.7646, Train: 68.33%, Valid: 48.75% Test: 58.82%\n",
      "Run: 06, Epoch: 84, Loss: 0.8458, Train: 60.83%, Valid: 46.25% Test: 54.90%\n",
      "Run: 06, Epoch: 85, Loss: 0.7834, Train: 55.00%, Valid: 46.25% Test: 50.98%\n",
      "Run: 06, Epoch: 86, Loss: 0.8295, Train: 50.83%, Valid: 45.00% Test: 47.06%\n",
      "Run: 06, Epoch: 87, Loss: 0.8894, Train: 55.83%, Valid: 43.75% Test: 47.06%\n",
      "Run: 06, Epoch: 88, Loss: 0.8139, Train: 62.50%, Valid: 41.25% Test: 60.78%\n",
      "Run: 06, Epoch: 89, Loss: 0.7232, Train: 63.33%, Valid: 45.00% Test: 52.94%\n",
      "Run: 06, Epoch: 90, Loss: 0.7970, Train: 67.50%, Valid: 47.50% Test: 58.82%\n",
      "Run: 06, Epoch: 91, Loss: 0.7594, Train: 68.33%, Valid: 48.75% Test: 58.82%\n",
      "Run: 06, Epoch: 92, Loss: 0.7426, Train: 72.50%, Valid: 53.75% Test: 60.78%\n",
      "Run: 06, Epoch: 93, Loss: 0.7944, Train: 71.67%, Valid: 56.25% Test: 64.71%\n",
      "Run: 06, Epoch: 94, Loss: 0.7358, Train: 69.17%, Valid: 60.00% Test: 66.67%\n",
      "Run: 06, Epoch: 95, Loss: 0.7344, Train: 67.50%, Valid: 58.75% Test: 64.71%\n",
      "Run: 06, Epoch: 96, Loss: 0.7303, Train: 69.17%, Valid: 56.25% Test: 60.78%\n",
      "Run: 06, Epoch: 97, Loss: 0.7482, Train: 69.17%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 98, Loss: 0.7225, Train: 68.33%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 99, Loss: 0.7271, Train: 71.67%, Valid: 56.25% Test: 62.75%\n",
      "Run: 06, Epoch: 100, Loss: 0.7129, Train: 75.00%, Valid: 55.00% Test: 66.67%\n",
      "Run: 06, Epoch: 101, Loss: 0.7693, Train: 73.33%, Valid: 51.25% Test: 62.75%\n",
      "Run: 06, Epoch: 102, Loss: 0.7994, Train: 79.17%, Valid: 53.75% Test: 60.78%\n",
      "Run: 06, Epoch: 103, Loss: 0.7921, Train: 74.17%, Valid: 51.25% Test: 56.86%\n",
      "Run: 06, Epoch: 104, Loss: 0.7429, Train: 73.33%, Valid: 50.00% Test: 58.82%\n",
      "Run: 06, Epoch: 105, Loss: 0.7470, Train: 67.50%, Valid: 53.75% Test: 60.78%\n",
      "Run: 06, Epoch: 106, Loss: 0.9179, Train: 70.83%, Valid: 56.25% Test: 60.78%\n",
      "Run: 06, Epoch: 107, Loss: 0.6698, Train: 69.17%, Valid: 52.50% Test: 62.75%\n",
      "Run: 06, Epoch: 108, Loss: 0.6469, Train: 70.83%, Valid: 51.25% Test: 62.75%\n",
      "Run: 06, Epoch: 109, Loss: 0.7852, Train: 72.50%, Valid: 50.00% Test: 62.75%\n",
      "Run: 06, Epoch: 110, Loss: 0.6720, Train: 75.00%, Valid: 53.75% Test: 62.75%\n",
      "Run: 06, Epoch: 111, Loss: 0.6730, Train: 75.83%, Valid: 57.50% Test: 62.75%\n",
      "Run: 06, Epoch: 112, Loss: 0.7431, Train: 73.33%, Valid: 56.25% Test: 66.67%\n",
      "Run: 06, Epoch: 113, Loss: 0.7677, Train: 65.83%, Valid: 53.75% Test: 58.82%\n",
      "Run: 06, Epoch: 114, Loss: 0.7789, Train: 67.50%, Valid: 52.50% Test: 56.86%\n",
      "Run: 06, Epoch: 115, Loss: 0.8596, Train: 73.33%, Valid: 52.50% Test: 62.75%\n",
      "Run: 06, Epoch: 116, Loss: 0.7074, Train: 76.67%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 117, Loss: 0.6928, Train: 72.50%, Valid: 48.75% Test: 49.02%\n",
      "Run: 06, Epoch: 118, Loss: 0.6523, Train: 70.83%, Valid: 47.50% Test: 50.98%\n",
      "Run: 06, Epoch: 119, Loss: 0.6322, Train: 73.33%, Valid: 46.25% Test: 56.86%\n",
      "Run: 06, Epoch: 120, Loss: 0.7013, Train: 75.00%, Valid: 45.00% Test: 56.86%\n",
      "Run: 06, Epoch: 121, Loss: 0.6793, Train: 76.67%, Valid: 47.50% Test: 56.86%\n",
      "Run: 06, Epoch: 122, Loss: 0.6863, Train: 75.83%, Valid: 46.25% Test: 58.82%\n",
      "Run: 06, Epoch: 123, Loss: 0.7099, Train: 73.33%, Valid: 45.00% Test: 52.94%\n",
      "Run: 06, Epoch: 124, Loss: 0.7152, Train: 73.33%, Valid: 51.25% Test: 60.78%\n",
      "Run: 06, Epoch: 125, Loss: 0.6976, Train: 73.33%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 126, Loss: 0.6464, Train: 72.50%, Valid: 51.25% Test: 60.78%\n",
      "Run: 06, Epoch: 127, Loss: 0.8018, Train: 75.83%, Valid: 50.00% Test: 60.78%\n",
      "Run: 06, Epoch: 128, Loss: 0.6631, Train: 75.83%, Valid: 47.50% Test: 56.86%\n",
      "Run: 06, Epoch: 129, Loss: 0.6635, Train: 66.67%, Valid: 46.25% Test: 45.10%\n",
      "Run: 06, Epoch: 130, Loss: 0.6650, Train: 75.83%, Valid: 51.25% Test: 68.63%\n",
      "Run: 06, Epoch: 131, Loss: 0.6646, Train: 68.33%, Valid: 58.75% Test: 64.71%\n",
      "Run: 06, Epoch: 132, Loss: 0.7257, Train: 65.83%, Valid: 58.75% Test: 62.75%\n",
      "Run: 06, Epoch: 133, Loss: 0.7371, Train: 66.67%, Valid: 57.50% Test: 66.67%\n",
      "Run: 06, Epoch: 134, Loss: 0.7104, Train: 72.50%, Valid: 56.25% Test: 64.71%\n",
      "Run: 06, Epoch: 135, Loss: 0.7320, Train: 76.67%, Valid: 55.00% Test: 70.59%\n",
      "Run: 06, Epoch: 136, Loss: 0.6911, Train: 70.83%, Valid: 43.75% Test: 50.98%\n",
      "Run: 06, Epoch: 137, Loss: 0.7129, Train: 70.83%, Valid: 46.25% Test: 56.86%\n",
      "Run: 06, Epoch: 138, Loss: 0.6982, Train: 73.33%, Valid: 45.00% Test: 56.86%\n",
      "Run: 06, Epoch: 139, Loss: 0.7761, Train: 70.00%, Valid: 43.75% Test: 58.82%\n",
      "Run: 06, Epoch: 140, Loss: 0.6896, Train: 65.00%, Valid: 40.00% Test: 50.98%\n",
      "Run: 06, Epoch: 141, Loss: 0.7192, Train: 60.83%, Valid: 40.00% Test: 49.02%\n",
      "Run: 06, Epoch: 142, Loss: 0.6709, Train: 55.83%, Valid: 38.75% Test: 43.14%\n",
      "Run: 06, Epoch: 143, Loss: 0.7448, Train: 60.83%, Valid: 47.50% Test: 50.98%\n",
      "Run: 06, Epoch: 144, Loss: 0.6892, Train: 68.33%, Valid: 50.00% Test: 56.86%\n",
      "Run: 06, Epoch: 145, Loss: 0.6097, Train: 77.50%, Valid: 48.75% Test: 66.67%\n",
      "Run: 06, Epoch: 146, Loss: 0.6838, Train: 75.83%, Valid: 53.75% Test: 66.67%\n",
      "Run: 06, Epoch: 147, Loss: 0.6035, Train: 78.33%, Valid: 57.50% Test: 62.75%\n",
      "Run: 06, Epoch: 148, Loss: 0.6395, Train: 73.33%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 149, Loss: 0.7529, Train: 75.83%, Valid: 58.75% Test: 70.59%\n",
      "Run: 06, Epoch: 150, Loss: 0.6846, Train: 72.50%, Valid: 57.50% Test: 70.59%\n",
      "Run: 06, Epoch: 151, Loss: 0.6419, Train: 70.83%, Valid: 56.25% Test: 70.59%\n",
      "Run: 06, Epoch: 152, Loss: 0.6629, Train: 75.83%, Valid: 60.00% Test: 72.55%\n",
      "Run: 06, Epoch: 153, Loss: 0.6543, Train: 78.33%, Valid: 55.00% Test: 58.82%\n",
      "Run: 06, Epoch: 154, Loss: 0.7010, Train: 68.33%, Valid: 46.25% Test: 41.18%\n",
      "Run: 06, Epoch: 155, Loss: 0.6701, Train: 75.83%, Valid: 55.00% Test: 52.94%\n",
      "Run: 06, Epoch: 156, Loss: 0.6947, Train: 75.00%, Valid: 56.25% Test: 60.78%\n",
      "Run: 06, Epoch: 157, Loss: 0.7675, Train: 71.67%, Valid: 55.00% Test: 66.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 158, Loss: 0.6799, Train: 75.00%, Valid: 53.75% Test: 64.71%\n",
      "Run: 06, Epoch: 159, Loss: 0.7285, Train: 80.00%, Valid: 48.75% Test: 62.75%\n",
      "Run: 06, Epoch: 160, Loss: 0.5889, Train: 75.00%, Valid: 46.25% Test: 54.90%\n",
      "Run: 06, Epoch: 161, Loss: 0.5768, Train: 75.83%, Valid: 46.25% Test: 50.98%\n",
      "Run: 06, Epoch: 162, Loss: 0.6708, Train: 77.50%, Valid: 47.50% Test: 60.78%\n",
      "Run: 06, Epoch: 163, Loss: 0.5609, Train: 81.67%, Valid: 51.25% Test: 70.59%\n",
      "Run: 06, Epoch: 164, Loss: 0.5395, Train: 75.83%, Valid: 53.75% Test: 68.63%\n",
      "Run: 06, Epoch: 165, Loss: 0.5921, Train: 73.33%, Valid: 55.00% Test: 76.47%\n",
      "Run: 06, Epoch: 166, Loss: 0.5910, Train: 75.00%, Valid: 56.25% Test: 74.51%\n",
      "Run: 06, Epoch: 167, Loss: 0.6880, Train: 75.00%, Valid: 48.75% Test: 60.78%\n",
      "Run: 06, Epoch: 168, Loss: 0.6925, Train: 75.83%, Valid: 51.25% Test: 58.82%\n",
      "Run: 06, Epoch: 169, Loss: 0.6518, Train: 75.83%, Valid: 56.25% Test: 64.71%\n",
      "Run: 06, Epoch: 170, Loss: 0.6402, Train: 78.33%, Valid: 56.25% Test: 60.78%\n",
      "Run: 06, Epoch: 171, Loss: 0.6429, Train: 80.00%, Valid: 52.50% Test: 56.86%\n",
      "Run: 06, Epoch: 172, Loss: 0.5329, Train: 84.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 06, Epoch: 173, Loss: 0.6284, Train: 84.17%, Valid: 52.50% Test: 54.90%\n",
      "Run: 06, Epoch: 174, Loss: 0.5358, Train: 81.67%, Valid: 50.00% Test: 54.90%\n",
      "Run: 06, Epoch: 175, Loss: 0.6390, Train: 80.83%, Valid: 51.25% Test: 62.75%\n",
      "Run: 06, Epoch: 176, Loss: 0.6202, Train: 79.17%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 177, Loss: 0.5866, Train: 74.17%, Valid: 43.75% Test: 50.98%\n",
      "Run: 06, Epoch: 178, Loss: 0.5712, Train: 76.67%, Valid: 45.00% Test: 58.82%\n",
      "Run: 06, Epoch: 179, Loss: 0.6422, Train: 72.50%, Valid: 50.00% Test: 56.86%\n",
      "Run: 06, Epoch: 180, Loss: 0.5747, Train: 72.50%, Valid: 50.00% Test: 58.82%\n",
      "Run: 06, Epoch: 181, Loss: 0.6180, Train: 74.17%, Valid: 48.75% Test: 56.86%\n",
      "Run: 06, Epoch: 182, Loss: 0.6137, Train: 75.83%, Valid: 52.50% Test: 62.75%\n",
      "Run: 06, Epoch: 183, Loss: 0.6308, Train: 81.67%, Valid: 58.75% Test: 72.55%\n",
      "Run: 06, Epoch: 184, Loss: 0.6982, Train: 81.67%, Valid: 57.50% Test: 70.59%\n",
      "Run: 06, Epoch: 185, Loss: 0.5271, Train: 83.33%, Valid: 55.00% Test: 64.71%\n",
      "Run: 06, Epoch: 186, Loss: 0.6537, Train: 79.17%, Valid: 55.00% Test: 50.98%\n",
      "Run: 06, Epoch: 187, Loss: 0.5617, Train: 80.00%, Valid: 58.75% Test: 56.86%\n",
      "Run: 06, Epoch: 188, Loss: 0.5785, Train: 80.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 06, Epoch: 189, Loss: 0.5706, Train: 75.83%, Valid: 58.75% Test: 60.78%\n",
      "Run: 06, Epoch: 190, Loss: 0.6209, Train: 76.67%, Valid: 53.75% Test: 68.63%\n",
      "Run: 06, Epoch: 191, Loss: 0.5605, Train: 75.00%, Valid: 53.75% Test: 60.78%\n",
      "Run: 06, Epoch: 192, Loss: 0.6061, Train: 75.00%, Valid: 50.00% Test: 60.78%\n",
      "Run: 06, Epoch: 193, Loss: 0.5906, Train: 75.00%, Valid: 52.50% Test: 60.78%\n",
      "Run: 06, Epoch: 194, Loss: 0.6506, Train: 75.83%, Valid: 51.25% Test: 60.78%\n",
      "Run: 06, Epoch: 195, Loss: 0.5557, Train: 75.83%, Valid: 53.75% Test: 60.78%\n",
      "Run: 06, Epoch: 196, Loss: 0.6689, Train: 73.33%, Valid: 51.25% Test: 60.78%\n",
      "Run: 06, Epoch: 197, Loss: 0.5630, Train: 80.00%, Valid: 55.00% Test: 66.67%\n",
      "Run: 06, Epoch: 198, Loss: 0.5655, Train: 73.33%, Valid: 56.25% Test: 74.51%\n",
      "Run: 06, Epoch: 199, Loss: 0.6719, Train: 75.00%, Valid: 57.50% Test: 76.47%\n",
      "Run: 06, Epoch: 200, Loss: 0.6990, Train: 82.50%, Valid: 52.50% Test: 62.75%\n",
      "Run 06:\n",
      "Highest Train: 84.17\n",
      "Highest Valid: 60.00\n",
      "  Final Train: 65.83\n",
      "   Final Test: 64.71\n",
      "Run: 07, Epoch: 01, Loss: 1.7835, Train: 31.67%, Valid: 21.25% Test: 29.41%\n",
      "Run: 07, Epoch: 02, Loss: 1.3933, Train: 34.17%, Valid: 21.25% Test: 33.33%\n",
      "Run: 07, Epoch: 03, Loss: 1.2489, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 04, Loss: 1.1719, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 05, Loss: 1.2452, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 06, Loss: 1.2262, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 07, Loss: 1.2289, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 08, Loss: 1.2183, Train: 49.17%, Valid: 52.50% Test: 49.02%\n",
      "Run: 07, Epoch: 09, Loss: 1.1774, Train: 58.33%, Valid: 56.25% Test: 54.90%\n",
      "Run: 07, Epoch: 10, Loss: 1.1387, Train: 62.50%, Valid: 53.75% Test: 64.71%\n",
      "Run: 07, Epoch: 11, Loss: 1.1080, Train: 58.33%, Valid: 55.00% Test: 62.75%\n",
      "Run: 07, Epoch: 12, Loss: 1.1162, Train: 57.50%, Valid: 57.50% Test: 58.82%\n",
      "Run: 07, Epoch: 13, Loss: 1.1172, Train: 58.33%, Valid: 60.00% Test: 54.90%\n",
      "Run: 07, Epoch: 14, Loss: 1.0963, Train: 57.50%, Valid: 63.75% Test: 58.82%\n",
      "Run: 07, Epoch: 15, Loss: 1.1190, Train: 59.17%, Valid: 65.00% Test: 58.82%\n",
      "Run: 07, Epoch: 16, Loss: 1.1057, Train: 57.50%, Valid: 58.75% Test: 60.78%\n",
      "Run: 07, Epoch: 17, Loss: 1.0685, Train: 60.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 07, Epoch: 18, Loss: 1.1076, Train: 61.67%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 19, Loss: 1.0506, Train: 61.67%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 20, Loss: 1.0200, Train: 61.67%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 21, Loss: 1.0375, Train: 60.83%, Valid: 63.75% Test: 68.63%\n",
      "Run: 07, Epoch: 22, Loss: 1.0669, Train: 59.17%, Valid: 62.50% Test: 62.75%\n",
      "Run: 07, Epoch: 23, Loss: 1.0065, Train: 60.00%, Valid: 60.00% Test: 66.67%\n",
      "Run: 07, Epoch: 24, Loss: 1.0362, Train: 60.00%, Valid: 60.00% Test: 66.67%\n",
      "Run: 07, Epoch: 25, Loss: 0.9826, Train: 60.83%, Valid: 60.00% Test: 66.67%\n",
      "Run: 07, Epoch: 26, Loss: 1.0112, Train: 60.83%, Valid: 58.75% Test: 66.67%\n",
      "Run: 07, Epoch: 27, Loss: 0.9717, Train: 64.17%, Valid: 57.50% Test: 70.59%\n",
      "Run: 07, Epoch: 28, Loss: 1.0094, Train: 63.33%, Valid: 60.00% Test: 70.59%\n",
      "Run: 07, Epoch: 29, Loss: 0.9626, Train: 61.67%, Valid: 60.00% Test: 72.55%\n",
      "Run: 07, Epoch: 30, Loss: 0.9715, Train: 60.83%, Valid: 56.25% Test: 74.51%\n",
      "Run: 07, Epoch: 31, Loss: 0.9633, Train: 59.17%, Valid: 50.00% Test: 60.78%\n",
      "Run: 07, Epoch: 32, Loss: 0.9406, Train: 57.50%, Valid: 52.50% Test: 60.78%\n",
      "Run: 07, Epoch: 33, Loss: 0.9239, Train: 59.17%, Valid: 51.25% Test: 56.86%\n",
      "Run: 07, Epoch: 34, Loss: 0.9193, Train: 60.83%, Valid: 55.00% Test: 66.67%\n",
      "Run: 07, Epoch: 35, Loss: 1.0119, Train: 60.83%, Valid: 55.00% Test: 64.71%\n",
      "Run: 07, Epoch: 36, Loss: 0.9801, Train: 58.33%, Valid: 60.00% Test: 64.71%\n",
      "Run: 07, Epoch: 37, Loss: 1.0644, Train: 60.83%, Valid: 62.50% Test: 62.75%\n",
      "Run: 07, Epoch: 38, Loss: 0.9501, Train: 61.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 07, Epoch: 39, Loss: 0.9915, Train: 69.17%, Valid: 63.75% Test: 68.63%\n",
      "Run: 07, Epoch: 40, Loss: 0.9263, Train: 61.67%, Valid: 53.75% Test: 60.78%\n",
      "Run: 07, Epoch: 41, Loss: 0.9805, Train: 64.17%, Valid: 51.25% Test: 60.78%\n",
      "Run: 07, Epoch: 42, Loss: 0.9594, Train: 65.00%, Valid: 52.50% Test: 62.75%\n",
      "Run: 07, Epoch: 43, Loss: 0.9003, Train: 63.33%, Valid: 56.25% Test: 45.10%\n",
      "Run: 07, Epoch: 44, Loss: 0.9793, Train: 60.83%, Valid: 50.00% Test: 41.18%\n",
      "Run: 07, Epoch: 45, Loss: 0.9262, Train: 64.17%, Valid: 52.50% Test: 60.78%\n",
      "Run: 07, Epoch: 46, Loss: 0.8879, Train: 61.67%, Valid: 52.50% Test: 52.94%\n",
      "Run: 07, Epoch: 47, Loss: 0.9431, Train: 59.17%, Valid: 51.25% Test: 50.98%\n",
      "Run: 07, Epoch: 48, Loss: 1.0390, Train: 57.50%, Valid: 50.00% Test: 52.94%\n",
      "Run: 07, Epoch: 49, Loss: 0.9903, Train: 58.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 07, Epoch: 50, Loss: 0.9785, Train: 62.50%, Valid: 53.75% Test: 54.90%\n",
      "Run: 07, Epoch: 51, Loss: 1.0248, Train: 60.83%, Valid: 55.00% Test: 52.94%\n",
      "Run: 07, Epoch: 52, Loss: 0.9933, Train: 61.67%, Valid: 57.50% Test: 54.90%\n",
      "Run: 07, Epoch: 53, Loss: 0.9595, Train: 57.50%, Valid: 55.00% Test: 50.98%\n",
      "Run: 07, Epoch: 54, Loss: 0.9488, Train: 59.17%, Valid: 56.25% Test: 49.02%\n",
      "Run: 07, Epoch: 55, Loss: 1.0074, Train: 60.00%, Valid: 55.00% Test: 52.94%\n",
      "Run: 07, Epoch: 56, Loss: 0.9430, Train: 61.67%, Valid: 57.50% Test: 50.98%\n",
      "Run: 07, Epoch: 57, Loss: 0.9872, Train: 65.00%, Valid: 56.25% Test: 50.98%\n",
      "Run: 07, Epoch: 58, Loss: 0.9880, Train: 60.83%, Valid: 56.25% Test: 45.10%\n",
      "Run: 07, Epoch: 59, Loss: 0.9134, Train: 61.67%, Valid: 56.25% Test: 43.14%\n",
      "Run: 07, Epoch: 60, Loss: 0.9284, Train: 62.50%, Valid: 58.75% Test: 47.06%\n",
      "Run: 07, Epoch: 61, Loss: 0.9493, Train: 63.33%, Valid: 56.25% Test: 50.98%\n",
      "Run: 07, Epoch: 62, Loss: 0.8913, Train: 61.67%, Valid: 57.50% Test: 54.90%\n",
      "Run: 07, Epoch: 63, Loss: 0.9268, Train: 62.50%, Valid: 56.25% Test: 56.86%\n",
      "Run: 07, Epoch: 64, Loss: 0.9409, Train: 60.00%, Valid: 58.75% Test: 54.90%\n",
      "Run: 07, Epoch: 65, Loss: 0.8665, Train: 62.50%, Valid: 53.75% Test: 52.94%\n",
      "Run: 07, Epoch: 66, Loss: 0.9333, Train: 65.00%, Valid: 48.75% Test: 50.98%\n",
      "Run: 07, Epoch: 67, Loss: 0.9469, Train: 63.33%, Valid: 48.75% Test: 45.10%\n",
      "Run: 07, Epoch: 68, Loss: 0.9596, Train: 61.67%, Valid: 47.50% Test: 43.14%\n",
      "Run: 07, Epoch: 69, Loss: 0.9070, Train: 61.67%, Valid: 45.00% Test: 45.10%\n",
      "Run: 07, Epoch: 70, Loss: 0.9075, Train: 64.17%, Valid: 42.50% Test: 47.06%\n",
      "Run: 07, Epoch: 71, Loss: 0.8857, Train: 65.00%, Valid: 45.00% Test: 47.06%\n",
      "Run: 07, Epoch: 72, Loss: 0.8305, Train: 67.50%, Valid: 56.25% Test: 54.90%\n",
      "Run: 07, Epoch: 73, Loss: 0.7971, Train: 66.67%, Valid: 58.75% Test: 56.86%\n",
      "Run: 07, Epoch: 74, Loss: 0.9197, Train: 67.50%, Valid: 56.25% Test: 56.86%\n",
      "Run: 07, Epoch: 75, Loss: 0.8719, Train: 66.67%, Valid: 51.25% Test: 56.86%\n",
      "Run: 07, Epoch: 76, Loss: 0.7924, Train: 65.83%, Valid: 45.00% Test: 52.94%\n",
      "Run: 07, Epoch: 77, Loss: 0.8714, Train: 63.33%, Valid: 50.00% Test: 58.82%\n",
      "Run: 07, Epoch: 78, Loss: 0.8303, Train: 65.00%, Valid: 50.00% Test: 58.82%\n",
      "Run: 07, Epoch: 79, Loss: 0.7987, Train: 67.50%, Valid: 48.75% Test: 50.98%\n",
      "Run: 07, Epoch: 80, Loss: 0.8041, Train: 66.67%, Valid: 50.00% Test: 50.98%\n",
      "Run: 07, Epoch: 81, Loss: 0.8175, Train: 68.33%, Valid: 53.75% Test: 52.94%\n",
      "Run: 07, Epoch: 82, Loss: 0.8224, Train: 68.33%, Valid: 53.75% Test: 50.98%\n",
      "Run: 07, Epoch: 83, Loss: 0.7573, Train: 64.17%, Valid: 51.25% Test: 49.02%\n",
      "Run: 07, Epoch: 84, Loss: 0.7189, Train: 63.33%, Valid: 48.75% Test: 49.02%\n",
      "Run: 07, Epoch: 85, Loss: 0.7702, Train: 65.83%, Valid: 56.25% Test: 56.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 86, Loss: 0.7598, Train: 66.67%, Valid: 57.50% Test: 54.90%\n",
      "Run: 07, Epoch: 87, Loss: 0.7895, Train: 62.50%, Valid: 53.75% Test: 54.90%\n",
      "Run: 07, Epoch: 88, Loss: 0.7949, Train: 69.17%, Valid: 55.00% Test: 56.86%\n",
      "Run: 07, Epoch: 89, Loss: 0.7158, Train: 70.00%, Valid: 62.50% Test: 62.75%\n",
      "Run: 07, Epoch: 90, Loss: 0.7965, Train: 64.17%, Valid: 58.75% Test: 60.78%\n",
      "Run: 07, Epoch: 91, Loss: 0.8045, Train: 75.83%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 92, Loss: 0.7320, Train: 63.33%, Valid: 61.25% Test: 64.71%\n",
      "Run: 07, Epoch: 93, Loss: 0.7121, Train: 59.17%, Valid: 62.50% Test: 66.67%\n",
      "Run: 07, Epoch: 94, Loss: 0.8499, Train: 58.33%, Valid: 65.00% Test: 64.71%\n",
      "Run: 07, Epoch: 95, Loss: 0.7579, Train: 65.00%, Valid: 67.50% Test: 60.78%\n",
      "Run: 07, Epoch: 96, Loss: 0.7348, Train: 70.00%, Valid: 61.25% Test: 58.82%\n",
      "Run: 07, Epoch: 97, Loss: 0.8069, Train: 67.50%, Valid: 66.25% Test: 58.82%\n",
      "Run: 07, Epoch: 98, Loss: 0.7740, Train: 65.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 07, Epoch: 99, Loss: 0.6897, Train: 65.83%, Valid: 63.75% Test: 66.67%\n",
      "Run: 07, Epoch: 100, Loss: 0.7358, Train: 70.00%, Valid: 65.00% Test: 68.63%\n",
      "Run: 07, Epoch: 101, Loss: 0.6610, Train: 66.67%, Valid: 48.75% Test: 49.02%\n",
      "Run: 07, Epoch: 102, Loss: 0.7035, Train: 49.17%, Valid: 32.50% Test: 35.29%\n",
      "Run: 07, Epoch: 103, Loss: 0.8140, Train: 65.83%, Valid: 58.75% Test: 60.78%\n",
      "Run: 07, Epoch: 104, Loss: 0.6922, Train: 65.00%, Valid: 61.25% Test: 64.71%\n",
      "Run: 07, Epoch: 105, Loss: 0.7940, Train: 65.00%, Valid: 61.25% Test: 70.59%\n",
      "Run: 07, Epoch: 106, Loss: 0.8077, Train: 65.83%, Valid: 62.50% Test: 62.75%\n",
      "Run: 07, Epoch: 107, Loss: 0.8222, Train: 64.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 07, Epoch: 108, Loss: 0.7684, Train: 70.83%, Valid: 53.75% Test: 54.90%\n",
      "Run: 07, Epoch: 109, Loss: 0.7481, Train: 61.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 07, Epoch: 110, Loss: 0.7389, Train: 62.50%, Valid: 56.25% Test: 58.82%\n",
      "Run: 07, Epoch: 111, Loss: 0.7932, Train: 66.67%, Valid: 52.50% Test: 54.90%\n",
      "Run: 07, Epoch: 112, Loss: 0.6408, Train: 66.67%, Valid: 51.25% Test: 49.02%\n",
      "Run: 07, Epoch: 113, Loss: 0.7638, Train: 64.17%, Valid: 53.75% Test: 52.94%\n",
      "Run: 07, Epoch: 114, Loss: 0.7148, Train: 65.83%, Valid: 52.50% Test: 56.86%\n",
      "Run: 07, Epoch: 115, Loss: 0.6812, Train: 71.67%, Valid: 55.00% Test: 60.78%\n",
      "Run: 07, Epoch: 116, Loss: 0.7712, Train: 72.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 07, Epoch: 117, Loss: 0.6751, Train: 69.17%, Valid: 58.75% Test: 64.71%\n",
      "Run: 07, Epoch: 118, Loss: 0.6251, Train: 74.17%, Valid: 61.25% Test: 64.71%\n",
      "Run: 07, Epoch: 119, Loss: 0.6933, Train: 77.50%, Valid: 63.75% Test: 70.59%\n",
      "Run: 07, Epoch: 120, Loss: 0.6518, Train: 73.33%, Valid: 63.75% Test: 66.67%\n",
      "Run: 07, Epoch: 121, Loss: 0.6462, Train: 73.33%, Valid: 61.25% Test: 70.59%\n",
      "Run: 07, Epoch: 122, Loss: 0.6402, Train: 75.00%, Valid: 56.25% Test: 68.63%\n",
      "Run: 07, Epoch: 123, Loss: 0.6392, Train: 66.67%, Valid: 52.50% Test: 56.86%\n",
      "Run: 07, Epoch: 124, Loss: 0.6465, Train: 65.00%, Valid: 56.25% Test: 56.86%\n",
      "Run: 07, Epoch: 125, Loss: 0.6933, Train: 63.33%, Valid: 56.25% Test: 56.86%\n",
      "Run: 07, Epoch: 126, Loss: 0.6234, Train: 67.50%, Valid: 53.75% Test: 52.94%\n",
      "Run: 07, Epoch: 127, Loss: 0.5592, Train: 70.00%, Valid: 53.75% Test: 54.90%\n",
      "Run: 07, Epoch: 128, Loss: 0.6828, Train: 74.17%, Valid: 58.75% Test: 62.75%\n",
      "Run: 07, Epoch: 129, Loss: 0.5911, Train: 75.83%, Valid: 63.75% Test: 66.67%\n",
      "Run: 07, Epoch: 130, Loss: 0.5925, Train: 74.17%, Valid: 73.75% Test: 66.67%\n",
      "Run: 07, Epoch: 131, Loss: 0.6107, Train: 69.17%, Valid: 72.50% Test: 66.67%\n",
      "Run: 07, Epoch: 132, Loss: 0.6606, Train: 75.00%, Valid: 65.00% Test: 66.67%\n",
      "Run: 07, Epoch: 133, Loss: 0.6479, Train: 75.83%, Valid: 63.75% Test: 62.75%\n",
      "Run: 07, Epoch: 134, Loss: 0.6142, Train: 60.00%, Valid: 47.50% Test: 43.14%\n",
      "Run: 07, Epoch: 135, Loss: 0.7294, Train: 72.50%, Valid: 58.75% Test: 60.78%\n",
      "Run: 07, Epoch: 136, Loss: 0.7198, Train: 75.00%, Valid: 58.75% Test: 56.86%\n",
      "Run: 07, Epoch: 137, Loss: 0.6650, Train: 69.17%, Valid: 58.75% Test: 52.94%\n",
      "Run: 07, Epoch: 138, Loss: 0.5894, Train: 60.83%, Valid: 51.25% Test: 49.02%\n",
      "Run: 07, Epoch: 139, Loss: 0.5932, Train: 60.83%, Valid: 50.00% Test: 49.02%\n",
      "Run: 07, Epoch: 140, Loss: 0.7168, Train: 60.83%, Valid: 62.50% Test: 50.98%\n",
      "Run: 07, Epoch: 141, Loss: 0.6225, Train: 68.33%, Valid: 62.50% Test: 56.86%\n",
      "Run: 07, Epoch: 142, Loss: 0.6690, Train: 76.67%, Valid: 65.00% Test: 60.78%\n",
      "Run: 07, Epoch: 143, Loss: 0.6467, Train: 78.33%, Valid: 62.50% Test: 68.63%\n",
      "Run: 07, Epoch: 144, Loss: 0.6195, Train: 75.83%, Valid: 60.00% Test: 64.71%\n",
      "Run: 07, Epoch: 145, Loss: 0.6231, Train: 70.00%, Valid: 65.00% Test: 64.71%\n",
      "Run: 07, Epoch: 146, Loss: 0.6193, Train: 67.50%, Valid: 62.50% Test: 64.71%\n",
      "Run: 07, Epoch: 147, Loss: 0.5474, Train: 66.67%, Valid: 62.50% Test: 66.67%\n",
      "Run: 07, Epoch: 148, Loss: 0.6137, Train: 73.33%, Valid: 63.75% Test: 66.67%\n",
      "Run: 07, Epoch: 149, Loss: 0.6427, Train: 75.83%, Valid: 57.50% Test: 60.78%\n",
      "Run: 07, Epoch: 150, Loss: 0.6344, Train: 65.83%, Valid: 53.75% Test: 50.98%\n",
      "Run: 07, Epoch: 151, Loss: 0.6656, Train: 59.17%, Valid: 48.75% Test: 41.18%\n",
      "Run: 07, Epoch: 152, Loss: 0.6128, Train: 54.17%, Valid: 45.00% Test: 47.06%\n",
      "Run: 07, Epoch: 153, Loss: 0.6481, Train: 60.00%, Valid: 47.50% Test: 50.98%\n",
      "Run: 07, Epoch: 154, Loss: 0.6556, Train: 65.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 07, Epoch: 155, Loss: 0.6091, Train: 65.83%, Valid: 60.00% Test: 54.90%\n",
      "Run: 07, Epoch: 156, Loss: 0.5755, Train: 68.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 07, Epoch: 157, Loss: 0.6672, Train: 62.50%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 158, Loss: 0.6893, Train: 58.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 07, Epoch: 159, Loss: 0.6330, Train: 55.00%, Valid: 41.25% Test: 35.29%\n",
      "Run: 07, Epoch: 160, Loss: 0.5728, Train: 66.67%, Valid: 51.25% Test: 50.98%\n",
      "Run: 07, Epoch: 161, Loss: 0.5887, Train: 72.50%, Valid: 56.25% Test: 52.94%\n",
      "Run: 07, Epoch: 162, Loss: 0.5794, Train: 72.50%, Valid: 60.00% Test: 60.78%\n",
      "Run: 07, Epoch: 163, Loss: 0.6485, Train: 73.33%, Valid: 57.50% Test: 64.71%\n",
      "Run: 07, Epoch: 164, Loss: 0.5496, Train: 71.67%, Valid: 56.25% Test: 56.86%\n",
      "Run: 07, Epoch: 165, Loss: 0.5678, Train: 77.50%, Valid: 63.75% Test: 68.63%\n",
      "Run: 07, Epoch: 166, Loss: 0.6412, Train: 78.33%, Valid: 58.75% Test: 66.67%\n",
      "Run: 07, Epoch: 167, Loss: 0.5875, Train: 68.33%, Valid: 55.00% Test: 56.86%\n",
      "Run: 07, Epoch: 168, Loss: 0.5919, Train: 65.83%, Valid: 46.25% Test: 49.02%\n",
      "Run: 07, Epoch: 169, Loss: 0.6489, Train: 74.17%, Valid: 63.75% Test: 58.82%\n",
      "Run: 07, Epoch: 170, Loss: 0.5778, Train: 73.33%, Valid: 62.50% Test: 56.86%\n",
      "Run: 07, Epoch: 171, Loss: 0.6507, Train: 77.50%, Valid: 56.25% Test: 60.78%\n",
      "Run: 07, Epoch: 172, Loss: 0.6004, Train: 69.17%, Valid: 53.75% Test: 54.90%\n",
      "Run: 07, Epoch: 173, Loss: 0.5922, Train: 65.00%, Valid: 58.75% Test: 54.90%\n",
      "Run: 07, Epoch: 174, Loss: 0.5176, Train: 55.83%, Valid: 55.00% Test: 54.90%\n",
      "Run: 07, Epoch: 175, Loss: 0.6119, Train: 55.00%, Valid: 56.25% Test: 54.90%\n",
      "Run: 07, Epoch: 176, Loss: 0.6015, Train: 59.17%, Valid: 56.25% Test: 58.82%\n",
      "Run: 07, Epoch: 177, Loss: 0.5046, Train: 62.50%, Valid: 55.00% Test: 60.78%\n",
      "Run: 07, Epoch: 178, Loss: 0.6114, Train: 73.33%, Valid: 61.25% Test: 60.78%\n",
      "Run: 07, Epoch: 179, Loss: 0.5753, Train: 78.33%, Valid: 58.75% Test: 62.75%\n",
      "Run: 07, Epoch: 180, Loss: 0.5483, Train: 82.50%, Valid: 63.75% Test: 70.59%\n",
      "Run: 07, Epoch: 181, Loss: 0.5367, Train: 74.17%, Valid: 60.00% Test: 58.82%\n",
      "Run: 07, Epoch: 182, Loss: 0.5815, Train: 74.17%, Valid: 58.75% Test: 54.90%\n",
      "Run: 07, Epoch: 183, Loss: 0.5759, Train: 81.67%, Valid: 60.00% Test: 64.71%\n",
      "Run: 07, Epoch: 184, Loss: 0.6399, Train: 76.67%, Valid: 62.50% Test: 66.67%\n",
      "Run: 07, Epoch: 185, Loss: 0.5228, Train: 71.67%, Valid: 63.75% Test: 62.75%\n",
      "Run: 07, Epoch: 186, Loss: 0.6253, Train: 75.83%, Valid: 63.75% Test: 64.71%\n",
      "Run: 07, Epoch: 187, Loss: 0.5809, Train: 68.33%, Valid: 58.75% Test: 47.06%\n",
      "Run: 07, Epoch: 188, Loss: 0.5553, Train: 74.17%, Valid: 65.00% Test: 54.90%\n",
      "Run: 07, Epoch: 189, Loss: 0.5505, Train: 76.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 07, Epoch: 190, Loss: 0.5666, Train: 69.17%, Valid: 52.50% Test: 50.98%\n",
      "Run: 07, Epoch: 191, Loss: 0.5759, Train: 55.00%, Valid: 41.25% Test: 43.14%\n",
      "Run: 07, Epoch: 192, Loss: 0.6316, Train: 61.67%, Valid: 47.50% Test: 50.98%\n",
      "Run: 07, Epoch: 193, Loss: 0.5394, Train: 70.00%, Valid: 55.00% Test: 54.90%\n",
      "Run: 07, Epoch: 194, Loss: 0.5697, Train: 73.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 07, Epoch: 195, Loss: 0.7302, Train: 60.00%, Valid: 47.50% Test: 54.90%\n",
      "Run: 07, Epoch: 196, Loss: 0.5788, Train: 50.83%, Valid: 41.25% Test: 50.98%\n",
      "Run: 07, Epoch: 197, Loss: 0.6362, Train: 62.50%, Valid: 56.25% Test: 49.02%\n",
      "Run: 07, Epoch: 198, Loss: 0.6078, Train: 67.50%, Valid: 57.50% Test: 52.94%\n",
      "Run: 07, Epoch: 199, Loss: 0.5457, Train: 74.17%, Valid: 57.50% Test: 54.90%\n",
      "Run: 07, Epoch: 200, Loss: 0.5886, Train: 78.33%, Valid: 57.50% Test: 60.78%\n",
      "Run 07:\n",
      "Highest Train: 82.50\n",
      "Highest Valid: 73.75\n",
      "  Final Train: 74.17\n",
      "   Final Test: 66.67\n",
      "Run: 08, Epoch: 01, Loss: 1.7543, Train: 28.33%, Valid: 27.50% Test: 27.45%\n",
      "Run: 08, Epoch: 02, Loss: 1.4814, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 03, Loss: 1.2943, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 04, Loss: 1.2654, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 05, Loss: 1.3780, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 06, Loss: 1.3204, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 07, Loss: 1.3509, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 08, Loss: 1.2585, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 09, Loss: 1.2083, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 10, Loss: 1.2875, Train: 44.17%, Valid: 48.75% Test: 50.98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 11, Loss: 1.2502, Train: 44.17%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 12, Loss: 1.1903, Train: 45.00%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 13, Loss: 1.1765, Train: 44.17%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 14, Loss: 1.1672, Train: 45.00%, Valid: 47.50% Test: 50.98%\n",
      "Run: 08, Epoch: 15, Loss: 1.1804, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 16, Loss: 1.1685, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 17, Loss: 1.1586, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 18, Loss: 1.1533, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 19, Loss: 1.1834, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 20, Loss: 1.1217, Train: 44.17%, Valid: 48.75% Test: 52.94%\n",
      "Run: 08, Epoch: 21, Loss: 1.1142, Train: 43.33%, Valid: 50.00% Test: 56.86%\n",
      "Run: 08, Epoch: 22, Loss: 1.1068, Train: 44.17%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 23, Loss: 1.1349, Train: 43.33%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 24, Loss: 1.1266, Train: 44.17%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 25, Loss: 1.0866, Train: 44.17%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 26, Loss: 1.1253, Train: 45.83%, Valid: 50.00% Test: 58.82%\n",
      "Run: 08, Epoch: 27, Loss: 1.0960, Train: 45.00%, Valid: 48.75% Test: 58.82%\n",
      "Run: 08, Epoch: 28, Loss: 0.9944, Train: 45.00%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 29, Loss: 1.0971, Train: 48.33%, Valid: 58.75% Test: 66.67%\n",
      "Run: 08, Epoch: 30, Loss: 1.0536, Train: 50.00%, Valid: 56.25% Test: 64.71%\n",
      "Run: 08, Epoch: 31, Loss: 1.0205, Train: 51.67%, Valid: 52.50% Test: 62.75%\n",
      "Run: 08, Epoch: 32, Loss: 1.0829, Train: 53.33%, Valid: 47.50% Test: 58.82%\n",
      "Run: 08, Epoch: 33, Loss: 1.0810, Train: 55.00%, Valid: 46.25% Test: 56.86%\n",
      "Run: 08, Epoch: 34, Loss: 1.1145, Train: 53.33%, Valid: 46.25% Test: 58.82%\n",
      "Run: 08, Epoch: 35, Loss: 1.0837, Train: 52.50%, Valid: 52.50% Test: 60.78%\n",
      "Run: 08, Epoch: 36, Loss: 1.0915, Train: 52.50%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 37, Loss: 1.1165, Train: 50.00%, Valid: 55.00% Test: 60.78%\n",
      "Run: 08, Epoch: 38, Loss: 1.0916, Train: 52.50%, Valid: 57.50% Test: 60.78%\n",
      "Run: 08, Epoch: 39, Loss: 1.0727, Train: 54.17%, Valid: 58.75% Test: 58.82%\n",
      "Run: 08, Epoch: 40, Loss: 1.0912, Train: 56.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 08, Epoch: 41, Loss: 1.0719, Train: 56.67%, Valid: 53.75% Test: 56.86%\n",
      "Run: 08, Epoch: 42, Loss: 1.1181, Train: 55.83%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 43, Loss: 1.0423, Train: 55.00%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 44, Loss: 0.9976, Train: 60.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 08, Epoch: 45, Loss: 1.0041, Train: 59.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 08, Epoch: 46, Loss: 1.1058, Train: 59.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 08, Epoch: 47, Loss: 0.9848, Train: 60.83%, Valid: 48.75% Test: 54.90%\n",
      "Run: 08, Epoch: 48, Loss: 1.1015, Train: 60.00%, Valid: 50.00% Test: 58.82%\n",
      "Run: 08, Epoch: 49, Loss: 1.0508, Train: 56.67%, Valid: 58.75% Test: 62.75%\n",
      "Run: 08, Epoch: 50, Loss: 1.0228, Train: 60.00%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 51, Loss: 0.9855, Train: 60.83%, Valid: 55.00% Test: 62.75%\n",
      "Run: 08, Epoch: 52, Loss: 0.9956, Train: 62.50%, Valid: 53.75% Test: 60.78%\n",
      "Run: 08, Epoch: 53, Loss: 0.9492, Train: 61.67%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 54, Loss: 1.0446, Train: 57.50%, Valid: 56.25% Test: 56.86%\n",
      "Run: 08, Epoch: 55, Loss: 0.9595, Train: 56.67%, Valid: 57.50% Test: 60.78%\n",
      "Run: 08, Epoch: 56, Loss: 1.0515, Train: 52.50%, Valid: 57.50% Test: 56.86%\n",
      "Run: 08, Epoch: 57, Loss: 1.0362, Train: 56.67%, Valid: 56.25% Test: 54.90%\n",
      "Run: 08, Epoch: 58, Loss: 0.9811, Train: 59.17%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 59, Loss: 0.9598, Train: 59.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 08, Epoch: 60, Loss: 1.0014, Train: 60.00%, Valid: 55.00% Test: 60.78%\n",
      "Run: 08, Epoch: 61, Loss: 1.0273, Train: 59.17%, Valid: 58.75% Test: 60.78%\n",
      "Run: 08, Epoch: 62, Loss: 0.9823, Train: 58.33%, Valid: 57.50% Test: 60.78%\n",
      "Run: 08, Epoch: 63, Loss: 0.9620, Train: 55.00%, Valid: 53.75% Test: 58.82%\n",
      "Run: 08, Epoch: 64, Loss: 0.9750, Train: 53.33%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 65, Loss: 0.9510, Train: 55.00%, Valid: 51.25% Test: 62.75%\n",
      "Run: 08, Epoch: 66, Loss: 1.0382, Train: 51.67%, Valid: 47.50% Test: 56.86%\n",
      "Run: 08, Epoch: 67, Loss: 0.9848, Train: 51.67%, Valid: 48.75% Test: 58.82%\n",
      "Run: 08, Epoch: 68, Loss: 1.0135, Train: 53.33%, Valid: 51.25% Test: 60.78%\n",
      "Run: 08, Epoch: 69, Loss: 1.0893, Train: 54.17%, Valid: 55.00% Test: 60.78%\n",
      "Run: 08, Epoch: 70, Loss: 1.0428, Train: 59.17%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 71, Loss: 0.9936, Train: 60.83%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 72, Loss: 1.0581, Train: 59.17%, Valid: 55.00% Test: 62.75%\n",
      "Run: 08, Epoch: 73, Loss: 1.0070, Train: 58.33%, Valid: 55.00% Test: 60.78%\n",
      "Run: 08, Epoch: 74, Loss: 1.0048, Train: 55.00%, Valid: 53.75% Test: 52.94%\n",
      "Run: 08, Epoch: 75, Loss: 0.9831, Train: 55.00%, Valid: 55.00% Test: 47.06%\n",
      "Run: 08, Epoch: 76, Loss: 1.0251, Train: 53.33%, Valid: 45.00% Test: 52.94%\n",
      "Run: 08, Epoch: 77, Loss: 1.0338, Train: 51.67%, Valid: 48.75% Test: 58.82%\n",
      "Run: 08, Epoch: 78, Loss: 1.0300, Train: 52.50%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 79, Loss: 1.0548, Train: 50.83%, Valid: 53.75% Test: 62.75%\n",
      "Run: 08, Epoch: 80, Loss: 1.0842, Train: 50.83%, Valid: 55.00% Test: 58.82%\n",
      "Run: 08, Epoch: 81, Loss: 1.0233, Train: 51.67%, Valid: 57.50% Test: 58.82%\n",
      "Run: 08, Epoch: 82, Loss: 0.9947, Train: 54.17%, Valid: 56.25% Test: 56.86%\n",
      "Run: 08, Epoch: 83, Loss: 1.0573, Train: 56.67%, Valid: 58.75% Test: 54.90%\n",
      "Run: 08, Epoch: 84, Loss: 1.0308, Train: 55.83%, Valid: 57.50% Test: 54.90%\n",
      "Run: 08, Epoch: 85, Loss: 1.0114, Train: 54.17%, Valid: 56.25% Test: 54.90%\n",
      "Run: 08, Epoch: 86, Loss: 1.1196, Train: 54.17%, Valid: 57.50% Test: 58.82%\n",
      "Run: 08, Epoch: 87, Loss: 0.9842, Train: 53.33%, Valid: 55.00% Test: 56.86%\n",
      "Run: 08, Epoch: 88, Loss: 0.9915, Train: 55.83%, Valid: 55.00% Test: 58.82%\n",
      "Run: 08, Epoch: 89, Loss: 1.0338, Train: 56.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 08, Epoch: 90, Loss: 1.0397, Train: 55.00%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 91, Loss: 1.0641, Train: 55.00%, Valid: 50.00% Test: 56.86%\n",
      "Run: 08, Epoch: 92, Loss: 0.9917, Train: 55.83%, Valid: 51.25% Test: 54.90%\n",
      "Run: 08, Epoch: 93, Loss: 0.9708, Train: 55.83%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 94, Loss: 1.0433, Train: 56.67%, Valid: 55.00% Test: 54.90%\n",
      "Run: 08, Epoch: 95, Loss: 0.9755, Train: 59.17%, Valid: 55.00% Test: 54.90%\n",
      "Run: 08, Epoch: 96, Loss: 1.0029, Train: 60.83%, Valid: 58.75% Test: 58.82%\n",
      "Run: 08, Epoch: 97, Loss: 1.0352, Train: 60.83%, Valid: 57.50% Test: 60.78%\n",
      "Run: 08, Epoch: 98, Loss: 0.9757, Train: 56.67%, Valid: 60.00% Test: 58.82%\n",
      "Run: 08, Epoch: 99, Loss: 0.9620, Train: 60.83%, Valid: 57.50% Test: 58.82%\n",
      "Run: 08, Epoch: 100, Loss: 1.0624, Train: 58.33%, Valid: 57.50% Test: 56.86%\n",
      "Run: 08, Epoch: 101, Loss: 1.0000, Train: 60.83%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 102, Loss: 0.9970, Train: 62.50%, Valid: 48.75% Test: 54.90%\n",
      "Run: 08, Epoch: 103, Loss: 0.9852, Train: 61.67%, Valid: 57.50% Test: 64.71%\n",
      "Run: 08, Epoch: 104, Loss: 1.0016, Train: 60.00%, Valid: 57.50% Test: 62.75%\n",
      "Run: 08, Epoch: 105, Loss: 0.9236, Train: 59.17%, Valid: 56.25% Test: 62.75%\n",
      "Run: 08, Epoch: 106, Loss: 0.9718, Train: 61.67%, Valid: 56.25% Test: 60.78%\n",
      "Run: 08, Epoch: 107, Loss: 0.9770, Train: 65.00%, Valid: 48.75% Test: 56.86%\n",
      "Run: 08, Epoch: 108, Loss: 0.9496, Train: 64.17%, Valid: 47.50% Test: 56.86%\n",
      "Run: 08, Epoch: 109, Loss: 0.9697, Train: 64.17%, Valid: 46.25% Test: 52.94%\n",
      "Run: 08, Epoch: 110, Loss: 0.9741, Train: 63.33%, Valid: 48.75% Test: 54.90%\n",
      "Run: 08, Epoch: 111, Loss: 1.0126, Train: 63.33%, Valid: 47.50% Test: 49.02%\n",
      "Run: 08, Epoch: 112, Loss: 0.9346, Train: 58.33%, Valid: 45.00% Test: 45.10%\n",
      "Run: 08, Epoch: 113, Loss: 0.9630, Train: 58.33%, Valid: 48.75% Test: 45.10%\n",
      "Run: 08, Epoch: 114, Loss: 0.9423, Train: 55.83%, Valid: 46.25% Test: 54.90%\n",
      "Run: 08, Epoch: 115, Loss: 0.9445, Train: 58.33%, Valid: 45.00% Test: 50.98%\n",
      "Run: 08, Epoch: 116, Loss: 0.9833, Train: 60.83%, Valid: 48.75% Test: 58.82%\n",
      "Run: 08, Epoch: 117, Loss: 0.8935, Train: 59.17%, Valid: 48.75% Test: 58.82%\n",
      "Run: 08, Epoch: 118, Loss: 0.9045, Train: 61.67%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 119, Loss: 0.9143, Train: 62.50%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 120, Loss: 0.9000, Train: 65.00%, Valid: 50.00% Test: 58.82%\n",
      "Run: 08, Epoch: 121, Loss: 0.9476, Train: 65.00%, Valid: 48.75% Test: 58.82%\n",
      "Run: 08, Epoch: 122, Loss: 0.9331, Train: 65.83%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 123, Loss: 0.9218, Train: 65.83%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 124, Loss: 0.8791, Train: 60.00%, Valid: 60.00% Test: 64.71%\n",
      "Run: 08, Epoch: 125, Loss: 0.9769, Train: 60.00%, Valid: 57.50% Test: 64.71%\n",
      "Run: 08, Epoch: 126, Loss: 0.9361, Train: 58.33%, Valid: 53.75% Test: 60.78%\n",
      "Run: 08, Epoch: 127, Loss: 0.8781, Train: 55.83%, Valid: 56.25% Test: 62.75%\n",
      "Run: 08, Epoch: 128, Loss: 0.9131, Train: 58.33%, Valid: 56.25% Test: 62.75%\n",
      "Run: 08, Epoch: 129, Loss: 0.8874, Train: 55.00%, Valid: 56.25% Test: 56.86%\n",
      "Run: 08, Epoch: 130, Loss: 0.9948, Train: 60.00%, Valid: 55.00% Test: 56.86%\n",
      "Run: 08, Epoch: 131, Loss: 0.9737, Train: 65.00%, Valid: 55.00% Test: 56.86%\n",
      "Run: 08, Epoch: 132, Loss: 0.9279, Train: 62.50%, Valid: 55.00% Test: 58.82%\n",
      "Run: 08, Epoch: 133, Loss: 0.9503, Train: 60.00%, Valid: 55.00% Test: 60.78%\n",
      "Run: 08, Epoch: 134, Loss: 0.8897, Train: 61.67%, Valid: 55.00% Test: 60.78%\n",
      "Run: 08, Epoch: 135, Loss: 0.9306, Train: 63.33%, Valid: 53.75% Test: 60.78%\n",
      "Run: 08, Epoch: 136, Loss: 0.9518, Train: 65.00%, Valid: 53.75% Test: 60.78%\n",
      "Run: 08, Epoch: 137, Loss: 0.9416, Train: 64.17%, Valid: 55.00% Test: 60.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 138, Loss: 0.9330, Train: 65.00%, Valid: 55.00% Test: 62.75%\n",
      "Run: 08, Epoch: 139, Loss: 0.9349, Train: 64.17%, Valid: 53.75% Test: 60.78%\n",
      "Run: 08, Epoch: 140, Loss: 0.8732, Train: 66.67%, Valid: 56.25% Test: 62.75%\n",
      "Run: 08, Epoch: 141, Loss: 0.8687, Train: 62.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 08, Epoch: 142, Loss: 0.9788, Train: 56.67%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 143, Loss: 0.9104, Train: 56.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 08, Epoch: 144, Loss: 0.9174, Train: 58.33%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 145, Loss: 0.9343, Train: 53.33%, Valid: 61.25% Test: 60.78%\n",
      "Run: 08, Epoch: 146, Loss: 0.9230, Train: 55.83%, Valid: 56.25% Test: 64.71%\n",
      "Run: 08, Epoch: 147, Loss: 0.8885, Train: 53.33%, Valid: 53.75% Test: 62.75%\n",
      "Run: 08, Epoch: 148, Loss: 0.9085, Train: 54.17%, Valid: 52.50% Test: 60.78%\n",
      "Run: 08, Epoch: 149, Loss: 0.8944, Train: 55.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 08, Epoch: 150, Loss: 0.8910, Train: 57.50%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 151, Loss: 0.9697, Train: 56.67%, Valid: 52.50% Test: 60.78%\n",
      "Run: 08, Epoch: 152, Loss: 0.9295, Train: 53.33%, Valid: 51.25% Test: 66.67%\n",
      "Run: 08, Epoch: 153, Loss: 1.0298, Train: 55.00%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 154, Loss: 0.9334, Train: 53.33%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 155, Loss: 0.9268, Train: 50.00%, Valid: 51.25% Test: 47.06%\n",
      "Run: 08, Epoch: 156, Loss: 0.9299, Train: 48.33%, Valid: 51.25% Test: 39.22%\n",
      "Run: 08, Epoch: 157, Loss: 0.8747, Train: 50.00%, Valid: 52.50% Test: 45.10%\n",
      "Run: 08, Epoch: 158, Loss: 1.0325, Train: 55.83%, Valid: 60.00% Test: 56.86%\n",
      "Run: 08, Epoch: 159, Loss: 0.9235, Train: 58.33%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 160, Loss: 0.9286, Train: 60.00%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 161, Loss: 0.9273, Train: 60.00%, Valid: 52.50% Test: 56.86%\n",
      "Run: 08, Epoch: 162, Loss: 0.9756, Train: 59.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 08, Epoch: 163, Loss: 0.9085, Train: 55.83%, Valid: 52.50% Test: 52.94%\n",
      "Run: 08, Epoch: 164, Loss: 0.9872, Train: 55.00%, Valid: 51.25% Test: 56.86%\n",
      "Run: 08, Epoch: 165, Loss: 0.9338, Train: 59.17%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 166, Loss: 1.0234, Train: 61.67%, Valid: 53.75% Test: 60.78%\n",
      "Run: 08, Epoch: 167, Loss: 0.8522, Train: 61.67%, Valid: 55.00% Test: 56.86%\n",
      "Run: 08, Epoch: 168, Loss: 0.9128, Train: 60.00%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 169, Loss: 0.8613, Train: 63.33%, Valid: 51.25% Test: 62.75%\n",
      "Run: 08, Epoch: 170, Loss: 0.8706, Train: 65.00%, Valid: 50.00% Test: 60.78%\n",
      "Run: 08, Epoch: 171, Loss: 0.9112, Train: 66.67%, Valid: 47.50% Test: 58.82%\n",
      "Run: 08, Epoch: 172, Loss: 0.8894, Train: 65.00%, Valid: 51.25% Test: 54.90%\n",
      "Run: 08, Epoch: 173, Loss: 0.8980, Train: 65.83%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 174, Loss: 0.8769, Train: 66.67%, Valid: 55.00% Test: 54.90%\n",
      "Run: 08, Epoch: 175, Loss: 0.9302, Train: 64.17%, Valid: 51.25% Test: 52.94%\n",
      "Run: 08, Epoch: 176, Loss: 0.8631, Train: 65.83%, Valid: 50.00% Test: 54.90%\n",
      "Run: 08, Epoch: 177, Loss: 0.8925, Train: 67.50%, Valid: 50.00% Test: 58.82%\n",
      "Run: 08, Epoch: 178, Loss: 0.9285, Train: 66.67%, Valid: 52.50% Test: 58.82%\n",
      "Run: 08, Epoch: 179, Loss: 0.8294, Train: 65.00%, Valid: 55.00% Test: 56.86%\n",
      "Run: 08, Epoch: 180, Loss: 0.9272, Train: 65.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 08, Epoch: 181, Loss: 0.8996, Train: 65.00%, Valid: 53.75% Test: 56.86%\n",
      "Run: 08, Epoch: 182, Loss: 0.8481, Train: 65.83%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 183, Loss: 0.8502, Train: 65.00%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 184, Loss: 0.9562, Train: 62.50%, Valid: 51.25% Test: 54.90%\n",
      "Run: 08, Epoch: 185, Loss: 0.8192, Train: 65.00%, Valid: 50.00% Test: 50.98%\n",
      "Run: 08, Epoch: 186, Loss: 0.8446, Train: 64.17%, Valid: 50.00% Test: 54.90%\n",
      "Run: 08, Epoch: 187, Loss: 0.9084, Train: 66.67%, Valid: 53.75% Test: 52.94%\n",
      "Run: 08, Epoch: 188, Loss: 0.9060, Train: 67.50%, Valid: 55.00% Test: 49.02%\n",
      "Run: 08, Epoch: 189, Loss: 0.8477, Train: 66.67%, Valid: 52.50% Test: 47.06%\n",
      "Run: 08, Epoch: 190, Loss: 0.7749, Train: 67.50%, Valid: 51.25% Test: 47.06%\n",
      "Run: 08, Epoch: 191, Loss: 0.8180, Train: 66.67%, Valid: 50.00% Test: 56.86%\n",
      "Run: 08, Epoch: 192, Loss: 0.8301, Train: 65.00%, Valid: 51.25% Test: 58.82%\n",
      "Run: 08, Epoch: 193, Loss: 0.8628, Train: 61.67%, Valid: 50.00% Test: 64.71%\n",
      "Run: 08, Epoch: 194, Loss: 0.9302, Train: 60.00%, Valid: 52.50% Test: 66.67%\n",
      "Run: 08, Epoch: 195, Loss: 0.8130, Train: 61.67%, Valid: 50.00% Test: 64.71%\n",
      "Run: 08, Epoch: 196, Loss: 0.8837, Train: 63.33%, Valid: 51.25% Test: 66.67%\n",
      "Run: 08, Epoch: 197, Loss: 0.8624, Train: 65.00%, Valid: 53.75% Test: 62.75%\n",
      "Run: 08, Epoch: 198, Loss: 0.8102, Train: 65.83%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 199, Loss: 0.8598, Train: 65.00%, Valid: 55.00% Test: 54.90%\n",
      "Run: 08, Epoch: 200, Loss: 0.9843, Train: 65.00%, Valid: 53.75% Test: 54.90%\n",
      "Run 08:\n",
      "Highest Train: 67.50\n",
      "Highest Valid: 61.25\n",
      "  Final Train: 53.33\n",
      "   Final Test: 60.78\n",
      "Run: 09, Epoch: 01, Loss: 1.7003, Train: 23.33%, Valid: 33.75% Test: 29.41%\n",
      "Run: 09, Epoch: 02, Loss: 1.3818, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 03, Loss: 1.3016, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 04, Loss: 1.2338, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 05, Loss: 1.2206, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 06, Loss: 1.2044, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 07, Loss: 1.1881, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 08, Loss: 1.1591, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 09, Loss: 1.1747, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 10, Loss: 1.0586, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 11, Loss: 1.2049, Train: 55.83%, Valid: 40.00% Test: 45.10%\n",
      "Run: 09, Epoch: 12, Loss: 1.1356, Train: 54.17%, Valid: 38.75% Test: 43.14%\n",
      "Run: 09, Epoch: 13, Loss: 1.0571, Train: 54.17%, Valid: 38.75% Test: 43.14%\n",
      "Run: 09, Epoch: 14, Loss: 1.0666, Train: 53.33%, Valid: 40.00% Test: 43.14%\n",
      "Run: 09, Epoch: 15, Loss: 1.1454, Train: 54.17%, Valid: 40.00% Test: 43.14%\n",
      "Run: 09, Epoch: 16, Loss: 1.0528, Train: 53.33%, Valid: 41.25% Test: 47.06%\n",
      "Run: 09, Epoch: 17, Loss: 1.0499, Train: 54.17%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 18, Loss: 1.0386, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 19, Loss: 1.1026, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 20, Loss: 1.0401, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 21, Loss: 1.0185, Train: 52.50%, Valid: 40.00% Test: 47.06%\n",
      "Run: 09, Epoch: 22, Loss: 1.0522, Train: 54.17%, Valid: 40.00% Test: 45.10%\n",
      "Run: 09, Epoch: 23, Loss: 0.9757, Train: 53.33%, Valid: 40.00% Test: 45.10%\n",
      "Run: 09, Epoch: 24, Loss: 1.0223, Train: 52.50%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 25, Loss: 0.9706, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 26, Loss: 1.0201, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 27, Loss: 0.9860, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 28, Loss: 1.0051, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 29, Loss: 1.0196, Train: 56.67%, Valid: 35.00% Test: 43.14%\n",
      "Run: 09, Epoch: 30, Loss: 0.9342, Train: 56.67%, Valid: 35.00% Test: 41.18%\n",
      "Run: 09, Epoch: 31, Loss: 0.9438, Train: 55.00%, Valid: 33.75% Test: 39.22%\n",
      "Run: 09, Epoch: 32, Loss: 0.9711, Train: 57.50%, Valid: 33.75% Test: 37.25%\n",
      "Run: 09, Epoch: 33, Loss: 0.9268, Train: 60.00%, Valid: 38.75% Test: 39.22%\n",
      "Run: 09, Epoch: 34, Loss: 0.9138, Train: 58.33%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 35, Loss: 0.9417, Train: 60.83%, Valid: 46.25% Test: 45.10%\n",
      "Run: 09, Epoch: 36, Loss: 0.9311, Train: 59.17%, Valid: 48.75% Test: 47.06%\n",
      "Run: 09, Epoch: 37, Loss: 0.8715, Train: 60.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 09, Epoch: 38, Loss: 0.9776, Train: 60.00%, Valid: 50.00% Test: 49.02%\n",
      "Run: 09, Epoch: 39, Loss: 0.9583, Train: 63.33%, Valid: 47.50% Test: 45.10%\n",
      "Run: 09, Epoch: 40, Loss: 0.9910, Train: 59.17%, Valid: 43.75% Test: 39.22%\n",
      "Run: 09, Epoch: 41, Loss: 0.9021, Train: 60.00%, Valid: 46.25% Test: 39.22%\n",
      "Run: 09, Epoch: 42, Loss: 0.9588, Train: 59.17%, Valid: 47.50% Test: 41.18%\n",
      "Run: 09, Epoch: 43, Loss: 0.8736, Train: 60.00%, Valid: 46.25% Test: 43.14%\n",
      "Run: 09, Epoch: 44, Loss: 0.8916, Train: 61.67%, Valid: 50.00% Test: 45.10%\n",
      "Run: 09, Epoch: 45, Loss: 0.9249, Train: 58.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 09, Epoch: 46, Loss: 0.9132, Train: 60.00%, Valid: 41.25% Test: 45.10%\n",
      "Run: 09, Epoch: 47, Loss: 0.9773, Train: 56.67%, Valid: 37.50% Test: 43.14%\n",
      "Run: 09, Epoch: 48, Loss: 0.9801, Train: 55.83%, Valid: 35.00% Test: 43.14%\n",
      "Run: 09, Epoch: 49, Loss: 0.9076, Train: 55.00%, Valid: 36.25% Test: 43.14%\n",
      "Run: 09, Epoch: 50, Loss: 0.9067, Train: 55.00%, Valid: 36.25% Test: 43.14%\n",
      "Run: 09, Epoch: 51, Loss: 0.8982, Train: 55.83%, Valid: 35.00% Test: 43.14%\n",
      "Run: 09, Epoch: 52, Loss: 0.8785, Train: 59.17%, Valid: 33.75% Test: 43.14%\n",
      "Run: 09, Epoch: 53, Loss: 0.8764, Train: 60.00%, Valid: 33.75% Test: 43.14%\n",
      "Run: 09, Epoch: 54, Loss: 0.8730, Train: 60.83%, Valid: 33.75% Test: 39.22%\n",
      "Run: 09, Epoch: 55, Loss: 0.8784, Train: 59.17%, Valid: 33.75% Test: 35.29%\n",
      "Run: 09, Epoch: 56, Loss: 0.8669, Train: 62.50%, Valid: 40.00% Test: 33.33%\n",
      "Run: 09, Epoch: 57, Loss: 0.9545, Train: 65.00%, Valid: 47.50% Test: 45.10%\n",
      "Run: 09, Epoch: 58, Loss: 0.8863, Train: 64.17%, Valid: 45.00% Test: 47.06%\n",
      "Run: 09, Epoch: 59, Loss: 0.8184, Train: 60.83%, Valid: 48.75% Test: 47.06%\n",
      "Run: 09, Epoch: 60, Loss: 0.9059, Train: 60.83%, Valid: 48.75% Test: 49.02%\n",
      "Run: 09, Epoch: 61, Loss: 0.8385, Train: 62.50%, Valid: 48.75% Test: 50.98%\n",
      "Run: 09, Epoch: 62, Loss: 0.9148, Train: 62.50%, Valid: 47.50% Test: 43.14%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 63, Loss: 0.8491, Train: 62.50%, Valid: 48.75% Test: 45.10%\n",
      "Run: 09, Epoch: 64, Loss: 0.8766, Train: 60.00%, Valid: 48.75% Test: 45.10%\n",
      "Run: 09, Epoch: 65, Loss: 0.8356, Train: 64.17%, Valid: 53.75% Test: 43.14%\n",
      "Run: 09, Epoch: 66, Loss: 0.8423, Train: 61.67%, Valid: 52.50% Test: 45.10%\n",
      "Run: 09, Epoch: 67, Loss: 0.8708, Train: 62.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 09, Epoch: 68, Loss: 0.8849, Train: 64.17%, Valid: 47.50% Test: 49.02%\n",
      "Run: 09, Epoch: 69, Loss: 0.8027, Train: 61.67%, Valid: 53.75% Test: 49.02%\n",
      "Run: 09, Epoch: 70, Loss: 0.8827, Train: 60.00%, Valid: 56.25% Test: 49.02%\n",
      "Run: 09, Epoch: 71, Loss: 0.8608, Train: 57.50%, Valid: 57.50% Test: 52.94%\n",
      "Run: 09, Epoch: 72, Loss: 0.9239, Train: 61.67%, Valid: 53.75% Test: 49.02%\n",
      "Run: 09, Epoch: 73, Loss: 0.9031, Train: 64.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 74, Loss: 0.8039, Train: 65.83%, Valid: 48.75% Test: 47.06%\n",
      "Run: 09, Epoch: 75, Loss: 0.8411, Train: 62.50%, Valid: 51.25% Test: 45.10%\n",
      "Run: 09, Epoch: 76, Loss: 1.0375, Train: 64.17%, Valid: 55.00% Test: 45.10%\n",
      "Run: 09, Epoch: 77, Loss: 0.8889, Train: 64.17%, Valid: 57.50% Test: 39.22%\n",
      "Run: 09, Epoch: 78, Loss: 0.9533, Train: 60.83%, Valid: 52.50% Test: 43.14%\n",
      "Run: 09, Epoch: 79, Loss: 0.8044, Train: 62.50%, Valid: 52.50% Test: 43.14%\n",
      "Run: 09, Epoch: 80, Loss: 0.8831, Train: 61.67%, Valid: 45.00% Test: 41.18%\n",
      "Run: 09, Epoch: 81, Loss: 0.8465, Train: 61.67%, Valid: 42.50% Test: 41.18%\n",
      "Run: 09, Epoch: 82, Loss: 0.8220, Train: 61.67%, Valid: 43.75% Test: 43.14%\n",
      "Run: 09, Epoch: 83, Loss: 0.8825, Train: 60.83%, Valid: 46.25% Test: 47.06%\n",
      "Run: 09, Epoch: 84, Loss: 0.9018, Train: 62.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 09, Epoch: 85, Loss: 0.8550, Train: 65.00%, Valid: 53.75% Test: 49.02%\n",
      "Run: 09, Epoch: 86, Loss: 0.8315, Train: 62.50%, Valid: 51.25% Test: 49.02%\n",
      "Run: 09, Epoch: 87, Loss: 0.7885, Train: 63.33%, Valid: 48.75% Test: 49.02%\n",
      "Run: 09, Epoch: 88, Loss: 0.7648, Train: 65.83%, Valid: 50.00% Test: 54.90%\n",
      "Run: 09, Epoch: 89, Loss: 0.7682, Train: 68.33%, Valid: 53.75% Test: 49.02%\n",
      "Run: 09, Epoch: 90, Loss: 0.8594, Train: 68.33%, Valid: 53.75% Test: 49.02%\n",
      "Run: 09, Epoch: 91, Loss: 0.8222, Train: 67.50%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 92, Loss: 0.8546, Train: 65.00%, Valid: 51.25% Test: 54.90%\n",
      "Run: 09, Epoch: 93, Loss: 0.8128, Train: 64.17%, Valid: 53.75% Test: 52.94%\n",
      "Run: 09, Epoch: 94, Loss: 0.8150, Train: 65.83%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 95, Loss: 0.8657, Train: 64.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 96, Loss: 0.7867, Train: 62.50%, Valid: 47.50% Test: 47.06%\n",
      "Run: 09, Epoch: 97, Loss: 0.9610, Train: 58.33%, Valid: 42.50% Test: 39.22%\n",
      "Run: 09, Epoch: 98, Loss: 0.8287, Train: 60.00%, Valid: 35.00% Test: 43.14%\n",
      "Run: 09, Epoch: 99, Loss: 0.7919, Train: 59.17%, Valid: 36.25% Test: 43.14%\n",
      "Run: 09, Epoch: 100, Loss: 0.8417, Train: 57.50%, Valid: 36.25% Test: 37.25%\n",
      "Run: 09, Epoch: 101, Loss: 0.7843, Train: 56.67%, Valid: 40.00% Test: 37.25%\n",
      "Run: 09, Epoch: 102, Loss: 0.8977, Train: 60.83%, Valid: 46.25% Test: 43.14%\n",
      "Run: 09, Epoch: 103, Loss: 0.8607, Train: 64.17%, Valid: 48.75% Test: 49.02%\n",
      "Run: 09, Epoch: 104, Loss: 0.8300, Train: 68.33%, Valid: 50.00% Test: 49.02%\n",
      "Run: 09, Epoch: 105, Loss: 0.8506, Train: 66.67%, Valid: 45.00% Test: 50.98%\n",
      "Run: 09, Epoch: 106, Loss: 0.8310, Train: 70.00%, Valid: 45.00% Test: 50.98%\n",
      "Run: 09, Epoch: 107, Loss: 0.8002, Train: 70.83%, Valid: 43.75% Test: 50.98%\n",
      "Run: 09, Epoch: 108, Loss: 0.7966, Train: 70.83%, Valid: 43.75% Test: 50.98%\n",
      "Run: 09, Epoch: 109, Loss: 0.8111, Train: 70.00%, Valid: 43.75% Test: 52.94%\n",
      "Run: 09, Epoch: 110, Loss: 0.8229, Train: 71.67%, Valid: 42.50% Test: 52.94%\n",
      "Run: 09, Epoch: 111, Loss: 0.7733, Train: 70.83%, Valid: 46.25% Test: 52.94%\n",
      "Run: 09, Epoch: 112, Loss: 0.7568, Train: 70.83%, Valid: 48.75% Test: 50.98%\n",
      "Run: 09, Epoch: 113, Loss: 0.7585, Train: 69.17%, Valid: 53.75% Test: 49.02%\n",
      "Run: 09, Epoch: 114, Loss: 0.8308, Train: 70.00%, Valid: 53.75% Test: 49.02%\n",
      "Run: 09, Epoch: 115, Loss: 0.8184, Train: 65.83%, Valid: 48.75% Test: 41.18%\n",
      "Run: 09, Epoch: 116, Loss: 0.8770, Train: 66.67%, Valid: 43.75% Test: 39.22%\n",
      "Run: 09, Epoch: 117, Loss: 0.8430, Train: 65.83%, Valid: 45.00% Test: 41.18%\n",
      "Run: 09, Epoch: 118, Loss: 0.8557, Train: 74.17%, Valid: 47.50% Test: 45.10%\n",
      "Run: 09, Epoch: 119, Loss: 0.7505, Train: 74.17%, Valid: 50.00% Test: 49.02%\n",
      "Run: 09, Epoch: 120, Loss: 0.7221, Train: 76.67%, Valid: 50.00% Test: 50.98%\n",
      "Run: 09, Epoch: 121, Loss: 0.7509, Train: 76.67%, Valid: 51.25% Test: 49.02%\n",
      "Run: 09, Epoch: 122, Loss: 0.7658, Train: 75.83%, Valid: 51.25% Test: 50.98%\n",
      "Run: 09, Epoch: 123, Loss: 0.7431, Train: 71.67%, Valid: 55.00% Test: 50.98%\n",
      "Run: 09, Epoch: 124, Loss: 0.7930, Train: 71.67%, Valid: 53.75% Test: 49.02%\n",
      "Run: 09, Epoch: 125, Loss: 0.7455, Train: 71.67%, Valid: 51.25% Test: 47.06%\n",
      "Run: 09, Epoch: 126, Loss: 0.7436, Train: 70.83%, Valid: 48.75% Test: 47.06%\n",
      "Run: 09, Epoch: 127, Loss: 0.7840, Train: 70.83%, Valid: 45.00% Test: 47.06%\n",
      "Run: 09, Epoch: 128, Loss: 0.7128, Train: 74.17%, Valid: 43.75% Test: 45.10%\n",
      "Run: 09, Epoch: 129, Loss: 0.6880, Train: 75.83%, Valid: 45.00% Test: 47.06%\n",
      "Run: 09, Epoch: 130, Loss: 0.7638, Train: 75.83%, Valid: 45.00% Test: 47.06%\n",
      "Run: 09, Epoch: 131, Loss: 0.8226, Train: 71.67%, Valid: 45.00% Test: 50.98%\n",
      "Run: 09, Epoch: 132, Loss: 0.7843, Train: 72.50%, Valid: 45.00% Test: 47.06%\n",
      "Run: 09, Epoch: 133, Loss: 0.7278, Train: 71.67%, Valid: 46.25% Test: 43.14%\n",
      "Run: 09, Epoch: 134, Loss: 0.7824, Train: 72.50%, Valid: 45.00% Test: 47.06%\n",
      "Run: 09, Epoch: 135, Loss: 0.7747, Train: 73.33%, Valid: 43.75% Test: 47.06%\n",
      "Run: 09, Epoch: 136, Loss: 0.9065, Train: 69.17%, Valid: 43.75% Test: 43.14%\n",
      "Run: 09, Epoch: 137, Loss: 0.8432, Train: 65.00%, Valid: 42.50% Test: 43.14%\n",
      "Run: 09, Epoch: 138, Loss: 0.7527, Train: 63.33%, Valid: 42.50% Test: 43.14%\n",
      "Run: 09, Epoch: 139, Loss: 0.7283, Train: 62.50%, Valid: 37.50% Test: 43.14%\n",
      "Run: 09, Epoch: 140, Loss: 0.7990, Train: 61.67%, Valid: 38.75% Test: 43.14%\n",
      "Run: 09, Epoch: 141, Loss: 0.8036, Train: 64.17%, Valid: 38.75% Test: 37.25%\n",
      "Run: 09, Epoch: 142, Loss: 0.8157, Train: 73.33%, Valid: 46.25% Test: 43.14%\n",
      "Run: 09, Epoch: 143, Loss: 0.8008, Train: 73.33%, Valid: 47.50% Test: 45.10%\n",
      "Run: 09, Epoch: 144, Loss: 0.7917, Train: 69.17%, Valid: 46.25% Test: 43.14%\n",
      "Run: 09, Epoch: 145, Loss: 0.7977, Train: 60.83%, Valid: 45.00% Test: 35.29%\n",
      "Run: 09, Epoch: 146, Loss: 0.8548, Train: 59.17%, Valid: 42.50% Test: 35.29%\n",
      "Run: 09, Epoch: 147, Loss: 0.7936, Train: 61.67%, Valid: 43.75% Test: 35.29%\n",
      "Run: 09, Epoch: 148, Loss: 0.7403, Train: 70.83%, Valid: 47.50% Test: 49.02%\n",
      "Run: 09, Epoch: 149, Loss: 0.7827, Train: 72.50%, Valid: 48.75% Test: 50.98%\n",
      "Run: 09, Epoch: 150, Loss: 0.7958, Train: 70.83%, Valid: 51.25% Test: 50.98%\n",
      "Run: 09, Epoch: 151, Loss: 0.8199, Train: 70.00%, Valid: 53.75% Test: 54.90%\n",
      "Run: 09, Epoch: 152, Loss: 0.8314, Train: 71.67%, Valid: 52.50% Test: 52.94%\n",
      "Run: 09, Epoch: 153, Loss: 0.8035, Train: 70.00%, Valid: 52.50% Test: 52.94%\n",
      "Run: 09, Epoch: 154, Loss: 0.7871, Train: 70.83%, Valid: 52.50% Test: 50.98%\n",
      "Run: 09, Epoch: 155, Loss: 0.7531, Train: 74.17%, Valid: 51.25% Test: 49.02%\n",
      "Run: 09, Epoch: 156, Loss: 0.6759, Train: 75.00%, Valid: 48.75% Test: 49.02%\n",
      "Run: 09, Epoch: 157, Loss: 0.7640, Train: 75.00%, Valid: 47.50% Test: 50.98%\n",
      "Run: 09, Epoch: 158, Loss: 0.7558, Train: 75.00%, Valid: 46.25% Test: 49.02%\n",
      "Run: 09, Epoch: 159, Loss: 0.7868, Train: 75.83%, Valid: 45.00% Test: 47.06%\n",
      "Run: 09, Epoch: 160, Loss: 0.7942, Train: 75.83%, Valid: 45.00% Test: 49.02%\n",
      "Run: 09, Epoch: 161, Loss: 0.8186, Train: 74.17%, Valid: 46.25% Test: 49.02%\n",
      "Run: 09, Epoch: 162, Loss: 0.7760, Train: 70.83%, Valid: 47.50% Test: 45.10%\n",
      "Run: 09, Epoch: 163, Loss: 0.7137, Train: 71.67%, Valid: 47.50% Test: 45.10%\n",
      "Run: 09, Epoch: 164, Loss: 0.6752, Train: 66.67%, Valid: 41.25% Test: 33.33%\n",
      "Run: 09, Epoch: 165, Loss: 0.7438, Train: 66.67%, Valid: 40.00% Test: 33.33%\n",
      "Run: 09, Epoch: 166, Loss: 0.7548, Train: 67.50%, Valid: 41.25% Test: 33.33%\n",
      "Run: 09, Epoch: 167, Loss: 0.7388, Train: 69.17%, Valid: 43.75% Test: 47.06%\n",
      "Run: 09, Epoch: 168, Loss: 0.6707, Train: 76.67%, Valid: 45.00% Test: 45.10%\n",
      "Run: 09, Epoch: 169, Loss: 0.8236, Train: 75.83%, Valid: 46.25% Test: 45.10%\n",
      "Run: 09, Epoch: 170, Loss: 0.7301, Train: 76.67%, Valid: 45.00% Test: 41.18%\n",
      "Run: 09, Epoch: 171, Loss: 0.7162, Train: 76.67%, Valid: 45.00% Test: 41.18%\n",
      "Run: 09, Epoch: 172, Loss: 0.6669, Train: 76.67%, Valid: 47.50% Test: 45.10%\n",
      "Run: 09, Epoch: 173, Loss: 0.7184, Train: 73.33%, Valid: 45.00% Test: 43.14%\n",
      "Run: 09, Epoch: 174, Loss: 0.6659, Train: 75.83%, Valid: 45.00% Test: 41.18%\n",
      "Run: 09, Epoch: 175, Loss: 0.7789, Train: 75.83%, Valid: 51.25% Test: 47.06%\n",
      "Run: 09, Epoch: 176, Loss: 0.7960, Train: 76.67%, Valid: 52.50% Test: 54.90%\n",
      "Run: 09, Epoch: 177, Loss: 0.6970, Train: 74.17%, Valid: 48.75% Test: 56.86%\n",
      "Run: 09, Epoch: 178, Loss: 0.7143, Train: 73.33%, Valid: 50.00% Test: 56.86%\n",
      "Run: 09, Epoch: 179, Loss: 0.8310, Train: 75.83%, Valid: 46.25% Test: 52.94%\n",
      "Run: 09, Epoch: 180, Loss: 0.6840, Train: 76.67%, Valid: 45.00% Test: 47.06%\n",
      "Run: 09, Epoch: 181, Loss: 0.8258, Train: 73.33%, Valid: 42.50% Test: 47.06%\n",
      "Run: 09, Epoch: 182, Loss: 0.7094, Train: 65.83%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 183, Loss: 0.7355, Train: 66.67%, Valid: 43.75% Test: 43.14%\n",
      "Run: 09, Epoch: 184, Loss: 0.7384, Train: 65.00%, Valid: 43.75% Test: 43.14%\n",
      "Run: 09, Epoch: 185, Loss: 0.6443, Train: 70.00%, Valid: 43.75% Test: 47.06%\n",
      "Run: 09, Epoch: 186, Loss: 0.7724, Train: 70.83%, Valid: 48.75% Test: 52.94%\n",
      "Run: 09, Epoch: 187, Loss: 0.7584, Train: 68.33%, Valid: 53.75% Test: 54.90%\n",
      "Run: 09, Epoch: 188, Loss: 0.7454, Train: 71.67%, Valid: 52.50% Test: 54.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 189, Loss: 0.6407, Train: 76.67%, Valid: 50.00% Test: 52.94%\n",
      "Run: 09, Epoch: 190, Loss: 0.7015, Train: 78.33%, Valid: 50.00% Test: 49.02%\n",
      "Run: 09, Epoch: 191, Loss: 0.7224, Train: 78.33%, Valid: 50.00% Test: 41.18%\n",
      "Run: 09, Epoch: 192, Loss: 0.7733, Train: 78.33%, Valid: 50.00% Test: 41.18%\n",
      "Run: 09, Epoch: 193, Loss: 0.6987, Train: 77.50%, Valid: 51.25% Test: 43.14%\n",
      "Run: 09, Epoch: 194, Loss: 0.6898, Train: 80.00%, Valid: 48.75% Test: 47.06%\n",
      "Run: 09, Epoch: 195, Loss: 0.7199, Train: 69.17%, Valid: 41.25% Test: 41.18%\n",
      "Run: 09, Epoch: 196, Loss: 0.7362, Train: 75.83%, Valid: 46.25% Test: 50.98%\n",
      "Run: 09, Epoch: 197, Loss: 0.7178, Train: 72.50%, Valid: 45.00% Test: 45.10%\n",
      "Run: 09, Epoch: 198, Loss: 0.7628, Train: 70.00%, Valid: 46.25% Test: 45.10%\n",
      "Run: 09, Epoch: 199, Loss: 0.7497, Train: 66.67%, Valid: 45.00% Test: 41.18%\n",
      "Run: 09, Epoch: 200, Loss: 0.6621, Train: 65.83%, Valid: 41.25% Test: 43.14%\n",
      "Run 09:\n",
      "Highest Train: 80.00\n",
      "Highest Valid: 57.50\n",
      "  Final Train: 57.50\n",
      "   Final Test: 52.94\n",
      "Run: 10, Epoch: 01, Loss: 1.5473, Train: 30.00%, Valid: 22.50% Test: 33.33%\n",
      "Run: 10, Epoch: 02, Loss: 1.3393, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 03, Loss: 1.2764, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 04, Loss: 1.3086, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 05, Loss: 1.2872, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 06, Loss: 1.2939, Train: 48.33%, Valid: 43.75% Test: 45.10%\n",
      "Run: 10, Epoch: 07, Loss: 1.2155, Train: 50.00%, Valid: 43.75% Test: 43.14%\n",
      "Run: 10, Epoch: 08, Loss: 1.2855, Train: 49.17%, Valid: 45.00% Test: 43.14%\n",
      "Run: 10, Epoch: 09, Loss: 1.2028, Train: 50.00%, Valid: 43.75% Test: 43.14%\n",
      "Run: 10, Epoch: 10, Loss: 1.2359, Train: 50.00%, Valid: 43.75% Test: 45.10%\n",
      "Run: 10, Epoch: 11, Loss: 1.1784, Train: 50.00%, Valid: 45.00% Test: 45.10%\n",
      "Run: 10, Epoch: 12, Loss: 1.2262, Train: 50.00%, Valid: 45.00% Test: 45.10%\n",
      "Run: 10, Epoch: 13, Loss: 1.1907, Train: 50.00%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 14, Loss: 1.1460, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 15, Loss: 1.0905, Train: 49.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 16, Loss: 1.1328, Train: 50.00%, Valid: 48.75% Test: 49.02%\n",
      "Run: 10, Epoch: 17, Loss: 1.0288, Train: 55.00%, Valid: 52.50% Test: 52.94%\n",
      "Run: 10, Epoch: 18, Loss: 1.0743, Train: 56.67%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 19, Loss: 1.0746, Train: 58.33%, Valid: 60.00% Test: 56.86%\n",
      "Run: 10, Epoch: 20, Loss: 1.1298, Train: 60.00%, Valid: 58.75% Test: 56.86%\n",
      "Run: 10, Epoch: 21, Loss: 1.0194, Train: 59.17%, Valid: 60.00% Test: 54.90%\n",
      "Run: 10, Epoch: 22, Loss: 1.0005, Train: 61.67%, Valid: 61.25% Test: 58.82%\n",
      "Run: 10, Epoch: 23, Loss: 0.9865, Train: 62.50%, Valid: 61.25% Test: 56.86%\n",
      "Run: 10, Epoch: 24, Loss: 0.9609, Train: 62.50%, Valid: 57.50% Test: 54.90%\n",
      "Run: 10, Epoch: 25, Loss: 0.9814, Train: 63.33%, Valid: 57.50% Test: 54.90%\n",
      "Run: 10, Epoch: 26, Loss: 0.9690, Train: 65.00%, Valid: 60.00% Test: 54.90%\n",
      "Run: 10, Epoch: 27, Loss: 0.9774, Train: 65.00%, Valid: 60.00% Test: 54.90%\n",
      "Run: 10, Epoch: 28, Loss: 0.9743, Train: 65.00%, Valid: 61.25% Test: 54.90%\n",
      "Run: 10, Epoch: 29, Loss: 0.9953, Train: 65.00%, Valid: 61.25% Test: 54.90%\n",
      "Run: 10, Epoch: 30, Loss: 0.9781, Train: 62.50%, Valid: 60.00% Test: 54.90%\n",
      "Run: 10, Epoch: 31, Loss: 0.9899, Train: 60.00%, Valid: 57.50% Test: 56.86%\n",
      "Run: 10, Epoch: 32, Loss: 1.0577, Train: 62.50%, Valid: 58.75% Test: 56.86%\n",
      "Run: 10, Epoch: 33, Loss: 0.9363, Train: 63.33%, Valid: 60.00% Test: 54.90%\n",
      "Run: 10, Epoch: 34, Loss: 0.9716, Train: 64.17%, Valid: 61.25% Test: 56.86%\n",
      "Run: 10, Epoch: 35, Loss: 0.9407, Train: 62.50%, Valid: 61.25% Test: 58.82%\n",
      "Run: 10, Epoch: 36, Loss: 0.9873, Train: 65.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 10, Epoch: 37, Loss: 1.0125, Train: 65.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 10, Epoch: 38, Loss: 1.0127, Train: 67.50%, Valid: 62.50% Test: 58.82%\n",
      "Run: 10, Epoch: 39, Loss: 0.9645, Train: 64.17%, Valid: 62.50% Test: 56.86%\n",
      "Run: 10, Epoch: 40, Loss: 0.9291, Train: 64.17%, Valid: 61.25% Test: 56.86%\n",
      "Run: 10, Epoch: 41, Loss: 0.9101, Train: 65.00%, Valid: 60.00% Test: 54.90%\n",
      "Run: 10, Epoch: 42, Loss: 0.9057, Train: 66.67%, Valid: 60.00% Test: 56.86%\n",
      "Run: 10, Epoch: 43, Loss: 0.9103, Train: 67.50%, Valid: 61.25% Test: 60.78%\n",
      "Run: 10, Epoch: 44, Loss: 0.9494, Train: 70.00%, Valid: 61.25% Test: 56.86%\n",
      "Run: 10, Epoch: 45, Loss: 0.9227, Train: 69.17%, Valid: 61.25% Test: 58.82%\n",
      "Run: 10, Epoch: 46, Loss: 0.9070, Train: 65.83%, Valid: 60.00% Test: 56.86%\n",
      "Run: 10, Epoch: 47, Loss: 0.8869, Train: 66.67%, Valid: 60.00% Test: 56.86%\n",
      "Run: 10, Epoch: 48, Loss: 0.8899, Train: 66.67%, Valid: 61.25% Test: 56.86%\n",
      "Run: 10, Epoch: 49, Loss: 0.9167, Train: 69.17%, Valid: 62.50% Test: 54.90%\n",
      "Run: 10, Epoch: 50, Loss: 0.8537, Train: 68.33%, Valid: 61.25% Test: 54.90%\n",
      "Run: 10, Epoch: 51, Loss: 0.8506, Train: 66.67%, Valid: 61.25% Test: 52.94%\n",
      "Run: 10, Epoch: 52, Loss: 0.8555, Train: 66.67%, Valid: 58.75% Test: 52.94%\n",
      "Run: 10, Epoch: 53, Loss: 0.8150, Train: 68.33%, Valid: 60.00% Test: 50.98%\n",
      "Run: 10, Epoch: 54, Loss: 0.8272, Train: 69.17%, Valid: 60.00% Test: 54.90%\n",
      "Run: 10, Epoch: 55, Loss: 0.7686, Train: 68.33%, Valid: 60.00% Test: 54.90%\n",
      "Run: 10, Epoch: 56, Loss: 0.7987, Train: 69.17%, Valid: 60.00% Test: 56.86%\n",
      "Run: 10, Epoch: 57, Loss: 0.8586, Train: 70.83%, Valid: 61.25% Test: 54.90%\n",
      "Run: 10, Epoch: 58, Loss: 0.7680, Train: 69.17%, Valid: 61.25% Test: 54.90%\n",
      "Run: 10, Epoch: 59, Loss: 0.8512, Train: 68.33%, Valid: 56.25% Test: 54.90%\n",
      "Run: 10, Epoch: 60, Loss: 0.8429, Train: 68.33%, Valid: 60.00% Test: 60.78%\n",
      "Run: 10, Epoch: 61, Loss: 0.7983, Train: 68.33%, Valid: 61.25% Test: 60.78%\n",
      "Run: 10, Epoch: 62, Loss: 0.7856, Train: 70.83%, Valid: 62.50% Test: 58.82%\n",
      "Run: 10, Epoch: 63, Loss: 0.8421, Train: 68.33%, Valid: 61.25% Test: 50.98%\n",
      "Run: 10, Epoch: 64, Loss: 0.7843, Train: 71.67%, Valid: 57.50% Test: 54.90%\n",
      "Run: 10, Epoch: 65, Loss: 0.7847, Train: 72.50%, Valid: 56.25% Test: 58.82%\n",
      "Run: 10, Epoch: 66, Loss: 0.7555, Train: 64.17%, Valid: 56.25% Test: 54.90%\n",
      "Run: 10, Epoch: 67, Loss: 0.8722, Train: 63.33%, Valid: 56.25% Test: 50.98%\n",
      "Run: 10, Epoch: 68, Loss: 0.8216, Train: 65.00%, Valid: 56.25% Test: 50.98%\n",
      "Run: 10, Epoch: 69, Loss: 0.7956, Train: 62.50%, Valid: 56.25% Test: 50.98%\n",
      "Run: 10, Epoch: 70, Loss: 0.8034, Train: 65.83%, Valid: 61.25% Test: 56.86%\n",
      "Run: 10, Epoch: 71, Loss: 0.8285, Train: 68.33%, Valid: 61.25% Test: 58.82%\n",
      "Run: 10, Epoch: 72, Loss: 0.7636, Train: 66.67%, Valid: 61.25% Test: 52.94%\n",
      "Run: 10, Epoch: 73, Loss: 0.8096, Train: 66.67%, Valid: 60.00% Test: 58.82%\n",
      "Run: 10, Epoch: 74, Loss: 0.7662, Train: 65.83%, Valid: 61.25% Test: 54.90%\n",
      "Run: 10, Epoch: 75, Loss: 0.8611, Train: 69.17%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 76, Loss: 0.7505, Train: 65.83%, Valid: 53.75% Test: 56.86%\n",
      "Run: 10, Epoch: 77, Loss: 0.8271, Train: 65.83%, Valid: 55.00% Test: 58.82%\n",
      "Run: 10, Epoch: 78, Loss: 0.8975, Train: 66.67%, Valid: 62.50% Test: 58.82%\n",
      "Run: 10, Epoch: 79, Loss: 0.7519, Train: 63.33%, Valid: 61.25% Test: 50.98%\n",
      "Run: 10, Epoch: 80, Loss: 0.8439, Train: 65.00%, Valid: 60.00% Test: 56.86%\n",
      "Run: 10, Epoch: 81, Loss: 0.7856, Train: 58.33%, Valid: 55.00% Test: 58.82%\n",
      "Run: 10, Epoch: 82, Loss: 0.7291, Train: 58.33%, Valid: 55.00% Test: 56.86%\n",
      "Run: 10, Epoch: 83, Loss: 0.8214, Train: 59.17%, Valid: 53.75% Test: 56.86%\n",
      "Run: 10, Epoch: 84, Loss: 0.8024, Train: 57.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 10, Epoch: 85, Loss: 0.7630, Train: 60.00%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 86, Loss: 0.7726, Train: 64.17%, Valid: 61.25% Test: 54.90%\n",
      "Run: 10, Epoch: 87, Loss: 0.7815, Train: 69.17%, Valid: 62.50% Test: 56.86%\n",
      "Run: 10, Epoch: 88, Loss: 0.7630, Train: 69.17%, Valid: 62.50% Test: 56.86%\n",
      "Run: 10, Epoch: 89, Loss: 0.7687, Train: 70.00%, Valid: 62.50% Test: 58.82%\n",
      "Run: 10, Epoch: 90, Loss: 0.7124, Train: 68.33%, Valid: 62.50% Test: 60.78%\n",
      "Run: 10, Epoch: 91, Loss: 0.7634, Train: 69.17%, Valid: 60.00% Test: 60.78%\n",
      "Run: 10, Epoch: 92, Loss: 0.7728, Train: 68.33%, Valid: 61.25% Test: 60.78%\n",
      "Run: 10, Epoch: 93, Loss: 0.7893, Train: 70.00%, Valid: 62.50% Test: 62.75%\n",
      "Run: 10, Epoch: 94, Loss: 0.7753, Train: 69.17%, Valid: 62.50% Test: 56.86%\n",
      "Run: 10, Epoch: 95, Loss: 0.7430, Train: 66.67%, Valid: 63.75% Test: 58.82%\n",
      "Run: 10, Epoch: 96, Loss: 0.7806, Train: 70.00%, Valid: 63.75% Test: 60.78%\n",
      "Run: 10, Epoch: 97, Loss: 0.7453, Train: 67.50%, Valid: 60.00% Test: 56.86%\n",
      "Run: 10, Epoch: 98, Loss: 0.7795, Train: 67.50%, Valid: 58.75% Test: 60.78%\n",
      "Run: 10, Epoch: 99, Loss: 0.8254, Train: 66.67%, Valid: 56.25% Test: 60.78%\n",
      "Run: 10, Epoch: 100, Loss: 0.7910, Train: 65.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 10, Epoch: 101, Loss: 0.7768, Train: 63.33%, Valid: 58.75% Test: 58.82%\n",
      "Run: 10, Epoch: 102, Loss: 0.7318, Train: 67.50%, Valid: 58.75% Test: 58.82%\n",
      "Run: 10, Epoch: 103, Loss: 0.7152, Train: 66.67%, Valid: 58.75% Test: 58.82%\n",
      "Run: 10, Epoch: 104, Loss: 0.7006, Train: 72.50%, Valid: 58.75% Test: 62.75%\n",
      "Run: 10, Epoch: 105, Loss: 0.7863, Train: 74.17%, Valid: 62.50% Test: 62.75%\n",
      "Run: 10, Epoch: 106, Loss: 0.7467, Train: 70.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 10, Epoch: 107, Loss: 0.7581, Train: 68.33%, Valid: 51.25% Test: 52.94%\n",
      "Run: 10, Epoch: 108, Loss: 0.7274, Train: 58.33%, Valid: 42.50% Test: 47.06%\n",
      "Run: 10, Epoch: 109, Loss: 0.7401, Train: 66.67%, Valid: 53.75% Test: 52.94%\n",
      "Run: 10, Epoch: 110, Loss: 0.6878, Train: 69.17%, Valid: 61.25% Test: 56.86%\n",
      "Run: 10, Epoch: 111, Loss: 0.7541, Train: 69.17%, Valid: 63.75% Test: 58.82%\n",
      "Run: 10, Epoch: 112, Loss: 0.8030, Train: 73.33%, Valid: 65.00% Test: 62.75%\n",
      "Run: 10, Epoch: 113, Loss: 0.7542, Train: 69.17%, Valid: 65.00% Test: 66.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 114, Loss: 0.6608, Train: 69.17%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 115, Loss: 0.8099, Train: 70.00%, Valid: 58.75% Test: 64.71%\n",
      "Run: 10, Epoch: 116, Loss: 0.7028, Train: 67.50%, Valid: 56.25% Test: 58.82%\n",
      "Run: 10, Epoch: 117, Loss: 0.7326, Train: 66.67%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 118, Loss: 0.7035, Train: 66.67%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 119, Loss: 0.8508, Train: 64.17%, Valid: 56.25% Test: 58.82%\n",
      "Run: 10, Epoch: 120, Loss: 0.6983, Train: 65.83%, Valid: 57.50% Test: 60.78%\n",
      "Run: 10, Epoch: 121, Loss: 0.6753, Train: 65.83%, Valid: 63.75% Test: 62.75%\n",
      "Run: 10, Epoch: 122, Loss: 0.7377, Train: 70.00%, Valid: 66.25% Test: 62.75%\n",
      "Run: 10, Epoch: 123, Loss: 0.7589, Train: 70.83%, Valid: 65.00% Test: 62.75%\n",
      "Run: 10, Epoch: 124, Loss: 0.7297, Train: 71.67%, Valid: 62.50% Test: 62.75%\n",
      "Run: 10, Epoch: 125, Loss: 0.7033, Train: 70.00%, Valid: 63.75% Test: 62.75%\n",
      "Run: 10, Epoch: 126, Loss: 0.7432, Train: 69.17%, Valid: 60.00% Test: 62.75%\n",
      "Run: 10, Epoch: 127, Loss: 0.6437, Train: 70.00%, Valid: 58.75% Test: 62.75%\n",
      "Run: 10, Epoch: 128, Loss: 0.6572, Train: 68.33%, Valid: 60.00% Test: 62.75%\n",
      "Run: 10, Epoch: 129, Loss: 0.6850, Train: 65.00%, Valid: 62.50% Test: 60.78%\n",
      "Run: 10, Epoch: 130, Loss: 0.7042, Train: 61.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 10, Epoch: 131, Loss: 0.6909, Train: 60.00%, Valid: 55.00% Test: 54.90%\n",
      "Run: 10, Epoch: 132, Loss: 0.6483, Train: 59.17%, Valid: 55.00% Test: 54.90%\n",
      "Run: 10, Epoch: 133, Loss: 0.7038, Train: 57.50%, Valid: 53.75% Test: 52.94%\n",
      "Run: 10, Epoch: 134, Loss: 0.6893, Train: 57.50%, Valid: 57.50% Test: 54.90%\n",
      "Run: 10, Epoch: 135, Loss: 0.7107, Train: 60.00%, Valid: 57.50% Test: 54.90%\n",
      "Run: 10, Epoch: 136, Loss: 0.7186, Train: 62.50%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 137, Loss: 0.7547, Train: 62.50%, Valid: 58.75% Test: 58.82%\n",
      "Run: 10, Epoch: 138, Loss: 0.6842, Train: 68.33%, Valid: 62.50% Test: 66.67%\n",
      "Run: 10, Epoch: 139, Loss: 0.7467, Train: 73.33%, Valid: 68.75% Test: 68.63%\n",
      "Run: 10, Epoch: 140, Loss: 0.7401, Train: 75.00%, Valid: 62.50% Test: 64.71%\n",
      "Run: 10, Epoch: 141, Loss: 0.6761, Train: 75.00%, Valid: 62.50% Test: 66.67%\n",
      "Run: 10, Epoch: 142, Loss: 0.6698, Train: 73.33%, Valid: 61.25% Test: 66.67%\n",
      "Run: 10, Epoch: 143, Loss: 0.7073, Train: 70.00%, Valid: 56.25% Test: 56.86%\n",
      "Run: 10, Epoch: 144, Loss: 0.6825, Train: 63.33%, Valid: 52.50% Test: 56.86%\n",
      "Run: 10, Epoch: 145, Loss: 0.7824, Train: 65.83%, Valid: 53.75% Test: 54.90%\n",
      "Run: 10, Epoch: 146, Loss: 0.6582, Train: 69.17%, Valid: 60.00% Test: 64.71%\n",
      "Run: 10, Epoch: 147, Loss: 0.8264, Train: 68.33%, Valid: 57.50% Test: 64.71%\n",
      "Run: 10, Epoch: 148, Loss: 0.8026, Train: 70.00%, Valid: 56.25% Test: 58.82%\n",
      "Run: 10, Epoch: 149, Loss: 0.8460, Train: 73.33%, Valid: 63.75% Test: 60.78%\n",
      "Run: 10, Epoch: 150, Loss: 0.7355, Train: 74.17%, Valid: 63.75% Test: 68.63%\n",
      "Run: 10, Epoch: 151, Loss: 0.7829, Train: 60.83%, Valid: 57.50% Test: 49.02%\n",
      "Run: 10, Epoch: 152, Loss: 0.7784, Train: 70.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 10, Epoch: 153, Loss: 0.6833, Train: 70.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 10, Epoch: 154, Loss: 0.6837, Train: 73.33%, Valid: 66.25% Test: 66.67%\n",
      "Run: 10, Epoch: 155, Loss: 0.7587, Train: 71.67%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 156, Loss: 0.7063, Train: 70.00%, Valid: 63.75% Test: 62.75%\n",
      "Run: 10, Epoch: 157, Loss: 0.6963, Train: 73.33%, Valid: 66.25% Test: 62.75%\n",
      "Run: 10, Epoch: 158, Loss: 0.7375, Train: 75.83%, Valid: 65.00% Test: 60.78%\n",
      "Run: 10, Epoch: 159, Loss: 0.6685, Train: 72.50%, Valid: 63.75% Test: 58.82%\n",
      "Run: 10, Epoch: 160, Loss: 0.6287, Train: 75.00%, Valid: 65.00% Test: 60.78%\n",
      "Run: 10, Epoch: 161, Loss: 0.6496, Train: 75.00%, Valid: 62.50% Test: 62.75%\n",
      "Run: 10, Epoch: 162, Loss: 0.6988, Train: 75.00%, Valid: 63.75% Test: 62.75%\n",
      "Run: 10, Epoch: 163, Loss: 0.6767, Train: 74.17%, Valid: 66.25% Test: 62.75%\n",
      "Run: 10, Epoch: 164, Loss: 0.7289, Train: 74.17%, Valid: 65.00% Test: 68.63%\n",
      "Run: 10, Epoch: 165, Loss: 0.7186, Train: 72.50%, Valid: 61.25% Test: 70.59%\n",
      "Run: 10, Epoch: 166, Loss: 0.8604, Train: 70.00%, Valid: 57.50% Test: 66.67%\n",
      "Run: 10, Epoch: 167, Loss: 0.6779, Train: 70.83%, Valid: 56.25% Test: 62.75%\n",
      "Run: 10, Epoch: 168, Loss: 0.7268, Train: 74.17%, Valid: 60.00% Test: 64.71%\n",
      "Run: 10, Epoch: 169, Loss: 0.7173, Train: 73.33%, Valid: 62.50% Test: 64.71%\n",
      "Run: 10, Epoch: 170, Loss: 0.6763, Train: 76.67%, Valid: 66.25% Test: 56.86%\n",
      "Run: 10, Epoch: 171, Loss: 0.7083, Train: 73.33%, Valid: 60.00% Test: 60.78%\n",
      "Run: 10, Epoch: 172, Loss: 0.8183, Train: 75.83%, Valid: 65.00% Test: 60.78%\n",
      "Run: 10, Epoch: 173, Loss: 0.6993, Train: 76.67%, Valid: 65.00% Test: 68.63%\n",
      "Run: 10, Epoch: 174, Loss: 0.7860, Train: 74.17%, Valid: 65.00% Test: 66.67%\n",
      "Run: 10, Epoch: 175, Loss: 0.7412, Train: 68.33%, Valid: 60.00% Test: 64.71%\n",
      "Run: 10, Epoch: 176, Loss: 0.7966, Train: 70.00%, Valid: 61.25% Test: 68.63%\n",
      "Run: 10, Epoch: 177, Loss: 0.6766, Train: 70.83%, Valid: 60.00% Test: 72.55%\n",
      "Run: 10, Epoch: 178, Loss: 0.6824, Train: 71.67%, Valid: 62.50% Test: 68.63%\n",
      "Run: 10, Epoch: 179, Loss: 0.6443, Train: 71.67%, Valid: 61.25% Test: 72.55%\n",
      "Run: 10, Epoch: 180, Loss: 0.6315, Train: 75.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 10, Epoch: 181, Loss: 0.6550, Train: 71.67%, Valid: 61.25% Test: 58.82%\n",
      "Run: 10, Epoch: 182, Loss: 0.6181, Train: 70.83%, Valid: 60.00% Test: 62.75%\n",
      "Run: 10, Epoch: 183, Loss: 0.7347, Train: 71.67%, Valid: 58.75% Test: 64.71%\n",
      "Run: 10, Epoch: 184, Loss: 0.6842, Train: 70.83%, Valid: 60.00% Test: 66.67%\n",
      "Run: 10, Epoch: 185, Loss: 0.6709, Train: 73.33%, Valid: 63.75% Test: 70.59%\n",
      "Run: 10, Epoch: 186, Loss: 0.6457, Train: 75.00%, Valid: 63.75% Test: 68.63%\n",
      "Run: 10, Epoch: 187, Loss: 0.6077, Train: 73.33%, Valid: 62.50% Test: 70.59%\n",
      "Run: 10, Epoch: 188, Loss: 0.6725, Train: 71.67%, Valid: 60.00% Test: 68.63%\n",
      "Run: 10, Epoch: 189, Loss: 0.6307, Train: 71.67%, Valid: 61.25% Test: 62.75%\n",
      "Run: 10, Epoch: 190, Loss: 0.6760, Train: 74.17%, Valid: 62.50% Test: 62.75%\n",
      "Run: 10, Epoch: 191, Loss: 0.6787, Train: 76.67%, Valid: 61.25% Test: 66.67%\n",
      "Run: 10, Epoch: 192, Loss: 0.6503, Train: 76.67%, Valid: 61.25% Test: 66.67%\n",
      "Run: 10, Epoch: 193, Loss: 0.6955, Train: 72.50%, Valid: 63.75% Test: 62.75%\n",
      "Run: 10, Epoch: 194, Loss: 0.5933, Train: 73.33%, Valid: 63.75% Test: 58.82%\n",
      "Run: 10, Epoch: 195, Loss: 0.6886, Train: 73.33%, Valid: 61.25% Test: 58.82%\n",
      "Run: 10, Epoch: 196, Loss: 0.6606, Train: 70.00%, Valid: 58.75% Test: 62.75%\n",
      "Run: 10, Epoch: 197, Loss: 0.5914, Train: 70.83%, Valid: 57.50% Test: 60.78%\n",
      "Run: 10, Epoch: 198, Loss: 0.6408, Train: 73.33%, Valid: 58.75% Test: 64.71%\n",
      "Run: 10, Epoch: 199, Loss: 0.6867, Train: 74.17%, Valid: 62.50% Test: 64.71%\n",
      "Run: 10, Epoch: 200, Loss: 0.5891, Train: 72.50%, Valid: 62.50% Test: 64.71%\n",
      "Run 10:\n",
      "Highest Train: 76.67\n",
      "Highest Valid: 68.75\n",
      "  Final Train: 73.33\n",
      "   Final Test: 68.63\n",
      "All runs:\n",
      "Highest Train: 77.17 Â± 5.30\n",
      "Highest Valid: 63.38 Â± 4.90\n",
      "  Final Train: 65.67 Â± 6.90\n",
      "   Final Test: 60.00 Â± 6.74\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 8, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.5,'num_layers_mlp': 3}\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = GAT(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout,args.heads)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 10,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(20, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        \n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.01)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.01)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1b267c",
   "metadata": {},
   "source": [
    "# Topo-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceda79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4407be0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515], topo=[251, 24])\n"
     ]
    }
   ],
   "source": [
    "topo_fe=torch.cat((topo_betti0,topo_betti1),1)\n",
    "data.topo=topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "189943fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x12e9b9000>\n",
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 63.75\n",
      "  Final Train: 72.50\n",
      "   Final Test: 66.67\n",
      "Run 02:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 60.00\n",
      "  Final Train: 97.50\n",
      "   Final Test: 52.94\n",
      "Run 03:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 60.00\n",
      "  Final Train: 72.50\n",
      "   Final Test: 60.78\n",
      "Run 04:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 53.75\n",
      "  Final Train: 86.67\n",
      "   Final Test: 52.94\n",
      "Run 05:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 52.50\n",
      "  Final Train: 49.17\n",
      "   Final Test: 39.22\n",
      "Run 06:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 52.50\n",
      "  Final Train: 82.50\n",
      "   Final Test: 60.78\n",
      "Run 07:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 58.75\n",
      "  Final Train: 73.33\n",
      "   Final Test: 58.82\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 57.50\n",
      "  Final Train: 61.67\n",
      "   Final Test: 60.78\n",
      "Run 09:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 52.50\n",
      "  Final Train: 91.67\n",
      "   Final Test: 52.94\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 56.25\n",
      "  Final Train: 68.33\n",
      "   Final Test: 54.90\n",
      "All runs:\n",
      "Highest Train: 99.50 Â± 0.43\n",
      "Highest Valid: 56.75 Â± 3.92\n",
      "  Final Train: 75.58 Â± 14.44\n",
      "   Final Test: 56.08 Â± 7.46\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 8, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.0,'num_layers_mlp': 3}\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = GCN(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout,args.heads)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 10,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(20, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        \n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.001)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                #print(f'Run: {run + 1:02d}, 'f'Epoch: {epoch:02d}, 'f'Loss: {loss:.4f}, 'f'Train: {100 * train_acc:.2f}%, '\n",
    "                 #     f'Valid: {100 * valid_acc:.2f}% '\n",
    "                  #    f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb1beb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
