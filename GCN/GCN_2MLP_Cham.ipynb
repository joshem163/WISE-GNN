{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af88d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx import ego_graph\n",
    "\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "\n",
    "#from logger import Logger\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import WikipediaNetwork\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7babc9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2277, 2325], y=[2277], train_mask=[2277, 10], val_mask=[2277, 10], test_mask=[2277, 10], adj_t=[2277, 2277, nnz=36101])\n"
     ]
    }
   ],
   "source": [
    "dataset = WikipediaNetwork(root='/tmp/chameleon', name='chameleon',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "print(data)\n",
    "#split_idx = dataset.get_idx_split()\n",
    "#train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91fdcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10920\n",
      "7290\n",
      "4560\n"
     ]
    }
   ],
   "source": [
    "train_index = np.where(data.train_mask)[0]\n",
    "print(len(train_index))\n",
    "valid_index = np.where(data.val_mask)[0]\n",
    "print(len(valid_index))\n",
    "test_index = np.where(data.test_mask)[0]\n",
    "print(len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0b82f",
   "metadata": {},
   "source": [
    "# GCN using only domain Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9ef33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, runs, info=None):\n",
    "        self.info = info\n",
    "        self.results = [[] for _ in range(runs)]\n",
    "\n",
    "    def add_result(self, run, result):\n",
    "        assert len(result) == 3\n",
    "        assert run >= 0 and run < len(self.results)\n",
    "        self.results[run].append(result)\n",
    "\n",
    "    def print_statistics(self, run=None):\n",
    "        if run is not None:\n",
    "            result = 100 * torch.tensor(self.results[run])\n",
    "            argmax = result[:, 1].argmax().item()\n",
    "            print(f'Run {run + 1:02d}:')\n",
    "            print(f'Highest Train: {result[:, 0].max():.2f}')\n",
    "            print(f'Highest Valid: {result[:, 1].max():.2f}')\n",
    "            print(f'  Final Train: {result[argmax, 0]:.2f}')\n",
    "            print(f'   Final Test: {result[argmax, 2]:.2f}')\n",
    "        else:\n",
    "            result = 100 * torch.tensor(self.results)\n",
    "\n",
    "            best_results = []\n",
    "            for r in result:\n",
    "                train1 = r[:, 0].max().item()\n",
    "                valid = r[:, 1].max().item()\n",
    "                train2 = r[r[:, 1].argmax(), 0].item()\n",
    "                test = r[r[:, 1].argmax(), 2].item()\n",
    "                best_results.append((train1, valid, train2, test))\n",
    "\n",
    "            best_result = torch.tensor(best_results)\n",
    "\n",
    "            print(f'All runs:')\n",
    "            r = best_result[:, 0]\n",
    "            print(f'Highest Train: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 1]\n",
    "            print(f'Highest Valid: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 2]\n",
    "            print(f'  Final Train: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 3]\n",
    "            print(f'   Final Test: {r.mean():.2f} ± {r.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47468ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(len(out))\n",
    "    #print(data.y.squeeze(1)[train_idx])\n",
    "    loss = F.nll_loss(out, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.adj_t)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=[data.train_mask[i][0] for i in range(183)]\n",
    "train_index = np.where(idx)[0]\n",
    "print(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b23796d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x15246a290>\n",
      "Run: 01, Epoch: 01, Loss: 2.0705, Train: 24.91%, Valid: 21.67% Test: 23.90%\n",
      "Run: 01, Epoch: 02, Loss: 1.3888, Train: 34.89%, Valid: 29.77% Test: 31.80%\n",
      "Run: 01, Epoch: 03, Loss: 1.3086, Train: 35.16%, Valid: 32.24% Test: 32.24%\n",
      "Run: 01, Epoch: 04, Loss: 1.2730, Train: 34.98%, Valid: 30.73% Test: 31.36%\n",
      "Run: 01, Epoch: 05, Loss: 1.2449, Train: 39.74%, Valid: 35.53% Test: 33.99%\n",
      "Run: 01, Epoch: 06, Loss: 1.2176, Train: 44.78%, Valid: 37.31% Test: 39.25%\n",
      "Run: 01, Epoch: 07, Loss: 1.2017, Train: 46.61%, Valid: 40.19% Test: 41.01%\n",
      "Run: 01, Epoch: 08, Loss: 1.1655, Train: 49.82%, Valid: 43.62% Test: 43.42%\n",
      "Run: 01, Epoch: 09, Loss: 1.1692, Train: 52.66%, Valid: 45.82% Test: 47.15%\n",
      "Run: 01, Epoch: 10, Loss: 1.1402, Train: 53.94%, Valid: 48.83% Test: 48.46%\n",
      "Run: 01, Epoch: 11, Loss: 1.1236, Train: 57.69%, Valid: 52.13% Test: 51.97%\n",
      "Run: 01, Epoch: 12, Loss: 1.1029, Train: 60.26%, Valid: 55.01% Test: 54.39%\n",
      "Run: 01, Epoch: 13, Loss: 1.0898, Train: 60.99%, Valid: 55.97% Test: 55.48%\n",
      "Run: 01, Epoch: 14, Loss: 1.0738, Train: 60.99%, Valid: 54.60% Test: 54.61%\n",
      "Run: 01, Epoch: 15, Loss: 1.0586, Train: 61.72%, Valid: 53.64% Test: 55.48%\n",
      "Run: 01, Epoch: 16, Loss: 1.0337, Train: 61.72%, Valid: 54.05% Test: 55.70%\n",
      "Run: 01, Epoch: 17, Loss: 1.0329, Train: 62.09%, Valid: 54.73% Test: 55.92%\n",
      "Run: 01, Epoch: 18, Loss: 1.0239, Train: 63.10%, Valid: 55.42% Test: 55.92%\n",
      "Run: 01, Epoch: 19, Loss: 1.0040, Train: 63.28%, Valid: 55.69% Test: 56.14%\n",
      "Run: 01, Epoch: 20, Loss: 0.9812, Train: 64.38%, Valid: 56.38% Test: 57.02%\n",
      "Run: 01, Epoch: 21, Loss: 0.9640, Train: 63.92%, Valid: 55.97% Test: 57.02%\n",
      "Run: 01, Epoch: 22, Loss: 0.9567, Train: 64.56%, Valid: 55.83% Test: 57.46%\n",
      "Run: 01, Epoch: 23, Loss: 0.9497, Train: 65.57%, Valid: 56.38% Test: 58.99%\n",
      "Run: 01, Epoch: 24, Loss: 0.9255, Train: 66.67%, Valid: 56.24% Test: 58.33%\n",
      "Run: 01, Epoch: 25, Loss: 0.9122, Train: 67.40%, Valid: 56.10% Test: 58.99%\n",
      "Run: 01, Epoch: 26, Loss: 0.9007, Train: 67.12%, Valid: 56.52% Test: 58.55%\n",
      "Run: 01, Epoch: 27, Loss: 0.8770, Train: 67.40%, Valid: 56.79% Test: 58.77%\n",
      "Run: 01, Epoch: 28, Loss: 0.8655, Train: 67.12%, Valid: 57.20% Test: 59.43%\n",
      "Run: 01, Epoch: 29, Loss: 0.8547, Train: 68.96%, Valid: 59.26% Test: 60.31%\n",
      "Run: 01, Epoch: 30, Loss: 0.8432, Train: 70.42%, Valid: 60.49% Test: 61.18%\n",
      "Run: 01, Epoch: 31, Loss: 0.8236, Train: 71.25%, Valid: 60.36% Test: 60.75%\n",
      "Run: 01, Epoch: 32, Loss: 0.8094, Train: 71.89%, Valid: 60.91% Test: 60.53%\n",
      "Run: 01, Epoch: 33, Loss: 0.7883, Train: 72.99%, Valid: 62.14% Test: 60.96%\n",
      "Run: 01, Epoch: 34, Loss: 0.7889, Train: 73.17%, Valid: 62.28% Test: 60.75%\n",
      "Run: 01, Epoch: 35, Loss: 0.7658, Train: 73.63%, Valid: 61.73% Test: 60.31%\n",
      "Run: 01, Epoch: 36, Loss: 0.7487, Train: 74.45%, Valid: 62.00% Test: 60.75%\n",
      "Run: 01, Epoch: 37, Loss: 0.7507, Train: 75.73%, Valid: 63.10% Test: 61.18%\n",
      "Run: 01, Epoch: 38, Loss: 0.7403, Train: 75.46%, Valid: 63.65% Test: 62.28%\n",
      "Run: 01, Epoch: 39, Loss: 0.7046, Train: 76.92%, Valid: 62.55% Test: 61.84%\n",
      "Run: 01, Epoch: 40, Loss: 0.7184, Train: 77.38%, Valid: 63.51% Test: 62.28%\n",
      "Run: 01, Epoch: 41, Loss: 0.7015, Train: 78.02%, Valid: 63.51% Test: 61.18%\n",
      "Run: 01, Epoch: 42, Loss: 0.6805, Train: 78.75%, Valid: 64.06% Test: 63.82%\n",
      "Run: 01, Epoch: 43, Loss: 0.6800, Train: 78.94%, Valid: 64.20% Test: 64.04%\n",
      "Run: 01, Epoch: 44, Loss: 0.6603, Train: 79.21%, Valid: 62.69% Test: 62.50%\n",
      "Run: 01, Epoch: 45, Loss: 0.6302, Train: 79.95%, Valid: 63.79% Test: 63.38%\n",
      "Run: 01, Epoch: 46, Loss: 0.6512, Train: 80.68%, Valid: 65.29% Test: 64.04%\n",
      "Run: 01, Epoch: 47, Loss: 0.6409, Train: 80.86%, Valid: 64.61% Test: 62.94%\n",
      "Run: 01, Epoch: 48, Loss: 0.6156, Train: 80.40%, Valid: 64.33% Test: 63.82%\n",
      "Run: 01, Epoch: 49, Loss: 0.6041, Train: 81.23%, Valid: 65.43% Test: 63.60%\n",
      "Run: 01, Epoch: 50, Loss: 0.5980, Train: 81.04%, Valid: 64.88% Test: 62.72%\n",
      "Run: 01, Epoch: 51, Loss: 0.6032, Train: 82.05%, Valid: 64.61% Test: 63.38%\n",
      "Run: 01, Epoch: 52, Loss: 0.5746, Train: 81.78%, Valid: 64.20% Test: 63.38%\n",
      "Run: 01, Epoch: 53, Loss: 0.5793, Train: 82.33%, Valid: 65.16% Test: 63.60%\n",
      "Run: 01, Epoch: 54, Loss: 0.5738, Train: 83.15%, Valid: 65.43% Test: 63.38%\n",
      "Run: 01, Epoch: 55, Loss: 0.5526, Train: 83.24%, Valid: 65.02% Test: 62.72%\n",
      "Run: 01, Epoch: 56, Loss: 0.5549, Train: 82.69%, Valid: 64.47% Test: 62.72%\n",
      "Run: 01, Epoch: 57, Loss: 0.5345, Train: 84.07%, Valid: 65.98% Test: 63.82%\n",
      "Run: 01, Epoch: 58, Loss: 0.5436, Train: 83.61%, Valid: 67.08% Test: 65.13%\n",
      "Run: 01, Epoch: 59, Loss: 0.5177, Train: 83.97%, Valid: 65.98% Test: 64.69%\n",
      "Run: 01, Epoch: 60, Loss: 0.5308, Train: 84.34%, Valid: 66.26% Test: 64.25%\n",
      "Run: 01, Epoch: 61, Loss: 0.5197, Train: 84.89%, Valid: 66.26% Test: 65.35%\n",
      "Run: 01, Epoch: 62, Loss: 0.5059, Train: 85.62%, Valid: 66.26% Test: 65.57%\n",
      "Run: 01, Epoch: 63, Loss: 0.4927, Train: 85.44%, Valid: 67.22% Test: 65.35%\n",
      "Run: 01, Epoch: 64, Loss: 0.4869, Train: 85.44%, Valid: 66.12% Test: 64.91%\n",
      "Run: 01, Epoch: 65, Loss: 0.4805, Train: 84.89%, Valid: 65.71% Test: 64.69%\n",
      "Run: 01, Epoch: 66, Loss: 0.4898, Train: 85.53%, Valid: 65.29% Test: 65.35%\n",
      "Run: 01, Epoch: 67, Loss: 0.4734, Train: 85.81%, Valid: 65.43% Test: 64.69%\n",
      "Run: 01, Epoch: 68, Loss: 0.4510, Train: 86.17%, Valid: 66.26% Test: 64.91%\n",
      "Run: 01, Epoch: 69, Loss: 0.4605, Train: 86.08%, Valid: 66.94% Test: 64.25%\n",
      "Run: 01, Epoch: 70, Loss: 0.4446, Train: 85.99%, Valid: 67.49% Test: 65.35%\n",
      "Run: 01, Epoch: 71, Loss: 0.4526, Train: 85.71%, Valid: 65.16% Test: 61.62%\n",
      "Run: 01, Epoch: 72, Loss: 0.4656, Train: 85.99%, Valid: 65.02% Test: 64.04%\n",
      "Run: 01, Epoch: 73, Loss: 0.4510, Train: 87.18%, Valid: 65.71% Test: 63.38%\n",
      "Run: 01, Epoch: 74, Loss: 0.4490, Train: 87.36%, Valid: 65.98% Test: 64.25%\n",
      "Run: 01, Epoch: 75, Loss: 0.4500, Train: 87.18%, Valid: 65.57% Test: 62.72%\n",
      "Run: 01, Epoch: 76, Loss: 0.4349, Train: 86.81%, Valid: 65.71% Test: 63.60%\n",
      "Run: 01, Epoch: 77, Loss: 0.4329, Train: 87.18%, Valid: 64.88% Test: 62.06%\n",
      "Run: 01, Epoch: 78, Loss: 0.4257, Train: 87.64%, Valid: 66.53% Test: 63.60%\n",
      "Run: 01, Epoch: 79, Loss: 0.4187, Train: 88.46%, Valid: 66.94% Test: 64.47%\n",
      "Run: 01, Epoch: 80, Loss: 0.4116, Train: 88.55%, Valid: 67.63% Test: 64.91%\n",
      "Run: 01, Epoch: 81, Loss: 0.4101, Train: 88.19%, Valid: 65.84% Test: 63.38%\n",
      "Run: 01, Epoch: 82, Loss: 0.4013, Train: 86.81%, Valid: 64.20% Test: 64.47%\n",
      "Run: 01, Epoch: 83, Loss: 0.4164, Train: 87.27%, Valid: 65.02% Test: 63.82%\n",
      "Run: 01, Epoch: 84, Loss: 0.4009, Train: 88.10%, Valid: 66.67% Test: 64.69%\n",
      "Run: 01, Epoch: 85, Loss: 0.3948, Train: 87.45%, Valid: 67.08% Test: 64.69%\n",
      "Run: 01, Epoch: 86, Loss: 0.3762, Train: 88.00%, Valid: 66.94% Test: 65.79%\n",
      "Run: 01, Epoch: 87, Loss: 0.3827, Train: 88.28%, Valid: 66.80% Test: 66.67%\n",
      "Run: 01, Epoch: 88, Loss: 0.3785, Train: 88.46%, Valid: 67.08% Test: 66.23%\n",
      "Run: 01, Epoch: 89, Loss: 0.3791, Train: 88.00%, Valid: 68.04% Test: 65.79%\n",
      "Run: 01, Epoch: 90, Loss: 0.3682, Train: 88.92%, Valid: 68.18% Test: 64.47%\n",
      "Run: 01, Epoch: 91, Loss: 0.3740, Train: 89.19%, Valid: 69.27% Test: 65.57%\n",
      "Run: 01, Epoch: 92, Loss: 0.3707, Train: 89.29%, Valid: 68.18% Test: 63.82%\n",
      "Run: 01, Epoch: 93, Loss: 0.3576, Train: 89.84%, Valid: 68.04% Test: 64.69%\n",
      "Run: 01, Epoch: 94, Loss: 0.3514, Train: 90.02%, Valid: 68.31% Test: 64.69%\n",
      "Run: 01, Epoch: 95, Loss: 0.3526, Train: 90.29%, Valid: 68.45% Test: 66.01%\n",
      "Run: 01, Epoch: 96, Loss: 0.3750, Train: 89.93%, Valid: 67.63% Test: 64.25%\n",
      "Run: 01, Epoch: 97, Loss: 0.3462, Train: 88.83%, Valid: 66.94% Test: 64.69%\n",
      "Run: 01, Epoch: 98, Loss: 0.3547, Train: 90.38%, Valid: 67.63% Test: 64.91%\n",
      "Run: 01, Epoch: 99, Loss: 0.3431, Train: 89.38%, Valid: 67.63% Test: 64.25%\n",
      "Run: 01, Epoch: 100, Loss: 0.3475, Train: 88.92%, Valid: 68.18% Test: 65.57%\n",
      "Run 01:\n",
      "Highest Train: 90.38\n",
      "Highest Valid: 69.27\n",
      "  Final Train: 89.19\n",
      "   Final Test: 65.57\n",
      "Run: 02, Epoch: 01, Loss: 2.0562, Train: 32.23%, Valid: 30.18% Test: 29.61%\n",
      "Run: 02, Epoch: 02, Loss: 1.6246, Train: 31.68%, Valid: 27.85% Test: 31.58%\n",
      "Run: 02, Epoch: 03, Loss: 1.3554, Train: 33.33%, Valid: 28.81% Test: 32.24%\n",
      "Run: 02, Epoch: 04, Loss: 1.3078, Train: 32.78%, Valid: 27.30% Test: 30.48%\n",
      "Run: 02, Epoch: 05, Loss: 1.2833, Train: 34.34%, Valid: 29.36% Test: 32.89%\n",
      "Run: 02, Epoch: 06, Loss: 1.2503, Train: 35.53%, Valid: 31.00% Test: 35.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 07, Loss: 1.2599, Train: 37.27%, Valid: 33.06% Test: 36.62%\n",
      "Run: 02, Epoch: 08, Loss: 1.2285, Train: 38.00%, Valid: 34.02% Test: 37.28%\n",
      "Run: 02, Epoch: 09, Loss: 1.2054, Train: 39.38%, Valid: 34.29% Test: 39.04%\n",
      "Run: 02, Epoch: 10, Loss: 1.1993, Train: 45.05%, Valid: 39.23% Test: 44.52%\n",
      "Run: 02, Epoch: 11, Loss: 1.1768, Train: 46.43%, Valid: 39.92% Test: 45.61%\n",
      "Run: 02, Epoch: 12, Loss: 1.1753, Train: 49.54%, Valid: 42.52% Test: 47.15%\n",
      "Run: 02, Epoch: 13, Loss: 1.1534, Train: 52.93%, Valid: 43.90% Test: 49.78%\n",
      "Run: 02, Epoch: 14, Loss: 1.1305, Train: 55.22%, Valid: 46.78% Test: 51.10%\n",
      "Run: 02, Epoch: 15, Loss: 1.1274, Train: 58.79%, Valid: 50.21% Test: 53.73%\n",
      "Run: 02, Epoch: 16, Loss: 1.1116, Train: 61.54%, Valid: 50.21% Test: 54.17%\n",
      "Run: 02, Epoch: 17, Loss: 1.0881, Train: 62.82%, Valid: 50.75% Test: 55.48%\n",
      "Run: 02, Epoch: 18, Loss: 1.0880, Train: 64.38%, Valid: 51.44% Test: 57.24%\n",
      "Run: 02, Epoch: 19, Loss: 1.0726, Train: 64.19%, Valid: 51.99% Test: 57.46%\n",
      "Run: 02, Epoch: 20, Loss: 1.0593, Train: 65.11%, Valid: 53.77% Test: 59.65%\n",
      "Run: 02, Epoch: 21, Loss: 1.0494, Train: 65.57%, Valid: 53.64% Test: 60.53%\n",
      "Run: 02, Epoch: 22, Loss: 1.0299, Train: 65.38%, Valid: 53.50% Test: 59.87%\n",
      "Run: 02, Epoch: 23, Loss: 1.0070, Train: 65.75%, Valid: 52.81% Test: 59.21%\n",
      "Run: 02, Epoch: 24, Loss: 1.0112, Train: 65.84%, Valid: 52.81% Test: 59.43%\n",
      "Run: 02, Epoch: 25, Loss: 0.9890, Train: 66.76%, Valid: 52.13% Test: 59.43%\n",
      "Run: 02, Epoch: 26, Loss: 0.9924, Train: 67.67%, Valid: 52.26% Test: 58.55%\n",
      "Run: 02, Epoch: 27, Loss: 0.9677, Train: 68.13%, Valid: 52.40% Test: 58.55%\n",
      "Run: 02, Epoch: 28, Loss: 0.9608, Train: 68.41%, Valid: 52.26% Test: 58.11%\n",
      "Run: 02, Epoch: 29, Loss: 0.9351, Train: 68.59%, Valid: 52.40% Test: 58.11%\n",
      "Run: 02, Epoch: 30, Loss: 0.9258, Train: 69.87%, Valid: 53.36% Test: 58.99%\n",
      "Run: 02, Epoch: 31, Loss: 0.9079, Train: 69.32%, Valid: 53.22% Test: 58.33%\n",
      "Run: 02, Epoch: 32, Loss: 0.8957, Train: 69.51%, Valid: 53.22% Test: 57.68%\n",
      "Run: 02, Epoch: 33, Loss: 0.8907, Train: 69.32%, Valid: 53.09% Test: 58.11%\n",
      "Run: 02, Epoch: 34, Loss: 0.8889, Train: 69.78%, Valid: 53.22% Test: 58.11%\n",
      "Run: 02, Epoch: 35, Loss: 0.8738, Train: 71.25%, Valid: 54.32% Test: 58.77%\n",
      "Run: 02, Epoch: 36, Loss: 0.8617, Train: 71.98%, Valid: 55.01% Test: 58.99%\n",
      "Run: 02, Epoch: 37, Loss: 0.8473, Train: 71.89%, Valid: 55.56% Test: 59.87%\n",
      "Run: 02, Epoch: 38, Loss: 0.8323, Train: 72.89%, Valid: 55.97% Test: 61.18%\n",
      "Run: 02, Epoch: 39, Loss: 0.8131, Train: 73.08%, Valid: 55.69% Test: 61.18%\n",
      "Run: 02, Epoch: 40, Loss: 0.8124, Train: 74.27%, Valid: 55.42% Test: 62.06%\n",
      "Run: 02, Epoch: 41, Loss: 0.7952, Train: 73.63%, Valid: 55.28% Test: 61.84%\n",
      "Run: 02, Epoch: 42, Loss: 0.7862, Train: 74.18%, Valid: 55.56% Test: 62.28%\n",
      "Run: 02, Epoch: 43, Loss: 0.7665, Train: 75.09%, Valid: 56.38% Test: 62.28%\n",
      "Run: 02, Epoch: 44, Loss: 0.7535, Train: 75.27%, Valid: 56.38% Test: 61.40%\n",
      "Run: 02, Epoch: 45, Loss: 0.7537, Train: 75.64%, Valid: 56.52% Test: 61.18%\n",
      "Run: 02, Epoch: 46, Loss: 0.7293, Train: 74.08%, Valid: 55.28% Test: 59.43%\n",
      "Run: 02, Epoch: 47, Loss: 0.7281, Train: 75.73%, Valid: 55.69% Test: 61.40%\n",
      "Run: 02, Epoch: 48, Loss: 0.7253, Train: 78.21%, Valid: 57.61% Test: 64.91%\n",
      "Run: 02, Epoch: 49, Loss: 0.6982, Train: 77.93%, Valid: 58.16% Test: 64.25%\n",
      "Run: 02, Epoch: 50, Loss: 0.7009, Train: 78.21%, Valid: 57.48% Test: 64.25%\n",
      "Run: 02, Epoch: 51, Loss: 0.6977, Train: 78.85%, Valid: 58.16% Test: 66.01%\n",
      "Run: 02, Epoch: 52, Loss: 0.6927, Train: 77.56%, Valid: 56.38% Test: 64.25%\n",
      "Run: 02, Epoch: 53, Loss: 0.6714, Train: 78.85%, Valid: 57.06% Test: 64.69%\n",
      "Run: 02, Epoch: 54, Loss: 0.6545, Train: 78.66%, Valid: 56.65% Test: 64.04%\n",
      "Run: 02, Epoch: 55, Loss: 0.6524, Train: 78.85%, Valid: 56.79% Test: 64.25%\n",
      "Run: 02, Epoch: 56, Loss: 0.6521, Train: 79.40%, Valid: 57.20% Test: 64.69%\n",
      "Run: 02, Epoch: 57, Loss: 0.6377, Train: 78.57%, Valid: 55.83% Test: 63.38%\n",
      "Run: 02, Epoch: 58, Loss: 0.6208, Train: 80.22%, Valid: 57.89% Test: 65.79%\n",
      "Run: 02, Epoch: 59, Loss: 0.6089, Train: 80.59%, Valid: 57.75% Test: 65.79%\n",
      "Run: 02, Epoch: 60, Loss: 0.6101, Train: 80.04%, Valid: 57.75% Test: 66.23%\n",
      "Run: 02, Epoch: 61, Loss: 0.6149, Train: 81.50%, Valid: 58.98% Test: 66.67%\n",
      "Run: 02, Epoch: 62, Loss: 0.5936, Train: 82.33%, Valid: 60.36% Test: 65.35%\n",
      "Run: 02, Epoch: 63, Loss: 0.5986, Train: 81.32%, Valid: 57.34% Test: 64.91%\n",
      "Run: 02, Epoch: 64, Loss: 0.5766, Train: 82.42%, Valid: 58.44% Test: 65.79%\n",
      "Run: 02, Epoch: 65, Loss: 0.5776, Train: 81.68%, Valid: 58.71% Test: 66.23%\n",
      "Run: 02, Epoch: 66, Loss: 0.5563, Train: 81.96%, Valid: 58.30% Test: 66.67%\n",
      "Run: 02, Epoch: 67, Loss: 0.5504, Train: 82.33%, Valid: 59.12% Test: 66.01%\n",
      "Run: 02, Epoch: 68, Loss: 0.5465, Train: 83.15%, Valid: 59.53% Test: 66.01%\n",
      "Run: 02, Epoch: 69, Loss: 0.5404, Train: 83.52%, Valid: 58.98% Test: 65.57%\n",
      "Run: 02, Epoch: 70, Loss: 0.5164, Train: 83.52%, Valid: 58.98% Test: 65.79%\n",
      "Run: 02, Epoch: 71, Loss: 0.5287, Train: 84.62%, Valid: 58.57% Test: 66.89%\n",
      "Run: 02, Epoch: 72, Loss: 0.5205, Train: 85.07%, Valid: 59.53% Test: 67.76%\n",
      "Run: 02, Epoch: 73, Loss: 0.5328, Train: 85.16%, Valid: 60.22% Test: 67.32%\n",
      "Run: 02, Epoch: 74, Loss: 0.5326, Train: 84.43%, Valid: 59.40% Test: 66.01%\n",
      "Run: 02, Epoch: 75, Loss: 0.5156, Train: 85.07%, Valid: 60.22% Test: 66.67%\n",
      "Run: 02, Epoch: 76, Loss: 0.4992, Train: 85.44%, Valid: 61.04% Test: 66.45%\n",
      "Run: 02, Epoch: 77, Loss: 0.4804, Train: 85.71%, Valid: 61.45% Test: 67.32%\n",
      "Run: 02, Epoch: 78, Loss: 0.4974, Train: 85.07%, Valid: 61.18% Test: 67.76%\n",
      "Run: 02, Epoch: 79, Loss: 0.4952, Train: 85.44%, Valid: 61.73% Test: 67.32%\n",
      "Run: 02, Epoch: 80, Loss: 0.4751, Train: 85.99%, Valid: 61.04% Test: 66.67%\n",
      "Run: 02, Epoch: 81, Loss: 0.4718, Train: 85.35%, Valid: 60.08% Test: 65.79%\n",
      "Run: 02, Epoch: 82, Loss: 0.4618, Train: 85.44%, Valid: 59.81% Test: 65.13%\n",
      "Run: 02, Epoch: 83, Loss: 0.4845, Train: 86.26%, Valid: 61.45% Test: 67.76%\n",
      "Run: 02, Epoch: 84, Loss: 0.4530, Train: 85.62%, Valid: 60.63% Test: 67.54%\n",
      "Run: 02, Epoch: 85, Loss: 0.4541, Train: 86.17%, Valid: 61.04% Test: 66.67%\n",
      "Run: 02, Epoch: 86, Loss: 0.4453, Train: 84.25%, Valid: 59.53% Test: 65.57%\n",
      "Run: 02, Epoch: 87, Loss: 0.4452, Train: 87.36%, Valid: 61.45% Test: 68.20%\n",
      "Run: 02, Epoch: 88, Loss: 0.4349, Train: 85.99%, Valid: 62.41% Test: 68.42%\n",
      "Run: 02, Epoch: 89, Loss: 0.4380, Train: 84.62%, Valid: 61.87% Test: 67.98%\n",
      "Run: 02, Epoch: 90, Loss: 0.4471, Train: 86.08%, Valid: 62.14% Test: 68.42%\n",
      "Run: 02, Epoch: 91, Loss: 0.4286, Train: 85.99%, Valid: 60.49% Test: 66.67%\n",
      "Run: 02, Epoch: 92, Loss: 0.4311, Train: 86.54%, Valid: 61.87% Test: 68.20%\n",
      "Run: 02, Epoch: 93, Loss: 0.4423, Train: 86.36%, Valid: 62.55% Test: 68.42%\n",
      "Run: 02, Epoch: 94, Loss: 0.4272, Train: 86.90%, Valid: 62.83% Test: 69.52%\n",
      "Run: 02, Epoch: 95, Loss: 0.4309, Train: 88.19%, Valid: 64.20% Test: 69.08%\n",
      "Run: 02, Epoch: 96, Loss: 0.4267, Train: 85.99%, Valid: 61.45% Test: 66.89%\n",
      "Run: 02, Epoch: 97, Loss: 0.4193, Train: 87.36%, Valid: 62.00% Test: 66.67%\n",
      "Run: 02, Epoch: 98, Loss: 0.4104, Train: 87.91%, Valid: 61.87% Test: 68.64%\n",
      "Run: 02, Epoch: 99, Loss: 0.4054, Train: 88.46%, Valid: 63.37% Test: 69.96%\n",
      "Run: 02, Epoch: 100, Loss: 0.3990, Train: 86.63%, Valid: 62.00% Test: 69.52%\n",
      "Run 02:\n",
      "Highest Train: 88.46\n",
      "Highest Valid: 64.20\n",
      "  Final Train: 88.19\n",
      "   Final Test: 69.08\n",
      "Run: 03, Epoch: 01, Loss: 2.1607, Train: 27.84%, Valid: 25.79% Test: 29.82%\n",
      "Run: 03, Epoch: 02, Loss: 1.6162, Train: 34.52%, Valid: 31.69% Test: 34.43%\n",
      "Run: 03, Epoch: 03, Loss: 1.4407, Train: 38.64%, Valid: 34.57% Test: 36.84%\n",
      "Run: 03, Epoch: 04, Loss: 1.3518, Train: 41.30%, Valid: 37.31% Test: 38.38%\n",
      "Run: 03, Epoch: 05, Loss: 1.2973, Train: 48.08%, Valid: 40.19% Test: 39.91%\n",
      "Run: 03, Epoch: 06, Loss: 1.2508, Train: 47.44%, Valid: 39.92% Test: 39.25%\n",
      "Run: 03, Epoch: 07, Loss: 1.2555, Train: 47.99%, Valid: 40.74% Test: 39.25%\n",
      "Run: 03, Epoch: 08, Loss: 1.2530, Train: 48.72%, Valid: 41.43% Test: 39.04%\n",
      "Run: 03, Epoch: 09, Loss: 1.2189, Train: 49.45%, Valid: 41.98% Test: 40.79%\n",
      "Run: 03, Epoch: 10, Loss: 1.2277, Train: 49.54%, Valid: 42.52% Test: 40.57%\n",
      "Run: 03, Epoch: 11, Loss: 1.2002, Train: 49.91%, Valid: 43.48% Test: 41.23%\n",
      "Run: 03, Epoch: 12, Loss: 1.1958, Train: 50.92%, Valid: 43.76% Test: 40.13%\n",
      "Run: 03, Epoch: 13, Loss: 1.1685, Train: 52.56%, Valid: 47.19% Test: 44.08%\n",
      "Run: 03, Epoch: 14, Loss: 1.1582, Train: 55.31%, Valid: 49.66% Test: 47.15%\n",
      "Run: 03, Epoch: 15, Loss: 1.1483, Train: 57.69%, Valid: 52.13% Test: 49.12%\n",
      "Run: 03, Epoch: 16, Loss: 1.1380, Train: 57.51%, Valid: 51.71% Test: 47.81%\n",
      "Run: 03, Epoch: 17, Loss: 1.1246, Train: 57.78%, Valid: 51.58% Test: 46.93%\n",
      "Run: 03, Epoch: 18, Loss: 1.0983, Train: 58.79%, Valid: 51.71% Test: 48.03%\n",
      "Run: 03, Epoch: 19, Loss: 1.0974, Train: 59.71%, Valid: 52.26% Test: 48.25%\n",
      "Run: 03, Epoch: 20, Loss: 1.0824, Train: 59.52%, Valid: 51.30% Test: 49.34%\n",
      "Run: 03, Epoch: 21, Loss: 1.0703, Train: 60.35%, Valid: 51.71% Test: 49.78%\n",
      "Run: 03, Epoch: 22, Loss: 1.0546, Train: 61.36%, Valid: 52.40% Test: 50.44%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 23, Loss: 1.0348, Train: 61.72%, Valid: 52.13% Test: 50.66%\n",
      "Run: 03, Epoch: 24, Loss: 1.0251, Train: 61.36%, Valid: 51.58% Test: 50.00%\n",
      "Run: 03, Epoch: 25, Loss: 1.0204, Train: 62.36%, Valid: 52.13% Test: 49.12%\n",
      "Run: 03, Epoch: 26, Loss: 0.9987, Train: 63.00%, Valid: 52.13% Test: 49.34%\n",
      "Run: 03, Epoch: 27, Loss: 1.0006, Train: 63.28%, Valid: 52.67% Test: 49.34%\n",
      "Run: 03, Epoch: 28, Loss: 0.9987, Train: 63.74%, Valid: 52.81% Test: 49.34%\n",
      "Run: 03, Epoch: 29, Loss: 0.9685, Train: 63.92%, Valid: 52.81% Test: 49.12%\n",
      "Run: 03, Epoch: 30, Loss: 0.9599, Train: 64.84%, Valid: 55.56% Test: 51.10%\n",
      "Run: 03, Epoch: 31, Loss: 0.9487, Train: 65.66%, Valid: 56.79% Test: 51.97%\n",
      "Run: 03, Epoch: 32, Loss: 0.9453, Train: 66.03%, Valid: 56.79% Test: 52.41%\n",
      "Run: 03, Epoch: 33, Loss: 0.9319, Train: 66.58%, Valid: 56.93% Test: 52.41%\n",
      "Run: 03, Epoch: 34, Loss: 0.9014, Train: 67.58%, Valid: 56.93% Test: 51.97%\n",
      "Run: 03, Epoch: 35, Loss: 0.8913, Train: 68.32%, Valid: 56.79% Test: 51.97%\n",
      "Run: 03, Epoch: 36, Loss: 0.9050, Train: 69.23%, Valid: 56.79% Test: 51.97%\n",
      "Run: 03, Epoch: 37, Loss: 0.8903, Train: 68.68%, Valid: 55.97% Test: 52.19%\n",
      "Run: 03, Epoch: 38, Loss: 0.8704, Train: 69.23%, Valid: 55.69% Test: 51.97%\n",
      "Run: 03, Epoch: 39, Loss: 0.8651, Train: 69.51%, Valid: 55.97% Test: 52.19%\n",
      "Run: 03, Epoch: 40, Loss: 0.8419, Train: 70.88%, Valid: 55.97% Test: 52.85%\n",
      "Run: 03, Epoch: 41, Loss: 0.8508, Train: 70.88%, Valid: 55.97% Test: 52.41%\n",
      "Run: 03, Epoch: 42, Loss: 0.8312, Train: 72.53%, Valid: 56.52% Test: 52.85%\n",
      "Run: 03, Epoch: 43, Loss: 0.8186, Train: 71.52%, Valid: 55.01% Test: 51.32%\n",
      "Run: 03, Epoch: 44, Loss: 0.7910, Train: 71.06%, Valid: 55.42% Test: 51.97%\n",
      "Run: 03, Epoch: 45, Loss: 0.7860, Train: 71.89%, Valid: 56.52% Test: 52.19%\n",
      "Run: 03, Epoch: 46, Loss: 0.7774, Train: 72.53%, Valid: 57.34% Test: 52.85%\n",
      "Run: 03, Epoch: 47, Loss: 0.7799, Train: 73.26%, Valid: 56.38% Test: 52.85%\n",
      "Run: 03, Epoch: 48, Loss: 0.7584, Train: 74.08%, Valid: 57.20% Test: 52.41%\n",
      "Run: 03, Epoch: 49, Loss: 0.7429, Train: 76.01%, Valid: 58.98% Test: 54.82%\n",
      "Run: 03, Epoch: 50, Loss: 0.7362, Train: 77.20%, Valid: 59.67% Test: 55.48%\n",
      "Run: 03, Epoch: 51, Loss: 0.7160, Train: 77.66%, Valid: 60.49% Test: 56.14%\n",
      "Run: 03, Epoch: 52, Loss: 0.7373, Train: 77.93%, Valid: 61.87% Test: 58.77%\n",
      "Run: 03, Epoch: 53, Loss: 0.7002, Train: 78.66%, Valid: 62.96% Test: 59.87%\n",
      "Run: 03, Epoch: 54, Loss: 0.7070, Train: 78.85%, Valid: 62.00% Test: 57.46%\n",
      "Run: 03, Epoch: 55, Loss: 0.6963, Train: 79.30%, Valid: 61.87% Test: 58.33%\n",
      "Run: 03, Epoch: 56, Loss: 0.6835, Train: 80.49%, Valid: 62.55% Test: 59.21%\n",
      "Run: 03, Epoch: 57, Loss: 0.6759, Train: 80.31%, Valid: 62.96% Test: 59.87%\n",
      "Run: 03, Epoch: 58, Loss: 0.6799, Train: 80.95%, Valid: 63.10% Test: 60.09%\n",
      "Run: 03, Epoch: 59, Loss: 0.6524, Train: 82.69%, Valid: 63.37% Test: 59.65%\n",
      "Run: 03, Epoch: 60, Loss: 0.6591, Train: 81.14%, Valid: 62.00% Test: 59.21%\n",
      "Run: 03, Epoch: 61, Loss: 0.6442, Train: 82.05%, Valid: 62.41% Test: 58.99%\n",
      "Run: 03, Epoch: 62, Loss: 0.6421, Train: 82.69%, Valid: 63.37% Test: 59.87%\n",
      "Run: 03, Epoch: 63, Loss: 0.6257, Train: 82.88%, Valid: 63.51% Test: 60.96%\n",
      "Run: 03, Epoch: 64, Loss: 0.6205, Train: 81.50%, Valid: 63.24% Test: 61.18%\n",
      "Run: 03, Epoch: 65, Loss: 0.6094, Train: 82.33%, Valid: 63.92% Test: 61.62%\n",
      "Run: 03, Epoch: 66, Loss: 0.5884, Train: 83.06%, Valid: 64.61% Test: 60.96%\n",
      "Run: 03, Epoch: 67, Loss: 0.5929, Train: 82.05%, Valid: 63.65% Test: 59.87%\n",
      "Run: 03, Epoch: 68, Loss: 0.5760, Train: 82.33%, Valid: 63.51% Test: 59.21%\n",
      "Run: 03, Epoch: 69, Loss: 0.5904, Train: 84.34%, Valid: 64.47% Test: 60.31%\n",
      "Run: 03, Epoch: 70, Loss: 0.5821, Train: 82.51%, Valid: 62.69% Test: 58.11%\n",
      "Run: 03, Epoch: 71, Loss: 0.5891, Train: 83.42%, Valid: 64.61% Test: 60.96%\n",
      "Run: 03, Epoch: 72, Loss: 0.5500, Train: 83.15%, Valid: 65.43% Test: 60.75%\n",
      "Run: 03, Epoch: 73, Loss: 0.5544, Train: 83.24%, Valid: 66.53% Test: 60.96%\n",
      "Run: 03, Epoch: 74, Loss: 0.5566, Train: 84.43%, Valid: 67.08% Test: 62.50%\n",
      "Run: 03, Epoch: 75, Loss: 0.5363, Train: 83.61%, Valid: 65.57% Test: 61.40%\n",
      "Run: 03, Epoch: 76, Loss: 0.5392, Train: 85.07%, Valid: 66.80% Test: 61.40%\n",
      "Run: 03, Epoch: 77, Loss: 0.5233, Train: 84.25%, Valid: 66.94% Test: 61.84%\n",
      "Run: 03, Epoch: 78, Loss: 0.5052, Train: 84.07%, Valid: 67.22% Test: 62.28%\n",
      "Run: 03, Epoch: 79, Loss: 0.5131, Train: 84.62%, Valid: 64.75% Test: 60.75%\n",
      "Run: 03, Epoch: 80, Loss: 0.5001, Train: 84.89%, Valid: 62.55% Test: 61.40%\n",
      "Run: 03, Epoch: 81, Loss: 0.5172, Train: 84.71%, Valid: 63.37% Test: 60.96%\n",
      "Run: 03, Epoch: 82, Loss: 0.4970, Train: 85.53%, Valid: 64.75% Test: 61.18%\n",
      "Run: 03, Epoch: 83, Loss: 0.5406, Train: 85.62%, Valid: 64.33% Test: 60.75%\n",
      "Run: 03, Epoch: 84, Loss: 0.5186, Train: 85.99%, Valid: 66.80% Test: 60.31%\n",
      "Run: 03, Epoch: 85, Loss: 0.4648, Train: 85.90%, Valid: 66.12% Test: 62.06%\n",
      "Run: 03, Epoch: 86, Loss: 0.4892, Train: 84.25%, Valid: 65.16% Test: 62.50%\n",
      "Run: 03, Epoch: 87, Loss: 0.4999, Train: 83.88%, Valid: 65.57% Test: 62.06%\n",
      "Run: 03, Epoch: 88, Loss: 0.4943, Train: 85.53%, Valid: 64.75% Test: 62.94%\n",
      "Run: 03, Epoch: 89, Loss: 0.4764, Train: 86.26%, Valid: 65.02% Test: 62.28%\n",
      "Run: 03, Epoch: 90, Loss: 0.4874, Train: 85.99%, Valid: 66.67% Test: 62.06%\n",
      "Run: 03, Epoch: 91, Loss: 0.4579, Train: 85.90%, Valid: 66.80% Test: 62.50%\n",
      "Run: 03, Epoch: 92, Loss: 0.4765, Train: 86.54%, Valid: 65.29% Test: 61.62%\n",
      "Run: 03, Epoch: 93, Loss: 0.4626, Train: 86.63%, Valid: 64.20% Test: 62.28%\n",
      "Run: 03, Epoch: 94, Loss: 0.4567, Train: 86.63%, Valid: 64.20% Test: 62.72%\n",
      "Run: 03, Epoch: 95, Loss: 0.4821, Train: 87.00%, Valid: 65.29% Test: 62.06%\n",
      "Run: 03, Epoch: 96, Loss: 0.4454, Train: 87.27%, Valid: 65.98% Test: 62.72%\n",
      "Run: 03, Epoch: 97, Loss: 0.4519, Train: 87.73%, Valid: 65.98% Test: 62.28%\n",
      "Run: 03, Epoch: 98, Loss: 0.4513, Train: 86.54%, Valid: 65.57% Test: 61.18%\n",
      "Run: 03, Epoch: 99, Loss: 0.4496, Train: 87.09%, Valid: 65.29% Test: 63.16%\n",
      "Run: 03, Epoch: 100, Loss: 0.4372, Train: 87.27%, Valid: 66.12% Test: 64.25%\n",
      "Run 03:\n",
      "Highest Train: 87.73\n",
      "Highest Valid: 67.22\n",
      "  Final Train: 84.07\n",
      "   Final Test: 62.28\n",
      "Run: 04, Epoch: 01, Loss: 1.9626, Train: 24.45%, Valid: 22.91% Test: 21.71%\n",
      "Run: 04, Epoch: 02, Loss: 1.4239, Train: 34.80%, Valid: 29.90% Test: 29.17%\n",
      "Run: 04, Epoch: 03, Loss: 1.3205, Train: 37.09%, Valid: 33.88% Test: 32.46%\n",
      "Run: 04, Epoch: 04, Loss: 1.2962, Train: 32.33%, Valid: 29.63% Test: 31.14%\n",
      "Run: 04, Epoch: 05, Loss: 1.2634, Train: 33.24%, Valid: 31.96% Test: 32.89%\n",
      "Run: 04, Epoch: 06, Loss: 1.2358, Train: 35.62%, Valid: 32.51% Test: 33.77%\n",
      "Run: 04, Epoch: 07, Loss: 1.2193, Train: 41.76%, Valid: 38.96% Test: 39.25%\n",
      "Run: 04, Epoch: 08, Loss: 1.2030, Train: 47.53%, Valid: 44.31% Test: 42.54%\n",
      "Run: 04, Epoch: 09, Loss: 1.1931, Train: 52.47%, Valid: 48.56% Test: 45.39%\n",
      "Run: 04, Epoch: 10, Loss: 1.1768, Train: 55.13%, Valid: 51.85% Test: 47.81%\n",
      "Run: 04, Epoch: 11, Loss: 1.1515, Train: 56.87%, Valid: 52.40% Test: 49.12%\n",
      "Run: 04, Epoch: 12, Loss: 1.1505, Train: 58.24%, Valid: 54.46% Test: 51.10%\n",
      "Run: 04, Epoch: 13, Loss: 1.1212, Train: 59.62%, Valid: 54.46% Test: 52.85%\n",
      "Run: 04, Epoch: 14, Loss: 1.1172, Train: 61.17%, Valid: 54.60% Test: 54.17%\n",
      "Run: 04, Epoch: 15, Loss: 1.0942, Train: 61.45%, Valid: 54.18% Test: 53.73%\n",
      "Run: 04, Epoch: 16, Loss: 1.0748, Train: 61.81%, Valid: 54.73% Test: 55.92%\n",
      "Run: 04, Epoch: 17, Loss: 1.0627, Train: 62.82%, Valid: 55.14% Test: 57.68%\n",
      "Run: 04, Epoch: 18, Loss: 1.0596, Train: 64.10%, Valid: 56.24% Test: 57.46%\n",
      "Run: 04, Epoch: 19, Loss: 1.0269, Train: 64.47%, Valid: 56.52% Test: 57.02%\n",
      "Run: 04, Epoch: 20, Loss: 1.0297, Train: 64.56%, Valid: 56.10% Test: 57.02%\n",
      "Run: 04, Epoch: 21, Loss: 1.0170, Train: 65.02%, Valid: 56.65% Test: 57.46%\n",
      "Run: 04, Epoch: 22, Loss: 0.9992, Train: 65.57%, Valid: 57.61% Test: 58.33%\n",
      "Run: 04, Epoch: 23, Loss: 0.9920, Train: 65.75%, Valid: 57.48% Test: 57.89%\n",
      "Run: 04, Epoch: 24, Loss: 0.9786, Train: 65.48%, Valid: 57.48% Test: 57.24%\n",
      "Run: 04, Epoch: 25, Loss: 0.9495, Train: 66.67%, Valid: 57.89% Test: 57.89%\n",
      "Run: 04, Epoch: 26, Loss: 0.9444, Train: 67.67%, Valid: 58.30% Test: 57.46%\n",
      "Run: 04, Epoch: 27, Loss: 0.9548, Train: 68.77%, Valid: 58.16% Test: 59.21%\n",
      "Run: 04, Epoch: 28, Loss: 0.9127, Train: 69.23%, Valid: 58.57% Test: 59.43%\n",
      "Run: 04, Epoch: 29, Loss: 0.9226, Train: 68.86%, Valid: 59.12% Test: 59.65%\n",
      "Run: 04, Epoch: 30, Loss: 0.8957, Train: 68.86%, Valid: 59.53% Test: 58.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 31, Loss: 0.8646, Train: 69.32%, Valid: 59.40% Test: 57.68%\n",
      "Run: 04, Epoch: 32, Loss: 0.8700, Train: 69.69%, Valid: 58.44% Test: 58.99%\n",
      "Run: 04, Epoch: 33, Loss: 0.8444, Train: 70.97%, Valid: 57.61% Test: 59.65%\n",
      "Run: 04, Epoch: 34, Loss: 0.8403, Train: 71.34%, Valid: 57.61% Test: 60.31%\n",
      "Run: 04, Epoch: 35, Loss: 0.8310, Train: 72.99%, Valid: 58.71% Test: 60.09%\n",
      "Run: 04, Epoch: 36, Loss: 0.7960, Train: 73.26%, Valid: 60.22% Test: 58.99%\n",
      "Run: 04, Epoch: 37, Loss: 0.8033, Train: 72.99%, Valid: 61.32% Test: 59.21%\n",
      "Run: 04, Epoch: 38, Loss: 0.7875, Train: 73.99%, Valid: 61.32% Test: 59.43%\n",
      "Run: 04, Epoch: 39, Loss: 0.7840, Train: 74.91%, Valid: 61.87% Test: 59.87%\n",
      "Run: 04, Epoch: 40, Loss: 0.7485, Train: 76.56%, Valid: 62.55% Test: 59.87%\n",
      "Run: 04, Epoch: 41, Loss: 0.7649, Train: 74.82%, Valid: 60.49% Test: 59.43%\n",
      "Run: 04, Epoch: 42, Loss: 0.7460, Train: 75.55%, Valid: 60.22% Test: 59.65%\n",
      "Run: 04, Epoch: 43, Loss: 0.7313, Train: 76.19%, Valid: 61.04% Test: 59.65%\n",
      "Run: 04, Epoch: 44, Loss: 0.7282, Train: 77.84%, Valid: 63.51% Test: 60.96%\n",
      "Run: 04, Epoch: 45, Loss: 0.7015, Train: 77.38%, Valid: 63.10% Test: 60.09%\n",
      "Run: 04, Epoch: 46, Loss: 0.6901, Train: 77.38%, Valid: 62.41% Test: 59.87%\n",
      "Run: 04, Epoch: 47, Loss: 0.7049, Train: 77.47%, Valid: 61.87% Test: 59.87%\n",
      "Run: 04, Epoch: 48, Loss: 0.6752, Train: 78.85%, Valid: 63.24% Test: 60.31%\n",
      "Run: 04, Epoch: 49, Loss: 0.6744, Train: 79.40%, Valid: 63.51% Test: 60.31%\n",
      "Run: 04, Epoch: 50, Loss: 0.6449, Train: 79.12%, Valid: 62.96% Test: 59.43%\n",
      "Run: 04, Epoch: 51, Loss: 0.6558, Train: 78.66%, Valid: 62.55% Test: 59.43%\n",
      "Run: 04, Epoch: 52, Loss: 0.6306, Train: 79.76%, Valid: 63.24% Test: 60.96%\n",
      "Run: 04, Epoch: 53, Loss: 0.6457, Train: 79.58%, Valid: 64.20% Test: 61.40%\n",
      "Run: 04, Epoch: 54, Loss: 0.6123, Train: 78.75%, Valid: 63.92% Test: 61.40%\n",
      "Run: 04, Epoch: 55, Loss: 0.6248, Train: 79.30%, Valid: 64.20% Test: 61.84%\n",
      "Run: 04, Epoch: 56, Loss: 0.5961, Train: 80.13%, Valid: 65.02% Test: 62.28%\n",
      "Run: 04, Epoch: 57, Loss: 0.5869, Train: 80.95%, Valid: 64.75% Test: 61.40%\n",
      "Run: 04, Epoch: 58, Loss: 0.5785, Train: 81.78%, Valid: 64.61% Test: 62.28%\n",
      "Run: 04, Epoch: 59, Loss: 0.5798, Train: 81.68%, Valid: 65.02% Test: 62.94%\n",
      "Run: 04, Epoch: 60, Loss: 0.5870, Train: 81.23%, Valid: 65.84% Test: 62.72%\n",
      "Run: 04, Epoch: 61, Loss: 0.5668, Train: 81.23%, Valid: 65.57% Test: 62.28%\n",
      "Run: 04, Epoch: 62, Loss: 0.5493, Train: 81.68%, Valid: 66.12% Test: 62.50%\n",
      "Run: 04, Epoch: 63, Loss: 0.5416, Train: 82.88%, Valid: 65.98% Test: 63.16%\n",
      "Run: 04, Epoch: 64, Loss: 0.5448, Train: 83.33%, Valid: 65.16% Test: 62.50%\n",
      "Run: 04, Epoch: 65, Loss: 0.5309, Train: 82.14%, Valid: 65.43% Test: 63.38%\n",
      "Run: 04, Epoch: 66, Loss: 0.5211, Train: 81.87%, Valid: 65.29% Test: 62.72%\n",
      "Run: 04, Epoch: 67, Loss: 0.5187, Train: 83.24%, Valid: 66.12% Test: 62.94%\n",
      "Run: 04, Epoch: 68, Loss: 0.5222, Train: 83.88%, Valid: 63.92% Test: 63.82%\n",
      "Run: 04, Epoch: 69, Loss: 0.5131, Train: 83.52%, Valid: 63.10% Test: 63.38%\n",
      "Run: 04, Epoch: 70, Loss: 0.4976, Train: 82.97%, Valid: 63.79% Test: 65.35%\n",
      "Run: 04, Epoch: 71, Loss: 0.5002, Train: 84.52%, Valid: 65.29% Test: 64.69%\n",
      "Run: 04, Epoch: 72, Loss: 0.4763, Train: 83.61%, Valid: 64.47% Test: 63.38%\n",
      "Run: 04, Epoch: 73, Loss: 0.4898, Train: 84.98%, Valid: 65.71% Test: 63.38%\n",
      "Run: 04, Epoch: 74, Loss: 0.4683, Train: 84.25%, Valid: 63.51% Test: 63.38%\n",
      "Run: 04, Epoch: 75, Loss: 0.4716, Train: 84.89%, Valid: 63.51% Test: 62.94%\n",
      "Run: 04, Epoch: 76, Loss: 0.4504, Train: 85.44%, Valid: 64.33% Test: 63.38%\n",
      "Run: 04, Epoch: 77, Loss: 0.4609, Train: 85.07%, Valid: 66.12% Test: 63.82%\n",
      "Run: 04, Epoch: 78, Loss: 0.4536, Train: 86.08%, Valid: 65.57% Test: 62.50%\n",
      "Run: 04, Epoch: 79, Loss: 0.4609, Train: 86.45%, Valid: 64.75% Test: 62.06%\n",
      "Run: 04, Epoch: 80, Loss: 0.4217, Train: 85.07%, Valid: 64.88% Test: 63.16%\n",
      "Run: 04, Epoch: 81, Loss: 0.4370, Train: 85.35%, Valid: 64.47% Test: 62.06%\n",
      "Run: 04, Epoch: 82, Loss: 0.4331, Train: 85.44%, Valid: 66.80% Test: 62.50%\n",
      "Run: 04, Epoch: 83, Loss: 0.4418, Train: 85.07%, Valid: 66.12% Test: 62.72%\n",
      "Run: 04, Epoch: 84, Loss: 0.4537, Train: 86.45%, Valid: 66.53% Test: 63.38%\n",
      "Run: 04, Epoch: 85, Loss: 0.4317, Train: 84.89%, Valid: 63.92% Test: 62.06%\n",
      "Run: 04, Epoch: 86, Loss: 0.4169, Train: 85.07%, Valid: 63.51% Test: 62.72%\n",
      "Run: 04, Epoch: 87, Loss: 0.4167, Train: 87.18%, Valid: 65.02% Test: 62.94%\n",
      "Run: 04, Epoch: 88, Loss: 0.4099, Train: 86.63%, Valid: 67.08% Test: 64.25%\n",
      "Run: 04, Epoch: 89, Loss: 0.4097, Train: 85.16%, Valid: 66.12% Test: 63.16%\n",
      "Run: 04, Epoch: 90, Loss: 0.4284, Train: 88.92%, Valid: 67.49% Test: 63.60%\n",
      "Run: 04, Epoch: 91, Loss: 0.4225, Train: 87.18%, Valid: 64.75% Test: 62.94%\n",
      "Run: 04, Epoch: 92, Loss: 0.3814, Train: 81.41%, Valid: 61.73% Test: 62.94%\n",
      "Run: 04, Epoch: 93, Loss: 0.4170, Train: 86.26%, Valid: 64.61% Test: 63.16%\n",
      "Run: 04, Epoch: 94, Loss: 0.3892, Train: 87.82%, Valid: 67.49% Test: 64.04%\n",
      "Run: 04, Epoch: 95, Loss: 0.3952, Train: 86.90%, Valid: 67.76% Test: 64.47%\n",
      "Run: 04, Epoch: 96, Loss: 0.4136, Train: 88.00%, Valid: 67.76% Test: 64.69%\n",
      "Run: 04, Epoch: 97, Loss: 0.3865, Train: 89.10%, Valid: 67.22% Test: 62.50%\n",
      "Run: 04, Epoch: 98, Loss: 0.3803, Train: 87.91%, Valid: 66.26% Test: 62.50%\n",
      "Run: 04, Epoch: 99, Loss: 0.3757, Train: 88.55%, Valid: 66.26% Test: 62.50%\n",
      "Run: 04, Epoch: 100, Loss: 0.3824, Train: 89.19%, Valid: 67.90% Test: 63.38%\n",
      "Run 04:\n",
      "Highest Train: 89.19\n",
      "Highest Valid: 67.90\n",
      "  Final Train: 89.19\n",
      "   Final Test: 63.38\n",
      "Run: 05, Epoch: 01, Loss: 1.8675, Train: 29.49%, Valid: 31.14% Test: 28.07%\n",
      "Run: 05, Epoch: 02, Loss: 1.3877, Train: 35.53%, Valid: 33.88% Test: 31.58%\n",
      "Run: 05, Epoch: 03, Loss: 1.2730, Train: 40.48%, Valid: 39.37% Test: 36.40%\n",
      "Run: 05, Epoch: 04, Loss: 1.2537, Train: 41.85%, Valid: 39.23% Test: 36.84%\n",
      "Run: 05, Epoch: 05, Loss: 1.2007, Train: 42.86%, Valid: 37.59% Test: 39.47%\n",
      "Run: 05, Epoch: 06, Loss: 1.1856, Train: 45.79%, Valid: 39.09% Test: 40.57%\n",
      "Run: 05, Epoch: 07, Loss: 1.1640, Train: 47.07%, Valid: 41.02% Test: 42.11%\n",
      "Run: 05, Epoch: 08, Loss: 1.1378, Train: 47.07%, Valid: 40.19% Test: 41.89%\n",
      "Run: 05, Epoch: 09, Loss: 1.1238, Train: 48.53%, Valid: 41.15% Test: 43.42%\n",
      "Run: 05, Epoch: 10, Loss: 1.1152, Train: 49.91%, Valid: 42.11% Test: 44.52%\n",
      "Run: 05, Epoch: 11, Loss: 1.0967, Train: 53.85%, Valid: 45.68% Test: 48.68%\n",
      "Run: 05, Epoch: 12, Loss: 1.0920, Train: 54.95%, Valid: 46.50% Test: 49.34%\n",
      "Run: 05, Epoch: 13, Loss: 1.0736, Train: 56.14%, Valid: 48.15% Test: 51.10%\n",
      "Run: 05, Epoch: 14, Loss: 1.0486, Train: 57.69%, Valid: 49.66% Test: 52.41%\n",
      "Run: 05, Epoch: 15, Loss: 1.0356, Train: 58.79%, Valid: 50.34% Test: 52.41%\n",
      "Run: 05, Epoch: 16, Loss: 1.0219, Train: 59.34%, Valid: 50.62% Test: 53.07%\n",
      "Run: 05, Epoch: 17, Loss: 0.9975, Train: 60.44%, Valid: 51.03% Test: 53.51%\n",
      "Run: 05, Epoch: 18, Loss: 0.9948, Train: 61.08%, Valid: 52.67% Test: 54.17%\n",
      "Run: 05, Epoch: 19, Loss: 0.9671, Train: 61.63%, Valid: 52.26% Test: 54.61%\n",
      "Run: 05, Epoch: 20, Loss: 0.9619, Train: 62.36%, Valid: 52.26% Test: 55.04%\n",
      "Run: 05, Epoch: 21, Loss: 0.9528, Train: 63.00%, Valid: 53.09% Test: 55.48%\n",
      "Run: 05, Epoch: 22, Loss: 0.9289, Train: 63.10%, Valid: 52.67% Test: 54.82%\n",
      "Run: 05, Epoch: 23, Loss: 0.9198, Train: 63.64%, Valid: 52.81% Test: 55.04%\n",
      "Run: 05, Epoch: 24, Loss: 0.9093, Train: 64.65%, Valid: 54.18% Test: 55.26%\n",
      "Run: 05, Epoch: 25, Loss: 0.8880, Train: 66.48%, Valid: 55.28% Test: 56.36%\n",
      "Run: 05, Epoch: 26, Loss: 0.8810, Train: 67.49%, Valid: 55.83% Test: 57.24%\n",
      "Run: 05, Epoch: 27, Loss: 0.8486, Train: 68.32%, Valid: 56.65% Test: 58.11%\n",
      "Run: 05, Epoch: 28, Loss: 0.8346, Train: 69.32%, Valid: 57.61% Test: 58.99%\n",
      "Run: 05, Epoch: 29, Loss: 0.8380, Train: 71.06%, Valid: 60.08% Test: 60.75%\n",
      "Run: 05, Epoch: 30, Loss: 0.8002, Train: 71.98%, Valid: 60.36% Test: 61.40%\n",
      "Run: 05, Epoch: 31, Loss: 0.8019, Train: 72.89%, Valid: 60.22% Test: 60.09%\n",
      "Run: 05, Epoch: 32, Loss: 0.7961, Train: 73.72%, Valid: 61.45% Test: 61.18%\n",
      "Run: 05, Epoch: 33, Loss: 0.7744, Train: 74.91%, Valid: 60.63% Test: 61.62%\n",
      "Run: 05, Epoch: 34, Loss: 0.7653, Train: 75.92%, Valid: 62.00% Test: 61.62%\n",
      "Run: 05, Epoch: 35, Loss: 0.7512, Train: 76.47%, Valid: 62.28% Test: 62.28%\n",
      "Run: 05, Epoch: 36, Loss: 0.7329, Train: 77.47%, Valid: 64.06% Test: 63.82%\n",
      "Run: 05, Epoch: 37, Loss: 0.7201, Train: 77.47%, Valid: 63.37% Test: 64.25%\n",
      "Run: 05, Epoch: 38, Loss: 0.7063, Train: 78.11%, Valid: 65.16% Test: 63.60%\n",
      "Run: 05, Epoch: 39, Loss: 0.6889, Train: 78.39%, Valid: 64.88% Test: 63.60%\n",
      "Run: 05, Epoch: 40, Loss: 0.6932, Train: 78.30%, Valid: 65.29% Test: 64.47%\n",
      "Run: 05, Epoch: 41, Loss: 0.6684, Train: 79.67%, Valid: 65.57% Test: 64.25%\n",
      "Run: 05, Epoch: 42, Loss: 0.6462, Train: 80.13%, Valid: 65.16% Test: 62.94%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 43, Loss: 0.6298, Train: 79.58%, Valid: 64.47% Test: 63.16%\n",
      "Run: 05, Epoch: 44, Loss: 0.6291, Train: 80.49%, Valid: 64.06% Test: 62.94%\n",
      "Run: 05, Epoch: 45, Loss: 0.6219, Train: 80.31%, Valid: 63.92% Test: 64.47%\n",
      "Run: 05, Epoch: 46, Loss: 0.6159, Train: 81.59%, Valid: 64.20% Test: 64.91%\n",
      "Run: 05, Epoch: 47, Loss: 0.5981, Train: 81.96%, Valid: 63.92% Test: 64.91%\n",
      "Run: 05, Epoch: 48, Loss: 0.5982, Train: 81.50%, Valid: 63.65% Test: 63.60%\n",
      "Run: 05, Epoch: 49, Loss: 0.5828, Train: 81.14%, Valid: 62.55% Test: 64.04%\n",
      "Run: 05, Epoch: 50, Loss: 0.5736, Train: 81.87%, Valid: 61.59% Test: 64.25%\n",
      "Run: 05, Epoch: 51, Loss: 0.5542, Train: 82.05%, Valid: 62.83% Test: 63.82%\n",
      "Run: 05, Epoch: 52, Loss: 0.5544, Train: 83.06%, Valid: 63.92% Test: 65.35%\n",
      "Run: 05, Epoch: 53, Loss: 0.5428, Train: 83.61%, Valid: 63.79% Test: 65.57%\n",
      "Run: 05, Epoch: 54, Loss: 0.5336, Train: 83.79%, Valid: 63.65% Test: 64.69%\n",
      "Run: 05, Epoch: 55, Loss: 0.5186, Train: 83.88%, Valid: 63.79% Test: 64.25%\n",
      "Run: 05, Epoch: 56, Loss: 0.5134, Train: 84.07%, Valid: 65.43% Test: 63.82%\n",
      "Run: 05, Epoch: 57, Loss: 0.5163, Train: 82.69%, Valid: 63.37% Test: 63.38%\n",
      "Run: 05, Epoch: 58, Loss: 0.5014, Train: 83.97%, Valid: 65.16% Test: 65.79%\n",
      "Run: 05, Epoch: 59, Loss: 0.5028, Train: 84.07%, Valid: 65.84% Test: 63.82%\n",
      "Run: 05, Epoch: 60, Loss: 0.5136, Train: 84.89%, Valid: 65.84% Test: 66.23%\n",
      "Run: 05, Epoch: 61, Loss: 0.4779, Train: 84.43%, Valid: 64.06% Test: 64.69%\n",
      "Run: 05, Epoch: 62, Loss: 0.4706, Train: 84.80%, Valid: 63.24% Test: 64.69%\n",
      "Run: 05, Epoch: 63, Loss: 0.4826, Train: 86.08%, Valid: 65.57% Test: 65.13%\n",
      "Run: 05, Epoch: 64, Loss: 0.4566, Train: 84.89%, Valid: 64.61% Test: 64.47%\n",
      "Run: 05, Epoch: 65, Loss: 0.4696, Train: 87.45%, Valid: 65.43% Test: 66.23%\n",
      "Run: 05, Epoch: 66, Loss: 0.4455, Train: 85.44%, Valid: 63.79% Test: 64.91%\n",
      "Run: 05, Epoch: 67, Loss: 0.4742, Train: 85.81%, Valid: 65.16% Test: 65.57%\n",
      "Run: 05, Epoch: 68, Loss: 0.4555, Train: 87.00%, Valid: 66.26% Test: 66.23%\n",
      "Run: 05, Epoch: 69, Loss: 0.4295, Train: 86.63%, Valid: 65.71% Test: 65.57%\n",
      "Run: 05, Epoch: 70, Loss: 0.4413, Train: 87.73%, Valid: 65.84% Test: 65.57%\n",
      "Run: 05, Epoch: 71, Loss: 0.4316, Train: 87.82%, Valid: 66.80% Test: 64.47%\n",
      "Run: 05, Epoch: 72, Loss: 0.4234, Train: 88.46%, Valid: 67.76% Test: 65.35%\n",
      "Run: 05, Epoch: 73, Loss: 0.4318, Train: 88.92%, Valid: 67.49% Test: 66.89%\n",
      "Run: 05, Epoch: 74, Loss: 0.4135, Train: 88.37%, Valid: 66.39% Test: 67.98%\n",
      "Run: 05, Epoch: 75, Loss: 0.4226, Train: 88.19%, Valid: 65.84% Test: 66.23%\n",
      "Run: 05, Epoch: 76, Loss: 0.4105, Train: 87.09%, Valid: 64.61% Test: 64.69%\n",
      "Run: 05, Epoch: 77, Loss: 0.4040, Train: 88.00%, Valid: 65.29% Test: 64.04%\n",
      "Run: 05, Epoch: 78, Loss: 0.4061, Train: 89.10%, Valid: 66.26% Test: 67.32%\n",
      "Run: 05, Epoch: 79, Loss: 0.4054, Train: 89.10%, Valid: 65.84% Test: 66.23%\n",
      "Run: 05, Epoch: 80, Loss: 0.4125, Train: 89.84%, Valid: 66.53% Test: 66.23%\n",
      "Run: 05, Epoch: 81, Loss: 0.3829, Train: 88.92%, Valid: 66.53% Test: 65.79%\n",
      "Run: 05, Epoch: 82, Loss: 0.3922, Train: 88.92%, Valid: 66.53% Test: 65.35%\n",
      "Run: 05, Epoch: 83, Loss: 0.3667, Train: 88.64%, Valid: 65.57% Test: 65.13%\n",
      "Run: 05, Epoch: 84, Loss: 0.3776, Train: 89.74%, Valid: 66.12% Test: 66.01%\n",
      "Run: 05, Epoch: 85, Loss: 0.3702, Train: 87.91%, Valid: 64.33% Test: 65.35%\n",
      "Run: 05, Epoch: 86, Loss: 0.3691, Train: 89.56%, Valid: 65.43% Test: 65.13%\n",
      "Run: 05, Epoch: 87, Loss: 0.3602, Train: 90.02%, Valid: 65.29% Test: 66.01%\n",
      "Run: 05, Epoch: 88, Loss: 0.3632, Train: 89.38%, Valid: 65.71% Test: 64.69%\n",
      "Run: 05, Epoch: 89, Loss: 0.3737, Train: 89.01%, Valid: 65.57% Test: 65.35%\n",
      "Run: 05, Epoch: 90, Loss: 0.3551, Train: 89.84%, Valid: 66.67% Test: 66.01%\n",
      "Run: 05, Epoch: 91, Loss: 0.3500, Train: 89.47%, Valid: 63.92% Test: 66.23%\n",
      "Run: 05, Epoch: 92, Loss: 0.3937, Train: 90.38%, Valid: 65.98% Test: 65.79%\n",
      "Run: 05, Epoch: 93, Loss: 0.3628, Train: 87.91%, Valid: 64.61% Test: 63.60%\n",
      "Run: 05, Epoch: 94, Loss: 0.3763, Train: 89.19%, Valid: 64.47% Test: 64.91%\n",
      "Run: 05, Epoch: 95, Loss: 0.3724, Train: 89.65%, Valid: 63.37% Test: 66.01%\n",
      "Run: 05, Epoch: 96, Loss: 0.3451, Train: 86.45%, Valid: 62.00% Test: 63.16%\n",
      "Run: 05, Epoch: 97, Loss: 0.4051, Train: 89.38%, Valid: 64.88% Test: 65.79%\n",
      "Run: 05, Epoch: 98, Loss: 0.3527, Train: 86.17%, Valid: 63.79% Test: 63.82%\n",
      "Run: 05, Epoch: 99, Loss: 0.3716, Train: 88.00%, Valid: 64.61% Test: 62.94%\n",
      "Run: 05, Epoch: 100, Loss: 0.3481, Train: 88.19%, Valid: 66.12% Test: 64.47%\n",
      "Run 05:\n",
      "Highest Train: 90.38\n",
      "Highest Valid: 67.76\n",
      "  Final Train: 88.46\n",
      "   Final Test: 65.35\n",
      "Run: 06, Epoch: 01, Loss: 1.9215, Train: 22.16%, Valid: 23.32% Test: 25.44%\n",
      "Run: 06, Epoch: 02, Loss: 1.4996, Train: 29.40%, Valid: 28.26% Test: 28.07%\n",
      "Run: 06, Epoch: 03, Loss: 1.3611, Train: 34.07%, Valid: 29.63% Test: 30.26%\n",
      "Run: 06, Epoch: 04, Loss: 1.3031, Train: 43.77%, Valid: 38.41% Test: 35.31%\n",
      "Run: 06, Epoch: 05, Loss: 1.2717, Train: 46.34%, Valid: 41.84% Test: 39.25%\n",
      "Run: 06, Epoch: 06, Loss: 1.2393, Train: 52.84%, Valid: 48.29% Test: 46.05%\n",
      "Run: 06, Epoch: 07, Loss: 1.2171, Train: 57.78%, Valid: 51.44% Test: 49.56%\n",
      "Run: 06, Epoch: 08, Loss: 1.1942, Train: 56.14%, Valid: 49.66% Test: 48.46%\n",
      "Run: 06, Epoch: 09, Loss: 1.1803, Train: 56.50%, Valid: 50.07% Test: 48.90%\n",
      "Run: 06, Epoch: 10, Loss: 1.1662, Train: 55.04%, Valid: 49.11% Test: 48.03%\n",
      "Run: 06, Epoch: 11, Loss: 1.1420, Train: 55.13%, Valid: 48.97% Test: 48.25%\n",
      "Run: 06, Epoch: 12, Loss: 1.1364, Train: 56.32%, Valid: 50.07% Test: 49.12%\n",
      "Run: 06, Epoch: 13, Loss: 1.1153, Train: 57.33%, Valid: 50.62% Test: 49.34%\n",
      "Run: 06, Epoch: 14, Loss: 1.0967, Train: 58.52%, Valid: 52.40% Test: 50.00%\n",
      "Run: 06, Epoch: 15, Loss: 1.0851, Train: 59.52%, Valid: 54.60% Test: 51.32%\n",
      "Run: 06, Epoch: 16, Loss: 1.0729, Train: 62.91%, Valid: 57.34% Test: 54.61%\n",
      "Run: 06, Epoch: 17, Loss: 1.0571, Train: 62.36%, Valid: 57.48% Test: 53.73%\n",
      "Run: 06, Epoch: 18, Loss: 1.0474, Train: 61.81%, Valid: 57.48% Test: 53.73%\n",
      "Run: 06, Epoch: 19, Loss: 1.0404, Train: 62.45%, Valid: 57.61% Test: 53.73%\n",
      "Run: 06, Epoch: 20, Loss: 1.0191, Train: 63.19%, Valid: 58.57% Test: 54.61%\n",
      "Run: 06, Epoch: 21, Loss: 1.0065, Train: 64.74%, Valid: 58.98% Test: 54.82%\n",
      "Run: 06, Epoch: 22, Loss: 1.0018, Train: 65.48%, Valid: 59.81% Test: 54.61%\n",
      "Run: 06, Epoch: 23, Loss: 0.9769, Train: 64.29%, Valid: 58.98% Test: 53.95%\n",
      "Run: 06, Epoch: 24, Loss: 0.9642, Train: 64.93%, Valid: 58.44% Test: 52.63%\n",
      "Run: 06, Epoch: 25, Loss: 0.9619, Train: 65.57%, Valid: 59.12% Test: 52.85%\n",
      "Run: 06, Epoch: 26, Loss: 0.9425, Train: 67.67%, Valid: 61.32% Test: 55.48%\n",
      "Run: 06, Epoch: 27, Loss: 0.9361, Train: 69.87%, Valid: 61.73% Test: 57.46%\n",
      "Run: 06, Epoch: 28, Loss: 0.9190, Train: 70.24%, Valid: 62.00% Test: 57.68%\n",
      "Run: 06, Epoch: 29, Loss: 0.8978, Train: 70.88%, Valid: 62.55% Test: 59.21%\n",
      "Run: 06, Epoch: 30, Loss: 0.8974, Train: 71.61%, Valid: 62.41% Test: 59.65%\n",
      "Run: 06, Epoch: 31, Loss: 0.8689, Train: 71.43%, Valid: 62.41% Test: 59.87%\n",
      "Run: 06, Epoch: 32, Loss: 0.8492, Train: 71.70%, Valid: 62.14% Test: 59.87%\n",
      "Run: 06, Epoch: 33, Loss: 0.8626, Train: 72.99%, Valid: 63.51% Test: 59.65%\n",
      "Run: 06, Epoch: 34, Loss: 0.8372, Train: 73.26%, Valid: 62.55% Test: 58.11%\n",
      "Run: 06, Epoch: 35, Loss: 0.8235, Train: 74.08%, Valid: 62.00% Test: 59.21%\n",
      "Run: 06, Epoch: 36, Loss: 0.8099, Train: 74.82%, Valid: 62.41% Test: 58.99%\n",
      "Run: 06, Epoch: 37, Loss: 0.7895, Train: 75.73%, Valid: 63.10% Test: 59.87%\n",
      "Run: 06, Epoch: 38, Loss: 0.7862, Train: 76.10%, Valid: 62.83% Test: 60.53%\n",
      "Run: 06, Epoch: 39, Loss: 0.7693, Train: 76.56%, Valid: 62.14% Test: 60.96%\n",
      "Run: 06, Epoch: 40, Loss: 0.7581, Train: 77.47%, Valid: 63.10% Test: 60.53%\n",
      "Run: 06, Epoch: 41, Loss: 0.7651, Train: 77.75%, Valid: 62.96% Test: 61.84%\n",
      "Run: 06, Epoch: 42, Loss: 0.7520, Train: 78.02%, Valid: 63.10% Test: 61.62%\n",
      "Run: 06, Epoch: 43, Loss: 0.7352, Train: 77.11%, Valid: 62.00% Test: 60.75%\n",
      "Run: 06, Epoch: 44, Loss: 0.7189, Train: 78.39%, Valid: 62.83% Test: 61.18%\n",
      "Run: 06, Epoch: 45, Loss: 0.7147, Train: 78.75%, Valid: 63.79% Test: 61.84%\n",
      "Run: 06, Epoch: 46, Loss: 0.6905, Train: 78.21%, Valid: 62.96% Test: 60.96%\n",
      "Run: 06, Epoch: 47, Loss: 0.7070, Train: 78.75%, Valid: 63.37% Test: 62.72%\n",
      "Run: 06, Epoch: 48, Loss: 0.6699, Train: 78.66%, Valid: 62.41% Test: 62.06%\n",
      "Run: 06, Epoch: 49, Loss: 0.6761, Train: 79.85%, Valid: 63.10% Test: 61.18%\n",
      "Run: 06, Epoch: 50, Loss: 0.6682, Train: 79.40%, Valid: 63.10% Test: 61.40%\n",
      "Run: 06, Epoch: 51, Loss: 0.6490, Train: 81.78%, Valid: 64.20% Test: 63.38%\n",
      "Run: 06, Epoch: 52, Loss: 0.6463, Train: 81.04%, Valid: 63.92% Test: 62.94%\n",
      "Run: 06, Epoch: 53, Loss: 0.6256, Train: 79.40%, Valid: 63.92% Test: 62.50%\n",
      "Run: 06, Epoch: 54, Loss: 0.6052, Train: 82.33%, Valid: 64.33% Test: 63.82%\n",
      "Run: 06, Epoch: 55, Loss: 0.6035, Train: 81.41%, Valid: 63.79% Test: 60.09%\n",
      "Run: 06, Epoch: 56, Loss: 0.5790, Train: 82.60%, Valid: 63.92% Test: 61.62%\n",
      "Run: 06, Epoch: 57, Loss: 0.5737, Train: 82.23%, Valid: 64.20% Test: 62.72%\n",
      "Run: 06, Epoch: 58, Loss: 0.5876, Train: 81.68%, Valid: 64.47% Test: 61.84%\n",
      "Run: 06, Epoch: 59, Loss: 0.5753, Train: 82.42%, Valid: 64.20% Test: 61.84%\n",
      "Run: 06, Epoch: 60, Loss: 0.5704, Train: 84.16%, Valid: 64.88% Test: 62.28%\n",
      "Run: 06, Epoch: 61, Loss: 0.5552, Train: 82.97%, Valid: 64.75% Test: 63.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 62, Loss: 0.5575, Train: 83.06%, Valid: 64.61% Test: 63.38%\n",
      "Run: 06, Epoch: 63, Loss: 0.5511, Train: 83.52%, Valid: 64.47% Test: 63.38%\n",
      "Run: 06, Epoch: 64, Loss: 0.5461, Train: 83.33%, Valid: 64.75% Test: 63.82%\n",
      "Run: 06, Epoch: 65, Loss: 0.5447, Train: 83.24%, Valid: 64.06% Test: 64.91%\n",
      "Run: 06, Epoch: 66, Loss: 0.5258, Train: 84.16%, Valid: 65.43% Test: 64.25%\n",
      "Run: 06, Epoch: 67, Loss: 0.5110, Train: 84.89%, Valid: 65.84% Test: 64.25%\n",
      "Run: 06, Epoch: 68, Loss: 0.5085, Train: 85.26%, Valid: 66.94% Test: 64.69%\n",
      "Run: 06, Epoch: 69, Loss: 0.5027, Train: 84.62%, Valid: 65.98% Test: 64.69%\n",
      "Run: 06, Epoch: 70, Loss: 0.5010, Train: 83.97%, Valid: 65.29% Test: 64.04%\n",
      "Run: 06, Epoch: 71, Loss: 0.4976, Train: 85.35%, Valid: 65.84% Test: 64.69%\n",
      "Run: 06, Epoch: 72, Loss: 0.4739, Train: 85.71%, Valid: 65.29% Test: 63.82%\n",
      "Run: 06, Epoch: 73, Loss: 0.4899, Train: 86.17%, Valid: 65.84% Test: 63.16%\n",
      "Run: 06, Epoch: 74, Loss: 0.4682, Train: 87.00%, Valid: 66.80% Test: 64.47%\n",
      "Run: 06, Epoch: 75, Loss: 0.4532, Train: 85.53%, Valid: 65.98% Test: 64.47%\n",
      "Run: 06, Epoch: 76, Loss: 0.4592, Train: 85.81%, Valid: 65.84% Test: 64.04%\n",
      "Run: 06, Epoch: 77, Loss: 0.4766, Train: 87.00%, Valid: 66.67% Test: 64.47%\n",
      "Run: 06, Epoch: 78, Loss: 0.4663, Train: 85.71%, Valid: 66.94% Test: 64.04%\n",
      "Run: 06, Epoch: 79, Loss: 0.4472, Train: 86.36%, Valid: 66.67% Test: 64.04%\n",
      "Run: 06, Epoch: 80, Loss: 0.4616, Train: 87.09%, Valid: 65.98% Test: 65.35%\n",
      "Run: 06, Epoch: 81, Loss: 0.4542, Train: 85.90%, Valid: 65.57% Test: 64.69%\n",
      "Run: 06, Epoch: 82, Loss: 0.4420, Train: 86.08%, Valid: 65.71% Test: 66.67%\n",
      "Run: 06, Epoch: 83, Loss: 0.4394, Train: 86.54%, Valid: 63.92% Test: 66.45%\n",
      "Run: 06, Epoch: 84, Loss: 0.4354, Train: 86.90%, Valid: 64.06% Test: 65.13%\n",
      "Run: 06, Epoch: 85, Loss: 0.4256, Train: 86.45%, Valid: 63.79% Test: 65.35%\n",
      "Run: 06, Epoch: 86, Loss: 0.4415, Train: 87.27%, Valid: 65.98% Test: 66.67%\n",
      "Run: 06, Epoch: 87, Loss: 0.4320, Train: 87.73%, Valid: 65.71% Test: 65.35%\n",
      "Run: 06, Epoch: 88, Loss: 0.4197, Train: 88.00%, Valid: 65.02% Test: 66.01%\n",
      "Run: 06, Epoch: 89, Loss: 0.4184, Train: 87.82%, Valid: 65.16% Test: 65.13%\n",
      "Run: 06, Epoch: 90, Loss: 0.4021, Train: 86.90%, Valid: 65.71% Test: 65.57%\n",
      "Run: 06, Epoch: 91, Loss: 0.4069, Train: 88.00%, Valid: 65.84% Test: 66.23%\n",
      "Run: 06, Epoch: 92, Loss: 0.3967, Train: 88.46%, Valid: 65.57% Test: 64.91%\n",
      "Run: 06, Epoch: 93, Loss: 0.4203, Train: 88.28%, Valid: 65.71% Test: 65.57%\n",
      "Run: 06, Epoch: 94, Loss: 0.4195, Train: 87.73%, Valid: 64.61% Test: 65.57%\n",
      "Run: 06, Epoch: 95, Loss: 0.3819, Train: 86.17%, Valid: 65.16% Test: 64.47%\n",
      "Run: 06, Epoch: 96, Loss: 0.4292, Train: 88.19%, Valid: 66.12% Test: 65.35%\n",
      "Run: 06, Epoch: 97, Loss: 0.3934, Train: 86.72%, Valid: 66.53% Test: 65.13%\n",
      "Run: 06, Epoch: 98, Loss: 0.4044, Train: 88.46%, Valid: 67.08% Test: 65.35%\n",
      "Run: 06, Epoch: 99, Loss: 0.3674, Train: 87.27%, Valid: 65.98% Test: 65.35%\n",
      "Run: 06, Epoch: 100, Loss: 0.3908, Train: 87.09%, Valid: 65.02% Test: 66.45%\n",
      "Run 06:\n",
      "Highest Train: 88.46\n",
      "Highest Valid: 67.08\n",
      "  Final Train: 88.46\n",
      "   Final Test: 65.35\n",
      "Run: 07, Epoch: 01, Loss: 1.8397, Train: 28.57%, Valid: 26.34% Test: 22.81%\n",
      "Run: 07, Epoch: 02, Loss: 1.2929, Train: 30.68%, Valid: 28.26% Test: 25.22%\n",
      "Run: 07, Epoch: 03, Loss: 1.2234, Train: 33.52%, Valid: 32.24% Test: 28.07%\n",
      "Run: 07, Epoch: 04, Loss: 1.1954, Train: 36.81%, Valid: 32.92% Test: 29.17%\n",
      "Run: 07, Epoch: 05, Loss: 1.1666, Train: 39.29%, Valid: 34.29% Test: 31.36%\n",
      "Run: 07, Epoch: 06, Loss: 1.1395, Train: 44.60%, Valid: 38.41% Test: 35.53%\n",
      "Run: 07, Epoch: 07, Loss: 1.1146, Train: 49.54%, Valid: 41.70% Test: 40.13%\n",
      "Run: 07, Epoch: 08, Loss: 1.0927, Train: 52.11%, Valid: 44.44% Test: 39.69%\n",
      "Run: 07, Epoch: 09, Loss: 1.0712, Train: 54.58%, Valid: 46.23% Test: 42.11%\n",
      "Run: 07, Epoch: 10, Loss: 1.0479, Train: 56.96%, Valid: 46.91% Test: 44.08%\n",
      "Run: 07, Epoch: 11, Loss: 1.0315, Train: 59.25%, Valid: 49.25% Test: 45.83%\n",
      "Run: 07, Epoch: 12, Loss: 1.0254, Train: 60.16%, Valid: 50.07% Test: 47.37%\n",
      "Run: 07, Epoch: 13, Loss: 0.9948, Train: 60.90%, Valid: 50.48% Test: 48.90%\n",
      "Run: 07, Epoch: 14, Loss: 0.9758, Train: 61.26%, Valid: 51.30% Test: 49.78%\n",
      "Run: 07, Epoch: 15, Loss: 0.9557, Train: 62.55%, Valid: 51.58% Test: 50.44%\n",
      "Run: 07, Epoch: 16, Loss: 0.9333, Train: 63.55%, Valid: 52.26% Test: 50.88%\n",
      "Run: 07, Epoch: 17, Loss: 0.9240, Train: 63.92%, Valid: 52.40% Test: 51.32%\n",
      "Run: 07, Epoch: 18, Loss: 0.9084, Train: 63.28%, Valid: 52.67% Test: 53.73%\n",
      "Run: 07, Epoch: 19, Loss: 0.8877, Train: 65.20%, Valid: 52.67% Test: 53.73%\n",
      "Run: 07, Epoch: 20, Loss: 0.8566, Train: 66.39%, Valid: 53.77% Test: 53.29%\n",
      "Run: 07, Epoch: 21, Loss: 0.8565, Train: 66.85%, Valid: 54.73% Test: 53.73%\n",
      "Run: 07, Epoch: 22, Loss: 0.8459, Train: 68.50%, Valid: 55.14% Test: 53.95%\n",
      "Run: 07, Epoch: 23, Loss: 0.8266, Train: 69.41%, Valid: 56.24% Test: 54.39%\n",
      "Run: 07, Epoch: 24, Loss: 0.8172, Train: 70.15%, Valid: 56.10% Test: 55.48%\n",
      "Run: 07, Epoch: 25, Loss: 0.8088, Train: 70.51%, Valid: 56.65% Test: 54.82%\n",
      "Run: 07, Epoch: 26, Loss: 0.7849, Train: 71.61%, Valid: 56.52% Test: 56.36%\n",
      "Run: 07, Epoch: 27, Loss: 0.7610, Train: 72.34%, Valid: 56.93% Test: 57.02%\n",
      "Run: 07, Epoch: 28, Loss: 0.7546, Train: 74.91%, Valid: 59.40% Test: 58.55%\n",
      "Run: 07, Epoch: 29, Loss: 0.7424, Train: 76.65%, Valid: 60.49% Test: 57.02%\n",
      "Run: 07, Epoch: 30, Loss: 0.7357, Train: 76.56%, Valid: 60.77% Test: 55.48%\n",
      "Run: 07, Epoch: 31, Loss: 0.7166, Train: 76.92%, Valid: 60.36% Test: 56.14%\n",
      "Run: 07, Epoch: 32, Loss: 0.7095, Train: 78.39%, Valid: 60.08% Test: 57.89%\n",
      "Run: 07, Epoch: 33, Loss: 0.6746, Train: 78.21%, Valid: 60.36% Test: 57.68%\n",
      "Run: 07, Epoch: 34, Loss: 0.6647, Train: 78.66%, Valid: 61.87% Test: 57.46%\n",
      "Run: 07, Epoch: 35, Loss: 0.6813, Train: 78.39%, Valid: 62.41% Test: 58.33%\n",
      "Run: 07, Epoch: 36, Loss: 0.6561, Train: 78.85%, Valid: 62.55% Test: 58.33%\n",
      "Run: 07, Epoch: 37, Loss: 0.6337, Train: 79.85%, Valid: 62.69% Test: 59.65%\n",
      "Run: 07, Epoch: 38, Loss: 0.6203, Train: 79.95%, Valid: 63.37% Test: 60.53%\n",
      "Run: 07, Epoch: 39, Loss: 0.6156, Train: 80.40%, Valid: 63.65% Test: 59.43%\n",
      "Run: 07, Epoch: 40, Loss: 0.6121, Train: 80.77%, Valid: 64.20% Test: 61.18%\n",
      "Run: 07, Epoch: 41, Loss: 0.6157, Train: 81.59%, Valid: 64.61% Test: 61.84%\n",
      "Run: 07, Epoch: 42, Loss: 0.5924, Train: 82.33%, Valid: 64.47% Test: 61.18%\n",
      "Run: 07, Epoch: 43, Loss: 0.5931, Train: 83.06%, Valid: 64.61% Test: 62.06%\n",
      "Run: 07, Epoch: 44, Loss: 0.5895, Train: 82.69%, Valid: 64.33% Test: 59.43%\n",
      "Run: 07, Epoch: 45, Loss: 0.5534, Train: 82.42%, Valid: 64.75% Test: 60.09%\n",
      "Run: 07, Epoch: 46, Loss: 0.5530, Train: 82.88%, Valid: 64.47% Test: 59.65%\n",
      "Run: 07, Epoch: 47, Loss: 0.5331, Train: 83.15%, Valid: 64.88% Test: 60.75%\n",
      "Run: 07, Epoch: 48, Loss: 0.5333, Train: 82.51%, Valid: 64.20% Test: 61.18%\n",
      "Run: 07, Epoch: 49, Loss: 0.5225, Train: 82.78%, Valid: 64.75% Test: 60.75%\n",
      "Run: 07, Epoch: 50, Loss: 0.4990, Train: 82.69%, Valid: 65.02% Test: 61.40%\n",
      "Run: 07, Epoch: 51, Loss: 0.5321, Train: 85.07%, Valid: 65.84% Test: 62.06%\n",
      "Run: 07, Epoch: 52, Loss: 0.5266, Train: 83.06%, Valid: 63.65% Test: 59.21%\n",
      "Run: 07, Epoch: 53, Loss: 0.5187, Train: 83.79%, Valid: 64.20% Test: 59.65%\n",
      "Run: 07, Epoch: 54, Loss: 0.4936, Train: 84.43%, Valid: 64.88% Test: 60.53%\n",
      "Run: 07, Epoch: 55, Loss: 0.4944, Train: 84.80%, Valid: 64.61% Test: 59.65%\n",
      "Run: 07, Epoch: 56, Loss: 0.5025, Train: 85.90%, Valid: 65.84% Test: 62.28%\n",
      "Run: 07, Epoch: 57, Loss: 0.4795, Train: 84.98%, Valid: 65.71% Test: 63.38%\n",
      "Run: 07, Epoch: 58, Loss: 0.4812, Train: 85.81%, Valid: 66.26% Test: 61.40%\n",
      "Run: 07, Epoch: 59, Loss: 0.4734, Train: 86.45%, Valid: 66.67% Test: 62.50%\n",
      "Run: 07, Epoch: 60, Loss: 0.4558, Train: 86.54%, Valid: 65.84% Test: 63.82%\n",
      "Run: 07, Epoch: 61, Loss: 0.4584, Train: 86.63%, Valid: 66.39% Test: 63.60%\n",
      "Run: 07, Epoch: 62, Loss: 0.4560, Train: 87.73%, Valid: 67.35% Test: 64.25%\n",
      "Run: 07, Epoch: 63, Loss: 0.4376, Train: 87.00%, Valid: 67.63% Test: 63.16%\n",
      "Run: 07, Epoch: 64, Loss: 0.4443, Train: 85.90%, Valid: 66.26% Test: 62.50%\n",
      "Run: 07, Epoch: 65, Loss: 0.4529, Train: 87.09%, Valid: 66.39% Test: 61.40%\n",
      "Run: 07, Epoch: 66, Loss: 0.4285, Train: 87.73%, Valid: 66.53% Test: 62.72%\n",
      "Run: 07, Epoch: 67, Loss: 0.4425, Train: 87.55%, Valid: 64.75% Test: 62.28%\n",
      "Run: 07, Epoch: 68, Loss: 0.4402, Train: 88.37%, Valid: 66.39% Test: 63.82%\n",
      "Run: 07, Epoch: 69, Loss: 0.4236, Train: 87.00%, Valid: 66.26% Test: 65.13%\n",
      "Run: 07, Epoch: 70, Loss: 0.4284, Train: 88.46%, Valid: 67.35% Test: 66.67%\n",
      "Run: 07, Epoch: 71, Loss: 0.4130, Train: 87.00%, Valid: 65.57% Test: 65.57%\n",
      "Run: 07, Epoch: 72, Loss: 0.4358, Train: 87.27%, Valid: 66.12% Test: 64.91%\n",
      "Run: 07, Epoch: 73, Loss: 0.4269, Train: 86.26%, Valid: 66.12% Test: 63.60%\n",
      "Run: 07, Epoch: 74, Loss: 0.4219, Train: 87.91%, Valid: 67.08% Test: 63.16%\n",
      "Run: 07, Epoch: 75, Loss: 0.3929, Train: 86.36%, Valid: 64.88% Test: 61.62%\n",
      "Run: 07, Epoch: 76, Loss: 0.4081, Train: 87.73%, Valid: 66.53% Test: 62.72%\n",
      "Run: 07, Epoch: 77, Loss: 0.3906, Train: 87.09%, Valid: 65.02% Test: 63.82%\n",
      "Run: 07, Epoch: 78, Loss: 0.4067, Train: 88.10%, Valid: 65.98% Test: 64.25%\n",
      "Run: 07, Epoch: 79, Loss: 0.3874, Train: 89.01%, Valid: 67.63% Test: 64.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 80, Loss: 0.3661, Train: 88.64%, Valid: 66.80% Test: 64.04%\n",
      "Run: 07, Epoch: 81, Loss: 0.3740, Train: 89.01%, Valid: 66.39% Test: 62.72%\n",
      "Run: 07, Epoch: 82, Loss: 0.3923, Train: 88.92%, Valid: 67.35% Test: 64.69%\n",
      "Run: 07, Epoch: 83, Loss: 0.3944, Train: 88.37%, Valid: 67.76% Test: 64.25%\n",
      "Run: 07, Epoch: 84, Loss: 0.3787, Train: 88.64%, Valid: 68.72% Test: 64.25%\n",
      "Run: 07, Epoch: 85, Loss: 0.3654, Train: 89.29%, Valid: 67.22% Test: 64.47%\n",
      "Run: 07, Epoch: 86, Loss: 0.3778, Train: 89.38%, Valid: 66.67% Test: 64.47%\n",
      "Run: 07, Epoch: 87, Loss: 0.3693, Train: 89.29%, Valid: 66.94% Test: 64.47%\n",
      "Run: 07, Epoch: 88, Loss: 0.3678, Train: 89.74%, Valid: 66.53% Test: 64.91%\n",
      "Run: 07, Epoch: 89, Loss: 0.3663, Train: 88.83%, Valid: 66.53% Test: 64.04%\n",
      "Run: 07, Epoch: 90, Loss: 0.3750, Train: 88.83%, Valid: 66.53% Test: 63.38%\n",
      "Run: 07, Epoch: 91, Loss: 0.3692, Train: 89.01%, Valid: 65.84% Test: 62.72%\n",
      "Run: 07, Epoch: 92, Loss: 0.3881, Train: 86.72%, Valid: 65.84% Test: 63.16%\n",
      "Run: 07, Epoch: 93, Loss: 0.4158, Train: 88.46%, Valid: 65.71% Test: 63.38%\n",
      "Run: 07, Epoch: 94, Loss: 0.3635, Train: 88.74%, Valid: 65.29% Test: 62.28%\n",
      "Run: 07, Epoch: 95, Loss: 0.3520, Train: 88.28%, Valid: 64.61% Test: 62.06%\n",
      "Run: 07, Epoch: 96, Loss: 0.3708, Train: 90.11%, Valid: 65.71% Test: 63.60%\n",
      "Run: 07, Epoch: 97, Loss: 0.3444, Train: 89.38%, Valid: 66.80% Test: 64.04%\n",
      "Run: 07, Epoch: 98, Loss: 0.3631, Train: 89.10%, Valid: 66.53% Test: 64.25%\n",
      "Run: 07, Epoch: 99, Loss: 0.3621, Train: 91.48%, Valid: 67.35% Test: 65.57%\n",
      "Run: 07, Epoch: 100, Loss: 0.3401, Train: 91.12%, Valid: 67.22% Test: 64.91%\n",
      "Run 07:\n",
      "Highest Train: 91.48\n",
      "Highest Valid: 68.72\n",
      "  Final Train: 88.64\n",
      "   Final Test: 64.25\n",
      "Run: 08, Epoch: 01, Loss: 1.8921, Train: 27.01%, Valid: 27.43% Test: 26.10%\n",
      "Run: 08, Epoch: 02, Loss: 1.3820, Train: 34.16%, Valid: 29.77% Test: 28.07%\n",
      "Run: 08, Epoch: 03, Loss: 1.2834, Train: 36.26%, Valid: 32.24% Test: 31.14%\n",
      "Run: 08, Epoch: 04, Loss: 1.2521, Train: 40.02%, Valid: 34.84% Test: 32.24%\n",
      "Run: 08, Epoch: 05, Loss: 1.2195, Train: 42.12%, Valid: 36.35% Test: 35.31%\n",
      "Run: 08, Epoch: 06, Loss: 1.2082, Train: 42.95%, Valid: 37.45% Test: 35.53%\n",
      "Run: 08, Epoch: 07, Loss: 1.1911, Train: 44.96%, Valid: 39.37% Test: 36.40%\n",
      "Run: 08, Epoch: 08, Loss: 1.1484, Train: 46.52%, Valid: 40.88% Test: 36.62%\n",
      "Run: 08, Epoch: 09, Loss: 1.1499, Train: 48.63%, Valid: 43.76% Test: 41.67%\n",
      "Run: 08, Epoch: 10, Loss: 1.1577, Train: 51.37%, Valid: 45.13% Test: 44.52%\n",
      "Run: 08, Epoch: 11, Loss: 1.1177, Train: 54.67%, Valid: 48.42% Test: 45.18%\n",
      "Run: 08, Epoch: 12, Loss: 1.0971, Train: 57.42%, Valid: 50.62% Test: 46.05%\n",
      "Run: 08, Epoch: 13, Loss: 1.0779, Train: 60.81%, Valid: 52.81% Test: 48.46%\n",
      "Run: 08, Epoch: 14, Loss: 1.0643, Train: 61.72%, Valid: 52.54% Test: 48.25%\n",
      "Run: 08, Epoch: 15, Loss: 1.0419, Train: 62.73%, Valid: 53.09% Test: 49.12%\n",
      "Run: 08, Epoch: 16, Loss: 1.0317, Train: 64.38%, Valid: 54.05% Test: 51.10%\n",
      "Run: 08, Epoch: 17, Loss: 1.0193, Train: 66.21%, Valid: 53.50% Test: 50.66%\n",
      "Run: 08, Epoch: 18, Loss: 1.0158, Train: 66.03%, Valid: 52.95% Test: 50.66%\n",
      "Run: 08, Epoch: 19, Loss: 1.0041, Train: 66.48%, Valid: 54.18% Test: 50.66%\n",
      "Run: 08, Epoch: 20, Loss: 0.9755, Train: 68.04%, Valid: 56.24% Test: 51.32%\n",
      "Run: 08, Epoch: 21, Loss: 0.9571, Train: 68.41%, Valid: 56.65% Test: 51.97%\n",
      "Run: 08, Epoch: 22, Loss: 0.9467, Train: 68.68%, Valid: 56.52% Test: 52.85%\n",
      "Run: 08, Epoch: 23, Loss: 0.9417, Train: 70.42%, Valid: 57.06% Test: 54.17%\n",
      "Run: 08, Epoch: 24, Loss: 0.9194, Train: 70.79%, Valid: 58.02% Test: 54.61%\n",
      "Run: 08, Epoch: 25, Loss: 0.9081, Train: 72.07%, Valid: 58.16% Test: 55.04%\n",
      "Run: 08, Epoch: 26, Loss: 0.8909, Train: 72.44%, Valid: 58.71% Test: 54.39%\n",
      "Run: 08, Epoch: 27, Loss: 0.8730, Train: 71.70%, Valid: 58.02% Test: 51.97%\n",
      "Run: 08, Epoch: 28, Loss: 0.8593, Train: 70.88%, Valid: 56.52% Test: 50.22%\n",
      "Run: 08, Epoch: 29, Loss: 0.8463, Train: 70.97%, Valid: 55.69% Test: 50.44%\n",
      "Run: 08, Epoch: 30, Loss: 0.8445, Train: 72.16%, Valid: 56.38% Test: 51.32%\n",
      "Run: 08, Epoch: 31, Loss: 0.8235, Train: 72.25%, Valid: 56.79% Test: 51.32%\n",
      "Run: 08, Epoch: 32, Loss: 0.8054, Train: 71.98%, Valid: 55.56% Test: 51.10%\n",
      "Run: 08, Epoch: 33, Loss: 0.7930, Train: 72.89%, Valid: 56.52% Test: 52.19%\n",
      "Run: 08, Epoch: 34, Loss: 0.8054, Train: 74.27%, Valid: 57.34% Test: 53.73%\n",
      "Run: 08, Epoch: 35, Loss: 0.7876, Train: 75.09%, Valid: 58.57% Test: 55.48%\n",
      "Run: 08, Epoch: 36, Loss: 0.7704, Train: 76.83%, Valid: 59.95% Test: 56.14%\n",
      "Run: 08, Epoch: 37, Loss: 0.7604, Train: 76.92%, Valid: 59.95% Test: 56.36%\n",
      "Run: 08, Epoch: 38, Loss: 0.7492, Train: 77.01%, Valid: 59.67% Test: 55.70%\n",
      "Run: 08, Epoch: 39, Loss: 0.7157, Train: 77.38%, Valid: 60.36% Test: 55.70%\n",
      "Run: 08, Epoch: 40, Loss: 0.7178, Train: 77.01%, Valid: 59.67% Test: 56.80%\n",
      "Run: 08, Epoch: 41, Loss: 0.7091, Train: 77.56%, Valid: 59.40% Test: 57.89%\n",
      "Run: 08, Epoch: 42, Loss: 0.7208, Train: 78.30%, Valid: 60.77% Test: 57.46%\n",
      "Run: 08, Epoch: 43, Loss: 0.6675, Train: 78.21%, Valid: 60.22% Test: 56.14%\n",
      "Run: 08, Epoch: 44, Loss: 0.6649, Train: 77.66%, Valid: 59.81% Test: 55.70%\n",
      "Run: 08, Epoch: 45, Loss: 0.6606, Train: 80.31%, Valid: 60.63% Test: 58.77%\n",
      "Run: 08, Epoch: 46, Loss: 0.6540, Train: 79.76%, Valid: 60.08% Test: 60.31%\n",
      "Run: 08, Epoch: 47, Loss: 0.6486, Train: 79.49%, Valid: 60.63% Test: 60.31%\n",
      "Run: 08, Epoch: 48, Loss: 0.6408, Train: 81.68%, Valid: 60.77% Test: 60.09%\n",
      "Run: 08, Epoch: 49, Loss: 0.6107, Train: 80.31%, Valid: 58.98% Test: 58.11%\n",
      "Run: 08, Epoch: 50, Loss: 0.6224, Train: 80.59%, Valid: 59.67% Test: 58.77%\n",
      "Run: 08, Epoch: 51, Loss: 0.6173, Train: 82.05%, Valid: 60.36% Test: 60.09%\n",
      "Run: 08, Epoch: 52, Loss: 0.6031, Train: 83.24%, Valid: 59.81% Test: 61.18%\n",
      "Run: 08, Epoch: 53, Loss: 0.5773, Train: 82.33%, Valid: 59.26% Test: 61.18%\n",
      "Run: 08, Epoch: 54, Loss: 0.5677, Train: 82.88%, Valid: 59.81% Test: 60.53%\n",
      "Run: 08, Epoch: 55, Loss: 0.5796, Train: 82.42%, Valid: 61.04% Test: 59.43%\n",
      "Run: 08, Epoch: 56, Loss: 0.5603, Train: 82.69%, Valid: 60.63% Test: 60.53%\n",
      "Run: 08, Epoch: 57, Loss: 0.5428, Train: 83.33%, Valid: 60.49% Test: 60.53%\n",
      "Run: 08, Epoch: 58, Loss: 0.5411, Train: 83.15%, Valid: 60.22% Test: 61.84%\n",
      "Run: 08, Epoch: 59, Loss: 0.5659, Train: 82.51%, Valid: 61.45% Test: 62.28%\n",
      "Run: 08, Epoch: 60, Loss: 0.5378, Train: 82.97%, Valid: 62.83% Test: 60.96%\n",
      "Run: 08, Epoch: 61, Loss: 0.5225, Train: 84.16%, Valid: 62.96% Test: 60.96%\n",
      "Run: 08, Epoch: 62, Loss: 0.5244, Train: 83.52%, Valid: 61.59% Test: 59.65%\n",
      "Run: 08, Epoch: 63, Loss: 0.5173, Train: 84.34%, Valid: 62.28% Test: 61.40%\n",
      "Run: 08, Epoch: 64, Loss: 0.5037, Train: 84.34%, Valid: 61.59% Test: 61.84%\n",
      "Run: 08, Epoch: 65, Loss: 0.4986, Train: 84.71%, Valid: 60.77% Test: 62.28%\n",
      "Run: 08, Epoch: 66, Loss: 0.4880, Train: 86.17%, Valid: 60.63% Test: 63.60%\n",
      "Run: 08, Epoch: 67, Loss: 0.4769, Train: 86.72%, Valid: 61.59% Test: 62.94%\n",
      "Run: 08, Epoch: 68, Loss: 0.4667, Train: 85.90%, Valid: 61.18% Test: 62.28%\n",
      "Run: 08, Epoch: 69, Loss: 0.4739, Train: 85.26%, Valid: 61.73% Test: 61.84%\n",
      "Run: 08, Epoch: 70, Loss: 0.4584, Train: 84.62%, Valid: 62.55% Test: 62.28%\n",
      "Run: 08, Epoch: 71, Loss: 0.4768, Train: 84.98%, Valid: 63.10% Test: 61.40%\n",
      "Run: 08, Epoch: 72, Loss: 0.4670, Train: 85.71%, Valid: 61.87% Test: 62.28%\n",
      "Run: 08, Epoch: 73, Loss: 0.4308, Train: 86.72%, Valid: 62.00% Test: 63.16%\n",
      "Run: 08, Epoch: 74, Loss: 0.4406, Train: 86.72%, Valid: 61.32% Test: 64.04%\n",
      "Run: 08, Epoch: 75, Loss: 0.4437, Train: 86.45%, Valid: 61.87% Test: 64.91%\n",
      "Run: 08, Epoch: 76, Loss: 0.4323, Train: 87.00%, Valid: 61.59% Test: 64.69%\n",
      "Run: 08, Epoch: 77, Loss: 0.4278, Train: 88.10%, Valid: 62.96% Test: 63.60%\n",
      "Run: 08, Epoch: 78, Loss: 0.4460, Train: 88.46%, Valid: 62.41% Test: 63.82%\n",
      "Run: 08, Epoch: 79, Loss: 0.4051, Train: 88.92%, Valid: 61.87% Test: 63.16%\n",
      "Run: 08, Epoch: 80, Loss: 0.4178, Train: 89.10%, Valid: 61.45% Test: 63.16%\n",
      "Run: 08, Epoch: 81, Loss: 0.4079, Train: 88.00%, Valid: 62.00% Test: 63.16%\n",
      "Run: 08, Epoch: 82, Loss: 0.4111, Train: 87.09%, Valid: 61.87% Test: 63.38%\n",
      "Run: 08, Epoch: 83, Loss: 0.4439, Train: 88.83%, Valid: 61.87% Test: 62.06%\n",
      "Run: 08, Epoch: 84, Loss: 0.4275, Train: 88.74%, Valid: 62.96% Test: 64.25%\n",
      "Run: 08, Epoch: 85, Loss: 0.3940, Train: 88.74%, Valid: 62.00% Test: 61.84%\n",
      "Run: 08, Epoch: 86, Loss: 0.3845, Train: 87.73%, Valid: 61.32% Test: 60.53%\n",
      "Run: 08, Epoch: 87, Loss: 0.3948, Train: 88.10%, Valid: 61.18% Test: 62.28%\n",
      "Run: 08, Epoch: 88, Loss: 0.3665, Train: 88.19%, Valid: 61.87% Test: 63.60%\n",
      "Run: 08, Epoch: 89, Loss: 0.3804, Train: 87.91%, Valid: 62.00% Test: 64.69%\n",
      "Run: 08, Epoch: 90, Loss: 0.3907, Train: 87.45%, Valid: 61.45% Test: 63.16%\n",
      "Run: 08, Epoch: 91, Loss: 0.3725, Train: 87.73%, Valid: 60.91% Test: 62.72%\n",
      "Run: 08, Epoch: 92, Loss: 0.3874, Train: 89.84%, Valid: 62.96% Test: 65.35%\n",
      "Run: 08, Epoch: 93, Loss: 0.3676, Train: 88.55%, Valid: 62.28% Test: 64.47%\n",
      "Run: 08, Epoch: 94, Loss: 0.3793, Train: 89.29%, Valid: 61.59% Test: 63.38%\n",
      "Run: 08, Epoch: 95, Loss: 0.3702, Train: 89.56%, Valid: 62.83% Test: 63.16%\n",
      "Run: 08, Epoch: 96, Loss: 0.3777, Train: 90.57%, Valid: 64.47% Test: 64.69%\n",
      "Run: 08, Epoch: 97, Loss: 0.3471, Train: 88.92%, Valid: 64.06% Test: 65.35%\n",
      "Run: 08, Epoch: 98, Loss: 0.3865, Train: 89.01%, Valid: 63.65% Test: 64.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 99, Loss: 0.3666, Train: 90.11%, Valid: 64.20% Test: 64.04%\n",
      "Run: 08, Epoch: 100, Loss: 0.3802, Train: 89.01%, Valid: 63.37% Test: 64.25%\n",
      "Run 08:\n",
      "Highest Train: 90.57\n",
      "Highest Valid: 64.47\n",
      "  Final Train: 90.57\n",
      "   Final Test: 64.69\n",
      "Run: 09, Epoch: 01, Loss: 1.9826, Train: 28.85%, Valid: 27.57% Test: 27.63%\n",
      "Run: 09, Epoch: 02, Loss: 1.3683, Train: 28.75%, Valid: 27.43% Test: 27.63%\n",
      "Run: 09, Epoch: 03, Loss: 1.2665, Train: 32.33%, Valid: 29.90% Test: 30.26%\n",
      "Run: 09, Epoch: 04, Loss: 1.2287, Train: 36.08%, Valid: 31.41% Test: 32.89%\n",
      "Run: 09, Epoch: 05, Loss: 1.1871, Train: 39.01%, Valid: 33.47% Test: 34.21%\n",
      "Run: 09, Epoch: 06, Loss: 1.1745, Train: 45.70%, Valid: 37.04% Test: 39.47%\n",
      "Run: 09, Epoch: 07, Loss: 1.1436, Train: 48.63%, Valid: 39.09% Test: 41.01%\n",
      "Run: 09, Epoch: 08, Loss: 1.1330, Train: 49.73%, Valid: 40.74% Test: 43.42%\n",
      "Run: 09, Epoch: 09, Loss: 1.1178, Train: 52.01%, Valid: 42.52% Test: 44.96%\n",
      "Run: 09, Epoch: 10, Loss: 1.0934, Train: 53.75%, Valid: 44.99% Test: 45.61%\n",
      "Run: 09, Epoch: 11, Loss: 1.0786, Train: 56.14%, Valid: 47.05% Test: 49.56%\n",
      "Run: 09, Epoch: 12, Loss: 1.0453, Train: 57.69%, Valid: 47.60% Test: 50.00%\n",
      "Run: 09, Epoch: 13, Loss: 1.0532, Train: 59.71%, Valid: 50.07% Test: 51.97%\n",
      "Run: 09, Epoch: 14, Loss: 1.0297, Train: 59.98%, Valid: 51.85% Test: 51.97%\n",
      "Run: 09, Epoch: 15, Loss: 1.0119, Train: 60.07%, Valid: 52.54% Test: 52.41%\n",
      "Run: 09, Epoch: 16, Loss: 1.0032, Train: 60.44%, Valid: 52.40% Test: 52.85%\n",
      "Run: 09, Epoch: 17, Loss: 0.9822, Train: 61.45%, Valid: 53.22% Test: 53.29%\n",
      "Run: 09, Epoch: 18, Loss: 0.9647, Train: 62.64%, Valid: 53.77% Test: 53.95%\n",
      "Run: 09, Epoch: 19, Loss: 0.9517, Train: 63.55%, Valid: 54.32% Test: 55.04%\n",
      "Run: 09, Epoch: 20, Loss: 0.9229, Train: 65.57%, Valid: 55.42% Test: 55.48%\n",
      "Run: 09, Epoch: 21, Loss: 0.9247, Train: 66.03%, Valid: 55.56% Test: 55.92%\n",
      "Run: 09, Epoch: 22, Loss: 0.8949, Train: 66.67%, Valid: 56.10% Test: 56.14%\n",
      "Run: 09, Epoch: 23, Loss: 0.8776, Train: 66.85%, Valid: 55.83% Test: 56.80%\n",
      "Run: 09, Epoch: 24, Loss: 0.8752, Train: 66.85%, Valid: 56.24% Test: 56.80%\n",
      "Run: 09, Epoch: 25, Loss: 0.8584, Train: 68.04%, Valid: 56.65% Test: 56.80%\n",
      "Run: 09, Epoch: 26, Loss: 0.8555, Train: 69.51%, Valid: 59.26% Test: 57.89%\n",
      "Run: 09, Epoch: 27, Loss: 0.8389, Train: 70.60%, Valid: 59.40% Test: 58.77%\n",
      "Run: 09, Epoch: 28, Loss: 0.8239, Train: 72.16%, Valid: 61.73% Test: 62.06%\n",
      "Run: 09, Epoch: 29, Loss: 0.8140, Train: 73.17%, Valid: 63.51% Test: 62.72%\n",
      "Run: 09, Epoch: 30, Loss: 0.8017, Train: 73.90%, Valid: 64.20% Test: 62.94%\n",
      "Run: 09, Epoch: 31, Loss: 0.7979, Train: 74.36%, Valid: 64.75% Test: 64.04%\n",
      "Run: 09, Epoch: 32, Loss: 0.7670, Train: 74.27%, Valid: 64.75% Test: 63.16%\n",
      "Run: 09, Epoch: 33, Loss: 0.7717, Train: 75.55%, Valid: 63.51% Test: 64.04%\n",
      "Run: 09, Epoch: 34, Loss: 0.7578, Train: 76.28%, Valid: 63.51% Test: 63.82%\n",
      "Run: 09, Epoch: 35, Loss: 0.7306, Train: 75.27%, Valid: 64.20% Test: 62.72%\n",
      "Run: 09, Epoch: 36, Loss: 0.7272, Train: 75.46%, Valid: 63.65% Test: 62.94%\n",
      "Run: 09, Epoch: 37, Loss: 0.7267, Train: 76.28%, Valid: 63.51% Test: 63.38%\n",
      "Run: 09, Epoch: 38, Loss: 0.7104, Train: 77.66%, Valid: 63.10% Test: 63.38%\n",
      "Run: 09, Epoch: 39, Loss: 0.7102, Train: 76.92%, Valid: 61.87% Test: 63.16%\n",
      "Run: 09, Epoch: 40, Loss: 0.6871, Train: 77.38%, Valid: 64.33% Test: 63.60%\n",
      "Run: 09, Epoch: 41, Loss: 0.6828, Train: 76.47%, Valid: 65.43% Test: 65.35%\n",
      "Run: 09, Epoch: 42, Loss: 0.6793, Train: 78.02%, Valid: 65.71% Test: 65.13%\n",
      "Run: 09, Epoch: 43, Loss: 0.6545, Train: 80.13%, Valid: 66.53% Test: 66.67%\n",
      "Run: 09, Epoch: 44, Loss: 0.6548, Train: 79.95%, Valid: 65.98% Test: 65.79%\n",
      "Run: 09, Epoch: 45, Loss: 0.6561, Train: 79.12%, Valid: 66.80% Test: 65.79%\n",
      "Run: 09, Epoch: 46, Loss: 0.6326, Train: 78.30%, Valid: 66.94% Test: 66.01%\n",
      "Run: 09, Epoch: 47, Loss: 0.6262, Train: 78.21%, Valid: 66.39% Test: 65.13%\n",
      "Run: 09, Epoch: 48, Loss: 0.6397, Train: 80.68%, Valid: 65.02% Test: 65.35%\n",
      "Run: 09, Epoch: 49, Loss: 0.6084, Train: 82.14%, Valid: 66.12% Test: 66.23%\n",
      "Run: 09, Epoch: 50, Loss: 0.6218, Train: 81.68%, Valid: 67.08% Test: 66.89%\n",
      "Run: 09, Epoch: 51, Loss: 0.6107, Train: 82.23%, Valid: 66.26% Test: 65.35%\n",
      "Run: 09, Epoch: 52, Loss: 0.6002, Train: 81.32%, Valid: 65.43% Test: 65.13%\n",
      "Run: 09, Epoch: 53, Loss: 0.5926, Train: 80.04%, Valid: 66.67% Test: 65.35%\n",
      "Run: 09, Epoch: 54, Loss: 0.6037, Train: 81.59%, Valid: 66.26% Test: 65.13%\n",
      "Run: 09, Epoch: 55, Loss: 0.5859, Train: 82.69%, Valid: 66.26% Test: 66.45%\n",
      "Run: 09, Epoch: 56, Loss: 0.5811, Train: 81.50%, Valid: 66.94% Test: 65.57%\n",
      "Run: 09, Epoch: 57, Loss: 0.5711, Train: 83.15%, Valid: 66.80% Test: 65.79%\n",
      "Run: 09, Epoch: 58, Loss: 0.5601, Train: 82.78%, Valid: 64.88% Test: 65.35%\n",
      "Run: 09, Epoch: 59, Loss: 0.5307, Train: 82.88%, Valid: 66.26% Test: 67.98%\n",
      "Run: 09, Epoch: 60, Loss: 0.5511, Train: 82.51%, Valid: 66.12% Test: 65.57%\n",
      "Run: 09, Epoch: 61, Loss: 0.5370, Train: 83.79%, Valid: 65.84% Test: 65.79%\n",
      "Run: 09, Epoch: 62, Loss: 0.5271, Train: 83.70%, Valid: 64.47% Test: 64.69%\n",
      "Run: 09, Epoch: 63, Loss: 0.5263, Train: 84.34%, Valid: 63.92% Test: 65.79%\n",
      "Run: 09, Epoch: 64, Loss: 0.5418, Train: 83.79%, Valid: 66.67% Test: 65.79%\n",
      "Run: 09, Epoch: 65, Loss: 0.5277, Train: 84.34%, Valid: 67.08% Test: 65.35%\n",
      "Run: 09, Epoch: 66, Loss: 0.5347, Train: 84.34%, Valid: 65.98% Test: 66.23%\n",
      "Run: 09, Epoch: 67, Loss: 0.4950, Train: 83.42%, Valid: 63.92% Test: 65.79%\n",
      "Run: 09, Epoch: 68, Loss: 0.5180, Train: 84.34%, Valid: 65.71% Test: 66.01%\n",
      "Run: 09, Epoch: 69, Loss: 0.5106, Train: 84.98%, Valid: 66.80% Test: 65.79%\n",
      "Run: 09, Epoch: 70, Loss: 0.5051, Train: 84.34%, Valid: 65.98% Test: 66.45%\n",
      "Run: 09, Epoch: 71, Loss: 0.4887, Train: 85.07%, Valid: 65.29% Test: 65.35%\n",
      "Run: 09, Epoch: 72, Loss: 0.5003, Train: 85.16%, Valid: 65.29% Test: 66.89%\n",
      "Run: 09, Epoch: 73, Loss: 0.4759, Train: 84.43%, Valid: 65.71% Test: 64.04%\n",
      "Run: 09, Epoch: 74, Loss: 0.4675, Train: 84.71%, Valid: 66.39% Test: 64.69%\n",
      "Run: 09, Epoch: 75, Loss: 0.4628, Train: 86.26%, Valid: 67.35% Test: 67.11%\n",
      "Run: 09, Epoch: 76, Loss: 0.5005, Train: 84.62%, Valid: 65.02% Test: 66.01%\n",
      "Run: 09, Epoch: 77, Loss: 0.4711, Train: 85.90%, Valid: 66.67% Test: 67.98%\n",
      "Run: 09, Epoch: 78, Loss: 0.4632, Train: 85.26%, Valid: 66.94% Test: 66.01%\n",
      "Run: 09, Epoch: 79, Loss: 0.4714, Train: 85.99%, Valid: 67.08% Test: 65.79%\n",
      "Run: 09, Epoch: 80, Loss: 0.4295, Train: 85.35%, Valid: 65.57% Test: 65.79%\n",
      "Run: 09, Epoch: 81, Loss: 0.4540, Train: 85.53%, Valid: 64.61% Test: 64.91%\n",
      "Run: 09, Epoch: 82, Loss: 0.4475, Train: 86.45%, Valid: 64.47% Test: 64.47%\n",
      "Run: 09, Epoch: 83, Loss: 0.4535, Train: 87.64%, Valid: 65.02% Test: 66.01%\n",
      "Run: 09, Epoch: 84, Loss: 0.4307, Train: 87.73%, Valid: 66.12% Test: 67.11%\n",
      "Run: 09, Epoch: 85, Loss: 0.4349, Train: 87.55%, Valid: 66.12% Test: 66.45%\n",
      "Run: 09, Epoch: 86, Loss: 0.4339, Train: 86.90%, Valid: 65.84% Test: 65.57%\n",
      "Run: 09, Epoch: 87, Loss: 0.4211, Train: 86.81%, Valid: 66.80% Test: 65.35%\n",
      "Run: 09, Epoch: 88, Loss: 0.4343, Train: 86.54%, Valid: 65.98% Test: 66.89%\n",
      "Run: 09, Epoch: 89, Loss: 0.4164, Train: 85.99%, Valid: 64.06% Test: 64.47%\n",
      "Run: 09, Epoch: 90, Loss: 0.4377, Train: 87.00%, Valid: 66.26% Test: 65.35%\n",
      "Run: 09, Epoch: 91, Loss: 0.4005, Train: 86.54%, Valid: 65.98% Test: 64.69%\n",
      "Run: 09, Epoch: 92, Loss: 0.4432, Train: 86.90%, Valid: 65.98% Test: 65.13%\n",
      "Run: 09, Epoch: 93, Loss: 0.4255, Train: 86.81%, Valid: 63.24% Test: 64.91%\n",
      "Run: 09, Epoch: 94, Loss: 0.4503, Train: 87.91%, Valid: 64.47% Test: 66.01%\n",
      "Run: 09, Epoch: 95, Loss: 0.4260, Train: 87.00%, Valid: 66.94% Test: 66.01%\n",
      "Run: 09, Epoch: 96, Loss: 0.4063, Train: 87.27%, Valid: 67.08% Test: 66.89%\n",
      "Run: 09, Epoch: 97, Loss: 0.4228, Train: 88.28%, Valid: 65.71% Test: 67.11%\n",
      "Run: 09, Epoch: 98, Loss: 0.4074, Train: 88.83%, Valid: 65.29% Test: 67.32%\n",
      "Run: 09, Epoch: 99, Loss: 0.4000, Train: 87.18%, Valid: 63.79% Test: 64.91%\n",
      "Run: 09, Epoch: 100, Loss: 0.4146, Train: 88.46%, Valid: 65.84% Test: 66.01%\n",
      "Run 09:\n",
      "Highest Train: 88.83\n",
      "Highest Valid: 67.35\n",
      "  Final Train: 86.26\n",
      "   Final Test: 67.11\n",
      "Run: 10, Epoch: 01, Loss: 1.8172, Train: 26.10%, Valid: 29.08% Test: 29.61%\n",
      "Run: 10, Epoch: 02, Loss: 1.4040, Train: 31.32%, Valid: 31.55% Test: 33.11%\n",
      "Run: 10, Epoch: 03, Loss: 1.3281, Train: 34.98%, Valid: 33.33% Test: 36.40%\n",
      "Run: 10, Epoch: 04, Loss: 1.3098, Train: 37.91%, Valid: 35.53% Test: 37.94%\n",
      "Run: 10, Epoch: 05, Loss: 1.2579, Train: 40.57%, Valid: 36.63% Test: 39.69%\n",
      "Run: 10, Epoch: 06, Loss: 1.2412, Train: 45.33%, Valid: 40.33% Test: 43.64%\n",
      "Run: 10, Epoch: 07, Loss: 1.2101, Train: 48.17%, Valid: 42.94% Test: 46.71%\n",
      "Run: 10, Epoch: 08, Loss: 1.1903, Train: 48.99%, Valid: 44.72% Test: 47.81%\n",
      "Run: 10, Epoch: 09, Loss: 1.1661, Train: 51.19%, Valid: 46.91% Test: 50.00%\n",
      "Run: 10, Epoch: 10, Loss: 1.1611, Train: 54.12%, Valid: 48.42% Test: 51.54%\n",
      "Run: 10, Epoch: 11, Loss: 1.1384, Train: 56.68%, Valid: 50.89% Test: 51.54%\n",
      "Run: 10, Epoch: 12, Loss: 1.1262, Train: 57.88%, Valid: 50.75% Test: 53.51%\n",
      "Run: 10, Epoch: 13, Loss: 1.1008, Train: 58.52%, Valid: 51.58% Test: 53.29%\n",
      "Run: 10, Epoch: 14, Loss: 1.0836, Train: 59.07%, Valid: 51.58% Test: 53.29%\n",
      "Run: 10, Epoch: 15, Loss: 1.0739, Train: 59.71%, Valid: 51.58% Test: 54.17%\n",
      "Run: 10, Epoch: 16, Loss: 1.0575, Train: 59.62%, Valid: 51.99% Test: 54.82%\n",
      "Run: 10, Epoch: 17, Loss: 1.0338, Train: 60.44%, Valid: 52.67% Test: 55.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 18, Loss: 1.0155, Train: 61.26%, Valid: 52.67% Test: 56.14%\n",
      "Run: 10, Epoch: 19, Loss: 1.0136, Train: 62.82%, Valid: 53.77% Test: 56.36%\n",
      "Run: 10, Epoch: 20, Loss: 0.9869, Train: 64.29%, Valid: 55.42% Test: 57.46%\n",
      "Run: 10, Epoch: 21, Loss: 0.9783, Train: 65.11%, Valid: 55.69% Test: 56.80%\n",
      "Run: 10, Epoch: 22, Loss: 0.9591, Train: 65.66%, Valid: 56.10% Test: 57.24%\n",
      "Run: 10, Epoch: 23, Loss: 0.9451, Train: 67.12%, Valid: 56.24% Test: 57.68%\n",
      "Run: 10, Epoch: 24, Loss: 0.9207, Train: 67.22%, Valid: 56.52% Test: 58.55%\n",
      "Run: 10, Epoch: 25, Loss: 0.8996, Train: 67.12%, Valid: 57.20% Test: 58.11%\n",
      "Run: 10, Epoch: 26, Loss: 0.9061, Train: 67.95%, Valid: 58.57% Test: 57.46%\n",
      "Run: 10, Epoch: 27, Loss: 0.8801, Train: 69.05%, Valid: 59.12% Test: 57.68%\n",
      "Run: 10, Epoch: 28, Loss: 0.8753, Train: 69.14%, Valid: 58.30% Test: 58.77%\n",
      "Run: 10, Epoch: 29, Loss: 0.8424, Train: 69.14%, Valid: 57.89% Test: 58.99%\n",
      "Run: 10, Epoch: 30, Loss: 0.8400, Train: 70.97%, Valid: 59.81% Test: 61.40%\n",
      "Run: 10, Epoch: 31, Loss: 0.8172, Train: 72.44%, Valid: 60.63% Test: 62.28%\n",
      "Run: 10, Epoch: 32, Loss: 0.8119, Train: 73.44%, Valid: 61.04% Test: 61.84%\n",
      "Run: 10, Epoch: 33, Loss: 0.8180, Train: 73.53%, Valid: 60.91% Test: 61.84%\n",
      "Run: 10, Epoch: 34, Loss: 0.7785, Train: 73.53%, Valid: 60.77% Test: 61.84%\n",
      "Run: 10, Epoch: 35, Loss: 0.7675, Train: 74.18%, Valid: 60.63% Test: 62.72%\n",
      "Run: 10, Epoch: 36, Loss: 0.7715, Train: 74.45%, Valid: 61.18% Test: 62.06%\n",
      "Run: 10, Epoch: 37, Loss: 0.7436, Train: 76.10%, Valid: 61.87% Test: 62.06%\n",
      "Run: 10, Epoch: 38, Loss: 0.7178, Train: 77.66%, Valid: 62.69% Test: 62.06%\n",
      "Run: 10, Epoch: 39, Loss: 0.7368, Train: 78.02%, Valid: 62.55% Test: 63.82%\n",
      "Run: 10, Epoch: 40, Loss: 0.7240, Train: 77.38%, Valid: 61.45% Test: 62.94%\n",
      "Run: 10, Epoch: 41, Loss: 0.6937, Train: 78.30%, Valid: 61.45% Test: 63.16%\n",
      "Run: 10, Epoch: 42, Loss: 0.6868, Train: 78.30%, Valid: 61.73% Test: 63.38%\n",
      "Run: 10, Epoch: 43, Loss: 0.6672, Train: 77.93%, Valid: 60.91% Test: 62.50%\n",
      "Run: 10, Epoch: 44, Loss: 0.6642, Train: 79.03%, Valid: 62.28% Test: 63.82%\n",
      "Run: 10, Epoch: 45, Loss: 0.6447, Train: 79.67%, Valid: 61.87% Test: 64.47%\n",
      "Run: 10, Epoch: 46, Loss: 0.6383, Train: 80.77%, Valid: 61.87% Test: 64.25%\n",
      "Run: 10, Epoch: 47, Loss: 0.6422, Train: 81.14%, Valid: 62.96% Test: 64.91%\n",
      "Run: 10, Epoch: 48, Loss: 0.6119, Train: 81.14%, Valid: 62.41% Test: 64.04%\n",
      "Run: 10, Epoch: 49, Loss: 0.6177, Train: 82.42%, Valid: 62.96% Test: 65.13%\n",
      "Run: 10, Epoch: 50, Loss: 0.6008, Train: 82.14%, Valid: 62.55% Test: 66.01%\n",
      "Run: 10, Epoch: 51, Loss: 0.5941, Train: 83.15%, Valid: 63.24% Test: 66.01%\n",
      "Run: 10, Epoch: 52, Loss: 0.5728, Train: 83.33%, Valid: 64.75% Test: 67.11%\n",
      "Run: 10, Epoch: 53, Loss: 0.5869, Train: 82.69%, Valid: 62.96% Test: 65.13%\n",
      "Run: 10, Epoch: 54, Loss: 0.5577, Train: 83.06%, Valid: 63.65% Test: 66.45%\n",
      "Run: 10, Epoch: 55, Loss: 0.5634, Train: 82.69%, Valid: 62.83% Test: 65.57%\n",
      "Run: 10, Epoch: 56, Loss: 0.5528, Train: 82.88%, Valid: 63.24% Test: 66.01%\n",
      "Run: 10, Epoch: 57, Loss: 0.5466, Train: 83.52%, Valid: 62.55% Test: 65.35%\n",
      "Run: 10, Epoch: 58, Loss: 0.5386, Train: 83.52%, Valid: 61.59% Test: 65.35%\n",
      "Run: 10, Epoch: 59, Loss: 0.5116, Train: 83.79%, Valid: 62.14% Test: 65.35%\n",
      "Run: 10, Epoch: 60, Loss: 0.5288, Train: 83.70%, Valid: 61.87% Test: 66.23%\n",
      "Run: 10, Epoch: 61, Loss: 0.5234, Train: 82.97%, Valid: 61.87% Test: 66.01%\n",
      "Run: 10, Epoch: 62, Loss: 0.5152, Train: 84.34%, Valid: 63.10% Test: 65.79%\n",
      "Run: 10, Epoch: 63, Loss: 0.4989, Train: 84.07%, Valid: 63.51% Test: 64.91%\n",
      "Run: 10, Epoch: 64, Loss: 0.4878, Train: 84.71%, Valid: 64.61% Test: 67.98%\n",
      "Run: 10, Epoch: 65, Loss: 0.4843, Train: 84.43%, Valid: 63.79% Test: 67.11%\n",
      "Run: 10, Epoch: 66, Loss: 0.4857, Train: 85.16%, Valid: 63.92% Test: 68.20%\n",
      "Run: 10, Epoch: 67, Loss: 0.4700, Train: 86.63%, Valid: 65.29% Test: 67.11%\n",
      "Run: 10, Epoch: 68, Loss: 0.4575, Train: 85.99%, Valid: 64.47% Test: 65.35%\n",
      "Run: 10, Epoch: 69, Loss: 0.4547, Train: 85.81%, Valid: 63.51% Test: 67.54%\n",
      "Run: 10, Epoch: 70, Loss: 0.4466, Train: 84.89%, Valid: 64.61% Test: 68.86%\n",
      "Run: 10, Epoch: 71, Loss: 0.4474, Train: 85.99%, Valid: 64.20% Test: 68.64%\n",
      "Run: 10, Epoch: 72, Loss: 0.4436, Train: 85.90%, Valid: 64.20% Test: 67.98%\n",
      "Run: 10, Epoch: 73, Loss: 0.4347, Train: 86.54%, Valid: 64.06% Test: 66.67%\n",
      "Run: 10, Epoch: 74, Loss: 0.4539, Train: 85.62%, Valid: 62.55% Test: 65.79%\n",
      "Run: 10, Epoch: 75, Loss: 0.4329, Train: 86.17%, Valid: 64.33% Test: 66.23%\n",
      "Run: 10, Epoch: 76, Loss: 0.4418, Train: 85.90%, Valid: 65.43% Test: 67.98%\n",
      "Run: 10, Epoch: 77, Loss: 0.4209, Train: 87.36%, Valid: 64.61% Test: 66.67%\n",
      "Run: 10, Epoch: 78, Loss: 0.4150, Train: 87.00%, Valid: 65.57% Test: 66.45%\n",
      "Run: 10, Epoch: 79, Loss: 0.4161, Train: 88.10%, Valid: 65.71% Test: 68.64%\n",
      "Run: 10, Epoch: 80, Loss: 0.4088, Train: 87.18%, Valid: 65.29% Test: 69.52%\n",
      "Run: 10, Epoch: 81, Loss: 0.4017, Train: 88.64%, Valid: 65.43% Test: 69.08%\n",
      "Run: 10, Epoch: 82, Loss: 0.3865, Train: 87.18%, Valid: 63.92% Test: 67.76%\n",
      "Run: 10, Epoch: 83, Loss: 0.3998, Train: 87.82%, Valid: 64.75% Test: 69.96%\n",
      "Run: 10, Epoch: 84, Loss: 0.4039, Train: 86.81%, Valid: 62.96% Test: 68.64%\n",
      "Run: 10, Epoch: 85, Loss: 0.3992, Train: 86.90%, Valid: 62.69% Test: 67.54%\n",
      "Run: 10, Epoch: 86, Loss: 0.3920, Train: 85.44%, Valid: 62.14% Test: 65.57%\n",
      "Run: 10, Epoch: 87, Loss: 0.3892, Train: 87.18%, Valid: 63.79% Test: 66.23%\n",
      "Run: 10, Epoch: 88, Loss: 0.3791, Train: 88.10%, Valid: 65.29% Test: 68.64%\n",
      "Run: 10, Epoch: 89, Loss: 0.3955, Train: 86.63%, Valid: 64.75% Test: 69.08%\n",
      "Run: 10, Epoch: 90, Loss: 0.3858, Train: 86.45%, Valid: 65.02% Test: 70.18%\n",
      "Run: 10, Epoch: 91, Loss: 0.3754, Train: 88.28%, Valid: 64.47% Test: 69.52%\n",
      "Run: 10, Epoch: 92, Loss: 0.3868, Train: 88.55%, Valid: 66.26% Test: 68.42%\n",
      "Run: 10, Epoch: 93, Loss: 0.3647, Train: 89.74%, Valid: 66.26% Test: 69.52%\n",
      "Run: 10, Epoch: 94, Loss: 0.3682, Train: 89.10%, Valid: 65.43% Test: 69.74%\n",
      "Run: 10, Epoch: 95, Loss: 0.3670, Train: 88.28%, Valid: 63.92% Test: 68.86%\n",
      "Run: 10, Epoch: 96, Loss: 0.3764, Train: 88.19%, Valid: 65.16% Test: 68.86%\n",
      "Run: 10, Epoch: 97, Loss: 0.3780, Train: 89.19%, Valid: 65.57% Test: 69.08%\n",
      "Run: 10, Epoch: 98, Loss: 0.3495, Train: 88.92%, Valid: 63.65% Test: 68.20%\n",
      "Run: 10, Epoch: 99, Loss: 0.3471, Train: 88.19%, Valid: 64.20% Test: 68.64%\n",
      "Run: 10, Epoch: 100, Loss: 0.3569, Train: 90.20%, Valid: 65.57% Test: 68.20%\n",
      "Run 10:\n",
      "Highest Train: 90.20\n",
      "Highest Valid: 66.26\n",
      "  Final Train: 88.55\n",
      "   Final Test: 68.42\n",
      "All runs:\n",
      "Highest Train: 89.57 ± 1.20\n",
      "Highest Valid: 67.02 ± 1.65\n",
      "  Final Train: 88.16 ± 1.79\n",
      "   Final Test: 65.55 ± 2.13\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 48, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-5, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    dataset = WikipediaNetwork(root='/tmp/chameleon', name='chameleon',transform=T.ToSparseTensor())\n",
    "    data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    #idx_train=[data.train_mask[i][0] for i in range(len(data.y))]\n",
    "    #train_idx = np.where(idx_train)[0]\n",
    "    #idx_val=[data.val_mask[i][0] for i in range(len(data.y))]\n",
    "    #valid_idx = np.where(idx_val)[0]\n",
    "    #idx_test=[data.test_mask[i][0] for i in range(len(data.y))]\n",
    "    #test_idx = np.where(idx_test)[0]\n",
    "    \n",
    "    model = GCN(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52f151",
   "metadata": {},
   "source": [
    "# Wise Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a09514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2277, 2325], y=[2277], train_mask=[2277, 10], val_mask=[2277, 10], test_mask=[2277, 10], adj_t=[2277, 2277, nnz=36101])\n"
     ]
    }
   ],
   "source": [
    "dataset = WikipediaNetwork(root='/tmp/chameleon', name='chameleon',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f82a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2316</th>\n",
       "      <th>2317</th>\n",
       "      <th>2318</th>\n",
       "      <th>2319</th>\n",
       "      <th>2320</th>\n",
       "      <th>2321</th>\n",
       "      <th>2322</th>\n",
       "      <th>2323</th>\n",
       "      <th>2324</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  2316  2317  2318  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "   2319  2320  2321  2322  2323  2324  class  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0      0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "3   0.0   0.0   0.0   0.0   1.0   0.0      4  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0      2  \n",
       "\n",
       "[5 rows x 2326 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Domain_Fec=pd.DataFrame(data.x.numpy())\n",
    "label=pd.DataFrame(data.y.numpy(),columns =['class'])\n",
    "Data=pd.concat([Domain_Fec,label], axis=1)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2642b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_nodes=len(data.y)\n",
    "fe_len=len(data.x[0])\n",
    "catagories=Data['class'].to_numpy()\n",
    "data_by_class = {cls: Data.loc[Data['class'] == cls].drop(['class'], axis=1) for cls in range(max(catagories) + 1)}\n",
    "basis = [[max(df[i]) for i in range(len(df.columns))] for df in data_by_class.values()]\n",
    "sel_basis = [[int(list(df[i].to_numpy()).count(1) >= int(len(df[i].index)*0.01)) \n",
    "              for i in range(len(df.columns))]\n",
    "             for df in data_by_class.values()]\n",
    "feature_names = [ii for ii in range(fe_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b62d735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity(array1, array2):\n",
    "    intersection = np.sum(np.logical_and(array1, array2))\n",
    "    #union = np.sum(np.logical_or(array1, array2))\n",
    "    #jaccard_similarity = intersection / union\n",
    "    \n",
    "    #return jaccard_similarity\n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12133154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0, 3.0, 3.0, 2.0, 3.0], [6.0, 5.0, 8.0, 10.0, 9.0], [9.0, 13.0, 22.0, 23.0, 21.0], [7.0, 10.0, 11.0, 14.0, 14.0], [16.0, 23.0, 41.0, 37.0, 37.0], [3.0, 2.0, 3.0, 3.0, 3.0], [1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0], [4.0, 5.0, 6.0, 6.0, 6.0], [1.0, 3.0, 3.0, 3.0, 3.0], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 2.0, 2.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [5.0, 8.0, 11.0, 11.0, 20.0], [10.0, 10.0, 13.0, 14.0, 16.0], [10.0, 10.0, 14.0, 16.0, 20.0], [1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0], [2.0, 2.0, 4.0, 14.0, 4.0], [1.0, 1.0, 0.0, 1.0, 1.0], [2.0, 2.0, 3.0, 3.0, 3.0]]\n"
     ]
    }
   ],
   "source": [
    "#It takes long time\n",
    "Fec=[]\n",
    "for i in range(23):\n",
    "    vec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=np.zeros(7)\n",
    "    for j in range(1433):\n",
    "        for i in range(max(catagories)+1):\n",
    "            if f[j]==1 and basis[i][j]==1:\n",
    "                count[i]=count[i]+1;\n",
    "\n",
    "    for i in range(max(catagories)+1):\n",
    "        vec.append(count[i])\n",
    "    f.clear()\n",
    "    Fec.append(vec)\n",
    "print(Fec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4db5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Fec=[]\n",
    "for i in range(Number_nodes):\n",
    "#for i in range(2):\n",
    "    vec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    vec.append(Similarity(f,basis[0]))\n",
    "    vec.append(Similarity(f,basis[1]))\n",
    "    vec.append(Similarity(f,basis[2]))\n",
    "    vec.append(Similarity(f,basis[3]))\n",
    "    vec.append(Similarity(f,basis[4]))\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    Fec.append(vec)\n",
    "SFec=[]\n",
    "for i in range(Number_nodes):\n",
    "#for i in range(2):\n",
    "    Svec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    Svec.append(Similarity(f,sel_basis[0]))\n",
    "    Svec.append(Similarity(f,sel_basis[1]))\n",
    "    Svec.append(Similarity(f,sel_basis[2]))\n",
    "    Svec.append(Similarity(f,sel_basis[3]))\n",
    "    Svec.append(Similarity(f,sel_basis[4]))\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    SFec.append(Svec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084212fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Fec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SFec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "054ee569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.,  6.,  6.,  ...,  5.,  5.,  7.],\n",
      "        [10., 12., 18.,  ...,  8., 16., 15.],\n",
      "        [19., 24., 39.,  ..., 19., 33., 28.],\n",
      "        ...,\n",
      "        [ 3.,  2.,  1.,  ...,  0.,  2.,  2.],\n",
      "        [16., 20., 32.,  ..., 17., 22., 38.],\n",
      "        [ 4.,  4.,  3.,  ...,  2.,  1.,  2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inc_fe=torch.tensor(Fec)\n",
    "sel_fe=torch.tensor(SFec)\n",
    "CC_domain=torch.cat((Inc_fe, sel_fe), 1).float()\n",
    "print(CC_domain)\n",
    "CC_domain.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f7d51",
   "metadata": {},
   "source": [
    "# W-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c6fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2277, 10], y=[2277], train_mask=[2277, 10], val_mask=[2277, 10], test_mask=[2277, 10], adj_t=[2277, 2277, nnz=36101])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4763ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x1572d1630>\n",
      "Run: 01, Epoch: 01, Loss: 2.0673, Train: 17.22%, Valid: 15.50% Test: 19.08%\n",
      "Run: 01, Epoch: 02, Loss: 1.4177, Train: 31.68%, Valid: 30.59% Test: 31.36%\n",
      "Run: 01, Epoch: 03, Loss: 1.4314, Train: 22.62%, Valid: 20.44% Test: 23.90%\n",
      "Run: 01, Epoch: 04, Loss: 1.4224, Train: 36.81%, Valid: 34.29% Test: 35.53%\n",
      "Run: 01, Epoch: 05, Loss: 1.4006, Train: 31.23%, Valid: 34.84% Test: 32.68%\n",
      "Run: 01, Epoch: 06, Loss: 1.3768, Train: 36.08%, Valid: 39.51% Test: 39.04%\n",
      "Run: 01, Epoch: 07, Loss: 1.3191, Train: 36.72%, Valid: 39.23% Test: 35.53%\n",
      "Run: 01, Epoch: 08, Loss: 1.3918, Train: 39.93%, Valid: 40.88% Test: 39.47%\n",
      "Run: 01, Epoch: 09, Loss: 1.2741, Train: 35.62%, Valid: 32.65% Test: 35.53%\n",
      "Run: 01, Epoch: 10, Loss: 1.3451, Train: 38.46%, Valid: 34.43% Test: 36.62%\n",
      "Run: 01, Epoch: 11, Loss: 1.3006, Train: 36.26%, Valid: 36.08% Test: 36.62%\n",
      "Run: 01, Epoch: 12, Loss: 1.2950, Train: 34.71%, Valid: 34.29% Test: 34.43%\n",
      "Run: 01, Epoch: 13, Loss: 1.3490, Train: 43.68%, Valid: 43.48% Test: 41.89%\n",
      "Run: 01, Epoch: 14, Loss: 1.2711, Train: 39.10%, Valid: 35.39% Test: 37.72%\n",
      "Run: 01, Epoch: 15, Loss: 1.3065, Train: 42.77%, Valid: 42.80% Test: 41.67%\n",
      "Run: 01, Epoch: 16, Loss: 1.2470, Train: 39.65%, Valid: 40.19% Test: 38.82%\n",
      "Run: 01, Epoch: 17, Loss: 1.2856, Train: 44.60%, Valid: 45.40% Test: 42.76%\n",
      "Run: 01, Epoch: 18, Loss: 1.2327, Train: 50.18%, Valid: 47.46% Test: 47.81%\n",
      "Run: 01, Epoch: 19, Loss: 1.2249, Train: 44.32%, Valid: 44.99% Test: 43.64%\n",
      "Run: 01, Epoch: 20, Loss: 1.2146, Train: 43.50%, Valid: 43.76% Test: 42.54%\n",
      "Run: 01, Epoch: 21, Loss: 1.2161, Train: 48.35%, Valid: 46.64% Test: 45.18%\n",
      "Run: 01, Epoch: 22, Loss: 1.2351, Train: 53.39%, Valid: 52.40% Test: 51.32%\n",
      "Run: 01, Epoch: 23, Loss: 1.2217, Train: 50.64%, Valid: 50.34% Test: 51.97%\n",
      "Run: 01, Epoch: 24, Loss: 1.2081, Train: 43.59%, Valid: 44.03% Test: 42.54%\n",
      "Run: 01, Epoch: 25, Loss: 1.2070, Train: 45.42%, Valid: 45.13% Test: 43.42%\n",
      "Run: 01, Epoch: 26, Loss: 1.1929, Train: 47.44%, Valid: 46.64% Test: 44.96%\n",
      "Run: 01, Epoch: 27, Loss: 1.1775, Train: 49.45%, Valid: 47.05% Test: 47.59%\n",
      "Run: 01, Epoch: 28, Loss: 1.1769, Train: 49.08%, Valid: 49.79% Test: 47.15%\n",
      "Run: 01, Epoch: 29, Loss: 1.1730, Train: 42.22%, Valid: 45.13% Test: 41.89%\n",
      "Run: 01, Epoch: 30, Loss: 1.1662, Train: 48.44%, Valid: 47.05% Test: 47.81%\n",
      "Run: 01, Epoch: 31, Loss: 1.1821, Train: 51.01%, Valid: 51.30% Test: 50.88%\n",
      "Run: 01, Epoch: 32, Loss: 1.1805, Train: 50.55%, Valid: 52.13% Test: 51.10%\n",
      "Run: 01, Epoch: 33, Loss: 1.1843, Train: 54.67%, Valid: 51.85% Test: 53.73%\n",
      "Run: 01, Epoch: 34, Loss: 1.1841, Train: 54.03%, Valid: 53.22% Test: 54.39%\n",
      "Run: 01, Epoch: 35, Loss: 1.1812, Train: 53.57%, Valid: 54.18% Test: 53.29%\n",
      "Run: 01, Epoch: 36, Loss: 1.1396, Train: 48.99%, Valid: 52.81% Test: 49.34%\n",
      "Run: 01, Epoch: 37, Loss: 1.1431, Train: 55.04%, Valid: 55.56% Test: 56.14%\n",
      "Run: 01, Epoch: 38, Loss: 1.1608, Train: 55.77%, Valid: 56.38% Test: 55.92%\n",
      "Run: 01, Epoch: 39, Loss: 1.1487, Train: 56.68%, Valid: 57.61% Test: 54.39%\n",
      "Run: 01, Epoch: 40, Loss: 1.1336, Train: 54.85%, Valid: 51.44% Test: 56.14%\n",
      "Run: 01, Epoch: 41, Loss: 1.1449, Train: 52.01%, Valid: 50.89% Test: 50.66%\n",
      "Run: 01, Epoch: 42, Loss: 1.1509, Train: 53.02%, Valid: 51.85% Test: 51.75%\n",
      "Run: 01, Epoch: 43, Loss: 1.1353, Train: 60.07%, Valid: 56.10% Test: 58.11%\n",
      "Run: 01, Epoch: 44, Loss: 1.1473, Train: 56.04%, Valid: 53.09% Test: 55.26%\n",
      "Run: 01, Epoch: 45, Loss: 1.1170, Train: 57.97%, Valid: 56.93% Test: 56.58%\n",
      "Run: 01, Epoch: 46, Loss: 1.1128, Train: 60.44%, Valid: 59.67% Test: 58.33%\n",
      "Run: 01, Epoch: 47, Loss: 1.1453, Train: 55.49%, Valid: 51.71% Test: 55.48%\n",
      "Run: 01, Epoch: 48, Loss: 1.1296, Train: 58.15%, Valid: 57.48% Test: 60.53%\n",
      "Run: 01, Epoch: 49, Loss: 1.1099, Train: 59.43%, Valid: 57.20% Test: 61.62%\n",
      "Run: 01, Epoch: 50, Loss: 1.1347, Train: 59.71%, Valid: 57.34% Test: 61.62%\n",
      "Run: 01, Epoch: 51, Loss: 1.1152, Train: 55.77%, Valid: 55.69% Test: 55.70%\n",
      "Run: 01, Epoch: 52, Loss: 1.1016, Train: 53.30%, Valid: 53.36% Test: 50.88%\n",
      "Run: 01, Epoch: 53, Loss: 1.1250, Train: 57.78%, Valid: 56.10% Test: 57.68%\n",
      "Run: 01, Epoch: 54, Loss: 1.0981, Train: 60.53%, Valid: 58.57% Test: 59.87%\n",
      "Run: 01, Epoch: 55, Loss: 1.0929, Train: 54.49%, Valid: 50.62% Test: 54.17%\n",
      "Run: 01, Epoch: 56, Loss: 1.1319, Train: 55.59%, Valid: 55.28% Test: 55.04%\n",
      "Run: 01, Epoch: 57, Loss: 1.1462, Train: 58.88%, Valid: 58.02% Test: 54.39%\n",
      "Run: 01, Epoch: 58, Loss: 1.1106, Train: 55.22%, Valid: 51.71% Test: 54.61%\n",
      "Run: 01, Epoch: 59, Loss: 1.1021, Train: 54.49%, Valid: 53.22% Test: 54.61%\n",
      "Run: 01, Epoch: 60, Loss: 1.1211, Train: 53.66%, Valid: 53.64% Test: 53.51%\n",
      "Run: 01, Epoch: 61, Loss: 1.0730, Train: 51.10%, Valid: 51.03% Test: 50.22%\n",
      "Run: 01, Epoch: 62, Loss: 1.1014, Train: 53.57%, Valid: 51.99% Test: 52.85%\n",
      "Run: 01, Epoch: 63, Loss: 1.1400, Train: 58.79%, Valid: 56.65% Test: 55.92%\n",
      "Run: 01, Epoch: 64, Loss: 1.1326, Train: 61.08%, Valid: 59.81% Test: 59.43%\n",
      "Run: 01, Epoch: 65, Loss: 1.1253, Train: 56.78%, Valid: 56.65% Test: 56.58%\n",
      "Run: 01, Epoch: 66, Loss: 1.0993, Train: 58.61%, Valid: 55.42% Test: 56.58%\n",
      "Run: 01, Epoch: 67, Loss: 1.1564, Train: 50.92%, Valid: 53.91% Test: 50.00%\n",
      "Run: 01, Epoch: 68, Loss: 1.0968, Train: 54.49%, Valid: 55.83% Test: 51.10%\n",
      "Run: 01, Epoch: 69, Loss: 1.0919, Train: 53.85%, Valid: 51.30% Test: 54.39%\n",
      "Run: 01, Epoch: 70, Loss: 1.1245, Train: 57.69%, Valid: 55.56% Test: 57.02%\n",
      "Run: 01, Epoch: 71, Loss: 1.0944, Train: 61.90%, Valid: 59.53% Test: 60.09%\n",
      "Run: 01, Epoch: 72, Loss: 1.0909, Train: 62.91%, Valid: 60.63% Test: 60.75%\n",
      "Run: 01, Epoch: 73, Loss: 1.1153, Train: 49.63%, Valid: 49.38% Test: 47.81%\n",
      "Run: 01, Epoch: 74, Loss: 1.0941, Train: 48.44%, Valid: 50.07% Test: 47.81%\n",
      "Run: 01, Epoch: 75, Loss: 1.0831, Train: 60.62%, Valid: 57.75% Test: 57.02%\n",
      "Run: 01, Epoch: 76, Loss: 1.0689, Train: 60.16%, Valid: 56.52% Test: 57.46%\n",
      "Run: 01, Epoch: 77, Loss: 1.1078, Train: 50.64%, Valid: 52.81% Test: 48.46%\n",
      "Run: 01, Epoch: 78, Loss: 1.1228, Train: 55.13%, Valid: 56.52% Test: 53.73%\n",
      "Run: 01, Epoch: 79, Loss: 1.1142, Train: 57.05%, Valid: 55.56% Test: 56.14%\n",
      "Run: 01, Epoch: 80, Loss: 1.0884, Train: 60.35%, Valid: 57.61% Test: 57.89%\n",
      "Run: 01, Epoch: 81, Loss: 1.0694, Train: 57.23%, Valid: 55.28% Test: 55.92%\n",
      "Run: 01, Epoch: 82, Loss: 1.1112, Train: 58.52%, Valid: 58.71% Test: 57.24%\n",
      "Run: 01, Epoch: 83, Loss: 1.0824, Train: 56.87%, Valid: 57.89% Test: 55.70%\n",
      "Run: 01, Epoch: 84, Loss: 1.1000, Train: 54.21%, Valid: 55.14% Test: 53.51%\n",
      "Run: 01, Epoch: 85, Loss: 1.0918, Train: 53.57%, Valid: 53.22% Test: 50.66%\n",
      "Run: 01, Epoch: 86, Loss: 1.0933, Train: 57.05%, Valid: 58.02% Test: 58.33%\n",
      "Run: 01, Epoch: 87, Loss: 1.0756, Train: 60.26%, Valid: 60.36% Test: 60.53%\n",
      "Run: 01, Epoch: 88, Loss: 1.1015, Train: 60.07%, Valid: 59.40% Test: 60.75%\n",
      "Run: 01, Epoch: 89, Loss: 1.0708, Train: 59.71%, Valid: 59.67% Test: 58.55%\n",
      "Run: 01, Epoch: 90, Loss: 1.0908, Train: 60.99%, Valid: 60.77% Test: 57.68%\n",
      "Run: 01, Epoch: 91, Loss: 1.0814, Train: 59.62%, Valid: 59.26% Test: 56.80%\n",
      "Run: 01, Epoch: 92, Loss: 1.0850, Train: 57.97%, Valid: 57.34% Test: 54.61%\n",
      "Run: 01, Epoch: 93, Loss: 1.0864, Train: 58.33%, Valid: 57.34% Test: 55.48%\n",
      "Run: 01, Epoch: 94, Loss: 1.0651, Train: 60.16%, Valid: 58.71% Test: 59.65%\n",
      "Run: 01, Epoch: 95, Loss: 1.0858, Train: 55.40%, Valid: 57.34% Test: 55.26%\n",
      "Run: 01, Epoch: 96, Loss: 1.0781, Train: 55.68%, Valid: 56.93% Test: 55.04%\n",
      "Run: 01, Epoch: 97, Loss: 1.1070, Train: 57.33%, Valid: 52.67% Test: 54.39%\n",
      "Run: 01, Epoch: 98, Loss: 1.0902, Train: 58.33%, Valid: 56.52% Test: 57.89%\n",
      "Run: 01, Epoch: 99, Loss: 1.0895, Train: 57.51%, Valid: 57.89% Test: 53.73%\n",
      "Run: 01, Epoch: 100, Loss: 1.1112, Train: 62.27%, Valid: 60.49% Test: 58.33%\n",
      "Run: 01, Epoch: 101, Loss: 1.0784, Train: 58.79%, Valid: 54.05% Test: 55.92%\n",
      "Run: 01, Epoch: 102, Loss: 1.1087, Train: 60.62%, Valid: 57.61% Test: 57.89%\n",
      "Run: 01, Epoch: 103, Loss: 1.0509, Train: 59.07%, Valid: 60.63% Test: 56.58%\n",
      "Run: 01, Epoch: 104, Loss: 1.0703, Train: 57.78%, Valid: 57.20% Test: 54.17%\n",
      "Run: 01, Epoch: 105, Loss: 1.0658, Train: 59.16%, Valid: 58.85% Test: 57.89%\n",
      "Run: 01, Epoch: 106, Loss: 1.0765, Train: 55.49%, Valid: 53.77% Test: 55.48%\n",
      "Run: 01, Epoch: 107, Loss: 1.0928, Train: 62.00%, Valid: 60.49% Test: 60.75%\n",
      "Run: 01, Epoch: 108, Loss: 1.0661, Train: 49.18%, Valid: 51.58% Test: 49.56%\n",
      "Run: 01, Epoch: 109, Loss: 1.0947, Train: 52.75%, Valid: 52.54% Test: 54.39%\n",
      "Run: 01, Epoch: 110, Loss: 1.0829, Train: 51.19%, Valid: 47.74% Test: 52.41%\n",
      "Run: 01, Epoch: 111, Loss: 1.1051, Train: 52.01%, Valid: 48.42% Test: 53.29%\n",
      "Run: 01, Epoch: 112, Loss: 1.0817, Train: 52.93%, Valid: 53.50% Test: 52.63%\n",
      "Run: 01, Epoch: 113, Loss: 1.0823, Train: 55.59%, Valid: 57.75% Test: 55.26%\n",
      "Run: 01, Epoch: 114, Loss: 1.1058, Train: 53.66%, Valid: 51.03% Test: 51.54%\n",
      "Run: 01, Epoch: 115, Loss: 1.0983, Train: 62.09%, Valid: 59.53% Test: 57.46%\n",
      "Run: 01, Epoch: 116, Loss: 1.0942, Train: 57.05%, Valid: 58.30% Test: 53.73%\n",
      "Run: 01, Epoch: 117, Loss: 1.1087, Train: 58.70%, Valid: 58.30% Test: 54.61%\n",
      "Run: 01, Epoch: 118, Loss: 1.0746, Train: 53.11%, Valid: 50.48% Test: 53.07%\n",
      "Run: 01, Epoch: 119, Loss: 1.1059, Train: 56.68%, Valid: 53.36% Test: 55.04%\n",
      "Run: 01, Epoch: 120, Loss: 1.0875, Train: 54.21%, Valid: 55.42% Test: 53.51%\n",
      "Run: 01, Epoch: 121, Loss: 1.1018, Train: 54.40%, Valid: 55.42% Test: 53.07%\n",
      "Run: 01, Epoch: 122, Loss: 1.0918, Train: 56.59%, Valid: 53.77% Test: 55.92%\n",
      "Run: 01, Epoch: 123, Loss: 1.0863, Train: 55.04%, Valid: 54.60% Test: 56.14%\n",
      "Run: 01, Epoch: 124, Loss: 1.0511, Train: 57.33%, Valid: 57.48% Test: 57.89%\n",
      "Run: 01, Epoch: 125, Loss: 1.0578, Train: 59.25%, Valid: 58.30% Test: 57.46%\n",
      "Run: 01, Epoch: 126, Loss: 1.0427, Train: 59.25%, Valid: 58.16% Test: 57.02%\n",
      "Run: 01, Epoch: 127, Loss: 1.0870, Train: 60.62%, Valid: 59.67% Test: 59.87%\n",
      "Run: 01, Epoch: 128, Loss: 1.0821, Train: 62.55%, Valid: 60.08% Test: 61.62%\n",
      "Run: 01, Epoch: 129, Loss: 1.0383, Train: 61.72%, Valid: 59.53% Test: 59.87%\n",
      "Run: 01, Epoch: 130, Loss: 1.0672, Train: 59.25%, Valid: 57.06% Test: 56.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 131, Loss: 1.0864, Train: 58.97%, Valid: 58.85% Test: 56.80%\n",
      "Run: 01, Epoch: 132, Loss: 1.0654, Train: 57.88%, Valid: 58.02% Test: 57.02%\n",
      "Run: 01, Epoch: 133, Loss: 1.0585, Train: 59.07%, Valid: 57.75% Test: 58.11%\n",
      "Run: 01, Epoch: 134, Loss: 1.0508, Train: 59.89%, Valid: 58.98% Test: 59.65%\n",
      "Run: 01, Epoch: 135, Loss: 1.0651, Train: 60.35%, Valid: 59.67% Test: 57.02%\n",
      "Run: 01, Epoch: 136, Loss: 1.0444, Train: 63.74%, Valid: 61.45% Test: 60.96%\n",
      "Run: 01, Epoch: 137, Loss: 1.0474, Train: 62.27%, Valid: 59.67% Test: 60.09%\n",
      "Run: 01, Epoch: 138, Loss: 1.0728, Train: 62.73%, Valid: 60.22% Test: 62.28%\n",
      "Run: 01, Epoch: 139, Loss: 1.0590, Train: 58.06%, Valid: 58.44% Test: 53.29%\n",
      "Run: 01, Epoch: 140, Loss: 1.0556, Train: 62.36%, Valid: 61.04% Test: 58.77%\n",
      "Run: 01, Epoch: 141, Loss: 1.0642, Train: 62.09%, Valid: 59.12% Test: 60.75%\n",
      "Run: 01, Epoch: 142, Loss: 1.0502, Train: 61.54%, Valid: 58.30% Test: 60.09%\n",
      "Run: 01, Epoch: 143, Loss: 1.0485, Train: 57.14%, Valid: 55.28% Test: 53.51%\n",
      "Run: 01, Epoch: 144, Loss: 1.0364, Train: 58.88%, Valid: 59.26% Test: 56.58%\n",
      "Run: 01, Epoch: 145, Loss: 1.0840, Train: 63.00%, Valid: 59.40% Test: 59.87%\n",
      "Run: 01, Epoch: 146, Loss: 1.0676, Train: 64.01%, Valid: 61.45% Test: 60.75%\n",
      "Run: 01, Epoch: 147, Loss: 1.0748, Train: 61.81%, Valid: 59.26% Test: 59.43%\n",
      "Run: 01, Epoch: 148, Loss: 1.0336, Train: 61.45%, Valid: 60.91% Test: 56.36%\n",
      "Run: 01, Epoch: 149, Loss: 1.0671, Train: 60.26%, Valid: 60.36% Test: 55.70%\n",
      "Run: 01, Epoch: 150, Loss: 1.0266, Train: 62.00%, Valid: 60.08% Test: 61.40%\n",
      "Run: 01, Epoch: 151, Loss: 1.0385, Train: 62.27%, Valid: 59.81% Test: 60.31%\n",
      "Run: 01, Epoch: 152, Loss: 1.0357, Train: 62.55%, Valid: 59.26% Test: 60.31%\n",
      "Run: 01, Epoch: 153, Loss: 1.0548, Train: 62.27%, Valid: 61.04% Test: 59.87%\n",
      "Run: 01, Epoch: 154, Loss: 1.0793, Train: 64.74%, Valid: 63.24% Test: 60.75%\n",
      "Run: 01, Epoch: 155, Loss: 1.0476, Train: 63.55%, Valid: 61.45% Test: 61.18%\n",
      "Run: 01, Epoch: 156, Loss: 1.0352, Train: 63.74%, Valid: 61.32% Test: 60.31%\n",
      "Run: 01, Epoch: 157, Loss: 1.0400, Train: 62.73%, Valid: 61.18% Test: 59.87%\n",
      "Run: 01, Epoch: 158, Loss: 1.0367, Train: 60.53%, Valid: 58.71% Test: 58.11%\n",
      "Run: 01, Epoch: 159, Loss: 1.0671, Train: 62.18%, Valid: 60.63% Test: 62.06%\n",
      "Run: 01, Epoch: 160, Loss: 1.0383, Train: 65.75%, Valid: 63.79% Test: 61.18%\n",
      "Run: 01, Epoch: 161, Loss: 1.0189, Train: 63.28%, Valid: 60.63% Test: 59.43%\n",
      "Run: 01, Epoch: 162, Loss: 1.0190, Train: 64.56%, Valid: 61.45% Test: 60.31%\n",
      "Run: 01, Epoch: 163, Loss: 1.0247, Train: 64.74%, Valid: 62.96% Test: 62.50%\n",
      "Run: 01, Epoch: 164, Loss: 1.0232, Train: 61.72%, Valid: 60.22% Test: 60.31%\n",
      "Run: 01, Epoch: 165, Loss: 1.0288, Train: 61.45%, Valid: 60.36% Test: 59.87%\n",
      "Run: 01, Epoch: 166, Loss: 1.0142, Train: 63.10%, Valid: 61.59% Test: 59.43%\n",
      "Run: 01, Epoch: 167, Loss: 1.0175, Train: 62.91%, Valid: 60.49% Test: 57.89%\n",
      "Run: 01, Epoch: 168, Loss: 1.0341, Train: 59.62%, Valid: 58.30% Test: 55.92%\n",
      "Run: 01, Epoch: 169, Loss: 1.0492, Train: 63.74%, Valid: 62.00% Test: 61.40%\n",
      "Run: 01, Epoch: 170, Loss: 1.0259, Train: 64.84%, Valid: 62.55% Test: 62.28%\n",
      "Run: 01, Epoch: 171, Loss: 1.0219, Train: 64.19%, Valid: 62.41% Test: 60.09%\n",
      "Run: 01, Epoch: 172, Loss: 1.0538, Train: 65.84%, Valid: 64.47% Test: 62.28%\n",
      "Run: 01, Epoch: 173, Loss: 1.0157, Train: 63.46%, Valid: 61.87% Test: 61.62%\n",
      "Run: 01, Epoch: 174, Loss: 1.0321, Train: 61.45%, Valid: 61.18% Test: 58.77%\n",
      "Run: 01, Epoch: 175, Loss: 1.0143, Train: 58.88%, Valid: 59.12% Test: 57.68%\n",
      "Run: 01, Epoch: 176, Loss: 1.0344, Train: 63.46%, Valid: 63.51% Test: 61.18%\n",
      "Run: 01, Epoch: 177, Loss: 1.0190, Train: 63.10%, Valid: 61.73% Test: 62.94%\n",
      "Run: 01, Epoch: 178, Loss: 1.0199, Train: 61.90%, Valid: 61.32% Test: 59.65%\n",
      "Run: 01, Epoch: 179, Loss: 0.9979, Train: 61.63%, Valid: 62.14% Test: 59.43%\n",
      "Run: 01, Epoch: 180, Loss: 1.0232, Train: 62.55%, Valid: 61.59% Test: 60.96%\n",
      "Run: 01, Epoch: 181, Loss: 1.0240, Train: 61.54%, Valid: 59.81% Test: 61.84%\n",
      "Run: 01, Epoch: 182, Loss: 1.0111, Train: 62.18%, Valid: 61.73% Test: 59.87%\n",
      "Run: 01, Epoch: 183, Loss: 1.0161, Train: 62.00%, Valid: 61.59% Test: 61.18%\n",
      "Run: 01, Epoch: 184, Loss: 1.0446, Train: 63.37%, Valid: 62.28% Test: 63.16%\n",
      "Run: 01, Epoch: 185, Loss: 1.0552, Train: 60.16%, Valid: 57.89% Test: 56.80%\n",
      "Run: 01, Epoch: 186, Loss: 1.0357, Train: 58.15%, Valid: 57.48% Test: 55.26%\n",
      "Run: 01, Epoch: 187, Loss: 1.0339, Train: 62.91%, Valid: 60.63% Test: 61.40%\n",
      "Run: 01, Epoch: 188, Loss: 1.0170, Train: 59.71%, Valid: 58.16% Test: 57.89%\n",
      "Run: 01, Epoch: 189, Loss: 1.0466, Train: 63.00%, Valid: 62.28% Test: 59.43%\n",
      "Run: 01, Epoch: 190, Loss: 1.0399, Train: 60.07%, Valid: 60.49% Test: 58.55%\n",
      "Run: 01, Epoch: 191, Loss: 1.0460, Train: 62.55%, Valid: 60.77% Test: 61.40%\n",
      "Run: 01, Epoch: 192, Loss: 1.0129, Train: 60.53%, Valid: 56.38% Test: 58.55%\n",
      "Run: 01, Epoch: 193, Loss: 1.0327, Train: 64.10%, Valid: 64.75% Test: 59.65%\n",
      "Run: 01, Epoch: 194, Loss: 1.0204, Train: 53.48%, Valid: 53.77% Test: 51.54%\n",
      "Run: 01, Epoch: 195, Loss: 1.0348, Train: 58.33%, Valid: 58.71% Test: 55.92%\n",
      "Run: 01, Epoch: 196, Loss: 1.0335, Train: 63.37%, Valid: 60.63% Test: 58.33%\n",
      "Run: 01, Epoch: 197, Loss: 1.0348, Train: 65.02%, Valid: 62.14% Test: 61.84%\n",
      "Run: 01, Epoch: 198, Loss: 0.9998, Train: 64.56%, Valid: 61.59% Test: 59.43%\n",
      "Run: 01, Epoch: 199, Loss: 1.0227, Train: 64.65%, Valid: 63.10% Test: 61.18%\n",
      "Run: 01, Epoch: 200, Loss: 1.0139, Train: 65.84%, Valid: 62.41% Test: 61.84%\n",
      "Run 01:\n",
      "Highest Train: 65.84\n",
      "Highest Valid: 64.75\n",
      "  Final Train: 64.10\n",
      "   Final Test: 59.65\n",
      "Run: 02, Epoch: 01, Loss: 2.1009, Train: 26.28%, Valid: 27.71% Test: 26.97%\n",
      "Run: 02, Epoch: 02, Loss: 1.5374, Train: 22.34%, Valid: 24.28% Test: 22.59%\n",
      "Run: 02, Epoch: 03, Loss: 1.4871, Train: 24.08%, Valid: 23.32% Test: 26.54%\n",
      "Run: 02, Epoch: 04, Loss: 1.5714, Train: 29.58%, Valid: 30.18% Test: 33.77%\n",
      "Run: 02, Epoch: 05, Loss: 1.4809, Train: 31.59%, Valid: 37.04% Test: 38.38%\n",
      "Run: 02, Epoch: 06, Loss: 1.4612, Train: 39.10%, Valid: 41.84% Test: 42.11%\n",
      "Run: 02, Epoch: 07, Loss: 1.3934, Train: 33.15%, Valid: 31.00% Test: 34.43%\n",
      "Run: 02, Epoch: 08, Loss: 1.4413, Train: 33.24%, Valid: 31.14% Test: 35.31%\n",
      "Run: 02, Epoch: 09, Loss: 1.3771, Train: 37.27%, Valid: 36.49% Test: 41.01%\n",
      "Run: 02, Epoch: 10, Loss: 1.3384, Train: 32.97%, Valid: 32.10% Test: 37.94%\n",
      "Run: 02, Epoch: 11, Loss: 1.3382, Train: 32.42%, Valid: 34.29% Test: 39.91%\n",
      "Run: 02, Epoch: 12, Loss: 1.3711, Train: 32.33%, Valid: 34.02% Test: 40.79%\n",
      "Run: 02, Epoch: 13, Loss: 1.3157, Train: 32.42%, Valid: 33.88% Test: 39.25%\n",
      "Run: 02, Epoch: 14, Loss: 1.3246, Train: 36.36%, Valid: 35.67% Test: 39.69%\n",
      "Run: 02, Epoch: 15, Loss: 1.3015, Train: 40.20%, Valid: 38.13% Test: 41.89%\n",
      "Run: 02, Epoch: 16, Loss: 1.2937, Train: 42.86%, Valid: 39.64% Test: 44.52%\n",
      "Run: 02, Epoch: 17, Loss: 1.3211, Train: 42.03%, Valid: 38.41% Test: 44.96%\n",
      "Run: 02, Epoch: 18, Loss: 1.2890, Train: 39.74%, Valid: 37.31% Test: 42.32%\n",
      "Run: 02, Epoch: 19, Loss: 1.2612, Train: 40.93%, Valid: 38.27% Test: 42.98%\n",
      "Run: 02, Epoch: 20, Loss: 1.2768, Train: 43.68%, Valid: 41.70% Test: 47.15%\n",
      "Run: 02, Epoch: 21, Loss: 1.2623, Train: 41.67%, Valid: 41.43% Test: 48.46%\n",
      "Run: 02, Epoch: 22, Loss: 1.2740, Train: 39.10%, Valid: 38.41% Test: 42.11%\n",
      "Run: 02, Epoch: 23, Loss: 1.2360, Train: 33.88%, Valid: 33.06% Test: 37.50%\n",
      "Run: 02, Epoch: 24, Loss: 1.3006, Train: 39.56%, Valid: 39.37% Test: 44.96%\n",
      "Run: 02, Epoch: 25, Loss: 1.2761, Train: 46.89%, Valid: 47.19% Test: 50.88%\n",
      "Run: 02, Epoch: 26, Loss: 1.2455, Train: 49.82%, Valid: 51.17% Test: 51.10%\n",
      "Run: 02, Epoch: 27, Loss: 1.2255, Train: 48.99%, Valid: 50.75% Test: 50.22%\n",
      "Run: 02, Epoch: 28, Loss: 1.2288, Train: 47.89%, Valid: 49.52% Test: 52.41%\n",
      "Run: 02, Epoch: 29, Loss: 1.2314, Train: 50.73%, Valid: 49.11% Test: 52.19%\n",
      "Run: 02, Epoch: 30, Loss: 1.2249, Train: 46.06%, Valid: 45.13% Test: 49.34%\n",
      "Run: 02, Epoch: 31, Loss: 1.2329, Train: 46.25%, Valid: 43.48% Test: 46.27%\n",
      "Run: 02, Epoch: 32, Loss: 1.2378, Train: 46.98%, Valid: 44.58% Test: 48.90%\n",
      "Run: 02, Epoch: 33, Loss: 1.2330, Train: 49.82%, Valid: 48.42% Test: 53.95%\n",
      "Run: 02, Epoch: 34, Loss: 1.2329, Train: 49.54%, Valid: 48.70% Test: 51.75%\n",
      "Run: 02, Epoch: 35, Loss: 1.2174, Train: 48.17%, Valid: 49.11% Test: 50.44%\n",
      "Run: 02, Epoch: 36, Loss: 1.2040, Train: 45.88%, Valid: 45.13% Test: 46.93%\n",
      "Run: 02, Epoch: 37, Loss: 1.2062, Train: 47.07%, Valid: 42.25% Test: 46.93%\n",
      "Run: 02, Epoch: 38, Loss: 1.2095, Train: 48.44%, Valid: 45.27% Test: 53.29%\n",
      "Run: 02, Epoch: 39, Loss: 1.2007, Train: 53.39%, Valid: 50.62% Test: 56.80%\n",
      "Run: 02, Epoch: 40, Loss: 1.1894, Train: 49.45%, Valid: 48.97% Test: 53.07%\n",
      "Run: 02, Epoch: 41, Loss: 1.1844, Train: 45.97%, Valid: 46.50% Test: 48.90%\n",
      "Run: 02, Epoch: 42, Loss: 1.1966, Train: 50.09%, Valid: 50.75% Test: 54.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 43, Loss: 1.1767, Train: 54.76%, Valid: 50.07% Test: 57.24%\n",
      "Run: 02, Epoch: 44, Loss: 1.1896, Train: 49.18%, Valid: 45.27% Test: 52.63%\n",
      "Run: 02, Epoch: 45, Loss: 1.1775, Train: 47.80%, Valid: 44.17% Test: 49.78%\n",
      "Run: 02, Epoch: 46, Loss: 1.1823, Train: 49.36%, Valid: 47.33% Test: 50.22%\n",
      "Run: 02, Epoch: 47, Loss: 1.1772, Train: 52.01%, Valid: 51.71% Test: 54.82%\n",
      "Run: 02, Epoch: 48, Loss: 1.1418, Train: 53.75%, Valid: 52.26% Test: 56.58%\n",
      "Run: 02, Epoch: 49, Loss: 1.1504, Train: 52.93%, Valid: 52.26% Test: 53.73%\n",
      "Run: 02, Epoch: 50, Loss: 1.1349, Train: 54.49%, Valid: 52.54% Test: 57.46%\n",
      "Run: 02, Epoch: 51, Loss: 1.1279, Train: 51.47%, Valid: 49.66% Test: 55.70%\n",
      "Run: 02, Epoch: 52, Loss: 1.1534, Train: 51.28%, Valid: 49.25% Test: 51.75%\n",
      "Run: 02, Epoch: 53, Loss: 1.1882, Train: 54.85%, Valid: 51.71% Test: 57.89%\n",
      "Run: 02, Epoch: 54, Loss: 1.1633, Train: 55.49%, Valid: 52.54% Test: 57.24%\n",
      "Run: 02, Epoch: 55, Loss: 1.1595, Train: 50.18%, Valid: 46.91% Test: 50.88%\n",
      "Run: 02, Epoch: 56, Loss: 1.1288, Train: 55.59%, Valid: 52.13% Test: 59.65%\n",
      "Run: 02, Epoch: 57, Loss: 1.1491, Train: 46.43%, Valid: 42.94% Test: 49.12%\n",
      "Run: 02, Epoch: 58, Loss: 1.1816, Train: 45.97%, Valid: 44.31% Test: 49.78%\n",
      "Run: 02, Epoch: 59, Loss: 1.1278, Train: 53.57%, Valid: 50.62% Test: 56.80%\n",
      "Run: 02, Epoch: 60, Loss: 1.1142, Train: 53.57%, Valid: 52.40% Test: 56.36%\n",
      "Run: 02, Epoch: 61, Loss: 1.1174, Train: 50.73%, Valid: 50.48% Test: 52.63%\n",
      "Run: 02, Epoch: 62, Loss: 1.1365, Train: 51.01%, Valid: 50.34% Test: 53.51%\n",
      "Run: 02, Epoch: 63, Loss: 1.1379, Train: 55.31%, Valid: 51.58% Test: 58.55%\n",
      "Run: 02, Epoch: 64, Loss: 1.1119, Train: 55.22%, Valid: 50.75% Test: 59.21%\n",
      "Run: 02, Epoch: 65, Loss: 1.1235, Train: 53.48%, Valid: 51.99% Test: 54.39%\n",
      "Run: 02, Epoch: 66, Loss: 1.1110, Train: 54.30%, Valid: 53.36% Test: 55.70%\n",
      "Run: 02, Epoch: 67, Loss: 1.0984, Train: 55.86%, Valid: 55.42% Test: 58.33%\n",
      "Run: 02, Epoch: 68, Loss: 1.0898, Train: 58.70%, Valid: 56.93% Test: 61.18%\n",
      "Run: 02, Epoch: 69, Loss: 1.1155, Train: 58.42%, Valid: 56.79% Test: 62.28%\n",
      "Run: 02, Epoch: 70, Loss: 1.0877, Train: 53.94%, Valid: 53.64% Test: 57.02%\n",
      "Run: 02, Epoch: 71, Loss: 1.0985, Train: 53.02%, Valid: 55.01% Test: 55.70%\n",
      "Run: 02, Epoch: 72, Loss: 1.1169, Train: 55.22%, Valid: 53.77% Test: 57.02%\n",
      "Run: 02, Epoch: 73, Loss: 1.1315, Train: 49.73%, Valid: 48.83% Test: 49.34%\n",
      "Run: 02, Epoch: 74, Loss: 1.1230, Train: 53.66%, Valid: 51.58% Test: 53.95%\n",
      "Run: 02, Epoch: 75, Loss: 1.1053, Train: 55.40%, Valid: 54.60% Test: 58.99%\n",
      "Run: 02, Epoch: 76, Loss: 1.1340, Train: 58.88%, Valid: 56.38% Test: 59.87%\n",
      "Run: 02, Epoch: 77, Loss: 1.0992, Train: 47.07%, Valid: 47.33% Test: 48.46%\n",
      "Run: 02, Epoch: 78, Loss: 1.1197, Train: 50.92%, Valid: 51.17% Test: 52.41%\n",
      "Run: 02, Epoch: 79, Loss: 1.1243, Train: 56.87%, Valid: 54.18% Test: 60.96%\n",
      "Run: 02, Epoch: 80, Loss: 1.1400, Train: 54.30%, Valid: 51.99% Test: 59.65%\n",
      "Run: 02, Epoch: 81, Loss: 1.1286, Train: 53.11%, Valid: 51.85% Test: 54.61%\n",
      "Run: 02, Epoch: 82, Loss: 1.1011, Train: 52.75%, Valid: 49.93% Test: 53.07%\n",
      "Run: 02, Epoch: 83, Loss: 1.1052, Train: 54.49%, Valid: 53.91% Test: 54.82%\n",
      "Run: 02, Epoch: 84, Loss: 1.1037, Train: 57.60%, Valid: 53.64% Test: 61.40%\n",
      "Run: 02, Epoch: 85, Loss: 1.1258, Train: 57.51%, Valid: 53.36% Test: 61.40%\n",
      "Run: 02, Epoch: 86, Loss: 1.0822, Train: 53.66%, Valid: 52.81% Test: 55.48%\n",
      "Run: 02, Epoch: 87, Loss: 1.1146, Train: 53.21%, Valid: 51.71% Test: 52.85%\n",
      "Run: 02, Epoch: 88, Loss: 1.0734, Train: 53.75%, Valid: 52.54% Test: 54.39%\n",
      "Run: 02, Epoch: 89, Loss: 1.0986, Train: 58.97%, Valid: 56.10% Test: 60.96%\n",
      "Run: 02, Epoch: 90, Loss: 1.1098, Train: 58.06%, Valid: 54.18% Test: 60.75%\n",
      "Run: 02, Epoch: 91, Loss: 1.0844, Train: 55.59%, Valid: 52.95% Test: 56.58%\n",
      "Run: 02, Epoch: 92, Loss: 1.1158, Train: 55.31%, Valid: 53.77% Test: 57.02%\n",
      "Run: 02, Epoch: 93, Loss: 1.0827, Train: 57.88%, Valid: 56.38% Test: 59.21%\n",
      "Run: 02, Epoch: 94, Loss: 1.0955, Train: 57.14%, Valid: 54.87% Test: 60.96%\n",
      "Run: 02, Epoch: 95, Loss: 1.1044, Train: 57.05%, Valid: 54.46% Test: 60.75%\n",
      "Run: 02, Epoch: 96, Loss: 1.0931, Train: 53.30%, Valid: 54.05% Test: 54.39%\n",
      "Run: 02, Epoch: 97, Loss: 1.1169, Train: 54.95%, Valid: 55.14% Test: 57.24%\n",
      "Run: 02, Epoch: 98, Loss: 1.1106, Train: 58.33%, Valid: 56.24% Test: 60.31%\n",
      "Run: 02, Epoch: 99, Loss: 1.0774, Train: 58.15%, Valid: 55.28% Test: 61.18%\n",
      "Run: 02, Epoch: 100, Loss: 1.0927, Train: 57.78%, Valid: 56.93% Test: 60.96%\n",
      "Run: 02, Epoch: 101, Loss: 1.0754, Train: 55.22%, Valid: 56.52% Test: 59.87%\n",
      "Run: 02, Epoch: 102, Loss: 1.0795, Train: 58.79%, Valid: 60.77% Test: 63.38%\n",
      "Run: 02, Epoch: 103, Loss: 1.1000, Train: 59.07%, Valid: 56.93% Test: 61.62%\n",
      "Run: 02, Epoch: 104, Loss: 1.1056, Train: 57.51%, Valid: 54.46% Test: 61.84%\n",
      "Run: 02, Epoch: 105, Loss: 1.1080, Train: 59.25%, Valid: 56.93% Test: 59.43%\n",
      "Run: 02, Epoch: 106, Loss: 1.0959, Train: 56.32%, Valid: 56.10% Test: 60.09%\n",
      "Run: 02, Epoch: 107, Loss: 1.0952, Train: 59.07%, Valid: 59.12% Test: 61.62%\n",
      "Run: 02, Epoch: 108, Loss: 1.1132, Train: 58.97%, Valid: 57.20% Test: 59.87%\n",
      "Run: 02, Epoch: 109, Loss: 1.0820, Train: 58.42%, Valid: 57.48% Test: 61.62%\n",
      "Run: 02, Epoch: 110, Loss: 1.0739, Train: 57.33%, Valid: 58.02% Test: 61.40%\n",
      "Run: 02, Epoch: 111, Loss: 1.0776, Train: 53.85%, Valid: 53.91% Test: 54.82%\n",
      "Run: 02, Epoch: 112, Loss: 1.0423, Train: 56.41%, Valid: 53.91% Test: 56.80%\n",
      "Run: 02, Epoch: 113, Loss: 1.1018, Train: 55.95%, Valid: 55.28% Test: 57.02%\n",
      "Run: 02, Epoch: 114, Loss: 1.0983, Train: 57.42%, Valid: 56.79% Test: 58.99%\n",
      "Run: 02, Epoch: 115, Loss: 1.0595, Train: 56.96%, Valid: 54.32% Test: 57.89%\n",
      "Run: 02, Epoch: 116, Loss: 1.0640, Train: 56.50%, Valid: 56.65% Test: 59.21%\n",
      "Run: 02, Epoch: 117, Loss: 1.0818, Train: 57.69%, Valid: 55.28% Test: 58.55%\n",
      "Run: 02, Epoch: 118, Loss: 1.0893, Train: 56.68%, Valid: 54.18% Test: 58.55%\n",
      "Run: 02, Epoch: 119, Loss: 1.0812, Train: 57.78%, Valid: 59.81% Test: 60.53%\n",
      "Run: 02, Epoch: 120, Loss: 1.0607, Train: 56.78%, Valid: 58.16% Test: 59.43%\n",
      "Run: 02, Epoch: 121, Loss: 1.0744, Train: 56.23%, Valid: 54.05% Test: 58.99%\n",
      "Run: 02, Epoch: 122, Loss: 1.1264, Train: 56.96%, Valid: 55.28% Test: 56.80%\n",
      "Run: 02, Epoch: 123, Loss: 1.0647, Train: 54.40%, Valid: 53.22% Test: 53.73%\n",
      "Run: 02, Epoch: 124, Loss: 1.0613, Train: 56.23%, Valid: 55.42% Test: 57.24%\n",
      "Run: 02, Epoch: 125, Loss: 1.0581, Train: 60.16%, Valid: 54.87% Test: 62.50%\n",
      "Run: 02, Epoch: 126, Loss: 1.0773, Train: 58.15%, Valid: 55.56% Test: 62.94%\n",
      "Run: 02, Epoch: 127, Loss: 1.0624, Train: 59.43%, Valid: 55.97% Test: 62.28%\n",
      "Run: 02, Epoch: 128, Loss: 1.0834, Train: 58.33%, Valid: 55.14% Test: 59.21%\n",
      "Run: 02, Epoch: 129, Loss: 1.0516, Train: 59.34%, Valid: 56.10% Test: 60.31%\n",
      "Run: 02, Epoch: 130, Loss: 1.0679, Train: 59.71%, Valid: 55.69% Test: 60.31%\n",
      "Run: 02, Epoch: 131, Loss: 1.0854, Train: 59.34%, Valid: 57.61% Test: 62.06%\n",
      "Run: 02, Epoch: 132, Loss: 1.0683, Train: 59.34%, Valid: 58.71% Test: 62.28%\n",
      "Run: 02, Epoch: 133, Loss: 1.0937, Train: 57.97%, Valid: 54.18% Test: 56.58%\n",
      "Run: 02, Epoch: 134, Loss: 1.0465, Train: 59.25%, Valid: 55.01% Test: 58.99%\n",
      "Run: 02, Epoch: 135, Loss: 1.0358, Train: 57.69%, Valid: 55.28% Test: 57.89%\n",
      "Run: 02, Epoch: 136, Loss: 1.0604, Train: 60.90%, Valid: 59.12% Test: 61.84%\n",
      "Run: 02, Epoch: 137, Loss: 1.0657, Train: 57.42%, Valid: 54.73% Test: 59.87%\n",
      "Run: 02, Epoch: 138, Loss: 1.0350, Train: 56.78%, Valid: 54.32% Test: 58.11%\n",
      "Run: 02, Epoch: 139, Loss: 1.1021, Train: 57.42%, Valid: 56.52% Test: 60.53%\n",
      "Run: 02, Epoch: 140, Loss: 1.0731, Train: 58.97%, Valid: 56.52% Test: 61.84%\n",
      "Run: 02, Epoch: 141, Loss: 1.0879, Train: 61.08%, Valid: 58.98% Test: 62.72%\n",
      "Run: 02, Epoch: 142, Loss: 1.0610, Train: 61.45%, Valid: 58.85% Test: 62.06%\n",
      "Run: 02, Epoch: 143, Loss: 1.0595, Train: 55.40%, Valid: 54.18% Test: 55.48%\n",
      "Run: 02, Epoch: 144, Loss: 1.0591, Train: 53.66%, Valid: 50.21% Test: 54.82%\n",
      "Run: 02, Epoch: 145, Loss: 1.0683, Train: 57.51%, Valid: 54.73% Test: 59.21%\n",
      "Run: 02, Epoch: 146, Loss: 1.0599, Train: 59.07%, Valid: 56.38% Test: 59.21%\n",
      "Run: 02, Epoch: 147, Loss: 1.0650, Train: 59.25%, Valid: 57.06% Test: 60.96%\n",
      "Run: 02, Epoch: 148, Loss: 1.0496, Train: 59.25%, Valid: 55.14% Test: 62.72%\n",
      "Run: 02, Epoch: 149, Loss: 1.0590, Train: 58.52%, Valid: 54.73% Test: 61.84%\n",
      "Run: 02, Epoch: 150, Loss: 1.0443, Train: 57.14%, Valid: 55.83% Test: 58.33%\n",
      "Run: 02, Epoch: 151, Loss: 1.0648, Train: 61.17%, Valid: 60.08% Test: 62.94%\n",
      "Run: 02, Epoch: 152, Loss: 1.0476, Train: 59.43%, Valid: 55.42% Test: 63.38%\n",
      "Run: 02, Epoch: 153, Loss: 1.0750, Train: 56.32%, Valid: 52.81% Test: 58.55%\n",
      "Run: 02, Epoch: 154, Loss: 1.0512, Train: 61.72%, Valid: 60.36% Test: 63.16%\n",
      "Run: 02, Epoch: 155, Loss: 1.0398, Train: 57.69%, Valid: 57.34% Test: 60.75%\n",
      "Run: 02, Epoch: 156, Loss: 1.0294, Train: 60.90%, Valid: 58.02% Test: 63.82%\n",
      "Run: 02, Epoch: 157, Loss: 1.0450, Train: 60.44%, Valid: 58.02% Test: 64.91%\n",
      "Run: 02, Epoch: 158, Loss: 1.0577, Train: 59.98%, Valid: 59.95% Test: 64.47%\n",
      "Run: 02, Epoch: 159, Loss: 1.0342, Train: 57.42%, Valid: 57.48% Test: 61.40%\n",
      "Run: 02, Epoch: 160, Loss: 1.0404, Train: 57.42%, Valid: 55.14% Test: 59.87%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 161, Loss: 1.0540, Train: 59.16%, Valid: 57.20% Test: 59.65%\n",
      "Run: 02, Epoch: 162, Loss: 1.0586, Train: 57.78%, Valid: 56.52% Test: 62.94%\n",
      "Run: 02, Epoch: 163, Loss: 1.0374, Train: 55.59%, Valid: 55.28% Test: 62.06%\n",
      "Run: 02, Epoch: 164, Loss: 1.0711, Train: 58.70%, Valid: 56.24% Test: 61.62%\n",
      "Run: 02, Epoch: 165, Loss: 1.0506, Train: 60.16%, Valid: 55.14% Test: 59.21%\n",
      "Run: 02, Epoch: 166, Loss: 1.0646, Train: 60.44%, Valid: 55.28% Test: 60.75%\n",
      "Run: 02, Epoch: 167, Loss: 1.0341, Train: 55.40%, Valid: 54.60% Test: 57.24%\n",
      "Run: 02, Epoch: 168, Loss: 1.0670, Train: 59.52%, Valid: 59.26% Test: 63.38%\n",
      "Run: 02, Epoch: 169, Loss: 1.0459, Train: 60.99%, Valid: 57.61% Test: 63.38%\n",
      "Run: 02, Epoch: 170, Loss: 1.0491, Train: 57.88%, Valid: 55.83% Test: 61.62%\n",
      "Run: 02, Epoch: 171, Loss: 1.0284, Train: 55.59%, Valid: 54.32% Test: 57.68%\n",
      "Run: 02, Epoch: 172, Loss: 1.0296, Train: 56.59%, Valid: 53.36% Test: 54.61%\n",
      "Run: 02, Epoch: 173, Loss: 1.0764, Train: 59.71%, Valid: 56.65% Test: 61.18%\n",
      "Run: 02, Epoch: 174, Loss: 1.0243, Train: 58.42%, Valid: 53.77% Test: 61.40%\n",
      "Run: 02, Epoch: 175, Loss: 1.0422, Train: 62.45%, Valid: 58.98% Test: 63.60%\n",
      "Run: 02, Epoch: 176, Loss: 1.0565, Train: 60.44%, Valid: 57.75% Test: 59.21%\n",
      "Run: 02, Epoch: 177, Loss: 1.0381, Train: 56.23%, Valid: 55.42% Test: 57.46%\n",
      "Run: 02, Epoch: 178, Loss: 1.0636, Train: 56.96%, Valid: 53.91% Test: 58.55%\n",
      "Run: 02, Epoch: 179, Loss: 1.0350, Train: 60.90%, Valid: 55.97% Test: 59.65%\n",
      "Run: 02, Epoch: 180, Loss: 1.0672, Train: 60.90%, Valid: 59.26% Test: 59.87%\n",
      "Run: 02, Epoch: 181, Loss: 1.0327, Train: 58.79%, Valid: 56.65% Test: 60.09%\n",
      "Run: 02, Epoch: 182, Loss: 1.0409, Train: 57.78%, Valid: 55.14% Test: 61.84%\n",
      "Run: 02, Epoch: 183, Loss: 1.0664, Train: 59.62%, Valid: 58.98% Test: 64.25%\n",
      "Run: 02, Epoch: 184, Loss: 1.0284, Train: 59.71%, Valid: 58.98% Test: 63.38%\n",
      "Run: 02, Epoch: 185, Loss: 1.0392, Train: 57.51%, Valid: 57.20% Test: 58.55%\n",
      "Run: 02, Epoch: 186, Loss: 1.0621, Train: 56.32%, Valid: 54.18% Test: 59.65%\n",
      "Run: 02, Epoch: 187, Loss: 1.0875, Train: 57.97%, Valid: 54.60% Test: 59.43%\n",
      "Run: 02, Epoch: 188, Loss: 1.0595, Train: 57.97%, Valid: 56.24% Test: 57.68%\n",
      "Run: 02, Epoch: 189, Loss: 1.0308, Train: 53.66%, Valid: 52.13% Test: 55.26%\n",
      "Run: 02, Epoch: 190, Loss: 1.0538, Train: 55.31%, Valid: 51.58% Test: 57.68%\n",
      "Run: 02, Epoch: 191, Loss: 1.0825, Train: 60.44%, Valid: 56.79% Test: 63.60%\n",
      "Run: 02, Epoch: 192, Loss: 1.0378, Train: 61.26%, Valid: 58.71% Test: 63.38%\n",
      "Run: 02, Epoch: 193, Loss: 1.0584, Train: 56.68%, Valid: 56.65% Test: 60.09%\n",
      "Run: 02, Epoch: 194, Loss: 1.0520, Train: 58.88%, Valid: 57.48% Test: 59.87%\n",
      "Run: 02, Epoch: 195, Loss: 0.9999, Train: 58.52%, Valid: 55.83% Test: 61.40%\n",
      "Run: 02, Epoch: 196, Loss: 1.0670, Train: 59.25%, Valid: 58.57% Test: 60.96%\n",
      "Run: 02, Epoch: 197, Loss: 1.0113, Train: 59.80%, Valid: 58.57% Test: 62.28%\n",
      "Run: 02, Epoch: 198, Loss: 1.0376, Train: 62.55%, Valid: 58.71% Test: 64.47%\n",
      "Run: 02, Epoch: 199, Loss: 1.0259, Train: 58.15%, Valid: 56.65% Test: 63.60%\n",
      "Run: 02, Epoch: 200, Loss: 1.0253, Train: 62.27%, Valid: 60.91% Test: 64.47%\n",
      "Run 02:\n",
      "Highest Train: 62.55\n",
      "Highest Valid: 60.91\n",
      "  Final Train: 62.27\n",
      "   Final Test: 64.47\n",
      "Run: 03, Epoch: 01, Loss: 2.0846, Train: 22.80%, Valid: 21.67% Test: 26.75%\n",
      "Run: 03, Epoch: 02, Loss: 1.5023, Train: 20.15%, Valid: 20.03% Test: 24.78%\n",
      "Run: 03, Epoch: 03, Loss: 1.5854, Train: 21.06%, Valid: 21.12% Test: 25.66%\n",
      "Run: 03, Epoch: 04, Loss: 1.4344, Train: 27.66%, Valid: 27.02% Test: 29.61%\n",
      "Run: 03, Epoch: 05, Loss: 1.3780, Train: 41.67%, Valid: 41.84% Test: 41.45%\n",
      "Run: 03, Epoch: 06, Loss: 1.3730, Train: 33.15%, Valid: 30.59% Test: 30.92%\n",
      "Run: 03, Epoch: 07, Loss: 1.3623, Train: 34.34%, Valid: 32.37% Test: 33.99%\n",
      "Run: 03, Epoch: 08, Loss: 1.3129, Train: 37.18%, Valid: 34.98% Test: 34.21%\n",
      "Run: 03, Epoch: 09, Loss: 1.3258, Train: 38.64%, Valid: 34.98% Test: 33.99%\n",
      "Run: 03, Epoch: 10, Loss: 1.3245, Train: 40.57%, Valid: 36.76% Test: 36.18%\n",
      "Run: 03, Epoch: 11, Loss: 1.3163, Train: 46.89%, Valid: 45.95% Test: 42.11%\n",
      "Run: 03, Epoch: 12, Loss: 1.2984, Train: 41.48%, Valid: 43.62% Test: 39.91%\n",
      "Run: 03, Epoch: 13, Loss: 1.3185, Train: 45.60%, Valid: 44.44% Test: 42.11%\n",
      "Run: 03, Epoch: 14, Loss: 1.2856, Train: 46.34%, Valid: 46.36% Test: 43.64%\n",
      "Run: 03, Epoch: 15, Loss: 1.2600, Train: 47.44%, Valid: 46.91% Test: 43.20%\n",
      "Run: 03, Epoch: 16, Loss: 1.2342, Train: 47.16%, Valid: 45.82% Test: 43.42%\n",
      "Run: 03, Epoch: 17, Loss: 1.2201, Train: 41.58%, Valid: 38.96% Test: 37.72%\n",
      "Run: 03, Epoch: 18, Loss: 1.2396, Train: 42.86%, Valid: 41.02% Test: 35.96%\n",
      "Run: 03, Epoch: 19, Loss: 1.2573, Train: 46.43%, Valid: 44.99% Test: 39.25%\n",
      "Run: 03, Epoch: 20, Loss: 1.2255, Train: 48.17%, Valid: 47.05% Test: 45.83%\n",
      "Run: 03, Epoch: 21, Loss: 1.2154, Train: 49.91%, Valid: 47.87% Test: 47.59%\n",
      "Run: 03, Epoch: 22, Loss: 1.2205, Train: 47.62%, Valid: 44.58% Test: 46.93%\n",
      "Run: 03, Epoch: 23, Loss: 1.2105, Train: 46.43%, Valid: 42.25% Test: 43.86%\n",
      "Run: 03, Epoch: 24, Loss: 1.1762, Train: 48.99%, Valid: 44.72% Test: 47.81%\n",
      "Run: 03, Epoch: 25, Loss: 1.1962, Train: 50.46%, Valid: 46.91% Test: 50.00%\n",
      "Run: 03, Epoch: 26, Loss: 1.1673, Train: 46.34%, Valid: 44.44% Test: 46.05%\n",
      "Run: 03, Epoch: 27, Loss: 1.1905, Train: 51.47%, Valid: 49.38% Test: 50.00%\n",
      "Run: 03, Epoch: 28, Loss: 1.1758, Train: 50.37%, Valid: 46.91% Test: 46.71%\n",
      "Run: 03, Epoch: 29, Loss: 1.1577, Train: 53.94%, Valid: 49.38% Test: 48.68%\n",
      "Run: 03, Epoch: 30, Loss: 1.1711, Train: 52.66%, Valid: 49.38% Test: 48.68%\n",
      "Run: 03, Epoch: 31, Loss: 1.1721, Train: 47.71%, Valid: 45.68% Test: 45.61%\n",
      "Run: 03, Epoch: 32, Loss: 1.1975, Train: 49.82%, Valid: 46.36% Test: 46.93%\n",
      "Run: 03, Epoch: 33, Loss: 1.1750, Train: 55.13%, Valid: 52.40% Test: 51.32%\n",
      "Run: 03, Epoch: 34, Loss: 1.1884, Train: 50.82%, Valid: 47.60% Test: 49.12%\n",
      "Run: 03, Epoch: 35, Loss: 1.1460, Train: 50.46%, Valid: 46.50% Test: 46.71%\n",
      "Run: 03, Epoch: 36, Loss: 1.1576, Train: 49.82%, Valid: 47.46% Test: 45.83%\n",
      "Run: 03, Epoch: 37, Loss: 1.1739, Train: 50.73%, Valid: 49.11% Test: 48.46%\n",
      "Run: 03, Epoch: 38, Loss: 1.1558, Train: 52.38%, Valid: 49.66% Test: 51.54%\n",
      "Run: 03, Epoch: 39, Loss: 1.1505, Train: 48.81%, Valid: 47.05% Test: 48.03%\n",
      "Run: 03, Epoch: 40, Loss: 1.1607, Train: 48.53%, Valid: 45.27% Test: 45.61%\n",
      "Run: 03, Epoch: 41, Loss: 1.1457, Train: 46.98%, Valid: 41.29% Test: 42.76%\n",
      "Run: 03, Epoch: 42, Loss: 1.1502, Train: 45.88%, Valid: 40.05% Test: 42.76%\n",
      "Run: 03, Epoch: 43, Loss: 1.1417, Train: 49.08%, Valid: 43.90% Test: 42.11%\n",
      "Run: 03, Epoch: 44, Loss: 1.1559, Train: 52.20%, Valid: 45.95% Test: 48.90%\n",
      "Run: 03, Epoch: 45, Loss: 1.1529, Train: 53.66%, Valid: 50.21% Test: 48.46%\n",
      "Run: 03, Epoch: 46, Loss: 1.1427, Train: 52.56%, Valid: 49.11% Test: 49.34%\n",
      "Run: 03, Epoch: 47, Loss: 1.1537, Train: 55.86%, Valid: 51.71% Test: 51.54%\n",
      "Run: 03, Epoch: 48, Loss: 1.1634, Train: 51.83%, Valid: 47.87% Test: 48.25%\n",
      "Run: 03, Epoch: 49, Loss: 1.1300, Train: 48.99%, Valid: 46.36% Test: 45.83%\n",
      "Run: 03, Epoch: 50, Loss: 1.1440, Train: 52.11%, Valid: 48.42% Test: 50.88%\n",
      "Run: 03, Epoch: 51, Loss: 1.1600, Train: 49.08%, Valid: 44.99% Test: 46.27%\n",
      "Run: 03, Epoch: 52, Loss: 1.1247, Train: 48.35%, Valid: 43.21% Test: 45.61%\n",
      "Run: 03, Epoch: 53, Loss: 1.1566, Train: 45.70%, Valid: 41.29% Test: 43.20%\n",
      "Run: 03, Epoch: 54, Loss: 1.1757, Train: 48.53%, Valid: 44.17% Test: 44.74%\n",
      "Run: 03, Epoch: 55, Loss: 1.1238, Train: 45.05%, Valid: 41.56% Test: 45.18%\n",
      "Run: 03, Epoch: 56, Loss: 1.1664, Train: 46.70%, Valid: 42.66% Test: 44.52%\n",
      "Run: 03, Epoch: 57, Loss: 1.1192, Train: 44.05%, Valid: 38.96% Test: 41.67%\n",
      "Run: 03, Epoch: 58, Loss: 1.1373, Train: 44.14%, Valid: 40.19% Test: 41.01%\n",
      "Run: 03, Epoch: 59, Loss: 1.1349, Train: 44.32%, Valid: 41.84% Test: 42.76%\n",
      "Run: 03, Epoch: 60, Loss: 1.1529, Train: 48.35%, Valid: 42.94% Test: 43.64%\n",
      "Run: 03, Epoch: 61, Loss: 1.1412, Train: 43.68%, Valid: 38.13% Test: 41.89%\n",
      "Run: 03, Epoch: 62, Loss: 1.1852, Train: 50.09%, Valid: 46.36% Test: 45.61%\n",
      "Run: 03, Epoch: 63, Loss: 1.1287, Train: 51.92%, Valid: 47.05% Test: 48.46%\n",
      "Run: 03, Epoch: 64, Loss: 1.1370, Train: 52.56%, Valid: 49.25% Test: 48.03%\n",
      "Run: 03, Epoch: 65, Loss: 1.1254, Train: 48.99%, Valid: 44.31% Test: 45.83%\n",
      "Run: 03, Epoch: 66, Loss: 1.1349, Train: 52.11%, Valid: 47.46% Test: 48.46%\n",
      "Run: 03, Epoch: 67, Loss: 1.0906, Train: 52.38%, Valid: 48.15% Test: 48.90%\n",
      "Run: 03, Epoch: 68, Loss: 1.1285, Train: 52.01%, Valid: 47.33% Test: 47.37%\n",
      "Run: 03, Epoch: 69, Loss: 1.0896, Train: 48.35%, Valid: 42.94% Test: 42.11%\n",
      "Run: 03, Epoch: 70, Loss: 1.1329, Train: 51.01%, Valid: 45.82% Test: 47.15%\n",
      "Run: 03, Epoch: 71, Loss: 1.1054, Train: 51.74%, Valid: 46.09% Test: 47.37%\n",
      "Run: 03, Epoch: 72, Loss: 1.1437, Train: 53.94%, Valid: 50.21% Test: 48.68%\n",
      "Run: 03, Epoch: 73, Loss: 1.0952, Train: 49.73%, Valid: 48.70% Test: 43.64%\n",
      "Run: 03, Epoch: 74, Loss: 1.1318, Train: 50.00%, Valid: 51.44% Test: 44.96%\n",
      "Run: 03, Epoch: 75, Loss: 1.1216, Train: 53.11%, Valid: 53.22% Test: 46.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 76, Loss: 1.1140, Train: 58.15%, Valid: 56.65% Test: 51.97%\n",
      "Run: 03, Epoch: 77, Loss: 1.0984, Train: 55.86%, Valid: 51.71% Test: 51.75%\n",
      "Run: 03, Epoch: 78, Loss: 1.1264, Train: 54.76%, Valid: 52.67% Test: 52.85%\n",
      "Run: 03, Epoch: 79, Loss: 1.1198, Train: 55.77%, Valid: 53.91% Test: 51.97%\n",
      "Run: 03, Epoch: 80, Loss: 1.0805, Train: 56.50%, Valid: 54.87% Test: 52.19%\n",
      "Run: 03, Epoch: 81, Loss: 1.0948, Train: 55.49%, Valid: 53.50% Test: 50.88%\n",
      "Run: 03, Epoch: 82, Loss: 1.0901, Train: 54.03%, Valid: 51.99% Test: 50.22%\n",
      "Run: 03, Epoch: 83, Loss: 1.0902, Train: 52.11%, Valid: 49.66% Test: 49.78%\n",
      "Run: 03, Epoch: 84, Loss: 1.0984, Train: 52.66%, Valid: 49.38% Test: 49.12%\n",
      "Run: 03, Epoch: 85, Loss: 1.0956, Train: 51.74%, Valid: 49.38% Test: 49.34%\n",
      "Run: 03, Epoch: 86, Loss: 1.0945, Train: 54.58%, Valid: 51.17% Test: 51.54%\n",
      "Run: 03, Epoch: 87, Loss: 1.0817, Train: 55.68%, Valid: 51.17% Test: 52.63%\n",
      "Run: 03, Epoch: 88, Loss: 1.0861, Train: 53.30%, Valid: 49.93% Test: 48.90%\n",
      "Run: 03, Epoch: 89, Loss: 1.0702, Train: 56.41%, Valid: 54.60% Test: 51.97%\n",
      "Run: 03, Epoch: 90, Loss: 1.0922, Train: 59.89%, Valid: 57.89% Test: 55.48%\n",
      "Run: 03, Epoch: 91, Loss: 1.0779, Train: 58.97%, Valid: 57.75% Test: 54.82%\n",
      "Run: 03, Epoch: 92, Loss: 1.0981, Train: 57.60%, Valid: 57.06% Test: 49.12%\n",
      "Run: 03, Epoch: 93, Loss: 1.1135, Train: 58.88%, Valid: 58.98% Test: 54.82%\n",
      "Run: 03, Epoch: 94, Loss: 1.0774, Train: 57.23%, Valid: 55.97% Test: 53.51%\n",
      "Run: 03, Epoch: 95, Loss: 1.1036, Train: 58.70%, Valid: 56.38% Test: 52.85%\n",
      "Run: 03, Epoch: 96, Loss: 1.0845, Train: 56.68%, Valid: 54.05% Test: 48.90%\n",
      "Run: 03, Epoch: 97, Loss: 1.0768, Train: 56.23%, Valid: 53.77% Test: 51.97%\n",
      "Run: 03, Epoch: 98, Loss: 1.1029, Train: 57.05%, Valid: 56.10% Test: 53.29%\n",
      "Run: 03, Epoch: 99, Loss: 1.0711, Train: 58.61%, Valid: 57.20% Test: 53.95%\n",
      "Run: 03, Epoch: 100, Loss: 1.0716, Train: 57.42%, Valid: 54.73% Test: 51.10%\n",
      "Run: 03, Epoch: 101, Loss: 1.0927, Train: 58.42%, Valid: 56.93% Test: 53.51%\n",
      "Run: 03, Epoch: 102, Loss: 1.0837, Train: 57.42%, Valid: 52.95% Test: 50.88%\n",
      "Run: 03, Epoch: 103, Loss: 1.0748, Train: 51.56%, Valid: 48.29% Test: 46.05%\n",
      "Run: 03, Epoch: 104, Loss: 1.0877, Train: 54.03%, Valid: 48.01% Test: 49.56%\n",
      "Run: 03, Epoch: 105, Loss: 1.1198, Train: 52.47%, Valid: 47.19% Test: 48.25%\n",
      "Run: 03, Epoch: 106, Loss: 1.1207, Train: 55.95%, Valid: 55.69% Test: 48.90%\n",
      "Run: 03, Epoch: 107, Loss: 1.1098, Train: 47.62%, Valid: 45.68% Test: 44.30%\n",
      "Run: 03, Epoch: 108, Loss: 1.1443, Train: 50.64%, Valid: 47.19% Test: 49.34%\n",
      "Run: 03, Epoch: 109, Loss: 1.1392, Train: 51.19%, Valid: 49.38% Test: 49.34%\n",
      "Run: 03, Epoch: 110, Loss: 1.0983, Train: 59.16%, Valid: 58.16% Test: 55.04%\n",
      "Run: 03, Epoch: 111, Loss: 1.0817, Train: 58.33%, Valid: 58.85% Test: 54.82%\n",
      "Run: 03, Epoch: 112, Loss: 1.0952, Train: 57.42%, Valid: 57.48% Test: 52.85%\n",
      "Run: 03, Epoch: 113, Loss: 1.1155, Train: 58.15%, Valid: 55.01% Test: 52.41%\n",
      "Run: 03, Epoch: 114, Loss: 1.1116, Train: 57.33%, Valid: 55.42% Test: 52.85%\n",
      "Run: 03, Epoch: 115, Loss: 1.1014, Train: 57.51%, Valid: 56.79% Test: 53.73%\n",
      "Run: 03, Epoch: 116, Loss: 1.0780, Train: 57.05%, Valid: 56.65% Test: 52.85%\n",
      "Run: 03, Epoch: 117, Loss: 1.0861, Train: 55.13%, Valid: 54.05% Test: 51.97%\n",
      "Run: 03, Epoch: 118, Loss: 1.0797, Train: 55.68%, Valid: 55.28% Test: 51.10%\n",
      "Run: 03, Epoch: 119, Loss: 1.0744, Train: 56.68%, Valid: 56.79% Test: 53.51%\n",
      "Run: 03, Epoch: 120, Loss: 1.0923, Train: 58.88%, Valid: 57.75% Test: 55.48%\n",
      "Run: 03, Epoch: 121, Loss: 1.0530, Train: 58.52%, Valid: 56.10% Test: 53.07%\n",
      "Run: 03, Epoch: 122, Loss: 1.0603, Train: 59.80%, Valid: 58.02% Test: 55.92%\n",
      "Run: 03, Epoch: 123, Loss: 1.0713, Train: 60.81%, Valid: 59.81% Test: 57.02%\n",
      "Run: 03, Epoch: 124, Loss: 1.0866, Train: 60.26%, Valid: 58.71% Test: 56.58%\n",
      "Run: 03, Epoch: 125, Loss: 1.0762, Train: 56.96%, Valid: 55.14% Test: 52.85%\n",
      "Run: 03, Epoch: 126, Loss: 1.0537, Train: 59.52%, Valid: 58.71% Test: 57.02%\n",
      "Run: 03, Epoch: 127, Loss: 1.0533, Train: 62.00%, Valid: 59.81% Test: 57.24%\n",
      "Run: 03, Epoch: 128, Loss: 1.0478, Train: 57.97%, Valid: 56.10% Test: 51.97%\n",
      "Run: 03, Epoch: 129, Loss: 1.0739, Train: 58.79%, Valid: 57.34% Test: 53.51%\n",
      "Run: 03, Epoch: 130, Loss: 1.0557, Train: 60.53%, Valid: 61.87% Test: 56.80%\n",
      "Run: 03, Epoch: 131, Loss: 1.0542, Train: 59.52%, Valid: 61.45% Test: 56.36%\n",
      "Run: 03, Epoch: 132, Loss: 1.0469, Train: 58.24%, Valid: 61.18% Test: 57.46%\n",
      "Run: 03, Epoch: 133, Loss: 1.0595, Train: 55.40%, Valid: 55.14% Test: 51.97%\n",
      "Run: 03, Epoch: 134, Loss: 1.0584, Train: 56.78%, Valid: 57.61% Test: 54.39%\n",
      "Run: 03, Epoch: 135, Loss: 1.0859, Train: 60.07%, Valid: 58.98% Test: 56.80%\n",
      "Run: 03, Epoch: 136, Loss: 1.0521, Train: 59.52%, Valid: 59.12% Test: 55.92%\n",
      "Run: 03, Epoch: 137, Loss: 1.0417, Train: 61.54%, Valid: 61.45% Test: 57.68%\n",
      "Run: 03, Epoch: 138, Loss: 1.0663, Train: 59.80%, Valid: 60.77% Test: 55.04%\n",
      "Run: 03, Epoch: 139, Loss: 1.0523, Train: 57.88%, Valid: 59.12% Test: 53.73%\n",
      "Run: 03, Epoch: 140, Loss: 1.0660, Train: 59.71%, Valid: 57.75% Test: 56.14%\n",
      "Run: 03, Epoch: 141, Loss: 1.0980, Train: 59.34%, Valid: 56.79% Test: 54.82%\n",
      "Run: 03, Epoch: 142, Loss: 1.0929, Train: 59.89%, Valid: 62.00% Test: 58.11%\n",
      "Run: 03, Epoch: 143, Loss: 1.0707, Train: 59.25%, Valid: 59.40% Test: 52.85%\n",
      "Run: 03, Epoch: 144, Loss: 1.0503, Train: 60.81%, Valid: 61.04% Test: 54.82%\n",
      "Run: 03, Epoch: 145, Loss: 1.0542, Train: 61.45%, Valid: 59.95% Test: 57.89%\n",
      "Run: 03, Epoch: 146, Loss: 1.0548, Train: 57.51%, Valid: 55.97% Test: 55.04%\n",
      "Run: 03, Epoch: 147, Loss: 1.0596, Train: 57.97%, Valid: 55.97% Test: 53.51%\n",
      "Run: 03, Epoch: 148, Loss: 1.0519, Train: 58.52%, Valid: 56.10% Test: 54.17%\n",
      "Run: 03, Epoch: 149, Loss: 1.0525, Train: 58.33%, Valid: 56.65% Test: 55.26%\n",
      "Run: 03, Epoch: 150, Loss: 1.0377, Train: 54.95%, Valid: 51.17% Test: 49.56%\n",
      "Run: 03, Epoch: 151, Loss: 1.0669, Train: 58.70%, Valid: 54.87% Test: 53.95%\n",
      "Run: 03, Epoch: 152, Loss: 1.0260, Train: 60.62%, Valid: 58.16% Test: 55.70%\n",
      "Run: 03, Epoch: 153, Loss: 1.0401, Train: 62.45%, Valid: 62.69% Test: 56.80%\n",
      "Run: 03, Epoch: 154, Loss: 1.0611, Train: 60.53%, Valid: 61.32% Test: 53.29%\n",
      "Run: 03, Epoch: 155, Loss: 1.0490, Train: 59.52%, Valid: 59.81% Test: 54.61%\n",
      "Run: 03, Epoch: 156, Loss: 1.0734, Train: 59.98%, Valid: 59.81% Test: 55.92%\n",
      "Run: 03, Epoch: 157, Loss: 1.0324, Train: 61.08%, Valid: 59.53% Test: 57.02%\n",
      "Run: 03, Epoch: 158, Loss: 1.0448, Train: 58.42%, Valid: 55.01% Test: 53.29%\n",
      "Run: 03, Epoch: 159, Loss: 1.0377, Train: 59.89%, Valid: 59.12% Test: 55.70%\n",
      "Run: 03, Epoch: 160, Loss: 1.0296, Train: 58.42%, Valid: 57.89% Test: 53.07%\n",
      "Run: 03, Epoch: 161, Loss: 1.0334, Train: 56.32%, Valid: 53.50% Test: 51.97%\n",
      "Run: 03, Epoch: 162, Loss: 1.0335, Train: 59.16%, Valid: 55.56% Test: 56.14%\n",
      "Run: 03, Epoch: 163, Loss: 1.0441, Train: 60.81%, Valid: 61.04% Test: 56.58%\n",
      "Run: 03, Epoch: 164, Loss: 1.0417, Train: 59.25%, Valid: 58.16% Test: 56.58%\n",
      "Run: 03, Epoch: 165, Loss: 1.0351, Train: 54.21%, Valid: 49.93% Test: 52.19%\n",
      "Run: 03, Epoch: 166, Loss: 1.0492, Train: 55.49%, Valid: 52.81% Test: 51.97%\n",
      "Run: 03, Epoch: 167, Loss: 1.0321, Train: 55.49%, Valid: 55.28% Test: 54.39%\n",
      "Run: 03, Epoch: 168, Loss: 1.0462, Train: 59.43%, Valid: 56.52% Test: 53.51%\n",
      "Run: 03, Epoch: 169, Loss: 1.0389, Train: 59.98%, Valid: 59.95% Test: 54.39%\n",
      "Run: 03, Epoch: 170, Loss: 1.0479, Train: 59.16%, Valid: 58.71% Test: 55.70%\n",
      "Run: 03, Epoch: 171, Loss: 1.0464, Train: 56.96%, Valid: 55.42% Test: 54.39%\n",
      "Run: 03, Epoch: 172, Loss: 1.0709, Train: 57.14%, Valid: 56.93% Test: 51.97%\n",
      "Run: 03, Epoch: 173, Loss: 1.0301, Train: 59.16%, Valid: 59.26% Test: 51.97%\n",
      "Run: 03, Epoch: 174, Loss: 1.0505, Train: 59.98%, Valid: 61.04% Test: 54.61%\n",
      "Run: 03, Epoch: 175, Loss: 1.0215, Train: 61.72%, Valid: 61.73% Test: 57.89%\n",
      "Run: 03, Epoch: 176, Loss: 1.0492, Train: 54.21%, Valid: 53.22% Test: 53.51%\n",
      "Run: 03, Epoch: 177, Loss: 1.0490, Train: 54.21%, Valid: 52.40% Test: 53.51%\n",
      "Run: 03, Epoch: 178, Loss: 1.0339, Train: 61.45%, Valid: 59.26% Test: 59.65%\n",
      "Run: 03, Epoch: 179, Loss: 1.0599, Train: 61.45%, Valid: 61.04% Test: 57.89%\n",
      "Run: 03, Epoch: 180, Loss: 1.0413, Train: 57.97%, Valid: 58.98% Test: 54.61%\n",
      "Run: 03, Epoch: 181, Loss: 1.0416, Train: 59.25%, Valid: 60.49% Test: 55.04%\n",
      "Run: 03, Epoch: 182, Loss: 1.0421, Train: 59.80%, Valid: 61.04% Test: 55.48%\n",
      "Run: 03, Epoch: 183, Loss: 1.0425, Train: 59.34%, Valid: 58.71% Test: 57.02%\n",
      "Run: 03, Epoch: 184, Loss: 1.0443, Train: 55.86%, Valid: 51.85% Test: 52.19%\n",
      "Run: 03, Epoch: 185, Loss: 1.0735, Train: 57.88%, Valid: 55.28% Test: 54.61%\n",
      "Run: 03, Epoch: 186, Loss: 1.0926, Train: 56.50%, Valid: 56.38% Test: 50.66%\n",
      "Run: 03, Epoch: 187, Loss: 1.1052, Train: 59.16%, Valid: 58.98% Test: 54.39%\n",
      "Run: 03, Epoch: 188, Loss: 1.0376, Train: 56.50%, Valid: 58.57% Test: 53.95%\n",
      "Run: 03, Epoch: 189, Loss: 1.0467, Train: 54.95%, Valid: 56.24% Test: 53.73%\n",
      "Run: 03, Epoch: 190, Loss: 1.0767, Train: 57.51%, Valid: 58.57% Test: 54.17%\n",
      "Run: 03, Epoch: 191, Loss: 1.0452, Train: 57.51%, Valid: 59.26% Test: 50.88%\n",
      "Run: 03, Epoch: 192, Loss: 1.0562, Train: 61.45%, Valid: 61.18% Test: 56.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 193, Loss: 1.0571, Train: 60.99%, Valid: 61.04% Test: 55.92%\n",
      "Run: 03, Epoch: 194, Loss: 1.0351, Train: 57.23%, Valid: 58.02% Test: 54.82%\n",
      "Run: 03, Epoch: 195, Loss: 1.0488, Train: 60.44%, Valid: 60.91% Test: 54.61%\n",
      "Run: 03, Epoch: 196, Loss: 1.0604, Train: 59.43%, Valid: 58.98% Test: 55.26%\n",
      "Run: 03, Epoch: 197, Loss: 1.0402, Train: 58.70%, Valid: 59.12% Test: 54.82%\n",
      "Run: 03, Epoch: 198, Loss: 1.0474, Train: 60.81%, Valid: 60.91% Test: 57.02%\n",
      "Run: 03, Epoch: 199, Loss: 1.0515, Train: 60.07%, Valid: 61.18% Test: 56.80%\n",
      "Run: 03, Epoch: 200, Loss: 1.0511, Train: 58.06%, Valid: 59.40% Test: 52.85%\n",
      "Run 03:\n",
      "Highest Train: 62.45\n",
      "Highest Valid: 62.69\n",
      "  Final Train: 62.45\n",
      "   Final Test: 56.80\n",
      "Run: 04, Epoch: 01, Loss: 2.2911, Train: 23.44%, Valid: 22.91% Test: 21.49%\n",
      "Run: 04, Epoch: 02, Loss: 1.4849, Train: 20.79%, Valid: 21.12% Test: 22.15%\n",
      "Run: 04, Epoch: 03, Loss: 1.4541, Train: 22.62%, Valid: 24.28% Test: 24.34%\n",
      "Run: 04, Epoch: 04, Loss: 1.4768, Train: 35.16%, Valid: 34.29% Test: 35.31%\n",
      "Run: 04, Epoch: 05, Loss: 1.4236, Train: 38.28%, Valid: 36.63% Test: 38.38%\n",
      "Run: 04, Epoch: 06, Loss: 1.3618, Train: 34.52%, Valid: 35.39% Test: 34.65%\n",
      "Run: 04, Epoch: 07, Loss: 1.3665, Train: 40.66%, Valid: 41.70% Test: 44.96%\n",
      "Run: 04, Epoch: 08, Loss: 1.3321, Train: 39.84%, Valid: 40.60% Test: 42.32%\n",
      "Run: 04, Epoch: 09, Loss: 1.2917, Train: 36.08%, Valid: 36.76% Test: 35.31%\n",
      "Run: 04, Epoch: 10, Loss: 1.2907, Train: 35.99%, Valid: 33.20% Test: 31.80%\n",
      "Run: 04, Epoch: 11, Loss: 1.3312, Train: 39.93%, Valid: 37.17% Test: 37.50%\n",
      "Run: 04, Epoch: 12, Loss: 1.2758, Train: 45.24%, Valid: 41.02% Test: 41.45%\n",
      "Run: 04, Epoch: 13, Loss: 1.3227, Train: 47.16%, Valid: 43.90% Test: 45.61%\n",
      "Run: 04, Epoch: 14, Loss: 1.2946, Train: 42.49%, Valid: 40.47% Test: 42.32%\n",
      "Run: 04, Epoch: 15, Loss: 1.3015, Train: 41.21%, Valid: 38.27% Test: 41.89%\n",
      "Run: 04, Epoch: 16, Loss: 1.2637, Train: 40.84%, Valid: 38.96% Test: 40.57%\n",
      "Run: 04, Epoch: 17, Loss: 1.3175, Train: 44.87%, Valid: 41.43% Test: 44.08%\n",
      "Run: 04, Epoch: 18, Loss: 1.2465, Train: 44.87%, Valid: 41.84% Test: 46.93%\n",
      "Run: 04, Epoch: 19, Loss: 1.2562, Train: 45.97%, Valid: 43.90% Test: 47.81%\n",
      "Run: 04, Epoch: 20, Loss: 1.2693, Train: 46.06%, Valid: 44.31% Test: 47.81%\n",
      "Run: 04, Epoch: 21, Loss: 1.2662, Train: 46.15%, Valid: 45.40% Test: 47.59%\n",
      "Run: 04, Epoch: 22, Loss: 1.2481, Train: 45.15%, Valid: 45.27% Test: 42.54%\n",
      "Run: 04, Epoch: 23, Loss: 1.2318, Train: 41.94%, Valid: 42.39% Test: 43.42%\n",
      "Run: 04, Epoch: 24, Loss: 1.2372, Train: 46.79%, Valid: 46.23% Test: 49.34%\n",
      "Run: 04, Epoch: 25, Loss: 1.2082, Train: 48.53%, Valid: 49.66% Test: 49.34%\n",
      "Run: 04, Epoch: 26, Loss: 1.2085, Train: 46.61%, Valid: 48.70% Test: 48.03%\n",
      "Run: 04, Epoch: 27, Loss: 1.2185, Train: 41.39%, Valid: 43.90% Test: 43.86%\n",
      "Run: 04, Epoch: 28, Loss: 1.2054, Train: 44.05%, Valid: 43.35% Test: 43.64%\n",
      "Run: 04, Epoch: 29, Loss: 1.2008, Train: 44.60%, Valid: 46.23% Test: 45.39%\n",
      "Run: 04, Epoch: 30, Loss: 1.2087, Train: 49.91%, Valid: 51.71% Test: 48.90%\n",
      "Run: 04, Epoch: 31, Loss: 1.1912, Train: 52.29%, Valid: 51.71% Test: 51.75%\n",
      "Run: 04, Epoch: 32, Loss: 1.1700, Train: 49.73%, Valid: 49.66% Test: 47.37%\n",
      "Run: 04, Epoch: 33, Loss: 1.1893, Train: 44.96%, Valid: 47.46% Test: 44.52%\n",
      "Run: 04, Epoch: 34, Loss: 1.1658, Train: 50.64%, Valid: 52.95% Test: 48.46%\n",
      "Run: 04, Epoch: 35, Loss: 1.1653, Train: 44.60%, Valid: 44.72% Test: 45.61%\n",
      "Run: 04, Epoch: 36, Loss: 1.2011, Train: 48.81%, Valid: 51.71% Test: 50.22%\n",
      "Run: 04, Epoch: 37, Loss: 1.1582, Train: 40.48%, Valid: 42.11% Test: 41.67%\n",
      "Run: 04, Epoch: 38, Loss: 1.1677, Train: 47.80%, Valid: 49.38% Test: 50.22%\n",
      "Run: 04, Epoch: 39, Loss: 1.1820, Train: 47.07%, Valid: 46.64% Test: 48.68%\n",
      "Run: 04, Epoch: 40, Loss: 1.1542, Train: 55.13%, Valid: 55.83% Test: 51.97%\n",
      "Run: 04, Epoch: 41, Loss: 1.1918, Train: 49.73%, Valid: 49.66% Test: 51.54%\n",
      "Run: 04, Epoch: 42, Loss: 1.1574, Train: 52.01%, Valid: 52.95% Test: 50.88%\n",
      "Run: 04, Epoch: 43, Loss: 1.1466, Train: 47.99%, Valid: 47.05% Test: 48.68%\n",
      "Run: 04, Epoch: 44, Loss: 1.1869, Train: 40.11%, Valid: 39.92% Test: 39.69%\n",
      "Run: 04, Epoch: 45, Loss: 1.1487, Train: 36.45%, Valid: 36.63% Test: 36.84%\n",
      "Run: 04, Epoch: 46, Loss: 1.1606, Train: 39.47%, Valid: 39.23% Test: 40.35%\n",
      "Run: 04, Epoch: 47, Loss: 1.1372, Train: 49.54%, Valid: 49.25% Test: 49.34%\n",
      "Run: 04, Epoch: 48, Loss: 1.1398, Train: 48.53%, Valid: 47.87% Test: 47.59%\n",
      "Run: 04, Epoch: 49, Loss: 1.1251, Train: 47.89%, Valid: 48.83% Test: 48.90%\n",
      "Run: 04, Epoch: 50, Loss: 1.1409, Train: 50.73%, Valid: 51.17% Test: 48.25%\n",
      "Run: 04, Epoch: 51, Loss: 1.1123, Train: 47.89%, Valid: 48.83% Test: 47.15%\n",
      "Run: 04, Epoch: 52, Loss: 1.1392, Train: 45.79%, Valid: 45.68% Test: 42.54%\n",
      "Run: 04, Epoch: 53, Loss: 1.1269, Train: 45.05%, Valid: 46.50% Test: 42.54%\n",
      "Run: 04, Epoch: 54, Loss: 1.1028, Train: 47.07%, Valid: 48.97% Test: 44.96%\n",
      "Run: 04, Epoch: 55, Loss: 1.1216, Train: 51.56%, Valid: 51.85% Test: 50.44%\n",
      "Run: 04, Epoch: 56, Loss: 1.1051, Train: 50.37%, Valid: 50.89% Test: 50.00%\n",
      "Run: 04, Epoch: 57, Loss: 1.1072, Train: 50.27%, Valid: 50.21% Test: 48.90%\n",
      "Run: 04, Epoch: 58, Loss: 1.1121, Train: 50.55%, Valid: 52.54% Test: 50.44%\n",
      "Run: 04, Epoch: 59, Loss: 1.1080, Train: 54.21%, Valid: 53.64% Test: 52.19%\n",
      "Run: 04, Epoch: 60, Loss: 1.1160, Train: 55.22%, Valid: 55.97% Test: 55.70%\n",
      "Run: 04, Epoch: 61, Loss: 1.0852, Train: 54.40%, Valid: 54.87% Test: 52.85%\n",
      "Run: 04, Epoch: 62, Loss: 1.0872, Train: 52.38%, Valid: 53.22% Test: 51.97%\n",
      "Run: 04, Epoch: 63, Loss: 1.0965, Train: 55.77%, Valid: 55.42% Test: 54.17%\n",
      "Run: 04, Epoch: 64, Loss: 1.0690, Train: 53.11%, Valid: 51.85% Test: 50.22%\n",
      "Run: 04, Epoch: 65, Loss: 1.1408, Train: 57.51%, Valid: 58.30% Test: 55.48%\n",
      "Run: 04, Epoch: 66, Loss: 1.0902, Train: 54.21%, Valid: 54.32% Test: 53.29%\n",
      "Run: 04, Epoch: 67, Loss: 1.1034, Train: 52.84%, Valid: 51.85% Test: 51.32%\n",
      "Run: 04, Epoch: 68, Loss: 1.0944, Train: 55.95%, Valid: 55.56% Test: 54.61%\n",
      "Run: 04, Epoch: 69, Loss: 1.0946, Train: 56.04%, Valid: 57.20% Test: 56.14%\n",
      "Run: 04, Epoch: 70, Loss: 1.0982, Train: 58.06%, Valid: 58.02% Test: 55.26%\n",
      "Run: 04, Epoch: 71, Loss: 1.0668, Train: 52.20%, Valid: 52.54% Test: 48.90%\n",
      "Run: 04, Epoch: 72, Loss: 1.1201, Train: 56.78%, Valid: 54.87% Test: 55.26%\n",
      "Run: 04, Epoch: 73, Loss: 1.1027, Train: 56.87%, Valid: 55.14% Test: 53.95%\n",
      "Run: 04, Epoch: 74, Loss: 1.0919, Train: 55.68%, Valid: 54.73% Test: 51.75%\n",
      "Run: 04, Epoch: 75, Loss: 1.0901, Train: 55.04%, Valid: 53.09% Test: 55.48%\n",
      "Run: 04, Epoch: 76, Loss: 1.0952, Train: 56.04%, Valid: 54.32% Test: 54.82%\n",
      "Run: 04, Epoch: 77, Loss: 1.0742, Train: 51.10%, Valid: 50.62% Test: 51.97%\n",
      "Run: 04, Epoch: 78, Loss: 1.0743, Train: 53.30%, Valid: 51.58% Test: 50.66%\n",
      "Run: 04, Epoch: 79, Loss: 1.1298, Train: 51.83%, Valid: 50.89% Test: 51.54%\n",
      "Run: 04, Epoch: 80, Loss: 1.0567, Train: 53.30%, Valid: 51.44% Test: 52.85%\n",
      "Run: 04, Epoch: 81, Loss: 1.0745, Train: 55.95%, Valid: 54.32% Test: 54.82%\n",
      "Run: 04, Epoch: 82, Loss: 1.0632, Train: 59.62%, Valid: 57.61% Test: 56.58%\n",
      "Run: 04, Epoch: 83, Loss: 1.0542, Train: 57.88%, Valid: 57.48% Test: 55.04%\n",
      "Run: 04, Epoch: 84, Loss: 1.0877, Train: 58.61%, Valid: 57.89% Test: 55.92%\n",
      "Run: 04, Epoch: 85, Loss: 1.0770, Train: 53.75%, Valid: 54.18% Test: 52.85%\n",
      "Run: 04, Epoch: 86, Loss: 1.1093, Train: 56.14%, Valid: 54.60% Test: 57.02%\n",
      "Run: 04, Epoch: 87, Loss: 1.0922, Train: 58.06%, Valid: 56.10% Test: 55.92%\n",
      "Run: 04, Epoch: 88, Loss: 1.0971, Train: 55.04%, Valid: 54.18% Test: 54.82%\n",
      "Run: 04, Epoch: 89, Loss: 1.0884, Train: 52.20%, Valid: 51.85% Test: 51.54%\n",
      "Run: 04, Epoch: 90, Loss: 1.0701, Train: 53.39%, Valid: 53.22% Test: 50.66%\n",
      "Run: 04, Epoch: 91, Loss: 1.1001, Train: 57.78%, Valid: 55.83% Test: 54.39%\n",
      "Run: 04, Epoch: 92, Loss: 1.0934, Train: 55.86%, Valid: 56.65% Test: 52.85%\n",
      "Run: 04, Epoch: 93, Loss: 1.1119, Train: 55.13%, Valid: 55.56% Test: 52.41%\n",
      "Run: 04, Epoch: 94, Loss: 1.0902, Train: 49.45%, Valid: 49.66% Test: 46.05%\n",
      "Run: 04, Epoch: 95, Loss: 1.0966, Train: 51.28%, Valid: 51.58% Test: 48.25%\n",
      "Run: 04, Epoch: 96, Loss: 1.0874, Train: 55.31%, Valid: 53.50% Test: 54.17%\n",
      "Run: 04, Epoch: 97, Loss: 1.1181, Train: 56.59%, Valid: 56.10% Test: 57.24%\n",
      "Run: 04, Epoch: 98, Loss: 1.1007, Train: 55.04%, Valid: 54.73% Test: 57.46%\n",
      "Run: 04, Epoch: 99, Loss: 1.0719, Train: 57.05%, Valid: 54.87% Test: 56.80%\n",
      "Run: 04, Epoch: 100, Loss: 1.0811, Train: 55.77%, Valid: 54.87% Test: 52.63%\n",
      "Run: 04, Epoch: 101, Loss: 1.0661, Train: 57.88%, Valid: 58.44% Test: 54.61%\n",
      "Run: 04, Epoch: 102, Loss: 1.0936, Train: 58.52%, Valid: 60.22% Test: 57.02%\n",
      "Run: 04, Epoch: 103, Loss: 1.0623, Train: 58.42%, Valid: 59.12% Test: 57.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 104, Loss: 1.0818, Train: 60.26%, Valid: 55.69% Test: 57.46%\n",
      "Run: 04, Epoch: 105, Loss: 1.0882, Train: 60.53%, Valid: 57.48% Test: 58.33%\n",
      "Run: 04, Epoch: 106, Loss: 1.0832, Train: 58.42%, Valid: 56.52% Test: 56.58%\n",
      "Run: 04, Epoch: 107, Loss: 1.0856, Train: 59.71%, Valid: 56.65% Test: 60.09%\n",
      "Run: 04, Epoch: 108, Loss: 1.0800, Train: 60.99%, Valid: 58.30% Test: 59.87%\n",
      "Run: 04, Epoch: 109, Loss: 1.0660, Train: 59.34%, Valid: 59.12% Test: 57.02%\n",
      "Run: 04, Epoch: 110, Loss: 1.0871, Train: 56.41%, Valid: 57.20% Test: 53.29%\n",
      "Run: 04, Epoch: 111, Loss: 1.1179, Train: 58.97%, Valid: 59.26% Test: 57.68%\n",
      "Run: 04, Epoch: 112, Loss: 1.0716, Train: 56.32%, Valid: 53.91% Test: 54.61%\n",
      "Run: 04, Epoch: 113, Loss: 1.0566, Train: 56.68%, Valid: 56.65% Test: 55.04%\n",
      "Run: 04, Epoch: 114, Loss: 1.0513, Train: 54.85%, Valid: 54.87% Test: 54.39%\n",
      "Run: 04, Epoch: 115, Loss: 1.0534, Train: 54.40%, Valid: 55.42% Test: 54.82%\n",
      "Run: 04, Epoch: 116, Loss: 1.0705, Train: 53.48%, Valid: 50.89% Test: 55.04%\n",
      "Run: 04, Epoch: 117, Loss: 1.0765, Train: 56.87%, Valid: 56.10% Test: 53.51%\n",
      "Run: 04, Epoch: 118, Loss: 1.0494, Train: 58.70%, Valid: 57.61% Test: 55.92%\n",
      "Run: 04, Epoch: 119, Loss: 1.1181, Train: 57.42%, Valid: 54.32% Test: 58.33%\n",
      "Run: 04, Epoch: 120, Loss: 1.0443, Train: 55.59%, Valid: 53.22% Test: 55.26%\n",
      "Run: 04, Epoch: 121, Loss: 1.0780, Train: 60.71%, Valid: 58.02% Test: 58.11%\n",
      "Run: 04, Epoch: 122, Loss: 1.0930, Train: 58.24%, Valid: 59.81% Test: 57.46%\n",
      "Run: 04, Epoch: 123, Loss: 1.0447, Train: 58.97%, Valid: 57.48% Test: 56.36%\n",
      "Run: 04, Epoch: 124, Loss: 1.0331, Train: 54.12%, Valid: 51.03% Test: 54.17%\n",
      "Run: 04, Epoch: 125, Loss: 1.0603, Train: 53.11%, Valid: 51.71% Test: 52.41%\n",
      "Run: 04, Epoch: 126, Loss: 1.0622, Train: 59.43%, Valid: 60.91% Test: 58.33%\n",
      "Run: 04, Epoch: 127, Loss: 1.0443, Train: 58.24%, Valid: 58.44% Test: 56.58%\n",
      "Run: 04, Epoch: 128, Loss: 1.0845, Train: 60.81%, Valid: 60.49% Test: 59.21%\n",
      "Run: 04, Epoch: 129, Loss: 1.0469, Train: 59.80%, Valid: 58.16% Test: 57.24%\n",
      "Run: 04, Epoch: 130, Loss: 1.0600, Train: 58.15%, Valid: 56.79% Test: 57.02%\n",
      "Run: 04, Epoch: 131, Loss: 1.0335, Train: 60.81%, Valid: 59.81% Test: 57.46%\n",
      "Run: 04, Epoch: 132, Loss: 1.0525, Train: 59.71%, Valid: 59.53% Test: 58.11%\n",
      "Run: 04, Epoch: 133, Loss: 1.0788, Train: 58.42%, Valid: 54.46% Test: 57.68%\n",
      "Run: 04, Epoch: 134, Loss: 1.0370, Train: 56.68%, Valid: 52.95% Test: 55.92%\n",
      "Run: 04, Epoch: 135, Loss: 1.0642, Train: 60.81%, Valid: 58.98% Test: 56.80%\n",
      "Run: 04, Epoch: 136, Loss: 1.0432, Train: 58.61%, Valid: 58.02% Test: 54.39%\n",
      "Run: 04, Epoch: 137, Loss: 1.0600, Train: 53.39%, Valid: 51.44% Test: 51.97%\n",
      "Run: 04, Epoch: 138, Loss: 1.0579, Train: 62.55%, Valid: 61.18% Test: 58.11%\n",
      "Run: 04, Epoch: 139, Loss: 1.0331, Train: 61.17%, Valid: 60.08% Test: 59.21%\n",
      "Run: 04, Epoch: 140, Loss: 1.0496, Train: 62.27%, Valid: 58.44% Test: 61.84%\n",
      "Run: 04, Epoch: 141, Loss: 1.0422, Train: 63.92%, Valid: 62.00% Test: 59.65%\n",
      "Run: 04, Epoch: 142, Loss: 1.0290, Train: 63.46%, Valid: 61.59% Test: 60.31%\n",
      "Run: 04, Epoch: 143, Loss: 1.0412, Train: 59.98%, Valid: 58.85% Test: 59.43%\n",
      "Run: 04, Epoch: 144, Loss: 1.0197, Train: 60.81%, Valid: 61.32% Test: 58.33%\n",
      "Run: 04, Epoch: 145, Loss: 1.0313, Train: 59.71%, Valid: 61.32% Test: 59.87%\n",
      "Run: 04, Epoch: 146, Loss: 1.0277, Train: 61.90%, Valid: 60.08% Test: 58.99%\n",
      "Run: 04, Epoch: 147, Loss: 1.0440, Train: 60.16%, Valid: 57.48% Test: 57.68%\n",
      "Run: 04, Epoch: 148, Loss: 1.0285, Train: 62.91%, Valid: 59.53% Test: 59.65%\n",
      "Run: 04, Epoch: 149, Loss: 1.0420, Train: 62.00%, Valid: 60.77% Test: 60.09%\n",
      "Run: 04, Epoch: 150, Loss: 1.0278, Train: 62.73%, Valid: 61.45% Test: 60.96%\n",
      "Run: 04, Epoch: 151, Loss: 1.0299, Train: 63.10%, Valid: 60.77% Test: 62.06%\n",
      "Run: 04, Epoch: 152, Loss: 1.0167, Train: 64.01%, Valid: 61.45% Test: 61.62%\n",
      "Run: 04, Epoch: 153, Loss: 1.0047, Train: 63.64%, Valid: 63.51% Test: 62.72%\n",
      "Run: 04, Epoch: 154, Loss: 1.0252, Train: 63.28%, Valid: 63.79% Test: 62.50%\n",
      "Run: 04, Epoch: 155, Loss: 1.0494, Train: 63.92%, Valid: 62.14% Test: 61.18%\n",
      "Run: 04, Epoch: 156, Loss: 1.0184, Train: 64.19%, Valid: 59.12% Test: 62.06%\n",
      "Run: 04, Epoch: 157, Loss: 1.0148, Train: 63.10%, Valid: 60.08% Test: 60.53%\n",
      "Run: 04, Epoch: 158, Loss: 1.0172, Train: 63.37%, Valid: 60.63% Test: 59.87%\n",
      "Run: 04, Epoch: 159, Loss: 1.0094, Train: 62.64%, Valid: 58.02% Test: 59.87%\n",
      "Run: 04, Epoch: 160, Loss: 1.0033, Train: 62.27%, Valid: 57.75% Test: 58.33%\n",
      "Run: 04, Epoch: 161, Loss: 1.0193, Train: 62.27%, Valid: 59.53% Test: 57.24%\n",
      "Run: 04, Epoch: 162, Loss: 1.0178, Train: 60.62%, Valid: 58.98% Test: 56.36%\n",
      "Run: 04, Epoch: 163, Loss: 1.0020, Train: 63.00%, Valid: 60.36% Test: 57.68%\n",
      "Run: 04, Epoch: 164, Loss: 1.0048, Train: 62.45%, Valid: 61.59% Test: 58.77%\n",
      "Run: 04, Epoch: 165, Loss: 1.0134, Train: 63.10%, Valid: 60.77% Test: 58.99%\n",
      "Run: 04, Epoch: 166, Loss: 0.9931, Train: 64.01%, Valid: 59.67% Test: 58.55%\n",
      "Run: 04, Epoch: 167, Loss: 0.9987, Train: 64.47%, Valid: 61.59% Test: 58.33%\n",
      "Run: 04, Epoch: 168, Loss: 1.0273, Train: 63.28%, Valid: 61.18% Test: 56.58%\n",
      "Run: 04, Epoch: 169, Loss: 1.0048, Train: 61.90%, Valid: 58.71% Test: 56.36%\n",
      "Run: 04, Epoch: 170, Loss: 0.9977, Train: 63.92%, Valid: 60.91% Test: 59.43%\n",
      "Run: 04, Epoch: 171, Loss: 1.0060, Train: 64.19%, Valid: 59.95% Test: 58.33%\n",
      "Run: 04, Epoch: 172, Loss: 1.0011, Train: 62.91%, Valid: 59.95% Test: 57.68%\n",
      "Run: 04, Epoch: 173, Loss: 1.0152, Train: 64.93%, Valid: 63.10% Test: 59.43%\n",
      "Run: 04, Epoch: 174, Loss: 1.0099, Train: 65.02%, Valid: 62.96% Test: 58.99%\n",
      "Run: 04, Epoch: 175, Loss: 1.0160, Train: 64.56%, Valid: 61.32% Test: 58.55%\n",
      "Run: 04, Epoch: 176, Loss: 0.9880, Train: 63.37%, Valid: 62.14% Test: 60.53%\n",
      "Run: 04, Epoch: 177, Loss: 1.0051, Train: 63.83%, Valid: 62.00% Test: 60.53%\n",
      "Run: 04, Epoch: 178, Loss: 0.9943, Train: 62.82%, Valid: 59.67% Test: 60.09%\n",
      "Run: 04, Epoch: 179, Loss: 1.0044, Train: 65.11%, Valid: 61.73% Test: 60.53%\n",
      "Run: 04, Epoch: 180, Loss: 0.9902, Train: 65.57%, Valid: 62.00% Test: 61.18%\n",
      "Run: 04, Epoch: 181, Loss: 1.0319, Train: 65.29%, Valid: 60.22% Test: 60.31%\n",
      "Run: 04, Epoch: 182, Loss: 0.9823, Train: 63.19%, Valid: 58.57% Test: 60.31%\n",
      "Run: 04, Epoch: 183, Loss: 0.9874, Train: 63.55%, Valid: 61.59% Test: 58.77%\n",
      "Run: 04, Epoch: 184, Loss: 0.9910, Train: 62.64%, Valid: 61.04% Test: 57.89%\n",
      "Run: 04, Epoch: 185, Loss: 1.0222, Train: 60.07%, Valid: 56.24% Test: 58.11%\n",
      "Run: 04, Epoch: 186, Loss: 1.0049, Train: 61.17%, Valid: 56.52% Test: 59.43%\n",
      "Run: 04, Epoch: 187, Loss: 0.9884, Train: 63.74%, Valid: 62.00% Test: 59.43%\n",
      "Run: 04, Epoch: 188, Loss: 0.9821, Train: 62.18%, Valid: 57.34% Test: 59.65%\n",
      "Run: 04, Epoch: 189, Loss: 0.9952, Train: 61.90%, Valid: 57.06% Test: 59.65%\n",
      "Run: 04, Epoch: 190, Loss: 1.0136, Train: 64.38%, Valid: 62.55% Test: 61.18%\n",
      "Run: 04, Epoch: 191, Loss: 0.9964, Train: 64.10%, Valid: 62.69% Test: 60.75%\n",
      "Run: 04, Epoch: 192, Loss: 0.9937, Train: 64.29%, Valid: 62.14% Test: 58.11%\n",
      "Run: 04, Epoch: 193, Loss: 0.9873, Train: 65.02%, Valid: 59.40% Test: 62.06%\n",
      "Run: 04, Epoch: 194, Loss: 0.9920, Train: 65.38%, Valid: 60.49% Test: 62.72%\n",
      "Run: 04, Epoch: 195, Loss: 0.9698, Train: 64.10%, Valid: 60.91% Test: 58.99%\n",
      "Run: 04, Epoch: 196, Loss: 1.0053, Train: 55.31%, Valid: 54.87% Test: 53.95%\n",
      "Run: 04, Epoch: 197, Loss: 1.0140, Train: 61.26%, Valid: 59.40% Test: 54.61%\n",
      "Run: 04, Epoch: 198, Loss: 0.9927, Train: 63.19%, Valid: 61.59% Test: 59.21%\n",
      "Run: 04, Epoch: 199, Loss: 1.0009, Train: 65.75%, Valid: 61.87% Test: 61.40%\n",
      "Run: 04, Epoch: 200, Loss: 1.0001, Train: 64.65%, Valid: 61.59% Test: 61.40%\n",
      "Run 04:\n",
      "Highest Train: 65.75\n",
      "Highest Valid: 63.79\n",
      "  Final Train: 63.28\n",
      "   Final Test: 62.50\n",
      "Run: 05, Epoch: 01, Loss: 1.7883, Train: 23.44%, Valid: 24.97% Test: 26.75%\n",
      "Run: 05, Epoch: 02, Loss: 1.4278, Train: 27.11%, Valid: 23.87% Test: 23.90%\n",
      "Run: 05, Epoch: 03, Loss: 1.4092, Train: 22.71%, Valid: 20.30% Test: 19.96%\n",
      "Run: 05, Epoch: 04, Loss: 1.4530, Train: 37.18%, Valid: 36.76% Test: 36.40%\n",
      "Run: 05, Epoch: 05, Loss: 1.3901, Train: 32.05%, Valid: 32.37% Test: 32.24%\n",
      "Run: 05, Epoch: 06, Loss: 1.3673, Train: 34.07%, Valid: 35.80% Test: 36.84%\n",
      "Run: 05, Epoch: 07, Loss: 1.3185, Train: 37.55%, Valid: 36.90% Test: 35.75%\n",
      "Run: 05, Epoch: 08, Loss: 1.3415, Train: 32.23%, Valid: 29.63% Test: 32.24%\n",
      "Run: 05, Epoch: 09, Loss: 1.3259, Train: 38.46%, Valid: 33.74% Test: 36.40%\n",
      "Run: 05, Epoch: 10, Loss: 1.3220, Train: 44.05%, Valid: 42.25% Test: 41.45%\n",
      "Run: 05, Epoch: 11, Loss: 1.3077, Train: 39.19%, Valid: 37.04% Test: 33.77%\n",
      "Run: 05, Epoch: 12, Loss: 1.3511, Train: 45.60%, Valid: 44.17% Test: 41.45%\n",
      "Run: 05, Epoch: 13, Loss: 1.2785, Train: 43.13%, Valid: 41.84% Test: 42.98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 14, Loss: 1.2610, Train: 41.67%, Valid: 40.47% Test: 43.42%\n",
      "Run: 05, Epoch: 15, Loss: 1.2855, Train: 46.52%, Valid: 45.95% Test: 47.81%\n",
      "Run: 05, Epoch: 16, Loss: 1.2572, Train: 48.90%, Valid: 46.64% Test: 46.05%\n",
      "Run: 05, Epoch: 17, Loss: 1.2709, Train: 48.63%, Valid: 45.68% Test: 46.27%\n",
      "Run: 05, Epoch: 18, Loss: 1.2527, Train: 44.32%, Valid: 42.25% Test: 43.42%\n",
      "Run: 05, Epoch: 19, Loss: 1.2561, Train: 48.08%, Valid: 45.27% Test: 44.96%\n",
      "Run: 05, Epoch: 20, Loss: 1.2304, Train: 49.45%, Valid: 47.46% Test: 50.44%\n",
      "Run: 05, Epoch: 21, Loss: 1.2474, Train: 47.71%, Valid: 49.25% Test: 49.56%\n",
      "Run: 05, Epoch: 22, Loss: 1.2333, Train: 46.79%, Valid: 47.19% Test: 48.68%\n",
      "Run: 05, Epoch: 23, Loss: 1.2307, Train: 47.16%, Valid: 47.74% Test: 48.90%\n",
      "Run: 05, Epoch: 24, Loss: 1.1834, Train: 48.90%, Valid: 48.56% Test: 50.88%\n",
      "Run: 05, Epoch: 25, Loss: 1.1987, Train: 47.89%, Valid: 47.46% Test: 50.22%\n",
      "Run: 05, Epoch: 26, Loss: 1.1751, Train: 49.54%, Valid: 48.56% Test: 52.63%\n",
      "Run: 05, Epoch: 27, Loss: 1.2079, Train: 46.89%, Valid: 47.05% Test: 48.03%\n",
      "Run: 05, Epoch: 28, Loss: 1.1747, Train: 51.10%, Valid: 48.83% Test: 51.10%\n",
      "Run: 05, Epoch: 29, Loss: 1.1795, Train: 46.98%, Valid: 43.90% Test: 45.61%\n",
      "Run: 05, Epoch: 30, Loss: 1.2067, Train: 52.47%, Valid: 50.48% Test: 53.07%\n",
      "Run: 05, Epoch: 31, Loss: 1.1520, Train: 50.46%, Valid: 49.25% Test: 50.88%\n",
      "Run: 05, Epoch: 32, Loss: 1.1625, Train: 53.57%, Valid: 52.26% Test: 52.19%\n",
      "Run: 05, Epoch: 33, Loss: 1.1757, Train: 53.39%, Valid: 51.99% Test: 52.19%\n",
      "Run: 05, Epoch: 34, Loss: 1.1686, Train: 50.27%, Valid: 49.93% Test: 50.88%\n",
      "Run: 05, Epoch: 35, Loss: 1.1670, Train: 52.56%, Valid: 50.62% Test: 51.75%\n",
      "Run: 05, Epoch: 36, Loss: 1.1304, Train: 43.77%, Valid: 41.84% Test: 44.30%\n",
      "Run: 05, Epoch: 37, Loss: 1.1365, Train: 45.33%, Valid: 42.39% Test: 45.18%\n",
      "Run: 05, Epoch: 38, Loss: 1.1405, Train: 55.22%, Valid: 52.40% Test: 54.82%\n",
      "Run: 05, Epoch: 39, Loss: 1.1409, Train: 54.30%, Valid: 50.48% Test: 54.82%\n",
      "Run: 05, Epoch: 40, Loss: 1.1402, Train: 54.49%, Valid: 52.54% Test: 55.04%\n",
      "Run: 05, Epoch: 41, Loss: 1.1250, Train: 54.12%, Valid: 52.81% Test: 52.19%\n",
      "Run: 05, Epoch: 42, Loss: 1.1308, Train: 52.56%, Valid: 50.89% Test: 51.75%\n",
      "Run: 05, Epoch: 43, Loss: 1.1484, Train: 53.21%, Valid: 52.13% Test: 53.51%\n",
      "Run: 05, Epoch: 44, Loss: 1.1174, Train: 54.21%, Valid: 52.13% Test: 54.39%\n",
      "Run: 05, Epoch: 45, Loss: 1.1386, Train: 54.76%, Valid: 49.93% Test: 53.29%\n",
      "Run: 05, Epoch: 46, Loss: 1.0941, Train: 53.30%, Valid: 51.03% Test: 53.07%\n",
      "Run: 05, Epoch: 47, Loss: 1.1351, Train: 52.29%, Valid: 51.30% Test: 51.97%\n",
      "Run: 05, Epoch: 48, Loss: 1.0967, Train: 49.82%, Valid: 49.66% Test: 51.32%\n",
      "Run: 05, Epoch: 49, Loss: 1.1438, Train: 50.00%, Valid: 47.87% Test: 50.44%\n",
      "Run: 05, Epoch: 50, Loss: 1.1152, Train: 52.84%, Valid: 50.48% Test: 51.97%\n",
      "Run: 05, Epoch: 51, Loss: 1.0824, Train: 50.00%, Valid: 46.09% Test: 49.56%\n",
      "Run: 05, Epoch: 52, Loss: 1.1105, Train: 53.75%, Valid: 52.26% Test: 53.73%\n",
      "Run: 05, Epoch: 53, Loss: 1.0781, Train: 51.92%, Valid: 51.99% Test: 52.85%\n",
      "Run: 05, Epoch: 54, Loss: 1.0937, Train: 52.29%, Valid: 53.77% Test: 55.26%\n",
      "Run: 05, Epoch: 55, Loss: 1.1052, Train: 57.69%, Valid: 56.24% Test: 57.46%\n",
      "Run: 05, Epoch: 56, Loss: 1.0908, Train: 53.75%, Valid: 50.75% Test: 53.29%\n",
      "Run: 05, Epoch: 57, Loss: 1.0885, Train: 57.23%, Valid: 56.38% Test: 59.65%\n",
      "Run: 05, Epoch: 58, Loss: 1.0807, Train: 54.21%, Valid: 54.32% Test: 57.02%\n",
      "Run: 05, Epoch: 59, Loss: 1.0646, Train: 52.75%, Valid: 51.17% Test: 52.19%\n",
      "Run: 05, Epoch: 60, Loss: 1.0866, Train: 54.30%, Valid: 55.28% Test: 55.26%\n",
      "Run: 05, Epoch: 61, Loss: 1.0651, Train: 57.51%, Valid: 58.71% Test: 57.68%\n",
      "Run: 05, Epoch: 62, Loss: 1.0803, Train: 57.51%, Valid: 58.30% Test: 56.36%\n",
      "Run: 05, Epoch: 63, Loss: 1.0720, Train: 56.32%, Valid: 55.56% Test: 55.92%\n",
      "Run: 05, Epoch: 64, Loss: 1.0805, Train: 57.97%, Valid: 56.10% Test: 55.04%\n",
      "Run: 05, Epoch: 65, Loss: 1.0611, Train: 58.52%, Valid: 58.57% Test: 58.33%\n",
      "Run: 05, Epoch: 66, Loss: 1.0589, Train: 53.66%, Valid: 53.64% Test: 56.14%\n",
      "Run: 05, Epoch: 67, Loss: 1.0862, Train: 57.60%, Valid: 58.57% Test: 59.21%\n",
      "Run: 05, Epoch: 68, Loss: 1.0824, Train: 56.50%, Valid: 53.64% Test: 57.02%\n",
      "Run: 05, Epoch: 69, Loss: 1.0689, Train: 58.24%, Valid: 57.20% Test: 56.80%\n",
      "Run: 05, Epoch: 70, Loss: 1.0650, Train: 56.59%, Valid: 54.32% Test: 55.04%\n",
      "Run: 05, Epoch: 71, Loss: 1.0781, Train: 52.75%, Valid: 50.62% Test: 52.19%\n",
      "Run: 05, Epoch: 72, Loss: 1.0910, Train: 57.23%, Valid: 53.36% Test: 55.48%\n",
      "Run: 05, Epoch: 73, Loss: 1.0522, Train: 56.50%, Valid: 54.32% Test: 55.26%\n",
      "Run: 05, Epoch: 74, Loss: 1.1024, Train: 57.97%, Valid: 55.69% Test: 56.36%\n",
      "Run: 05, Epoch: 75, Loss: 1.0572, Train: 57.51%, Valid: 56.52% Test: 54.82%\n",
      "Run: 05, Epoch: 76, Loss: 1.0697, Train: 54.95%, Valid: 54.18% Test: 54.61%\n",
      "Run: 05, Epoch: 77, Loss: 1.1089, Train: 57.05%, Valid: 56.52% Test: 57.02%\n",
      "Run: 05, Epoch: 78, Loss: 1.0742, Train: 53.48%, Valid: 52.40% Test: 52.63%\n",
      "Run: 05, Epoch: 79, Loss: 1.0797, Train: 54.49%, Valid: 55.01% Test: 56.14%\n",
      "Run: 05, Epoch: 80, Loss: 1.0579, Train: 54.12%, Valid: 52.95% Test: 54.17%\n",
      "Run: 05, Epoch: 81, Loss: 1.0805, Train: 54.40%, Valid: 54.32% Test: 56.36%\n",
      "Run: 05, Epoch: 82, Loss: 1.0629, Train: 55.68%, Valid: 57.75% Test: 57.89%\n",
      "Run: 05, Epoch: 83, Loss: 1.0729, Train: 56.59%, Valid: 58.71% Test: 58.99%\n",
      "Run: 05, Epoch: 84, Loss: 1.0710, Train: 58.15%, Valid: 58.16% Test: 58.11%\n",
      "Run: 05, Epoch: 85, Loss: 1.0558, Train: 58.15%, Valid: 57.89% Test: 57.68%\n",
      "Run: 05, Epoch: 86, Loss: 1.0669, Train: 55.49%, Valid: 56.38% Test: 56.58%\n",
      "Run: 05, Epoch: 87, Loss: 1.0585, Train: 57.97%, Valid: 60.77% Test: 60.96%\n",
      "Run: 05, Epoch: 88, Loss: 1.0536, Train: 56.14%, Valid: 56.65% Test: 57.68%\n",
      "Run: 05, Epoch: 89, Loss: 1.0636, Train: 54.40%, Valid: 55.56% Test: 56.36%\n",
      "Run: 05, Epoch: 90, Loss: 1.0615, Train: 52.11%, Valid: 51.71% Test: 52.63%\n",
      "Run: 05, Epoch: 91, Loss: 1.0672, Train: 57.05%, Valid: 57.20% Test: 58.33%\n",
      "Run: 05, Epoch: 92, Loss: 1.0466, Train: 55.22%, Valid: 56.38% Test: 58.11%\n",
      "Run: 05, Epoch: 93, Loss: 1.0752, Train: 55.68%, Valid: 54.87% Test: 56.80%\n",
      "Run: 05, Epoch: 94, Loss: 1.0502, Train: 54.30%, Valid: 53.22% Test: 55.04%\n",
      "Run: 05, Epoch: 95, Loss: 1.0599, Train: 56.59%, Valid: 57.06% Test: 57.46%\n",
      "Run: 05, Epoch: 96, Loss: 1.0386, Train: 54.58%, Valid: 55.97% Test: 57.68%\n",
      "Run: 05, Epoch: 97, Loss: 1.0460, Train: 54.76%, Valid: 54.05% Test: 55.92%\n",
      "Run: 05, Epoch: 98, Loss: 1.0513, Train: 56.41%, Valid: 53.22% Test: 56.36%\n",
      "Run: 05, Epoch: 99, Loss: 1.0340, Train: 55.77%, Valid: 56.65% Test: 58.55%\n",
      "Run: 05, Epoch: 100, Loss: 1.0368, Train: 58.06%, Valid: 57.20% Test: 57.68%\n",
      "Run: 05, Epoch: 101, Loss: 1.0207, Train: 58.52%, Valid: 56.65% Test: 56.36%\n",
      "Run: 05, Epoch: 102, Loss: 1.0371, Train: 54.67%, Valid: 50.21% Test: 53.73%\n",
      "Run: 05, Epoch: 103, Loss: 1.0514, Train: 56.14%, Valid: 53.36% Test: 55.04%\n",
      "Run: 05, Epoch: 104, Loss: 1.0411, Train: 57.42%, Valid: 55.69% Test: 56.36%\n",
      "Run: 05, Epoch: 105, Loss: 1.0511, Train: 54.95%, Valid: 55.14% Test: 56.80%\n",
      "Run: 05, Epoch: 106, Loss: 1.0616, Train: 54.58%, Valid: 54.73% Test: 57.46%\n",
      "Run: 05, Epoch: 107, Loss: 1.0592, Train: 54.30%, Valid: 52.67% Test: 55.26%\n",
      "Run: 05, Epoch: 108, Loss: 1.0464, Train: 56.32%, Valid: 54.46% Test: 57.89%\n",
      "Run: 05, Epoch: 109, Loss: 1.0484, Train: 58.70%, Valid: 57.89% Test: 58.77%\n",
      "Run: 05, Epoch: 110, Loss: 1.0474, Train: 59.89%, Valid: 59.40% Test: 60.75%\n",
      "Run: 05, Epoch: 111, Loss: 1.0338, Train: 59.07%, Valid: 59.12% Test: 59.21%\n",
      "Run: 05, Epoch: 112, Loss: 1.0354, Train: 57.88%, Valid: 57.34% Test: 59.43%\n",
      "Run: 05, Epoch: 113, Loss: 1.0493, Train: 59.80%, Valid: 60.36% Test: 60.53%\n",
      "Run: 05, Epoch: 114, Loss: 1.0420, Train: 59.25%, Valid: 59.67% Test: 60.75%\n",
      "Run: 05, Epoch: 115, Loss: 1.0374, Train: 58.79%, Valid: 56.93% Test: 60.09%\n",
      "Run: 05, Epoch: 116, Loss: 1.0196, Train: 59.89%, Valid: 58.71% Test: 59.43%\n",
      "Run: 05, Epoch: 117, Loss: 1.0030, Train: 57.97%, Valid: 58.44% Test: 58.77%\n",
      "Run: 05, Epoch: 118, Loss: 1.0087, Train: 57.23%, Valid: 58.16% Test: 59.21%\n",
      "Run: 05, Epoch: 119, Loss: 1.0066, Train: 56.87%, Valid: 57.89% Test: 57.68%\n",
      "Run: 05, Epoch: 120, Loss: 1.0363, Train: 56.32%, Valid: 57.75% Test: 57.89%\n",
      "Run: 05, Epoch: 121, Loss: 0.9970, Train: 52.93%, Valid: 54.46% Test: 56.58%\n",
      "Run: 05, Epoch: 122, Loss: 1.0149, Train: 53.48%, Valid: 52.95% Test: 53.95%\n",
      "Run: 05, Epoch: 123, Loss: 1.0452, Train: 58.61%, Valid: 58.44% Test: 59.43%\n",
      "Run: 05, Epoch: 124, Loss: 0.9976, Train: 56.04%, Valid: 54.18% Test: 52.63%\n",
      "Run: 05, Epoch: 125, Loss: 1.0368, Train: 59.89%, Valid: 60.49% Test: 59.43%\n",
      "Run: 05, Epoch: 126, Loss: 1.0351, Train: 57.33%, Valid: 60.08% Test: 59.65%\n",
      "Run: 05, Epoch: 127, Loss: 1.0347, Train: 60.07%, Valid: 60.08% Test: 59.65%\n",
      "Run: 05, Epoch: 128, Loss: 1.0152, Train: 57.78%, Valid: 55.28% Test: 55.48%\n",
      "Run: 05, Epoch: 129, Loss: 1.0488, Train: 58.15%, Valid: 55.83% Test: 54.17%\n",
      "Run: 05, Epoch: 130, Loss: 1.0244, Train: 58.97%, Valid: 61.59% Test: 59.65%\n",
      "Run: 05, Epoch: 131, Loss: 1.0529, Train: 59.98%, Valid: 61.18% Test: 59.21%\n",
      "Run: 05, Epoch: 132, Loss: 1.0145, Train: 60.16%, Valid: 60.49% Test: 59.43%\n",
      "Run: 05, Epoch: 133, Loss: 0.9908, Train: 56.96%, Valid: 54.32% Test: 53.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 134, Loss: 1.0452, Train: 61.45%, Valid: 62.14% Test: 60.96%\n",
      "Run: 05, Epoch: 135, Loss: 1.0209, Train: 54.49%, Valid: 55.14% Test: 55.26%\n",
      "Run: 05, Epoch: 136, Loss: 1.0261, Train: 53.11%, Valid: 53.64% Test: 52.85%\n",
      "Run: 05, Epoch: 137, Loss: 1.0283, Train: 52.93%, Valid: 52.67% Test: 53.51%\n",
      "Run: 05, Epoch: 138, Loss: 1.0744, Train: 61.45%, Valid: 62.55% Test: 60.53%\n",
      "Run: 05, Epoch: 139, Loss: 0.9978, Train: 57.33%, Valid: 58.16% Test: 55.26%\n",
      "Run: 05, Epoch: 140, Loss: 1.0484, Train: 59.80%, Valid: 61.73% Test: 60.31%\n",
      "Run: 05, Epoch: 141, Loss: 1.0350, Train: 59.62%, Valid: 61.04% Test: 61.62%\n",
      "Run: 05, Epoch: 142, Loss: 1.0495, Train: 55.13%, Valid: 51.85% Test: 52.41%\n",
      "Run: 05, Epoch: 143, Loss: 1.0546, Train: 58.88%, Valid: 59.40% Test: 59.65%\n",
      "Run: 05, Epoch: 144, Loss: 1.0266, Train: 58.97%, Valid: 58.85% Test: 58.33%\n",
      "Run: 05, Epoch: 145, Loss: 1.0385, Train: 59.80%, Valid: 59.53% Test: 57.02%\n",
      "Run: 05, Epoch: 146, Loss: 1.0368, Train: 60.99%, Valid: 57.34% Test: 57.89%\n",
      "Run: 05, Epoch: 147, Loss: 1.0269, Train: 59.98%, Valid: 56.38% Test: 57.68%\n",
      "Run: 05, Epoch: 148, Loss: 1.0194, Train: 58.79%, Valid: 57.75% Test: 58.11%\n",
      "Run: 05, Epoch: 149, Loss: 1.0412, Train: 58.61%, Valid: 57.61% Test: 57.68%\n",
      "Run: 05, Epoch: 150, Loss: 1.0192, Train: 60.35%, Valid: 58.57% Test: 58.11%\n",
      "Run: 05, Epoch: 151, Loss: 1.0234, Train: 60.62%, Valid: 59.26% Test: 59.87%\n",
      "Run: 05, Epoch: 152, Loss: 1.0226, Train: 57.88%, Valid: 53.22% Test: 54.61%\n",
      "Run: 05, Epoch: 153, Loss: 1.0026, Train: 59.34%, Valid: 58.71% Test: 57.46%\n",
      "Run: 05, Epoch: 154, Loss: 1.0167, Train: 61.36%, Valid: 61.32% Test: 61.62%\n",
      "Run: 05, Epoch: 155, Loss: 1.0351, Train: 57.51%, Valid: 58.02% Test: 58.99%\n",
      "Run: 05, Epoch: 156, Loss: 1.0595, Train: 56.32%, Valid: 56.24% Test: 56.14%\n",
      "Run: 05, Epoch: 157, Loss: 1.0703, Train: 58.24%, Valid: 59.53% Test: 60.96%\n",
      "Run: 05, Epoch: 158, Loss: 1.0609, Train: 56.96%, Valid: 55.56% Test: 57.24%\n",
      "Run: 05, Epoch: 159, Loss: 1.0581, Train: 50.37%, Valid: 49.25% Test: 48.90%\n",
      "Run: 05, Epoch: 160, Loss: 1.0540, Train: 58.15%, Valid: 56.38% Test: 56.58%\n",
      "Run: 05, Epoch: 161, Loss: 1.0548, Train: 56.87%, Valid: 56.10% Test: 57.46%\n",
      "Run: 05, Epoch: 162, Loss: 1.0685, Train: 55.68%, Valid: 55.01% Test: 56.36%\n",
      "Run: 05, Epoch: 163, Loss: 1.0640, Train: 59.25%, Valid: 53.77% Test: 54.17%\n",
      "Run: 05, Epoch: 164, Loss: 1.0780, Train: 56.23%, Valid: 48.97% Test: 50.66%\n",
      "Run: 05, Epoch: 165, Loss: 1.0547, Train: 59.34%, Valid: 57.75% Test: 59.87%\n",
      "Run: 05, Epoch: 166, Loss: 1.0446, Train: 58.79%, Valid: 57.61% Test: 58.99%\n",
      "Run: 05, Epoch: 167, Loss: 1.0590, Train: 57.14%, Valid: 53.77% Test: 55.26%\n",
      "Run: 05, Epoch: 168, Loss: 1.0810, Train: 57.05%, Valid: 52.81% Test: 54.61%\n",
      "Run: 05, Epoch: 169, Loss: 1.0764, Train: 56.59%, Valid: 54.60% Test: 55.92%\n",
      "Run: 05, Epoch: 170, Loss: 1.0420, Train: 57.42%, Valid: 58.16% Test: 58.99%\n",
      "Run: 05, Epoch: 171, Loss: 1.0367, Train: 58.06%, Valid: 58.30% Test: 59.87%\n",
      "Run: 05, Epoch: 172, Loss: 1.0350, Train: 58.24%, Valid: 57.61% Test: 60.31%\n",
      "Run: 05, Epoch: 173, Loss: 1.0495, Train: 57.69%, Valid: 58.30% Test: 57.24%\n",
      "Run: 05, Epoch: 174, Loss: 1.0356, Train: 59.16%, Valid: 58.44% Test: 58.11%\n",
      "Run: 05, Epoch: 175, Loss: 1.0411, Train: 59.43%, Valid: 59.95% Test: 59.65%\n",
      "Run: 05, Epoch: 176, Loss: 1.0539, Train: 58.70%, Valid: 56.65% Test: 59.87%\n",
      "Run: 05, Epoch: 177, Loss: 1.0238, Train: 59.89%, Valid: 59.95% Test: 60.96%\n",
      "Run: 05, Epoch: 178, Loss: 1.0428, Train: 60.44%, Valid: 58.44% Test: 61.40%\n",
      "Run: 05, Epoch: 179, Loss: 1.0338, Train: 56.32%, Valid: 55.97% Test: 57.89%\n",
      "Run: 05, Epoch: 180, Loss: 1.0050, Train: 56.41%, Valid: 59.95% Test: 61.62%\n",
      "Run: 05, Epoch: 181, Loss: 1.0294, Train: 58.79%, Valid: 63.37% Test: 63.16%\n",
      "Run: 05, Epoch: 182, Loss: 1.0415, Train: 59.16%, Valid: 59.67% Test: 62.94%\n",
      "Run: 05, Epoch: 183, Loss: 1.0359, Train: 57.97%, Valid: 56.79% Test: 59.65%\n",
      "Run: 05, Epoch: 184, Loss: 1.0325, Train: 56.59%, Valid: 54.73% Test: 56.14%\n",
      "Run: 05, Epoch: 185, Loss: 1.0636, Train: 58.24%, Valid: 56.24% Test: 59.65%\n",
      "Run: 05, Epoch: 186, Loss: 1.0316, Train: 59.89%, Valid: 59.95% Test: 63.60%\n",
      "Run: 05, Epoch: 187, Loss: 1.0434, Train: 51.56%, Valid: 51.03% Test: 53.51%\n",
      "Run: 05, Epoch: 188, Loss: 1.0704, Train: 57.14%, Valid: 56.79% Test: 61.18%\n",
      "Run: 05, Epoch: 189, Loss: 1.0259, Train: 59.16%, Valid: 58.02% Test: 60.09%\n",
      "Run: 05, Epoch: 190, Loss: 1.0305, Train: 60.35%, Valid: 58.30% Test: 58.11%\n",
      "Run: 05, Epoch: 191, Loss: 1.0332, Train: 59.80%, Valid: 57.75% Test: 58.77%\n",
      "Run: 05, Epoch: 192, Loss: 1.0436, Train: 55.95%, Valid: 53.22% Test: 57.68%\n",
      "Run: 05, Epoch: 193, Loss: 1.0692, Train: 58.42%, Valid: 57.48% Test: 61.84%\n",
      "Run: 05, Epoch: 194, Loss: 1.0413, Train: 59.43%, Valid: 58.98% Test: 60.96%\n",
      "Run: 05, Epoch: 195, Loss: 1.0116, Train: 58.06%, Valid: 57.89% Test: 58.11%\n",
      "Run: 05, Epoch: 196, Loss: 1.0438, Train: 55.59%, Valid: 54.32% Test: 57.68%\n",
      "Run: 05, Epoch: 197, Loss: 1.0659, Train: 55.49%, Valid: 55.83% Test: 57.68%\n",
      "Run: 05, Epoch: 198, Loss: 1.0431, Train: 56.50%, Valid: 55.69% Test: 57.24%\n",
      "Run: 05, Epoch: 199, Loss: 1.0560, Train: 61.17%, Valid: 59.95% Test: 59.65%\n",
      "Run: 05, Epoch: 200, Loss: 1.0312, Train: 61.08%, Valid: 59.95% Test: 60.96%\n",
      "Run 05:\n",
      "Highest Train: 61.45\n",
      "Highest Valid: 63.37\n",
      "  Final Train: 58.79\n",
      "   Final Test: 63.16\n",
      "Run: 06, Epoch: 01, Loss: 1.6011, Train: 25.27%, Valid: 24.14% Test: 20.61%\n",
      "Run: 06, Epoch: 02, Loss: 1.5059, Train: 25.64%, Valid: 27.71% Test: 30.26%\n",
      "Run: 06, Epoch: 03, Loss: 1.4261, Train: 34.16%, Valid: 34.57% Test: 37.94%\n",
      "Run: 06, Epoch: 04, Loss: 1.4806, Train: 28.39%, Valid: 30.73% Test: 33.11%\n",
      "Run: 06, Epoch: 05, Loss: 1.3682, Train: 25.64%, Valid: 27.85% Test: 30.04%\n",
      "Run: 06, Epoch: 06, Loss: 1.3956, Train: 26.65%, Valid: 28.26% Test: 30.26%\n",
      "Run: 06, Epoch: 07, Loss: 1.4034, Train: 31.78%, Valid: 33.88% Test: 33.33%\n",
      "Run: 06, Epoch: 08, Loss: 1.3830, Train: 34.25%, Valid: 36.21% Test: 32.24%\n",
      "Run: 06, Epoch: 09, Loss: 1.3699, Train: 38.37%, Valid: 38.55% Test: 34.65%\n",
      "Run: 06, Epoch: 10, Loss: 1.3544, Train: 41.67%, Valid: 40.88% Test: 38.16%\n",
      "Run: 06, Epoch: 11, Loss: 1.3235, Train: 39.47%, Valid: 40.47% Test: 38.60%\n",
      "Run: 06, Epoch: 12, Loss: 1.2901, Train: 40.66%, Valid: 41.70% Test: 39.25%\n",
      "Run: 06, Epoch: 13, Loss: 1.2908, Train: 39.74%, Valid: 41.98% Test: 39.04%\n",
      "Run: 06, Epoch: 14, Loss: 1.2948, Train: 38.83%, Valid: 40.88% Test: 38.82%\n",
      "Run: 06, Epoch: 15, Loss: 1.2793, Train: 40.75%, Valid: 41.15% Test: 42.54%\n",
      "Run: 06, Epoch: 16, Loss: 1.2599, Train: 38.92%, Valid: 39.37% Test: 40.79%\n",
      "Run: 06, Epoch: 17, Loss: 1.2623, Train: 41.67%, Valid: 39.64% Test: 39.69%\n",
      "Run: 06, Epoch: 18, Loss: 1.2527, Train: 46.15%, Valid: 42.25% Test: 40.57%\n",
      "Run: 06, Epoch: 19, Loss: 1.2454, Train: 44.69%, Valid: 41.29% Test: 39.25%\n",
      "Run: 06, Epoch: 20, Loss: 1.2479, Train: 44.41%, Valid: 40.60% Test: 37.06%\n",
      "Run: 06, Epoch: 21, Loss: 1.2633, Train: 45.79%, Valid: 43.35% Test: 40.13%\n",
      "Run: 06, Epoch: 22, Loss: 1.2577, Train: 44.23%, Valid: 41.02% Test: 39.04%\n",
      "Run: 06, Epoch: 23, Loss: 1.2410, Train: 43.41%, Valid: 39.64% Test: 37.94%\n",
      "Run: 06, Epoch: 24, Loss: 1.2293, Train: 42.31%, Valid: 40.74% Test: 37.94%\n",
      "Run: 06, Epoch: 25, Loss: 1.2127, Train: 46.34%, Valid: 45.82% Test: 42.76%\n",
      "Run: 06, Epoch: 26, Loss: 1.2210, Train: 51.92%, Valid: 50.48% Test: 45.83%\n",
      "Run: 06, Epoch: 27, Loss: 1.2106, Train: 50.55%, Valid: 48.01% Test: 46.27%\n",
      "Run: 06, Epoch: 28, Loss: 1.2235, Train: 47.25%, Valid: 47.87% Test: 43.64%\n",
      "Run: 06, Epoch: 29, Loss: 1.3481, Train: 50.18%, Valid: 49.25% Test: 48.46%\n",
      "Run: 06, Epoch: 30, Loss: 1.2489, Train: 45.33%, Valid: 45.54% Test: 42.54%\n",
      "Run: 06, Epoch: 31, Loss: 1.2439, Train: 44.05%, Valid: 44.03% Test: 42.76%\n",
      "Run: 06, Epoch: 32, Loss: 1.2448, Train: 46.43%, Valid: 44.17% Test: 41.67%\n",
      "Run: 06, Epoch: 33, Loss: 1.2326, Train: 46.25%, Valid: 44.31% Test: 41.01%\n",
      "Run: 06, Epoch: 34, Loss: 1.2035, Train: 49.36%, Valid: 48.15% Test: 44.52%\n",
      "Run: 06, Epoch: 35, Loss: 1.2271, Train: 47.80%, Valid: 44.99% Test: 43.42%\n",
      "Run: 06, Epoch: 36, Loss: 1.2060, Train: 46.25%, Valid: 44.58% Test: 42.32%\n",
      "Run: 06, Epoch: 37, Loss: 1.1986, Train: 47.34%, Valid: 44.72% Test: 44.30%\n",
      "Run: 06, Epoch: 38, Loss: 1.2057, Train: 52.11%, Valid: 52.26% Test: 50.22%\n",
      "Run: 06, Epoch: 39, Loss: 1.1778, Train: 50.92%, Valid: 49.52% Test: 48.68%\n",
      "Run: 06, Epoch: 40, Loss: 1.1834, Train: 44.14%, Valid: 45.27% Test: 44.08%\n",
      "Run: 06, Epoch: 41, Loss: 1.2320, Train: 48.44%, Valid: 51.03% Test: 46.93%\n",
      "Run: 06, Epoch: 42, Loss: 1.1884, Train: 49.63%, Valid: 50.48% Test: 48.25%\n",
      "Run: 06, Epoch: 43, Loss: 1.2043, Train: 50.92%, Valid: 51.71% Test: 50.22%\n",
      "Run: 06, Epoch: 44, Loss: 1.1556, Train: 53.21%, Valid: 53.09% Test: 50.22%\n",
      "Run: 06, Epoch: 45, Loss: 1.1536, Train: 52.56%, Valid: 51.44% Test: 48.25%\n",
      "Run: 06, Epoch: 46, Loss: 1.1571, Train: 52.29%, Valid: 53.50% Test: 52.19%\n",
      "Run: 06, Epoch: 47, Loss: 1.1689, Train: 51.83%, Valid: 51.99% Test: 53.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 48, Loss: 1.1765, Train: 48.53%, Valid: 49.79% Test: 49.34%\n",
      "Run: 06, Epoch: 49, Loss: 1.1608, Train: 48.26%, Valid: 49.79% Test: 46.93%\n",
      "Run: 06, Epoch: 50, Loss: 1.1507, Train: 44.51%, Valid: 45.95% Test: 43.20%\n",
      "Run: 06, Epoch: 51, Loss: 1.1541, Train: 44.41%, Valid: 46.09% Test: 42.98%\n",
      "Run: 06, Epoch: 52, Loss: 1.1465, Train: 48.72%, Valid: 50.34% Test: 49.78%\n",
      "Run: 06, Epoch: 53, Loss: 1.1373, Train: 49.27%, Valid: 48.97% Test: 50.22%\n",
      "Run: 06, Epoch: 54, Loss: 1.1378, Train: 50.64%, Valid: 51.17% Test: 53.29%\n",
      "Run: 06, Epoch: 55, Loss: 1.1370, Train: 50.09%, Valid: 49.93% Test: 47.15%\n",
      "Run: 06, Epoch: 56, Loss: 1.2046, Train: 51.37%, Valid: 50.75% Test: 51.54%\n",
      "Run: 06, Epoch: 57, Loss: 1.1294, Train: 50.82%, Valid: 51.99% Test: 53.51%\n",
      "Run: 06, Epoch: 58, Loss: 1.1643, Train: 47.16%, Valid: 50.62% Test: 47.15%\n",
      "Run: 06, Epoch: 59, Loss: 1.1508, Train: 44.69%, Valid: 45.54% Test: 43.64%\n",
      "Run: 06, Epoch: 60, Loss: 1.1454, Train: 45.51%, Valid: 46.36% Test: 42.98%\n",
      "Run: 06, Epoch: 61, Loss: 1.1419, Train: 49.08%, Valid: 47.87% Test: 45.61%\n",
      "Run: 06, Epoch: 62, Loss: 1.1460, Train: 50.55%, Valid: 49.79% Test: 49.78%\n",
      "Run: 06, Epoch: 63, Loss: 1.1548, Train: 53.30%, Valid: 52.13% Test: 49.12%\n",
      "Run: 06, Epoch: 64, Loss: 1.1438, Train: 54.12%, Valid: 52.26% Test: 48.46%\n",
      "Run: 06, Epoch: 65, Loss: 1.1648, Train: 55.68%, Valid: 51.71% Test: 51.75%\n",
      "Run: 06, Epoch: 66, Loss: 1.1229, Train: 53.21%, Valid: 51.58% Test: 49.34%\n",
      "Run: 06, Epoch: 67, Loss: 1.1224, Train: 51.74%, Valid: 51.85% Test: 50.44%\n",
      "Run: 06, Epoch: 68, Loss: 1.1188, Train: 53.48%, Valid: 53.64% Test: 51.32%\n",
      "Run: 06, Epoch: 69, Loss: 1.1228, Train: 55.40%, Valid: 55.01% Test: 53.07%\n",
      "Run: 06, Epoch: 70, Loss: 1.1089, Train: 57.60%, Valid: 54.46% Test: 53.73%\n",
      "Run: 06, Epoch: 71, Loss: 1.0871, Train: 57.23%, Valid: 55.83% Test: 54.17%\n",
      "Run: 06, Epoch: 72, Loss: 1.0905, Train: 55.40%, Valid: 55.28% Test: 55.04%\n",
      "Run: 06, Epoch: 73, Loss: 1.1047, Train: 55.04%, Valid: 55.01% Test: 58.55%\n",
      "Run: 06, Epoch: 74, Loss: 1.0962, Train: 57.51%, Valid: 54.46% Test: 59.65%\n",
      "Run: 06, Epoch: 75, Loss: 1.1154, Train: 53.85%, Valid: 53.77% Test: 52.85%\n",
      "Run: 06, Epoch: 76, Loss: 1.1249, Train: 53.02%, Valid: 48.15% Test: 49.12%\n",
      "Run: 06, Epoch: 77, Loss: 1.1103, Train: 54.76%, Valid: 51.58% Test: 53.29%\n",
      "Run: 06, Epoch: 78, Loss: 1.1229, Train: 53.57%, Valid: 54.46% Test: 54.17%\n",
      "Run: 06, Epoch: 79, Loss: 1.0856, Train: 57.60%, Valid: 57.89% Test: 59.65%\n",
      "Run: 06, Epoch: 80, Loss: 1.0855, Train: 58.15%, Valid: 58.98% Test: 59.21%\n",
      "Run: 06, Epoch: 81, Loss: 1.1131, Train: 56.50%, Valid: 55.01% Test: 57.68%\n",
      "Run: 06, Epoch: 82, Loss: 1.0806, Train: 55.49%, Valid: 53.09% Test: 54.82%\n",
      "Run: 06, Epoch: 83, Loss: 1.0904, Train: 57.60%, Valid: 55.42% Test: 52.85%\n",
      "Run: 06, Epoch: 84, Loss: 1.1077, Train: 58.24%, Valid: 54.87% Test: 56.80%\n",
      "Run: 06, Epoch: 85, Loss: 1.1040, Train: 57.14%, Valid: 55.28% Test: 54.61%\n",
      "Run: 06, Epoch: 86, Loss: 1.1056, Train: 58.70%, Valid: 56.93% Test: 58.77%\n",
      "Run: 06, Epoch: 87, Loss: 1.0995, Train: 54.30%, Valid: 53.36% Test: 55.48%\n",
      "Run: 06, Epoch: 88, Loss: 1.0694, Train: 51.83%, Valid: 52.40% Test: 53.51%\n",
      "Run: 06, Epoch: 89, Loss: 1.1279, Train: 59.80%, Valid: 58.85% Test: 57.24%\n",
      "Run: 06, Epoch: 90, Loss: 1.0784, Train: 56.04%, Valid: 52.67% Test: 51.54%\n",
      "Run: 06, Epoch: 91, Loss: 1.1180, Train: 57.42%, Valid: 56.24% Test: 55.92%\n",
      "Run: 06, Epoch: 92, Loss: 1.0829, Train: 58.33%, Valid: 56.52% Test: 60.09%\n",
      "Run: 06, Epoch: 93, Loss: 1.0703, Train: 57.42%, Valid: 55.97% Test: 58.77%\n",
      "Run: 06, Epoch: 94, Loss: 1.0807, Train: 58.33%, Valid: 55.14% Test: 53.07%\n",
      "Run: 06, Epoch: 95, Loss: 1.0619, Train: 58.70%, Valid: 55.56% Test: 53.51%\n",
      "Run: 06, Epoch: 96, Loss: 1.0888, Train: 61.36%, Valid: 58.85% Test: 57.89%\n",
      "Run: 06, Epoch: 97, Loss: 1.0777, Train: 60.90%, Valid: 59.26% Test: 58.55%\n",
      "Run: 06, Epoch: 98, Loss: 1.0920, Train: 60.62%, Valid: 59.67% Test: 57.68%\n",
      "Run: 06, Epoch: 99, Loss: 1.0690, Train: 59.62%, Valid: 58.02% Test: 55.04%\n",
      "Run: 06, Epoch: 100, Loss: 1.0560, Train: 58.79%, Valid: 58.30% Test: 55.48%\n",
      "Run: 06, Epoch: 101, Loss: 1.0666, Train: 55.68%, Valid: 56.65% Test: 55.26%\n",
      "Run: 06, Epoch: 102, Loss: 1.0639, Train: 59.89%, Valid: 59.81% Test: 57.24%\n",
      "Run: 06, Epoch: 103, Loss: 1.0620, Train: 61.90%, Valid: 60.91% Test: 58.55%\n",
      "Run: 06, Epoch: 104, Loss: 1.0547, Train: 61.63%, Valid: 60.91% Test: 59.87%\n",
      "Run: 06, Epoch: 105, Loss: 1.0584, Train: 61.08%, Valid: 59.40% Test: 58.77%\n",
      "Run: 06, Epoch: 106, Loss: 1.0544, Train: 60.44%, Valid: 59.40% Test: 58.11%\n",
      "Run: 06, Epoch: 107, Loss: 1.0559, Train: 61.90%, Valid: 60.63% Test: 60.31%\n",
      "Run: 06, Epoch: 108, Loss: 1.0477, Train: 62.64%, Valid: 59.81% Test: 59.43%\n",
      "Run: 06, Epoch: 109, Loss: 1.0568, Train: 60.90%, Valid: 58.98% Test: 56.36%\n",
      "Run: 06, Epoch: 110, Loss: 1.0628, Train: 63.10%, Valid: 62.28% Test: 59.65%\n",
      "Run: 06, Epoch: 111, Loss: 1.0299, Train: 60.35%, Valid: 60.63% Test: 57.89%\n",
      "Run: 06, Epoch: 112, Loss: 1.0598, Train: 61.36%, Valid: 58.71% Test: 57.46%\n",
      "Run: 06, Epoch: 113, Loss: 1.0659, Train: 56.59%, Valid: 54.32% Test: 50.66%\n",
      "Run: 06, Epoch: 114, Loss: 1.0394, Train: 60.07%, Valid: 57.48% Test: 55.26%\n",
      "Run: 06, Epoch: 115, Loss: 1.0401, Train: 59.52%, Valid: 58.02% Test: 57.02%\n",
      "Run: 06, Epoch: 116, Loss: 1.0597, Train: 59.52%, Valid: 57.75% Test: 57.02%\n",
      "Run: 06, Epoch: 117, Loss: 1.0597, Train: 59.62%, Valid: 57.61% Test: 56.36%\n",
      "Run: 06, Epoch: 118, Loss: 1.0737, Train: 59.71%, Valid: 57.06% Test: 55.48%\n",
      "Run: 06, Epoch: 119, Loss: 1.0354, Train: 59.34%, Valid: 57.20% Test: 55.48%\n",
      "Run: 06, Epoch: 120, Loss: 1.0721, Train: 58.88%, Valid: 55.83% Test: 57.46%\n",
      "Run: 06, Epoch: 121, Loss: 1.0504, Train: 58.33%, Valid: 57.20% Test: 56.58%\n",
      "Run: 06, Epoch: 122, Loss: 1.0492, Train: 61.45%, Valid: 60.77% Test: 58.99%\n",
      "Run: 06, Epoch: 123, Loss: 1.0615, Train: 55.49%, Valid: 57.61% Test: 54.82%\n",
      "Run: 06, Epoch: 124, Loss: 1.0618, Train: 59.07%, Valid: 61.04% Test: 59.21%\n",
      "Run: 06, Epoch: 125, Loss: 1.0430, Train: 60.62%, Valid: 60.77% Test: 58.33%\n",
      "Run: 06, Epoch: 126, Loss: 1.0507, Train: 60.81%, Valid: 57.06% Test: 55.92%\n",
      "Run: 06, Epoch: 127, Loss: 1.0343, Train: 60.53%, Valid: 58.71% Test: 56.58%\n",
      "Run: 06, Epoch: 128, Loss: 1.0431, Train: 58.70%, Valid: 57.89% Test: 57.46%\n",
      "Run: 06, Epoch: 129, Loss: 1.0532, Train: 60.44%, Valid: 59.26% Test: 58.77%\n",
      "Run: 06, Epoch: 130, Loss: 1.0536, Train: 61.81%, Valid: 61.32% Test: 60.96%\n",
      "Run: 06, Epoch: 131, Loss: 1.0414, Train: 62.45%, Valid: 61.87% Test: 58.33%\n",
      "Run: 06, Epoch: 132, Loss: 1.0437, Train: 60.81%, Valid: 59.12% Test: 57.68%\n",
      "Run: 06, Epoch: 133, Loss: 1.0418, Train: 55.77%, Valid: 54.60% Test: 54.82%\n",
      "Run: 06, Epoch: 134, Loss: 1.0459, Train: 60.62%, Valid: 59.81% Test: 60.09%\n",
      "Run: 06, Epoch: 135, Loss: 1.0416, Train: 59.16%, Valid: 59.67% Test: 58.77%\n",
      "Run: 06, Epoch: 136, Loss: 1.0528, Train: 60.35%, Valid: 60.36% Test: 58.77%\n",
      "Run: 06, Epoch: 137, Loss: 1.0459, Train: 63.00%, Valid: 60.63% Test: 60.75%\n",
      "Run: 06, Epoch: 138, Loss: 1.0371, Train: 62.73%, Valid: 62.69% Test: 60.96%\n",
      "Run: 06, Epoch: 139, Loss: 1.0130, Train: 61.36%, Valid: 61.73% Test: 60.75%\n",
      "Run: 06, Epoch: 140, Loss: 1.0663, Train: 60.99%, Valid: 60.08% Test: 60.75%\n",
      "Run: 06, Epoch: 141, Loss: 1.0624, Train: 62.55%, Valid: 59.95% Test: 58.55%\n",
      "Run: 06, Epoch: 142, Loss: 1.0359, Train: 62.73%, Valid: 59.95% Test: 59.43%\n",
      "Run: 06, Epoch: 143, Loss: 1.0225, Train: 62.45%, Valid: 62.83% Test: 62.50%\n",
      "Run: 06, Epoch: 144, Loss: 1.0349, Train: 62.09%, Valid: 62.41% Test: 61.84%\n",
      "Run: 06, Epoch: 145, Loss: 1.0265, Train: 62.73%, Valid: 61.45% Test: 62.06%\n",
      "Run: 06, Epoch: 146, Loss: 1.0251, Train: 60.07%, Valid: 59.53% Test: 56.36%\n",
      "Run: 06, Epoch: 147, Loss: 1.0243, Train: 62.91%, Valid: 61.18% Test: 60.96%\n",
      "Run: 06, Epoch: 148, Loss: 1.0232, Train: 56.96%, Valid: 57.48% Test: 57.46%\n",
      "Run: 06, Epoch: 149, Loss: 1.0286, Train: 60.62%, Valid: 59.81% Test: 57.46%\n",
      "Run: 06, Epoch: 150, Loss: 1.0313, Train: 63.46%, Valid: 61.32% Test: 57.68%\n",
      "Run: 06, Epoch: 151, Loss: 1.0284, Train: 61.63%, Valid: 58.71% Test: 55.92%\n",
      "Run: 06, Epoch: 152, Loss: 1.0286, Train: 56.68%, Valid: 54.05% Test: 50.66%\n",
      "Run: 06, Epoch: 153, Loss: 1.0472, Train: 59.52%, Valid: 58.98% Test: 56.58%\n",
      "Run: 06, Epoch: 154, Loss: 1.0491, Train: 61.63%, Valid: 62.14% Test: 57.46%\n",
      "Run: 06, Epoch: 155, Loss: 1.0353, Train: 60.81%, Valid: 58.57% Test: 54.82%\n",
      "Run: 06, Epoch: 156, Loss: 1.0170, Train: 60.16%, Valid: 57.20% Test: 53.95%\n",
      "Run: 06, Epoch: 157, Loss: 1.0216, Train: 58.61%, Valid: 58.98% Test: 55.26%\n",
      "Run: 06, Epoch: 158, Loss: 1.0147, Train: 54.30%, Valid: 56.38% Test: 54.17%\n",
      "Run: 06, Epoch: 159, Loss: 1.0199, Train: 61.26%, Valid: 58.71% Test: 56.14%\n",
      "Run: 06, Epoch: 160, Loss: 1.0183, Train: 62.64%, Valid: 58.16% Test: 56.58%\n",
      "Run: 06, Epoch: 161, Loss: 1.0293, Train: 64.38%, Valid: 59.81% Test: 59.43%\n",
      "Run: 06, Epoch: 162, Loss: 1.0336, Train: 64.01%, Valid: 58.71% Test: 58.55%\n",
      "Run: 06, Epoch: 163, Loss: 1.0155, Train: 65.48%, Valid: 62.14% Test: 60.75%\n",
      "Run: 06, Epoch: 164, Loss: 1.0265, Train: 65.48%, Valid: 60.91% Test: 60.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 165, Loss: 1.0183, Train: 66.12%, Valid: 62.55% Test: 61.40%\n",
      "Run: 06, Epoch: 166, Loss: 1.0330, Train: 64.29%, Valid: 62.41% Test: 60.96%\n",
      "Run: 06, Epoch: 167, Loss: 0.9928, Train: 65.29%, Valid: 62.28% Test: 57.89%\n",
      "Run: 06, Epoch: 168, Loss: 1.0284, Train: 64.47%, Valid: 62.83% Test: 60.31%\n",
      "Run: 06, Epoch: 169, Loss: 1.0626, Train: 59.07%, Valid: 54.73% Test: 53.07%\n",
      "Run: 06, Epoch: 170, Loss: 1.0109, Train: 62.82%, Valid: 60.49% Test: 60.96%\n",
      "Run: 06, Epoch: 171, Loss: 1.0456, Train: 60.99%, Valid: 61.32% Test: 59.87%\n",
      "Run: 06, Epoch: 172, Loss: 1.0313, Train: 62.64%, Valid: 61.73% Test: 60.96%\n",
      "Run: 06, Epoch: 173, Loss: 1.0578, Train: 61.08%, Valid: 57.89% Test: 57.24%\n",
      "Run: 06, Epoch: 174, Loss: 1.0295, Train: 63.10%, Valid: 57.89% Test: 58.33%\n",
      "Run: 06, Epoch: 175, Loss: 0.9929, Train: 62.82%, Valid: 59.67% Test: 60.31%\n",
      "Run: 06, Epoch: 176, Loss: 1.0305, Train: 58.97%, Valid: 57.34% Test: 57.68%\n",
      "Run: 06, Epoch: 177, Loss: 1.0278, Train: 62.36%, Valid: 61.87% Test: 59.65%\n",
      "Run: 06, Epoch: 178, Loss: 1.0100, Train: 62.82%, Valid: 60.36% Test: 58.11%\n",
      "Run: 06, Epoch: 179, Loss: 1.0127, Train: 60.62%, Valid: 58.02% Test: 52.41%\n",
      "Run: 06, Epoch: 180, Loss: 1.0073, Train: 65.57%, Valid: 62.96% Test: 60.75%\n",
      "Run: 06, Epoch: 181, Loss: 1.0050, Train: 63.55%, Valid: 61.59% Test: 60.53%\n",
      "Run: 06, Epoch: 182, Loss: 1.0179, Train: 63.74%, Valid: 61.32% Test: 58.77%\n",
      "Run: 06, Epoch: 183, Loss: 1.0233, Train: 62.00%, Valid: 57.06% Test: 53.95%\n",
      "Run: 06, Epoch: 184, Loss: 1.0044, Train: 63.19%, Valid: 58.44% Test: 58.77%\n",
      "Run: 06, Epoch: 185, Loss: 1.0190, Train: 62.82%, Valid: 58.57% Test: 57.46%\n",
      "Run: 06, Epoch: 186, Loss: 1.0134, Train: 63.92%, Valid: 61.18% Test: 60.75%\n",
      "Run: 06, Epoch: 187, Loss: 0.9899, Train: 64.84%, Valid: 62.55% Test: 61.62%\n",
      "Run: 06, Epoch: 188, Loss: 0.9987, Train: 66.67%, Valid: 62.55% Test: 61.18%\n",
      "Run: 06, Epoch: 189, Loss: 0.9868, Train: 66.48%, Valid: 61.87% Test: 60.31%\n",
      "Run: 06, Epoch: 190, Loss: 1.0118, Train: 65.02%, Valid: 61.45% Test: 59.65%\n",
      "Run: 06, Epoch: 191, Loss: 0.9922, Train: 63.83%, Valid: 61.59% Test: 56.80%\n",
      "Run: 06, Epoch: 192, Loss: 1.0133, Train: 62.00%, Valid: 61.59% Test: 58.99%\n",
      "Run: 06, Epoch: 193, Loss: 0.9901, Train: 62.36%, Valid: 62.00% Test: 59.65%\n",
      "Run: 06, Epoch: 194, Loss: 1.0048, Train: 63.10%, Valid: 62.69% Test: 61.62%\n",
      "Run: 06, Epoch: 195, Loss: 1.0072, Train: 64.29%, Valid: 61.18% Test: 60.31%\n",
      "Run: 06, Epoch: 196, Loss: 1.0070, Train: 64.29%, Valid: 61.73% Test: 59.43%\n",
      "Run: 06, Epoch: 197, Loss: 1.0077, Train: 63.74%, Valid: 61.87% Test: 59.87%\n",
      "Run: 06, Epoch: 198, Loss: 0.9786, Train: 62.64%, Valid: 59.26% Test: 57.89%\n",
      "Run: 06, Epoch: 199, Loss: 1.0029, Train: 66.30%, Valid: 62.83% Test: 61.18%\n",
      "Run: 06, Epoch: 200, Loss: 1.0075, Train: 63.64%, Valid: 62.83% Test: 64.04%\n",
      "Run 06:\n",
      "Highest Train: 66.67\n",
      "Highest Valid: 62.96\n",
      "  Final Train: 65.57\n",
      "   Final Test: 60.75\n",
      "Run: 07, Epoch: 01, Loss: 1.9316, Train: 21.61%, Valid: 22.22% Test: 19.30%\n",
      "Run: 07, Epoch: 02, Loss: 1.3913, Train: 22.99%, Valid: 24.42% Test: 20.18%\n",
      "Run: 07, Epoch: 03, Loss: 1.6095, Train: 28.02%, Valid: 27.30% Test: 25.66%\n",
      "Run: 07, Epoch: 04, Loss: 1.4925, Train: 31.04%, Valid: 31.41% Test: 27.63%\n",
      "Run: 07, Epoch: 05, Loss: 1.3554, Train: 31.59%, Valid: 30.04% Test: 27.63%\n",
      "Run: 07, Epoch: 06, Loss: 1.3870, Train: 33.42%, Valid: 31.55% Test: 27.85%\n",
      "Run: 07, Epoch: 07, Loss: 1.3635, Train: 41.39%, Valid: 41.02% Test: 37.28%\n",
      "Run: 07, Epoch: 08, Loss: 1.3269, Train: 35.90%, Valid: 35.39% Test: 32.46%\n",
      "Run: 07, Epoch: 09, Loss: 1.3244, Train: 41.94%, Valid: 38.82% Test: 39.69%\n",
      "Run: 07, Epoch: 10, Loss: 1.2855, Train: 41.67%, Valid: 36.35% Test: 38.38%\n",
      "Run: 07, Epoch: 11, Loss: 1.3054, Train: 37.36%, Valid: 33.74% Test: 34.43%\n",
      "Run: 07, Epoch: 12, Loss: 1.2823, Train: 36.63%, Valid: 32.78% Test: 33.99%\n",
      "Run: 07, Epoch: 13, Loss: 1.2856, Train: 41.21%, Valid: 35.80% Test: 37.94%\n",
      "Run: 07, Epoch: 14, Loss: 1.2424, Train: 41.48%, Valid: 36.63% Test: 40.57%\n",
      "Run: 07, Epoch: 15, Loss: 1.2284, Train: 43.13%, Valid: 38.82% Test: 39.04%\n",
      "Run: 07, Epoch: 16, Loss: 1.2253, Train: 47.34%, Valid: 41.84% Test: 42.98%\n",
      "Run: 07, Epoch: 17, Loss: 1.2148, Train: 45.15%, Valid: 42.80% Test: 42.11%\n",
      "Run: 07, Epoch: 18, Loss: 1.2081, Train: 46.06%, Valid: 43.48% Test: 44.74%\n",
      "Run: 07, Epoch: 19, Loss: 1.2079, Train: 45.51%, Valid: 42.80% Test: 41.67%\n",
      "Run: 07, Epoch: 20, Loss: 1.2067, Train: 44.41%, Valid: 41.02% Test: 40.79%\n",
      "Run: 07, Epoch: 21, Loss: 1.1790, Train: 49.08%, Valid: 45.40% Test: 44.74%\n",
      "Run: 07, Epoch: 22, Loss: 1.1941, Train: 51.65%, Valid: 48.70% Test: 45.83%\n",
      "Run: 07, Epoch: 23, Loss: 1.1898, Train: 49.91%, Valid: 46.91% Test: 45.39%\n",
      "Run: 07, Epoch: 24, Loss: 1.2012, Train: 47.53%, Valid: 44.99% Test: 44.52%\n",
      "Run: 07, Epoch: 25, Loss: 1.1593, Train: 50.55%, Valid: 46.09% Test: 46.27%\n",
      "Run: 07, Epoch: 26, Loss: 1.1442, Train: 47.53%, Valid: 44.03% Test: 44.30%\n",
      "Run: 07, Epoch: 27, Loss: 1.1786, Train: 51.74%, Valid: 49.25% Test: 45.61%\n",
      "Run: 07, Epoch: 28, Loss: 1.1819, Train: 54.03%, Valid: 51.99% Test: 47.59%\n",
      "Run: 07, Epoch: 29, Loss: 1.1528, Train: 52.84%, Valid: 51.30% Test: 46.27%\n",
      "Run: 07, Epoch: 30, Loss: 1.1888, Train: 53.02%, Valid: 48.56% Test: 46.49%\n",
      "Run: 07, Epoch: 31, Loss: 1.1339, Train: 56.32%, Valid: 48.97% Test: 48.03%\n",
      "Run: 07, Epoch: 32, Loss: 1.1725, Train: 46.61%, Valid: 41.84% Test: 43.42%\n",
      "Run: 07, Epoch: 33, Loss: 1.1489, Train: 43.50%, Valid: 40.05% Test: 41.89%\n",
      "Run: 07, Epoch: 34, Loss: 1.1403, Train: 45.42%, Valid: 42.25% Test: 42.76%\n",
      "Run: 07, Epoch: 35, Loss: 1.1207, Train: 50.27%, Valid: 49.38% Test: 46.71%\n",
      "Run: 07, Epoch: 36, Loss: 1.1285, Train: 50.73%, Valid: 48.42% Test: 46.05%\n",
      "Run: 07, Epoch: 37, Loss: 1.1089, Train: 48.72%, Valid: 45.40% Test: 46.93%\n",
      "Run: 07, Epoch: 38, Loss: 1.1093, Train: 48.44%, Valid: 45.68% Test: 45.61%\n",
      "Run: 07, Epoch: 39, Loss: 1.0991, Train: 52.66%, Valid: 49.79% Test: 49.34%\n",
      "Run: 07, Epoch: 40, Loss: 1.0988, Train: 52.75%, Valid: 49.38% Test: 50.66%\n",
      "Run: 07, Epoch: 41, Loss: 1.0851, Train: 50.64%, Valid: 47.33% Test: 49.56%\n",
      "Run: 07, Epoch: 42, Loss: 1.1259, Train: 54.40%, Valid: 50.89% Test: 51.97%\n",
      "Run: 07, Epoch: 43, Loss: 1.0832, Train: 54.58%, Valid: 51.85% Test: 49.56%\n",
      "Run: 07, Epoch: 44, Loss: 1.0883, Train: 53.66%, Valid: 50.48% Test: 47.81%\n",
      "Run: 07, Epoch: 45, Loss: 1.0841, Train: 50.37%, Valid: 48.15% Test: 48.46%\n",
      "Run: 07, Epoch: 46, Loss: 1.0667, Train: 54.49%, Valid: 54.05% Test: 47.59%\n",
      "Run: 07, Epoch: 47, Loss: 1.0882, Train: 56.78%, Valid: 53.36% Test: 52.41%\n",
      "Run: 07, Epoch: 48, Loss: 1.0667, Train: 51.56%, Valid: 47.74% Test: 50.44%\n",
      "Run: 07, Epoch: 49, Loss: 1.0754, Train: 56.50%, Valid: 52.13% Test: 51.75%\n",
      "Run: 07, Epoch: 50, Loss: 1.0335, Train: 53.94%, Valid: 51.71% Test: 49.34%\n",
      "Run: 07, Epoch: 51, Loss: 1.0594, Train: 54.40%, Valid: 51.58% Test: 48.03%\n",
      "Run: 07, Epoch: 52, Loss: 1.0694, Train: 56.59%, Valid: 51.71% Test: 50.22%\n",
      "Run: 07, Epoch: 53, Loss: 1.0826, Train: 58.15%, Valid: 55.01% Test: 50.22%\n",
      "Run: 07, Epoch: 54, Loss: 1.1026, Train: 56.04%, Valid: 51.99% Test: 49.56%\n",
      "Run: 07, Epoch: 55, Loss: 1.0858, Train: 57.51%, Valid: 55.42% Test: 52.85%\n",
      "Run: 07, Epoch: 56, Loss: 1.0502, Train: 58.42%, Valid: 56.38% Test: 51.54%\n",
      "Run: 07, Epoch: 57, Loss: 1.0312, Train: 56.59%, Valid: 52.13% Test: 51.75%\n",
      "Run: 07, Epoch: 58, Loss: 1.0804, Train: 56.59%, Valid: 52.40% Test: 51.32%\n",
      "Run: 07, Epoch: 59, Loss: 1.0608, Train: 59.52%, Valid: 54.87% Test: 52.63%\n",
      "Run: 07, Epoch: 60, Loss: 1.0632, Train: 59.43%, Valid: 55.14% Test: 52.19%\n",
      "Run: 07, Epoch: 61, Loss: 1.0409, Train: 60.07%, Valid: 55.56% Test: 51.10%\n",
      "Run: 07, Epoch: 62, Loss: 1.0409, Train: 59.89%, Valid: 55.42% Test: 52.63%\n",
      "Run: 07, Epoch: 63, Loss: 1.0473, Train: 60.44%, Valid: 56.52% Test: 51.75%\n",
      "Run: 07, Epoch: 64, Loss: 1.0120, Train: 58.61%, Valid: 52.26% Test: 52.41%\n",
      "Run: 07, Epoch: 65, Loss: 1.0519, Train: 61.08%, Valid: 56.38% Test: 54.61%\n",
      "Run: 07, Epoch: 66, Loss: 1.0403, Train: 60.35%, Valid: 56.10% Test: 53.29%\n",
      "Run: 07, Epoch: 67, Loss: 1.0425, Train: 60.44%, Valid: 56.52% Test: 51.54%\n",
      "Run: 07, Epoch: 68, Loss: 1.0304, Train: 58.70%, Valid: 52.95% Test: 50.88%\n",
      "Run: 07, Epoch: 69, Loss: 1.0439, Train: 57.60%, Valid: 52.54% Test: 50.88%\n",
      "Run: 07, Epoch: 70, Loss: 1.0629, Train: 59.62%, Valid: 56.65% Test: 51.97%\n",
      "Run: 07, Epoch: 71, Loss: 1.0508, Train: 60.44%, Valid: 57.89% Test: 50.00%\n",
      "Run: 07, Epoch: 72, Loss: 1.0760, Train: 60.71%, Valid: 56.93% Test: 51.97%\n",
      "Run: 07, Epoch: 73, Loss: 1.0254, Train: 58.88%, Valid: 54.87% Test: 51.75%\n",
      "Run: 07, Epoch: 74, Loss: 1.0289, Train: 59.89%, Valid: 58.30% Test: 53.73%\n",
      "Run: 07, Epoch: 75, Loss: 1.0199, Train: 58.97%, Valid: 55.56% Test: 47.59%\n",
      "Run: 07, Epoch: 76, Loss: 1.0131, Train: 61.54%, Valid: 59.26% Test: 50.66%\n",
      "Run: 07, Epoch: 77, Loss: 1.0424, Train: 52.01%, Valid: 47.46% Test: 46.27%\n",
      "Run: 07, Epoch: 78, Loss: 1.0275, Train: 63.83%, Valid: 59.40% Test: 53.73%\n",
      "Run: 07, Epoch: 79, Loss: 1.0326, Train: 59.16%, Valid: 55.69% Test: 51.75%\n",
      "Run: 07, Epoch: 80, Loss: 1.0381, Train: 54.21%, Valid: 51.58% Test: 50.00%\n",
      "Run: 07, Epoch: 81, Loss: 1.0696, Train: 58.61%, Valid: 55.97% Test: 52.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 82, Loss: 1.0103, Train: 57.60%, Valid: 56.52% Test: 50.44%\n",
      "Run: 07, Epoch: 83, Loss: 1.0198, Train: 57.88%, Valid: 56.10% Test: 51.54%\n",
      "Run: 07, Epoch: 84, Loss: 1.0225, Train: 57.88%, Valid: 55.83% Test: 51.75%\n",
      "Run: 07, Epoch: 85, Loss: 1.0414, Train: 58.24%, Valid: 55.42% Test: 52.19%\n",
      "Run: 07, Epoch: 86, Loss: 1.0058, Train: 54.85%, Valid: 51.71% Test: 50.44%\n",
      "Run: 07, Epoch: 87, Loss: 1.0621, Train: 60.53%, Valid: 55.97% Test: 56.14%\n",
      "Run: 07, Epoch: 88, Loss: 1.0196, Train: 59.89%, Valid: 54.87% Test: 54.17%\n",
      "Run: 07, Epoch: 89, Loss: 1.0289, Train: 58.33%, Valid: 54.46% Test: 53.51%\n",
      "Run: 07, Epoch: 90, Loss: 1.0387, Train: 53.75%, Valid: 52.54% Test: 50.44%\n",
      "Run: 07, Epoch: 91, Loss: 1.0108, Train: 53.85%, Valid: 51.71% Test: 48.68%\n",
      "Run: 07, Epoch: 92, Loss: 1.0348, Train: 59.89%, Valid: 56.24% Test: 52.63%\n",
      "Run: 07, Epoch: 93, Loss: 1.0200, Train: 60.07%, Valid: 55.01% Test: 55.04%\n",
      "Run: 07, Epoch: 94, Loss: 1.0034, Train: 57.88%, Valid: 53.36% Test: 52.63%\n",
      "Run: 07, Epoch: 95, Loss: 1.0280, Train: 60.35%, Valid: 56.79% Test: 54.82%\n",
      "Run: 07, Epoch: 96, Loss: 1.0297, Train: 61.81%, Valid: 55.56% Test: 54.17%\n",
      "Run: 07, Epoch: 97, Loss: 1.0299, Train: 60.71%, Valid: 54.87% Test: 53.07%\n",
      "Run: 07, Epoch: 98, Loss: 1.0196, Train: 60.16%, Valid: 57.89% Test: 57.02%\n",
      "Run: 07, Epoch: 99, Loss: 1.0186, Train: 60.07%, Valid: 55.83% Test: 55.70%\n",
      "Run: 07, Epoch: 100, Loss: 1.0106, Train: 63.10%, Valid: 58.98% Test: 53.29%\n",
      "Run: 07, Epoch: 101, Loss: 1.0033, Train: 64.10%, Valid: 59.95% Test: 54.82%\n",
      "Run: 07, Epoch: 102, Loss: 1.0098, Train: 65.66%, Valid: 58.16% Test: 57.89%\n",
      "Run: 07, Epoch: 103, Loss: 1.0052, Train: 61.08%, Valid: 55.83% Test: 56.36%\n",
      "Run: 07, Epoch: 104, Loss: 1.0251, Train: 63.74%, Valid: 58.85% Test: 54.82%\n",
      "Run: 07, Epoch: 105, Loss: 0.9885, Train: 61.63%, Valid: 57.89% Test: 56.36%\n",
      "Run: 07, Epoch: 106, Loss: 0.9888, Train: 63.10%, Valid: 57.75% Test: 57.46%\n",
      "Run: 07, Epoch: 107, Loss: 0.9926, Train: 58.06%, Valid: 54.60% Test: 54.82%\n",
      "Run: 07, Epoch: 108, Loss: 1.0122, Train: 56.50%, Valid: 52.81% Test: 53.29%\n",
      "Run: 07, Epoch: 109, Loss: 1.0259, Train: 63.92%, Valid: 59.40% Test: 58.77%\n",
      "Run: 07, Epoch: 110, Loss: 0.9967, Train: 62.27%, Valid: 56.79% Test: 55.04%\n",
      "Run: 07, Epoch: 111, Loss: 0.9789, Train: 61.90%, Valid: 55.69% Test: 55.26%\n",
      "Run: 07, Epoch: 112, Loss: 1.0268, Train: 61.08%, Valid: 58.57% Test: 55.48%\n",
      "Run: 07, Epoch: 113, Loss: 1.0011, Train: 62.27%, Valid: 60.91% Test: 52.63%\n",
      "Run: 07, Epoch: 114, Loss: 1.0186, Train: 60.16%, Valid: 56.93% Test: 53.51%\n",
      "Run: 07, Epoch: 115, Loss: 1.0128, Train: 56.32%, Valid: 53.77% Test: 54.82%\n",
      "Run: 07, Epoch: 116, Loss: 1.0121, Train: 60.99%, Valid: 57.75% Test: 55.92%\n",
      "Run: 07, Epoch: 117, Loss: 0.9974, Train: 61.54%, Valid: 59.53% Test: 53.07%\n",
      "Run: 07, Epoch: 118, Loss: 1.0009, Train: 63.37%, Valid: 59.67% Test: 54.39%\n",
      "Run: 07, Epoch: 119, Loss: 0.9831, Train: 60.90%, Valid: 53.22% Test: 52.19%\n",
      "Run: 07, Epoch: 120, Loss: 1.0156, Train: 60.35%, Valid: 53.91% Test: 51.75%\n",
      "Run: 07, Epoch: 121, Loss: 1.0170, Train: 63.28%, Valid: 60.49% Test: 54.17%\n",
      "Run: 07, Epoch: 122, Loss: 0.9825, Train: 59.71%, Valid: 58.85% Test: 53.29%\n",
      "Run: 07, Epoch: 123, Loss: 1.0236, Train: 60.16%, Valid: 59.40% Test: 54.61%\n",
      "Run: 07, Epoch: 124, Loss: 0.9667, Train: 60.35%, Valid: 57.34% Test: 56.36%\n",
      "Run: 07, Epoch: 125, Loss: 1.0197, Train: 61.63%, Valid: 57.20% Test: 51.97%\n",
      "Run: 07, Epoch: 126, Loss: 0.9886, Train: 59.71%, Valid: 55.97% Test: 49.34%\n",
      "Run: 07, Epoch: 127, Loss: 1.0273, Train: 63.00%, Valid: 62.28% Test: 57.68%\n",
      "Run: 07, Epoch: 128, Loss: 0.9913, Train: 54.95%, Valid: 54.18% Test: 52.19%\n",
      "Run: 07, Epoch: 129, Loss: 1.0284, Train: 60.35%, Valid: 57.34% Test: 55.48%\n",
      "Run: 07, Epoch: 130, Loss: 0.9863, Train: 65.48%, Valid: 62.83% Test: 55.92%\n",
      "Run: 07, Epoch: 131, Loss: 0.9767, Train: 63.83%, Valid: 59.95% Test: 53.51%\n",
      "Run: 07, Epoch: 132, Loss: 0.9963, Train: 61.72%, Valid: 57.06% Test: 55.48%\n",
      "Run: 07, Epoch: 133, Loss: 0.9848, Train: 61.17%, Valid: 55.28% Test: 55.48%\n",
      "Run: 07, Epoch: 134, Loss: 0.9906, Train: 64.84%, Valid: 60.22% Test: 54.82%\n",
      "Run: 07, Epoch: 135, Loss: 0.9804, Train: 63.28%, Valid: 62.83% Test: 55.48%\n",
      "Run: 07, Epoch: 136, Loss: 0.9646, Train: 60.26%, Valid: 58.57% Test: 54.39%\n",
      "Run: 07, Epoch: 137, Loss: 1.0571, Train: 64.84%, Valid: 61.04% Test: 55.92%\n",
      "Run: 07, Epoch: 138, Loss: 0.9955, Train: 63.19%, Valid: 60.08% Test: 55.48%\n",
      "Run: 07, Epoch: 139, Loss: 0.9818, Train: 60.90%, Valid: 58.98% Test: 55.92%\n",
      "Run: 07, Epoch: 140, Loss: 0.9653, Train: 60.62%, Valid: 58.30% Test: 56.58%\n",
      "Run: 07, Epoch: 141, Loss: 0.9855, Train: 61.72%, Valid: 59.12% Test: 54.17%\n",
      "Run: 07, Epoch: 142, Loss: 0.9848, Train: 64.84%, Valid: 61.59% Test: 54.17%\n",
      "Run: 07, Epoch: 143, Loss: 0.9919, Train: 63.10%, Valid: 60.22% Test: 54.17%\n",
      "Run: 07, Epoch: 144, Loss: 0.9889, Train: 67.40%, Valid: 62.83% Test: 59.87%\n",
      "Run: 07, Epoch: 145, Loss: 0.9939, Train: 63.83%, Valid: 62.00% Test: 56.80%\n",
      "Run: 07, Epoch: 146, Loss: 0.9894, Train: 64.10%, Valid: 61.32% Test: 55.92%\n",
      "Run: 07, Epoch: 147, Loss: 0.9855, Train: 63.64%, Valid: 58.71% Test: 58.11%\n",
      "Run: 07, Epoch: 148, Loss: 0.9811, Train: 62.64%, Valid: 58.98% Test: 57.02%\n",
      "Run: 07, Epoch: 149, Loss: 0.9840, Train: 65.75%, Valid: 60.91% Test: 55.48%\n",
      "Run: 07, Epoch: 150, Loss: 0.9614, Train: 64.65%, Valid: 60.22% Test: 54.82%\n",
      "Run: 07, Epoch: 151, Loss: 0.9683, Train: 63.74%, Valid: 58.57% Test: 57.89%\n",
      "Run: 07, Epoch: 152, Loss: 0.9553, Train: 62.45%, Valid: 58.44% Test: 56.80%\n",
      "Run: 07, Epoch: 153, Loss: 0.9613, Train: 63.28%, Valid: 60.49% Test: 57.68%\n",
      "Run: 07, Epoch: 154, Loss: 0.9862, Train: 60.62%, Valid: 60.08% Test: 55.04%\n",
      "Run: 07, Epoch: 155, Loss: 0.9716, Train: 64.93%, Valid: 61.73% Test: 56.14%\n",
      "Run: 07, Epoch: 156, Loss: 0.9817, Train: 65.48%, Valid: 61.59% Test: 58.33%\n",
      "Run: 07, Epoch: 157, Loss: 0.9707, Train: 60.71%, Valid: 56.65% Test: 56.80%\n",
      "Run: 07, Epoch: 158, Loss: 0.9890, Train: 65.93%, Valid: 61.04% Test: 57.46%\n",
      "Run: 07, Epoch: 159, Loss: 0.9868, Train: 65.20%, Valid: 63.10% Test: 55.48%\n",
      "Run: 07, Epoch: 160, Loss: 0.9497, Train: 64.19%, Valid: 62.83% Test: 54.39%\n",
      "Run: 07, Epoch: 161, Loss: 0.9550, Train: 64.47%, Valid: 61.45% Test: 56.14%\n",
      "Run: 07, Epoch: 162, Loss: 0.9599, Train: 65.02%, Valid: 61.59% Test: 58.99%\n",
      "Run: 07, Epoch: 163, Loss: 0.9610, Train: 66.39%, Valid: 62.00% Test: 57.46%\n",
      "Run: 07, Epoch: 164, Loss: 0.9622, Train: 66.12%, Valid: 63.10% Test: 56.14%\n",
      "Run: 07, Epoch: 165, Loss: 0.9750, Train: 66.85%, Valid: 64.20% Test: 58.77%\n",
      "Run: 07, Epoch: 166, Loss: 0.9490, Train: 67.58%, Valid: 62.41% Test: 58.33%\n",
      "Run: 07, Epoch: 167, Loss: 0.9660, Train: 65.02%, Valid: 62.41% Test: 59.21%\n",
      "Run: 07, Epoch: 168, Loss: 0.9532, Train: 62.91%, Valid: 61.18% Test: 57.24%\n",
      "Run: 07, Epoch: 169, Loss: 0.9666, Train: 67.22%, Valid: 61.73% Test: 60.09%\n",
      "Run: 07, Epoch: 170, Loss: 0.9478, Train: 64.74%, Valid: 56.65% Test: 60.31%\n",
      "Run: 07, Epoch: 171, Loss: 0.9774, Train: 64.56%, Valid: 58.57% Test: 60.09%\n",
      "Run: 07, Epoch: 172, Loss: 0.9404, Train: 66.39%, Valid: 61.18% Test: 59.43%\n",
      "Run: 07, Epoch: 173, Loss: 0.9539, Train: 65.38%, Valid: 62.41% Test: 57.46%\n",
      "Run: 07, Epoch: 174, Loss: 0.9689, Train: 68.13%, Valid: 60.63% Test: 60.75%\n",
      "Run: 07, Epoch: 175, Loss: 0.9213, Train: 63.64%, Valid: 56.79% Test: 56.58%\n",
      "Run: 07, Epoch: 176, Loss: 0.9704, Train: 64.56%, Valid: 58.85% Test: 57.24%\n",
      "Run: 07, Epoch: 177, Loss: 0.9479, Train: 67.03%, Valid: 63.37% Test: 58.55%\n",
      "Run: 07, Epoch: 178, Loss: 0.9718, Train: 66.21%, Valid: 64.06% Test: 56.80%\n",
      "Run: 07, Epoch: 179, Loss: 0.9529, Train: 65.57%, Valid: 63.37% Test: 58.11%\n",
      "Run: 07, Epoch: 180, Loss: 0.9714, Train: 65.02%, Valid: 60.22% Test: 56.36%\n",
      "Run: 07, Epoch: 181, Loss: 0.9813, Train: 64.19%, Valid: 59.95% Test: 56.80%\n",
      "Run: 07, Epoch: 182, Loss: 0.9723, Train: 66.21%, Valid: 61.59% Test: 58.33%\n",
      "Run: 07, Epoch: 183, Loss: 0.9519, Train: 64.93%, Valid: 61.04% Test: 57.24%\n",
      "Run: 07, Epoch: 184, Loss: 0.9564, Train: 66.76%, Valid: 60.08% Test: 57.24%\n",
      "Run: 07, Epoch: 185, Loss: 0.9589, Train: 68.04%, Valid: 62.00% Test: 59.21%\n",
      "Run: 07, Epoch: 186, Loss: 0.9512, Train: 66.39%, Valid: 62.28% Test: 57.89%\n",
      "Run: 07, Epoch: 187, Loss: 0.9392, Train: 66.39%, Valid: 62.69% Test: 57.89%\n",
      "Run: 07, Epoch: 188, Loss: 0.9631, Train: 67.22%, Valid: 61.59% Test: 58.33%\n",
      "Run: 07, Epoch: 189, Loss: 0.9520, Train: 66.21%, Valid: 61.87% Test: 57.68%\n",
      "Run: 07, Epoch: 190, Loss: 0.9490, Train: 63.00%, Valid: 61.18% Test: 57.02%\n",
      "Run: 07, Epoch: 191, Loss: 0.9406, Train: 66.39%, Valid: 62.69% Test: 57.89%\n",
      "Run: 07, Epoch: 192, Loss: 0.9490, Train: 66.58%, Valid: 62.96% Test: 57.02%\n",
      "Run: 07, Epoch: 193, Loss: 0.9362, Train: 66.76%, Valid: 64.06% Test: 57.24%\n",
      "Run: 07, Epoch: 194, Loss: 0.9464, Train: 65.29%, Valid: 60.77% Test: 56.14%\n",
      "Run: 07, Epoch: 195, Loss: 0.9362, Train: 64.74%, Valid: 62.28% Test: 55.92%\n",
      "Run: 07, Epoch: 196, Loss: 0.9619, Train: 65.02%, Valid: 60.22% Test: 58.77%\n",
      "Run: 07, Epoch: 197, Loss: 0.9381, Train: 64.84%, Valid: 61.73% Test: 58.33%\n",
      "Run: 07, Epoch: 198, Loss: 0.9246, Train: 62.73%, Valid: 56.38% Test: 54.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 199, Loss: 0.9291, Train: 66.21%, Valid: 60.77% Test: 58.33%\n",
      "Run: 07, Epoch: 200, Loss: 0.9412, Train: 65.48%, Valid: 62.83% Test: 56.14%\n",
      "Run 07:\n",
      "Highest Train: 68.13\n",
      "Highest Valid: 64.20\n",
      "  Final Train: 66.85\n",
      "   Final Test: 58.77\n",
      "Run: 08, Epoch: 01, Loss: 1.8938, Train: 16.58%, Valid: 17.01% Test: 19.08%\n",
      "Run: 08, Epoch: 02, Loss: 1.4531, Train: 24.73%, Valid: 27.43% Test: 25.88%\n",
      "Run: 08, Epoch: 03, Loss: 1.4496, Train: 34.52%, Valid: 36.08% Test: 33.77%\n",
      "Run: 08, Epoch: 04, Loss: 1.3771, Train: 34.34%, Valid: 35.67% Test: 37.06%\n",
      "Run: 08, Epoch: 05, Loss: 1.3863, Train: 33.33%, Valid: 34.84% Test: 38.38%\n",
      "Run: 08, Epoch: 06, Loss: 1.4160, Train: 41.12%, Valid: 40.33% Test: 36.84%\n",
      "Run: 08, Epoch: 07, Loss: 1.2991, Train: 32.51%, Valid: 34.98% Test: 32.24%\n",
      "Run: 08, Epoch: 08, Loss: 1.3670, Train: 37.64%, Valid: 38.00% Test: 37.28%\n",
      "Run: 08, Epoch: 09, Loss: 1.2799, Train: 40.29%, Valid: 38.68% Test: 37.50%\n",
      "Run: 08, Epoch: 10, Loss: 1.2941, Train: 39.84%, Valid: 42.94% Test: 40.13%\n",
      "Run: 08, Epoch: 11, Loss: 1.2548, Train: 40.48%, Valid: 42.66% Test: 40.13%\n",
      "Run: 08, Epoch: 12, Loss: 1.2687, Train: 39.19%, Valid: 42.11% Test: 38.38%\n",
      "Run: 08, Epoch: 13, Loss: 1.2581, Train: 42.22%, Valid: 41.56% Test: 39.04%\n",
      "Run: 08, Epoch: 14, Loss: 1.2409, Train: 43.68%, Valid: 40.88% Test: 38.38%\n",
      "Run: 08, Epoch: 15, Loss: 1.2433, Train: 39.19%, Valid: 38.96% Test: 39.25%\n",
      "Run: 08, Epoch: 16, Loss: 1.2391, Train: 41.58%, Valid: 42.39% Test: 41.01%\n",
      "Run: 08, Epoch: 17, Loss: 1.2182, Train: 42.95%, Valid: 44.03% Test: 41.67%\n",
      "Run: 08, Epoch: 18, Loss: 1.2172, Train: 41.94%, Valid: 41.56% Test: 39.91%\n",
      "Run: 08, Epoch: 19, Loss: 1.1838, Train: 42.40%, Valid: 41.15% Test: 41.45%\n",
      "Run: 08, Epoch: 20, Loss: 1.2169, Train: 43.77%, Valid: 41.70% Test: 43.20%\n",
      "Run: 08, Epoch: 21, Loss: 1.1897, Train: 43.13%, Valid: 41.98% Test: 41.23%\n",
      "Run: 08, Epoch: 22, Loss: 1.1993, Train: 42.12%, Valid: 41.02% Test: 40.35%\n",
      "Run: 08, Epoch: 23, Loss: 1.2045, Train: 45.42%, Valid: 42.94% Test: 44.96%\n",
      "Run: 08, Epoch: 24, Loss: 1.1900, Train: 45.33%, Valid: 42.66% Test: 44.30%\n",
      "Run: 08, Epoch: 25, Loss: 1.1929, Train: 47.07%, Valid: 45.13% Test: 46.27%\n",
      "Run: 08, Epoch: 26, Loss: 1.1889, Train: 46.70%, Valid: 43.21% Test: 45.39%\n",
      "Run: 08, Epoch: 27, Loss: 1.1765, Train: 47.62%, Valid: 45.13% Test: 49.78%\n",
      "Run: 08, Epoch: 28, Loss: 1.1600, Train: 46.70%, Valid: 44.72% Test: 47.59%\n",
      "Run: 08, Epoch: 29, Loss: 1.1641, Train: 44.87%, Valid: 41.70% Test: 42.32%\n",
      "Run: 08, Epoch: 30, Loss: 1.1439, Train: 48.35%, Valid: 45.95% Test: 46.27%\n",
      "Run: 08, Epoch: 31, Loss: 1.1512, Train: 51.56%, Valid: 50.75% Test: 50.00%\n",
      "Run: 08, Epoch: 32, Loss: 1.1631, Train: 46.89%, Valid: 43.21% Test: 41.67%\n",
      "Run: 08, Epoch: 33, Loss: 1.1442, Train: 46.25%, Valid: 42.25% Test: 41.45%\n",
      "Run: 08, Epoch: 34, Loss: 1.1571, Train: 51.28%, Valid: 49.66% Test: 47.59%\n",
      "Run: 08, Epoch: 35, Loss: 1.1342, Train: 54.12%, Valid: 52.95% Test: 53.07%\n",
      "Run: 08, Epoch: 36, Loss: 1.1349, Train: 52.29%, Valid: 49.38% Test: 47.15%\n",
      "Run: 08, Epoch: 37, Loss: 1.1228, Train: 51.65%, Valid: 48.29% Test: 46.93%\n",
      "Run: 08, Epoch: 38, Loss: 1.1444, Train: 52.29%, Valid: 49.93% Test: 47.37%\n",
      "Run: 08, Epoch: 39, Loss: 1.1236, Train: 53.94%, Valid: 52.95% Test: 50.44%\n",
      "Run: 08, Epoch: 40, Loss: 1.1164, Train: 55.04%, Valid: 52.81% Test: 50.66%\n",
      "Run: 08, Epoch: 41, Loss: 1.1123, Train: 54.30%, Valid: 51.85% Test: 51.97%\n",
      "Run: 08, Epoch: 42, Loss: 1.1250, Train: 54.03%, Valid: 53.91% Test: 52.19%\n",
      "Run: 08, Epoch: 43, Loss: 1.1068, Train: 54.58%, Valid: 53.77% Test: 51.75%\n",
      "Run: 08, Epoch: 44, Loss: 1.1038, Train: 48.81%, Valid: 48.42% Test: 46.71%\n",
      "Run: 08, Epoch: 45, Loss: 1.1237, Train: 50.37%, Valid: 48.15% Test: 43.86%\n",
      "Run: 08, Epoch: 46, Loss: 1.1109, Train: 49.82%, Valid: 49.52% Test: 47.37%\n",
      "Run: 08, Epoch: 47, Loss: 1.1547, Train: 54.76%, Valid: 51.17% Test: 52.19%\n",
      "Run: 08, Epoch: 48, Loss: 1.1083, Train: 53.39%, Valid: 53.36% Test: 49.34%\n",
      "Run: 08, Epoch: 49, Loss: 1.1514, Train: 55.49%, Valid: 54.73% Test: 55.70%\n",
      "Run: 08, Epoch: 50, Loss: 1.1205, Train: 52.20%, Valid: 51.71% Test: 53.95%\n",
      "Run: 08, Epoch: 51, Loss: 1.0975, Train: 50.18%, Valid: 49.93% Test: 47.59%\n",
      "Run: 08, Epoch: 52, Loss: 1.1275, Train: 50.18%, Valid: 50.89% Test: 49.34%\n",
      "Run: 08, Epoch: 53, Loss: 1.1118, Train: 53.02%, Valid: 51.17% Test: 50.22%\n",
      "Run: 08, Epoch: 54, Loss: 1.1010, Train: 52.66%, Valid: 50.34% Test: 46.93%\n",
      "Run: 08, Epoch: 55, Loss: 1.1068, Train: 54.21%, Valid: 53.36% Test: 50.00%\n",
      "Run: 08, Epoch: 56, Loss: 1.1163, Train: 51.37%, Valid: 48.56% Test: 45.61%\n",
      "Run: 08, Epoch: 57, Loss: 1.1069, Train: 51.37%, Valid: 48.42% Test: 47.15%\n",
      "Run: 08, Epoch: 58, Loss: 1.0784, Train: 55.04%, Valid: 50.89% Test: 52.85%\n",
      "Run: 08, Epoch: 59, Loss: 1.1228, Train: 50.64%, Valid: 47.05% Test: 45.61%\n",
      "Run: 08, Epoch: 60, Loss: 1.1026, Train: 50.37%, Valid: 47.33% Test: 45.61%\n",
      "Run: 08, Epoch: 61, Loss: 1.1118, Train: 52.20%, Valid: 51.44% Test: 48.90%\n",
      "Run: 08, Epoch: 62, Loss: 1.1147, Train: 55.49%, Valid: 55.28% Test: 52.19%\n",
      "Run: 08, Epoch: 63, Loss: 1.1108, Train: 57.33%, Valid: 54.05% Test: 57.02%\n",
      "Run: 08, Epoch: 64, Loss: 1.1069, Train: 53.21%, Valid: 50.21% Test: 49.12%\n",
      "Run: 08, Epoch: 65, Loss: 1.1251, Train: 54.76%, Valid: 51.44% Test: 51.97%\n",
      "Run: 08, Epoch: 66, Loss: 1.1005, Train: 57.60%, Valid: 55.42% Test: 58.33%\n",
      "Run: 08, Epoch: 67, Loss: 1.0892, Train: 58.15%, Valid: 56.38% Test: 58.11%\n",
      "Run: 08, Epoch: 68, Loss: 1.0772, Train: 55.49%, Valid: 52.81% Test: 53.07%\n",
      "Run: 08, Epoch: 69, Loss: 1.0987, Train: 54.40%, Valid: 48.83% Test: 49.34%\n",
      "Run: 08, Epoch: 70, Loss: 1.0773, Train: 56.50%, Valid: 52.13% Test: 51.75%\n",
      "Run: 08, Epoch: 71, Loss: 1.0926, Train: 54.40%, Valid: 52.40% Test: 52.19%\n",
      "Run: 08, Epoch: 72, Loss: 1.0726, Train: 55.59%, Valid: 52.81% Test: 53.95%\n",
      "Run: 08, Epoch: 73, Loss: 1.0823, Train: 57.42%, Valid: 51.71% Test: 55.92%\n",
      "Run: 08, Epoch: 74, Loss: 1.0634, Train: 57.42%, Valid: 53.77% Test: 55.92%\n",
      "Run: 08, Epoch: 75, Loss: 1.0687, Train: 58.52%, Valid: 57.61% Test: 57.68%\n",
      "Run: 08, Epoch: 76, Loss: 1.0896, Train: 59.71%, Valid: 56.93% Test: 57.89%\n",
      "Run: 08, Epoch: 77, Loss: 1.0648, Train: 56.23%, Valid: 51.44% Test: 54.82%\n",
      "Run: 08, Epoch: 78, Loss: 1.0793, Train: 58.15%, Valid: 54.73% Test: 53.73%\n",
      "Run: 08, Epoch: 79, Loss: 1.0637, Train: 58.33%, Valid: 55.83% Test: 57.89%\n",
      "Run: 08, Epoch: 80, Loss: 1.0964, Train: 54.95%, Valid: 51.44% Test: 51.54%\n",
      "Run: 08, Epoch: 81, Loss: 1.0734, Train: 53.39%, Valid: 48.42% Test: 48.25%\n",
      "Run: 08, Epoch: 82, Loss: 1.0539, Train: 54.95%, Valid: 50.62% Test: 49.34%\n",
      "Run: 08, Epoch: 83, Loss: 1.0914, Train: 58.70%, Valid: 56.65% Test: 58.55%\n",
      "Run: 08, Epoch: 84, Loss: 1.0470, Train: 57.23%, Valid: 54.18% Test: 53.51%\n",
      "Run: 08, Epoch: 85, Loss: 1.0989, Train: 56.14%, Valid: 53.50% Test: 52.63%\n",
      "Run: 08, Epoch: 86, Loss: 1.0701, Train: 59.07%, Valid: 57.61% Test: 56.80%\n",
      "Run: 08, Epoch: 87, Loss: 1.0526, Train: 60.62%, Valid: 56.93% Test: 57.89%\n",
      "Run: 08, Epoch: 88, Loss: 1.0721, Train: 59.34%, Valid: 55.14% Test: 55.48%\n",
      "Run: 08, Epoch: 89, Loss: 1.0615, Train: 59.43%, Valid: 56.93% Test: 56.36%\n",
      "Run: 08, Epoch: 90, Loss: 1.0824, Train: 59.89%, Valid: 55.97% Test: 56.36%\n",
      "Run: 08, Epoch: 91, Loss: 1.0417, Train: 56.68%, Valid: 54.32% Test: 53.51%\n",
      "Run: 08, Epoch: 92, Loss: 1.0552, Train: 57.51%, Valid: 55.14% Test: 56.58%\n",
      "Run: 08, Epoch: 93, Loss: 1.0467, Train: 54.95%, Valid: 51.71% Test: 49.12%\n",
      "Run: 08, Epoch: 94, Loss: 1.0687, Train: 59.80%, Valid: 57.34% Test: 55.70%\n",
      "Run: 08, Epoch: 95, Loss: 1.0459, Train: 60.44%, Valid: 58.44% Test: 60.09%\n",
      "Run: 08, Epoch: 96, Loss: 1.0561, Train: 60.81%, Valid: 56.79% Test: 56.36%\n",
      "Run: 08, Epoch: 97, Loss: 1.0798, Train: 61.63%, Valid: 58.57% Test: 58.55%\n",
      "Run: 08, Epoch: 98, Loss: 1.0647, Train: 59.62%, Valid: 59.26% Test: 57.46%\n",
      "Run: 08, Epoch: 99, Loss: 1.0537, Train: 60.53%, Valid: 60.08% Test: 57.89%\n",
      "Run: 08, Epoch: 100, Loss: 1.0669, Train: 61.26%, Valid: 58.71% Test: 58.11%\n",
      "Run: 08, Epoch: 101, Loss: 1.0539, Train: 62.73%, Valid: 58.02% Test: 59.87%\n",
      "Run: 08, Epoch: 102, Loss: 1.0769, Train: 62.82%, Valid: 59.53% Test: 61.40%\n",
      "Run: 08, Epoch: 103, Loss: 1.0432, Train: 62.09%, Valid: 57.75% Test: 60.09%\n",
      "Run: 08, Epoch: 104, Loss: 1.0356, Train: 58.88%, Valid: 55.56% Test: 53.29%\n",
      "Run: 08, Epoch: 105, Loss: 1.0306, Train: 59.80%, Valid: 56.65% Test: 56.14%\n",
      "Run: 08, Epoch: 106, Loss: 1.0327, Train: 57.42%, Valid: 55.56% Test: 60.96%\n",
      "Run: 08, Epoch: 107, Loss: 1.0358, Train: 58.61%, Valid: 56.65% Test: 58.33%\n",
      "Run: 08, Epoch: 108, Loss: 1.0508, Train: 58.15%, Valid: 54.73% Test: 57.02%\n",
      "Run: 08, Epoch: 109, Loss: 1.0410, Train: 58.24%, Valid: 53.64% Test: 54.61%\n",
      "Run: 08, Epoch: 110, Loss: 1.0630, Train: 61.36%, Valid: 58.71% Test: 57.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 111, Loss: 1.0544, Train: 58.97%, Valid: 58.16% Test: 58.77%\n",
      "Run: 08, Epoch: 112, Loss: 1.0734, Train: 58.33%, Valid: 55.56% Test: 55.48%\n",
      "Run: 08, Epoch: 113, Loss: 1.0430, Train: 59.52%, Valid: 56.24% Test: 55.92%\n",
      "Run: 08, Epoch: 114, Loss: 1.0249, Train: 61.72%, Valid: 58.16% Test: 58.55%\n",
      "Run: 08, Epoch: 115, Loss: 1.0307, Train: 54.49%, Valid: 54.05% Test: 53.95%\n",
      "Run: 08, Epoch: 116, Loss: 1.0711, Train: 57.05%, Valid: 55.01% Test: 52.85%\n",
      "Run: 08, Epoch: 117, Loss: 1.0354, Train: 58.24%, Valid: 54.60% Test: 50.00%\n",
      "Run: 08, Epoch: 118, Loss: 1.0467, Train: 60.16%, Valid: 58.44% Test: 56.58%\n",
      "Run: 08, Epoch: 119, Loss: 1.0195, Train: 61.63%, Valid: 57.75% Test: 59.21%\n",
      "Run: 08, Epoch: 120, Loss: 1.0251, Train: 57.23%, Valid: 54.32% Test: 57.24%\n",
      "Run: 08, Epoch: 121, Loss: 1.0285, Train: 60.35%, Valid: 57.06% Test: 57.46%\n",
      "Run: 08, Epoch: 122, Loss: 0.9976, Train: 62.82%, Valid: 58.98% Test: 57.46%\n",
      "Run: 08, Epoch: 123, Loss: 1.0000, Train: 62.36%, Valid: 57.34% Test: 56.80%\n",
      "Run: 08, Epoch: 124, Loss: 1.0175, Train: 60.71%, Valid: 58.57% Test: 60.75%\n",
      "Run: 08, Epoch: 125, Loss: 1.0277, Train: 60.35%, Valid: 56.52% Test: 59.65%\n",
      "Run: 08, Epoch: 126, Loss: 1.0364, Train: 57.78%, Valid: 52.40% Test: 51.97%\n",
      "Run: 08, Epoch: 127, Loss: 1.0166, Train: 53.02%, Valid: 48.97% Test: 46.71%\n",
      "Run: 08, Epoch: 128, Loss: 1.0503, Train: 59.89%, Valid: 60.22% Test: 60.53%\n",
      "Run: 08, Epoch: 129, Loss: 1.0309, Train: 57.69%, Valid: 56.10% Test: 60.09%\n",
      "Run: 08, Epoch: 130, Loss: 1.0142, Train: 59.43%, Valid: 57.48% Test: 56.58%\n",
      "Run: 08, Epoch: 131, Loss: 1.0357, Train: 62.45%, Valid: 58.98% Test: 57.68%\n",
      "Run: 08, Epoch: 132, Loss: 1.0556, Train: 62.73%, Valid: 59.26% Test: 61.84%\n",
      "Run: 08, Epoch: 133, Loss: 1.0108, Train: 63.00%, Valid: 61.18% Test: 60.96%\n",
      "Run: 08, Epoch: 134, Loss: 1.0354, Train: 62.27%, Valid: 59.26% Test: 61.40%\n",
      "Run: 08, Epoch: 135, Loss: 1.0053, Train: 62.09%, Valid: 58.98% Test: 57.68%\n",
      "Run: 08, Epoch: 136, Loss: 1.0232, Train: 58.79%, Valid: 57.48% Test: 56.58%\n",
      "Run: 08, Epoch: 137, Loss: 1.0154, Train: 57.69%, Valid: 57.34% Test: 55.04%\n",
      "Run: 08, Epoch: 138, Loss: 1.0303, Train: 55.86%, Valid: 51.44% Test: 48.68%\n",
      "Run: 08, Epoch: 139, Loss: 1.0236, Train: 58.79%, Valid: 54.32% Test: 53.95%\n",
      "Run: 08, Epoch: 140, Loss: 0.9871, Train: 62.09%, Valid: 58.71% Test: 59.87%\n",
      "Run: 08, Epoch: 141, Loss: 1.0167, Train: 63.00%, Valid: 60.22% Test: 58.11%\n",
      "Run: 08, Epoch: 142, Loss: 1.0054, Train: 63.46%, Valid: 59.12% Test: 58.99%\n",
      "Run: 08, Epoch: 143, Loss: 0.9993, Train: 61.54%, Valid: 58.85% Test: 58.11%\n",
      "Run: 08, Epoch: 144, Loss: 1.0279, Train: 60.53%, Valid: 61.59% Test: 61.40%\n",
      "Run: 08, Epoch: 145, Loss: 1.0348, Train: 60.71%, Valid: 58.44% Test: 60.31%\n",
      "Run: 08, Epoch: 146, Loss: 1.0573, Train: 61.90%, Valid: 62.41% Test: 61.18%\n",
      "Run: 08, Epoch: 147, Loss: 1.0064, Train: 64.01%, Valid: 59.12% Test: 59.21%\n",
      "Run: 08, Epoch: 148, Loss: 1.0011, Train: 64.38%, Valid: 61.18% Test: 60.09%\n",
      "Run: 08, Epoch: 149, Loss: 0.9971, Train: 63.37%, Valid: 61.87% Test: 59.43%\n",
      "Run: 08, Epoch: 150, Loss: 1.0175, Train: 63.00%, Valid: 60.91% Test: 61.84%\n",
      "Run: 08, Epoch: 151, Loss: 0.9841, Train: 61.36%, Valid: 58.30% Test: 60.31%\n",
      "Run: 08, Epoch: 152, Loss: 1.0379, Train: 64.29%, Valid: 60.49% Test: 58.55%\n",
      "Run: 08, Epoch: 153, Loss: 1.0323, Train: 62.45%, Valid: 57.89% Test: 54.82%\n",
      "Run: 08, Epoch: 154, Loss: 1.0310, Train: 59.71%, Valid: 57.89% Test: 54.82%\n",
      "Run: 08, Epoch: 155, Loss: 1.0530, Train: 60.81%, Valid: 58.57% Test: 56.58%\n",
      "Run: 08, Epoch: 156, Loss: 1.0552, Train: 59.71%, Valid: 56.65% Test: 51.10%\n",
      "Run: 08, Epoch: 157, Loss: 1.0238, Train: 61.90%, Valid: 58.16% Test: 55.70%\n",
      "Run: 08, Epoch: 158, Loss: 1.0476, Train: 60.26%, Valid: 56.24% Test: 57.68%\n",
      "Run: 08, Epoch: 159, Loss: 1.0250, Train: 60.26%, Valid: 57.48% Test: 61.40%\n",
      "Run: 08, Epoch: 160, Loss: 1.0426, Train: 60.07%, Valid: 57.20% Test: 55.92%\n",
      "Run: 08, Epoch: 161, Loss: 1.0373, Train: 59.34%, Valid: 53.77% Test: 54.61%\n",
      "Run: 08, Epoch: 162, Loss: 1.0165, Train: 62.00%, Valid: 58.71% Test: 56.80%\n",
      "Run: 08, Epoch: 163, Loss: 1.0178, Train: 61.72%, Valid: 61.32% Test: 60.31%\n",
      "Run: 08, Epoch: 164, Loss: 1.0263, Train: 61.54%, Valid: 60.08% Test: 58.99%\n",
      "Run: 08, Epoch: 165, Loss: 1.0127, Train: 59.98%, Valid: 56.38% Test: 57.24%\n",
      "Run: 08, Epoch: 166, Loss: 1.0480, Train: 53.21%, Valid: 49.79% Test: 44.52%\n",
      "Run: 08, Epoch: 167, Loss: 1.0649, Train: 58.79%, Valid: 57.06% Test: 53.51%\n",
      "Run: 08, Epoch: 168, Loss: 1.0074, Train: 51.47%, Valid: 51.44% Test: 51.75%\n",
      "Run: 08, Epoch: 169, Loss: 1.1493, Train: 50.46%, Valid: 47.46% Test: 47.15%\n",
      "Run: 08, Epoch: 170, Loss: 1.0739, Train: 55.13%, Valid: 52.40% Test: 56.14%\n",
      "Run: 08, Epoch: 171, Loss: 1.0927, Train: 58.70%, Valid: 56.38% Test: 57.24%\n",
      "Run: 08, Epoch: 172, Loss: 1.0538, Train: 56.78%, Valid: 56.10% Test: 54.17%\n",
      "Run: 08, Epoch: 173, Loss: 1.0726, Train: 56.50%, Valid: 56.52% Test: 55.92%\n",
      "Run: 08, Epoch: 174, Loss: 1.0354, Train: 60.44%, Valid: 59.81% Test: 60.09%\n",
      "Run: 08, Epoch: 175, Loss: 1.0509, Train: 61.36%, Valid: 60.22% Test: 57.89%\n",
      "Run: 08, Epoch: 176, Loss: 1.0742, Train: 60.90%, Valid: 58.98% Test: 59.21%\n",
      "Run: 08, Epoch: 177, Loss: 1.0694, Train: 58.33%, Valid: 58.57% Test: 59.21%\n",
      "Run: 08, Epoch: 178, Loss: 1.0435, Train: 59.62%, Valid: 58.57% Test: 59.65%\n",
      "Run: 08, Epoch: 179, Loss: 1.0380, Train: 55.22%, Valid: 54.87% Test: 53.73%\n",
      "Run: 08, Epoch: 180, Loss: 1.0153, Train: 54.12%, Valid: 51.30% Test: 50.22%\n",
      "Run: 08, Epoch: 181, Loss: 1.0303, Train: 56.14%, Valid: 55.42% Test: 55.04%\n",
      "Run: 08, Epoch: 182, Loss: 1.0294, Train: 58.33%, Valid: 56.38% Test: 60.09%\n",
      "Run: 08, Epoch: 183, Loss: 1.0569, Train: 60.90%, Valid: 58.44% Test: 60.09%\n",
      "Run: 08, Epoch: 184, Loss: 1.0259, Train: 57.69%, Valid: 52.67% Test: 53.51%\n",
      "Run: 08, Epoch: 185, Loss: 1.0096, Train: 61.54%, Valid: 56.93% Test: 57.24%\n",
      "Run: 08, Epoch: 186, Loss: 1.0437, Train: 60.53%, Valid: 57.89% Test: 59.21%\n",
      "Run: 08, Epoch: 187, Loss: 1.0618, Train: 58.70%, Valid: 53.09% Test: 51.97%\n",
      "Run: 08, Epoch: 188, Loss: 1.0459, Train: 62.27%, Valid: 58.16% Test: 56.14%\n",
      "Run: 08, Epoch: 189, Loss: 1.0466, Train: 60.99%, Valid: 57.75% Test: 61.18%\n",
      "Run: 08, Epoch: 190, Loss: 1.0175, Train: 59.43%, Valid: 55.56% Test: 58.33%\n",
      "Run: 08, Epoch: 191, Loss: 0.9884, Train: 58.33%, Valid: 56.93% Test: 60.09%\n",
      "Run: 08, Epoch: 192, Loss: 1.0394, Train: 62.27%, Valid: 57.20% Test: 60.31%\n",
      "Run: 08, Epoch: 193, Loss: 1.0013, Train: 63.46%, Valid: 58.16% Test: 60.31%\n",
      "Run: 08, Epoch: 194, Loss: 1.0054, Train: 62.18%, Valid: 57.48% Test: 58.55%\n",
      "Run: 08, Epoch: 195, Loss: 1.0044, Train: 62.82%, Valid: 58.57% Test: 57.46%\n",
      "Run: 08, Epoch: 196, Loss: 1.0189, Train: 60.90%, Valid: 57.61% Test: 57.89%\n",
      "Run: 08, Epoch: 197, Loss: 1.0047, Train: 60.44%, Valid: 57.61% Test: 58.99%\n",
      "Run: 08, Epoch: 198, Loss: 0.9935, Train: 61.63%, Valid: 58.98% Test: 62.72%\n",
      "Run: 08, Epoch: 199, Loss: 0.9879, Train: 64.29%, Valid: 58.85% Test: 61.62%\n",
      "Run: 08, Epoch: 200, Loss: 0.9850, Train: 61.54%, Valid: 58.71% Test: 59.21%\n",
      "Run 08:\n",
      "Highest Train: 64.38\n",
      "Highest Valid: 62.41\n",
      "  Final Train: 61.90\n",
      "   Final Test: 61.18\n",
      "Run: 09, Epoch: 01, Loss: 2.1743, Train: 16.94%, Valid: 18.38% Test: 15.13%\n",
      "Run: 09, Epoch: 02, Loss: 1.5480, Train: 20.97%, Valid: 23.32% Test: 18.86%\n",
      "Run: 09, Epoch: 03, Loss: 1.4793, Train: 26.37%, Valid: 26.34% Test: 26.10%\n",
      "Run: 09, Epoch: 04, Loss: 1.4878, Train: 26.19%, Valid: 27.57% Test: 23.03%\n",
      "Run: 09, Epoch: 05, Loss: 1.4153, Train: 27.56%, Valid: 30.18% Test: 25.88%\n",
      "Run: 09, Epoch: 06, Loss: 1.4055, Train: 29.76%, Valid: 30.59% Test: 26.10%\n",
      "Run: 09, Epoch: 07, Loss: 1.3685, Train: 36.81%, Valid: 38.41% Test: 35.96%\n",
      "Run: 09, Epoch: 08, Loss: 1.3120, Train: 34.52%, Valid: 34.43% Test: 32.68%\n",
      "Run: 09, Epoch: 09, Loss: 1.3327, Train: 34.16%, Valid: 36.08% Test: 34.21%\n",
      "Run: 09, Epoch: 10, Loss: 1.3033, Train: 37.64%, Valid: 38.13% Test: 38.82%\n",
      "Run: 09, Epoch: 11, Loss: 1.2812, Train: 38.46%, Valid: 40.05% Test: 41.01%\n",
      "Run: 09, Epoch: 12, Loss: 1.2923, Train: 40.20%, Valid: 41.02% Test: 43.64%\n",
      "Run: 09, Epoch: 13, Loss: 1.2736, Train: 37.00%, Valid: 40.19% Test: 38.60%\n",
      "Run: 09, Epoch: 14, Loss: 1.2641, Train: 42.03%, Valid: 44.99% Test: 45.39%\n",
      "Run: 09, Epoch: 15, Loss: 1.2523, Train: 44.96%, Valid: 46.50% Test: 44.08%\n",
      "Run: 09, Epoch: 16, Loss: 1.2240, Train: 42.95%, Valid: 43.62% Test: 44.08%\n",
      "Run: 09, Epoch: 17, Loss: 1.2545, Train: 45.79%, Valid: 44.86% Test: 45.18%\n",
      "Run: 09, Epoch: 18, Loss: 1.2520, Train: 48.90%, Valid: 47.33% Test: 49.56%\n",
      "Run: 09, Epoch: 19, Loss: 1.2369, Train: 50.00%, Valid: 50.62% Test: 50.22%\n",
      "Run: 09, Epoch: 20, Loss: 1.2348, Train: 46.15%, Valid: 46.23% Test: 45.83%\n",
      "Run: 09, Epoch: 21, Loss: 1.2205, Train: 40.48%, Valid: 41.43% Test: 41.23%\n",
      "Run: 09, Epoch: 22, Loss: 1.2177, Train: 44.69%, Valid: 45.27% Test: 44.08%\n",
      "Run: 09, Epoch: 23, Loss: 1.1897, Train: 45.70%, Valid: 46.36% Test: 47.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 24, Loss: 1.2066, Train: 45.70%, Valid: 46.50% Test: 48.25%\n",
      "Run: 09, Epoch: 25, Loss: 1.1966, Train: 42.95%, Valid: 42.25% Test: 43.42%\n",
      "Run: 09, Epoch: 26, Loss: 1.2083, Train: 38.83%, Valid: 38.68% Test: 38.38%\n",
      "Run: 09, Epoch: 27, Loss: 1.1858, Train: 43.96%, Valid: 43.21% Test: 44.96%\n",
      "Run: 09, Epoch: 28, Loss: 1.1776, Train: 45.33%, Valid: 45.40% Test: 47.15%\n",
      "Run: 09, Epoch: 29, Loss: 1.1997, Train: 49.18%, Valid: 50.34% Test: 50.22%\n",
      "Run: 09, Epoch: 30, Loss: 1.1648, Train: 46.52%, Valid: 46.23% Test: 47.15%\n",
      "Run: 09, Epoch: 31, Loss: 1.1775, Train: 47.99%, Valid: 49.66% Test: 49.56%\n",
      "Run: 09, Epoch: 32, Loss: 1.1592, Train: 49.91%, Valid: 49.11% Test: 51.10%\n",
      "Run: 09, Epoch: 33, Loss: 1.1562, Train: 49.18%, Valid: 47.74% Test: 51.10%\n",
      "Run: 09, Epoch: 34, Loss: 1.1646, Train: 49.73%, Valid: 48.42% Test: 50.22%\n",
      "Run: 09, Epoch: 35, Loss: 1.1659, Train: 49.08%, Valid: 51.44% Test: 50.66%\n",
      "Run: 09, Epoch: 36, Loss: 1.1278, Train: 49.63%, Valid: 51.30% Test: 50.22%\n",
      "Run: 09, Epoch: 37, Loss: 1.1417, Train: 47.62%, Valid: 44.99% Test: 47.37%\n",
      "Run: 09, Epoch: 38, Loss: 1.1463, Train: 51.01%, Valid: 52.67% Test: 52.63%\n",
      "Run: 09, Epoch: 39, Loss: 1.1364, Train: 51.19%, Valid: 51.17% Test: 52.63%\n",
      "Run: 09, Epoch: 40, Loss: 1.1173, Train: 49.54%, Valid: 48.29% Test: 50.44%\n",
      "Run: 09, Epoch: 41, Loss: 1.1076, Train: 49.91%, Valid: 50.07% Test: 50.00%\n",
      "Run: 09, Epoch: 42, Loss: 1.1184, Train: 53.02%, Valid: 53.50% Test: 54.61%\n",
      "Run: 09, Epoch: 43, Loss: 1.1292, Train: 47.99%, Valid: 47.60% Test: 47.59%\n",
      "Run: 09, Epoch: 44, Loss: 1.1504, Train: 48.26%, Valid: 45.40% Test: 48.46%\n",
      "Run: 09, Epoch: 45, Loss: 1.1303, Train: 48.99%, Valid: 48.97% Test: 50.66%\n",
      "Run: 09, Epoch: 46, Loss: 1.1383, Train: 52.84%, Valid: 54.46% Test: 55.92%\n",
      "Run: 09, Epoch: 47, Loss: 1.1105, Train: 50.82%, Valid: 48.97% Test: 51.10%\n",
      "Run: 09, Epoch: 48, Loss: 1.1158, Train: 47.07%, Valid: 45.54% Test: 49.12%\n",
      "Run: 09, Epoch: 49, Loss: 1.1130, Train: 53.85%, Valid: 55.01% Test: 55.70%\n",
      "Run: 09, Epoch: 50, Loss: 1.1374, Train: 56.14%, Valid: 55.83% Test: 56.14%\n",
      "Run: 09, Epoch: 51, Loss: 1.1101, Train: 53.75%, Valid: 52.26% Test: 53.95%\n",
      "Run: 09, Epoch: 52, Loss: 1.1201, Train: 50.27%, Valid: 47.46% Test: 50.66%\n",
      "Run: 09, Epoch: 53, Loss: 1.1099, Train: 56.78%, Valid: 53.91% Test: 54.82%\n",
      "Run: 09, Epoch: 54, Loss: 1.1127, Train: 58.06%, Valid: 57.06% Test: 57.02%\n",
      "Run: 09, Epoch: 55, Loss: 1.0976, Train: 54.85%, Valid: 53.77% Test: 55.26%\n",
      "Run: 09, Epoch: 56, Loss: 1.1136, Train: 54.30%, Valid: 53.50% Test: 53.95%\n",
      "Run: 09, Epoch: 57, Loss: 1.1061, Train: 53.21%, Valid: 51.58% Test: 52.63%\n",
      "Run: 09, Epoch: 58, Loss: 1.1121, Train: 48.44%, Valid: 49.66% Test: 48.25%\n",
      "Run: 09, Epoch: 59, Loss: 1.1161, Train: 53.75%, Valid: 53.64% Test: 55.26%\n",
      "Run: 09, Epoch: 60, Loss: 1.1197, Train: 56.32%, Valid: 56.93% Test: 58.77%\n",
      "Run: 09, Epoch: 61, Loss: 1.1028, Train: 56.32%, Valid: 55.28% Test: 54.82%\n",
      "Run: 09, Epoch: 62, Loss: 1.1077, Train: 52.66%, Valid: 51.85% Test: 51.10%\n",
      "Run: 09, Epoch: 63, Loss: 1.1055, Train: 57.60%, Valid: 58.30% Test: 57.46%\n",
      "Run: 09, Epoch: 64, Loss: 1.0901, Train: 51.74%, Valid: 55.42% Test: 51.75%\n",
      "Run: 09, Epoch: 65, Loss: 1.1009, Train: 53.39%, Valid: 55.42% Test: 53.51%\n",
      "Run: 09, Epoch: 66, Loss: 1.0986, Train: 51.83%, Valid: 51.58% Test: 50.66%\n",
      "Run: 09, Epoch: 67, Loss: 1.1112, Train: 52.93%, Valid: 52.81% Test: 52.63%\n",
      "Run: 09, Epoch: 68, Loss: 1.0983, Train: 52.29%, Valid: 52.40% Test: 51.32%\n",
      "Run: 09, Epoch: 69, Loss: 1.1133, Train: 53.21%, Valid: 54.32% Test: 52.85%\n",
      "Run: 09, Epoch: 70, Loss: 1.1129, Train: 53.94%, Valid: 52.40% Test: 52.85%\n",
      "Run: 09, Epoch: 71, Loss: 1.1091, Train: 53.39%, Valid: 51.58% Test: 54.39%\n",
      "Run: 09, Epoch: 72, Loss: 1.1070, Train: 58.52%, Valid: 58.85% Test: 57.02%\n",
      "Run: 09, Epoch: 73, Loss: 1.0861, Train: 58.42%, Valid: 58.85% Test: 57.02%\n",
      "Run: 09, Epoch: 74, Loss: 1.1125, Train: 58.52%, Valid: 59.40% Test: 57.89%\n",
      "Run: 09, Epoch: 75, Loss: 1.0711, Train: 55.13%, Valid: 57.20% Test: 55.92%\n",
      "Run: 09, Epoch: 76, Loss: 1.1053, Train: 57.51%, Valid: 58.30% Test: 57.24%\n",
      "Run: 09, Epoch: 77, Loss: 1.0933, Train: 59.07%, Valid: 61.18% Test: 58.55%\n",
      "Run: 09, Epoch: 78, Loss: 1.0959, Train: 59.62%, Valid: 58.02% Test: 58.55%\n",
      "Run: 09, Epoch: 79, Loss: 1.0915, Train: 55.95%, Valid: 54.05% Test: 55.26%\n",
      "Run: 09, Epoch: 80, Loss: 1.1031, Train: 51.47%, Valid: 50.75% Test: 50.00%\n",
      "Run: 09, Epoch: 81, Loss: 1.0914, Train: 51.83%, Valid: 51.71% Test: 51.54%\n",
      "Run: 09, Epoch: 82, Loss: 1.0714, Train: 53.21%, Valid: 53.77% Test: 52.85%\n",
      "Run: 09, Epoch: 83, Loss: 1.0782, Train: 56.32%, Valid: 55.28% Test: 56.14%\n",
      "Run: 09, Epoch: 84, Loss: 1.0883, Train: 58.79%, Valid: 58.16% Test: 57.68%\n",
      "Run: 09, Epoch: 85, Loss: 1.0820, Train: 60.16%, Valid: 60.22% Test: 59.21%\n",
      "Run: 09, Epoch: 86, Loss: 1.0743, Train: 59.25%, Valid: 60.77% Test: 59.21%\n",
      "Run: 09, Epoch: 87, Loss: 1.0695, Train: 57.51%, Valid: 58.02% Test: 56.14%\n",
      "Run: 09, Epoch: 88, Loss: 1.0740, Train: 59.34%, Valid: 58.85% Test: 57.46%\n",
      "Run: 09, Epoch: 89, Loss: 1.0759, Train: 58.24%, Valid: 56.24% Test: 55.92%\n",
      "Run: 09, Epoch: 90, Loss: 1.0712, Train: 55.49%, Valid: 53.22% Test: 52.85%\n",
      "Run: 09, Epoch: 91, Loss: 1.0774, Train: 52.29%, Valid: 50.89% Test: 51.32%\n",
      "Run: 09, Epoch: 92, Loss: 1.0897, Train: 58.61%, Valid: 56.79% Test: 58.33%\n",
      "Run: 09, Epoch: 93, Loss: 1.0530, Train: 56.14%, Valid: 54.32% Test: 53.95%\n",
      "Run: 09, Epoch: 94, Loss: 1.0842, Train: 59.80%, Valid: 60.91% Test: 59.65%\n",
      "Run: 09, Epoch: 95, Loss: 1.0560, Train: 59.34%, Valid: 62.28% Test: 60.75%\n",
      "Run: 09, Epoch: 96, Loss: 1.0920, Train: 58.42%, Valid: 59.40% Test: 57.02%\n",
      "Run: 09, Epoch: 97, Loss: 1.0603, Train: 59.07%, Valid: 58.98% Test: 56.14%\n",
      "Run: 09, Epoch: 98, Loss: 1.0472, Train: 57.78%, Valid: 60.63% Test: 58.77%\n",
      "Run: 09, Epoch: 99, Loss: 1.0886, Train: 55.22%, Valid: 55.28% Test: 57.02%\n",
      "Run: 09, Epoch: 100, Loss: 1.1249, Train: 56.96%, Valid: 56.52% Test: 54.39%\n",
      "Run: 09, Epoch: 101, Loss: 1.0752, Train: 53.85%, Valid: 52.95% Test: 53.07%\n",
      "Run: 09, Epoch: 102, Loss: 1.0840, Train: 57.23%, Valid: 54.32% Test: 56.14%\n",
      "Run: 09, Epoch: 103, Loss: 1.0754, Train: 56.04%, Valid: 52.95% Test: 54.61%\n",
      "Run: 09, Epoch: 104, Loss: 1.0742, Train: 55.68%, Valid: 57.06% Test: 57.46%\n",
      "Run: 09, Epoch: 105, Loss: 1.0657, Train: 54.12%, Valid: 56.93% Test: 56.36%\n",
      "Run: 09, Epoch: 106, Loss: 1.0818, Train: 52.75%, Valid: 52.95% Test: 52.41%\n",
      "Run: 09, Epoch: 107, Loss: 1.0835, Train: 57.51%, Valid: 57.34% Test: 54.39%\n",
      "Run: 09, Epoch: 108, Loss: 1.0579, Train: 59.52%, Valid: 60.08% Test: 60.09%\n",
      "Run: 09, Epoch: 109, Loss: 1.0799, Train: 58.15%, Valid: 58.57% Test: 58.55%\n",
      "Run: 09, Epoch: 110, Loss: 1.0408, Train: 56.50%, Valid: 55.56% Test: 54.82%\n",
      "Run: 09, Epoch: 111, Loss: 1.0530, Train: 56.50%, Valid: 55.14% Test: 55.26%\n",
      "Run: 09, Epoch: 112, Loss: 1.0658, Train: 57.05%, Valid: 55.69% Test: 54.61%\n",
      "Run: 09, Epoch: 113, Loss: 1.0596, Train: 57.33%, Valid: 55.01% Test: 56.58%\n",
      "Run: 09, Epoch: 114, Loss: 1.0621, Train: 60.53%, Valid: 61.18% Test: 60.31%\n",
      "Run: 09, Epoch: 115, Loss: 1.0719, Train: 59.98%, Valid: 59.12% Test: 59.87%\n",
      "Run: 09, Epoch: 116, Loss: 1.0661, Train: 60.99%, Valid: 59.53% Test: 60.53%\n",
      "Run: 09, Epoch: 117, Loss: 1.0511, Train: 61.36%, Valid: 61.59% Test: 62.72%\n",
      "Run: 09, Epoch: 118, Loss: 1.0471, Train: 60.81%, Valid: 62.00% Test: 62.28%\n",
      "Run: 09, Epoch: 119, Loss: 1.0393, Train: 59.34%, Valid: 57.48% Test: 58.11%\n",
      "Run: 09, Epoch: 120, Loss: 1.0388, Train: 59.71%, Valid: 59.40% Test: 61.18%\n",
      "Run: 09, Epoch: 121, Loss: 1.0318, Train: 58.06%, Valid: 56.79% Test: 57.68%\n",
      "Run: 09, Epoch: 122, Loss: 1.0298, Train: 56.78%, Valid: 55.69% Test: 55.92%\n",
      "Run: 09, Epoch: 123, Loss: 1.0232, Train: 56.41%, Valid: 56.38% Test: 55.70%\n",
      "Run: 09, Epoch: 124, Loss: 1.0282, Train: 58.52%, Valid: 57.20% Test: 59.65%\n",
      "Run: 09, Epoch: 125, Loss: 1.0359, Train: 62.64%, Valid: 62.55% Test: 64.69%\n",
      "Run: 09, Epoch: 126, Loss: 1.0388, Train: 61.90%, Valid: 60.63% Test: 62.06%\n",
      "Run: 09, Epoch: 127, Loss: 1.0277, Train: 60.26%, Valid: 61.18% Test: 61.18%\n",
      "Run: 09, Epoch: 128, Loss: 1.0528, Train: 62.00%, Valid: 60.77% Test: 62.72%\n",
      "Run: 09, Epoch: 129, Loss: 1.0200, Train: 62.82%, Valid: 62.41% Test: 61.18%\n",
      "Run: 09, Epoch: 130, Loss: 1.0546, Train: 62.36%, Valid: 61.18% Test: 62.50%\n",
      "Run: 09, Epoch: 131, Loss: 1.0389, Train: 58.52%, Valid: 56.79% Test: 57.46%\n",
      "Run: 09, Epoch: 132, Loss: 1.0695, Train: 60.99%, Valid: 60.22% Test: 60.09%\n",
      "Run: 09, Epoch: 133, Loss: 1.0275, Train: 56.59%, Valid: 55.83% Test: 56.58%\n",
      "Run: 09, Epoch: 134, Loss: 1.0552, Train: 59.34%, Valid: 58.98% Test: 59.21%\n",
      "Run: 09, Epoch: 135, Loss: 1.0408, Train: 59.43%, Valid: 58.16% Test: 59.65%\n",
      "Run: 09, Epoch: 136, Loss: 1.0549, Train: 61.08%, Valid: 62.00% Test: 61.40%\n",
      "Run: 09, Epoch: 137, Loss: 1.0367, Train: 55.31%, Valid: 55.42% Test: 56.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 138, Loss: 1.0718, Train: 57.69%, Valid: 58.16% Test: 59.43%\n",
      "Run: 09, Epoch: 139, Loss: 1.0385, Train: 55.95%, Valid: 55.01% Test: 56.36%\n",
      "Run: 09, Epoch: 140, Loss: 1.0652, Train: 57.33%, Valid: 59.26% Test: 57.46%\n",
      "Run: 09, Epoch: 141, Loss: 1.0460, Train: 55.59%, Valid: 55.83% Test: 57.68%\n",
      "Run: 09, Epoch: 142, Loss: 1.0686, Train: 59.89%, Valid: 59.12% Test: 60.09%\n",
      "Run: 09, Epoch: 143, Loss: 1.0470, Train: 58.70%, Valid: 58.44% Test: 59.65%\n",
      "Run: 09, Epoch: 144, Loss: 1.0247, Train: 59.62%, Valid: 59.81% Test: 60.53%\n",
      "Run: 09, Epoch: 145, Loss: 1.0452, Train: 60.07%, Valid: 58.30% Test: 58.55%\n",
      "Run: 09, Epoch: 146, Loss: 1.0555, Train: 61.26%, Valid: 61.73% Test: 60.75%\n",
      "Run: 09, Epoch: 147, Loss: 1.0421, Train: 61.08%, Valid: 60.36% Test: 60.75%\n",
      "Run: 09, Epoch: 148, Loss: 1.0323, Train: 58.06%, Valid: 57.34% Test: 60.31%\n",
      "Run: 09, Epoch: 149, Loss: 1.0480, Train: 61.08%, Valid: 62.00% Test: 65.13%\n",
      "Run: 09, Epoch: 150, Loss: 1.0272, Train: 59.89%, Valid: 60.08% Test: 64.04%\n",
      "Run: 09, Epoch: 151, Loss: 1.0271, Train: 60.53%, Valid: 60.91% Test: 62.28%\n",
      "Run: 09, Epoch: 152, Loss: 1.0234, Train: 61.26%, Valid: 62.14% Test: 63.82%\n",
      "Run: 09, Epoch: 153, Loss: 1.0467, Train: 59.98%, Valid: 59.40% Test: 60.31%\n",
      "Run: 09, Epoch: 154, Loss: 1.0132, Train: 59.80%, Valid: 60.36% Test: 61.62%\n",
      "Run: 09, Epoch: 155, Loss: 1.0215, Train: 61.90%, Valid: 61.32% Test: 65.57%\n",
      "Run: 09, Epoch: 156, Loss: 1.0245, Train: 59.71%, Valid: 57.06% Test: 60.53%\n",
      "Run: 09, Epoch: 157, Loss: 1.0195, Train: 60.16%, Valid: 60.49% Test: 60.09%\n",
      "Run: 09, Epoch: 158, Loss: 1.0144, Train: 61.17%, Valid: 61.04% Test: 61.84%\n",
      "Run: 09, Epoch: 159, Loss: 1.0281, Train: 59.80%, Valid: 60.22% Test: 60.96%\n",
      "Run: 09, Epoch: 160, Loss: 1.0371, Train: 57.97%, Valid: 56.93% Test: 58.33%\n",
      "Run: 09, Epoch: 161, Loss: 1.0268, Train: 62.64%, Valid: 62.00% Test: 60.96%\n",
      "Run: 09, Epoch: 162, Loss: 1.0541, Train: 62.36%, Valid: 62.00% Test: 62.06%\n",
      "Run: 09, Epoch: 163, Loss: 1.0349, Train: 60.16%, Valid: 59.53% Test: 61.18%\n",
      "Run: 09, Epoch: 164, Loss: 1.0157, Train: 61.17%, Valid: 61.45% Test: 61.84%\n",
      "Run: 09, Epoch: 165, Loss: 1.0138, Train: 59.62%, Valid: 60.91% Test: 60.53%\n",
      "Run: 09, Epoch: 166, Loss: 1.0110, Train: 61.90%, Valid: 61.87% Test: 60.09%\n",
      "Run: 09, Epoch: 167, Loss: 1.0081, Train: 61.17%, Valid: 62.69% Test: 62.72%\n",
      "Run: 09, Epoch: 168, Loss: 1.0110, Train: 60.62%, Valid: 61.04% Test: 61.18%\n",
      "Run: 09, Epoch: 169, Loss: 1.0177, Train: 61.72%, Valid: 62.55% Test: 63.60%\n",
      "Run: 09, Epoch: 170, Loss: 1.0160, Train: 60.44%, Valid: 61.18% Test: 62.28%\n",
      "Run: 09, Epoch: 171, Loss: 1.0104, Train: 61.54%, Valid: 63.10% Test: 63.38%\n",
      "Run: 09, Epoch: 172, Loss: 1.0134, Train: 60.81%, Valid: 58.30% Test: 59.21%\n",
      "Run: 09, Epoch: 173, Loss: 1.0115, Train: 61.45%, Valid: 61.73% Test: 62.06%\n",
      "Run: 09, Epoch: 174, Loss: 1.0059, Train: 59.98%, Valid: 60.77% Test: 59.87%\n",
      "Run: 09, Epoch: 175, Loss: 1.0252, Train: 60.53%, Valid: 61.18% Test: 59.21%\n",
      "Run: 09, Epoch: 176, Loss: 1.0212, Train: 60.26%, Valid: 59.95% Test: 58.11%\n",
      "Run: 09, Epoch: 177, Loss: 1.0064, Train: 62.09%, Valid: 62.83% Test: 63.82%\n",
      "Run: 09, Epoch: 178, Loss: 1.0181, Train: 58.61%, Valid: 58.98% Test: 58.99%\n",
      "Run: 09, Epoch: 179, Loss: 1.0502, Train: 54.03%, Valid: 53.22% Test: 53.95%\n",
      "Run: 09, Epoch: 180, Loss: 1.0695, Train: 55.04%, Valid: 52.40% Test: 54.61%\n",
      "Run: 09, Epoch: 181, Loss: 1.0188, Train: 52.47%, Valid: 52.67% Test: 53.95%\n",
      "Run: 09, Epoch: 182, Loss: 1.0518, Train: 57.97%, Valid: 59.95% Test: 59.65%\n",
      "Run: 09, Epoch: 183, Loss: 1.0406, Train: 56.32%, Valid: 55.28% Test: 55.04%\n",
      "Run: 09, Epoch: 184, Loss: 1.0400, Train: 57.14%, Valid: 53.36% Test: 56.58%\n",
      "Run: 09, Epoch: 185, Loss: 1.0567, Train: 58.33%, Valid: 58.57% Test: 59.21%\n",
      "Run: 09, Epoch: 186, Loss: 1.0515, Train: 58.24%, Valid: 59.40% Test: 60.09%\n",
      "Run: 09, Epoch: 187, Loss: 1.0433, Train: 53.30%, Valid: 50.62% Test: 53.95%\n",
      "Run: 09, Epoch: 188, Loss: 1.0382, Train: 59.62%, Valid: 56.10% Test: 57.02%\n",
      "Run: 09, Epoch: 189, Loss: 1.0290, Train: 58.70%, Valid: 57.34% Test: 56.14%\n",
      "Run: 09, Epoch: 190, Loss: 1.0434, Train: 60.16%, Valid: 58.44% Test: 58.55%\n",
      "Run: 09, Epoch: 191, Loss: 1.0585, Train: 54.12%, Valid: 55.01% Test: 55.04%\n",
      "Run: 09, Epoch: 192, Loss: 1.0406, Train: 58.52%, Valid: 58.02% Test: 59.43%\n",
      "Run: 09, Epoch: 193, Loss: 1.0264, Train: 55.59%, Valid: 54.73% Test: 56.36%\n",
      "Run: 09, Epoch: 194, Loss: 1.0184, Train: 59.62%, Valid: 56.65% Test: 59.43%\n",
      "Run: 09, Epoch: 195, Loss: 1.0406, Train: 57.14%, Valid: 55.83% Test: 55.70%\n",
      "Run: 09, Epoch: 196, Loss: 1.0245, Train: 52.84%, Valid: 49.66% Test: 52.85%\n",
      "Run: 09, Epoch: 197, Loss: 1.0534, Train: 55.49%, Valid: 55.01% Test: 54.82%\n",
      "Run: 09, Epoch: 198, Loss: 1.0560, Train: 59.07%, Valid: 58.30% Test: 57.89%\n",
      "Run: 09, Epoch: 199, Loss: 1.0544, Train: 55.40%, Valid: 55.14% Test: 54.82%\n",
      "Run: 09, Epoch: 200, Loss: 1.0318, Train: 54.58%, Valid: 51.17% Test: 55.48%\n",
      "Run 09:\n",
      "Highest Train: 62.82\n",
      "Highest Valid: 63.10\n",
      "  Final Train: 61.54\n",
      "   Final Test: 63.38\n",
      "Run: 10, Epoch: 01, Loss: 1.7730, Train: 19.87%, Valid: 20.03% Test: 19.74%\n",
      "Run: 10, Epoch: 02, Loss: 1.4650, Train: 26.01%, Valid: 28.12% Test: 29.39%\n",
      "Run: 10, Epoch: 03, Loss: 1.4215, Train: 26.56%, Valid: 27.02% Test: 28.07%\n",
      "Run: 10, Epoch: 04, Loss: 1.3700, Train: 32.60%, Valid: 32.51% Test: 34.87%\n",
      "Run: 10, Epoch: 05, Loss: 1.3332, Train: 29.85%, Valid: 29.49% Test: 32.68%\n",
      "Run: 10, Epoch: 06, Loss: 1.3475, Train: 38.37%, Valid: 34.84% Test: 37.06%\n",
      "Run: 10, Epoch: 07, Loss: 1.3426, Train: 38.46%, Valid: 37.45% Test: 38.38%\n",
      "Run: 10, Epoch: 08, Loss: 1.3197, Train: 44.87%, Valid: 44.72% Test: 46.93%\n",
      "Run: 10, Epoch: 09, Loss: 1.3144, Train: 47.62%, Valid: 44.86% Test: 49.12%\n",
      "Run: 10, Epoch: 10, Loss: 1.2764, Train: 38.37%, Valid: 38.00% Test: 40.13%\n",
      "Run: 10, Epoch: 11, Loss: 1.2755, Train: 37.27%, Valid: 35.94% Test: 38.82%\n",
      "Run: 10, Epoch: 12, Loss: 1.2696, Train: 41.48%, Valid: 39.78% Test: 42.32%\n",
      "Run: 10, Epoch: 13, Loss: 1.2692, Train: 42.31%, Valid: 41.15% Test: 42.11%\n",
      "Run: 10, Epoch: 14, Loss: 1.2616, Train: 42.95%, Valid: 42.80% Test: 44.74%\n",
      "Run: 10, Epoch: 15, Loss: 1.2462, Train: 50.64%, Valid: 49.52% Test: 50.66%\n",
      "Run: 10, Epoch: 16, Loss: 1.2332, Train: 47.34%, Valid: 46.09% Test: 46.05%\n",
      "Run: 10, Epoch: 17, Loss: 1.2260, Train: 45.24%, Valid: 48.29% Test: 47.15%\n",
      "Run: 10, Epoch: 18, Loss: 1.2405, Train: 45.05%, Valid: 47.33% Test: 47.81%\n",
      "Run: 10, Epoch: 19, Loss: 1.2359, Train: 46.52%, Valid: 46.23% Test: 46.27%\n",
      "Run: 10, Epoch: 20, Loss: 1.2064, Train: 46.52%, Valid: 46.64% Test: 45.18%\n",
      "Run: 10, Epoch: 21, Loss: 1.1946, Train: 44.32%, Valid: 44.99% Test: 44.74%\n",
      "Run: 10, Epoch: 22, Loss: 1.2177, Train: 45.88%, Valid: 48.29% Test: 47.37%\n",
      "Run: 10, Epoch: 23, Loss: 1.2039, Train: 48.44%, Valid: 48.56% Test: 49.56%\n",
      "Run: 10, Epoch: 24, Loss: 1.2008, Train: 50.73%, Valid: 48.56% Test: 50.66%\n",
      "Run: 10, Epoch: 25, Loss: 1.1791, Train: 45.24%, Valid: 43.76% Test: 43.64%\n",
      "Run: 10, Epoch: 26, Loss: 1.1915, Train: 44.60%, Valid: 43.35% Test: 43.64%\n",
      "Run: 10, Epoch: 27, Loss: 1.1754, Train: 45.42%, Valid: 45.95% Test: 47.37%\n",
      "Run: 10, Epoch: 28, Loss: 1.1737, Train: 47.16%, Valid: 46.23% Test: 48.90%\n",
      "Run: 10, Epoch: 29, Loss: 1.1674, Train: 50.55%, Valid: 47.19% Test: 48.68%\n",
      "Run: 10, Epoch: 30, Loss: 1.1458, Train: 51.01%, Valid: 46.78% Test: 48.90%\n",
      "Run: 10, Epoch: 31, Loss: 1.1891, Train: 48.63%, Valid: 46.23% Test: 50.00%\n",
      "Run: 10, Epoch: 32, Loss: 1.1627, Train: 44.32%, Valid: 43.35% Test: 43.86%\n",
      "Run: 10, Epoch: 33, Loss: 1.1604, Train: 48.35%, Valid: 48.15% Test: 50.00%\n",
      "Run: 10, Epoch: 34, Loss: 1.1589, Train: 45.97%, Valid: 44.72% Test: 46.71%\n",
      "Run: 10, Epoch: 35, Loss: 1.1591, Train: 46.79%, Valid: 45.13% Test: 47.81%\n",
      "Run: 10, Epoch: 36, Loss: 1.1588, Train: 47.89%, Valid: 45.27% Test: 48.46%\n",
      "Run: 10, Epoch: 37, Loss: 1.1473, Train: 50.27%, Valid: 50.34% Test: 52.19%\n",
      "Run: 10, Epoch: 38, Loss: 1.1461, Train: 51.56%, Valid: 50.48% Test: 52.63%\n",
      "Run: 10, Epoch: 39, Loss: 1.1212, Train: 53.30%, Valid: 52.26% Test: 53.51%\n",
      "Run: 10, Epoch: 40, Loss: 1.1214, Train: 45.33%, Valid: 45.95% Test: 46.71%\n",
      "Run: 10, Epoch: 41, Loss: 1.1979, Train: 49.45%, Valid: 47.60% Test: 47.59%\n",
      "Run: 10, Epoch: 42, Loss: 1.1807, Train: 44.41%, Valid: 43.76% Test: 43.20%\n",
      "Run: 10, Epoch: 43, Loss: 1.1944, Train: 41.48%, Valid: 41.02% Test: 40.35%\n",
      "Run: 10, Epoch: 44, Loss: 1.1733, Train: 46.98%, Valid: 48.70% Test: 48.25%\n",
      "Run: 10, Epoch: 45, Loss: 1.1581, Train: 45.15%, Valid: 46.50% Test: 47.15%\n",
      "Run: 10, Epoch: 46, Loss: 1.1491, Train: 52.11%, Valid: 52.81% Test: 53.95%\n",
      "Run: 10, Epoch: 47, Loss: 1.1488, Train: 55.68%, Valid: 51.58% Test: 55.04%\n",
      "Run: 10, Epoch: 48, Loss: 1.1503, Train: 56.59%, Valid: 55.42% Test: 58.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 49, Loss: 1.1492, Train: 53.75%, Valid: 51.99% Test: 53.51%\n",
      "Run: 10, Epoch: 50, Loss: 1.1428, Train: 53.39%, Valid: 51.71% Test: 51.54%\n",
      "Run: 10, Epoch: 51, Loss: 1.1427, Train: 56.14%, Valid: 53.64% Test: 52.85%\n",
      "Run: 10, Epoch: 52, Loss: 1.1242, Train: 55.49%, Valid: 54.87% Test: 54.82%\n",
      "Run: 10, Epoch: 53, Loss: 1.1213, Train: 53.57%, Valid: 51.30% Test: 54.17%\n",
      "Run: 10, Epoch: 54, Loss: 1.1247, Train: 50.55%, Valid: 48.83% Test: 50.00%\n",
      "Run: 10, Epoch: 55, Loss: 1.1260, Train: 50.09%, Valid: 50.34% Test: 50.66%\n",
      "Run: 10, Epoch: 56, Loss: 1.1283, Train: 50.55%, Valid: 52.26% Test: 51.75%\n",
      "Run: 10, Epoch: 57, Loss: 1.1309, Train: 58.42%, Valid: 54.73% Test: 57.24%\n",
      "Run: 10, Epoch: 58, Loss: 1.1003, Train: 59.98%, Valid: 55.69% Test: 58.33%\n",
      "Run: 10, Epoch: 59, Loss: 1.0968, Train: 59.25%, Valid: 56.24% Test: 57.02%\n",
      "Run: 10, Epoch: 60, Loss: 1.1054, Train: 58.61%, Valid: 55.97% Test: 56.58%\n",
      "Run: 10, Epoch: 61, Loss: 1.1115, Train: 55.04%, Valid: 50.34% Test: 53.51%\n",
      "Run: 10, Epoch: 62, Loss: 1.1088, Train: 56.78%, Valid: 53.09% Test: 57.24%\n",
      "Run: 10, Epoch: 63, Loss: 1.0703, Train: 56.87%, Valid: 54.60% Test: 56.58%\n",
      "Run: 10, Epoch: 64, Loss: 1.1208, Train: 55.13%, Valid: 54.18% Test: 54.82%\n",
      "Run: 10, Epoch: 65, Loss: 1.0962, Train: 56.41%, Valid: 51.17% Test: 55.04%\n",
      "Run: 10, Epoch: 66, Loss: 1.1114, Train: 58.33%, Valid: 52.95% Test: 57.02%\n",
      "Run: 10, Epoch: 67, Loss: 1.0877, Train: 59.34%, Valid: 54.46% Test: 57.68%\n",
      "Run: 10, Epoch: 68, Loss: 1.0902, Train: 59.25%, Valid: 56.10% Test: 56.36%\n",
      "Run: 10, Epoch: 69, Loss: 1.0878, Train: 58.88%, Valid: 56.10% Test: 56.14%\n",
      "Run: 10, Epoch: 70, Loss: 1.0781, Train: 57.33%, Valid: 53.50% Test: 54.61%\n",
      "Run: 10, Epoch: 71, Loss: 1.0691, Train: 54.30%, Valid: 50.62% Test: 53.51%\n",
      "Run: 10, Epoch: 72, Loss: 1.0968, Train: 59.71%, Valid: 55.42% Test: 58.33%\n",
      "Run: 10, Epoch: 73, Loss: 1.0832, Train: 60.07%, Valid: 56.93% Test: 59.43%\n",
      "Run: 10, Epoch: 74, Loss: 1.0779, Train: 55.86%, Valid: 51.03% Test: 53.95%\n",
      "Run: 10, Epoch: 75, Loss: 1.0794, Train: 56.32%, Valid: 52.54% Test: 54.61%\n",
      "Run: 10, Epoch: 76, Loss: 1.0636, Train: 57.42%, Valid: 55.83% Test: 55.48%\n",
      "Run: 10, Epoch: 77, Loss: 1.0843, Train: 57.60%, Valid: 55.01% Test: 55.92%\n",
      "Run: 10, Epoch: 78, Loss: 1.0716, Train: 60.16%, Valid: 57.20% Test: 60.53%\n",
      "Run: 10, Epoch: 79, Loss: 1.0492, Train: 59.62%, Valid: 56.10% Test: 59.87%\n",
      "Run: 10, Epoch: 80, Loss: 1.0713, Train: 60.53%, Valid: 57.75% Test: 59.43%\n",
      "Run: 10, Epoch: 81, Loss: 1.0717, Train: 60.53%, Valid: 57.06% Test: 59.43%\n",
      "Run: 10, Epoch: 82, Loss: 1.0640, Train: 61.36%, Valid: 58.98% Test: 61.40%\n",
      "Run: 10, Epoch: 83, Loss: 1.0579, Train: 56.14%, Valid: 56.65% Test: 56.80%\n",
      "Run: 10, Epoch: 84, Loss: 1.0615, Train: 55.49%, Valid: 56.24% Test: 57.24%\n",
      "Run: 10, Epoch: 85, Loss: 1.0852, Train: 60.07%, Valid: 57.89% Test: 57.89%\n",
      "Run: 10, Epoch: 86, Loss: 1.0524, Train: 57.88%, Valid: 52.54% Test: 55.70%\n",
      "Run: 10, Epoch: 87, Loss: 1.0757, Train: 59.16%, Valid: 53.91% Test: 57.46%\n",
      "Run: 10, Epoch: 88, Loss: 1.0464, Train: 60.53%, Valid: 58.44% Test: 59.87%\n",
      "Run: 10, Epoch: 89, Loss: 1.0638, Train: 60.71%, Valid: 58.57% Test: 60.75%\n",
      "Run: 10, Epoch: 90, Loss: 1.0695, Train: 58.70%, Valid: 55.56% Test: 58.11%\n",
      "Run: 10, Epoch: 91, Loss: 1.0464, Train: 54.67%, Valid: 49.66% Test: 50.00%\n",
      "Run: 10, Epoch: 92, Loss: 1.0572, Train: 58.15%, Valid: 53.77% Test: 54.82%\n",
      "Run: 10, Epoch: 93, Loss: 1.0694, Train: 60.44%, Valid: 56.38% Test: 58.99%\n",
      "Run: 10, Epoch: 94, Loss: 1.0556, Train: 60.99%, Valid: 57.20% Test: 60.53%\n",
      "Run: 10, Epoch: 95, Loss: 1.0390, Train: 58.70%, Valid: 52.95% Test: 57.89%\n",
      "Run: 10, Epoch: 96, Loss: 1.0363, Train: 57.60%, Valid: 52.81% Test: 56.58%\n",
      "Run: 10, Epoch: 97, Loss: 1.0597, Train: 57.23%, Valid: 52.81% Test: 57.24%\n",
      "Run: 10, Epoch: 98, Loss: 1.0487, Train: 58.97%, Valid: 55.97% Test: 59.87%\n",
      "Run: 10, Epoch: 99, Loss: 1.0401, Train: 58.42%, Valid: 56.65% Test: 59.87%\n",
      "Run: 10, Epoch: 100, Loss: 1.0248, Train: 58.24%, Valid: 57.06% Test: 59.43%\n",
      "Run: 10, Epoch: 101, Loss: 1.0030, Train: 59.52%, Valid: 57.48% Test: 58.11%\n",
      "Run: 10, Epoch: 102, Loss: 1.0201, Train: 62.73%, Valid: 58.16% Test: 61.40%\n",
      "Run: 10, Epoch: 103, Loss: 1.0212, Train: 62.09%, Valid: 58.71% Test: 62.72%\n",
      "Run: 10, Epoch: 104, Loss: 1.0317, Train: 60.16%, Valid: 57.34% Test: 61.62%\n",
      "Run: 10, Epoch: 105, Loss: 1.0171, Train: 58.79%, Valid: 56.38% Test: 59.43%\n",
      "Run: 10, Epoch: 106, Loss: 1.0203, Train: 59.16%, Valid: 55.56% Test: 58.11%\n",
      "Run: 10, Epoch: 107, Loss: 1.0211, Train: 58.70%, Valid: 56.10% Test: 58.55%\n",
      "Run: 10, Epoch: 108, Loss: 1.0331, Train: 58.61%, Valid: 55.28% Test: 58.33%\n",
      "Run: 10, Epoch: 109, Loss: 1.0228, Train: 54.21%, Valid: 50.48% Test: 52.63%\n",
      "Run: 10, Epoch: 110, Loss: 1.0408, Train: 61.17%, Valid: 58.85% Test: 60.53%\n",
      "Run: 10, Epoch: 111, Loss: 1.0084, Train: 59.98%, Valid: 57.89% Test: 61.18%\n",
      "Run: 10, Epoch: 112, Loss: 1.0269, Train: 58.88%, Valid: 54.87% Test: 55.70%\n",
      "Run: 10, Epoch: 113, Loss: 1.0416, Train: 61.72%, Valid: 59.26% Test: 61.40%\n",
      "Run: 10, Epoch: 114, Loss: 1.0414, Train: 62.00%, Valid: 61.18% Test: 62.06%\n",
      "Run: 10, Epoch: 115, Loss: 1.0141, Train: 61.36%, Valid: 60.22% Test: 60.31%\n",
      "Run: 10, Epoch: 116, Loss: 1.0366, Train: 62.36%, Valid: 61.32% Test: 64.04%\n",
      "Run: 10, Epoch: 117, Loss: 1.0300, Train: 61.72%, Valid: 59.95% Test: 60.75%\n",
      "Run: 10, Epoch: 118, Loss: 1.0396, Train: 62.55%, Valid: 60.36% Test: 59.87%\n",
      "Run: 10, Epoch: 119, Loss: 1.0113, Train: 63.55%, Valid: 62.28% Test: 66.01%\n",
      "Run: 10, Epoch: 120, Loss: 1.0223, Train: 59.34%, Valid: 57.20% Test: 59.87%\n",
      "Run: 10, Epoch: 121, Loss: 1.0140, Train: 59.07%, Valid: 56.10% Test: 57.89%\n",
      "Run: 10, Epoch: 122, Loss: 1.0377, Train: 61.26%, Valid: 60.08% Test: 60.75%\n",
      "Run: 10, Epoch: 123, Loss: 1.0128, Train: 60.62%, Valid: 58.85% Test: 60.96%\n",
      "Run: 10, Epoch: 124, Loss: 0.9956, Train: 59.80%, Valid: 57.48% Test: 61.18%\n",
      "Run: 10, Epoch: 125, Loss: 0.9935, Train: 63.64%, Valid: 62.55% Test: 63.16%\n",
      "Run: 10, Epoch: 126, Loss: 1.0058, Train: 63.28%, Valid: 60.08% Test: 64.47%\n",
      "Run: 10, Epoch: 127, Loss: 0.9977, Train: 62.18%, Valid: 59.95% Test: 62.06%\n",
      "Run: 10, Epoch: 128, Loss: 1.0278, Train: 62.73%, Valid: 61.87% Test: 63.38%\n",
      "Run: 10, Epoch: 129, Loss: 1.0187, Train: 61.08%, Valid: 60.36% Test: 62.72%\n",
      "Run: 10, Epoch: 130, Loss: 1.0357, Train: 60.53%, Valid: 60.49% Test: 61.40%\n",
      "Run: 10, Epoch: 131, Loss: 0.9785, Train: 61.54%, Valid: 59.40% Test: 60.31%\n",
      "Run: 10, Epoch: 132, Loss: 1.0070, Train: 62.09%, Valid: 59.40% Test: 61.84%\n",
      "Run: 10, Epoch: 133, Loss: 1.0248, Train: 61.26%, Valid: 59.40% Test: 61.84%\n",
      "Run: 10, Epoch: 134, Loss: 1.0077, Train: 60.53%, Valid: 58.71% Test: 62.50%\n",
      "Run: 10, Epoch: 135, Loss: 1.0193, Train: 61.08%, Valid: 58.02% Test: 61.84%\n",
      "Run: 10, Epoch: 136, Loss: 1.0142, Train: 59.98%, Valid: 58.02% Test: 61.18%\n",
      "Run: 10, Epoch: 137, Loss: 0.9948, Train: 60.90%, Valid: 57.20% Test: 60.53%\n",
      "Run: 10, Epoch: 138, Loss: 1.0097, Train: 63.64%, Valid: 59.67% Test: 62.72%\n",
      "Run: 10, Epoch: 139, Loss: 1.0124, Train: 62.45%, Valid: 60.22% Test: 62.50%\n",
      "Run: 10, Epoch: 140, Loss: 1.0222, Train: 64.01%, Valid: 61.87% Test: 64.04%\n",
      "Run: 10, Epoch: 141, Loss: 1.0127, Train: 62.73%, Valid: 60.36% Test: 64.04%\n",
      "Run: 10, Epoch: 142, Loss: 0.9809, Train: 62.36%, Valid: 59.95% Test: 64.91%\n",
      "Run: 10, Epoch: 143, Loss: 1.0172, Train: 62.27%, Valid: 59.81% Test: 63.60%\n",
      "Run: 10, Epoch: 144, Loss: 0.9973, Train: 64.56%, Valid: 62.14% Test: 65.13%\n",
      "Run: 10, Epoch: 145, Loss: 0.9883, Train: 63.92%, Valid: 62.83% Test: 65.35%\n",
      "Run: 10, Epoch: 146, Loss: 0.9769, Train: 63.74%, Valid: 62.14% Test: 64.69%\n",
      "Run: 10, Epoch: 147, Loss: 0.9885, Train: 60.62%, Valid: 57.48% Test: 58.99%\n",
      "Run: 10, Epoch: 148, Loss: 0.9831, Train: 61.81%, Valid: 59.81% Test: 61.84%\n",
      "Run: 10, Epoch: 149, Loss: 1.0014, Train: 61.08%, Valid: 59.81% Test: 58.99%\n",
      "Run: 10, Epoch: 150, Loss: 0.9897, Train: 62.55%, Valid: 58.57% Test: 59.87%\n",
      "Run: 10, Epoch: 151, Loss: 0.9836, Train: 62.55%, Valid: 58.85% Test: 61.62%\n",
      "Run: 10, Epoch: 152, Loss: 0.9846, Train: 62.45%, Valid: 60.22% Test: 62.50%\n",
      "Run: 10, Epoch: 153, Loss: 0.9757, Train: 63.28%, Valid: 60.22% Test: 63.16%\n",
      "Run: 10, Epoch: 154, Loss: 0.9985, Train: 62.18%, Valid: 56.52% Test: 60.53%\n",
      "Run: 10, Epoch: 155, Loss: 0.9881, Train: 63.10%, Valid: 59.53% Test: 61.62%\n",
      "Run: 10, Epoch: 156, Loss: 0.9938, Train: 63.19%, Valid: 61.73% Test: 63.16%\n",
      "Run: 10, Epoch: 157, Loss: 0.9977, Train: 63.74%, Valid: 60.63% Test: 62.72%\n",
      "Run: 10, Epoch: 158, Loss: 0.9987, Train: 61.72%, Valid: 58.16% Test: 61.18%\n",
      "Run: 10, Epoch: 159, Loss: 0.9913, Train: 63.37%, Valid: 59.12% Test: 62.72%\n",
      "Run: 10, Epoch: 160, Loss: 0.9841, Train: 61.26%, Valid: 57.75% Test: 61.18%\n",
      "Run: 10, Epoch: 161, Loss: 0.9665, Train: 62.45%, Valid: 58.71% Test: 61.62%\n",
      "Run: 10, Epoch: 162, Loss: 0.9894, Train: 58.06%, Valid: 55.69% Test: 54.82%\n",
      "Run: 10, Epoch: 163, Loss: 1.0583, Train: 63.00%, Valid: 58.71% Test: 58.99%\n",
      "Run: 10, Epoch: 164, Loss: 0.9955, Train: 65.20%, Valid: 62.83% Test: 63.16%\n",
      "Run: 10, Epoch: 165, Loss: 0.9871, Train: 62.00%, Valid: 60.77% Test: 60.96%\n",
      "Run: 10, Epoch: 166, Loss: 1.0107, Train: 60.26%, Valid: 59.26% Test: 60.53%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 167, Loss: 1.0170, Train: 58.79%, Valid: 55.56% Test: 60.09%\n",
      "Run: 10, Epoch: 168, Loss: 0.9905, Train: 60.53%, Valid: 56.38% Test: 58.33%\n",
      "Run: 10, Epoch: 169, Loss: 1.0069, Train: 58.70%, Valid: 55.14% Test: 57.89%\n",
      "Run: 10, Epoch: 170, Loss: 0.9927, Train: 59.25%, Valid: 56.52% Test: 58.99%\n",
      "Run: 10, Epoch: 171, Loss: 0.9882, Train: 62.73%, Valid: 58.98% Test: 61.40%\n",
      "Run: 10, Epoch: 172, Loss: 0.9932, Train: 62.00%, Valid: 58.30% Test: 59.65%\n",
      "Run: 10, Epoch: 173, Loss: 1.0039, Train: 63.37%, Valid: 61.59% Test: 62.06%\n",
      "Run: 10, Epoch: 174, Loss: 0.9886, Train: 60.16%, Valid: 58.02% Test: 58.33%\n",
      "Run: 10, Epoch: 175, Loss: 0.9874, Train: 59.89%, Valid: 57.61% Test: 59.65%\n",
      "Run: 10, Epoch: 176, Loss: 1.0167, Train: 62.45%, Valid: 59.40% Test: 60.96%\n",
      "Run: 10, Epoch: 177, Loss: 0.9519, Train: 61.72%, Valid: 58.44% Test: 57.68%\n",
      "Run: 10, Epoch: 178, Loss: 0.9911, Train: 62.36%, Valid: 58.85% Test: 60.96%\n",
      "Run: 10, Epoch: 179, Loss: 0.9710, Train: 63.74%, Valid: 61.59% Test: 64.91%\n",
      "Run: 10, Epoch: 180, Loss: 0.9713, Train: 61.81%, Valid: 58.16% Test: 63.82%\n",
      "Run: 10, Epoch: 181, Loss: 1.0063, Train: 64.01%, Valid: 60.63% Test: 65.35%\n",
      "Run: 10, Epoch: 182, Loss: 0.9738, Train: 61.90%, Valid: 60.36% Test: 59.43%\n",
      "Run: 10, Epoch: 183, Loss: 0.9760, Train: 58.79%, Valid: 58.30% Test: 58.77%\n",
      "Run: 10, Epoch: 184, Loss: 1.0129, Train: 61.72%, Valid: 58.98% Test: 60.31%\n",
      "Run: 10, Epoch: 185, Loss: 1.0115, Train: 61.72%, Valid: 61.45% Test: 63.16%\n",
      "Run: 10, Epoch: 186, Loss: 1.0174, Train: 64.93%, Valid: 62.69% Test: 63.60%\n",
      "Run: 10, Epoch: 187, Loss: 0.9719, Train: 59.80%, Valid: 58.71% Test: 59.21%\n",
      "Run: 10, Epoch: 188, Loss: 1.0290, Train: 63.46%, Valid: 60.49% Test: 62.50%\n",
      "Run: 10, Epoch: 189, Loss: 0.9782, Train: 62.09%, Valid: 59.40% Test: 62.28%\n",
      "Run: 10, Epoch: 190, Loss: 1.0065, Train: 60.99%, Valid: 58.02% Test: 58.77%\n",
      "Run: 10, Epoch: 191, Loss: 0.9812, Train: 61.17%, Valid: 58.44% Test: 60.75%\n",
      "Run: 10, Epoch: 192, Loss: 0.9878, Train: 59.89%, Valid: 57.20% Test: 60.09%\n",
      "Run: 10, Epoch: 193, Loss: 0.9888, Train: 60.44%, Valid: 57.06% Test: 61.40%\n",
      "Run: 10, Epoch: 194, Loss: 0.9863, Train: 63.83%, Valid: 59.81% Test: 64.91%\n",
      "Run: 10, Epoch: 195, Loss: 0.9776, Train: 63.19%, Valid: 58.02% Test: 63.38%\n",
      "Run: 10, Epoch: 196, Loss: 1.0099, Train: 64.01%, Valid: 61.59% Test: 65.13%\n",
      "Run: 10, Epoch: 197, Loss: 0.9567, Train: 62.55%, Valid: 59.81% Test: 62.72%\n",
      "Run: 10, Epoch: 198, Loss: 0.9960, Train: 62.73%, Valid: 60.49% Test: 62.06%\n",
      "Run: 10, Epoch: 199, Loss: 0.9822, Train: 64.01%, Valid: 60.49% Test: 62.94%\n",
      "Run: 10, Epoch: 200, Loss: 1.0096, Train: 65.48%, Valid: 63.10% Test: 67.32%\n",
      "Run 10:\n",
      "Highest Train: 65.48\n",
      "Highest Valid: 63.10\n",
      "  Final Train: 65.48\n",
      "   Final Test: 67.32\n",
      "All runs:\n",
      "Highest Train: 64.55 ± 2.17\n",
      "Highest Valid: 63.13 ± 1.05\n",
      "  Final Train: 63.22 ± 2.36\n",
      "   Final Test: 61.80 ± 3.03\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 48, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.05}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = WebKB(root='/tmp/Texas', name='Texas',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    #idx_train=[data.train_mask[i][0] for i in range(len(data.y))]\n",
    "    #train_idx = np.where(idx_train)[0]\n",
    "    #idx_val=[data.val_mask[i][0] for i in range(len(data.y))]\n",
    "    #valid_idx = np.where(idx_val)[0]\n",
    "    #idx_test=[data.test_mask[i][0] for i in range(len(data.y))]\n",
    "    #test_idx = np.where(idx_test)[0]\n",
    "    \n",
    "    model = GCN(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085c7fd",
   "metadata": {},
   "source": [
    "# Topological Encoddnig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33e47b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2277, 2325], edge_index=[2, 36101], y=[2277], train_mask=[2277, 10], val_mask=[2277, 10], test_mask=[2277, 10])\n"
     ]
    }
   ],
   "source": [
    "dataset = WikipediaNetwork(root='/tmp/chameleon', name='chameleon')\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607be4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.edge_index.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52514bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_idx=data.edge_index.numpy()\n",
    "Node=range(Number_nodes)\n",
    "Edgelist=[]\n",
    "for i in range(len(Edge_idx[1])):\n",
    "    Edgelist.append((Edge_idx[0][i],Edge_idx[1][i]))\n",
    "#print(Edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a \"plain\" graph is undirected\n",
    "#G = nx.DiGraph()\n",
    "G = nx.Graph()\n",
    "\n",
    "# give each a node a 'name', which is a letter in this case.\n",
    "#G.add_node('a')\n",
    "\n",
    "# the add_nodes_from method allows adding nodes from a sequence, in this case a list\n",
    "#nodes_to_add = ['b', 'c', 'd']\n",
    "G.add_nodes_from(Node)\n",
    "\n",
    "# add edge from 'a' to 'b'\n",
    "# since this graph is undirected, the order doesn't matter here\n",
    "#G.add_edge('a', 'b')\n",
    "\n",
    "# just like add_nodes_from, we can add edges from a sequence\n",
    "# edges should be specified as 2-tuples\n",
    "#edges_to_add = [('a', 'c'), ('b', 'c'), ('c', 'd')]\n",
    "G.add_edges_from(Edgelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781abc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77abd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topological_Feature_subLevel(adj,filtration_fun, Filtration):\n",
    "        betti_0=[]\n",
    "        betti_1=[]\n",
    "        for p in range(len(Filtration)):\n",
    "            n_active = np.where(np.array(filtration_fun) <= Filtration[p])[0].tolist()\n",
    "            Active_node=np.unique(n_active)\n",
    "            if (len(Active_node)==0):\n",
    "                betti_0.append(0)\n",
    "                betti_1.append(0)\n",
    "            else:\n",
    "                b=adj[Active_node,:][:,Active_node]\n",
    "                my_flag=pyflagser.flagser_unweighted(b, min_dimension=0, max_dimension=2, directed=False, coeff=2, approximation=None)\n",
    "                x = my_flag[\"betti\"]\n",
    "                betti_0.append(x[0])\n",
    "                betti_1.append(x[1])\n",
    "            n_active.clear()\n",
    "        return betti_0,betti_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40cacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Degree_list(Graph):\n",
    "    degree_list = [Graph.degree(node) for node in Graph.nodes]\n",
    "    return np.array(degree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_list=Degree_list(G)\n",
    "unique_list=np.unique(degree_list)\n",
    "for d in unique_list:\n",
    "    count=0\n",
    "    for i in range(len(degree_list)):\n",
    "        if degree_list[i]==d:\n",
    "            count=count+1\n",
    "    print(int(d),\" | \",count,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7080881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyflagser\n",
    "Node_fil=[1,2,3,4,5,6,7,8,9,10,12,15,20,25,30,50,100,200,400]\n",
    "topo_betti_0=[]\n",
    "topo_betti_1=[]\n",
    "Node_Edge=[]\n",
    "for i in range(Number_nodes):\n",
    "    print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//(Number_nodes-1)), end='', flush=True)\n",
    "    subgraph=ego_graph(G, i, radius=2, center=True, undirected=True, distance=None)\n",
    "    filt=Degree_list(subgraph)\n",
    "    A_sub = nx.to_numpy_array(subgraph)# adjacency matrix of subgraph\n",
    "    fe=Topological_Feature_subLevel(A_sub,filt,Node_fil)\n",
    "    topo_betti_0.append(fe[0])\n",
    "    topo_betti_1.append(fe[1])\n",
    "    Node_Edge.append([subgraph.number_of_nodes(),subgraph.number_of_edges()])\n",
    "    #topo_with_NE.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a5892bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>9.1</th>\n",
       "      <th>10.1</th>\n",
       "      <th>11.1</th>\n",
       "      <th>12.1</th>\n",
       "      <th>13.1</th>\n",
       "      <th>14.1</th>\n",
       "      <th>15.1</th>\n",
       "      <th>16.1</th>\n",
       "      <th>17.1</th>\n",
       "      <th>18.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>170</td>\n",
       "      <td>308</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>89</td>\n",
       "      <td>109</td>\n",
       "      <td>134</td>\n",
       "      <td>201</td>\n",
       "      <td>266</td>\n",
       "      <td>309</td>\n",
       "      <td>324</td>\n",
       "      <td>328</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>53</td>\n",
       "      <td>105</td>\n",
       "      <td>185</td>\n",
       "      <td>1191</td>\n",
       "      <td>1169</td>\n",
       "      <td>617</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   0   1    2    3    4    5    6    7    8  ...  9.1  10.1  \\\n",
       "0           0   0   5    5   13   14   14   14    8    8  ...    3     5   \n",
       "1           1   4  13   20   25   27   24   25   27   26  ...    0     0   \n",
       "2           2   3   4   11   12   17   18   26   26   30  ...    0     4   \n",
       "3           3   7   7    7    7    7    7    1    1    1  ...    0     0   \n",
       "4           4  33  89  109  134  201  266  309  324  328  ...   14    15   \n",
       "\n",
       "   11.1  12.1  13.1  14.1  15.1  16.1  17.1  18.1  \n",
       "0    13    13    10    10    10    10    10    10  \n",
       "1     3    13    40    56    25     3     3     3  \n",
       "2     6    13    23    38   170   308    44    13  \n",
       "3     0     0     0     0     0     0     0     0  \n",
       "4    27    53   105   185  1191  1169   617   617  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Feature_Cham.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ee3902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9.1</th>\n",
       "      <th>10.1</th>\n",
       "      <th>11.1</th>\n",
       "      <th>12.1</th>\n",
       "      <th>13.1</th>\n",
       "      <th>14.1</th>\n",
       "      <th>15.1</th>\n",
       "      <th>16.1</th>\n",
       "      <th>17.1</th>\n",
       "      <th>18.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>170</td>\n",
       "      <td>308</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>89</td>\n",
       "      <td>109</td>\n",
       "      <td>134</td>\n",
       "      <td>201</td>\n",
       "      <td>266</td>\n",
       "      <td>309</td>\n",
       "      <td>324</td>\n",
       "      <td>328</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>53</td>\n",
       "      <td>105</td>\n",
       "      <td>185</td>\n",
       "      <td>1191</td>\n",
       "      <td>1169</td>\n",
       "      <td>617</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1    2    3    4    5    6    7    8    9  ...  9.1  10.1  11.1  12.1  \\\n",
       "0   0   5    5   13   14   14   14    8    8    8  ...    3     5    13    13   \n",
       "1   4  13   20   25   27   24   25   27   26   27  ...    0     0     3    13   \n",
       "2   3   4   11   12   17   18   26   26   30   31  ...    0     4     6    13   \n",
       "3   7   7    7    7    7    7    1    1    1    1  ...    0     0     0     0   \n",
       "4  33  89  109  134  201  266  309  324  328  321  ...   14    15    27    53   \n",
       "\n",
       "   13.1  14.1  15.1  16.1  17.1  18.1  \n",
       "0    10    10    10    10    10    10  \n",
       "1    40    56    25     3     3     3  \n",
       "2    23    38   170   308    44    13  \n",
       "3     0     0     0     0     0     0  \n",
       "4   105   185  1191  1169   617   617  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1=data.drop(['Unnamed: 0'], axis=1)\n",
    "Data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d4b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topo_fe=torch.tensor(Data1.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef9ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2277, 2325], y=[2277], train_mask=[2277, 10], val_mask=[2277, 10], test_mask=[2277, 10], adj_t=[2277, 2277, nnz=36101])\n"
     ]
    }
   ],
   "source": [
    "dataset = WikipediaNetwork(root='/tmp/chameleon', name='chameleon',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea2a49",
   "metadata": {},
   "source": [
    "# Topo-W-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbeea52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2277, 2325], y=[2277], train_mask=[2277, 10], val_mask=[2277, 10], test_mask=[2277, 10], adj_t=[2277, 2277, nnz=36101], topo=[2277, 38])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "data.topo=Topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(topo_fe[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4668e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "        #return x.log_softmax(dim=-1)\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        #return torch.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "class MLP2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP2, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp2(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "    \n",
    "\n",
    "def train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2):\n",
    "    model.train()\n",
    "    mlp_model.train()\n",
    "    mlp_2.train()\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_mlp.zero_grad()\n",
    "    optimizer_mlp2.zero_grad()\n",
    "    gcn_embedding = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(gcn_embedding)\n",
    "    mlp_embedding = mlp_model(data.topo[train_idx])\n",
    "    #print(mlp_embedding)\n",
    "    combined_embedding = torch.cat((gcn_embedding, mlp_embedding), dim=1)\n",
    "    #print(combined_embedding)\n",
    "    mlp_emb = mlp_2(combined_embedding)\n",
    "    #print(mlp_emb)\n",
    "    loss = F.nll_loss(mlp_emb, data.y.squeeze()[train_idx])\n",
    "    #loss = F.nll_loss(combined_embedding, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer_mlp2.step()\n",
    "    optimizer.step()\n",
    "    optimizer_mlp.step()\n",
    "    \n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "    mlp_model.eval()\n",
    "    mlp_2.eval()\n",
    "\n",
    "    gcn_out = model(data.x, data.adj_t)\n",
    "    #print(gcn_out[0])\n",
    "    mlp_out=mlp_model(data.topo)\n",
    "    #print(mlp_out)\n",
    "    #out=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    Com=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    out=mlp_2(Com)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    #print(y_pred[0])\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef21f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x1773cea70>\n",
      "Run: 01, Epoch: 01, Loss: 1.6227, Train: 25.64%, Valid: 26.06% Test: 25.44%\n",
      "Run: 01, Epoch: 02, Loss: 1.4579, Train: 27.38%, Valid: 27.98% Test: 28.07%\n",
      "Run: 01, Epoch: 03, Loss: 1.4099, Train: 22.07%, Valid: 24.42% Test: 22.37%\n",
      "Run: 01, Epoch: 04, Loss: 1.3745, Train: 22.07%, Valid: 24.42% Test: 22.37%\n",
      "Run: 01, Epoch: 05, Loss: 1.3475, Train: 22.07%, Valid: 24.55% Test: 22.81%\n",
      "Run: 01, Epoch: 06, Loss: 1.3361, Train: 23.81%, Valid: 27.30% Test: 23.90%\n",
      "Run: 01, Epoch: 07, Loss: 1.3061, Train: 25.27%, Valid: 27.02% Test: 25.00%\n",
      "Run: 01, Epoch: 08, Loss: 1.2949, Train: 33.61%, Valid: 36.35% Test: 35.31%\n",
      "Run: 01, Epoch: 09, Loss: 1.2558, Train: 37.09%, Valid: 41.84% Test: 41.67%\n",
      "Run: 01, Epoch: 10, Loss: 1.2335, Train: 39.84%, Valid: 42.39% Test: 41.01%\n",
      "Run: 01, Epoch: 11, Loss: 1.2216, Train: 37.45%, Valid: 38.96% Test: 37.50%\n",
      "Run: 01, Epoch: 12, Loss: 1.2218, Train: 38.19%, Valid: 38.68% Test: 36.62%\n",
      "Run: 01, Epoch: 13, Loss: 1.2245, Train: 40.38%, Valid: 39.92% Test: 39.69%\n",
      "Run: 01, Epoch: 14, Loss: 1.2027, Train: 42.22%, Valid: 43.76% Test: 44.30%\n",
      "Run: 01, Epoch: 15, Loss: 1.1710, Train: 40.11%, Valid: 42.52% Test: 42.32%\n",
      "Run: 01, Epoch: 16, Loss: 1.1588, Train: 41.76%, Valid: 45.13% Test: 43.86%\n",
      "Run: 01, Epoch: 17, Loss: 1.1780, Train: 43.13%, Valid: 45.13% Test: 43.42%\n",
      "Run: 01, Epoch: 18, Loss: 1.1499, Train: 41.85%, Valid: 44.03% Test: 42.76%\n",
      "Run: 01, Epoch: 19, Loss: 1.1577, Train: 47.44%, Valid: 47.74% Test: 49.78%\n",
      "Run: 01, Epoch: 20, Loss: 1.1158, Train: 53.30%, Valid: 52.95% Test: 53.51%\n",
      "Run: 01, Epoch: 21, Loss: 1.1236, Train: 50.92%, Valid: 49.38% Test: 50.22%\n",
      "Run: 01, Epoch: 22, Loss: 1.1346, Train: 46.98%, Valid: 47.46% Test: 46.49%\n",
      "Run: 01, Epoch: 23, Loss: 1.1355, Train: 46.52%, Valid: 47.33% Test: 46.71%\n",
      "Run: 01, Epoch: 24, Loss: 1.1105, Train: 51.83%, Valid: 50.62% Test: 50.22%\n",
      "Run: 01, Epoch: 25, Loss: 1.0938, Train: 50.92%, Valid: 47.87% Test: 51.32%\n",
      "Run: 01, Epoch: 26, Loss: 1.1011, Train: 49.27%, Valid: 46.91% Test: 50.44%\n",
      "Run: 01, Epoch: 27, Loss: 1.0984, Train: 49.36%, Valid: 48.70% Test: 50.44%\n",
      "Run: 01, Epoch: 28, Loss: 1.0865, Train: 52.84%, Valid: 51.58% Test: 51.75%\n",
      "Run: 01, Epoch: 29, Loss: 1.1005, Train: 53.11%, Valid: 52.13% Test: 52.85%\n",
      "Run: 01, Epoch: 30, Loss: 1.0834, Train: 51.19%, Valid: 50.48% Test: 51.54%\n",
      "Run: 01, Epoch: 31, Loss: 1.1038, Train: 48.17%, Valid: 47.60% Test: 48.25%\n",
      "Run: 01, Epoch: 32, Loss: 1.0636, Train: 48.90%, Valid: 49.38% Test: 48.90%\n",
      "Run: 01, Epoch: 33, Loss: 1.0724, Train: 49.36%, Valid: 49.79% Test: 50.44%\n",
      "Run: 01, Epoch: 34, Loss: 1.0441, Train: 51.28%, Valid: 51.85% Test: 52.63%\n",
      "Run: 01, Epoch: 35, Loss: 1.0668, Train: 54.21%, Valid: 52.95% Test: 55.48%\n",
      "Run: 01, Epoch: 36, Loss: 1.0322, Train: 54.95%, Valid: 53.09% Test: 53.73%\n",
      "Run: 01, Epoch: 37, Loss: 1.0289, Train: 54.67%, Valid: 53.36% Test: 52.41%\n",
      "Run: 01, Epoch: 38, Loss: 1.0528, Train: 55.31%, Valid: 52.81% Test: 55.70%\n",
      "Run: 01, Epoch: 39, Loss: 1.0328, Train: 56.59%, Valid: 54.73% Test: 58.55%\n",
      "Run: 01, Epoch: 40, Loss: 1.0355, Train: 55.95%, Valid: 55.42% Test: 57.68%\n",
      "Run: 01, Epoch: 41, Loss: 1.0307, Train: 59.71%, Valid: 57.20% Test: 58.99%\n",
      "Run: 01, Epoch: 42, Loss: 1.0265, Train: 61.26%, Valid: 58.02% Test: 61.40%\n",
      "Run: 01, Epoch: 43, Loss: 1.0081, Train: 62.09%, Valid: 59.40% Test: 63.38%\n",
      "Run: 01, Epoch: 44, Loss: 0.9927, Train: 62.45%, Valid: 58.98% Test: 62.72%\n",
      "Run: 01, Epoch: 45, Loss: 1.0116, Train: 60.90%, Valid: 57.61% Test: 59.43%\n",
      "Run: 01, Epoch: 46, Loss: 1.0109, Train: 62.27%, Valid: 60.63% Test: 60.53%\n",
      "Run: 01, Epoch: 47, Loss: 1.0365, Train: 63.83%, Valid: 62.28% Test: 62.72%\n",
      "Run: 01, Epoch: 48, Loss: 1.0009, Train: 62.55%, Valid: 60.91% Test: 58.99%\n",
      "Run: 01, Epoch: 49, Loss: 0.9920, Train: 68.32%, Valid: 64.61% Test: 65.57%\n",
      "Run: 01, Epoch: 50, Loss: 0.9986, Train: 65.84%, Valid: 61.45% Test: 63.38%\n",
      "Run: 01, Epoch: 51, Loss: 0.9934, Train: 59.89%, Valid: 59.26% Test: 60.09%\n",
      "Run: 01, Epoch: 52, Loss: 0.9772, Train: 59.43%, Valid: 59.67% Test: 60.09%\n",
      "Run: 01, Epoch: 53, Loss: 0.9831, Train: 60.16%, Valid: 57.75% Test: 56.14%\n",
      "Run: 01, Epoch: 54, Loss: 0.9905, Train: 53.94%, Valid: 53.64% Test: 51.54%\n",
      "Run: 01, Epoch: 55, Loss: 1.0284, Train: 53.21%, Valid: 53.50% Test: 49.34%\n",
      "Run: 01, Epoch: 56, Loss: 1.0026, Train: 56.68%, Valid: 53.50% Test: 54.61%\n",
      "Run: 01, Epoch: 57, Loss: 0.9829, Train: 57.05%, Valid: 54.32% Test: 53.95%\n",
      "Run: 01, Epoch: 58, Loss: 0.9706, Train: 58.42%, Valid: 57.48% Test: 58.77%\n",
      "Run: 01, Epoch: 59, Loss: 0.9876, Train: 62.27%, Valid: 59.95% Test: 61.84%\n",
      "Run: 01, Epoch: 60, Loss: 0.9752, Train: 60.26%, Valid: 55.56% Test: 57.68%\n",
      "Run: 01, Epoch: 61, Loss: 1.0403, Train: 61.08%, Valid: 58.16% Test: 62.06%\n",
      "Run: 01, Epoch: 62, Loss: 0.9997, Train: 61.54%, Valid: 61.04% Test: 61.84%\n",
      "Run: 01, Epoch: 63, Loss: 0.9766, Train: 57.88%, Valid: 58.71% Test: 55.70%\n",
      "Run: 01, Epoch: 64, Loss: 0.9690, Train: 57.51%, Valid: 57.61% Test: 54.82%\n",
      "Run: 01, Epoch: 65, Loss: 0.9952, Train: 62.73%, Valid: 59.40% Test: 61.84%\n",
      "Run: 01, Epoch: 66, Loss: 0.9939, Train: 63.92%, Valid: 58.98% Test: 61.84%\n",
      "Run: 01, Epoch: 67, Loss: 0.9855, Train: 66.67%, Valid: 63.24% Test: 64.25%\n",
      "Run: 01, Epoch: 68, Loss: 0.9804, Train: 64.29%, Valid: 62.83% Test: 60.53%\n",
      "Run: 01, Epoch: 69, Loss: 0.9615, Train: 61.90%, Valid: 60.77% Test: 60.09%\n",
      "Run: 01, Epoch: 70, Loss: 0.9649, Train: 60.16%, Valid: 59.12% Test: 60.53%\n",
      "Run: 01, Epoch: 71, Loss: 0.9906, Train: 63.00%, Valid: 60.36% Test: 59.65%\n",
      "Run: 01, Epoch: 72, Loss: 0.9486, Train: 61.81%, Valid: 60.91% Test: 61.62%\n",
      "Run: 01, Epoch: 73, Loss: 0.9742, Train: 63.10%, Valid: 61.32% Test: 61.40%\n",
      "Run: 01, Epoch: 74, Loss: 0.9745, Train: 62.00%, Valid: 60.91% Test: 60.31%\n",
      "Run: 01, Epoch: 75, Loss: 0.9530, Train: 61.90%, Valid: 59.12% Test: 57.46%\n",
      "Run: 01, Epoch: 76, Loss: 0.9703, Train: 63.37%, Valid: 59.53% Test: 59.21%\n",
      "Run: 01, Epoch: 77, Loss: 0.9590, Train: 66.21%, Valid: 63.37% Test: 64.04%\n",
      "Run: 01, Epoch: 78, Loss: 0.9596, Train: 64.65%, Valid: 62.55% Test: 61.40%\n",
      "Run: 01, Epoch: 79, Loss: 0.9814, Train: 64.01%, Valid: 63.65% Test: 62.06%\n",
      "Run: 01, Epoch: 80, Loss: 0.9749, Train: 63.37%, Valid: 62.69% Test: 61.62%\n",
      "Run: 01, Epoch: 81, Loss: 0.9151, Train: 59.07%, Valid: 58.30% Test: 55.70%\n",
      "Run: 01, Epoch: 82, Loss: 0.9417, Train: 63.46%, Valid: 61.32% Test: 60.53%\n",
      "Run: 01, Epoch: 83, Loss: 0.9436, Train: 66.21%, Valid: 63.51% Test: 62.72%\n",
      "Run: 01, Epoch: 84, Loss: 0.9146, Train: 65.48%, Valid: 62.96% Test: 61.84%\n",
      "Run: 01, Epoch: 85, Loss: 0.9334, Train: 67.03%, Valid: 63.24% Test: 62.72%\n",
      "Run: 01, Epoch: 86, Loss: 0.9444, Train: 63.74%, Valid: 58.98% Test: 60.75%\n",
      "Run: 01, Epoch: 87, Loss: 0.9440, Train: 65.11%, Valid: 60.77% Test: 61.84%\n",
      "Run: 01, Epoch: 88, Loss: 0.9479, Train: 65.38%, Valid: 63.37% Test: 62.50%\n",
      "Run: 01, Epoch: 89, Loss: 0.9517, Train: 67.77%, Valid: 64.47% Test: 65.13%\n",
      "Run: 01, Epoch: 90, Loss: 0.9123, Train: 68.04%, Valid: 64.88% Test: 64.91%\n",
      "Run: 01, Epoch: 91, Loss: 0.9330, Train: 68.50%, Valid: 65.71% Test: 65.35%\n",
      "Run: 01, Epoch: 92, Loss: 0.9412, Train: 68.32%, Valid: 65.57% Test: 66.23%\n",
      "Run: 01, Epoch: 93, Loss: 0.9284, Train: 68.41%, Valid: 66.53% Test: 66.89%\n",
      "Run: 01, Epoch: 94, Loss: 0.9306, Train: 68.68%, Valid: 65.16% Test: 65.13%\n",
      "Run: 01, Epoch: 95, Loss: 0.9152, Train: 68.32%, Valid: 64.75% Test: 66.45%\n",
      "Run: 01, Epoch: 96, Loss: 0.9315, Train: 67.86%, Valid: 64.61% Test: 64.04%\n",
      "Run: 01, Epoch: 97, Loss: 0.9308, Train: 66.58%, Valid: 63.65% Test: 61.62%\n",
      "Run: 01, Epoch: 98, Loss: 0.9175, Train: 64.19%, Valid: 61.45% Test: 61.62%\n",
      "Run: 01, Epoch: 99, Loss: 0.9025, Train: 65.66%, Valid: 62.00% Test: 63.16%\n",
      "Run: 01, Epoch: 100, Loss: 0.9384, Train: 66.48%, Valid: 63.24% Test: 63.38%\n",
      "Run 01:\n",
      "Highest Train: 68.68\n",
      "Highest Valid: 66.53\n",
      "  Final Train: 68.41\n",
      "   Final Test: 66.89\n",
      "Run: 02, Epoch: 01, Loss: 1.6684, Train: 22.16%, Valid: 17.56% Test: 18.20%\n",
      "Run: 02, Epoch: 02, Loss: 1.4777, Train: 22.16%, Valid: 17.70% Test: 18.20%\n",
      "Run: 02, Epoch: 03, Loss: 1.4303, Train: 28.48%, Valid: 27.02% Test: 26.54%\n",
      "Run: 02, Epoch: 04, Loss: 1.3811, Train: 25.00%, Valid: 27.43% Test: 25.88%\n",
      "Run: 02, Epoch: 05, Loss: 1.3444, Train: 28.57%, Valid: 26.89% Test: 30.70%\n",
      "Run: 02, Epoch: 06, Loss: 1.3056, Train: 23.26%, Valid: 23.87% Test: 25.66%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 07, Loss: 1.2850, Train: 27.75%, Valid: 27.16% Test: 30.48%\n",
      "Run: 02, Epoch: 08, Loss: 1.2678, Train: 30.86%, Valid: 29.90% Test: 33.77%\n",
      "Run: 02, Epoch: 09, Loss: 1.2471, Train: 31.68%, Valid: 31.28% Test: 35.75%\n",
      "Run: 02, Epoch: 10, Loss: 1.2276, Train: 44.78%, Valid: 42.25% Test: 46.27%\n",
      "Run: 02, Epoch: 11, Loss: 1.1842, Train: 44.69%, Valid: 42.94% Test: 46.05%\n",
      "Run: 02, Epoch: 12, Loss: 1.1750, Train: 45.42%, Valid: 43.90% Test: 46.05%\n",
      "Run: 02, Epoch: 13, Loss: 1.1723, Train: 44.87%, Valid: 42.66% Test: 45.18%\n",
      "Run: 02, Epoch: 14, Loss: 1.1475, Train: 53.02%, Valid: 50.07% Test: 51.75%\n",
      "Run: 02, Epoch: 15, Loss: 1.1651, Train: 46.52%, Valid: 46.36% Test: 50.88%\n",
      "Run: 02, Epoch: 16, Loss: 1.1434, Train: 56.23%, Valid: 53.91% Test: 59.65%\n",
      "Run: 02, Epoch: 17, Loss: 1.1430, Train: 55.95%, Valid: 51.99% Test: 58.11%\n",
      "Run: 02, Epoch: 18, Loss: 1.1153, Train: 50.46%, Valid: 48.01% Test: 52.85%\n",
      "Run: 02, Epoch: 19, Loss: 1.1274, Train: 57.05%, Valid: 52.67% Test: 57.89%\n",
      "Run: 02, Epoch: 20, Loss: 1.1098, Train: 57.78%, Valid: 53.91% Test: 60.53%\n",
      "Run: 02, Epoch: 21, Loss: 1.1131, Train: 48.99%, Valid: 46.78% Test: 53.07%\n",
      "Run: 02, Epoch: 22, Loss: 1.0923, Train: 55.40%, Valid: 51.17% Test: 57.89%\n",
      "Run: 02, Epoch: 23, Loss: 1.0665, Train: 52.93%, Valid: 51.71% Test: 55.70%\n",
      "Run: 02, Epoch: 24, Loss: 1.0636, Train: 51.83%, Valid: 49.11% Test: 53.73%\n",
      "Run: 02, Epoch: 25, Loss: 1.0904, Train: 51.01%, Valid: 48.29% Test: 51.97%\n",
      "Run: 02, Epoch: 26, Loss: 1.0858, Train: 52.84%, Valid: 48.01% Test: 52.19%\n",
      "Run: 02, Epoch: 27, Loss: 1.0541, Train: 53.85%, Valid: 49.52% Test: 54.17%\n",
      "Run: 02, Epoch: 28, Loss: 1.0974, Train: 54.40%, Valid: 49.93% Test: 54.39%\n",
      "Run: 02, Epoch: 29, Loss: 1.0612, Train: 53.75%, Valid: 50.48% Test: 54.17%\n",
      "Run: 02, Epoch: 30, Loss: 1.0533, Train: 54.30%, Valid: 50.89% Test: 54.82%\n",
      "Run: 02, Epoch: 31, Loss: 1.0254, Train: 56.59%, Valid: 52.67% Test: 57.46%\n",
      "Run: 02, Epoch: 32, Loss: 1.0483, Train: 56.59%, Valid: 51.85% Test: 57.46%\n",
      "Run: 02, Epoch: 33, Loss: 1.0468, Train: 55.31%, Valid: 52.81% Test: 56.80%\n",
      "Run: 02, Epoch: 34, Loss: 1.0132, Train: 54.40%, Valid: 51.17% Test: 56.14%\n",
      "Run: 02, Epoch: 35, Loss: 1.0750, Train: 56.32%, Valid: 52.13% Test: 56.80%\n",
      "Run: 02, Epoch: 36, Loss: 1.0529, Train: 55.68%, Valid: 52.54% Test: 57.02%\n",
      "Run: 02, Epoch: 37, Loss: 1.0371, Train: 46.61%, Valid: 45.54% Test: 46.27%\n",
      "Run: 02, Epoch: 38, Loss: 1.0612, Train: 47.53%, Valid: 44.99% Test: 47.37%\n",
      "Run: 02, Epoch: 39, Loss: 1.0209, Train: 46.34%, Valid: 42.94% Test: 46.71%\n",
      "Run: 02, Epoch: 40, Loss: 1.0183, Train: 38.92%, Valid: 38.00% Test: 39.04%\n",
      "Run: 02, Epoch: 41, Loss: 1.0133, Train: 46.79%, Valid: 44.44% Test: 48.90%\n",
      "Run: 02, Epoch: 42, Loss: 1.0268, Train: 55.49%, Valid: 49.79% Test: 56.36%\n",
      "Run: 02, Epoch: 43, Loss: 1.0386, Train: 57.05%, Valid: 51.85% Test: 57.68%\n",
      "Run: 02, Epoch: 44, Loss: 1.0201, Train: 58.52%, Valid: 53.64% Test: 60.09%\n",
      "Run: 02, Epoch: 45, Loss: 1.0294, Train: 59.07%, Valid: 54.46% Test: 60.75%\n",
      "Run: 02, Epoch: 46, Loss: 1.0173, Train: 59.16%, Valid: 54.73% Test: 62.06%\n",
      "Run: 02, Epoch: 47, Loss: 1.0048, Train: 58.33%, Valid: 52.67% Test: 60.53%\n",
      "Run: 02, Epoch: 48, Loss: 1.0070, Train: 57.97%, Valid: 53.09% Test: 58.77%\n",
      "Run: 02, Epoch: 49, Loss: 1.0317, Train: 60.62%, Valid: 54.60% Test: 63.16%\n",
      "Run: 02, Epoch: 50, Loss: 1.0258, Train: 64.01%, Valid: 58.71% Test: 66.45%\n",
      "Run: 02, Epoch: 51, Loss: 0.9998, Train: 64.38%, Valid: 58.57% Test: 64.47%\n",
      "Run: 02, Epoch: 52, Loss: 1.0062, Train: 63.83%, Valid: 58.44% Test: 64.25%\n",
      "Run: 02, Epoch: 53, Loss: 0.9923, Train: 62.73%, Valid: 56.24% Test: 64.47%\n",
      "Run: 02, Epoch: 54, Loss: 1.0006, Train: 59.98%, Valid: 54.60% Test: 60.53%\n",
      "Run: 02, Epoch: 55, Loss: 0.9806, Train: 57.33%, Valid: 51.17% Test: 57.46%\n",
      "Run: 02, Epoch: 56, Loss: 0.9691, Train: 58.06%, Valid: 53.50% Test: 58.77%\n",
      "Run: 02, Epoch: 57, Loss: 0.9908, Train: 56.68%, Valid: 53.77% Test: 58.99%\n",
      "Run: 02, Epoch: 58, Loss: 0.9794, Train: 50.46%, Valid: 47.87% Test: 52.85%\n",
      "Run: 02, Epoch: 59, Loss: 1.0197, Train: 57.69%, Valid: 52.40% Test: 57.46%\n",
      "Run: 02, Epoch: 60, Loss: 0.9547, Train: 60.53%, Valid: 56.10% Test: 60.09%\n",
      "Run: 02, Epoch: 61, Loss: 0.9830, Train: 64.38%, Valid: 60.08% Test: 61.40%\n",
      "Run: 02, Epoch: 62, Loss: 1.0112, Train: 67.86%, Valid: 62.00% Test: 67.32%\n",
      "Run: 02, Epoch: 63, Loss: 0.9867, Train: 66.30%, Valid: 60.22% Test: 66.23%\n",
      "Run: 02, Epoch: 64, Loss: 0.9876, Train: 61.54%, Valid: 56.10% Test: 59.21%\n",
      "Run: 02, Epoch: 65, Loss: 0.9662, Train: 61.36%, Valid: 55.42% Test: 58.55%\n",
      "Run: 02, Epoch: 66, Loss: 0.9738, Train: 63.10%, Valid: 58.30% Test: 62.72%\n",
      "Run: 02, Epoch: 67, Loss: 0.9835, Train: 60.26%, Valid: 54.32% Test: 59.87%\n",
      "Run: 02, Epoch: 68, Loss: 0.9734, Train: 56.50%, Valid: 50.34% Test: 56.14%\n",
      "Run: 02, Epoch: 69, Loss: 0.9510, Train: 57.69%, Valid: 51.44% Test: 56.36%\n",
      "Run: 02, Epoch: 70, Loss: 0.9452, Train: 59.80%, Valid: 52.95% Test: 58.55%\n",
      "Run: 02, Epoch: 71, Loss: 0.9545, Train: 62.00%, Valid: 55.14% Test: 61.18%\n",
      "Run: 02, Epoch: 72, Loss: 0.9638, Train: 62.09%, Valid: 57.48% Test: 60.31%\n",
      "Run: 02, Epoch: 73, Loss: 0.9409, Train: 63.10%, Valid: 56.93% Test: 64.25%\n",
      "Run: 02, Epoch: 74, Loss: 0.9682, Train: 63.37%, Valid: 58.30% Test: 64.91%\n",
      "Run: 02, Epoch: 75, Loss: 0.9687, Train: 66.67%, Valid: 62.69% Test: 65.57%\n",
      "Run: 02, Epoch: 76, Loss: 0.9421, Train: 63.83%, Valid: 60.63% Test: 63.38%\n",
      "Run: 02, Epoch: 77, Loss: 0.9411, Train: 67.22%, Valid: 61.73% Test: 67.54%\n",
      "Run: 02, Epoch: 78, Loss: 0.9483, Train: 66.67%, Valid: 59.40% Test: 67.11%\n",
      "Run: 02, Epoch: 79, Loss: 0.9662, Train: 66.85%, Valid: 59.95% Test: 67.54%\n",
      "Run: 02, Epoch: 80, Loss: 0.9373, Train: 65.02%, Valid: 60.77% Test: 66.45%\n",
      "Run: 02, Epoch: 81, Loss: 0.9616, Train: 62.82%, Valid: 60.22% Test: 65.13%\n",
      "Run: 02, Epoch: 82, Loss: 0.9621, Train: 63.37%, Valid: 61.32% Test: 65.79%\n",
      "Run: 02, Epoch: 83, Loss: 0.9670, Train: 65.75%, Valid: 60.36% Test: 66.45%\n",
      "Run: 02, Epoch: 84, Loss: 0.9598, Train: 62.91%, Valid: 58.02% Test: 61.84%\n",
      "Run: 02, Epoch: 85, Loss: 0.9568, Train: 61.90%, Valid: 58.71% Test: 60.75%\n",
      "Run: 02, Epoch: 86, Loss: 0.9582, Train: 65.38%, Valid: 61.32% Test: 66.01%\n",
      "Run: 02, Epoch: 87, Loss: 0.9303, Train: 64.65%, Valid: 60.77% Test: 67.11%\n",
      "Run: 02, Epoch: 88, Loss: 0.9707, Train: 65.93%, Valid: 61.73% Test: 67.11%\n",
      "Run: 02, Epoch: 89, Loss: 0.9404, Train: 66.21%, Valid: 60.49% Test: 66.01%\n",
      "Run: 02, Epoch: 90, Loss: 0.9164, Train: 66.03%, Valid: 60.63% Test: 67.76%\n",
      "Run: 02, Epoch: 91, Loss: 0.9204, Train: 65.75%, Valid: 58.71% Test: 65.13%\n",
      "Run: 02, Epoch: 92, Loss: 0.9433, Train: 67.40%, Valid: 59.67% Test: 66.67%\n",
      "Run: 02, Epoch: 93, Loss: 0.9216, Train: 65.93%, Valid: 61.32% Test: 65.13%\n",
      "Run: 02, Epoch: 94, Loss: 0.9146, Train: 65.38%, Valid: 60.63% Test: 62.06%\n",
      "Run: 02, Epoch: 95, Loss: 0.9373, Train: 67.58%, Valid: 61.87% Test: 66.89%\n",
      "Run: 02, Epoch: 96, Loss: 0.8926, Train: 65.38%, Valid: 59.12% Test: 66.89%\n",
      "Run: 02, Epoch: 97, Loss: 0.9293, Train: 63.19%, Valid: 57.34% Test: 63.60%\n",
      "Run: 02, Epoch: 98, Loss: 0.9228, Train: 66.12%, Valid: 60.63% Test: 63.82%\n",
      "Run: 02, Epoch: 99, Loss: 0.9526, Train: 65.75%, Valid: 59.53% Test: 63.16%\n",
      "Run: 02, Epoch: 100, Loss: 0.9064, Train: 66.94%, Valid: 60.77% Test: 67.54%\n",
      "Run 02:\n",
      "Highest Train: 67.86\n",
      "Highest Valid: 62.69\n",
      "  Final Train: 66.67\n",
      "   Final Test: 65.57\n",
      "Run: 03, Epoch: 01, Loss: 1.6342, Train: 28.57%, Valid: 25.24% Test: 22.59%\n",
      "Run: 03, Epoch: 02, Loss: 1.4578, Train: 35.90%, Valid: 31.55% Test: 32.24%\n",
      "Run: 03, Epoch: 03, Loss: 1.3949, Train: 29.76%, Valid: 31.96% Test: 30.92%\n",
      "Run: 03, Epoch: 04, Loss: 1.3567, Train: 25.00%, Valid: 27.57% Test: 26.32%\n",
      "Run: 03, Epoch: 05, Loss: 1.3333, Train: 26.37%, Valid: 28.81% Test: 27.19%\n",
      "Run: 03, Epoch: 06, Loss: 1.3090, Train: 33.70%, Valid: 33.47% Test: 31.58%\n",
      "Run: 03, Epoch: 07, Loss: 1.2901, Train: 35.44%, Valid: 33.47% Test: 32.24%\n",
      "Run: 03, Epoch: 08, Loss: 1.2585, Train: 40.66%, Valid: 36.21% Test: 39.25%\n",
      "Run: 03, Epoch: 09, Loss: 1.2475, Train: 42.40%, Valid: 40.05% Test: 39.91%\n",
      "Run: 03, Epoch: 10, Loss: 1.2552, Train: 40.75%, Valid: 39.09% Test: 39.47%\n",
      "Run: 03, Epoch: 11, Loss: 1.2144, Train: 41.39%, Valid: 42.66% Test: 37.72%\n",
      "Run: 03, Epoch: 12, Loss: 1.2042, Train: 43.04%, Valid: 45.82% Test: 39.04%\n",
      "Run: 03, Epoch: 13, Loss: 1.1914, Train: 40.57%, Valid: 43.35% Test: 37.50%\n",
      "Run: 03, Epoch: 14, Loss: 1.2013, Train: 42.22%, Valid: 44.72% Test: 39.47%\n",
      "Run: 03, Epoch: 15, Loss: 1.1680, Train: 46.15%, Valid: 46.36% Test: 39.04%\n",
      "Run: 03, Epoch: 16, Loss: 1.1749, Train: 42.67%, Valid: 45.82% Test: 41.45%\n",
      "Run: 03, Epoch: 17, Loss: 1.1771, Train: 47.80%, Valid: 47.87% Test: 42.76%\n",
      "Run: 03, Epoch: 18, Loss: 1.1544, Train: 49.54%, Valid: 48.70% Test: 46.93%\n",
      "Run: 03, Epoch: 19, Loss: 1.1482, Train: 50.00%, Valid: 48.29% Test: 46.71%\n",
      "Run: 03, Epoch: 20, Loss: 1.1380, Train: 51.28%, Valid: 49.79% Test: 46.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 21, Loss: 1.1216, Train: 49.63%, Valid: 47.46% Test: 46.27%\n",
      "Run: 03, Epoch: 22, Loss: 1.1348, Train: 46.70%, Valid: 46.78% Test: 46.71%\n",
      "Run: 03, Epoch: 23, Loss: 1.1481, Train: 46.34%, Valid: 45.13% Test: 43.20%\n",
      "Run: 03, Epoch: 24, Loss: 1.1197, Train: 51.10%, Valid: 48.56% Test: 46.05%\n",
      "Run: 03, Epoch: 25, Loss: 1.1244, Train: 52.47%, Valid: 48.01% Test: 47.15%\n",
      "Run: 03, Epoch: 26, Loss: 1.1045, Train: 46.98%, Valid: 45.54% Test: 43.42%\n",
      "Run: 03, Epoch: 27, Loss: 1.0851, Train: 47.44%, Valid: 45.54% Test: 44.52%\n",
      "Run: 03, Epoch: 28, Loss: 1.0774, Train: 48.90%, Valid: 46.78% Test: 46.05%\n",
      "Run: 03, Epoch: 29, Loss: 1.0819, Train: 50.09%, Valid: 47.05% Test: 47.81%\n",
      "Run: 03, Epoch: 30, Loss: 1.0923, Train: 50.64%, Valid: 48.83% Test: 48.03%\n",
      "Run: 03, Epoch: 31, Loss: 1.0756, Train: 54.03%, Valid: 51.58% Test: 47.37%\n",
      "Run: 03, Epoch: 32, Loss: 1.0708, Train: 52.93%, Valid: 49.38% Test: 47.15%\n",
      "Run: 03, Epoch: 33, Loss: 1.0466, Train: 52.38%, Valid: 48.42% Test: 46.93%\n",
      "Run: 03, Epoch: 34, Loss: 1.0622, Train: 51.47%, Valid: 48.29% Test: 46.71%\n",
      "Run: 03, Epoch: 35, Loss: 1.0604, Train: 47.62%, Valid: 44.58% Test: 42.32%\n",
      "Run: 03, Epoch: 36, Loss: 1.0413, Train: 44.05%, Valid: 41.43% Test: 39.47%\n",
      "Run: 03, Epoch: 37, Loss: 1.0608, Train: 45.70%, Valid: 39.92% Test: 40.13%\n",
      "Run: 03, Epoch: 38, Loss: 1.0399, Train: 50.82%, Valid: 44.86% Test: 45.39%\n",
      "Run: 03, Epoch: 39, Loss: 1.0456, Train: 53.02%, Valid: 47.60% Test: 47.59%\n",
      "Run: 03, Epoch: 40, Loss: 1.0264, Train: 48.99%, Valid: 42.94% Test: 42.32%\n",
      "Run: 03, Epoch: 41, Loss: 1.0241, Train: 54.03%, Valid: 49.93% Test: 50.22%\n",
      "Run: 03, Epoch: 42, Loss: 1.0220, Train: 56.50%, Valid: 51.44% Test: 51.97%\n",
      "Run: 03, Epoch: 43, Loss: 1.0228, Train: 52.29%, Valid: 45.82% Test: 46.27%\n",
      "Run: 03, Epoch: 44, Loss: 1.0557, Train: 56.32%, Valid: 50.48% Test: 51.10%\n",
      "Run: 03, Epoch: 45, Loss: 1.0116, Train: 56.96%, Valid: 53.09% Test: 53.95%\n",
      "Run: 03, Epoch: 46, Loss: 1.0474, Train: 55.95%, Valid: 51.58% Test: 52.41%\n",
      "Run: 03, Epoch: 47, Loss: 0.9957, Train: 54.95%, Valid: 50.89% Test: 48.46%\n",
      "Run: 03, Epoch: 48, Loss: 1.0209, Train: 50.55%, Valid: 50.07% Test: 45.18%\n",
      "Run: 03, Epoch: 49, Loss: 1.0241, Train: 60.16%, Valid: 58.85% Test: 56.80%\n",
      "Run: 03, Epoch: 50, Loss: 1.0049, Train: 58.06%, Valid: 55.28% Test: 52.63%\n",
      "Run: 03, Epoch: 51, Loss: 1.0205, Train: 56.87%, Valid: 52.81% Test: 51.54%\n",
      "Run: 03, Epoch: 52, Loss: 1.0207, Train: 56.50%, Valid: 55.14% Test: 51.75%\n",
      "Run: 03, Epoch: 53, Loss: 0.9908, Train: 53.11%, Valid: 51.71% Test: 48.25%\n",
      "Run: 03, Epoch: 54, Loss: 0.9998, Train: 56.23%, Valid: 50.34% Test: 51.32%\n",
      "Run: 03, Epoch: 55, Loss: 0.9921, Train: 52.66%, Valid: 48.29% Test: 49.78%\n",
      "Run: 03, Epoch: 56, Loss: 1.0022, Train: 53.66%, Valid: 48.97% Test: 50.22%\n",
      "Run: 03, Epoch: 57, Loss: 0.9899, Train: 49.82%, Valid: 44.17% Test: 46.49%\n",
      "Run: 03, Epoch: 58, Loss: 1.0069, Train: 53.02%, Valid: 49.38% Test: 47.81%\n",
      "Run: 03, Epoch: 59, Loss: 0.9983, Train: 54.12%, Valid: 50.34% Test: 46.27%\n",
      "Run: 03, Epoch: 60, Loss: 1.0109, Train: 57.69%, Valid: 52.81% Test: 52.19%\n",
      "Run: 03, Epoch: 61, Loss: 0.9692, Train: 55.04%, Valid: 49.52% Test: 51.10%\n",
      "Run: 03, Epoch: 62, Loss: 0.9568, Train: 53.57%, Valid: 48.56% Test: 48.90%\n",
      "Run: 03, Epoch: 63, Loss: 1.0042, Train: 57.88%, Valid: 52.95% Test: 50.66%\n",
      "Run: 03, Epoch: 64, Loss: 0.9971, Train: 58.79%, Valid: 54.73% Test: 53.95%\n",
      "Run: 03, Epoch: 65, Loss: 0.9831, Train: 60.71%, Valid: 56.79% Test: 54.17%\n",
      "Run: 03, Epoch: 66, Loss: 1.0137, Train: 58.33%, Valid: 55.42% Test: 53.29%\n",
      "Run: 03, Epoch: 67, Loss: 0.9911, Train: 55.40%, Valid: 52.95% Test: 51.97%\n",
      "Run: 03, Epoch: 68, Loss: 1.0053, Train: 58.33%, Valid: 55.01% Test: 55.70%\n",
      "Run: 03, Epoch: 69, Loss: 0.9740, Train: 60.07%, Valid: 56.79% Test: 56.58%\n",
      "Run: 03, Epoch: 70, Loss: 0.9821, Train: 61.26%, Valid: 58.71% Test: 57.89%\n",
      "Run: 03, Epoch: 71, Loss: 0.9636, Train: 55.59%, Valid: 51.85% Test: 48.90%\n",
      "Run: 03, Epoch: 72, Loss: 1.0147, Train: 58.97%, Valid: 55.01% Test: 52.85%\n",
      "Run: 03, Epoch: 73, Loss: 0.9637, Train: 61.26%, Valid: 59.26% Test: 58.99%\n",
      "Run: 03, Epoch: 74, Loss: 0.9711, Train: 62.00%, Valid: 58.71% Test: 57.02%\n",
      "Run: 03, Epoch: 75, Loss: 0.9691, Train: 58.42%, Valid: 55.28% Test: 53.29%\n",
      "Run: 03, Epoch: 76, Loss: 0.9699, Train: 58.79%, Valid: 55.69% Test: 54.39%\n",
      "Run: 03, Epoch: 77, Loss: 0.9518, Train: 61.54%, Valid: 57.48% Test: 59.87%\n",
      "Run: 03, Epoch: 78, Loss: 0.9648, Train: 59.52%, Valid: 56.10% Test: 56.36%\n",
      "Run: 03, Epoch: 79, Loss: 0.9670, Train: 61.17%, Valid: 55.97% Test: 56.58%\n",
      "Run: 03, Epoch: 80, Loss: 0.9482, Train: 56.68%, Valid: 50.75% Test: 51.10%\n",
      "Run: 03, Epoch: 81, Loss: 0.9858, Train: 60.53%, Valid: 56.52% Test: 55.70%\n",
      "Run: 03, Epoch: 82, Loss: 0.9829, Train: 60.62%, Valid: 57.61% Test: 55.92%\n",
      "Run: 03, Epoch: 83, Loss: 0.9711, Train: 60.90%, Valid: 57.89% Test: 56.36%\n",
      "Run: 03, Epoch: 84, Loss: 0.9372, Train: 60.90%, Valid: 57.34% Test: 54.61%\n",
      "Run: 03, Epoch: 85, Loss: 0.9494, Train: 58.42%, Valid: 54.87% Test: 51.75%\n",
      "Run: 03, Epoch: 86, Loss: 0.9488, Train: 62.18%, Valid: 58.44% Test: 56.58%\n",
      "Run: 03, Epoch: 87, Loss: 0.9470, Train: 63.10%, Valid: 59.40% Test: 58.11%\n",
      "Run: 03, Epoch: 88, Loss: 0.9418, Train: 61.72%, Valid: 56.79% Test: 56.58%\n",
      "Run: 03, Epoch: 89, Loss: 0.9473, Train: 62.36%, Valid: 56.79% Test: 58.99%\n",
      "Run: 03, Epoch: 90, Loss: 0.9296, Train: 64.29%, Valid: 59.53% Test: 60.09%\n",
      "Run: 03, Epoch: 91, Loss: 0.9241, Train: 63.92%, Valid: 58.71% Test: 59.43%\n",
      "Run: 03, Epoch: 92, Loss: 0.9240, Train: 60.90%, Valid: 56.79% Test: 57.02%\n",
      "Run: 03, Epoch: 93, Loss: 0.9237, Train: 57.60%, Valid: 53.09% Test: 54.39%\n",
      "Run: 03, Epoch: 94, Loss: 0.9445, Train: 60.26%, Valid: 54.73% Test: 57.89%\n",
      "Run: 03, Epoch: 95, Loss: 0.9291, Train: 62.18%, Valid: 57.20% Test: 59.87%\n",
      "Run: 03, Epoch: 96, Loss: 0.9230, Train: 64.38%, Valid: 61.18% Test: 60.09%\n",
      "Run: 03, Epoch: 97, Loss: 0.9376, Train: 60.62%, Valid: 56.79% Test: 55.48%\n",
      "Run: 03, Epoch: 98, Loss: 0.9630, Train: 64.65%, Valid: 61.45% Test: 62.28%\n",
      "Run: 03, Epoch: 99, Loss: 0.9047, Train: 62.91%, Valid: 61.32% Test: 61.84%\n",
      "Run: 03, Epoch: 100, Loss: 0.9317, Train: 59.89%, Valid: 59.81% Test: 58.99%\n",
      "Run 03:\n",
      "Highest Train: 64.65\n",
      "Highest Valid: 61.45\n",
      "  Final Train: 64.65\n",
      "   Final Test: 62.28\n",
      "Run: 04, Epoch: 01, Loss: 1.6547, Train: 23.63%, Valid: 23.18% Test: 21.93%\n",
      "Run: 04, Epoch: 02, Loss: 1.4730, Train: 23.44%, Valid: 22.91% Test: 21.49%\n",
      "Run: 04, Epoch: 03, Loss: 1.4144, Train: 23.44%, Valid: 22.91% Test: 21.49%\n",
      "Run: 04, Epoch: 04, Loss: 1.3754, Train: 23.44%, Valid: 22.91% Test: 21.71%\n",
      "Run: 04, Epoch: 05, Loss: 1.3464, Train: 23.53%, Valid: 23.05% Test: 21.49%\n",
      "Run: 04, Epoch: 06, Loss: 1.3168, Train: 24.08%, Valid: 23.18% Test: 21.71%\n",
      "Run: 04, Epoch: 07, Loss: 1.2931, Train: 30.86%, Valid: 29.77% Test: 28.07%\n",
      "Run: 04, Epoch: 08, Loss: 1.2929, Train: 35.71%, Valid: 33.74% Test: 32.46%\n",
      "Run: 04, Epoch: 09, Loss: 1.2655, Train: 31.50%, Valid: 29.22% Test: 27.41%\n",
      "Run: 04, Epoch: 10, Loss: 1.2562, Train: 35.71%, Valid: 33.33% Test: 33.55%\n",
      "Run: 04, Epoch: 11, Loss: 1.2441, Train: 43.86%, Valid: 41.15% Test: 39.69%\n",
      "Run: 04, Epoch: 12, Loss: 1.2276, Train: 47.07%, Valid: 45.40% Test: 44.08%\n",
      "Run: 04, Epoch: 13, Loss: 1.2262, Train: 46.43%, Valid: 44.58% Test: 45.83%\n",
      "Run: 04, Epoch: 14, Loss: 1.2193, Train: 43.41%, Valid: 39.78% Test: 42.32%\n",
      "Run: 04, Epoch: 15, Loss: 1.2007, Train: 47.80%, Valid: 44.99% Test: 48.03%\n",
      "Run: 04, Epoch: 16, Loss: 1.1724, Train: 46.70%, Valid: 47.05% Test: 46.71%\n",
      "Run: 04, Epoch: 17, Loss: 1.2079, Train: 46.89%, Valid: 47.33% Test: 48.46%\n",
      "Run: 04, Epoch: 18, Loss: 1.1738, Train: 45.51%, Valid: 45.82% Test: 47.37%\n",
      "Run: 04, Epoch: 19, Loss: 1.1582, Train: 44.41%, Valid: 43.76% Test: 45.83%\n",
      "Run: 04, Epoch: 20, Loss: 1.1456, Train: 45.05%, Valid: 43.07% Test: 44.74%\n",
      "Run: 04, Epoch: 21, Loss: 1.1375, Train: 46.34%, Valid: 46.36% Test: 48.03%\n",
      "Run: 04, Epoch: 22, Loss: 1.1076, Train: 48.08%, Valid: 47.05% Test: 48.68%\n",
      "Run: 04, Epoch: 23, Loss: 1.1199, Train: 46.70%, Valid: 43.76% Test: 46.71%\n",
      "Run: 04, Epoch: 24, Loss: 1.1343, Train: 47.53%, Valid: 43.90% Test: 47.37%\n",
      "Run: 04, Epoch: 25, Loss: 1.1242, Train: 49.73%, Valid: 49.79% Test: 48.46%\n",
      "Run: 04, Epoch: 26, Loss: 1.1286, Train: 53.21%, Valid: 49.93% Test: 53.29%\n",
      "Run: 04, Epoch: 27, Loss: 1.0887, Train: 54.67%, Valid: 53.22% Test: 52.19%\n",
      "Run: 04, Epoch: 28, Loss: 1.0846, Train: 51.37%, Valid: 47.05% Test: 51.32%\n",
      "Run: 04, Epoch: 29, Loss: 1.0705, Train: 50.09%, Valid: 46.23% Test: 47.81%\n",
      "Run: 04, Epoch: 30, Loss: 1.1113, Train: 52.66%, Valid: 49.38% Test: 50.22%\n",
      "Run: 04, Epoch: 31, Loss: 1.0704, Train: 55.68%, Valid: 53.36% Test: 52.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 32, Loss: 1.0641, Train: 58.15%, Valid: 56.38% Test: 53.95%\n",
      "Run: 04, Epoch: 33, Loss: 1.0670, Train: 59.16%, Valid: 56.24% Test: 54.61%\n",
      "Run: 04, Epoch: 34, Loss: 1.0795, Train: 57.33%, Valid: 56.10% Test: 50.66%\n",
      "Run: 04, Epoch: 35, Loss: 1.0619, Train: 52.56%, Valid: 49.79% Test: 49.78%\n",
      "Run: 04, Epoch: 36, Loss: 1.0590, Train: 56.41%, Valid: 54.18% Test: 51.97%\n",
      "Run: 04, Epoch: 37, Loss: 1.0374, Train: 54.58%, Valid: 53.91% Test: 52.41%\n",
      "Run: 04, Epoch: 38, Loss: 1.0726, Train: 58.70%, Valid: 59.26% Test: 56.36%\n",
      "Run: 04, Epoch: 39, Loss: 1.0793, Train: 55.13%, Valid: 52.13% Test: 54.61%\n",
      "Run: 04, Epoch: 40, Loss: 1.0323, Train: 56.59%, Valid: 54.73% Test: 56.14%\n",
      "Run: 04, Epoch: 41, Loss: 1.0495, Train: 62.18%, Valid: 58.71% Test: 57.24%\n",
      "Run: 04, Epoch: 42, Loss: 1.0242, Train: 60.16%, Valid: 60.08% Test: 57.46%\n",
      "Run: 04, Epoch: 43, Loss: 1.0183, Train: 60.26%, Valid: 58.44% Test: 55.04%\n",
      "Run: 04, Epoch: 44, Loss: 1.0335, Train: 61.63%, Valid: 60.91% Test: 58.55%\n",
      "Run: 04, Epoch: 45, Loss: 1.0022, Train: 59.89%, Valid: 59.26% Test: 57.24%\n",
      "Run: 04, Epoch: 46, Loss: 1.0254, Train: 59.34%, Valid: 58.02% Test: 57.02%\n",
      "Run: 04, Epoch: 47, Loss: 1.0338, Train: 54.85%, Valid: 52.81% Test: 53.29%\n",
      "Run: 04, Epoch: 48, Loss: 1.0057, Train: 59.62%, Valid: 56.38% Test: 57.24%\n",
      "Run: 04, Epoch: 49, Loss: 1.0041, Train: 60.35%, Valid: 57.48% Test: 55.26%\n",
      "Run: 04, Epoch: 50, Loss: 1.0006, Train: 61.08%, Valid: 59.53% Test: 56.14%\n",
      "Run: 04, Epoch: 51, Loss: 1.0108, Train: 60.71%, Valid: 60.49% Test: 55.92%\n",
      "Run: 04, Epoch: 52, Loss: 1.0012, Train: 60.90%, Valid: 59.67% Test: 57.89%\n",
      "Run: 04, Epoch: 53, Loss: 0.9903, Train: 59.62%, Valid: 58.44% Test: 58.33%\n",
      "Run: 04, Epoch: 54, Loss: 0.9861, Train: 58.88%, Valid: 60.22% Test: 58.11%\n",
      "Run: 04, Epoch: 55, Loss: 0.9843, Train: 60.16%, Valid: 59.26% Test: 57.89%\n",
      "Run: 04, Epoch: 56, Loss: 1.0017, Train: 59.34%, Valid: 56.65% Test: 58.11%\n",
      "Run: 04, Epoch: 57, Loss: 0.9788, Train: 59.43%, Valid: 57.06% Test: 57.89%\n",
      "Run: 04, Epoch: 58, Loss: 0.9927, Train: 62.09%, Valid: 59.26% Test: 58.77%\n",
      "Run: 04, Epoch: 59, Loss: 0.9715, Train: 63.19%, Valid: 59.95% Test: 58.99%\n",
      "Run: 04, Epoch: 60, Loss: 0.9808, Train: 62.18%, Valid: 58.16% Test: 57.89%\n",
      "Run: 04, Epoch: 61, Loss: 0.9582, Train: 61.81%, Valid: 56.93% Test: 56.58%\n",
      "Run: 04, Epoch: 62, Loss: 0.9860, Train: 61.63%, Valid: 57.75% Test: 57.89%\n",
      "Run: 04, Epoch: 63, Loss: 0.9688, Train: 50.46%, Valid: 47.46% Test: 50.00%\n",
      "Run: 04, Epoch: 64, Loss: 0.9950, Train: 58.42%, Valid: 54.73% Test: 55.48%\n",
      "Run: 04, Epoch: 65, Loss: 0.9777, Train: 59.62%, Valid: 54.87% Test: 57.89%\n",
      "Run: 04, Epoch: 66, Loss: 0.9741, Train: 58.24%, Valid: 52.95% Test: 58.55%\n",
      "Run: 04, Epoch: 67, Loss: 0.9883, Train: 61.17%, Valid: 58.71% Test: 57.68%\n",
      "Run: 04, Epoch: 68, Loss: 0.9727, Train: 53.94%, Valid: 51.58% Test: 51.97%\n",
      "Run: 04, Epoch: 69, Loss: 0.9741, Train: 55.22%, Valid: 52.67% Test: 54.39%\n",
      "Run: 04, Epoch: 70, Loss: 0.9895, Train: 56.14%, Valid: 55.42% Test: 56.36%\n",
      "Run: 04, Epoch: 71, Loss: 0.9543, Train: 62.09%, Valid: 59.12% Test: 58.77%\n",
      "Run: 04, Epoch: 72, Loss: 0.9439, Train: 61.45%, Valid: 55.69% Test: 60.75%\n",
      "Run: 04, Epoch: 73, Loss: 0.9612, Train: 60.71%, Valid: 55.01% Test: 59.65%\n",
      "Run: 04, Epoch: 74, Loss: 0.9714, Train: 59.89%, Valid: 56.24% Test: 58.55%\n",
      "Run: 04, Epoch: 75, Loss: 0.9343, Train: 59.98%, Valid: 57.75% Test: 57.46%\n",
      "Run: 04, Epoch: 76, Loss: 0.9494, Train: 62.73%, Valid: 59.95% Test: 58.77%\n",
      "Run: 04, Epoch: 77, Loss: 0.9542, Train: 62.36%, Valid: 58.98% Test: 58.33%\n",
      "Run: 04, Epoch: 78, Loss: 0.9507, Train: 58.88%, Valid: 55.83% Test: 57.68%\n",
      "Run: 04, Epoch: 79, Loss: 0.9564, Train: 58.88%, Valid: 54.18% Test: 57.46%\n",
      "Run: 04, Epoch: 80, Loss: 0.9570, Train: 61.54%, Valid: 57.34% Test: 59.43%\n",
      "Run: 04, Epoch: 81, Loss: 0.9304, Train: 62.45%, Valid: 58.44% Test: 58.33%\n",
      "Run: 04, Epoch: 82, Loss: 0.9231, Train: 64.93%, Valid: 60.77% Test: 59.65%\n",
      "Run: 04, Epoch: 83, Loss: 0.9225, Train: 65.84%, Valid: 60.36% Test: 59.21%\n",
      "Run: 04, Epoch: 84, Loss: 0.9089, Train: 62.45%, Valid: 57.61% Test: 58.11%\n",
      "Run: 04, Epoch: 85, Loss: 0.9488, Train: 63.00%, Valid: 58.57% Test: 59.87%\n",
      "Run: 04, Epoch: 86, Loss: 0.9266, Train: 60.62%, Valid: 56.24% Test: 56.80%\n",
      "Run: 04, Epoch: 87, Loss: 0.8878, Train: 64.84%, Valid: 59.40% Test: 58.99%\n",
      "Run: 04, Epoch: 88, Loss: 0.9303, Train: 63.92%, Valid: 60.77% Test: 58.77%\n",
      "Run: 04, Epoch: 89, Loss: 0.9055, Train: 60.53%, Valid: 57.34% Test: 55.48%\n",
      "Run: 04, Epoch: 90, Loss: 0.9325, Train: 63.92%, Valid: 60.08% Test: 59.21%\n",
      "Run: 04, Epoch: 91, Loss: 0.9130, Train: 64.93%, Valid: 62.14% Test: 61.40%\n",
      "Run: 04, Epoch: 92, Loss: 0.9197, Train: 61.54%, Valid: 56.65% Test: 55.26%\n",
      "Run: 04, Epoch: 93, Loss: 0.9267, Train: 65.38%, Valid: 62.28% Test: 59.21%\n",
      "Run: 04, Epoch: 94, Loss: 0.9160, Train: 63.28%, Valid: 57.48% Test: 60.09%\n",
      "Run: 04, Epoch: 95, Loss: 0.9162, Train: 60.53%, Valid: 55.01% Test: 59.43%\n",
      "Run: 04, Epoch: 96, Loss: 0.8911, Train: 62.00%, Valid: 57.89% Test: 57.02%\n",
      "Run: 04, Epoch: 97, Loss: 0.9366, Train: 64.84%, Valid: 60.36% Test: 59.65%\n",
      "Run: 04, Epoch: 98, Loss: 0.9106, Train: 66.12%, Valid: 61.59% Test: 58.11%\n",
      "Run: 04, Epoch: 99, Loss: 0.9005, Train: 65.93%, Valid: 62.28% Test: 59.21%\n",
      "Run: 04, Epoch: 100, Loss: 0.8807, Train: 66.39%, Valid: 64.47% Test: 58.77%\n",
      "Run 04:\n",
      "Highest Train: 66.39\n",
      "Highest Valid: 64.47\n",
      "  Final Train: 66.39\n",
      "   Final Test: 58.77\n",
      "Run: 05, Epoch: 01, Loss: 1.6700, Train: 21.61%, Valid: 24.55% Test: 23.25%\n",
      "Run: 05, Epoch: 02, Loss: 1.4753, Train: 21.61%, Valid: 24.55% Test: 23.25%\n",
      "Run: 05, Epoch: 03, Loss: 1.4404, Train: 22.53%, Valid: 25.24% Test: 24.12%\n",
      "Run: 05, Epoch: 04, Loss: 1.4012, Train: 26.28%, Valid: 28.53% Test: 27.19%\n",
      "Run: 05, Epoch: 05, Loss: 1.3788, Train: 24.73%, Valid: 27.43% Test: 27.41%\n",
      "Run: 05, Epoch: 06, Loss: 1.3605, Train: 31.32%, Valid: 32.92% Test: 29.17%\n",
      "Run: 05, Epoch: 07, Loss: 1.3427, Train: 35.99%, Valid: 34.57% Test: 35.75%\n",
      "Run: 05, Epoch: 08, Loss: 1.3013, Train: 32.42%, Valid: 29.90% Test: 31.36%\n",
      "Run: 05, Epoch: 09, Loss: 1.2866, Train: 32.60%, Valid: 29.77% Test: 32.46%\n",
      "Run: 05, Epoch: 10, Loss: 1.2863, Train: 37.18%, Valid: 33.88% Test: 35.53%\n",
      "Run: 05, Epoch: 11, Loss: 1.2448, Train: 38.46%, Valid: 34.98% Test: 35.75%\n",
      "Run: 05, Epoch: 12, Loss: 1.2258, Train: 37.82%, Valid: 34.02% Test: 35.31%\n",
      "Run: 05, Epoch: 13, Loss: 1.2101, Train: 37.82%, Valid: 35.53% Test: 35.75%\n",
      "Run: 05, Epoch: 14, Loss: 1.1821, Train: 39.38%, Valid: 38.82% Test: 40.13%\n",
      "Run: 05, Epoch: 15, Loss: 1.1861, Train: 45.70%, Valid: 45.68% Test: 46.71%\n",
      "Run: 05, Epoch: 16, Loss: 1.1742, Train: 44.41%, Valid: 42.94% Test: 43.86%\n",
      "Run: 05, Epoch: 17, Loss: 1.1732, Train: 46.61%, Valid: 48.15% Test: 47.15%\n",
      "Run: 05, Epoch: 18, Loss: 1.1588, Train: 50.00%, Valid: 48.70% Test: 48.90%\n",
      "Run: 05, Epoch: 19, Loss: 1.1290, Train: 51.28%, Valid: 50.07% Test: 51.10%\n",
      "Run: 05, Epoch: 20, Loss: 1.1273, Train: 49.08%, Valid: 45.68% Test: 47.15%\n",
      "Run: 05, Epoch: 21, Loss: 1.1167, Train: 46.61%, Valid: 41.15% Test: 45.83%\n",
      "Run: 05, Epoch: 22, Loss: 1.1155, Train: 52.66%, Valid: 49.79% Test: 53.95%\n",
      "Run: 05, Epoch: 23, Loss: 1.1058, Train: 52.01%, Valid: 48.70% Test: 51.75%\n",
      "Run: 05, Epoch: 24, Loss: 1.0878, Train: 50.92%, Valid: 46.50% Test: 49.78%\n",
      "Run: 05, Epoch: 25, Loss: 1.0883, Train: 50.64%, Valid: 45.54% Test: 49.34%\n",
      "Run: 05, Epoch: 26, Loss: 1.0917, Train: 51.37%, Valid: 49.11% Test: 52.63%\n",
      "Run: 05, Epoch: 27, Loss: 1.0679, Train: 54.12%, Valid: 52.54% Test: 56.14%\n",
      "Run: 05, Epoch: 28, Loss: 1.0761, Train: 52.66%, Valid: 50.34% Test: 53.29%\n",
      "Run: 05, Epoch: 29, Loss: 1.1035, Train: 56.04%, Valid: 55.83% Test: 56.36%\n",
      "Run: 05, Epoch: 30, Loss: 1.0667, Train: 55.13%, Valid: 55.83% Test: 56.14%\n",
      "Run: 05, Epoch: 31, Loss: 1.0779, Train: 56.04%, Valid: 57.48% Test: 60.09%\n",
      "Run: 05, Epoch: 32, Loss: 1.0871, Train: 56.59%, Valid: 57.20% Test: 58.33%\n",
      "Run: 05, Epoch: 33, Loss: 1.0732, Train: 58.61%, Valid: 56.24% Test: 57.02%\n",
      "Run: 05, Epoch: 34, Loss: 1.0597, Train: 54.12%, Valid: 51.99% Test: 53.95%\n",
      "Run: 05, Epoch: 35, Loss: 1.0675, Train: 55.86%, Valid: 55.01% Test: 55.70%\n",
      "Run: 05, Epoch: 36, Loss: 1.0242, Train: 55.22%, Valid: 52.26% Test: 53.95%\n",
      "Run: 05, Epoch: 37, Loss: 1.0734, Train: 58.33%, Valid: 55.69% Test: 57.02%\n",
      "Run: 05, Epoch: 38, Loss: 1.0341, Train: 56.96%, Valid: 56.24% Test: 58.11%\n",
      "Run: 05, Epoch: 39, Loss: 1.0520, Train: 53.11%, Valid: 57.06% Test: 57.46%\n",
      "Run: 05, Epoch: 40, Loss: 1.0775, Train: 55.59%, Valid: 55.42% Test: 59.21%\n",
      "Run: 05, Epoch: 41, Loss: 1.0481, Train: 58.52%, Valid: 57.61% Test: 60.75%\n",
      "Run: 05, Epoch: 42, Loss: 1.0393, Train: 59.43%, Valid: 56.79% Test: 58.33%\n",
      "Run: 05, Epoch: 43, Loss: 1.0367, Train: 54.95%, Valid: 51.30% Test: 52.85%\n",
      "Run: 05, Epoch: 44, Loss: 1.0270, Train: 59.80%, Valid: 56.52% Test: 57.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 45, Loss: 1.0254, Train: 59.43%, Valid: 56.79% Test: 58.11%\n",
      "Run: 05, Epoch: 46, Loss: 1.0283, Train: 59.34%, Valid: 59.26% Test: 59.43%\n",
      "Run: 05, Epoch: 47, Loss: 1.0321, Train: 61.45%, Valid: 59.53% Test: 60.53%\n",
      "Run: 05, Epoch: 48, Loss: 1.0118, Train: 62.45%, Valid: 61.87% Test: 61.84%\n",
      "Run: 05, Epoch: 49, Loss: 1.0243, Train: 60.62%, Valid: 58.71% Test: 59.43%\n",
      "Run: 05, Epoch: 50, Loss: 1.0166, Train: 58.52%, Valid: 57.48% Test: 58.33%\n",
      "Run: 05, Epoch: 51, Loss: 1.0064, Train: 60.16%, Valid: 60.08% Test: 61.18%\n",
      "Run: 05, Epoch: 52, Loss: 1.0236, Train: 60.07%, Valid: 59.81% Test: 61.40%\n",
      "Run: 05, Epoch: 53, Loss: 1.0027, Train: 59.71%, Valid: 58.98% Test: 60.53%\n",
      "Run: 05, Epoch: 54, Loss: 1.0245, Train: 61.17%, Valid: 60.91% Test: 62.50%\n",
      "Run: 05, Epoch: 55, Loss: 1.0012, Train: 61.17%, Valid: 59.53% Test: 61.84%\n",
      "Run: 05, Epoch: 56, Loss: 0.9906, Train: 58.97%, Valid: 55.28% Test: 56.36%\n",
      "Run: 05, Epoch: 57, Loss: 1.0098, Train: 59.43%, Valid: 55.97% Test: 57.68%\n",
      "Run: 05, Epoch: 58, Loss: 1.0229, Train: 61.45%, Valid: 59.26% Test: 60.09%\n",
      "Run: 05, Epoch: 59, Loss: 0.9906, Train: 59.25%, Valid: 57.20% Test: 59.87%\n",
      "Run: 05, Epoch: 60, Loss: 0.9865, Train: 57.78%, Valid: 55.97% Test: 58.55%\n",
      "Run: 05, Epoch: 61, Loss: 0.9960, Train: 58.52%, Valid: 58.57% Test: 60.53%\n",
      "Run: 05, Epoch: 62, Loss: 0.9673, Train: 57.78%, Valid: 55.83% Test: 57.24%\n",
      "Run: 05, Epoch: 63, Loss: 0.9870, Train: 56.50%, Valid: 54.18% Test: 56.36%\n",
      "Run: 05, Epoch: 64, Loss: 0.9687, Train: 58.88%, Valid: 58.85% Test: 58.99%\n",
      "Run: 05, Epoch: 65, Loss: 0.9901, Train: 57.33%, Valid: 59.67% Test: 59.87%\n",
      "Run: 05, Epoch: 66, Loss: 0.9575, Train: 58.61%, Valid: 59.12% Test: 61.62%\n",
      "Run: 05, Epoch: 67, Loss: 0.9510, Train: 58.79%, Valid: 60.22% Test: 61.62%\n",
      "Run: 05, Epoch: 68, Loss: 0.9740, Train: 60.90%, Valid: 63.79% Test: 66.23%\n",
      "Run: 05, Epoch: 69, Loss: 0.9878, Train: 60.62%, Valid: 62.00% Test: 63.82%\n",
      "Run: 05, Epoch: 70, Loss: 0.9682, Train: 60.99%, Valid: 60.36% Test: 60.96%\n",
      "Run: 05, Epoch: 71, Loss: 0.9542, Train: 63.28%, Valid: 62.96% Test: 64.25%\n",
      "Run: 05, Epoch: 72, Loss: 0.9623, Train: 62.91%, Valid: 65.71% Test: 67.11%\n",
      "Run: 05, Epoch: 73, Loss: 0.9537, Train: 61.08%, Valid: 63.37% Test: 64.91%\n",
      "Run: 05, Epoch: 74, Loss: 0.9633, Train: 62.73%, Valid: 61.73% Test: 63.16%\n",
      "Run: 05, Epoch: 75, Loss: 0.9720, Train: 59.71%, Valid: 61.04% Test: 61.84%\n",
      "Run: 05, Epoch: 76, Loss: 0.9859, Train: 62.00%, Valid: 62.83% Test: 63.38%\n",
      "Run: 05, Epoch: 77, Loss: 0.9381, Train: 63.00%, Valid: 64.06% Test: 66.45%\n",
      "Run: 05, Epoch: 78, Loss: 0.9541, Train: 63.00%, Valid: 61.59% Test: 63.60%\n",
      "Run: 05, Epoch: 79, Loss: 0.9480, Train: 60.53%, Valid: 59.40% Test: 61.84%\n",
      "Run: 05, Epoch: 80, Loss: 0.9398, Train: 60.71%, Valid: 60.63% Test: 61.18%\n",
      "Run: 05, Epoch: 81, Loss: 0.9337, Train: 61.08%, Valid: 62.28% Test: 62.06%\n",
      "Run: 05, Epoch: 82, Loss: 0.9492, Train: 60.44%, Valid: 62.83% Test: 63.16%\n",
      "Run: 05, Epoch: 83, Loss: 0.9402, Train: 59.07%, Valid: 62.83% Test: 63.38%\n",
      "Run: 05, Epoch: 84, Loss: 0.9509, Train: 61.45%, Valid: 63.92% Test: 63.82%\n",
      "Run: 05, Epoch: 85, Loss: 0.9369, Train: 64.38%, Valid: 65.71% Test: 67.11%\n",
      "Run: 05, Epoch: 86, Loss: 0.9410, Train: 65.38%, Valid: 65.43% Test: 65.13%\n",
      "Run: 05, Epoch: 87, Loss: 0.9413, Train: 63.19%, Valid: 63.79% Test: 64.91%\n",
      "Run: 05, Epoch: 88, Loss: 0.9379, Train: 62.64%, Valid: 63.24% Test: 66.23%\n",
      "Run: 05, Epoch: 89, Loss: 0.9409, Train: 65.84%, Valid: 67.35% Test: 67.32%\n",
      "Run: 05, Epoch: 90, Loss: 0.9521, Train: 62.64%, Valid: 64.75% Test: 66.01%\n",
      "Run: 05, Epoch: 91, Loss: 0.9747, Train: 63.55%, Valid: 65.57% Test: 66.45%\n",
      "Run: 05, Epoch: 92, Loss: 0.9394, Train: 62.64%, Valid: 63.10% Test: 64.47%\n",
      "Run: 05, Epoch: 93, Loss: 0.9662, Train: 58.52%, Valid: 56.52% Test: 58.77%\n",
      "Run: 05, Epoch: 94, Loss: 0.9499, Train: 57.60%, Valid: 55.69% Test: 58.55%\n",
      "Run: 05, Epoch: 95, Loss: 0.9473, Train: 59.98%, Valid: 58.02% Test: 60.53%\n",
      "Run: 05, Epoch: 96, Loss: 0.9506, Train: 62.73%, Valid: 62.41% Test: 65.79%\n",
      "Run: 05, Epoch: 97, Loss: 0.9379, Train: 61.45%, Valid: 60.63% Test: 66.01%\n",
      "Run: 05, Epoch: 98, Loss: 0.9906, Train: 63.46%, Valid: 63.51% Test: 65.13%\n",
      "Run: 05, Epoch: 99, Loss: 0.9596, Train: 64.10%, Valid: 62.55% Test: 66.67%\n",
      "Run: 05, Epoch: 100, Loss: 0.9432, Train: 63.28%, Valid: 63.65% Test: 65.57%\n",
      "Run 05:\n",
      "Highest Train: 65.84\n",
      "Highest Valid: 67.35\n",
      "  Final Train: 65.84\n",
      "   Final Test: 67.32\n",
      "Run: 06, Epoch: 01, Loss: 1.6395, Train: 21.25%, Valid: 19.48% Test: 17.32%\n",
      "Run: 06, Epoch: 02, Loss: 1.4907, Train: 21.79%, Valid: 23.05% Test: 25.22%\n",
      "Run: 06, Epoch: 03, Loss: 1.4228, Train: 21.89%, Valid: 23.32% Test: 25.22%\n",
      "Run: 06, Epoch: 04, Loss: 1.3626, Train: 27.93%, Valid: 29.22% Test: 32.46%\n",
      "Run: 06, Epoch: 05, Loss: 1.3420, Train: 38.00%, Valid: 38.41% Test: 41.67%\n",
      "Run: 06, Epoch: 06, Loss: 1.3220, Train: 40.38%, Valid: 41.70% Test: 42.98%\n",
      "Run: 06, Epoch: 07, Loss: 1.3195, Train: 37.55%, Valid: 37.86% Test: 38.38%\n",
      "Run: 06, Epoch: 08, Loss: 1.2872, Train: 39.74%, Valid: 38.55% Test: 37.50%\n",
      "Run: 06, Epoch: 09, Loss: 1.2578, Train: 43.68%, Valid: 43.76% Test: 44.08%\n",
      "Run: 06, Epoch: 10, Loss: 1.2376, Train: 38.64%, Valid: 40.88% Test: 42.11%\n",
      "Run: 06, Epoch: 11, Loss: 1.2262, Train: 40.66%, Valid: 42.94% Test: 42.76%\n",
      "Run: 06, Epoch: 12, Loss: 1.2062, Train: 43.13%, Valid: 44.86% Test: 43.42%\n",
      "Run: 06, Epoch: 13, Loss: 1.1934, Train: 45.05%, Valid: 47.33% Test: 44.52%\n",
      "Run: 06, Epoch: 14, Loss: 1.1902, Train: 40.84%, Valid: 41.02% Test: 41.01%\n",
      "Run: 06, Epoch: 15, Loss: 1.1854, Train: 43.86%, Valid: 41.56% Test: 41.01%\n",
      "Run: 06, Epoch: 16, Loss: 1.1673, Train: 46.61%, Valid: 45.82% Test: 44.74%\n",
      "Run: 06, Epoch: 17, Loss: 1.1687, Train: 46.43%, Valid: 46.36% Test: 45.18%\n",
      "Run: 06, Epoch: 18, Loss: 1.1400, Train: 45.33%, Valid: 45.13% Test: 44.96%\n",
      "Run: 06, Epoch: 19, Loss: 1.1354, Train: 46.70%, Valid: 48.29% Test: 46.27%\n",
      "Run: 06, Epoch: 20, Loss: 1.1275, Train: 47.07%, Valid: 45.95% Test: 44.96%\n",
      "Run: 06, Epoch: 21, Loss: 1.1095, Train: 48.26%, Valid: 48.15% Test: 46.27%\n",
      "Run: 06, Epoch: 22, Loss: 1.1191, Train: 50.64%, Valid: 50.48% Test: 49.78%\n",
      "Run: 06, Epoch: 23, Loss: 1.0993, Train: 46.52%, Valid: 48.42% Test: 47.37%\n",
      "Run: 06, Epoch: 24, Loss: 1.1045, Train: 47.71%, Valid: 49.25% Test: 47.81%\n",
      "Run: 06, Epoch: 25, Loss: 1.0872, Train: 52.01%, Valid: 51.99% Test: 51.10%\n",
      "Run: 06, Epoch: 26, Loss: 1.0847, Train: 49.82%, Valid: 48.70% Test: 47.81%\n",
      "Run: 06, Epoch: 27, Loss: 1.0999, Train: 56.14%, Valid: 55.28% Test: 54.61%\n",
      "Run: 06, Epoch: 28, Loss: 1.0653, Train: 53.39%, Valid: 53.09% Test: 52.85%\n",
      "Run: 06, Epoch: 29, Loss: 1.0788, Train: 55.86%, Valid: 56.52% Test: 55.04%\n",
      "Run: 06, Epoch: 30, Loss: 1.0576, Train: 54.49%, Valid: 54.73% Test: 53.29%\n",
      "Run: 06, Epoch: 31, Loss: 1.0741, Train: 55.31%, Valid: 55.83% Test: 54.39%\n",
      "Run: 06, Epoch: 32, Loss: 1.0532, Train: 55.31%, Valid: 55.56% Test: 53.95%\n",
      "Run: 06, Epoch: 33, Loss: 1.0565, Train: 54.58%, Valid: 56.24% Test: 55.26%\n",
      "Run: 06, Epoch: 34, Loss: 1.0478, Train: 54.49%, Valid: 54.46% Test: 53.07%\n",
      "Run: 06, Epoch: 35, Loss: 1.0348, Train: 52.93%, Valid: 52.13% Test: 52.85%\n",
      "Run: 06, Epoch: 36, Loss: 1.0296, Train: 55.86%, Valid: 56.24% Test: 55.04%\n",
      "Run: 06, Epoch: 37, Loss: 1.0168, Train: 56.68%, Valid: 56.38% Test: 56.14%\n",
      "Run: 06, Epoch: 38, Loss: 1.0254, Train: 56.87%, Valid: 57.06% Test: 57.02%\n",
      "Run: 06, Epoch: 39, Loss: 0.9959, Train: 54.12%, Valid: 52.81% Test: 52.19%\n",
      "Run: 06, Epoch: 40, Loss: 1.0147, Train: 57.78%, Valid: 57.75% Test: 55.92%\n",
      "Run: 06, Epoch: 41, Loss: 1.0405, Train: 58.24%, Valid: 57.06% Test: 55.70%\n",
      "Run: 06, Epoch: 42, Loss: 1.0171, Train: 59.34%, Valid: 58.98% Test: 57.02%\n",
      "Run: 06, Epoch: 43, Loss: 1.0083, Train: 56.96%, Valid: 58.02% Test: 56.58%\n",
      "Run: 06, Epoch: 44, Loss: 0.9829, Train: 59.07%, Valid: 59.40% Test: 57.46%\n",
      "Run: 06, Epoch: 45, Loss: 1.0097, Train: 60.90%, Valid: 59.12% Test: 55.70%\n",
      "Run: 06, Epoch: 46, Loss: 1.0165, Train: 61.90%, Valid: 63.10% Test: 58.77%\n",
      "Run: 06, Epoch: 47, Loss: 1.0028, Train: 63.10%, Valid: 64.06% Test: 59.21%\n",
      "Run: 06, Epoch: 48, Loss: 0.9923, Train: 62.55%, Valid: 61.45% Test: 57.46%\n",
      "Run: 06, Epoch: 49, Loss: 1.0070, Train: 62.45%, Valid: 61.59% Test: 57.24%\n",
      "Run: 06, Epoch: 50, Loss: 0.9704, Train: 63.10%, Valid: 61.87% Test: 58.55%\n",
      "Run: 06, Epoch: 51, Loss: 0.9951, Train: 63.19%, Valid: 62.00% Test: 58.99%\n",
      "Run: 06, Epoch: 52, Loss: 0.9842, Train: 62.91%, Valid: 56.93% Test: 57.46%\n",
      "Run: 06, Epoch: 53, Loss: 0.9755, Train: 59.52%, Valid: 56.65% Test: 55.70%\n",
      "Run: 06, Epoch: 54, Loss: 0.9767, Train: 59.07%, Valid: 55.97% Test: 55.26%\n",
      "Run: 06, Epoch: 55, Loss: 0.9655, Train: 56.04%, Valid: 53.09% Test: 51.75%\n",
      "Run: 06, Epoch: 56, Loss: 0.9757, Train: 60.81%, Valid: 59.81% Test: 58.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 57, Loss: 0.9695, Train: 62.64%, Valid: 59.81% Test: 59.87%\n",
      "Run: 06, Epoch: 58, Loss: 0.9700, Train: 56.87%, Valid: 55.01% Test: 53.73%\n",
      "Run: 06, Epoch: 59, Loss: 1.0071, Train: 57.60%, Valid: 56.93% Test: 57.46%\n",
      "Run: 06, Epoch: 60, Loss: 0.9686, Train: 56.14%, Valid: 56.38% Test: 56.80%\n",
      "Run: 06, Epoch: 61, Loss: 0.9918, Train: 54.58%, Valid: 54.60% Test: 55.92%\n",
      "Run: 06, Epoch: 62, Loss: 0.9554, Train: 56.32%, Valid: 53.50% Test: 55.70%\n",
      "Run: 06, Epoch: 63, Loss: 0.9883, Train: 58.97%, Valid: 55.42% Test: 58.11%\n",
      "Run: 06, Epoch: 64, Loss: 0.9755, Train: 64.29%, Valid: 61.45% Test: 59.21%\n",
      "Run: 06, Epoch: 65, Loss: 0.9897, Train: 65.11%, Valid: 62.14% Test: 59.43%\n",
      "Run: 06, Epoch: 66, Loss: 0.9923, Train: 62.36%, Valid: 60.08% Test: 59.21%\n",
      "Run: 06, Epoch: 67, Loss: 0.9415, Train: 61.72%, Valid: 60.91% Test: 60.75%\n",
      "Run: 06, Epoch: 68, Loss: 0.9995, Train: 65.38%, Valid: 62.00% Test: 60.75%\n",
      "Run: 06, Epoch: 69, Loss: 0.9614, Train: 65.20%, Valid: 61.59% Test: 59.65%\n",
      "Run: 06, Epoch: 70, Loss: 0.9584, Train: 64.10%, Valid: 61.45% Test: 59.43%\n",
      "Run: 06, Epoch: 71, Loss: 0.9397, Train: 65.38%, Valid: 63.10% Test: 60.09%\n",
      "Run: 06, Epoch: 72, Loss: 0.9443, Train: 64.74%, Valid: 62.96% Test: 60.75%\n",
      "Run: 06, Epoch: 73, Loss: 0.9511, Train: 65.29%, Valid: 63.24% Test: 59.87%\n",
      "Run: 06, Epoch: 74, Loss: 0.9540, Train: 66.39%, Valid: 63.51% Test: 60.53%\n",
      "Run: 06, Epoch: 75, Loss: 0.9526, Train: 64.74%, Valid: 63.10% Test: 60.31%\n",
      "Run: 06, Epoch: 76, Loss: 0.9506, Train: 64.38%, Valid: 61.87% Test: 60.53%\n",
      "Run: 06, Epoch: 77, Loss: 0.9510, Train: 65.84%, Valid: 63.51% Test: 61.62%\n",
      "Run: 06, Epoch: 78, Loss: 0.9305, Train: 63.37%, Valid: 58.30% Test: 59.21%\n",
      "Run: 06, Epoch: 79, Loss: 0.9557, Train: 65.48%, Valid: 61.32% Test: 59.65%\n",
      "Run: 06, Epoch: 80, Loss: 0.9396, Train: 63.92%, Valid: 61.18% Test: 58.99%\n",
      "Run: 06, Epoch: 81, Loss: 0.9400, Train: 66.21%, Valid: 61.59% Test: 59.65%\n",
      "Run: 06, Epoch: 82, Loss: 0.9375, Train: 66.03%, Valid: 62.00% Test: 59.87%\n",
      "Run: 06, Epoch: 83, Loss: 0.9301, Train: 61.36%, Valid: 60.08% Test: 58.77%\n",
      "Run: 06, Epoch: 84, Loss: 0.9370, Train: 59.34%, Valid: 57.48% Test: 56.80%\n",
      "Run: 06, Epoch: 85, Loss: 0.9229, Train: 60.53%, Valid: 59.40% Test: 58.55%\n",
      "Run: 06, Epoch: 86, Loss: 0.9331, Train: 64.65%, Valid: 63.37% Test: 61.18%\n",
      "Run: 06, Epoch: 87, Loss: 0.9386, Train: 65.84%, Valid: 62.69% Test: 60.96%\n",
      "Run: 06, Epoch: 88, Loss: 0.9176, Train: 63.28%, Valid: 58.16% Test: 55.48%\n",
      "Run: 06, Epoch: 89, Loss: 0.9283, Train: 66.94%, Valid: 64.75% Test: 60.96%\n",
      "Run: 06, Epoch: 90, Loss: 0.9252, Train: 67.12%, Valid: 65.43% Test: 62.06%\n",
      "Run: 06, Epoch: 91, Loss: 0.9259, Train: 67.22%, Valid: 65.43% Test: 62.06%\n",
      "Run: 06, Epoch: 92, Loss: 0.9278, Train: 66.21%, Valid: 65.02% Test: 64.25%\n",
      "Run: 06, Epoch: 93, Loss: 0.9257, Train: 65.48%, Valid: 63.37% Test: 63.82%\n",
      "Run: 06, Epoch: 94, Loss: 0.9158, Train: 65.29%, Valid: 62.41% Test: 61.18%\n",
      "Run: 06, Epoch: 95, Loss: 0.9204, Train: 66.39%, Valid: 64.06% Test: 62.28%\n",
      "Run: 06, Epoch: 96, Loss: 0.9208, Train: 66.85%, Valid: 63.92% Test: 64.04%\n",
      "Run: 06, Epoch: 97, Loss: 0.9207, Train: 63.28%, Valid: 62.28% Test: 64.04%\n",
      "Run: 06, Epoch: 98, Loss: 0.9156, Train: 67.40%, Valid: 63.65% Test: 63.82%\n",
      "Run: 06, Epoch: 99, Loss: 0.8905, Train: 65.84%, Valid: 62.55% Test: 60.53%\n",
      "Run: 06, Epoch: 100, Loss: 0.9239, Train: 66.67%, Valid: 63.65% Test: 63.16%\n",
      "Run 06:\n",
      "Highest Train: 67.40\n",
      "Highest Valid: 65.43\n",
      "  Final Train: 67.12\n",
      "   Final Test: 62.06\n",
      "Run: 07, Epoch: 01, Loss: 1.7790, Train: 23.08%, Valid: 22.09% Test: 25.00%\n",
      "Run: 07, Epoch: 02, Loss: 1.4869, Train: 22.99%, Valid: 24.42% Test: 20.18%\n",
      "Run: 07, Epoch: 03, Loss: 1.4138, Train: 22.99%, Valid: 24.42% Test: 20.18%\n",
      "Run: 07, Epoch: 04, Loss: 1.4123, Train: 23.08%, Valid: 24.69% Test: 20.18%\n",
      "Run: 07, Epoch: 05, Loss: 1.3971, Train: 27.38%, Valid: 28.53% Test: 25.00%\n",
      "Run: 07, Epoch: 06, Loss: 1.3627, Train: 30.40%, Valid: 30.59% Test: 28.51%\n",
      "Run: 07, Epoch: 07, Loss: 1.3298, Train: 38.64%, Valid: 37.45% Test: 33.99%\n",
      "Run: 07, Epoch: 08, Loss: 1.2927, Train: 38.37%, Valid: 36.49% Test: 33.11%\n",
      "Run: 07, Epoch: 09, Loss: 1.2609, Train: 38.28%, Valid: 36.08% Test: 34.87%\n",
      "Run: 07, Epoch: 10, Loss: 1.2355, Train: 41.21%, Valid: 37.59% Test: 36.40%\n",
      "Run: 07, Epoch: 11, Loss: 1.2262, Train: 42.77%, Valid: 40.74% Test: 39.91%\n",
      "Run: 07, Epoch: 12, Loss: 1.2235, Train: 40.66%, Valid: 39.51% Test: 39.04%\n",
      "Run: 07, Epoch: 13, Loss: 1.2092, Train: 48.08%, Valid: 45.54% Test: 43.20%\n",
      "Run: 07, Epoch: 14, Loss: 1.1835, Train: 47.07%, Valid: 45.13% Test: 41.67%\n",
      "Run: 07, Epoch: 15, Loss: 1.1734, Train: 51.28%, Valid: 46.23% Test: 46.05%\n",
      "Run: 07, Epoch: 16, Loss: 1.1649, Train: 52.01%, Valid: 47.87% Test: 46.93%\n",
      "Run: 07, Epoch: 17, Loss: 1.1321, Train: 50.92%, Valid: 48.01% Test: 44.30%\n",
      "Run: 07, Epoch: 18, Loss: 1.1458, Train: 51.10%, Valid: 48.01% Test: 44.52%\n",
      "Run: 07, Epoch: 19, Loss: 1.1119, Train: 51.83%, Valid: 48.56% Test: 47.37%\n",
      "Run: 07, Epoch: 20, Loss: 1.1044, Train: 53.21%, Valid: 45.82% Test: 45.61%\n",
      "Run: 07, Epoch: 21, Loss: 1.1077, Train: 52.56%, Valid: 45.95% Test: 46.05%\n",
      "Run: 07, Epoch: 22, Loss: 1.0979, Train: 50.18%, Valid: 44.31% Test: 46.93%\n",
      "Run: 07, Epoch: 23, Loss: 1.1087, Train: 53.39%, Valid: 46.23% Test: 47.81%\n",
      "Run: 07, Epoch: 24, Loss: 1.0907, Train: 53.57%, Valid: 45.68% Test: 47.15%\n",
      "Run: 07, Epoch: 25, Loss: 1.0845, Train: 55.49%, Valid: 49.25% Test: 49.34%\n",
      "Run: 07, Epoch: 26, Loss: 1.0881, Train: 58.52%, Valid: 52.95% Test: 49.56%\n",
      "Run: 07, Epoch: 27, Loss: 1.0562, Train: 58.42%, Valid: 54.05% Test: 50.88%\n",
      "Run: 07, Epoch: 28, Loss: 1.0488, Train: 50.46%, Valid: 45.82% Test: 48.46%\n",
      "Run: 07, Epoch: 29, Loss: 1.0773, Train: 53.57%, Valid: 47.46% Test: 48.03%\n",
      "Run: 07, Epoch: 30, Loss: 1.0518, Train: 58.42%, Valid: 52.54% Test: 51.97%\n",
      "Run: 07, Epoch: 31, Loss: 1.0260, Train: 58.06%, Valid: 53.50% Test: 51.54%\n",
      "Run: 07, Epoch: 32, Loss: 0.9943, Train: 53.21%, Valid: 48.56% Test: 47.37%\n",
      "Run: 07, Epoch: 33, Loss: 1.0152, Train: 54.85%, Valid: 47.60% Test: 50.22%\n",
      "Run: 07, Epoch: 34, Loss: 1.0094, Train: 56.50%, Valid: 51.03% Test: 51.54%\n",
      "Run: 07, Epoch: 35, Loss: 1.0045, Train: 54.85%, Valid: 49.38% Test: 50.22%\n",
      "Run: 07, Epoch: 36, Loss: 0.9911, Train: 51.65%, Valid: 47.87% Test: 48.25%\n",
      "Run: 07, Epoch: 37, Loss: 1.0266, Train: 58.15%, Valid: 53.64% Test: 52.19%\n",
      "Run: 07, Epoch: 38, Loss: 0.9919, Train: 52.01%, Valid: 47.87% Test: 49.12%\n",
      "Run: 07, Epoch: 39, Loss: 1.0054, Train: 51.83%, Valid: 47.60% Test: 47.59%\n",
      "Run: 07, Epoch: 40, Loss: 0.9861, Train: 55.95%, Valid: 52.13% Test: 49.78%\n",
      "Run: 07, Epoch: 41, Loss: 0.9951, Train: 59.89%, Valid: 55.42% Test: 51.75%\n",
      "Run: 07, Epoch: 42, Loss: 0.9869, Train: 56.78%, Valid: 53.09% Test: 47.15%\n",
      "Run: 07, Epoch: 43, Loss: 0.9953, Train: 53.11%, Valid: 48.15% Test: 44.96%\n",
      "Run: 07, Epoch: 44, Loss: 0.9945, Train: 54.67%, Valid: 49.38% Test: 46.93%\n",
      "Run: 07, Epoch: 45, Loss: 0.9602, Train: 57.33%, Valid: 52.67% Test: 48.03%\n",
      "Run: 07, Epoch: 46, Loss: 0.9816, Train: 59.71%, Valid: 55.14% Test: 47.15%\n",
      "Run: 07, Epoch: 47, Loss: 0.9671, Train: 57.97%, Valid: 54.32% Test: 48.03%\n",
      "Run: 07, Epoch: 48, Loss: 0.9693, Train: 61.36%, Valid: 56.52% Test: 51.75%\n",
      "Run: 07, Epoch: 49, Loss: 0.9638, Train: 59.43%, Valid: 54.18% Test: 50.00%\n",
      "Run: 07, Epoch: 50, Loss: 0.9718, Train: 59.16%, Valid: 54.46% Test: 50.66%\n",
      "Run: 07, Epoch: 51, Loss: 0.9869, Train: 61.08%, Valid: 57.75% Test: 50.44%\n",
      "Run: 07, Epoch: 52, Loss: 0.9802, Train: 61.26%, Valid: 57.89% Test: 51.32%\n",
      "Run: 07, Epoch: 53, Loss: 0.9605, Train: 64.01%, Valid: 61.04% Test: 56.36%\n",
      "Run: 07, Epoch: 54, Loss: 0.9456, Train: 56.50%, Valid: 54.73% Test: 53.51%\n",
      "Run: 07, Epoch: 55, Loss: 0.9764, Train: 65.57%, Valid: 62.00% Test: 57.68%\n",
      "Run: 07, Epoch: 56, Loss: 0.9802, Train: 61.17%, Valid: 59.95% Test: 53.73%\n",
      "Run: 07, Epoch: 57, Loss: 0.9867, Train: 64.65%, Valid: 62.14% Test: 54.82%\n",
      "Run: 07, Epoch: 58, Loss: 0.9574, Train: 61.63%, Valid: 60.49% Test: 55.92%\n",
      "Run: 07, Epoch: 59, Loss: 0.9449, Train: 61.36%, Valid: 59.81% Test: 55.92%\n",
      "Run: 07, Epoch: 60, Loss: 0.9374, Train: 64.65%, Valid: 62.55% Test: 55.70%\n",
      "Run: 07, Epoch: 61, Loss: 0.9342, Train: 63.92%, Valid: 59.95% Test: 55.26%\n",
      "Run: 07, Epoch: 62, Loss: 0.9496, Train: 64.29%, Valid: 60.49% Test: 53.73%\n",
      "Run: 07, Epoch: 63, Loss: 0.9707, Train: 64.65%, Valid: 61.32% Test: 54.82%\n",
      "Run: 07, Epoch: 64, Loss: 0.9408, Train: 64.56%, Valid: 60.63% Test: 57.68%\n",
      "Run: 07, Epoch: 65, Loss: 0.9204, Train: 65.38%, Valid: 62.69% Test: 58.99%\n",
      "Run: 07, Epoch: 66, Loss: 0.9331, Train: 65.02%, Valid: 62.41% Test: 57.02%\n",
      "Run: 07, Epoch: 67, Loss: 0.9212, Train: 67.95%, Valid: 62.83% Test: 57.02%\n",
      "Run: 07, Epoch: 68, Loss: 0.9217, Train: 67.22%, Valid: 62.96% Test: 57.46%\n",
      "Run: 07, Epoch: 69, Loss: 0.9284, Train: 66.85%, Valid: 61.59% Test: 58.11%\n",
      "Run: 07, Epoch: 70, Loss: 0.9187, Train: 63.28%, Valid: 58.44% Test: 55.70%\n",
      "Run: 07, Epoch: 71, Loss: 0.9168, Train: 63.64%, Valid: 57.89% Test: 53.07%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 72, Loss: 0.8841, Train: 60.44%, Valid: 58.98% Test: 55.70%\n",
      "Run: 07, Epoch: 73, Loss: 0.8987, Train: 62.64%, Valid: 56.24% Test: 51.75%\n",
      "Run: 07, Epoch: 74, Loss: 0.9094, Train: 62.45%, Valid: 58.30% Test: 53.95%\n",
      "Run: 07, Epoch: 75, Loss: 0.9094, Train: 62.09%, Valid: 57.89% Test: 53.07%\n",
      "Run: 07, Epoch: 76, Loss: 0.8934, Train: 64.38%, Valid: 60.36% Test: 56.58%\n",
      "Run: 07, Epoch: 77, Loss: 0.9036, Train: 60.62%, Valid: 57.06% Test: 53.29%\n",
      "Run: 07, Epoch: 78, Loss: 0.9091, Train: 67.86%, Valid: 62.83% Test: 57.02%\n",
      "Run: 07, Epoch: 79, Loss: 0.8848, Train: 66.12%, Valid: 62.83% Test: 55.48%\n",
      "Run: 07, Epoch: 80, Loss: 0.9032, Train: 65.38%, Valid: 60.63% Test: 54.61%\n",
      "Run: 07, Epoch: 81, Loss: 0.8914, Train: 63.64%, Valid: 60.91% Test: 55.04%\n",
      "Run: 07, Epoch: 82, Loss: 0.8827, Train: 67.95%, Valid: 64.06% Test: 55.70%\n",
      "Run: 07, Epoch: 83, Loss: 0.8950, Train: 66.30%, Valid: 61.59% Test: 57.89%\n",
      "Run: 07, Epoch: 84, Loss: 0.8868, Train: 69.14%, Valid: 62.55% Test: 58.77%\n",
      "Run: 07, Epoch: 85, Loss: 0.8875, Train: 65.29%, Valid: 58.57% Test: 57.24%\n",
      "Run: 07, Epoch: 86, Loss: 0.8905, Train: 64.93%, Valid: 58.30% Test: 57.24%\n",
      "Run: 07, Epoch: 87, Loss: 0.8901, Train: 68.77%, Valid: 64.88% Test: 58.33%\n",
      "Run: 07, Epoch: 88, Loss: 0.8938, Train: 65.75%, Valid: 60.49% Test: 53.73%\n",
      "Run: 07, Epoch: 89, Loss: 0.8573, Train: 63.92%, Valid: 58.02% Test: 52.85%\n",
      "Run: 07, Epoch: 90, Loss: 0.8550, Train: 66.21%, Valid: 60.77% Test: 54.17%\n",
      "Run: 07, Epoch: 91, Loss: 0.8581, Train: 63.00%, Valid: 58.71% Test: 54.17%\n",
      "Run: 07, Epoch: 92, Loss: 0.9149, Train: 63.64%, Valid: 58.71% Test: 53.51%\n",
      "Run: 07, Epoch: 93, Loss: 0.8848, Train: 67.95%, Valid: 61.32% Test: 55.04%\n",
      "Run: 07, Epoch: 94, Loss: 0.8686, Train: 67.03%, Valid: 62.00% Test: 55.26%\n",
      "Run: 07, Epoch: 95, Loss: 0.8715, Train: 64.01%, Valid: 60.22% Test: 53.73%\n",
      "Run: 07, Epoch: 96, Loss: 0.8813, Train: 66.94%, Valid: 63.79% Test: 56.14%\n",
      "Run: 07, Epoch: 97, Loss: 0.8905, Train: 70.05%, Valid: 64.06% Test: 55.26%\n",
      "Run: 07, Epoch: 98, Loss: 0.8824, Train: 64.19%, Valid: 60.63% Test: 55.26%\n",
      "Run: 07, Epoch: 99, Loss: 0.8624, Train: 60.99%, Valid: 57.06% Test: 53.73%\n",
      "Run: 07, Epoch: 100, Loss: 0.8695, Train: 66.39%, Valid: 61.59% Test: 55.70%\n",
      "Run 07:\n",
      "Highest Train: 70.05\n",
      "Highest Valid: 64.88\n",
      "  Final Train: 68.77\n",
      "   Final Test: 58.33\n",
      "Run: 08, Epoch: 01, Loss: 1.6242, Train: 22.53%, Valid: 24.42% Test: 21.27%\n",
      "Run: 08, Epoch: 02, Loss: 1.4434, Train: 22.53%, Valid: 24.42% Test: 21.27%\n",
      "Run: 08, Epoch: 03, Loss: 1.4090, Train: 22.53%, Valid: 24.42% Test: 21.27%\n",
      "Run: 08, Epoch: 04, Loss: 1.3787, Train: 22.53%, Valid: 24.42% Test: 21.27%\n",
      "Run: 08, Epoch: 05, Loss: 1.3371, Train: 22.80%, Valid: 24.97% Test: 21.49%\n",
      "Run: 08, Epoch: 06, Loss: 1.3136, Train: 25.00%, Valid: 27.57% Test: 23.03%\n",
      "Run: 08, Epoch: 07, Loss: 1.2845, Train: 27.11%, Valid: 29.36% Test: 24.12%\n",
      "Run: 08, Epoch: 08, Loss: 1.2756, Train: 33.15%, Valid: 34.57% Test: 31.58%\n",
      "Run: 08, Epoch: 09, Loss: 1.2571, Train: 33.97%, Valid: 35.25% Test: 35.09%\n",
      "Run: 08, Epoch: 10, Loss: 1.2347, Train: 34.52%, Valid: 35.80% Test: 36.84%\n",
      "Run: 08, Epoch: 11, Loss: 1.1997, Train: 35.71%, Valid: 37.17% Test: 37.94%\n",
      "Run: 08, Epoch: 12, Loss: 1.1914, Train: 38.92%, Valid: 41.29% Test: 40.57%\n",
      "Run: 08, Epoch: 13, Loss: 1.1816, Train: 42.40%, Valid: 44.86% Test: 43.42%\n",
      "Run: 08, Epoch: 14, Loss: 1.1585, Train: 46.43%, Valid: 45.13% Test: 45.18%\n",
      "Run: 08, Epoch: 15, Loss: 1.1503, Train: 47.99%, Valid: 44.86% Test: 44.96%\n",
      "Run: 08, Epoch: 16, Loss: 1.1550, Train: 47.71%, Valid: 47.05% Test: 48.46%\n",
      "Run: 08, Epoch: 17, Loss: 1.1377, Train: 48.90%, Valid: 48.97% Test: 48.25%\n",
      "Run: 08, Epoch: 18, Loss: 1.1272, Train: 45.60%, Valid: 46.64% Test: 45.39%\n",
      "Run: 08, Epoch: 19, Loss: 1.1016, Train: 45.42%, Valid: 46.64% Test: 45.61%\n",
      "Run: 08, Epoch: 20, Loss: 1.1082, Train: 48.26%, Valid: 47.33% Test: 45.83%\n",
      "Run: 08, Epoch: 21, Loss: 1.0921, Train: 47.99%, Valid: 46.91% Test: 43.42%\n",
      "Run: 08, Epoch: 22, Loss: 1.1082, Train: 44.32%, Valid: 43.21% Test: 41.89%\n",
      "Run: 08, Epoch: 23, Loss: 1.0838, Train: 46.43%, Valid: 44.86% Test: 43.86%\n",
      "Run: 08, Epoch: 24, Loss: 1.0934, Train: 50.18%, Valid: 48.15% Test: 47.59%\n",
      "Run: 08, Epoch: 25, Loss: 1.0776, Train: 52.93%, Valid: 49.25% Test: 51.75%\n",
      "Run: 08, Epoch: 26, Loss: 1.0503, Train: 52.56%, Valid: 48.83% Test: 51.32%\n",
      "Run: 08, Epoch: 27, Loss: 1.0497, Train: 54.58%, Valid: 53.09% Test: 55.26%\n",
      "Run: 08, Epoch: 28, Loss: 1.0753, Train: 49.36%, Valid: 48.29% Test: 47.59%\n",
      "Run: 08, Epoch: 29, Loss: 1.0446, Train: 50.82%, Valid: 48.70% Test: 49.12%\n",
      "Run: 08, Epoch: 30, Loss: 1.0391, Train: 51.74%, Valid: 50.48% Test: 51.32%\n",
      "Run: 08, Epoch: 31, Loss: 1.0513, Train: 48.53%, Valid: 45.27% Test: 47.15%\n",
      "Run: 08, Epoch: 32, Loss: 1.0516, Train: 42.67%, Valid: 40.47% Test: 41.89%\n",
      "Run: 08, Epoch: 33, Loss: 1.0572, Train: 46.25%, Valid: 44.31% Test: 43.86%\n",
      "Run: 08, Epoch: 34, Loss: 1.0230, Train: 49.18%, Valid: 45.27% Test: 44.74%\n",
      "Run: 08, Epoch: 35, Loss: 1.0312, Train: 51.19%, Valid: 46.50% Test: 49.12%\n",
      "Run: 08, Epoch: 36, Loss: 1.0158, Train: 50.00%, Valid: 47.05% Test: 50.44%\n",
      "Run: 08, Epoch: 37, Loss: 1.0383, Train: 52.38%, Valid: 52.26% Test: 51.97%\n",
      "Run: 08, Epoch: 38, Loss: 1.0302, Train: 51.19%, Valid: 47.46% Test: 49.78%\n",
      "Run: 08, Epoch: 39, Loss: 1.0133, Train: 53.39%, Valid: 48.42% Test: 50.66%\n",
      "Run: 08, Epoch: 40, Loss: 1.0401, Train: 53.48%, Valid: 49.93% Test: 51.97%\n",
      "Run: 08, Epoch: 41, Loss: 1.0280, Train: 52.56%, Valid: 49.79% Test: 52.41%\n",
      "Run: 08, Epoch: 42, Loss: 1.0114, Train: 51.65%, Valid: 48.97% Test: 48.68%\n",
      "Run: 08, Epoch: 43, Loss: 1.0450, Train: 59.89%, Valid: 55.69% Test: 56.80%\n",
      "Run: 08, Epoch: 44, Loss: 1.0230, Train: 59.43%, Valid: 55.97% Test: 55.70%\n",
      "Run: 08, Epoch: 45, Loss: 0.9740, Train: 59.89%, Valid: 56.24% Test: 57.89%\n",
      "Run: 08, Epoch: 46, Loss: 0.9917, Train: 55.40%, Valid: 51.44% Test: 51.75%\n",
      "Run: 08, Epoch: 47, Loss: 0.9976, Train: 53.57%, Valid: 51.44% Test: 50.44%\n",
      "Run: 08, Epoch: 48, Loss: 1.0043, Train: 55.13%, Valid: 52.40% Test: 51.75%\n",
      "Run: 08, Epoch: 49, Loss: 0.9887, Train: 56.68%, Valid: 53.50% Test: 50.88%\n",
      "Run: 08, Epoch: 50, Loss: 0.9873, Train: 62.36%, Valid: 59.26% Test: 55.70%\n",
      "Run: 08, Epoch: 51, Loss: 0.9705, Train: 59.80%, Valid: 57.20% Test: 54.82%\n",
      "Run: 08, Epoch: 52, Loss: 1.0010, Train: 59.62%, Valid: 56.65% Test: 52.63%\n",
      "Run: 08, Epoch: 53, Loss: 0.9746, Train: 56.96%, Valid: 53.50% Test: 53.51%\n",
      "Run: 08, Epoch: 54, Loss: 0.9770, Train: 54.12%, Valid: 50.75% Test: 49.34%\n",
      "Run: 08, Epoch: 55, Loss: 0.9830, Train: 52.01%, Valid: 46.64% Test: 46.49%\n",
      "Run: 08, Epoch: 56, Loss: 0.9862, Train: 54.12%, Valid: 49.52% Test: 49.34%\n",
      "Run: 08, Epoch: 57, Loss: 0.9547, Train: 60.16%, Valid: 55.42% Test: 57.89%\n",
      "Run: 08, Epoch: 58, Loss: 0.9801, Train: 60.53%, Valid: 54.60% Test: 54.61%\n",
      "Run: 08, Epoch: 59, Loss: 0.9652, Train: 62.45%, Valid: 56.65% Test: 55.48%\n",
      "Run: 08, Epoch: 60, Loss: 0.9650, Train: 60.35%, Valid: 55.83% Test: 53.07%\n",
      "Run: 08, Epoch: 61, Loss: 0.9498, Train: 60.71%, Valid: 55.42% Test: 54.82%\n",
      "Run: 08, Epoch: 62, Loss: 0.9471, Train: 57.51%, Valid: 55.28% Test: 52.19%\n",
      "Run: 08, Epoch: 63, Loss: 0.9563, Train: 57.33%, Valid: 54.87% Test: 49.78%\n",
      "Run: 08, Epoch: 64, Loss: 0.9415, Train: 58.15%, Valid: 55.01% Test: 50.00%\n",
      "Run: 08, Epoch: 65, Loss: 0.9553, Train: 61.26%, Valid: 57.20% Test: 54.82%\n",
      "Run: 08, Epoch: 66, Loss: 0.9316, Train: 62.64%, Valid: 58.02% Test: 56.58%\n",
      "Run: 08, Epoch: 67, Loss: 0.9489, Train: 64.84%, Valid: 60.49% Test: 58.33%\n",
      "Run: 08, Epoch: 68, Loss: 0.9256, Train: 63.37%, Valid: 59.26% Test: 56.58%\n",
      "Run: 08, Epoch: 69, Loss: 0.9675, Train: 62.82%, Valid: 59.67% Test: 57.46%\n",
      "Run: 08, Epoch: 70, Loss: 0.9594, Train: 61.54%, Valid: 58.16% Test: 56.58%\n",
      "Run: 08, Epoch: 71, Loss: 0.9484, Train: 60.71%, Valid: 56.52% Test: 54.61%\n",
      "Run: 08, Epoch: 72, Loss: 0.9367, Train: 63.46%, Valid: 56.93% Test: 55.70%\n",
      "Run: 08, Epoch: 73, Loss: 0.9600, Train: 61.63%, Valid: 56.65% Test: 52.85%\n",
      "Run: 08, Epoch: 74, Loss: 0.9424, Train: 64.47%, Valid: 59.12% Test: 56.80%\n",
      "Run: 08, Epoch: 75, Loss: 0.9292, Train: 66.48%, Valid: 62.00% Test: 61.40%\n",
      "Run: 08, Epoch: 76, Loss: 0.9409, Train: 65.66%, Valid: 61.18% Test: 61.40%\n",
      "Run: 08, Epoch: 77, Loss: 0.9351, Train: 65.48%, Valid: 60.91% Test: 59.43%\n",
      "Run: 08, Epoch: 78, Loss: 0.9329, Train: 62.91%, Valid: 57.34% Test: 54.82%\n",
      "Run: 08, Epoch: 79, Loss: 0.9288, Train: 63.37%, Valid: 58.16% Test: 57.24%\n",
      "Run: 08, Epoch: 80, Loss: 0.9073, Train: 58.70%, Valid: 53.64% Test: 54.82%\n",
      "Run: 08, Epoch: 81, Loss: 0.9529, Train: 64.29%, Valid: 61.18% Test: 59.43%\n",
      "Run: 08, Epoch: 82, Loss: 0.9216, Train: 61.81%, Valid: 59.67% Test: 53.95%\n",
      "Run: 08, Epoch: 83, Loss: 0.9596, Train: 59.89%, Valid: 56.93% Test: 55.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 84, Loss: 0.9218, Train: 63.83%, Valid: 59.40% Test: 59.87%\n",
      "Run: 08, Epoch: 85, Loss: 0.9196, Train: 64.74%, Valid: 60.63% Test: 57.68%\n",
      "Run: 08, Epoch: 86, Loss: 0.9354, Train: 64.29%, Valid: 60.77% Test: 56.58%\n",
      "Run: 08, Epoch: 87, Loss: 0.9243, Train: 63.83%, Valid: 61.18% Test: 57.89%\n",
      "Run: 08, Epoch: 88, Loss: 0.9205, Train: 62.55%, Valid: 60.91% Test: 57.46%\n",
      "Run: 08, Epoch: 89, Loss: 0.9183, Train: 62.00%, Valid: 59.12% Test: 56.36%\n",
      "Run: 08, Epoch: 90, Loss: 0.8894, Train: 63.10%, Valid: 59.26% Test: 57.24%\n",
      "Run: 08, Epoch: 91, Loss: 0.9303, Train: 61.90%, Valid: 57.61% Test: 55.92%\n",
      "Run: 08, Epoch: 92, Loss: 0.9099, Train: 62.00%, Valid: 58.71% Test: 57.46%\n",
      "Run: 08, Epoch: 93, Loss: 0.9143, Train: 62.09%, Valid: 58.44% Test: 56.58%\n",
      "Run: 08, Epoch: 94, Loss: 0.8991, Train: 63.83%, Valid: 57.89% Test: 56.58%\n",
      "Run: 08, Epoch: 95, Loss: 0.9151, Train: 64.56%, Valid: 57.75% Test: 55.70%\n",
      "Run: 08, Epoch: 96, Loss: 0.9156, Train: 64.56%, Valid: 59.95% Test: 55.04%\n",
      "Run: 08, Epoch: 97, Loss: 0.8947, Train: 62.27%, Valid: 58.02% Test: 53.73%\n",
      "Run: 08, Epoch: 98, Loss: 0.8976, Train: 60.99%, Valid: 56.24% Test: 53.51%\n",
      "Run: 08, Epoch: 99, Loss: 0.8933, Train: 60.62%, Valid: 57.06% Test: 49.78%\n",
      "Run: 08, Epoch: 100, Loss: 0.9140, Train: 61.81%, Valid: 56.52% Test: 53.29%\n",
      "Run 08:\n",
      "Highest Train: 66.48\n",
      "Highest Valid: 62.00\n",
      "  Final Train: 66.48\n",
      "   Final Test: 61.40\n",
      "Run: 09, Epoch: 01, Loss: 1.7357, Train: 34.71%, Valid: 33.88% Test: 34.21%\n",
      "Run: 09, Epoch: 02, Loss: 1.4744, Train: 22.99%, Valid: 22.50% Test: 23.25%\n",
      "Run: 09, Epoch: 03, Loss: 1.4324, Train: 22.99%, Valid: 22.50% Test: 23.25%\n",
      "Run: 09, Epoch: 04, Loss: 1.4061, Train: 22.99%, Valid: 22.50% Test: 23.25%\n",
      "Run: 09, Epoch: 05, Loss: 1.3688, Train: 24.27%, Valid: 24.42% Test: 25.00%\n",
      "Run: 09, Epoch: 06, Loss: 1.3165, Train: 33.24%, Valid: 32.24% Test: 33.77%\n",
      "Run: 09, Epoch: 07, Loss: 1.2783, Train: 38.19%, Valid: 33.33% Test: 35.75%\n",
      "Run: 09, Epoch: 08, Loss: 1.2824, Train: 41.03%, Valid: 37.86% Test: 40.35%\n",
      "Run: 09, Epoch: 09, Loss: 1.2652, Train: 42.31%, Valid: 41.70% Test: 43.64%\n",
      "Run: 09, Epoch: 10, Loss: 1.2316, Train: 46.70%, Valid: 46.09% Test: 48.03%\n",
      "Run: 09, Epoch: 11, Loss: 1.2157, Train: 46.15%, Valid: 47.87% Test: 49.12%\n",
      "Run: 09, Epoch: 12, Loss: 1.2176, Train: 44.87%, Valid: 44.31% Test: 44.74%\n",
      "Run: 09, Epoch: 13, Loss: 1.1857, Train: 48.63%, Valid: 50.62% Test: 51.32%\n",
      "Run: 09, Epoch: 14, Loss: 1.1896, Train: 49.45%, Valid: 53.36% Test: 51.97%\n",
      "Run: 09, Epoch: 15, Loss: 1.1665, Train: 49.63%, Valid: 52.54% Test: 52.41%\n",
      "Run: 09, Epoch: 16, Loss: 1.1676, Train: 50.73%, Valid: 53.64% Test: 52.19%\n",
      "Run: 09, Epoch: 17, Loss: 1.1630, Train: 50.64%, Valid: 52.13% Test: 49.34%\n",
      "Run: 09, Epoch: 18, Loss: 1.1337, Train: 53.75%, Valid: 54.46% Test: 55.92%\n",
      "Run: 09, Epoch: 19, Loss: 1.1311, Train: 52.47%, Valid: 52.67% Test: 51.75%\n",
      "Run: 09, Epoch: 20, Loss: 1.1247, Train: 50.92%, Valid: 51.71% Test: 48.25%\n",
      "Run: 09, Epoch: 21, Loss: 1.1393, Train: 55.77%, Valid: 57.89% Test: 56.14%\n",
      "Run: 09, Epoch: 22, Loss: 1.1248, Train: 54.49%, Valid: 56.65% Test: 53.95%\n",
      "Run: 09, Epoch: 23, Loss: 1.1304, Train: 54.49%, Valid: 56.93% Test: 52.19%\n",
      "Run: 09, Epoch: 24, Loss: 1.1113, Train: 53.94%, Valid: 55.69% Test: 52.19%\n",
      "Run: 09, Epoch: 25, Loss: 1.1036, Train: 53.30%, Valid: 56.10% Test: 51.75%\n",
      "Run: 09, Epoch: 26, Loss: 1.0924, Train: 52.29%, Valid: 53.64% Test: 51.97%\n",
      "Run: 09, Epoch: 27, Loss: 1.0977, Train: 52.84%, Valid: 56.38% Test: 51.75%\n",
      "Run: 09, Epoch: 28, Loss: 1.0684, Train: 54.76%, Valid: 57.75% Test: 53.29%\n",
      "Run: 09, Epoch: 29, Loss: 1.0835, Train: 54.40%, Valid: 57.34% Test: 53.73%\n",
      "Run: 09, Epoch: 30, Loss: 1.0631, Train: 53.02%, Valid: 52.26% Test: 51.10%\n",
      "Run: 09, Epoch: 31, Loss: 1.0403, Train: 51.37%, Valid: 52.67% Test: 52.85%\n",
      "Run: 09, Epoch: 32, Loss: 1.0867, Train: 54.03%, Valid: 57.06% Test: 54.82%\n",
      "Run: 09, Epoch: 33, Loss: 1.0445, Train: 54.76%, Valid: 57.48% Test: 56.58%\n",
      "Run: 09, Epoch: 34, Loss: 1.0604, Train: 54.30%, Valid: 52.67% Test: 55.26%\n",
      "Run: 09, Epoch: 35, Loss: 1.0526, Train: 56.78%, Valid: 53.50% Test: 56.58%\n",
      "Run: 09, Epoch: 36, Loss: 1.0433, Train: 55.22%, Valid: 56.10% Test: 55.04%\n",
      "Run: 09, Epoch: 37, Loss: 1.0633, Train: 55.59%, Valid: 55.69% Test: 57.68%\n",
      "Run: 09, Epoch: 38, Loss: 1.0589, Train: 52.66%, Valid: 50.62% Test: 54.17%\n",
      "Run: 09, Epoch: 39, Loss: 1.0588, Train: 54.40%, Valid: 57.48% Test: 58.77%\n",
      "Run: 09, Epoch: 40, Loss: 1.0697, Train: 52.56%, Valid: 55.01% Test: 55.48%\n",
      "Run: 09, Epoch: 41, Loss: 1.0442, Train: 52.66%, Valid: 55.56% Test: 57.02%\n",
      "Run: 09, Epoch: 42, Loss: 1.0131, Train: 54.76%, Valid: 55.69% Test: 56.80%\n",
      "Run: 09, Epoch: 43, Loss: 1.0226, Train: 53.85%, Valid: 55.01% Test: 55.26%\n",
      "Run: 09, Epoch: 44, Loss: 1.0138, Train: 54.03%, Valid: 56.52% Test: 54.82%\n",
      "Run: 09, Epoch: 45, Loss: 1.0016, Train: 52.93%, Valid: 54.32% Test: 57.46%\n",
      "Run: 09, Epoch: 46, Loss: 1.0401, Train: 53.11%, Valid: 52.95% Test: 55.04%\n",
      "Run: 09, Epoch: 47, Loss: 1.0025, Train: 52.29%, Valid: 54.18% Test: 53.51%\n",
      "Run: 09, Epoch: 48, Loss: 1.0050, Train: 56.23%, Valid: 56.24% Test: 56.36%\n",
      "Run: 09, Epoch: 49, Loss: 1.0221, Train: 53.30%, Valid: 54.32% Test: 52.41%\n",
      "Run: 09, Epoch: 50, Loss: 0.9912, Train: 54.58%, Valid: 55.42% Test: 52.63%\n",
      "Run: 09, Epoch: 51, Loss: 0.9904, Train: 56.96%, Valid: 54.46% Test: 54.82%\n",
      "Run: 09, Epoch: 52, Loss: 0.9999, Train: 57.78%, Valid: 58.98% Test: 56.80%\n",
      "Run: 09, Epoch: 53, Loss: 1.0044, Train: 59.07%, Valid: 58.98% Test: 58.77%\n",
      "Run: 09, Epoch: 54, Loss: 0.9828, Train: 60.07%, Valid: 58.16% Test: 60.53%\n",
      "Run: 09, Epoch: 55, Loss: 0.9987, Train: 60.35%, Valid: 60.22% Test: 61.40%\n",
      "Run: 09, Epoch: 56, Loss: 0.9897, Train: 59.16%, Valid: 58.44% Test: 57.24%\n",
      "Run: 09, Epoch: 57, Loss: 0.9786, Train: 59.89%, Valid: 58.16% Test: 58.99%\n",
      "Run: 09, Epoch: 58, Loss: 0.9952, Train: 54.95%, Valid: 55.28% Test: 51.97%\n",
      "Run: 09, Epoch: 59, Loss: 0.9743, Train: 57.88%, Valid: 58.02% Test: 56.80%\n",
      "Run: 09, Epoch: 60, Loss: 0.9789, Train: 63.55%, Valid: 60.63% Test: 64.04%\n",
      "Run: 09, Epoch: 61, Loss: 0.9705, Train: 61.26%, Valid: 60.77% Test: 60.75%\n",
      "Run: 09, Epoch: 62, Loss: 0.9788, Train: 60.26%, Valid: 60.08% Test: 58.33%\n",
      "Run: 09, Epoch: 63, Loss: 0.9726, Train: 59.62%, Valid: 58.16% Test: 57.02%\n",
      "Run: 09, Epoch: 64, Loss: 0.9852, Train: 57.33%, Valid: 55.83% Test: 53.51%\n",
      "Run: 09, Epoch: 65, Loss: 0.9655, Train: 59.07%, Valid: 56.10% Test: 56.36%\n",
      "Run: 09, Epoch: 66, Loss: 0.9639, Train: 62.09%, Valid: 60.08% Test: 62.06%\n",
      "Run: 09, Epoch: 67, Loss: 0.9678, Train: 61.63%, Valid: 60.77% Test: 63.82%\n",
      "Run: 09, Epoch: 68, Loss: 0.9771, Train: 58.42%, Valid: 57.06% Test: 57.46%\n",
      "Run: 09, Epoch: 69, Loss: 0.9824, Train: 59.71%, Valid: 58.02% Test: 58.99%\n",
      "Run: 09, Epoch: 70, Loss: 0.9735, Train: 60.81%, Valid: 57.89% Test: 61.18%\n",
      "Run: 09, Epoch: 71, Loss: 0.9969, Train: 59.98%, Valid: 59.95% Test: 58.99%\n",
      "Run: 09, Epoch: 72, Loss: 0.9777, Train: 60.81%, Valid: 58.98% Test: 60.53%\n",
      "Run: 09, Epoch: 73, Loss: 0.9571, Train: 57.97%, Valid: 57.20% Test: 58.99%\n",
      "Run: 09, Epoch: 74, Loss: 0.9560, Train: 62.82%, Valid: 62.28% Test: 62.72%\n",
      "Run: 09, Epoch: 75, Loss: 0.9654, Train: 63.19%, Valid: 63.51% Test: 62.94%\n",
      "Run: 09, Epoch: 76, Loss: 0.9649, Train: 62.82%, Valid: 60.91% Test: 62.94%\n",
      "Run: 09, Epoch: 77, Loss: 0.9681, Train: 60.62%, Valid: 58.98% Test: 59.65%\n",
      "Run: 09, Epoch: 78, Loss: 0.9620, Train: 63.00%, Valid: 61.73% Test: 65.13%\n",
      "Run: 09, Epoch: 79, Loss: 0.9668, Train: 62.00%, Valid: 61.73% Test: 64.25%\n",
      "Run: 09, Epoch: 80, Loss: 0.9517, Train: 64.19%, Valid: 62.41% Test: 65.35%\n",
      "Run: 09, Epoch: 81, Loss: 0.9624, Train: 61.45%, Valid: 60.22% Test: 62.06%\n",
      "Run: 09, Epoch: 82, Loss: 0.9625, Train: 65.29%, Valid: 65.71% Test: 66.23%\n",
      "Run: 09, Epoch: 83, Loss: 0.9292, Train: 63.46%, Valid: 64.33% Test: 63.16%\n",
      "Run: 09, Epoch: 84, Loss: 0.9476, Train: 59.62%, Valid: 58.57% Test: 55.48%\n",
      "Run: 09, Epoch: 85, Loss: 0.9421, Train: 58.61%, Valid: 58.98% Test: 57.24%\n",
      "Run: 09, Epoch: 86, Loss: 0.9484, Train: 63.28%, Valid: 63.51% Test: 62.72%\n",
      "Run: 09, Epoch: 87, Loss: 0.9698, Train: 63.64%, Valid: 62.55% Test: 62.06%\n",
      "Run: 09, Epoch: 88, Loss: 0.9822, Train: 61.90%, Valid: 61.18% Test: 61.84%\n",
      "Run: 09, Epoch: 89, Loss: 0.9557, Train: 61.63%, Valid: 60.36% Test: 62.72%\n",
      "Run: 09, Epoch: 90, Loss: 0.9595, Train: 60.71%, Valid: 59.67% Test: 62.94%\n",
      "Run: 09, Epoch: 91, Loss: 0.9406, Train: 61.81%, Valid: 61.59% Test: 63.82%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 92, Loss: 0.9449, Train: 61.72%, Valid: 62.00% Test: 63.16%\n",
      "Run: 09, Epoch: 93, Loss: 0.9530, Train: 61.54%, Valid: 62.00% Test: 63.38%\n",
      "Run: 09, Epoch: 94, Loss: 0.9249, Train: 61.26%, Valid: 61.04% Test: 62.94%\n",
      "Run: 09, Epoch: 95, Loss: 0.9476, Train: 62.09%, Valid: 61.59% Test: 62.50%\n",
      "Run: 09, Epoch: 96, Loss: 0.9427, Train: 61.08%, Valid: 60.36% Test: 61.40%\n",
      "Run: 09, Epoch: 97, Loss: 0.9560, Train: 61.63%, Valid: 62.28% Test: 64.69%\n",
      "Run: 09, Epoch: 98, Loss: 0.9397, Train: 62.00%, Valid: 63.24% Test: 64.91%\n",
      "Run: 09, Epoch: 99, Loss: 0.9422, Train: 60.44%, Valid: 60.22% Test: 62.06%\n",
      "Run: 09, Epoch: 100, Loss: 0.9464, Train: 63.00%, Valid: 62.28% Test: 66.89%\n",
      "Run 09:\n",
      "Highest Train: 65.29\n",
      "Highest Valid: 65.71\n",
      "  Final Train: 65.29\n",
      "   Final Test: 66.23\n",
      "Run: 10, Epoch: 01, Loss: 1.6417, Train: 24.91%, Valid: 27.16% Test: 30.04%\n",
      "Run: 10, Epoch: 02, Loss: 1.4774, Train: 20.88%, Valid: 20.99% Test: 19.96%\n",
      "Run: 10, Epoch: 03, Loss: 1.4117, Train: 29.49%, Valid: 29.22% Test: 30.26%\n",
      "Run: 10, Epoch: 04, Loss: 1.3622, Train: 31.23%, Valid: 29.49% Test: 31.58%\n",
      "Run: 10, Epoch: 05, Loss: 1.3186, Train: 35.16%, Valid: 33.20% Test: 34.87%\n",
      "Run: 10, Epoch: 06, Loss: 1.3045, Train: 35.44%, Valid: 32.78% Test: 36.18%\n",
      "Run: 10, Epoch: 07, Loss: 1.2805, Train: 36.72%, Valid: 31.82% Test: 35.09%\n",
      "Run: 10, Epoch: 08, Loss: 1.2523, Train: 40.02%, Valid: 34.71% Test: 38.82%\n",
      "Run: 10, Epoch: 09, Loss: 1.2217, Train: 42.49%, Valid: 39.92% Test: 45.39%\n",
      "Run: 10, Epoch: 10, Loss: 1.1977, Train: 47.53%, Valid: 45.68% Test: 49.78%\n",
      "Run: 10, Epoch: 11, Loss: 1.2046, Train: 49.45%, Valid: 48.70% Test: 50.44%\n",
      "Run: 10, Epoch: 12, Loss: 1.1838, Train: 43.04%, Valid: 44.03% Test: 44.96%\n",
      "Run: 10, Epoch: 13, Loss: 1.1724, Train: 43.22%, Valid: 43.90% Test: 42.98%\n",
      "Run: 10, Epoch: 14, Loss: 1.1656, Train: 43.50%, Valid: 43.90% Test: 45.39%\n",
      "Run: 10, Epoch: 15, Loss: 1.1502, Train: 43.50%, Valid: 44.03% Test: 44.74%\n",
      "Run: 10, Epoch: 16, Loss: 1.1481, Train: 46.89%, Valid: 48.56% Test: 50.44%\n",
      "Run: 10, Epoch: 17, Loss: 1.1452, Train: 49.27%, Valid: 50.75% Test: 53.51%\n",
      "Run: 10, Epoch: 18, Loss: 1.1145, Train: 45.70%, Valid: 44.86% Test: 47.15%\n",
      "Run: 10, Epoch: 19, Loss: 1.1036, Train: 50.09%, Valid: 49.93% Test: 52.19%\n",
      "Run: 10, Epoch: 20, Loss: 1.1089, Train: 46.06%, Valid: 45.95% Test: 46.27%\n",
      "Run: 10, Epoch: 21, Loss: 1.1145, Train: 51.28%, Valid: 50.89% Test: 54.61%\n",
      "Run: 10, Epoch: 22, Loss: 1.1049, Train: 53.57%, Valid: 51.99% Test: 54.17%\n",
      "Run: 10, Epoch: 23, Loss: 1.0856, Train: 55.86%, Valid: 53.09% Test: 55.48%\n",
      "Run: 10, Epoch: 24, Loss: 1.0697, Train: 55.40%, Valid: 52.40% Test: 52.85%\n",
      "Run: 10, Epoch: 25, Loss: 1.0921, Train: 53.85%, Valid: 51.99% Test: 51.75%\n",
      "Run: 10, Epoch: 26, Loss: 1.0533, Train: 56.50%, Valid: 53.64% Test: 56.58%\n",
      "Run: 10, Epoch: 27, Loss: 1.0685, Train: 52.56%, Valid: 51.03% Test: 54.61%\n",
      "Run: 10, Epoch: 28, Loss: 1.0698, Train: 51.28%, Valid: 50.07% Test: 52.85%\n",
      "Run: 10, Epoch: 29, Loss: 1.0436, Train: 47.89%, Valid: 48.70% Test: 50.66%\n",
      "Run: 10, Epoch: 30, Loss: 1.0660, Train: 49.45%, Valid: 49.79% Test: 52.41%\n",
      "Run: 10, Epoch: 31, Loss: 1.0403, Train: 49.73%, Valid: 51.30% Test: 51.75%\n",
      "Run: 10, Epoch: 32, Loss: 1.0339, Train: 52.38%, Valid: 51.99% Test: 53.95%\n",
      "Run: 10, Epoch: 33, Loss: 1.0431, Train: 54.40%, Valid: 54.32% Test: 57.24%\n",
      "Run: 10, Epoch: 34, Loss: 1.0368, Train: 54.85%, Valid: 57.06% Test: 58.55%\n",
      "Run: 10, Epoch: 35, Loss: 1.0324, Train: 54.30%, Valid: 55.42% Test: 57.89%\n",
      "Run: 10, Epoch: 36, Loss: 1.0140, Train: 51.37%, Valid: 50.34% Test: 52.85%\n",
      "Run: 10, Epoch: 37, Loss: 1.0284, Train: 54.85%, Valid: 54.18% Test: 55.70%\n",
      "Run: 10, Epoch: 38, Loss: 1.0247, Train: 56.41%, Valid: 55.97% Test: 58.55%\n",
      "Run: 10, Epoch: 39, Loss: 1.0275, Train: 55.49%, Valid: 55.01% Test: 58.77%\n",
      "Run: 10, Epoch: 40, Loss: 1.0481, Train: 55.49%, Valid: 55.28% Test: 57.24%\n",
      "Run: 10, Epoch: 41, Loss: 1.0316, Train: 54.12%, Valid: 52.40% Test: 54.61%\n",
      "Run: 10, Epoch: 42, Loss: 1.0425, Train: 54.95%, Valid: 55.01% Test: 57.68%\n",
      "Run: 10, Epoch: 43, Loss: 0.9996, Train: 59.25%, Valid: 57.89% Test: 60.31%\n",
      "Run: 10, Epoch: 44, Loss: 1.0321, Train: 62.00%, Valid: 58.71% Test: 62.72%\n",
      "Run: 10, Epoch: 45, Loss: 0.9928, Train: 61.26%, Valid: 57.34% Test: 59.87%\n",
      "Run: 10, Epoch: 46, Loss: 1.0199, Train: 58.88%, Valid: 55.83% Test: 58.77%\n",
      "Run: 10, Epoch: 47, Loss: 1.0026, Train: 62.36%, Valid: 57.34% Test: 60.31%\n",
      "Run: 10, Epoch: 48, Loss: 0.9739, Train: 60.53%, Valid: 56.79% Test: 60.09%\n",
      "Run: 10, Epoch: 49, Loss: 0.9826, Train: 59.80%, Valid: 56.24% Test: 58.77%\n",
      "Run: 10, Epoch: 50, Loss: 1.0031, Train: 60.62%, Valid: 55.97% Test: 59.65%\n",
      "Run: 10, Epoch: 51, Loss: 1.0016, Train: 63.19%, Valid: 57.89% Test: 62.50%\n",
      "Run: 10, Epoch: 52, Loss: 0.9835, Train: 63.00%, Valid: 59.40% Test: 61.62%\n",
      "Run: 10, Epoch: 53, Loss: 0.9760, Train: 58.52%, Valid: 54.60% Test: 58.99%\n",
      "Run: 10, Epoch: 54, Loss: 0.9649, Train: 55.77%, Valid: 53.64% Test: 55.70%\n",
      "Run: 10, Epoch: 55, Loss: 0.9874, Train: 57.05%, Valid: 53.50% Test: 57.89%\n",
      "Run: 10, Epoch: 56, Loss: 0.9586, Train: 55.77%, Valid: 54.18% Test: 55.92%\n",
      "Run: 10, Epoch: 57, Loss: 0.9754, Train: 59.43%, Valid: 55.28% Test: 60.53%\n",
      "Run: 10, Epoch: 58, Loss: 0.9484, Train: 61.17%, Valid: 57.89% Test: 60.53%\n",
      "Run: 10, Epoch: 59, Loss: 0.9501, Train: 62.64%, Valid: 57.48% Test: 61.62%\n",
      "Run: 10, Epoch: 60, Loss: 0.9574, Train: 62.27%, Valid: 58.98% Test: 60.31%\n",
      "Run: 10, Epoch: 61, Loss: 0.9626, Train: 61.36%, Valid: 57.20% Test: 59.21%\n",
      "Run: 10, Epoch: 62, Loss: 0.9779, Train: 59.07%, Valid: 55.01% Test: 56.14%\n",
      "Run: 10, Epoch: 63, Loss: 0.9410, Train: 57.05%, Valid: 55.83% Test: 56.80%\n",
      "Run: 10, Epoch: 64, Loss: 0.9282, Train: 53.02%, Valid: 51.85% Test: 52.41%\n",
      "Run: 10, Epoch: 65, Loss: 0.9419, Train: 52.84%, Valid: 51.03% Test: 52.19%\n",
      "Run: 10, Epoch: 66, Loss: 0.9500, Train: 59.16%, Valid: 55.69% Test: 57.68%\n",
      "Run: 10, Epoch: 67, Loss: 0.9087, Train: 63.64%, Valid: 58.16% Test: 61.40%\n",
      "Run: 10, Epoch: 68, Loss: 0.9252, Train: 63.55%, Valid: 58.85% Test: 62.72%\n",
      "Run: 10, Epoch: 69, Loss: 0.9579, Train: 65.38%, Valid: 59.95% Test: 61.84%\n",
      "Run: 10, Epoch: 70, Loss: 0.9088, Train: 59.34%, Valid: 56.52% Test: 58.55%\n",
      "Run: 10, Epoch: 71, Loss: 0.9235, Train: 61.54%, Valid: 56.65% Test: 59.21%\n",
      "Run: 10, Epoch: 72, Loss: 0.9020, Train: 60.53%, Valid: 56.24% Test: 59.21%\n",
      "Run: 10, Epoch: 73, Loss: 0.9205, Train: 60.35%, Valid: 56.24% Test: 56.36%\n",
      "Run: 10, Epoch: 74, Loss: 0.9283, Train: 64.84%, Valid: 61.04% Test: 61.62%\n",
      "Run: 10, Epoch: 75, Loss: 0.9232, Train: 64.47%, Valid: 61.04% Test: 62.72%\n",
      "Run: 10, Epoch: 76, Loss: 0.9443, Train: 66.39%, Valid: 62.14% Test: 64.69%\n",
      "Run: 10, Epoch: 77, Loss: 0.9014, Train: 60.99%, Valid: 58.02% Test: 57.68%\n",
      "Run: 10, Epoch: 78, Loss: 0.9157, Train: 64.56%, Valid: 60.63% Test: 61.62%\n",
      "Run: 10, Epoch: 79, Loss: 0.9337, Train: 64.74%, Valid: 59.81% Test: 62.06%\n",
      "Run: 10, Epoch: 80, Loss: 0.9368, Train: 64.65%, Valid: 60.08% Test: 63.82%\n",
      "Run: 10, Epoch: 81, Loss: 0.9059, Train: 64.74%, Valid: 59.26% Test: 61.62%\n",
      "Run: 10, Epoch: 82, Loss: 0.9176, Train: 62.36%, Valid: 55.97% Test: 58.77%\n",
      "Run: 10, Epoch: 83, Loss: 0.9048, Train: 62.64%, Valid: 56.24% Test: 62.06%\n",
      "Run: 10, Epoch: 84, Loss: 0.9199, Train: 58.79%, Valid: 55.56% Test: 60.31%\n",
      "Run: 10, Epoch: 85, Loss: 0.9440, Train: 57.69%, Valid: 54.18% Test: 55.70%\n",
      "Run: 10, Epoch: 86, Loss: 0.9009, Train: 66.48%, Valid: 60.91% Test: 63.60%\n",
      "Run: 10, Epoch: 87, Loss: 0.9379, Train: 64.56%, Valid: 61.04% Test: 64.25%\n",
      "Run: 10, Epoch: 88, Loss: 0.9404, Train: 63.00%, Valid: 58.57% Test: 61.62%\n",
      "Run: 10, Epoch: 89, Loss: 0.8816, Train: 64.01%, Valid: 60.49% Test: 61.40%\n",
      "Run: 10, Epoch: 90, Loss: 0.8750, Train: 64.01%, Valid: 59.81% Test: 58.77%\n",
      "Run: 10, Epoch: 91, Loss: 0.9084, Train: 65.20%, Valid: 61.18% Test: 61.84%\n",
      "Run: 10, Epoch: 92, Loss: 0.9123, Train: 66.48%, Valid: 61.45% Test: 61.40%\n",
      "Run: 10, Epoch: 93, Loss: 0.9026, Train: 63.37%, Valid: 59.81% Test: 62.06%\n",
      "Run: 10, Epoch: 94, Loss: 0.9129, Train: 61.81%, Valid: 59.67% Test: 60.53%\n",
      "Run: 10, Epoch: 95, Loss: 0.9278, Train: 64.29%, Valid: 61.59% Test: 62.28%\n",
      "Run: 10, Epoch: 96, Loss: 0.9040, Train: 65.57%, Valid: 61.45% Test: 61.62%\n",
      "Run: 10, Epoch: 97, Loss: 0.9415, Train: 65.66%, Valid: 60.36% Test: 60.31%\n",
      "Run: 10, Epoch: 98, Loss: 0.9230, Train: 65.38%, Valid: 61.45% Test: 62.94%\n",
      "Run: 10, Epoch: 99, Loss: 0.8767, Train: 64.56%, Valid: 59.26% Test: 62.50%\n",
      "Run: 10, Epoch: 100, Loss: 0.9081, Train: 66.12%, Valid: 61.18% Test: 62.94%\n",
      "Run 10:\n",
      "Highest Train: 66.48\n",
      "Highest Valid: 62.14\n",
      "  Final Train: 66.39\n",
      "   Final Test: 64.69\n",
      "All runs:\n",
      "Highest Train: 66.91 ± 1.62\n",
      "Highest Valid: 64.27 ± 2.07\n",
      "  Final Train: 66.60 ± 1.27\n",
      "   Final Test: 63.36 ± 3.27\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 48, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-6, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.5,'num_layers_mlp': 3}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = GCN(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 5,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(15, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        \n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.01)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.01)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011de720",
   "metadata": {},
   "source": [
    "# Topo-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WikipediaNetwork(root='/tmp/chameleon', name='chameleon',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "data.topo=Topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "862766ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x1055c1480>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshem/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 01:\n",
      "Highest Train: 93.96\n",
      "Highest Valid: 69.82\n",
      "  Final Train: 92.31\n",
      "   Final Test: 65.35\n",
      "Run 02:\n",
      "Highest Train: 93.04\n",
      "Highest Valid: 65.57\n",
      "  Final Train: 90.57\n",
      "   Final Test: 70.83\n",
      "Run 03:\n",
      "Highest Train: 94.41\n",
      "Highest Valid: 68.72\n",
      "  Final Train: 94.23\n",
      "   Final Test: 67.76\n",
      "Run 04:\n",
      "Highest Train: 92.03\n",
      "Highest Valid: 68.31\n",
      "  Final Train: 89.84\n",
      "   Final Test: 66.01\n",
      "Run 05:\n",
      "Highest Train: 93.77\n",
      "Highest Valid: 68.45\n",
      "  Final Train: 92.86\n",
      "   Final Test: 67.76\n",
      "Run 06:\n",
      "Highest Train: 93.68\n",
      "Highest Valid: 67.63\n",
      "  Final Train: 90.11\n",
      "   Final Test: 67.11\n",
      "Run 07:\n",
      "Highest Train: 93.32\n",
      "Highest Valid: 68.45\n",
      "  Final Train: 88.28\n",
      "   Final Test: 64.69\n",
      "Run 08:\n",
      "Highest Train: 93.50\n",
      "Highest Valid: 65.43\n",
      "  Final Train: 90.66\n",
      "   Final Test: 64.47\n",
      "Run 09:\n",
      "Highest Train: 91.48\n",
      "Highest Valid: 69.14\n",
      "  Final Train: 90.02\n",
      "   Final Test: 67.11\n",
      "Run 10:\n",
      "Highest Train: 94.05\n",
      "Highest Valid: 67.76\n",
      "  Final Train: 94.05\n",
      "   Final Test: 68.20\n",
      "All runs:\n",
      "Highest Train: 93.32 ± 0.92\n",
      "Highest Valid: 67.93 ± 1.43\n",
      "  Final Train: 91.29 ± 1.97\n",
      "   Final Test: 66.93 ± 1.91\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 48, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-6, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.0,'num_layers_mlp': 3}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = GCN(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 5,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(15, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        \n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.01)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.01)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                #print(f'Run: {run + 1:02d}, 'f'Epoch: {epoch:02d}, ' f'Loss: {loss:.4f}, 'f'Train: {100 * train_acc:.2f}%, '\n",
    "                 #     f'Valid: {100 * valid_acc:.2f}% '\n",
    "                  #    f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33830b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ef003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10c8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
