{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af88d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import networkx as nx\n",
    "from networkx import ego_graph\n",
    "\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "\n",
    "#from logger import Logger\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7babc9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "print(data)\n",
    "#split_idx = dataset.get_idx_split()\n",
    "#train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91fdcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "train_index = np.where(data.train_mask)[0]\n",
    "print(len(train_index))\n",
    "valid_index = np.where(data.val_mask)[0]\n",
    "print(len(valid_index))\n",
    "test_index = np.where(data.test_mask)[0]\n",
    "print(len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0b82f",
   "metadata": {},
   "source": [
    "# GCN using only domain Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b9ef33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, runs, info=None):\n",
    "        self.info = info\n",
    "        self.results = [[] for _ in range(runs)]\n",
    "\n",
    "    def add_result(self, run, result):\n",
    "        assert len(result) == 3\n",
    "        assert run >= 0 and run < len(self.results)\n",
    "        self.results[run].append(result)\n",
    "\n",
    "    def print_statistics(self, run=None):\n",
    "        if run is not None:\n",
    "            result = 100 * torch.tensor(self.results[run])\n",
    "            argmax = result[:, 1].argmax().item()\n",
    "            print(f'Run {run + 1:02d}:')\n",
    "            print(f'Highest Train: {result[:, 0].max():.2f}')\n",
    "            print(f'Highest Valid: {result[:, 1].max():.2f}')\n",
    "            print(f'  Final Train: {result[argmax, 0]:.2f}')\n",
    "            print(f'   Final Test: {result[argmax, 2]:.2f}')\n",
    "        else:\n",
    "            result = 100 * torch.tensor(self.results)\n",
    "\n",
    "            best_results = []\n",
    "            for r in result:\n",
    "                train1 = r[:, 0].max().item()\n",
    "                valid = r[:, 1].max().item()\n",
    "                train2 = r[r[:, 1].argmax(), 0].item()\n",
    "                test = r[r[:, 1].argmax(), 2].item()\n",
    "                best_results.append((train1, valid, train2, test))\n",
    "\n",
    "            best_result = torch.tensor(best_results)\n",
    "\n",
    "            print(f'All runs:')\n",
    "            r = best_result[:, 0]\n",
    "            print(f'Highest Train: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 1]\n",
    "            print(f'Highest Valid: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 2]\n",
    "            print(f'  Final Train: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 3]\n",
    "            print(f'   Final Test: {r.mean():.2f} ± {r.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47468ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(len(out))\n",
    "    #print(data.y.squeeze(1)[train_idx])\n",
    "    loss = F.nll_loss(out, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.adj_t)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=torch.tensor([1, 0, 1,0])\n",
    "label=torch.tensor([1, 1, 1,0])\n",
    "correct = pred.eq(label).sum().item()\n",
    "total=len(label)\n",
    "print(correct)\n",
    "print(total)\n",
    "print(correct/total)\n",
    "print(ACC(pred,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23796d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x1688bfc40>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 01, Loss: 2.3461, Train: 48.57%, Valid: 35.60% Test: 38.70%\n",
      "Run: 01, Epoch: 02, Loss: 1.5001, Train: 77.86%, Valid: 56.60% Test: 60.30%\n",
      "Run: 01, Epoch: 03, Loss: 1.1152, Train: 90.00%, Valid: 64.00% Test: 66.90%\n",
      "Run: 01, Epoch: 04, Loss: 0.9433, Train: 94.29%, Valid: 66.80% Test: 70.10%\n",
      "Run: 01, Epoch: 05, Loss: 0.8134, Train: 97.86%, Valid: 69.20% Test: 71.60%\n",
      "Run: 01, Epoch: 06, Loss: 0.7259, Train: 97.86%, Valid: 71.80% Test: 72.40%\n",
      "Run: 01, Epoch: 07, Loss: 0.6297, Train: 97.86%, Valid: 71.40% Test: 73.30%\n",
      "Run: 01, Epoch: 08, Loss: 0.5426, Train: 98.57%, Valid: 71.20% Test: 72.70%\n",
      "Run: 01, Epoch: 09, Loss: 0.5027, Train: 98.57%, Valid: 70.60% Test: 73.20%\n",
      "Run: 01, Epoch: 10, Loss: 0.4358, Train: 98.57%, Valid: 71.00% Test: 72.80%\n",
      "Run: 01, Epoch: 11, Loss: 0.3901, Train: 98.57%, Valid: 71.00% Test: 72.90%\n",
      "Run: 01, Epoch: 12, Loss: 0.3628, Train: 98.57%, Valid: 70.80% Test: 72.50%\n",
      "Run: 01, Epoch: 13, Loss: 0.3141, Train: 100.00%, Valid: 70.80% Test: 72.60%\n",
      "Run: 01, Epoch: 14, Loss: 0.2686, Train: 100.00%, Valid: 70.20% Test: 72.50%\n",
      "Run: 01, Epoch: 15, Loss: 0.2479, Train: 100.00%, Valid: 70.00% Test: 72.80%\n",
      "Run: 01, Epoch: 16, Loss: 0.2254, Train: 100.00%, Valid: 70.00% Test: 73.20%\n",
      "Run: 01, Epoch: 17, Loss: 0.1939, Train: 100.00%, Valid: 69.20% Test: 73.30%\n",
      "Run: 01, Epoch: 18, Loss: 0.1828, Train: 100.00%, Valid: 69.00% Test: 73.60%\n",
      "Run: 01, Epoch: 19, Loss: 0.1540, Train: 100.00%, Valid: 70.00% Test: 73.50%\n",
      "Run: 01, Epoch: 20, Loss: 0.1802, Train: 100.00%, Valid: 70.40% Test: 73.30%\n",
      "Run: 01, Epoch: 21, Loss: 0.1103, Train: 100.00%, Valid: 70.60% Test: 72.80%\n",
      "Run: 01, Epoch: 22, Loss: 0.1210, Train: 100.00%, Valid: 70.40% Test: 72.40%\n",
      "Run: 01, Epoch: 23, Loss: 0.1330, Train: 100.00%, Valid: 70.20% Test: 72.10%\n",
      "Run: 01, Epoch: 24, Loss: 0.1145, Train: 100.00%, Valid: 69.60% Test: 72.10%\n",
      "Run: 01, Epoch: 25, Loss: 0.1057, Train: 100.00%, Valid: 69.60% Test: 71.60%\n",
      "Run: 01, Epoch: 26, Loss: 0.0964, Train: 100.00%, Valid: 69.40% Test: 71.60%\n",
      "Run: 01, Epoch: 27, Loss: 0.1089, Train: 100.00%, Valid: 68.40% Test: 70.90%\n",
      "Run: 01, Epoch: 28, Loss: 0.0716, Train: 100.00%, Valid: 68.20% Test: 70.70%\n",
      "Run: 01, Epoch: 29, Loss: 0.0782, Train: 100.00%, Valid: 68.00% Test: 70.50%\n",
      "Run: 01, Epoch: 30, Loss: 0.0792, Train: 100.00%, Valid: 68.20% Test: 69.90%\n",
      "Run: 01, Epoch: 31, Loss: 0.0650, Train: 100.00%, Valid: 68.00% Test: 69.50%\n",
      "Run: 01, Epoch: 32, Loss: 0.0594, Train: 100.00%, Valid: 67.20% Test: 69.50%\n",
      "Run: 01, Epoch: 33, Loss: 0.0851, Train: 100.00%, Valid: 67.00% Test: 69.40%\n",
      "Run: 01, Epoch: 34, Loss: 0.0550, Train: 100.00%, Valid: 67.00% Test: 69.30%\n",
      "Run: 01, Epoch: 35, Loss: 0.0688, Train: 100.00%, Valid: 67.00% Test: 69.30%\n",
      "Run: 01, Epoch: 36, Loss: 0.0439, Train: 100.00%, Valid: 66.80% Test: 69.20%\n",
      "Run: 01, Epoch: 37, Loss: 0.0498, Train: 100.00%, Valid: 66.80% Test: 69.00%\n",
      "Run: 01, Epoch: 38, Loss: 0.0650, Train: 100.00%, Valid: 67.00% Test: 69.10%\n",
      "Run: 01, Epoch: 39, Loss: 0.0434, Train: 100.00%, Valid: 66.80% Test: 69.10%\n",
      "Run: 01, Epoch: 40, Loss: 0.0301, Train: 100.00%, Valid: 66.60% Test: 68.90%\n",
      "Run: 01, Epoch: 41, Loss: 0.0410, Train: 100.00%, Valid: 66.80% Test: 68.80%\n",
      "Run: 01, Epoch: 42, Loss: 0.0410, Train: 100.00%, Valid: 66.80% Test: 68.90%\n",
      "Run: 01, Epoch: 43, Loss: 0.0320, Train: 100.00%, Valid: 66.40% Test: 68.70%\n",
      "Run: 01, Epoch: 44, Loss: 0.0736, Train: 100.00%, Valid: 66.40% Test: 68.50%\n",
      "Run: 01, Epoch: 45, Loss: 0.0395, Train: 100.00%, Valid: 66.20% Test: 68.40%\n",
      "Run: 01, Epoch: 46, Loss: 0.0554, Train: 100.00%, Valid: 66.20% Test: 68.50%\n",
      "Run: 01, Epoch: 47, Loss: 0.0328, Train: 100.00%, Valid: 65.40% Test: 68.30%\n",
      "Run: 01, Epoch: 48, Loss: 0.0204, Train: 100.00%, Valid: 65.40% Test: 68.20%\n",
      "Run: 01, Epoch: 49, Loss: 0.0453, Train: 100.00%, Valid: 65.60% Test: 68.00%\n",
      "Run: 01, Epoch: 50, Loss: 0.0402, Train: 100.00%, Valid: 65.40% Test: 68.20%\n",
      "Run: 01, Epoch: 51, Loss: 0.0253, Train: 100.00%, Valid: 65.00% Test: 68.20%\n",
      "Run: 01, Epoch: 52, Loss: 0.0221, Train: 100.00%, Valid: 65.00% Test: 67.90%\n",
      "Run: 01, Epoch: 53, Loss: 0.0227, Train: 100.00%, Valid: 65.00% Test: 67.90%\n",
      "Run: 01, Epoch: 54, Loss: 0.0279, Train: 100.00%, Valid: 65.00% Test: 67.80%\n",
      "Run: 01, Epoch: 55, Loss: 0.0304, Train: 100.00%, Valid: 65.20% Test: 68.10%\n",
      "Run: 01, Epoch: 56, Loss: 0.0329, Train: 100.00%, Valid: 64.80% Test: 68.10%\n",
      "Run: 01, Epoch: 57, Loss: 0.0314, Train: 100.00%, Valid: 65.20% Test: 68.40%\n",
      "Run: 01, Epoch: 58, Loss: 0.0226, Train: 100.00%, Valid: 65.20% Test: 68.50%\n",
      "Run: 01, Epoch: 59, Loss: 0.0423, Train: 100.00%, Valid: 65.60% Test: 68.40%\n",
      "Run: 01, Epoch: 60, Loss: 0.0249, Train: 100.00%, Valid: 65.60% Test: 68.50%\n",
      "Run: 01, Epoch: 61, Loss: 0.0206, Train: 100.00%, Valid: 65.40% Test: 68.70%\n",
      "Run: 01, Epoch: 62, Loss: 0.0206, Train: 100.00%, Valid: 65.60% Test: 68.70%\n",
      "Run: 01, Epoch: 63, Loss: 0.0361, Train: 100.00%, Valid: 65.60% Test: 68.60%\n",
      "Run: 01, Epoch: 64, Loss: 0.0200, Train: 100.00%, Valid: 65.60% Test: 68.60%\n",
      "Run: 01, Epoch: 65, Loss: 0.0269, Train: 100.00%, Valid: 65.40% Test: 68.30%\n",
      "Run: 01, Epoch: 66, Loss: 0.0391, Train: 100.00%, Valid: 65.40% Test: 68.20%\n",
      "Run: 01, Epoch: 67, Loss: 0.0177, Train: 100.00%, Valid: 65.20% Test: 68.30%\n",
      "Run: 01, Epoch: 68, Loss: 0.0279, Train: 100.00%, Valid: 65.20% Test: 68.10%\n",
      "Run: 01, Epoch: 69, Loss: 0.0239, Train: 100.00%, Valid: 65.20% Test: 68.20%\n",
      "Run: 01, Epoch: 70, Loss: 0.0323, Train: 100.00%, Valid: 65.20% Test: 67.90%\n",
      "Run: 01, Epoch: 71, Loss: 0.0414, Train: 100.00%, Valid: 64.80% Test: 67.70%\n",
      "Run: 01, Epoch: 72, Loss: 0.0259, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 01, Epoch: 73, Loss: 0.0304, Train: 100.00%, Valid: 64.80% Test: 67.70%\n",
      "Run: 01, Epoch: 74, Loss: 0.0196, Train: 100.00%, Valid: 65.20% Test: 67.70%\n",
      "Run: 01, Epoch: 75, Loss: 0.0285, Train: 100.00%, Valid: 65.60% Test: 67.50%\n",
      "Run: 01, Epoch: 76, Loss: 0.0334, Train: 100.00%, Valid: 65.60% Test: 67.50%\n",
      "Run: 01, Epoch: 77, Loss: 0.0174, Train: 100.00%, Valid: 65.60% Test: 67.70%\n",
      "Run: 01, Epoch: 78, Loss: 0.0183, Train: 100.00%, Valid: 65.60% Test: 67.70%\n",
      "Run: 01, Epoch: 79, Loss: 0.0321, Train: 100.00%, Valid: 65.60% Test: 67.60%\n",
      "Run: 01, Epoch: 80, Loss: 0.0341, Train: 100.00%, Valid: 65.60% Test: 67.60%\n",
      "Run: 01, Epoch: 81, Loss: 0.0168, Train: 100.00%, Valid: 65.40% Test: 67.80%\n",
      "Run: 01, Epoch: 82, Loss: 0.0338, Train: 100.00%, Valid: 65.40% Test: 67.80%\n",
      "Run: 01, Epoch: 83, Loss: 0.0249, Train: 100.00%, Valid: 65.80% Test: 67.80%\n",
      "Run: 01, Epoch: 84, Loss: 0.0339, Train: 100.00%, Valid: 66.20% Test: 67.70%\n",
      "Run: 01, Epoch: 85, Loss: 0.0085, Train: 100.00%, Valid: 66.00% Test: 67.80%\n",
      "Run: 01, Epoch: 86, Loss: 0.0462, Train: 100.00%, Valid: 65.80% Test: 67.80%\n",
      "Run: 01, Epoch: 87, Loss: 0.0154, Train: 100.00%, Valid: 66.00% Test: 68.10%\n",
      "Run: 01, Epoch: 88, Loss: 0.0319, Train: 100.00%, Valid: 65.80% Test: 68.20%\n",
      "Run: 01, Epoch: 89, Loss: 0.0200, Train: 100.00%, Valid: 65.80% Test: 68.30%\n",
      "Run: 01, Epoch: 90, Loss: 0.0239, Train: 100.00%, Valid: 65.40% Test: 68.30%\n",
      "Run: 01, Epoch: 91, Loss: 0.0244, Train: 100.00%, Valid: 65.40% Test: 68.40%\n",
      "Run: 01, Epoch: 92, Loss: 0.0154, Train: 100.00%, Valid: 65.40% Test: 68.70%\n",
      "Run: 01, Epoch: 93, Loss: 0.0353, Train: 100.00%, Valid: 65.40% Test: 68.60%\n",
      "Run: 01, Epoch: 94, Loss: 0.0171, Train: 100.00%, Valid: 65.40% Test: 68.50%\n",
      "Run: 01, Epoch: 95, Loss: 0.0251, Train: 100.00%, Valid: 65.20% Test: 68.30%\n",
      "Run: 01, Epoch: 96, Loss: 0.0209, Train: 100.00%, Valid: 65.20% Test: 68.40%\n",
      "Run: 01, Epoch: 97, Loss: 0.0251, Train: 100.00%, Valid: 65.20% Test: 68.30%\n",
      "Run: 01, Epoch: 98, Loss: 0.0144, Train: 100.00%, Valid: 65.20% Test: 68.30%\n",
      "Run: 01, Epoch: 99, Loss: 0.0228, Train: 100.00%, Valid: 65.20% Test: 68.30%\n",
      "Run: 01, Epoch: 100, Loss: 0.0100, Train: 100.00%, Valid: 65.20% Test: 68.10%\n",
      "Run: 01, Epoch: 101, Loss: 0.0233, Train: 100.00%, Valid: 65.20% Test: 68.10%\n",
      "Run: 01, Epoch: 102, Loss: 0.0304, Train: 100.00%, Valid: 65.20% Test: 68.30%\n",
      "Run: 01, Epoch: 103, Loss: 0.0134, Train: 100.00%, Valid: 65.20% Test: 68.30%\n",
      "Run: 01, Epoch: 104, Loss: 0.0087, Train: 100.00%, Valid: 65.20% Test: 67.90%\n",
      "Run: 01, Epoch: 105, Loss: 0.0198, Train: 100.00%, Valid: 65.20% Test: 67.80%\n",
      "Run: 01, Epoch: 106, Loss: 0.0113, Train: 100.00%, Valid: 65.00% Test: 67.70%\n",
      "Run: 01, Epoch: 107, Loss: 0.0161, Train: 100.00%, Valid: 65.00% Test: 67.70%\n",
      "Run: 01, Epoch: 108, Loss: 0.0188, Train: 100.00%, Valid: 65.00% Test: 67.70%\n",
      "Run: 01, Epoch: 109, Loss: 0.0088, Train: 100.00%, Valid: 65.00% Test: 67.70%\n",
      "Run: 01, Epoch: 110, Loss: 0.0073, Train: 100.00%, Valid: 65.20% Test: 67.70%\n",
      "Run: 01, Epoch: 111, Loss: 0.0051, Train: 100.00%, Valid: 65.20% Test: 67.70%\n",
      "Run: 01, Epoch: 112, Loss: 0.0135, Train: 100.00%, Valid: 65.20% Test: 67.90%\n",
      "Run: 01, Epoch: 113, Loss: 0.0114, Train: 100.00%, Valid: 65.20% Test: 67.90%\n",
      "Run: 01, Epoch: 114, Loss: 0.0080, Train: 100.00%, Valid: 65.20% Test: 67.90%\n",
      "Run: 01, Epoch: 115, Loss: 0.0063, Train: 100.00%, Valid: 65.20% Test: 67.80%\n",
      "Run: 01, Epoch: 116, Loss: 0.0067, Train: 100.00%, Valid: 64.80% Test: 67.80%\n",
      "Run: 01, Epoch: 117, Loss: 0.0319, Train: 100.00%, Valid: 64.80% Test: 67.80%\n",
      "Run: 01, Epoch: 118, Loss: 0.0158, Train: 100.00%, Valid: 64.80% Test: 67.80%\n",
      "Run: 01, Epoch: 119, Loss: 0.0109, Train: 100.00%, Valid: 64.80% Test: 67.80%\n",
      "Run: 01, Epoch: 120, Loss: 0.0136, Train: 100.00%, Valid: 64.60% Test: 67.70%\n",
      "Run: 01, Epoch: 121, Loss: 0.0101, Train: 100.00%, Valid: 64.60% Test: 67.70%\n",
      "Run: 01, Epoch: 122, Loss: 0.0040, Train: 100.00%, Valid: 64.60% Test: 67.80%\n",
      "Run: 01, Epoch: 123, Loss: 0.0218, Train: 100.00%, Valid: 65.00% Test: 67.90%\n",
      "Run: 01, Epoch: 124, Loss: 0.0126, Train: 100.00%, Valid: 65.20% Test: 67.70%\n",
      "Run: 01, Epoch: 125, Loss: 0.0098, Train: 100.00%, Valid: 65.40% Test: 67.80%\n",
      "Run: 01, Epoch: 126, Loss: 0.0129, Train: 100.00%, Valid: 65.40% Test: 67.90%\n",
      "Run: 01, Epoch: 127, Loss: 0.0161, Train: 100.00%, Valid: 65.40% Test: 67.90%\n",
      "Run: 01, Epoch: 128, Loss: 0.0092, Train: 100.00%, Valid: 65.40% Test: 67.80%\n",
      "Run: 01, Epoch: 129, Loss: 0.0063, Train: 100.00%, Valid: 65.40% Test: 67.80%\n",
      "Run: 01, Epoch: 130, Loss: 0.0050, Train: 100.00%, Valid: 65.20% Test: 67.80%\n",
      "Run: 01, Epoch: 131, Loss: 0.0155, Train: 100.00%, Valid: 65.20% Test: 67.80%\n",
      "Run: 01, Epoch: 132, Loss: 0.0288, Train: 100.00%, Valid: 65.20% Test: 67.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 133, Loss: 0.0050, Train: 100.00%, Valid: 65.20% Test: 68.00%\n",
      "Run: 01, Epoch: 134, Loss: 0.0284, Train: 100.00%, Valid: 65.20% Test: 67.90%\n",
      "Run: 01, Epoch: 135, Loss: 0.0090, Train: 100.00%, Valid: 65.20% Test: 67.90%\n",
      "Run: 01, Epoch: 136, Loss: 0.0099, Train: 100.00%, Valid: 65.00% Test: 67.90%\n",
      "Run: 01, Epoch: 137, Loss: 0.0203, Train: 100.00%, Valid: 65.00% Test: 68.00%\n",
      "Run: 01, Epoch: 138, Loss: 0.0248, Train: 100.00%, Valid: 65.00% Test: 68.00%\n",
      "Run: 01, Epoch: 139, Loss: 0.0068, Train: 100.00%, Valid: 65.00% Test: 68.00%\n",
      "Run: 01, Epoch: 140, Loss: 0.0038, Train: 100.00%, Valid: 65.00% Test: 68.40%\n",
      "Run: 01, Epoch: 141, Loss: 0.0106, Train: 100.00%, Valid: 64.80% Test: 68.30%\n",
      "Run: 01, Epoch: 142, Loss: 0.0100, Train: 100.00%, Valid: 64.80% Test: 68.20%\n",
      "Run: 01, Epoch: 143, Loss: 0.0060, Train: 100.00%, Valid: 64.40% Test: 68.20%\n",
      "Run: 01, Epoch: 144, Loss: 0.0132, Train: 100.00%, Valid: 64.40% Test: 68.20%\n",
      "Run: 01, Epoch: 145, Loss: 0.0085, Train: 100.00%, Valid: 64.60% Test: 68.20%\n",
      "Run: 01, Epoch: 146, Loss: 0.0112, Train: 100.00%, Valid: 64.60% Test: 68.20%\n",
      "Run: 01, Epoch: 147, Loss: 0.0070, Train: 100.00%, Valid: 64.40% Test: 68.10%\n",
      "Run: 01, Epoch: 148, Loss: 0.0064, Train: 100.00%, Valid: 64.60% Test: 68.20%\n",
      "Run: 01, Epoch: 149, Loss: 0.0165, Train: 100.00%, Valid: 65.00% Test: 68.20%\n",
      "Run: 01, Epoch: 150, Loss: 0.0057, Train: 100.00%, Valid: 65.00% Test: 68.30%\n",
      "Run: 01, Epoch: 151, Loss: 0.0119, Train: 100.00%, Valid: 64.80% Test: 68.10%\n",
      "Run: 01, Epoch: 152, Loss: 0.0058, Train: 100.00%, Valid: 64.60% Test: 67.90%\n",
      "Run: 01, Epoch: 153, Loss: 0.0103, Train: 100.00%, Valid: 64.60% Test: 68.00%\n",
      "Run: 01, Epoch: 154, Loss: 0.0067, Train: 100.00%, Valid: 65.00% Test: 68.00%\n",
      "Run: 01, Epoch: 155, Loss: 0.0251, Train: 100.00%, Valid: 65.00% Test: 68.00%\n",
      "Run: 01, Epoch: 156, Loss: 0.0028, Train: 100.00%, Valid: 65.00% Test: 68.00%\n",
      "Run: 01, Epoch: 157, Loss: 0.0066, Train: 100.00%, Valid: 65.00% Test: 68.00%\n",
      "Run: 01, Epoch: 158, Loss: 0.0078, Train: 100.00%, Valid: 64.80% Test: 67.80%\n",
      "Run: 01, Epoch: 159, Loss: 0.0028, Train: 100.00%, Valid: 64.80% Test: 67.80%\n",
      "Run: 01, Epoch: 160, Loss: 0.0059, Train: 100.00%, Valid: 64.60% Test: 67.90%\n",
      "Run: 01, Epoch: 161, Loss: 0.0088, Train: 100.00%, Valid: 64.80% Test: 67.90%\n",
      "Run: 01, Epoch: 162, Loss: 0.0025, Train: 100.00%, Valid: 64.60% Test: 67.80%\n",
      "Run: 01, Epoch: 163, Loss: 0.0035, Train: 100.00%, Valid: 64.60% Test: 67.60%\n",
      "Run: 01, Epoch: 164, Loss: 0.0034, Train: 100.00%, Valid: 64.40% Test: 67.60%\n",
      "Run: 01, Epoch: 165, Loss: 0.0061, Train: 100.00%, Valid: 64.60% Test: 67.60%\n",
      "Run: 01, Epoch: 166, Loss: 0.0035, Train: 100.00%, Valid: 64.60% Test: 67.50%\n",
      "Run: 01, Epoch: 167, Loss: 0.0114, Train: 100.00%, Valid: 64.60% Test: 67.60%\n",
      "Run: 01, Epoch: 168, Loss: 0.0100, Train: 100.00%, Valid: 64.80% Test: 67.50%\n",
      "Run: 01, Epoch: 169, Loss: 0.0061, Train: 100.00%, Valid: 64.80% Test: 67.50%\n",
      "Run: 01, Epoch: 170, Loss: 0.0117, Train: 100.00%, Valid: 64.80% Test: 67.50%\n",
      "Run: 01, Epoch: 171, Loss: 0.0087, Train: 100.00%, Valid: 64.80% Test: 67.50%\n",
      "Run: 01, Epoch: 172, Loss: 0.0046, Train: 100.00%, Valid: 64.80% Test: 67.60%\n",
      "Run: 01, Epoch: 173, Loss: 0.0237, Train: 100.00%, Valid: 64.80% Test: 67.50%\n",
      "Run: 01, Epoch: 174, Loss: 0.0064, Train: 100.00%, Valid: 65.00% Test: 67.50%\n",
      "Run: 01, Epoch: 175, Loss: 0.0076, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 01, Epoch: 176, Loss: 0.0084, Train: 100.00%, Valid: 64.80% Test: 67.60%\n",
      "Run: 01, Epoch: 177, Loss: 0.0057, Train: 100.00%, Valid: 64.80% Test: 67.70%\n",
      "Run: 01, Epoch: 178, Loss: 0.0076, Train: 100.00%, Valid: 64.60% Test: 67.50%\n",
      "Run: 01, Epoch: 179, Loss: 0.0039, Train: 100.00%, Valid: 64.60% Test: 67.40%\n",
      "Run: 01, Epoch: 180, Loss: 0.0061, Train: 100.00%, Valid: 64.20% Test: 67.40%\n",
      "Run: 01, Epoch: 181, Loss: 0.0112, Train: 100.00%, Valid: 64.00% Test: 67.50%\n",
      "Run: 01, Epoch: 182, Loss: 0.0116, Train: 100.00%, Valid: 63.80% Test: 67.40%\n",
      "Run: 01, Epoch: 183, Loss: 0.0119, Train: 100.00%, Valid: 63.80% Test: 67.40%\n",
      "Run: 01, Epoch: 184, Loss: 0.0176, Train: 100.00%, Valid: 64.00% Test: 67.40%\n",
      "Run: 01, Epoch: 185, Loss: 0.0148, Train: 100.00%, Valid: 64.00% Test: 67.10%\n",
      "Run: 01, Epoch: 186, Loss: 0.0074, Train: 100.00%, Valid: 64.00% Test: 67.00%\n",
      "Run: 01, Epoch: 187, Loss: 0.0099, Train: 100.00%, Valid: 64.00% Test: 66.90%\n",
      "Run: 01, Epoch: 188, Loss: 0.0091, Train: 100.00%, Valid: 63.80% Test: 66.70%\n",
      "Run: 01, Epoch: 189, Loss: 0.0057, Train: 100.00%, Valid: 64.20% Test: 66.80%\n",
      "Run: 01, Epoch: 190, Loss: 0.0025, Train: 100.00%, Valid: 64.20% Test: 66.80%\n",
      "Run: 01, Epoch: 191, Loss: 0.0233, Train: 100.00%, Valid: 64.40% Test: 66.60%\n",
      "Run: 01, Epoch: 192, Loss: 0.0041, Train: 100.00%, Valid: 64.40% Test: 66.50%\n",
      "Run: 01, Epoch: 193, Loss: 0.0098, Train: 100.00%, Valid: 64.40% Test: 66.60%\n",
      "Run: 01, Epoch: 194, Loss: 0.0223, Train: 100.00%, Valid: 64.40% Test: 66.60%\n",
      "Run: 01, Epoch: 195, Loss: 0.0186, Train: 100.00%, Valid: 64.40% Test: 66.60%\n",
      "Run: 01, Epoch: 196, Loss: 0.0046, Train: 100.00%, Valid: 64.60% Test: 66.70%\n",
      "Run: 01, Epoch: 197, Loss: 0.0172, Train: 100.00%, Valid: 64.60% Test: 66.80%\n",
      "Run: 01, Epoch: 198, Loss: 0.0101, Train: 100.00%, Valid: 64.20% Test: 66.90%\n",
      "Run: 01, Epoch: 199, Loss: 0.0049, Train: 100.00%, Valid: 64.20% Test: 66.80%\n",
      "Run: 01, Epoch: 200, Loss: 0.0010, Train: 100.00%, Valid: 64.20% Test: 66.60%\n",
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 71.80\n",
      "  Final Train: 97.86\n",
      "   Final Test: 72.40\n",
      "Run: 02, Epoch: 01, Loss: 2.1453, Train: 70.00%, Valid: 40.20% Test: 43.90%\n",
      "Run: 02, Epoch: 02, Loss: 1.1613, Train: 88.57%, Valid: 57.20% Test: 60.70%\n",
      "Run: 02, Epoch: 03, Loss: 0.7535, Train: 96.43%, Valid: 65.20% Test: 68.30%\n",
      "Run: 02, Epoch: 04, Loss: 0.6384, Train: 96.43%, Valid: 69.20% Test: 73.20%\n",
      "Run: 02, Epoch: 05, Loss: 0.5266, Train: 96.43%, Valid: 71.20% Test: 74.60%\n",
      "Run: 02, Epoch: 06, Loss: 0.4318, Train: 97.14%, Valid: 74.20% Test: 75.10%\n",
      "Run: 02, Epoch: 07, Loss: 0.3906, Train: 97.14%, Valid: 74.80% Test: 76.20%\n",
      "Run: 02, Epoch: 08, Loss: 0.3508, Train: 99.29%, Valid: 75.60% Test: 77.20%\n",
      "Run: 02, Epoch: 09, Loss: 0.3003, Train: 99.29%, Valid: 75.40% Test: 77.20%\n",
      "Run: 02, Epoch: 10, Loss: 0.2592, Train: 100.00%, Valid: 74.60% Test: 77.50%\n",
      "Run: 02, Epoch: 11, Loss: 0.2340, Train: 100.00%, Valid: 74.60% Test: 77.80%\n",
      "Run: 02, Epoch: 12, Loss: 0.2206, Train: 100.00%, Valid: 74.60% Test: 77.60%\n",
      "Run: 02, Epoch: 13, Loss: 0.1570, Train: 100.00%, Valid: 74.20% Test: 77.20%\n",
      "Run: 02, Epoch: 14, Loss: 0.1469, Train: 100.00%, Valid: 74.00% Test: 76.60%\n",
      "Run: 02, Epoch: 15, Loss: 0.1408, Train: 100.00%, Valid: 74.20% Test: 76.40%\n",
      "Run: 02, Epoch: 16, Loss: 0.1146, Train: 100.00%, Valid: 74.00% Test: 76.00%\n",
      "Run: 02, Epoch: 17, Loss: 0.1224, Train: 100.00%, Valid: 73.80% Test: 75.80%\n",
      "Run: 02, Epoch: 18, Loss: 0.0965, Train: 100.00%, Valid: 72.80% Test: 75.80%\n",
      "Run: 02, Epoch: 19, Loss: 0.1341, Train: 100.00%, Valid: 72.40% Test: 75.50%\n",
      "Run: 02, Epoch: 20, Loss: 0.0798, Train: 100.00%, Valid: 72.60% Test: 75.50%\n",
      "Run: 02, Epoch: 21, Loss: 0.1353, Train: 100.00%, Valid: 72.40% Test: 75.00%\n",
      "Run: 02, Epoch: 22, Loss: 0.0937, Train: 100.00%, Valid: 72.20% Test: 74.60%\n",
      "Run: 02, Epoch: 23, Loss: 0.0677, Train: 100.00%, Valid: 72.00% Test: 74.40%\n",
      "Run: 02, Epoch: 24, Loss: 0.0761, Train: 100.00%, Valid: 72.00% Test: 73.60%\n",
      "Run: 02, Epoch: 25, Loss: 0.0585, Train: 100.00%, Valid: 71.60% Test: 73.40%\n",
      "Run: 02, Epoch: 26, Loss: 0.1114, Train: 100.00%, Valid: 71.60% Test: 73.40%\n",
      "Run: 02, Epoch: 27, Loss: 0.0671, Train: 100.00%, Valid: 71.40% Test: 73.40%\n",
      "Run: 02, Epoch: 28, Loss: 0.0659, Train: 100.00%, Valid: 71.60% Test: 72.90%\n",
      "Run: 02, Epoch: 29, Loss: 0.0408, Train: 100.00%, Valid: 71.20% Test: 72.90%\n",
      "Run: 02, Epoch: 30, Loss: 0.0314, Train: 100.00%, Valid: 71.00% Test: 72.80%\n",
      "Run: 02, Epoch: 31, Loss: 0.0307, Train: 100.00%, Valid: 70.60% Test: 72.80%\n",
      "Run: 02, Epoch: 32, Loss: 0.0261, Train: 100.00%, Valid: 70.20% Test: 72.70%\n",
      "Run: 02, Epoch: 33, Loss: 0.0366, Train: 100.00%, Valid: 70.20% Test: 72.60%\n",
      "Run: 02, Epoch: 34, Loss: 0.0407, Train: 100.00%, Valid: 70.60% Test: 72.40%\n",
      "Run: 02, Epoch: 35, Loss: 0.0266, Train: 100.00%, Valid: 70.80% Test: 72.20%\n",
      "Run: 02, Epoch: 36, Loss: 0.0363, Train: 100.00%, Valid: 70.80% Test: 72.20%\n",
      "Run: 02, Epoch: 37, Loss: 0.0466, Train: 100.00%, Valid: 70.80% Test: 72.10%\n",
      "Run: 02, Epoch: 38, Loss: 0.0314, Train: 100.00%, Valid: 70.40% Test: 72.00%\n",
      "Run: 02, Epoch: 39, Loss: 0.0194, Train: 100.00%, Valid: 70.00% Test: 71.80%\n",
      "Run: 02, Epoch: 40, Loss: 0.0311, Train: 100.00%, Valid: 70.20% Test: 71.80%\n",
      "Run: 02, Epoch: 41, Loss: 0.0269, Train: 100.00%, Valid: 70.40% Test: 71.50%\n",
      "Run: 02, Epoch: 42, Loss: 0.0336, Train: 100.00%, Valid: 70.20% Test: 71.20%\n",
      "Run: 02, Epoch: 43, Loss: 0.0361, Train: 100.00%, Valid: 70.20% Test: 71.30%\n",
      "Run: 02, Epoch: 44, Loss: 0.0341, Train: 100.00%, Valid: 70.00% Test: 71.30%\n",
      "Run: 02, Epoch: 45, Loss: 0.0453, Train: 100.00%, Valid: 69.80% Test: 71.30%\n",
      "Run: 02, Epoch: 46, Loss: 0.0258, Train: 100.00%, Valid: 69.40% Test: 71.40%\n",
      "Run: 02, Epoch: 47, Loss: 0.0450, Train: 100.00%, Valid: 69.40% Test: 71.30%\n",
      "Run: 02, Epoch: 48, Loss: 0.0193, Train: 100.00%, Valid: 69.40% Test: 71.40%\n",
      "Run: 02, Epoch: 49, Loss: 0.0233, Train: 100.00%, Valid: 69.40% Test: 71.40%\n",
      "Run: 02, Epoch: 50, Loss: 0.0300, Train: 100.00%, Valid: 69.80% Test: 71.80%\n",
      "Run: 02, Epoch: 51, Loss: 0.0248, Train: 100.00%, Valid: 70.00% Test: 71.80%\n",
      "Run: 02, Epoch: 52, Loss: 0.0231, Train: 100.00%, Valid: 69.80% Test: 71.80%\n",
      "Run: 02, Epoch: 53, Loss: 0.0249, Train: 100.00%, Valid: 69.80% Test: 71.80%\n",
      "Run: 02, Epoch: 54, Loss: 0.0304, Train: 100.00%, Valid: 70.00% Test: 71.70%\n",
      "Run: 02, Epoch: 55, Loss: 0.0116, Train: 100.00%, Valid: 69.80% Test: 71.80%\n",
      "Run: 02, Epoch: 56, Loss: 0.0264, Train: 100.00%, Valid: 69.80% Test: 71.60%\n",
      "Run: 02, Epoch: 57, Loss: 0.0190, Train: 100.00%, Valid: 69.80% Test: 71.60%\n",
      "Run: 02, Epoch: 58, Loss: 0.0155, Train: 100.00%, Valid: 69.60% Test: 71.30%\n",
      "Run: 02, Epoch: 59, Loss: 0.0116, Train: 100.00%, Valid: 69.40% Test: 71.20%\n",
      "Run: 02, Epoch: 60, Loss: 0.0149, Train: 100.00%, Valid: 69.60% Test: 71.10%\n",
      "Run: 02, Epoch: 61, Loss: 0.0074, Train: 100.00%, Valid: 69.40% Test: 71.00%\n",
      "Run: 02, Epoch: 62, Loss: 0.0167, Train: 100.00%, Valid: 69.20% Test: 71.00%\n",
      "Run: 02, Epoch: 63, Loss: 0.0265, Train: 100.00%, Valid: 69.20% Test: 71.10%\n",
      "Run: 02, Epoch: 64, Loss: 0.0178, Train: 100.00%, Valid: 69.00% Test: 70.90%\n",
      "Run: 02, Epoch: 65, Loss: 0.0149, Train: 100.00%, Valid: 68.80% Test: 70.80%\n",
      "Run: 02, Epoch: 66, Loss: 0.0180, Train: 100.00%, Valid: 68.60% Test: 70.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 67, Loss: 0.0161, Train: 100.00%, Valid: 68.60% Test: 70.90%\n",
      "Run: 02, Epoch: 68, Loss: 0.0291, Train: 100.00%, Valid: 68.60% Test: 70.90%\n",
      "Run: 02, Epoch: 69, Loss: 0.0336, Train: 100.00%, Valid: 68.60% Test: 70.90%\n",
      "Run: 02, Epoch: 70, Loss: 0.0221, Train: 100.00%, Valid: 68.60% Test: 70.70%\n",
      "Run: 02, Epoch: 71, Loss: 0.0130, Train: 100.00%, Valid: 68.40% Test: 70.50%\n",
      "Run: 02, Epoch: 72, Loss: 0.0200, Train: 100.00%, Valid: 68.20% Test: 70.20%\n",
      "Run: 02, Epoch: 73, Loss: 0.0295, Train: 100.00%, Valid: 68.20% Test: 70.20%\n",
      "Run: 02, Epoch: 74, Loss: 0.0369, Train: 100.00%, Valid: 68.40% Test: 70.30%\n",
      "Run: 02, Epoch: 75, Loss: 0.0132, Train: 100.00%, Valid: 68.40% Test: 70.30%\n",
      "Run: 02, Epoch: 76, Loss: 0.0082, Train: 100.00%, Valid: 68.40% Test: 70.10%\n",
      "Run: 02, Epoch: 77, Loss: 0.0198, Train: 100.00%, Valid: 68.60% Test: 70.30%\n",
      "Run: 02, Epoch: 78, Loss: 0.0288, Train: 100.00%, Valid: 68.40% Test: 70.40%\n",
      "Run: 02, Epoch: 79, Loss: 0.0104, Train: 100.00%, Valid: 68.20% Test: 70.40%\n",
      "Run: 02, Epoch: 80, Loss: 0.0171, Train: 100.00%, Valid: 67.80% Test: 70.50%\n",
      "Run: 02, Epoch: 81, Loss: 0.0139, Train: 100.00%, Valid: 67.60% Test: 70.60%\n",
      "Run: 02, Epoch: 82, Loss: 0.0405, Train: 100.00%, Valid: 67.40% Test: 70.50%\n",
      "Run: 02, Epoch: 83, Loss: 0.0088, Train: 100.00%, Valid: 67.60% Test: 70.50%\n",
      "Run: 02, Epoch: 84, Loss: 0.0112, Train: 100.00%, Valid: 67.40% Test: 70.30%\n",
      "Run: 02, Epoch: 85, Loss: 0.0303, Train: 100.00%, Valid: 67.20% Test: 70.40%\n",
      "Run: 02, Epoch: 86, Loss: 0.0258, Train: 100.00%, Valid: 66.80% Test: 70.40%\n",
      "Run: 02, Epoch: 87, Loss: 0.0170, Train: 100.00%, Valid: 66.60% Test: 70.40%\n",
      "Run: 02, Epoch: 88, Loss: 0.0136, Train: 100.00%, Valid: 66.60% Test: 70.30%\n",
      "Run: 02, Epoch: 89, Loss: 0.0094, Train: 100.00%, Valid: 66.60% Test: 70.10%\n",
      "Run: 02, Epoch: 90, Loss: 0.0043, Train: 100.00%, Valid: 66.40% Test: 69.80%\n",
      "Run: 02, Epoch: 91, Loss: 0.0053, Train: 100.00%, Valid: 66.40% Test: 69.60%\n",
      "Run: 02, Epoch: 92, Loss: 0.0217, Train: 100.00%, Valid: 66.60% Test: 69.60%\n",
      "Run: 02, Epoch: 93, Loss: 0.0103, Train: 100.00%, Valid: 66.80% Test: 69.50%\n",
      "Run: 02, Epoch: 94, Loss: 0.0299, Train: 100.00%, Valid: 66.80% Test: 69.40%\n",
      "Run: 02, Epoch: 95, Loss: 0.0077, Train: 100.00%, Valid: 66.80% Test: 69.30%\n",
      "Run: 02, Epoch: 96, Loss: 0.0036, Train: 100.00%, Valid: 66.60% Test: 69.20%\n",
      "Run: 02, Epoch: 97, Loss: 0.0126, Train: 100.00%, Valid: 66.60% Test: 69.20%\n",
      "Run: 02, Epoch: 98, Loss: 0.0104, Train: 100.00%, Valid: 66.20% Test: 68.90%\n",
      "Run: 02, Epoch: 99, Loss: 0.0107, Train: 100.00%, Valid: 66.40% Test: 68.80%\n",
      "Run: 02, Epoch: 100, Loss: 0.0107, Train: 100.00%, Valid: 66.40% Test: 68.70%\n",
      "Run: 02, Epoch: 101, Loss: 0.0107, Train: 100.00%, Valid: 66.40% Test: 68.40%\n",
      "Run: 02, Epoch: 102, Loss: 0.0153, Train: 100.00%, Valid: 66.60% Test: 68.40%\n",
      "Run: 02, Epoch: 103, Loss: 0.0125, Train: 100.00%, Valid: 67.00% Test: 68.60%\n",
      "Run: 02, Epoch: 104, Loss: 0.0115, Train: 100.00%, Valid: 67.00% Test: 68.60%\n",
      "Run: 02, Epoch: 105, Loss: 0.0079, Train: 100.00%, Valid: 67.00% Test: 68.60%\n",
      "Run: 02, Epoch: 106, Loss: 0.0105, Train: 100.00%, Valid: 67.00% Test: 68.40%\n",
      "Run: 02, Epoch: 107, Loss: 0.0071, Train: 100.00%, Valid: 66.80% Test: 68.30%\n",
      "Run: 02, Epoch: 108, Loss: 0.0096, Train: 100.00%, Valid: 66.80% Test: 68.20%\n",
      "Run: 02, Epoch: 109, Loss: 0.0112, Train: 100.00%, Valid: 66.80% Test: 68.10%\n",
      "Run: 02, Epoch: 110, Loss: 0.0096, Train: 100.00%, Valid: 66.80% Test: 68.50%\n",
      "Run: 02, Epoch: 111, Loss: 0.0054, Train: 100.00%, Valid: 66.80% Test: 68.50%\n",
      "Run: 02, Epoch: 112, Loss: 0.0045, Train: 100.00%, Valid: 66.60% Test: 68.60%\n",
      "Run: 02, Epoch: 113, Loss: 0.0148, Train: 100.00%, Valid: 66.40% Test: 68.60%\n",
      "Run: 02, Epoch: 114, Loss: 0.0128, Train: 100.00%, Valid: 66.40% Test: 68.70%\n",
      "Run: 02, Epoch: 115, Loss: 0.0070, Train: 100.00%, Valid: 66.40% Test: 68.60%\n",
      "Run: 02, Epoch: 116, Loss: 0.0194, Train: 100.00%, Valid: 66.40% Test: 68.60%\n",
      "Run: 02, Epoch: 117, Loss: 0.0347, Train: 100.00%, Valid: 66.60% Test: 68.60%\n",
      "Run: 02, Epoch: 118, Loss: 0.0103, Train: 100.00%, Valid: 66.60% Test: 68.50%\n",
      "Run: 02, Epoch: 119, Loss: 0.0363, Train: 100.00%, Valid: 66.60% Test: 68.30%\n",
      "Run: 02, Epoch: 120, Loss: 0.0208, Train: 100.00%, Valid: 66.60% Test: 68.10%\n",
      "Run: 02, Epoch: 121, Loss: 0.0119, Train: 100.00%, Valid: 66.60% Test: 67.90%\n",
      "Run: 02, Epoch: 122, Loss: 0.0127, Train: 100.00%, Valid: 66.40% Test: 67.50%\n",
      "Run: 02, Epoch: 123, Loss: 0.0145, Train: 100.00%, Valid: 66.40% Test: 67.50%\n",
      "Run: 02, Epoch: 124, Loss: 0.0028, Train: 100.00%, Valid: 66.00% Test: 67.40%\n",
      "Run: 02, Epoch: 125, Loss: 0.0047, Train: 100.00%, Valid: 66.00% Test: 67.70%\n",
      "Run: 02, Epoch: 126, Loss: 0.0038, Train: 100.00%, Valid: 65.80% Test: 67.70%\n",
      "Run: 02, Epoch: 127, Loss: 0.0185, Train: 100.00%, Valid: 65.80% Test: 67.70%\n",
      "Run: 02, Epoch: 128, Loss: 0.0093, Train: 100.00%, Valid: 65.60% Test: 67.50%\n",
      "Run: 02, Epoch: 129, Loss: 0.0055, Train: 100.00%, Valid: 65.60% Test: 67.50%\n",
      "Run: 02, Epoch: 130, Loss: 0.0017, Train: 100.00%, Valid: 65.60% Test: 67.60%\n",
      "Run: 02, Epoch: 131, Loss: 0.0203, Train: 100.00%, Valid: 65.40% Test: 67.50%\n",
      "Run: 02, Epoch: 132, Loss: 0.0116, Train: 100.00%, Valid: 65.40% Test: 67.50%\n",
      "Run: 02, Epoch: 133, Loss: 0.0189, Train: 100.00%, Valid: 65.60% Test: 67.50%\n",
      "Run: 02, Epoch: 134, Loss: 0.0027, Train: 100.00%, Valid: 65.80% Test: 67.50%\n",
      "Run: 02, Epoch: 135, Loss: 0.0065, Train: 100.00%, Valid: 65.00% Test: 67.40%\n",
      "Run: 02, Epoch: 136, Loss: 0.0175, Train: 100.00%, Valid: 65.00% Test: 67.20%\n",
      "Run: 02, Epoch: 137, Loss: 0.0028, Train: 100.00%, Valid: 65.20% Test: 67.00%\n",
      "Run: 02, Epoch: 138, Loss: 0.0057, Train: 100.00%, Valid: 65.20% Test: 67.10%\n",
      "Run: 02, Epoch: 139, Loss: 0.0088, Train: 100.00%, Valid: 65.20% Test: 67.30%\n",
      "Run: 02, Epoch: 140, Loss: 0.0030, Train: 100.00%, Valid: 65.20% Test: 67.20%\n",
      "Run: 02, Epoch: 141, Loss: 0.0035, Train: 100.00%, Valid: 65.20% Test: 67.10%\n",
      "Run: 02, Epoch: 142, Loss: 0.0233, Train: 100.00%, Valid: 65.20% Test: 67.10%\n",
      "Run: 02, Epoch: 143, Loss: 0.0211, Train: 100.00%, Valid: 65.40% Test: 67.10%\n",
      "Run: 02, Epoch: 144, Loss: 0.0195, Train: 100.00%, Valid: 64.80% Test: 67.10%\n",
      "Run: 02, Epoch: 145, Loss: 0.0096, Train: 100.00%, Valid: 64.80% Test: 67.00%\n",
      "Run: 02, Epoch: 146, Loss: 0.0184, Train: 100.00%, Valid: 64.80% Test: 67.10%\n",
      "Run: 02, Epoch: 147, Loss: 0.0109, Train: 100.00%, Valid: 64.80% Test: 67.20%\n",
      "Run: 02, Epoch: 148, Loss: 0.0076, Train: 100.00%, Valid: 64.80% Test: 67.30%\n",
      "Run: 02, Epoch: 149, Loss: 0.0201, Train: 100.00%, Valid: 65.00% Test: 67.40%\n",
      "Run: 02, Epoch: 150, Loss: 0.0100, Train: 100.00%, Valid: 64.80% Test: 67.30%\n",
      "Run: 02, Epoch: 151, Loss: 0.0133, Train: 100.00%, Valid: 65.00% Test: 67.20%\n",
      "Run: 02, Epoch: 152, Loss: 0.0094, Train: 100.00%, Valid: 65.20% Test: 67.50%\n",
      "Run: 02, Epoch: 153, Loss: 0.0030, Train: 100.00%, Valid: 65.20% Test: 67.50%\n",
      "Run: 02, Epoch: 154, Loss: 0.0058, Train: 100.00%, Valid: 65.00% Test: 67.50%\n",
      "Run: 02, Epoch: 155, Loss: 0.0206, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 02, Epoch: 156, Loss: 0.0228, Train: 100.00%, Valid: 64.80% Test: 67.70%\n",
      "Run: 02, Epoch: 157, Loss: 0.0096, Train: 100.00%, Valid: 65.00% Test: 67.90%\n",
      "Run: 02, Epoch: 158, Loss: 0.0052, Train: 100.00%, Valid: 65.40% Test: 68.20%\n",
      "Run: 02, Epoch: 159, Loss: 0.0089, Train: 100.00%, Valid: 65.40% Test: 68.60%\n",
      "Run: 02, Epoch: 160, Loss: 0.0049, Train: 100.00%, Valid: 65.80% Test: 68.70%\n",
      "Run: 02, Epoch: 161, Loss: 0.0043, Train: 100.00%, Valid: 66.00% Test: 68.70%\n",
      "Run: 02, Epoch: 162, Loss: 0.0035, Train: 100.00%, Valid: 66.00% Test: 68.80%\n",
      "Run: 02, Epoch: 163, Loss: 0.0108, Train: 100.00%, Valid: 66.00% Test: 68.80%\n",
      "Run: 02, Epoch: 164, Loss: 0.0203, Train: 100.00%, Valid: 65.80% Test: 68.60%\n",
      "Run: 02, Epoch: 165, Loss: 0.0056, Train: 100.00%, Valid: 66.00% Test: 68.60%\n",
      "Run: 02, Epoch: 166, Loss: 0.0133, Train: 100.00%, Valid: 66.00% Test: 68.50%\n",
      "Run: 02, Epoch: 167, Loss: 0.0098, Train: 100.00%, Valid: 66.20% Test: 68.50%\n",
      "Run: 02, Epoch: 168, Loss: 0.0157, Train: 100.00%, Valid: 65.60% Test: 68.50%\n",
      "Run: 02, Epoch: 169, Loss: 0.0198, Train: 100.00%, Valid: 65.60% Test: 68.40%\n",
      "Run: 02, Epoch: 170, Loss: 0.0157, Train: 100.00%, Valid: 65.60% Test: 68.20%\n",
      "Run: 02, Epoch: 171, Loss: 0.0042, Train: 100.00%, Valid: 65.80% Test: 67.60%\n",
      "Run: 02, Epoch: 172, Loss: 0.0054, Train: 100.00%, Valid: 65.80% Test: 67.50%\n",
      "Run: 02, Epoch: 173, Loss: 0.0124, Train: 100.00%, Valid: 65.60% Test: 67.40%\n",
      "Run: 02, Epoch: 174, Loss: 0.0050, Train: 100.00%, Valid: 65.40% Test: 67.10%\n",
      "Run: 02, Epoch: 175, Loss: 0.0038, Train: 100.00%, Valid: 65.40% Test: 67.00%\n",
      "Run: 02, Epoch: 176, Loss: 0.0100, Train: 100.00%, Valid: 65.60% Test: 67.00%\n",
      "Run: 02, Epoch: 177, Loss: 0.0084, Train: 100.00%, Valid: 65.40% Test: 66.90%\n",
      "Run: 02, Epoch: 178, Loss: 0.0032, Train: 100.00%, Valid: 65.20% Test: 66.70%\n",
      "Run: 02, Epoch: 179, Loss: 0.0058, Train: 100.00%, Valid: 65.20% Test: 66.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 180, Loss: 0.0380, Train: 100.00%, Valid: 64.80% Test: 66.70%\n",
      "Run: 02, Epoch: 181, Loss: 0.0146, Train: 100.00%, Valid: 64.80% Test: 66.80%\n",
      "Run: 02, Epoch: 182, Loss: 0.0030, Train: 100.00%, Valid: 64.80% Test: 66.80%\n",
      "Run: 02, Epoch: 183, Loss: 0.0097, Train: 100.00%, Valid: 64.80% Test: 66.70%\n",
      "Run: 02, Epoch: 184, Loss: 0.0190, Train: 100.00%, Valid: 64.80% Test: 66.60%\n",
      "Run: 02, Epoch: 185, Loss: 0.0186, Train: 100.00%, Valid: 64.80% Test: 66.30%\n",
      "Run: 02, Epoch: 186, Loss: 0.0035, Train: 100.00%, Valid: 64.60% Test: 66.20%\n",
      "Run: 02, Epoch: 187, Loss: 0.0219, Train: 100.00%, Valid: 64.80% Test: 66.20%\n",
      "Run: 02, Epoch: 188, Loss: 0.0109, Train: 100.00%, Valid: 64.80% Test: 66.20%\n",
      "Run: 02, Epoch: 189, Loss: 0.0061, Train: 100.00%, Valid: 64.80% Test: 66.10%\n",
      "Run: 02, Epoch: 190, Loss: 0.0039, Train: 100.00%, Valid: 64.60% Test: 66.00%\n",
      "Run: 02, Epoch: 191, Loss: 0.0075, Train: 100.00%, Valid: 64.60% Test: 65.90%\n",
      "Run: 02, Epoch: 192, Loss: 0.0056, Train: 100.00%, Valid: 64.60% Test: 65.80%\n",
      "Run: 02, Epoch: 193, Loss: 0.0178, Train: 100.00%, Valid: 64.60% Test: 65.70%\n",
      "Run: 02, Epoch: 194, Loss: 0.0046, Train: 100.00%, Valid: 64.60% Test: 65.50%\n",
      "Run: 02, Epoch: 195, Loss: 0.0077, Train: 100.00%, Valid: 64.60% Test: 65.40%\n",
      "Run: 02, Epoch: 196, Loss: 0.0209, Train: 100.00%, Valid: 64.80% Test: 65.50%\n",
      "Run: 02, Epoch: 197, Loss: 0.0067, Train: 100.00%, Valid: 65.00% Test: 65.10%\n",
      "Run: 02, Epoch: 198, Loss: 0.0063, Train: 100.00%, Valid: 65.00% Test: 65.10%\n",
      "Run: 02, Epoch: 199, Loss: 0.0092, Train: 100.00%, Valid: 65.00% Test: 64.90%\n",
      "Run: 02, Epoch: 200, Loss: 0.0079, Train: 100.00%, Valid: 64.80% Test: 64.90%\n",
      "Run 02:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 75.60\n",
      "  Final Train: 99.29\n",
      "   Final Test: 77.20\n",
      "Run: 03, Epoch: 01, Loss: 2.1836, Train: 68.57%, Valid: 36.00% Test: 40.20%\n",
      "Run: 03, Epoch: 02, Loss: 1.4204, Train: 88.57%, Valid: 57.80% Test: 61.20%\n",
      "Run: 03, Epoch: 03, Loss: 1.0598, Train: 92.14%, Valid: 65.20% Test: 69.30%\n",
      "Run: 03, Epoch: 04, Loss: 0.9053, Train: 96.43%, Valid: 71.00% Test: 73.70%\n",
      "Run: 03, Epoch: 05, Loss: 0.7557, Train: 97.14%, Valid: 72.60% Test: 75.90%\n",
      "Run: 03, Epoch: 06, Loss: 0.5920, Train: 100.00%, Valid: 73.80% Test: 76.90%\n",
      "Run: 03, Epoch: 07, Loss: 0.5160, Train: 100.00%, Valid: 74.20% Test: 76.80%\n",
      "Run: 03, Epoch: 08, Loss: 0.4846, Train: 100.00%, Valid: 74.20% Test: 77.00%\n",
      "Run: 03, Epoch: 09, Loss: 0.4431, Train: 100.00%, Valid: 74.60% Test: 77.90%\n",
      "Run: 03, Epoch: 10, Loss: 0.3524, Train: 100.00%, Valid: 74.00% Test: 78.20%\n",
      "Run: 03, Epoch: 11, Loss: 0.3240, Train: 100.00%, Valid: 74.20% Test: 78.50%\n",
      "Run: 03, Epoch: 12, Loss: 0.2866, Train: 100.00%, Valid: 73.40% Test: 77.80%\n",
      "Run: 03, Epoch: 13, Loss: 0.2764, Train: 100.00%, Valid: 73.60% Test: 76.90%\n",
      "Run: 03, Epoch: 14, Loss: 0.2314, Train: 100.00%, Valid: 73.00% Test: 76.60%\n",
      "Run: 03, Epoch: 15, Loss: 0.2586, Train: 100.00%, Valid: 72.20% Test: 76.40%\n",
      "Run: 03, Epoch: 16, Loss: 0.2285, Train: 100.00%, Valid: 73.00% Test: 76.20%\n",
      "Run: 03, Epoch: 17, Loss: 0.1692, Train: 100.00%, Valid: 72.20% Test: 75.90%\n",
      "Run: 03, Epoch: 18, Loss: 0.1806, Train: 100.00%, Valid: 71.40% Test: 75.70%\n",
      "Run: 03, Epoch: 19, Loss: 0.1835, Train: 100.00%, Valid: 71.00% Test: 75.20%\n",
      "Run: 03, Epoch: 20, Loss: 0.1113, Train: 100.00%, Valid: 70.80% Test: 74.90%\n",
      "Run: 03, Epoch: 21, Loss: 0.1555, Train: 100.00%, Valid: 70.40% Test: 74.40%\n",
      "Run: 03, Epoch: 22, Loss: 0.1209, Train: 100.00%, Valid: 70.20% Test: 74.30%\n",
      "Run: 03, Epoch: 23, Loss: 0.0993, Train: 100.00%, Valid: 70.40% Test: 73.50%\n",
      "Run: 03, Epoch: 24, Loss: 0.0874, Train: 100.00%, Valid: 70.40% Test: 73.10%\n",
      "Run: 03, Epoch: 25, Loss: 0.0843, Train: 100.00%, Valid: 70.60% Test: 72.90%\n",
      "Run: 03, Epoch: 26, Loss: 0.1009, Train: 100.00%, Valid: 70.00% Test: 72.60%\n",
      "Run: 03, Epoch: 27, Loss: 0.0737, Train: 100.00%, Valid: 69.80% Test: 72.50%\n",
      "Run: 03, Epoch: 28, Loss: 0.0641, Train: 100.00%, Valid: 70.20% Test: 72.50%\n",
      "Run: 03, Epoch: 29, Loss: 0.0644, Train: 100.00%, Valid: 70.20% Test: 72.40%\n",
      "Run: 03, Epoch: 30, Loss: 0.0582, Train: 100.00%, Valid: 70.20% Test: 72.10%\n",
      "Run: 03, Epoch: 31, Loss: 0.0669, Train: 100.00%, Valid: 70.00% Test: 71.90%\n",
      "Run: 03, Epoch: 32, Loss: 0.0714, Train: 100.00%, Valid: 69.80% Test: 71.90%\n",
      "Run: 03, Epoch: 33, Loss: 0.0638, Train: 100.00%, Valid: 70.00% Test: 71.80%\n",
      "Run: 03, Epoch: 34, Loss: 0.0416, Train: 100.00%, Valid: 70.00% Test: 71.70%\n",
      "Run: 03, Epoch: 35, Loss: 0.0431, Train: 100.00%, Valid: 70.00% Test: 71.60%\n",
      "Run: 03, Epoch: 36, Loss: 0.0316, Train: 100.00%, Valid: 70.00% Test: 71.40%\n",
      "Run: 03, Epoch: 37, Loss: 0.0395, Train: 100.00%, Valid: 70.00% Test: 71.50%\n",
      "Run: 03, Epoch: 38, Loss: 0.0332, Train: 100.00%, Valid: 70.00% Test: 71.20%\n",
      "Run: 03, Epoch: 39, Loss: 0.0386, Train: 100.00%, Valid: 69.60% Test: 71.30%\n",
      "Run: 03, Epoch: 40, Loss: 0.0433, Train: 100.00%, Valid: 69.40% Test: 71.20%\n",
      "Run: 03, Epoch: 41, Loss: 0.0700, Train: 100.00%, Valid: 69.60% Test: 71.10%\n",
      "Run: 03, Epoch: 42, Loss: 0.0474, Train: 100.00%, Valid: 69.80% Test: 71.10%\n",
      "Run: 03, Epoch: 43, Loss: 0.0315, Train: 100.00%, Valid: 69.80% Test: 71.20%\n",
      "Run: 03, Epoch: 44, Loss: 0.0330, Train: 100.00%, Valid: 69.80% Test: 71.20%\n",
      "Run: 03, Epoch: 45, Loss: 0.0690, Train: 100.00%, Valid: 69.80% Test: 71.00%\n",
      "Run: 03, Epoch: 46, Loss: 0.0198, Train: 100.00%, Valid: 69.80% Test: 70.90%\n",
      "Run: 03, Epoch: 47, Loss: 0.0271, Train: 100.00%, Valid: 69.80% Test: 70.80%\n",
      "Run: 03, Epoch: 48, Loss: 0.0433, Train: 100.00%, Valid: 70.00% Test: 70.80%\n",
      "Run: 03, Epoch: 49, Loss: 0.0321, Train: 100.00%, Valid: 70.00% Test: 70.90%\n",
      "Run: 03, Epoch: 50, Loss: 0.0245, Train: 100.00%, Valid: 69.80% Test: 70.90%\n",
      "Run: 03, Epoch: 51, Loss: 0.0469, Train: 100.00%, Valid: 69.60% Test: 70.90%\n",
      "Run: 03, Epoch: 52, Loss: 0.0382, Train: 100.00%, Valid: 69.20% Test: 70.90%\n",
      "Run: 03, Epoch: 53, Loss: 0.0233, Train: 100.00%, Valid: 69.20% Test: 71.10%\n",
      "Run: 03, Epoch: 54, Loss: 0.0195, Train: 100.00%, Valid: 68.80% Test: 71.20%\n",
      "Run: 03, Epoch: 55, Loss: 0.0371, Train: 100.00%, Valid: 69.00% Test: 71.30%\n",
      "Run: 03, Epoch: 56, Loss: 0.0377, Train: 100.00%, Valid: 69.00% Test: 71.50%\n",
      "Run: 03, Epoch: 57, Loss: 0.0290, Train: 100.00%, Valid: 69.80% Test: 71.70%\n",
      "Run: 03, Epoch: 58, Loss: 0.0400, Train: 100.00%, Valid: 69.60% Test: 71.50%\n",
      "Run: 03, Epoch: 59, Loss: 0.0189, Train: 100.00%, Valid: 69.20% Test: 71.10%\n",
      "Run: 03, Epoch: 60, Loss: 0.0152, Train: 100.00%, Valid: 69.40% Test: 71.00%\n",
      "Run: 03, Epoch: 61, Loss: 0.0333, Train: 100.00%, Valid: 69.60% Test: 71.00%\n",
      "Run: 03, Epoch: 62, Loss: 0.0296, Train: 100.00%, Valid: 69.60% Test: 70.80%\n",
      "Run: 03, Epoch: 63, Loss: 0.0336, Train: 100.00%, Valid: 69.80% Test: 70.80%\n",
      "Run: 03, Epoch: 64, Loss: 0.0370, Train: 100.00%, Valid: 70.00% Test: 70.90%\n",
      "Run: 03, Epoch: 65, Loss: 0.0286, Train: 100.00%, Valid: 69.40% Test: 70.80%\n",
      "Run: 03, Epoch: 66, Loss: 0.0269, Train: 100.00%, Valid: 69.20% Test: 70.80%\n",
      "Run: 03, Epoch: 67, Loss: 0.0240, Train: 100.00%, Valid: 68.60% Test: 70.40%\n",
      "Run: 03, Epoch: 68, Loss: 0.0126, Train: 100.00%, Valid: 68.60% Test: 70.50%\n",
      "Run: 03, Epoch: 69, Loss: 0.0335, Train: 100.00%, Valid: 68.40% Test: 70.70%\n",
      "Run: 03, Epoch: 70, Loss: 0.0288, Train: 100.00%, Valid: 68.80% Test: 70.50%\n",
      "Run: 03, Epoch: 71, Loss: 0.0452, Train: 100.00%, Valid: 68.80% Test: 70.50%\n",
      "Run: 03, Epoch: 72, Loss: 0.0305, Train: 100.00%, Valid: 68.80% Test: 70.80%\n",
      "Run: 03, Epoch: 73, Loss: 0.0310, Train: 100.00%, Valid: 68.80% Test: 70.70%\n",
      "Run: 03, Epoch: 74, Loss: 0.0345, Train: 100.00%, Valid: 68.60% Test: 70.80%\n",
      "Run: 03, Epoch: 75, Loss: 0.0082, Train: 100.00%, Valid: 68.40% Test: 70.80%\n",
      "Run: 03, Epoch: 76, Loss: 0.0093, Train: 100.00%, Valid: 68.40% Test: 70.80%\n",
      "Run: 03, Epoch: 77, Loss: 0.0390, Train: 100.00%, Valid: 68.20% Test: 70.80%\n",
      "Run: 03, Epoch: 78, Loss: 0.0304, Train: 100.00%, Valid: 68.20% Test: 70.60%\n",
      "Run: 03, Epoch: 79, Loss: 0.0194, Train: 100.00%, Valid: 68.00% Test: 70.70%\n",
      "Run: 03, Epoch: 80, Loss: 0.0228, Train: 100.00%, Valid: 68.00% Test: 70.60%\n",
      "Run: 03, Epoch: 81, Loss: 0.0104, Train: 100.00%, Valid: 68.00% Test: 70.70%\n",
      "Run: 03, Epoch: 82, Loss: 0.0114, Train: 100.00%, Valid: 68.00% Test: 70.80%\n",
      "Run: 03, Epoch: 83, Loss: 0.0060, Train: 100.00%, Valid: 68.20% Test: 70.70%\n",
      "Run: 03, Epoch: 84, Loss: 0.0333, Train: 100.00%, Valid: 68.40% Test: 70.70%\n",
      "Run: 03, Epoch: 85, Loss: 0.0275, Train: 100.00%, Valid: 68.60% Test: 70.70%\n",
      "Run: 03, Epoch: 86, Loss: 0.0118, Train: 100.00%, Valid: 68.60% Test: 70.60%\n",
      "Run: 03, Epoch: 87, Loss: 0.0187, Train: 100.00%, Valid: 68.40% Test: 70.70%\n",
      "Run: 03, Epoch: 88, Loss: 0.0114, Train: 100.00%, Valid: 68.40% Test: 70.70%\n",
      "Run: 03, Epoch: 89, Loss: 0.0241, Train: 100.00%, Valid: 68.20% Test: 70.70%\n",
      "Run: 03, Epoch: 90, Loss: 0.0122, Train: 100.00%, Valid: 68.40% Test: 70.70%\n",
      "Run: 03, Epoch: 91, Loss: 0.0394, Train: 100.00%, Valid: 68.40% Test: 70.60%\n",
      "Run: 03, Epoch: 92, Loss: 0.0119, Train: 100.00%, Valid: 68.40% Test: 70.60%\n",
      "Run: 03, Epoch: 93, Loss: 0.0095, Train: 100.00%, Valid: 68.40% Test: 70.60%\n",
      "Run: 03, Epoch: 94, Loss: 0.0375, Train: 100.00%, Valid: 68.40% Test: 70.60%\n",
      "Run: 03, Epoch: 95, Loss: 0.0169, Train: 100.00%, Valid: 68.40% Test: 70.80%\n",
      "Run: 03, Epoch: 96, Loss: 0.0034, Train: 100.00%, Valid: 68.80% Test: 70.30%\n",
      "Run: 03, Epoch: 97, Loss: 0.0311, Train: 100.00%, Valid: 69.00% Test: 70.20%\n",
      "Run: 03, Epoch: 98, Loss: 0.0190, Train: 100.00%, Valid: 69.00% Test: 70.20%\n",
      "Run: 03, Epoch: 99, Loss: 0.0173, Train: 100.00%, Valid: 69.20% Test: 70.10%\n",
      "Run: 03, Epoch: 100, Loss: 0.0081, Train: 100.00%, Valid: 69.20% Test: 70.00%\n",
      "Run: 03, Epoch: 101, Loss: 0.0344, Train: 100.00%, Valid: 68.80% Test: 69.80%\n",
      "Run: 03, Epoch: 102, Loss: 0.0117, Train: 100.00%, Valid: 69.00% Test: 69.80%\n",
      "Run: 03, Epoch: 103, Loss: 0.0076, Train: 100.00%, Valid: 68.60% Test: 69.60%\n",
      "Run: 03, Epoch: 104, Loss: 0.0102, Train: 100.00%, Valid: 68.40% Test: 69.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 105, Loss: 0.0112, Train: 100.00%, Valid: 68.60% Test: 69.50%\n",
      "Run: 03, Epoch: 106, Loss: 0.0055, Train: 100.00%, Valid: 68.60% Test: 69.60%\n",
      "Run: 03, Epoch: 107, Loss: 0.0240, Train: 100.00%, Valid: 68.60% Test: 69.40%\n",
      "Run: 03, Epoch: 108, Loss: 0.0074, Train: 100.00%, Valid: 68.80% Test: 69.30%\n",
      "Run: 03, Epoch: 109, Loss: 0.0101, Train: 100.00%, Valid: 68.60% Test: 69.10%\n",
      "Run: 03, Epoch: 110, Loss: 0.0102, Train: 100.00%, Valid: 68.60% Test: 69.10%\n",
      "Run: 03, Epoch: 111, Loss: 0.0286, Train: 100.00%, Valid: 68.40% Test: 68.90%\n",
      "Run: 03, Epoch: 112, Loss: 0.0122, Train: 100.00%, Valid: 68.60% Test: 69.00%\n",
      "Run: 03, Epoch: 113, Loss: 0.0077, Train: 100.00%, Valid: 68.40% Test: 68.90%\n",
      "Run: 03, Epoch: 114, Loss: 0.0229, Train: 100.00%, Valid: 67.80% Test: 69.10%\n",
      "Run: 03, Epoch: 115, Loss: 0.0342, Train: 100.00%, Valid: 67.60% Test: 69.40%\n",
      "Run: 03, Epoch: 116, Loss: 0.0101, Train: 100.00%, Valid: 67.60% Test: 69.60%\n",
      "Run: 03, Epoch: 117, Loss: 0.0029, Train: 100.00%, Valid: 67.80% Test: 69.50%\n",
      "Run: 03, Epoch: 118, Loss: 0.0134, Train: 100.00%, Valid: 67.80% Test: 69.50%\n",
      "Run: 03, Epoch: 119, Loss: 0.0249, Train: 100.00%, Valid: 68.00% Test: 69.30%\n",
      "Run: 03, Epoch: 120, Loss: 0.0147, Train: 100.00%, Valid: 68.20% Test: 69.30%\n",
      "Run: 03, Epoch: 121, Loss: 0.0045, Train: 100.00%, Valid: 68.00% Test: 69.30%\n",
      "Run: 03, Epoch: 122, Loss: 0.0027, Train: 100.00%, Valid: 68.20% Test: 69.30%\n",
      "Run: 03, Epoch: 123, Loss: 0.0137, Train: 100.00%, Valid: 68.20% Test: 69.00%\n",
      "Run: 03, Epoch: 124, Loss: 0.0141, Train: 100.00%, Valid: 68.20% Test: 69.10%\n",
      "Run: 03, Epoch: 125, Loss: 0.0160, Train: 100.00%, Valid: 68.60% Test: 69.30%\n",
      "Run: 03, Epoch: 126, Loss: 0.0166, Train: 100.00%, Valid: 69.00% Test: 69.40%\n",
      "Run: 03, Epoch: 127, Loss: 0.0026, Train: 100.00%, Valid: 68.80% Test: 69.50%\n",
      "Run: 03, Epoch: 128, Loss: 0.0041, Train: 100.00%, Valid: 68.80% Test: 69.70%\n",
      "Run: 03, Epoch: 129, Loss: 0.0113, Train: 100.00%, Valid: 68.80% Test: 69.90%\n",
      "Run: 03, Epoch: 130, Loss: 0.0068, Train: 100.00%, Valid: 68.80% Test: 69.90%\n",
      "Run: 03, Epoch: 131, Loss: 0.0195, Train: 100.00%, Valid: 68.80% Test: 70.20%\n",
      "Run: 03, Epoch: 132, Loss: 0.0055, Train: 100.00%, Valid: 68.60% Test: 70.30%\n",
      "Run: 03, Epoch: 133, Loss: 0.0330, Train: 100.00%, Valid: 68.60% Test: 70.10%\n",
      "Run: 03, Epoch: 134, Loss: 0.0087, Train: 100.00%, Valid: 68.20% Test: 70.10%\n",
      "Run: 03, Epoch: 135, Loss: 0.0296, Train: 100.00%, Valid: 68.00% Test: 70.10%\n",
      "Run: 03, Epoch: 136, Loss: 0.0045, Train: 100.00%, Valid: 68.00% Test: 70.00%\n",
      "Run: 03, Epoch: 137, Loss: 0.0095, Train: 100.00%, Valid: 68.00% Test: 70.00%\n",
      "Run: 03, Epoch: 138, Loss: 0.0068, Train: 100.00%, Valid: 68.00% Test: 70.20%\n",
      "Run: 03, Epoch: 139, Loss: 0.0143, Train: 100.00%, Valid: 68.20% Test: 70.20%\n",
      "Run: 03, Epoch: 140, Loss: 0.0235, Train: 100.00%, Valid: 67.60% Test: 70.20%\n",
      "Run: 03, Epoch: 141, Loss: 0.0142, Train: 100.00%, Valid: 67.60% Test: 70.20%\n",
      "Run: 03, Epoch: 142, Loss: 0.0158, Train: 100.00%, Valid: 67.40% Test: 70.00%\n",
      "Run: 03, Epoch: 143, Loss: 0.0043, Train: 100.00%, Valid: 67.20% Test: 69.30%\n",
      "Run: 03, Epoch: 144, Loss: 0.0067, Train: 100.00%, Valid: 67.20% Test: 68.80%\n",
      "Run: 03, Epoch: 145, Loss: 0.0047, Train: 100.00%, Valid: 67.20% Test: 68.70%\n",
      "Run: 03, Epoch: 146, Loss: 0.0083, Train: 100.00%, Valid: 67.20% Test: 68.60%\n",
      "Run: 03, Epoch: 147, Loss: 0.0033, Train: 100.00%, Valid: 67.40% Test: 68.30%\n",
      "Run: 03, Epoch: 148, Loss: 0.0129, Train: 100.00%, Valid: 67.20% Test: 68.20%\n",
      "Run: 03, Epoch: 149, Loss: 0.0066, Train: 100.00%, Valid: 67.20% Test: 68.20%\n",
      "Run: 03, Epoch: 150, Loss: 0.0313, Train: 100.00%, Valid: 67.00% Test: 67.90%\n",
      "Run: 03, Epoch: 151, Loss: 0.0035, Train: 100.00%, Valid: 67.20% Test: 67.90%\n",
      "Run: 03, Epoch: 152, Loss: 0.0067, Train: 100.00%, Valid: 67.40% Test: 67.70%\n",
      "Run: 03, Epoch: 153, Loss: 0.0045, Train: 100.00%, Valid: 67.40% Test: 67.90%\n",
      "Run: 03, Epoch: 154, Loss: 0.0066, Train: 100.00%, Valid: 67.80% Test: 68.10%\n",
      "Run: 03, Epoch: 155, Loss: 0.0209, Train: 100.00%, Valid: 67.40% Test: 68.10%\n",
      "Run: 03, Epoch: 156, Loss: 0.0023, Train: 100.00%, Valid: 67.40% Test: 68.10%\n",
      "Run: 03, Epoch: 157, Loss: 0.0037, Train: 100.00%, Valid: 67.40% Test: 68.20%\n",
      "Run: 03, Epoch: 158, Loss: 0.0069, Train: 100.00%, Valid: 67.80% Test: 68.20%\n",
      "Run: 03, Epoch: 159, Loss: 0.0067, Train: 100.00%, Valid: 67.60% Test: 68.00%\n",
      "Run: 03, Epoch: 160, Loss: 0.0036, Train: 100.00%, Valid: 67.40% Test: 67.80%\n",
      "Run: 03, Epoch: 161, Loss: 0.0157, Train: 100.00%, Valid: 67.40% Test: 67.80%\n",
      "Run: 03, Epoch: 162, Loss: 0.0055, Train: 100.00%, Valid: 67.40% Test: 67.80%\n",
      "Run: 03, Epoch: 163, Loss: 0.0097, Train: 100.00%, Valid: 67.40% Test: 67.80%\n",
      "Run: 03, Epoch: 164, Loss: 0.0071, Train: 100.00%, Valid: 67.60% Test: 68.00%\n",
      "Run: 03, Epoch: 165, Loss: 0.0044, Train: 100.00%, Valid: 67.40% Test: 68.10%\n",
      "Run: 03, Epoch: 166, Loss: 0.0031, Train: 100.00%, Valid: 67.40% Test: 68.20%\n",
      "Run: 03, Epoch: 167, Loss: 0.0031, Train: 100.00%, Valid: 67.40% Test: 68.20%\n",
      "Run: 03, Epoch: 168, Loss: 0.0047, Train: 100.00%, Valid: 67.20% Test: 68.30%\n",
      "Run: 03, Epoch: 169, Loss: 0.0060, Train: 100.00%, Valid: 67.60% Test: 68.30%\n",
      "Run: 03, Epoch: 170, Loss: 0.0156, Train: 100.00%, Valid: 67.60% Test: 68.20%\n",
      "Run: 03, Epoch: 171, Loss: 0.0165, Train: 100.00%, Valid: 67.60% Test: 67.90%\n",
      "Run: 03, Epoch: 172, Loss: 0.0061, Train: 100.00%, Valid: 67.60% Test: 68.20%\n",
      "Run: 03, Epoch: 173, Loss: 0.0035, Train: 100.00%, Valid: 67.80% Test: 68.40%\n",
      "Run: 03, Epoch: 174, Loss: 0.0112, Train: 100.00%, Valid: 68.00% Test: 68.40%\n",
      "Run: 03, Epoch: 175, Loss: 0.0024, Train: 100.00%, Valid: 68.00% Test: 68.70%\n",
      "Run: 03, Epoch: 176, Loss: 0.0012, Train: 100.00%, Valid: 68.00% Test: 68.80%\n",
      "Run: 03, Epoch: 177, Loss: 0.0056, Train: 100.00%, Valid: 67.80% Test: 68.80%\n",
      "Run: 03, Epoch: 178, Loss: 0.0252, Train: 100.00%, Valid: 68.00% Test: 68.80%\n",
      "Run: 03, Epoch: 179, Loss: 0.0030, Train: 100.00%, Valid: 68.00% Test: 68.80%\n",
      "Run: 03, Epoch: 180, Loss: 0.0143, Train: 100.00%, Valid: 68.00% Test: 68.90%\n",
      "Run: 03, Epoch: 181, Loss: 0.0238, Train: 100.00%, Valid: 68.20% Test: 69.00%\n",
      "Run: 03, Epoch: 182, Loss: 0.0032, Train: 100.00%, Valid: 67.80% Test: 69.40%\n",
      "Run: 03, Epoch: 183, Loss: 0.0054, Train: 100.00%, Valid: 67.60% Test: 69.30%\n",
      "Run: 03, Epoch: 184, Loss: 0.0055, Train: 100.00%, Valid: 67.60% Test: 69.20%\n",
      "Run: 03, Epoch: 185, Loss: 0.0127, Train: 100.00%, Valid: 68.20% Test: 69.30%\n",
      "Run: 03, Epoch: 186, Loss: 0.0047, Train: 100.00%, Valid: 68.20% Test: 69.20%\n",
      "Run: 03, Epoch: 187, Loss: 0.0049, Train: 100.00%, Valid: 68.20% Test: 69.20%\n",
      "Run: 03, Epoch: 188, Loss: 0.0136, Train: 100.00%, Valid: 68.20% Test: 68.90%\n",
      "Run: 03, Epoch: 189, Loss: 0.0173, Train: 100.00%, Valid: 68.20% Test: 68.80%\n",
      "Run: 03, Epoch: 190, Loss: 0.0043, Train: 100.00%, Valid: 68.20% Test: 68.80%\n",
      "Run: 03, Epoch: 191, Loss: 0.0077, Train: 100.00%, Valid: 68.20% Test: 68.70%\n",
      "Run: 03, Epoch: 192, Loss: 0.0034, Train: 100.00%, Valid: 68.00% Test: 68.60%\n",
      "Run: 03, Epoch: 193, Loss: 0.0047, Train: 100.00%, Valid: 68.00% Test: 68.70%\n",
      "Run: 03, Epoch: 194, Loss: 0.0255, Train: 100.00%, Valid: 68.00% Test: 68.80%\n",
      "Run: 03, Epoch: 195, Loss: 0.0163, Train: 100.00%, Valid: 67.60% Test: 68.70%\n",
      "Run: 03, Epoch: 196, Loss: 0.0031, Train: 100.00%, Valid: 67.40% Test: 68.50%\n",
      "Run: 03, Epoch: 197, Loss: 0.0056, Train: 100.00%, Valid: 67.40% Test: 68.60%\n",
      "Run: 03, Epoch: 198, Loss: 0.0144, Train: 100.00%, Valid: 67.60% Test: 68.30%\n",
      "Run: 03, Epoch: 199, Loss: 0.0196, Train: 100.00%, Valid: 67.40% Test: 68.00%\n",
      "Run: 03, Epoch: 200, Loss: 0.0019, Train: 100.00%, Valid: 67.20% Test: 67.70%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 74.60\n",
      "  Final Train: 100.00\n",
      "   Final Test: 77.90\n",
      "Run: 04, Epoch: 01, Loss: 2.1812, Train: 62.86%, Valid: 31.80% Test: 36.80%\n",
      "Run: 04, Epoch: 02, Loss: 1.2693, Train: 87.14%, Valid: 49.20% Test: 51.10%\n",
      "Run: 04, Epoch: 03, Loss: 0.9326, Train: 93.57%, Valid: 61.60% Test: 63.30%\n",
      "Run: 04, Epoch: 04, Loss: 0.7228, Train: 96.43%, Valid: 67.40% Test: 70.80%\n",
      "Run: 04, Epoch: 05, Loss: 0.5968, Train: 96.43%, Valid: 70.00% Test: 74.20%\n",
      "Run: 04, Epoch: 06, Loss: 0.4533, Train: 99.29%, Valid: 73.20% Test: 75.60%\n",
      "Run: 04, Epoch: 07, Loss: 0.4706, Train: 99.29%, Valid: 73.40% Test: 76.10%\n",
      "Run: 04, Epoch: 08, Loss: 0.3926, Train: 99.29%, Valid: 73.00% Test: 75.80%\n",
      "Run: 04, Epoch: 09, Loss: 0.3417, Train: 99.29%, Valid: 72.00% Test: 75.90%\n",
      "Run: 04, Epoch: 10, Loss: 0.3156, Train: 99.29%, Valid: 71.40% Test: 75.90%\n",
      "Run: 04, Epoch: 11, Loss: 0.2931, Train: 100.00%, Valid: 71.20% Test: 75.50%\n",
      "Run: 04, Epoch: 12, Loss: 0.2476, Train: 100.00%, Valid: 71.60% Test: 75.20%\n",
      "Run: 04, Epoch: 13, Loss: 0.2142, Train: 100.00%, Valid: 71.20% Test: 74.60%\n",
      "Run: 04, Epoch: 14, Loss: 0.2011, Train: 100.00%, Valid: 70.80% Test: 74.30%\n",
      "Run: 04, Epoch: 15, Loss: 0.1388, Train: 100.00%, Valid: 70.40% Test: 73.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 16, Loss: 0.1461, Train: 100.00%, Valid: 69.80% Test: 73.10%\n",
      "Run: 04, Epoch: 17, Loss: 0.1341, Train: 100.00%, Valid: 69.40% Test: 73.00%\n",
      "Run: 04, Epoch: 18, Loss: 0.1076, Train: 100.00%, Valid: 69.60% Test: 72.70%\n",
      "Run: 04, Epoch: 19, Loss: 0.1221, Train: 100.00%, Valid: 69.40% Test: 72.60%\n",
      "Run: 04, Epoch: 20, Loss: 0.1058, Train: 100.00%, Valid: 68.80% Test: 72.40%\n",
      "Run: 04, Epoch: 21, Loss: 0.1055, Train: 100.00%, Valid: 68.80% Test: 72.00%\n",
      "Run: 04, Epoch: 22, Loss: 0.0953, Train: 100.00%, Valid: 68.40% Test: 71.80%\n",
      "Run: 04, Epoch: 23, Loss: 0.0896, Train: 100.00%, Valid: 68.40% Test: 71.20%\n",
      "Run: 04, Epoch: 24, Loss: 0.0927, Train: 100.00%, Valid: 68.20% Test: 71.00%\n",
      "Run: 04, Epoch: 25, Loss: 0.0671, Train: 100.00%, Valid: 68.40% Test: 70.90%\n",
      "Run: 04, Epoch: 26, Loss: 0.0882, Train: 100.00%, Valid: 68.20% Test: 70.70%\n",
      "Run: 04, Epoch: 27, Loss: 0.0713, Train: 100.00%, Valid: 68.00% Test: 70.60%\n",
      "Run: 04, Epoch: 28, Loss: 0.0621, Train: 100.00%, Valid: 67.60% Test: 70.40%\n",
      "Run: 04, Epoch: 29, Loss: 0.0664, Train: 100.00%, Valid: 67.60% Test: 70.20%\n",
      "Run: 04, Epoch: 30, Loss: 0.0551, Train: 100.00%, Valid: 67.60% Test: 70.10%\n",
      "Run: 04, Epoch: 31, Loss: 0.0357, Train: 100.00%, Valid: 67.40% Test: 70.20%\n",
      "Run: 04, Epoch: 32, Loss: 0.0331, Train: 100.00%, Valid: 67.40% Test: 70.10%\n",
      "Run: 04, Epoch: 33, Loss: 0.0372, Train: 100.00%, Valid: 67.40% Test: 70.40%\n",
      "Run: 04, Epoch: 34, Loss: 0.0373, Train: 100.00%, Valid: 67.40% Test: 70.40%\n",
      "Run: 04, Epoch: 35, Loss: 0.0296, Train: 100.00%, Valid: 67.60% Test: 70.20%\n",
      "Run: 04, Epoch: 36, Loss: 0.0414, Train: 100.00%, Valid: 67.60% Test: 69.90%\n",
      "Run: 04, Epoch: 37, Loss: 0.0498, Train: 100.00%, Valid: 67.40% Test: 69.50%\n",
      "Run: 04, Epoch: 38, Loss: 0.0297, Train: 100.00%, Valid: 67.60% Test: 69.50%\n",
      "Run: 04, Epoch: 39, Loss: 0.0428, Train: 100.00%, Valid: 67.80% Test: 69.50%\n",
      "Run: 04, Epoch: 40, Loss: 0.0265, Train: 100.00%, Valid: 68.00% Test: 69.30%\n",
      "Run: 04, Epoch: 41, Loss: 0.0204, Train: 100.00%, Valid: 67.80% Test: 69.10%\n",
      "Run: 04, Epoch: 42, Loss: 0.0242, Train: 100.00%, Valid: 68.00% Test: 69.20%\n",
      "Run: 04, Epoch: 43, Loss: 0.0473, Train: 100.00%, Valid: 68.20% Test: 69.30%\n",
      "Run: 04, Epoch: 44, Loss: 0.0256, Train: 100.00%, Valid: 67.80% Test: 69.30%\n",
      "Run: 04, Epoch: 45, Loss: 0.0359, Train: 100.00%, Valid: 67.20% Test: 69.40%\n",
      "Run: 04, Epoch: 46, Loss: 0.0179, Train: 100.00%, Valid: 67.20% Test: 69.30%\n",
      "Run: 04, Epoch: 47, Loss: 0.0121, Train: 100.00%, Valid: 67.20% Test: 69.40%\n",
      "Run: 04, Epoch: 48, Loss: 0.0312, Train: 100.00%, Valid: 67.00% Test: 69.40%\n",
      "Run: 04, Epoch: 49, Loss: 0.0203, Train: 100.00%, Valid: 66.80% Test: 69.50%\n",
      "Run: 04, Epoch: 50, Loss: 0.0315, Train: 100.00%, Valid: 67.40% Test: 69.60%\n",
      "Run: 04, Epoch: 51, Loss: 0.0210, Train: 100.00%, Valid: 67.60% Test: 69.20%\n",
      "Run: 04, Epoch: 52, Loss: 0.0272, Train: 100.00%, Valid: 67.60% Test: 69.20%\n",
      "Run: 04, Epoch: 53, Loss: 0.0178, Train: 100.00%, Valid: 67.60% Test: 69.20%\n",
      "Run: 04, Epoch: 54, Loss: 0.0387, Train: 100.00%, Valid: 67.40% Test: 69.10%\n",
      "Run: 04, Epoch: 55, Loss: 0.0255, Train: 100.00%, Valid: 67.60% Test: 69.00%\n",
      "Run: 04, Epoch: 56, Loss: 0.0205, Train: 100.00%, Valid: 67.00% Test: 69.10%\n",
      "Run: 04, Epoch: 57, Loss: 0.0127, Train: 100.00%, Valid: 67.00% Test: 69.10%\n",
      "Run: 04, Epoch: 58, Loss: 0.0181, Train: 100.00%, Valid: 67.00% Test: 69.00%\n",
      "Run: 04, Epoch: 59, Loss: 0.0329, Train: 100.00%, Valid: 67.40% Test: 68.90%\n",
      "Run: 04, Epoch: 60, Loss: 0.0205, Train: 100.00%, Valid: 67.60% Test: 68.70%\n",
      "Run: 04, Epoch: 61, Loss: 0.0183, Train: 100.00%, Valid: 67.60% Test: 68.70%\n",
      "Run: 04, Epoch: 62, Loss: 0.0262, Train: 100.00%, Valid: 68.20% Test: 69.00%\n",
      "Run: 04, Epoch: 63, Loss: 0.0317, Train: 100.00%, Valid: 68.00% Test: 68.80%\n",
      "Run: 04, Epoch: 64, Loss: 0.0072, Train: 100.00%, Valid: 67.60% Test: 68.60%\n",
      "Run: 04, Epoch: 65, Loss: 0.0427, Train: 100.00%, Valid: 67.60% Test: 68.70%\n",
      "Run: 04, Epoch: 66, Loss: 0.0168, Train: 100.00%, Valid: 67.60% Test: 68.70%\n",
      "Run: 04, Epoch: 67, Loss: 0.0146, Train: 100.00%, Valid: 67.40% Test: 68.70%\n",
      "Run: 04, Epoch: 68, Loss: 0.0134, Train: 100.00%, Valid: 67.20% Test: 68.70%\n",
      "Run: 04, Epoch: 69, Loss: 0.0078, Train: 100.00%, Valid: 67.60% Test: 68.70%\n",
      "Run: 04, Epoch: 70, Loss: 0.0111, Train: 100.00%, Valid: 67.60% Test: 68.90%\n",
      "Run: 04, Epoch: 71, Loss: 0.0403, Train: 100.00%, Valid: 67.80% Test: 69.10%\n",
      "Run: 04, Epoch: 72, Loss: 0.0245, Train: 100.00%, Valid: 67.60% Test: 69.20%\n",
      "Run: 04, Epoch: 73, Loss: 0.0337, Train: 100.00%, Valid: 67.60% Test: 69.40%\n",
      "Run: 04, Epoch: 74, Loss: 0.0240, Train: 100.00%, Valid: 67.40% Test: 69.50%\n",
      "Run: 04, Epoch: 75, Loss: 0.0136, Train: 100.00%, Valid: 67.80% Test: 69.40%\n",
      "Run: 04, Epoch: 76, Loss: 0.0278, Train: 100.00%, Valid: 67.80% Test: 69.30%\n",
      "Run: 04, Epoch: 77, Loss: 0.0221, Train: 100.00%, Valid: 67.60% Test: 69.40%\n",
      "Run: 04, Epoch: 78, Loss: 0.0443, Train: 100.00%, Valid: 67.80% Test: 69.50%\n",
      "Run: 04, Epoch: 79, Loss: 0.0105, Train: 100.00%, Valid: 67.80% Test: 69.50%\n",
      "Run: 04, Epoch: 80, Loss: 0.0143, Train: 100.00%, Valid: 67.80% Test: 69.40%\n",
      "Run: 04, Epoch: 81, Loss: 0.0121, Train: 100.00%, Valid: 68.20% Test: 69.20%\n",
      "Run: 04, Epoch: 82, Loss: 0.0080, Train: 100.00%, Valid: 68.20% Test: 69.30%\n",
      "Run: 04, Epoch: 83, Loss: 0.0094, Train: 100.00%, Valid: 68.00% Test: 69.20%\n",
      "Run: 04, Epoch: 84, Loss: 0.0160, Train: 100.00%, Valid: 68.00% Test: 69.00%\n",
      "Run: 04, Epoch: 85, Loss: 0.0290, Train: 100.00%, Valid: 68.00% Test: 68.90%\n",
      "Run: 04, Epoch: 86, Loss: 0.0256, Train: 100.00%, Valid: 67.80% Test: 69.10%\n",
      "Run: 04, Epoch: 87, Loss: 0.0260, Train: 100.00%, Valid: 68.00% Test: 68.90%\n",
      "Run: 04, Epoch: 88, Loss: 0.0139, Train: 100.00%, Valid: 67.60% Test: 68.90%\n",
      "Run: 04, Epoch: 89, Loss: 0.0149, Train: 100.00%, Valid: 67.60% Test: 68.90%\n",
      "Run: 04, Epoch: 90, Loss: 0.0129, Train: 100.00%, Valid: 67.40% Test: 68.90%\n",
      "Run: 04, Epoch: 91, Loss: 0.0054, Train: 100.00%, Valid: 67.60% Test: 68.80%\n",
      "Run: 04, Epoch: 92, Loss: 0.0104, Train: 100.00%, Valid: 67.40% Test: 68.50%\n",
      "Run: 04, Epoch: 93, Loss: 0.0120, Train: 100.00%, Valid: 67.80% Test: 68.10%\n",
      "Run: 04, Epoch: 94, Loss: 0.0293, Train: 100.00%, Valid: 67.40% Test: 68.10%\n",
      "Run: 04, Epoch: 95, Loss: 0.0226, Train: 100.00%, Valid: 67.20% Test: 68.00%\n",
      "Run: 04, Epoch: 96, Loss: 0.0132, Train: 100.00%, Valid: 66.80% Test: 67.80%\n",
      "Run: 04, Epoch: 97, Loss: 0.0135, Train: 100.00%, Valid: 66.60% Test: 67.90%\n",
      "Run: 04, Epoch: 98, Loss: 0.0092, Train: 100.00%, Valid: 66.60% Test: 67.90%\n",
      "Run: 04, Epoch: 99, Loss: 0.0048, Train: 100.00%, Valid: 66.60% Test: 67.90%\n",
      "Run: 04, Epoch: 100, Loss: 0.0062, Train: 100.00%, Valid: 66.40% Test: 67.80%\n",
      "Run: 04, Epoch: 101, Loss: 0.0104, Train: 100.00%, Valid: 66.40% Test: 67.80%\n",
      "Run: 04, Epoch: 102, Loss: 0.0062, Train: 100.00%, Valid: 66.40% Test: 67.80%\n",
      "Run: 04, Epoch: 103, Loss: 0.0224, Train: 100.00%, Valid: 66.20% Test: 67.80%\n",
      "Run: 04, Epoch: 104, Loss: 0.0265, Train: 100.00%, Valid: 66.20% Test: 67.60%\n",
      "Run: 04, Epoch: 105, Loss: 0.0057, Train: 100.00%, Valid: 66.40% Test: 67.50%\n",
      "Run: 04, Epoch: 106, Loss: 0.0131, Train: 100.00%, Valid: 66.20% Test: 67.30%\n",
      "Run: 04, Epoch: 107, Loss: 0.0092, Train: 100.00%, Valid: 65.80% Test: 67.20%\n",
      "Run: 04, Epoch: 108, Loss: 0.0063, Train: 100.00%, Valid: 66.00% Test: 67.20%\n",
      "Run: 04, Epoch: 109, Loss: 0.0156, Train: 100.00%, Valid: 66.00% Test: 67.20%\n",
      "Run: 04, Epoch: 110, Loss: 0.0130, Train: 100.00%, Valid: 66.00% Test: 67.30%\n",
      "Run: 04, Epoch: 111, Loss: 0.0088, Train: 100.00%, Valid: 66.00% Test: 67.40%\n",
      "Run: 04, Epoch: 112, Loss: 0.0234, Train: 100.00%, Valid: 66.00% Test: 67.60%\n",
      "Run: 04, Epoch: 113, Loss: 0.0251, Train: 100.00%, Valid: 66.00% Test: 67.80%\n",
      "Run: 04, Epoch: 114, Loss: 0.0133, Train: 100.00%, Valid: 66.20% Test: 67.90%\n",
      "Run: 04, Epoch: 115, Loss: 0.0184, Train: 100.00%, Valid: 66.40% Test: 67.90%\n",
      "Run: 04, Epoch: 116, Loss: 0.0116, Train: 100.00%, Valid: 66.60% Test: 67.80%\n",
      "Run: 04, Epoch: 117, Loss: 0.0051, Train: 100.00%, Valid: 66.80% Test: 68.00%\n",
      "Run: 04, Epoch: 118, Loss: 0.0063, Train: 100.00%, Valid: 67.20% Test: 68.10%\n",
      "Run: 04, Epoch: 119, Loss: 0.0074, Train: 100.00%, Valid: 67.00% Test: 68.40%\n",
      "Run: 04, Epoch: 120, Loss: 0.0052, Train: 100.00%, Valid: 67.00% Test: 68.40%\n",
      "Run: 04, Epoch: 121, Loss: 0.0053, Train: 100.00%, Valid: 66.80% Test: 68.40%\n",
      "Run: 04, Epoch: 122, Loss: 0.0047, Train: 100.00%, Valid: 66.80% Test: 68.50%\n",
      "Run: 04, Epoch: 123, Loss: 0.0246, Train: 100.00%, Valid: 67.00% Test: 68.60%\n",
      "Run: 04, Epoch: 124, Loss: 0.0115, Train: 100.00%, Valid: 66.80% Test: 68.60%\n",
      "Run: 04, Epoch: 125, Loss: 0.0091, Train: 100.00%, Valid: 66.80% Test: 68.90%\n",
      "Run: 04, Epoch: 126, Loss: 0.0381, Train: 100.00%, Valid: 66.80% Test: 69.10%\n",
      "Run: 04, Epoch: 127, Loss: 0.0210, Train: 100.00%, Valid: 66.80% Test: 69.10%\n",
      "Run: 04, Epoch: 128, Loss: 0.0074, Train: 100.00%, Valid: 66.80% Test: 69.00%\n",
      "Run: 04, Epoch: 129, Loss: 0.0089, Train: 100.00%, Valid: 66.20% Test: 68.80%\n",
      "Run: 04, Epoch: 130, Loss: 0.0046, Train: 100.00%, Valid: 66.20% Test: 68.60%\n",
      "Run: 04, Epoch: 131, Loss: 0.0139, Train: 100.00%, Valid: 66.00% Test: 68.50%\n",
      "Run: 04, Epoch: 132, Loss: 0.0105, Train: 100.00%, Valid: 66.00% Test: 68.50%\n",
      "Run: 04, Epoch: 133, Loss: 0.0196, Train: 100.00%, Valid: 65.20% Test: 68.40%\n",
      "Run: 04, Epoch: 134, Loss: 0.0055, Train: 100.00%, Valid: 65.40% Test: 68.50%\n",
      "Run: 04, Epoch: 135, Loss: 0.0127, Train: 100.00%, Valid: 65.20% Test: 68.50%\n",
      "Run: 04, Epoch: 136, Loss: 0.0162, Train: 100.00%, Valid: 65.20% Test: 68.50%\n",
      "Run: 04, Epoch: 137, Loss: 0.0186, Train: 100.00%, Valid: 65.40% Test: 68.30%\n",
      "Run: 04, Epoch: 138, Loss: 0.0055, Train: 100.00%, Valid: 65.40% Test: 68.30%\n",
      "Run: 04, Epoch: 139, Loss: 0.0137, Train: 100.00%, Valid: 65.20% Test: 68.20%\n",
      "Run: 04, Epoch: 140, Loss: 0.0253, Train: 100.00%, Valid: 65.40% Test: 68.30%\n",
      "Run: 04, Epoch: 141, Loss: 0.0264, Train: 100.00%, Valid: 65.40% Test: 68.20%\n",
      "Run: 04, Epoch: 142, Loss: 0.0115, Train: 100.00%, Valid: 65.80% Test: 68.10%\n",
      "Run: 04, Epoch: 143, Loss: 0.0093, Train: 100.00%, Valid: 65.80% Test: 68.00%\n",
      "Run: 04, Epoch: 144, Loss: 0.0155, Train: 100.00%, Valid: 65.60% Test: 68.20%\n",
      "Run: 04, Epoch: 145, Loss: 0.0091, Train: 100.00%, Valid: 65.80% Test: 67.90%\n",
      "Run: 04, Epoch: 146, Loss: 0.0127, Train: 100.00%, Valid: 65.80% Test: 68.00%\n",
      "Run: 04, Epoch: 147, Loss: 0.0062, Train: 100.00%, Valid: 65.80% Test: 67.90%\n",
      "Run: 04, Epoch: 148, Loss: 0.0146, Train: 100.00%, Valid: 65.60% Test: 67.90%\n",
      "Run: 04, Epoch: 149, Loss: 0.0096, Train: 100.00%, Valid: 65.60% Test: 68.00%\n",
      "Run: 04, Epoch: 150, Loss: 0.0118, Train: 100.00%, Valid: 65.40% Test: 68.00%\n",
      "Run: 04, Epoch: 151, Loss: 0.0018, Train: 100.00%, Valid: 65.20% Test: 68.20%\n",
      "Run: 04, Epoch: 152, Loss: 0.0142, Train: 100.00%, Valid: 65.40% Test: 68.30%\n",
      "Run: 04, Epoch: 153, Loss: 0.0072, Train: 100.00%, Valid: 65.40% Test: 68.30%\n",
      "Run: 04, Epoch: 154, Loss: 0.0039, Train: 100.00%, Valid: 65.20% Test: 68.20%\n",
      "Run: 04, Epoch: 155, Loss: 0.0146, Train: 100.00%, Valid: 65.20% Test: 68.10%\n",
      "Run: 04, Epoch: 156, Loss: 0.0062, Train: 100.00%, Valid: 65.20% Test: 67.90%\n",
      "Run: 04, Epoch: 157, Loss: 0.0166, Train: 100.00%, Valid: 65.20% Test: 68.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 158, Loss: 0.0173, Train: 100.00%, Valid: 64.80% Test: 67.90%\n",
      "Run: 04, Epoch: 159, Loss: 0.0044, Train: 100.00%, Valid: 65.20% Test: 68.10%\n",
      "Run: 04, Epoch: 160, Loss: 0.0132, Train: 100.00%, Valid: 65.00% Test: 68.20%\n",
      "Run: 04, Epoch: 161, Loss: 0.0079, Train: 100.00%, Valid: 65.00% Test: 68.10%\n",
      "Run: 04, Epoch: 162, Loss: 0.0145, Train: 100.00%, Valid: 65.40% Test: 68.00%\n",
      "Run: 04, Epoch: 163, Loss: 0.0104, Train: 100.00%, Valid: 65.80% Test: 68.00%\n",
      "Run: 04, Epoch: 164, Loss: 0.0105, Train: 100.00%, Valid: 65.80% Test: 68.10%\n",
      "Run: 04, Epoch: 165, Loss: 0.0366, Train: 100.00%, Valid: 65.80% Test: 68.00%\n",
      "Run: 04, Epoch: 166, Loss: 0.0052, Train: 100.00%, Valid: 65.60% Test: 67.90%\n",
      "Run: 04, Epoch: 167, Loss: 0.0128, Train: 100.00%, Valid: 65.60% Test: 67.90%\n",
      "Run: 04, Epoch: 168, Loss: 0.0082, Train: 100.00%, Valid: 65.60% Test: 67.90%\n",
      "Run: 04, Epoch: 169, Loss: 0.0068, Train: 100.00%, Valid: 65.80% Test: 67.90%\n",
      "Run: 04, Epoch: 170, Loss: 0.0018, Train: 100.00%, Valid: 65.60% Test: 67.90%\n",
      "Run: 04, Epoch: 171, Loss: 0.0028, Train: 100.00%, Valid: 65.20% Test: 67.70%\n",
      "Run: 04, Epoch: 172, Loss: 0.0032, Train: 100.00%, Valid: 65.40% Test: 67.70%\n",
      "Run: 04, Epoch: 173, Loss: 0.0063, Train: 100.00%, Valid: 65.20% Test: 67.70%\n",
      "Run: 04, Epoch: 174, Loss: 0.0028, Train: 100.00%, Valid: 65.20% Test: 67.70%\n",
      "Run: 04, Epoch: 175, Loss: 0.0030, Train: 100.00%, Valid: 65.20% Test: 67.80%\n",
      "Run: 04, Epoch: 176, Loss: 0.0140, Train: 100.00%, Valid: 65.20% Test: 67.90%\n",
      "Run: 04, Epoch: 177, Loss: 0.0080, Train: 100.00%, Valid: 65.60% Test: 67.80%\n",
      "Run: 04, Epoch: 178, Loss: 0.0067, Train: 100.00%, Valid: 65.60% Test: 67.80%\n",
      "Run: 04, Epoch: 179, Loss: 0.0083, Train: 100.00%, Valid: 65.60% Test: 67.80%\n",
      "Run: 04, Epoch: 180, Loss: 0.0059, Train: 100.00%, Valid: 65.80% Test: 67.60%\n",
      "Run: 04, Epoch: 181, Loss: 0.0089, Train: 100.00%, Valid: 65.80% Test: 67.50%\n",
      "Run: 04, Epoch: 182, Loss: 0.0062, Train: 100.00%, Valid: 65.80% Test: 67.50%\n",
      "Run: 04, Epoch: 183, Loss: 0.0085, Train: 100.00%, Valid: 66.00% Test: 67.50%\n",
      "Run: 04, Epoch: 184, Loss: 0.0042, Train: 100.00%, Valid: 66.20% Test: 67.50%\n",
      "Run: 04, Epoch: 185, Loss: 0.0033, Train: 100.00%, Valid: 66.20% Test: 67.50%\n",
      "Run: 04, Epoch: 186, Loss: 0.0110, Train: 100.00%, Valid: 66.20% Test: 67.50%\n",
      "Run: 04, Epoch: 187, Loss: 0.0035, Train: 100.00%, Valid: 66.00% Test: 67.70%\n",
      "Run: 04, Epoch: 188, Loss: 0.0040, Train: 100.00%, Valid: 66.00% Test: 67.60%\n",
      "Run: 04, Epoch: 189, Loss: 0.0044, Train: 100.00%, Valid: 65.80% Test: 67.60%\n",
      "Run: 04, Epoch: 190, Loss: 0.0019, Train: 100.00%, Valid: 66.00% Test: 67.60%\n",
      "Run: 04, Epoch: 191, Loss: 0.0111, Train: 100.00%, Valid: 66.20% Test: 67.80%\n",
      "Run: 04, Epoch: 192, Loss: 0.0078, Train: 100.00%, Valid: 66.00% Test: 67.70%\n",
      "Run: 04, Epoch: 193, Loss: 0.0126, Train: 100.00%, Valid: 66.00% Test: 67.80%\n",
      "Run: 04, Epoch: 194, Loss: 0.0064, Train: 100.00%, Valid: 65.80% Test: 67.70%\n",
      "Run: 04, Epoch: 195, Loss: 0.0039, Train: 100.00%, Valid: 65.80% Test: 67.70%\n",
      "Run: 04, Epoch: 196, Loss: 0.0146, Train: 100.00%, Valid: 65.40% Test: 67.50%\n",
      "Run: 04, Epoch: 197, Loss: 0.0005, Train: 100.00%, Valid: 65.40% Test: 67.30%\n",
      "Run: 04, Epoch: 198, Loss: 0.0044, Train: 100.00%, Valid: 65.60% Test: 67.20%\n",
      "Run: 04, Epoch: 199, Loss: 0.0252, Train: 100.00%, Valid: 65.60% Test: 67.20%\n",
      "Run: 04, Epoch: 200, Loss: 0.0071, Train: 100.00%, Valid: 65.80% Test: 67.20%\n",
      "Run 04:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.40\n",
      "  Final Train: 99.29\n",
      "   Final Test: 76.10\n",
      "Run: 05, Epoch: 01, Loss: 2.1514, Train: 66.43%, Valid: 37.60% Test: 39.00%\n",
      "Run: 05, Epoch: 02, Loss: 1.2491, Train: 74.29%, Valid: 47.40% Test: 50.30%\n",
      "Run: 05, Epoch: 03, Loss: 0.9933, Train: 79.29%, Valid: 52.00% Test: 55.50%\n",
      "Run: 05, Epoch: 04, Loss: 0.8204, Train: 82.86%, Valid: 54.00% Test: 58.70%\n",
      "Run: 05, Epoch: 05, Loss: 0.6695, Train: 87.14%, Valid: 60.00% Test: 65.10%\n",
      "Run: 05, Epoch: 06, Loss: 0.6215, Train: 92.86%, Valid: 65.00% Test: 68.00%\n",
      "Run: 05, Epoch: 07, Loss: 0.5547, Train: 96.43%, Valid: 67.80% Test: 69.60%\n",
      "Run: 05, Epoch: 08, Loss: 0.4722, Train: 98.57%, Valid: 69.20% Test: 71.00%\n",
      "Run: 05, Epoch: 09, Loss: 0.4115, Train: 99.29%, Valid: 69.20% Test: 72.00%\n",
      "Run: 05, Epoch: 10, Loss: 0.3665, Train: 99.29%, Valid: 70.20% Test: 71.90%\n",
      "Run: 05, Epoch: 11, Loss: 0.3401, Train: 99.29%, Valid: 70.00% Test: 71.50%\n",
      "Run: 05, Epoch: 12, Loss: 0.2991, Train: 99.29%, Valid: 69.80% Test: 71.50%\n",
      "Run: 05, Epoch: 13, Loss: 0.2765, Train: 100.00%, Valid: 69.40% Test: 70.70%\n",
      "Run: 05, Epoch: 14, Loss: 0.2586, Train: 100.00%, Valid: 69.40% Test: 70.00%\n",
      "Run: 05, Epoch: 15, Loss: 0.2207, Train: 100.00%, Valid: 68.80% Test: 69.30%\n",
      "Run: 05, Epoch: 16, Loss: 0.1884, Train: 100.00%, Valid: 68.60% Test: 69.40%\n",
      "Run: 05, Epoch: 17, Loss: 0.1776, Train: 100.00%, Valid: 68.20% Test: 68.80%\n",
      "Run: 05, Epoch: 18, Loss: 0.1316, Train: 100.00%, Valid: 68.80% Test: 68.20%\n",
      "Run: 05, Epoch: 19, Loss: 0.1371, Train: 100.00%, Valid: 68.20% Test: 68.50%\n",
      "Run: 05, Epoch: 20, Loss: 0.1202, Train: 100.00%, Valid: 67.80% Test: 69.00%\n",
      "Run: 05, Epoch: 21, Loss: 0.1004, Train: 100.00%, Valid: 68.20% Test: 68.70%\n",
      "Run: 05, Epoch: 22, Loss: 0.0783, Train: 100.00%, Valid: 68.60% Test: 68.80%\n",
      "Run: 05, Epoch: 23, Loss: 0.1057, Train: 100.00%, Valid: 68.80% Test: 69.10%\n",
      "Run: 05, Epoch: 24, Loss: 0.0751, Train: 100.00%, Valid: 68.80% Test: 69.10%\n",
      "Run: 05, Epoch: 25, Loss: 0.0988, Train: 100.00%, Valid: 68.80% Test: 69.40%\n",
      "Run: 05, Epoch: 26, Loss: 0.0573, Train: 100.00%, Valid: 69.00% Test: 69.40%\n",
      "Run: 05, Epoch: 27, Loss: 0.0480, Train: 100.00%, Valid: 68.60% Test: 69.30%\n",
      "Run: 05, Epoch: 28, Loss: 0.0657, Train: 100.00%, Valid: 68.60% Test: 69.80%\n",
      "Run: 05, Epoch: 29, Loss: 0.0538, Train: 100.00%, Valid: 69.20% Test: 69.80%\n",
      "Run: 05, Epoch: 30, Loss: 0.0606, Train: 100.00%, Valid: 69.00% Test: 69.50%\n",
      "Run: 05, Epoch: 31, Loss: 0.0590, Train: 100.00%, Valid: 68.60% Test: 69.20%\n",
      "Run: 05, Epoch: 32, Loss: 0.0317, Train: 100.00%, Valid: 69.00% Test: 69.10%\n",
      "Run: 05, Epoch: 33, Loss: 0.0650, Train: 100.00%, Valid: 68.60% Test: 68.90%\n",
      "Run: 05, Epoch: 34, Loss: 0.0375, Train: 100.00%, Valid: 68.60% Test: 69.00%\n",
      "Run: 05, Epoch: 35, Loss: 0.0295, Train: 100.00%, Valid: 68.20% Test: 69.00%\n",
      "Run: 05, Epoch: 36, Loss: 0.0616, Train: 100.00%, Valid: 68.00% Test: 69.10%\n",
      "Run: 05, Epoch: 37, Loss: 0.0493, Train: 100.00%, Valid: 67.80% Test: 69.00%\n",
      "Run: 05, Epoch: 38, Loss: 0.0404, Train: 100.00%, Valid: 67.40% Test: 68.90%\n",
      "Run: 05, Epoch: 39, Loss: 0.0529, Train: 100.00%, Valid: 67.40% Test: 68.70%\n",
      "Run: 05, Epoch: 40, Loss: 0.0292, Train: 100.00%, Valid: 67.20% Test: 68.50%\n",
      "Run: 05, Epoch: 41, Loss: 0.0386, Train: 100.00%, Valid: 67.40% Test: 68.40%\n",
      "Run: 05, Epoch: 42, Loss: 0.0377, Train: 100.00%, Valid: 67.40% Test: 68.30%\n",
      "Run: 05, Epoch: 43, Loss: 0.0282, Train: 100.00%, Valid: 67.60% Test: 68.10%\n",
      "Run: 05, Epoch: 44, Loss: 0.0216, Train: 100.00%, Valid: 67.40% Test: 68.10%\n",
      "Run: 05, Epoch: 45, Loss: 0.0169, Train: 100.00%, Valid: 67.60% Test: 68.10%\n",
      "Run: 05, Epoch: 46, Loss: 0.0206, Train: 100.00%, Valid: 67.60% Test: 68.10%\n",
      "Run: 05, Epoch: 47, Loss: 0.0188, Train: 100.00%, Valid: 67.40% Test: 68.20%\n",
      "Run: 05, Epoch: 48, Loss: 0.0337, Train: 100.00%, Valid: 67.40% Test: 68.00%\n",
      "Run: 05, Epoch: 49, Loss: 0.0331, Train: 100.00%, Valid: 67.40% Test: 68.00%\n",
      "Run: 05, Epoch: 50, Loss: 0.0151, Train: 100.00%, Valid: 67.60% Test: 67.90%\n",
      "Run: 05, Epoch: 51, Loss: 0.0239, Train: 100.00%, Valid: 67.20% Test: 67.90%\n",
      "Run: 05, Epoch: 52, Loss: 0.0184, Train: 100.00%, Valid: 67.20% Test: 68.10%\n",
      "Run: 05, Epoch: 53, Loss: 0.0239, Train: 100.00%, Valid: 67.20% Test: 68.10%\n",
      "Run: 05, Epoch: 54, Loss: 0.0243, Train: 100.00%, Valid: 67.20% Test: 68.10%\n",
      "Run: 05, Epoch: 55, Loss: 0.0147, Train: 100.00%, Valid: 67.00% Test: 68.00%\n",
      "Run: 05, Epoch: 56, Loss: 0.0126, Train: 100.00%, Valid: 67.00% Test: 67.90%\n",
      "Run: 05, Epoch: 57, Loss: 0.0194, Train: 100.00%, Valid: 66.80% Test: 67.90%\n",
      "Run: 05, Epoch: 58, Loss: 0.0581, Train: 100.00%, Valid: 66.80% Test: 67.90%\n",
      "Run: 05, Epoch: 59, Loss: 0.0239, Train: 100.00%, Valid: 66.80% Test: 67.90%\n",
      "Run: 05, Epoch: 60, Loss: 0.0278, Train: 100.00%, Valid: 67.00% Test: 68.00%\n",
      "Run: 05, Epoch: 61, Loss: 0.0178, Train: 100.00%, Valid: 67.00% Test: 68.10%\n",
      "Run: 05, Epoch: 62, Loss: 0.0125, Train: 100.00%, Valid: 66.80% Test: 67.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 63, Loss: 0.0151, Train: 100.00%, Valid: 66.80% Test: 67.80%\n",
      "Run: 05, Epoch: 64, Loss: 0.0146, Train: 100.00%, Valid: 66.00% Test: 67.70%\n",
      "Run: 05, Epoch: 65, Loss: 0.0143, Train: 100.00%, Valid: 65.80% Test: 67.70%\n",
      "Run: 05, Epoch: 66, Loss: 0.0149, Train: 100.00%, Valid: 65.80% Test: 67.80%\n",
      "Run: 05, Epoch: 67, Loss: 0.0220, Train: 100.00%, Valid: 65.80% Test: 67.70%\n",
      "Run: 05, Epoch: 68, Loss: 0.0152, Train: 100.00%, Valid: 65.80% Test: 67.60%\n",
      "Run: 05, Epoch: 69, Loss: 0.0304, Train: 100.00%, Valid: 65.20% Test: 67.50%\n",
      "Run: 05, Epoch: 70, Loss: 0.0108, Train: 100.00%, Valid: 65.20% Test: 67.70%\n",
      "Run: 05, Epoch: 71, Loss: 0.0157, Train: 100.00%, Valid: 65.20% Test: 67.70%\n",
      "Run: 05, Epoch: 72, Loss: 0.0198, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 05, Epoch: 73, Loss: 0.0218, Train: 100.00%, Valid: 65.00% Test: 67.50%\n",
      "Run: 05, Epoch: 74, Loss: 0.0160, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 05, Epoch: 75, Loss: 0.0127, Train: 100.00%, Valid: 65.00% Test: 67.30%\n",
      "Run: 05, Epoch: 76, Loss: 0.0167, Train: 100.00%, Valid: 64.80% Test: 67.30%\n",
      "Run: 05, Epoch: 77, Loss: 0.0147, Train: 100.00%, Valid: 64.80% Test: 67.20%\n",
      "Run: 05, Epoch: 78, Loss: 0.0117, Train: 100.00%, Valid: 64.80% Test: 67.20%\n",
      "Run: 05, Epoch: 79, Loss: 0.0103, Train: 100.00%, Valid: 64.80% Test: 67.20%\n",
      "Run: 05, Epoch: 80, Loss: 0.0124, Train: 100.00%, Valid: 64.60% Test: 67.20%\n",
      "Run: 05, Epoch: 81, Loss: 0.0301, Train: 100.00%, Valid: 64.80% Test: 67.10%\n",
      "Run: 05, Epoch: 82, Loss: 0.0052, Train: 100.00%, Valid: 64.80% Test: 67.10%\n",
      "Run: 05, Epoch: 83, Loss: 0.0266, Train: 100.00%, Valid: 65.20% Test: 67.40%\n",
      "Run: 05, Epoch: 84, Loss: 0.0218, Train: 100.00%, Valid: 65.00% Test: 67.40%\n",
      "Run: 05, Epoch: 85, Loss: 0.0131, Train: 100.00%, Valid: 65.20% Test: 67.60%\n",
      "Run: 05, Epoch: 86, Loss: 0.0144, Train: 100.00%, Valid: 65.20% Test: 67.50%\n",
      "Run: 05, Epoch: 87, Loss: 0.0186, Train: 100.00%, Valid: 65.20% Test: 67.30%\n",
      "Run: 05, Epoch: 88, Loss: 0.0070, Train: 100.00%, Valid: 65.20% Test: 67.30%\n",
      "Run: 05, Epoch: 89, Loss: 0.0061, Train: 100.00%, Valid: 65.20% Test: 67.30%\n",
      "Run: 05, Epoch: 90, Loss: 0.0176, Train: 100.00%, Valid: 65.20% Test: 67.30%\n",
      "Run: 05, Epoch: 91, Loss: 0.0249, Train: 100.00%, Valid: 64.80% Test: 66.90%\n",
      "Run: 05, Epoch: 92, Loss: 0.0105, Train: 100.00%, Valid: 64.60% Test: 66.60%\n",
      "Run: 05, Epoch: 93, Loss: 0.0161, Train: 100.00%, Valid: 64.80% Test: 66.50%\n",
      "Run: 05, Epoch: 94, Loss: 0.0179, Train: 100.00%, Valid: 64.60% Test: 66.50%\n",
      "Run: 05, Epoch: 95, Loss: 0.0089, Train: 100.00%, Valid: 64.60% Test: 66.50%\n",
      "Run: 05, Epoch: 96, Loss: 0.0077, Train: 100.00%, Valid: 64.60% Test: 66.50%\n",
      "Run: 05, Epoch: 97, Loss: 0.0110, Train: 100.00%, Valid: 64.80% Test: 66.20%\n",
      "Run: 05, Epoch: 98, Loss: 0.0152, Train: 100.00%, Valid: 64.60% Test: 66.00%\n",
      "Run: 05, Epoch: 99, Loss: 0.0086, Train: 100.00%, Valid: 64.60% Test: 66.00%\n",
      "Run: 05, Epoch: 100, Loss: 0.0083, Train: 100.00%, Valid: 64.60% Test: 65.90%\n",
      "Run: 05, Epoch: 101, Loss: 0.0046, Train: 100.00%, Valid: 64.60% Test: 66.00%\n",
      "Run: 05, Epoch: 102, Loss: 0.0219, Train: 100.00%, Valid: 64.60% Test: 65.90%\n",
      "Run: 05, Epoch: 103, Loss: 0.0032, Train: 100.00%, Valid: 64.60% Test: 66.00%\n",
      "Run: 05, Epoch: 104, Loss: 0.0102, Train: 100.00%, Valid: 64.40% Test: 66.00%\n",
      "Run: 05, Epoch: 105, Loss: 0.0164, Train: 100.00%, Valid: 64.60% Test: 66.00%\n",
      "Run: 05, Epoch: 106, Loss: 0.0101, Train: 100.00%, Valid: 64.60% Test: 66.00%\n",
      "Run: 05, Epoch: 107, Loss: 0.0066, Train: 100.00%, Valid: 64.60% Test: 65.80%\n",
      "Run: 05, Epoch: 108, Loss: 0.0108, Train: 100.00%, Valid: 64.60% Test: 65.90%\n",
      "Run: 05, Epoch: 109, Loss: 0.0048, Train: 100.00%, Valid: 64.40% Test: 66.00%\n",
      "Run: 05, Epoch: 110, Loss: 0.0207, Train: 100.00%, Valid: 64.40% Test: 66.00%\n",
      "Run: 05, Epoch: 111, Loss: 0.0131, Train: 100.00%, Valid: 64.60% Test: 66.10%\n",
      "Run: 05, Epoch: 112, Loss: 0.0122, Train: 100.00%, Valid: 64.60% Test: 66.10%\n",
      "Run: 05, Epoch: 113, Loss: 0.0117, Train: 100.00%, Valid: 64.60% Test: 66.10%\n",
      "Run: 05, Epoch: 114, Loss: 0.0097, Train: 100.00%, Valid: 64.80% Test: 66.10%\n",
      "Run: 05, Epoch: 115, Loss: 0.0033, Train: 100.00%, Valid: 64.80% Test: 66.30%\n",
      "Run: 05, Epoch: 116, Loss: 0.0041, Train: 100.00%, Valid: 64.60% Test: 66.20%\n",
      "Run: 05, Epoch: 117, Loss: 0.0136, Train: 100.00%, Valid: 64.60% Test: 66.30%\n",
      "Run: 05, Epoch: 118, Loss: 0.0108, Train: 100.00%, Valid: 64.60% Test: 66.30%\n",
      "Run: 05, Epoch: 119, Loss: 0.0089, Train: 100.00%, Valid: 64.60% Test: 66.30%\n",
      "Run: 05, Epoch: 120, Loss: 0.0138, Train: 100.00%, Valid: 64.60% Test: 66.30%\n",
      "Run: 05, Epoch: 121, Loss: 0.0089, Train: 100.00%, Valid: 64.60% Test: 66.30%\n",
      "Run: 05, Epoch: 122, Loss: 0.0248, Train: 100.00%, Valid: 65.20% Test: 66.50%\n",
      "Run: 05, Epoch: 123, Loss: 0.0067, Train: 100.00%, Valid: 65.20% Test: 66.50%\n",
      "Run: 05, Epoch: 124, Loss: 0.0172, Train: 100.00%, Valid: 65.20% Test: 66.50%\n",
      "Run: 05, Epoch: 125, Loss: 0.0230, Train: 100.00%, Valid: 65.20% Test: 66.40%\n",
      "Run: 05, Epoch: 126, Loss: 0.0093, Train: 100.00%, Valid: 65.20% Test: 66.40%\n",
      "Run: 05, Epoch: 127, Loss: 0.0055, Train: 100.00%, Valid: 65.20% Test: 66.40%\n",
      "Run: 05, Epoch: 128, Loss: 0.0142, Train: 100.00%, Valid: 65.20% Test: 66.20%\n",
      "Run: 05, Epoch: 129, Loss: 0.0088, Train: 100.00%, Valid: 65.00% Test: 66.20%\n",
      "Run: 05, Epoch: 130, Loss: 0.0082, Train: 100.00%, Valid: 65.00% Test: 66.10%\n",
      "Run: 05, Epoch: 131, Loss: 0.0071, Train: 100.00%, Valid: 64.60% Test: 66.00%\n",
      "Run: 05, Epoch: 132, Loss: 0.0117, Train: 100.00%, Valid: 64.80% Test: 66.00%\n",
      "Run: 05, Epoch: 133, Loss: 0.0087, Train: 100.00%, Valid: 64.60% Test: 65.90%\n",
      "Run: 05, Epoch: 134, Loss: 0.0032, Train: 100.00%, Valid: 64.60% Test: 65.90%\n",
      "Run: 05, Epoch: 135, Loss: 0.0097, Train: 100.00%, Valid: 64.60% Test: 65.80%\n",
      "Run: 05, Epoch: 136, Loss: 0.0070, Train: 100.00%, Valid: 64.80% Test: 65.70%\n",
      "Run: 05, Epoch: 137, Loss: 0.0048, Train: 100.00%, Valid: 64.80% Test: 65.60%\n",
      "Run: 05, Epoch: 138, Loss: 0.0109, Train: 100.00%, Valid: 64.80% Test: 65.60%\n",
      "Run: 05, Epoch: 139, Loss: 0.0056, Train: 100.00%, Valid: 64.80% Test: 65.60%\n",
      "Run: 05, Epoch: 140, Loss: 0.0230, Train: 100.00%, Valid: 65.00% Test: 65.70%\n",
      "Run: 05, Epoch: 141, Loss: 0.0047, Train: 100.00%, Valid: 64.60% Test: 65.60%\n",
      "Run: 05, Epoch: 142, Loss: 0.0084, Train: 100.00%, Valid: 64.80% Test: 65.60%\n",
      "Run: 05, Epoch: 143, Loss: 0.0217, Train: 100.00%, Valid: 64.60% Test: 65.70%\n",
      "Run: 05, Epoch: 144, Loss: 0.0114, Train: 100.00%, Valid: 64.80% Test: 65.80%\n",
      "Run: 05, Epoch: 145, Loss: 0.0203, Train: 100.00%, Valid: 64.60% Test: 66.00%\n",
      "Run: 05, Epoch: 146, Loss: 0.0023, Train: 100.00%, Valid: 64.80% Test: 66.00%\n",
      "Run: 05, Epoch: 147, Loss: 0.0064, Train: 100.00%, Valid: 64.80% Test: 65.80%\n",
      "Run: 05, Epoch: 148, Loss: 0.0180, Train: 100.00%, Valid: 64.80% Test: 65.80%\n",
      "Run: 05, Epoch: 149, Loss: 0.0041, Train: 100.00%, Valid: 65.00% Test: 65.80%\n",
      "Run: 05, Epoch: 150, Loss: 0.0018, Train: 100.00%, Valid: 64.80% Test: 65.80%\n",
      "Run: 05, Epoch: 151, Loss: 0.0046, Train: 100.00%, Valid: 64.80% Test: 65.70%\n",
      "Run: 05, Epoch: 152, Loss: 0.0058, Train: 100.00%, Valid: 64.80% Test: 65.60%\n",
      "Run: 05, Epoch: 153, Loss: 0.0033, Train: 100.00%, Valid: 64.60% Test: 65.70%\n",
      "Run: 05, Epoch: 154, Loss: 0.0043, Train: 100.00%, Valid: 64.80% Test: 65.80%\n",
      "Run: 05, Epoch: 155, Loss: 0.0019, Train: 100.00%, Valid: 64.80% Test: 65.60%\n",
      "Run: 05, Epoch: 156, Loss: 0.0033, Train: 100.00%, Valid: 64.40% Test: 65.50%\n",
      "Run: 05, Epoch: 157, Loss: 0.0074, Train: 100.00%, Valid: 64.40% Test: 65.20%\n",
      "Run: 05, Epoch: 158, Loss: 0.0092, Train: 100.00%, Valid: 64.40% Test: 65.20%\n",
      "Run: 05, Epoch: 159, Loss: 0.0067, Train: 100.00%, Valid: 64.40% Test: 65.20%\n",
      "Run: 05, Epoch: 160, Loss: 0.0085, Train: 100.00%, Valid: 64.60% Test: 65.20%\n",
      "Run: 05, Epoch: 161, Loss: 0.0123, Train: 100.00%, Valid: 64.60% Test: 65.00%\n",
      "Run: 05, Epoch: 162, Loss: 0.0088, Train: 100.00%, Valid: 64.60% Test: 64.80%\n",
      "Run: 05, Epoch: 163, Loss: 0.0150, Train: 100.00%, Valid: 64.60% Test: 64.60%\n",
      "Run: 05, Epoch: 164, Loss: 0.0091, Train: 100.00%, Valid: 64.60% Test: 64.60%\n",
      "Run: 05, Epoch: 165, Loss: 0.0128, Train: 100.00%, Valid: 64.60% Test: 64.60%\n",
      "Run: 05, Epoch: 166, Loss: 0.0105, Train: 100.00%, Valid: 64.40% Test: 64.60%\n",
      "Run: 05, Epoch: 167, Loss: 0.0104, Train: 100.00%, Valid: 64.40% Test: 64.70%\n",
      "Run: 05, Epoch: 168, Loss: 0.0151, Train: 100.00%, Valid: 64.40% Test: 64.80%\n",
      "Run: 05, Epoch: 169, Loss: 0.0035, Train: 100.00%, Valid: 64.20% Test: 64.80%\n",
      "Run: 05, Epoch: 170, Loss: 0.0447, Train: 100.00%, Valid: 64.40% Test: 65.00%\n",
      "Run: 05, Epoch: 171, Loss: 0.0296, Train: 100.00%, Valid: 64.20% Test: 64.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 172, Loss: 0.0282, Train: 100.00%, Valid: 64.20% Test: 65.00%\n",
      "Run: 05, Epoch: 173, Loss: 0.0067, Train: 100.00%, Valid: 64.20% Test: 64.90%\n",
      "Run: 05, Epoch: 174, Loss: 0.0204, Train: 100.00%, Valid: 64.40% Test: 64.80%\n",
      "Run: 05, Epoch: 175, Loss: 0.0016, Train: 100.00%, Valid: 64.60% Test: 64.60%\n",
      "Run: 05, Epoch: 176, Loss: 0.0025, Train: 100.00%, Valid: 64.00% Test: 64.50%\n",
      "Run: 05, Epoch: 177, Loss: 0.0120, Train: 100.00%, Valid: 63.80% Test: 64.50%\n",
      "Run: 05, Epoch: 178, Loss: 0.0039, Train: 100.00%, Valid: 63.80% Test: 64.50%\n",
      "Run: 05, Epoch: 179, Loss: 0.0144, Train: 100.00%, Valid: 63.80% Test: 64.40%\n",
      "Run: 05, Epoch: 180, Loss: 0.0033, Train: 100.00%, Valid: 63.60% Test: 64.50%\n",
      "Run: 05, Epoch: 181, Loss: 0.0105, Train: 100.00%, Valid: 63.40% Test: 64.50%\n",
      "Run: 05, Epoch: 182, Loss: 0.0018, Train: 100.00%, Valid: 63.40% Test: 64.60%\n",
      "Run: 05, Epoch: 183, Loss: 0.0026, Train: 100.00%, Valid: 63.60% Test: 64.60%\n",
      "Run: 05, Epoch: 184, Loss: 0.0085, Train: 100.00%, Valid: 63.40% Test: 64.80%\n",
      "Run: 05, Epoch: 185, Loss: 0.0101, Train: 100.00%, Valid: 63.20% Test: 64.80%\n",
      "Run: 05, Epoch: 186, Loss: 0.0070, Train: 100.00%, Valid: 63.20% Test: 64.80%\n",
      "Run: 05, Epoch: 187, Loss: 0.0064, Train: 100.00%, Valid: 63.20% Test: 64.80%\n",
      "Run: 05, Epoch: 188, Loss: 0.0118, Train: 100.00%, Valid: 63.40% Test: 64.60%\n",
      "Run: 05, Epoch: 189, Loss: 0.0062, Train: 100.00%, Valid: 63.60% Test: 64.70%\n",
      "Run: 05, Epoch: 190, Loss: 0.0055, Train: 100.00%, Valid: 63.80% Test: 64.80%\n",
      "Run: 05, Epoch: 191, Loss: 0.0046, Train: 100.00%, Valid: 63.80% Test: 64.90%\n",
      "Run: 05, Epoch: 192, Loss: 0.0032, Train: 100.00%, Valid: 63.80% Test: 64.90%\n",
      "Run: 05, Epoch: 193, Loss: 0.0091, Train: 100.00%, Valid: 63.80% Test: 64.70%\n",
      "Run: 05, Epoch: 194, Loss: 0.0222, Train: 100.00%, Valid: 63.80% Test: 64.70%\n",
      "Run: 05, Epoch: 195, Loss: 0.0053, Train: 100.00%, Valid: 63.80% Test: 64.80%\n",
      "Run: 05, Epoch: 196, Loss: 0.0023, Train: 100.00%, Valid: 63.60% Test: 64.70%\n",
      "Run: 05, Epoch: 197, Loss: 0.0158, Train: 100.00%, Valid: 63.60% Test: 65.00%\n",
      "Run: 05, Epoch: 198, Loss: 0.0215, Train: 100.00%, Valid: 63.80% Test: 65.10%\n",
      "Run: 05, Epoch: 199, Loss: 0.0098, Train: 100.00%, Valid: 64.00% Test: 65.20%\n",
      "Run: 05, Epoch: 200, Loss: 0.0019, Train: 100.00%, Valid: 64.00% Test: 65.30%\n",
      "Run 05:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 70.20\n",
      "  Final Train: 99.29\n",
      "   Final Test: 71.90\n",
      "Run: 06, Epoch: 01, Loss: 2.1925, Train: 79.29%, Valid: 51.80% Test: 52.00%\n",
      "Run: 06, Epoch: 02, Loss: 1.2461, Train: 92.14%, Valid: 63.60% Test: 67.30%\n",
      "Run: 06, Epoch: 03, Loss: 0.8120, Train: 97.14%, Valid: 67.00% Test: 71.80%\n",
      "Run: 06, Epoch: 04, Loss: 0.6407, Train: 97.86%, Valid: 70.00% Test: 73.30%\n",
      "Run: 06, Epoch: 05, Loss: 0.5130, Train: 98.57%, Valid: 72.40% Test: 74.70%\n",
      "Run: 06, Epoch: 06, Loss: 0.3869, Train: 99.29%, Valid: 73.20% Test: 75.50%\n",
      "Run: 06, Epoch: 07, Loss: 0.3819, Train: 100.00%, Valid: 73.40% Test: 75.40%\n",
      "Run: 06, Epoch: 08, Loss: 0.3120, Train: 100.00%, Valid: 73.00% Test: 75.90%\n",
      "Run: 06, Epoch: 09, Loss: 0.3120, Train: 100.00%, Valid: 72.80% Test: 74.80%\n",
      "Run: 06, Epoch: 10, Loss: 0.2284, Train: 100.00%, Valid: 71.60% Test: 74.60%\n",
      "Run: 06, Epoch: 11, Loss: 0.2080, Train: 100.00%, Valid: 71.00% Test: 74.50%\n",
      "Run: 06, Epoch: 12, Loss: 0.1789, Train: 100.00%, Valid: 70.80% Test: 74.00%\n",
      "Run: 06, Epoch: 13, Loss: 0.1775, Train: 100.00%, Valid: 70.40% Test: 74.00%\n",
      "Run: 06, Epoch: 14, Loss: 0.1494, Train: 100.00%, Valid: 70.20% Test: 74.00%\n",
      "Run: 06, Epoch: 15, Loss: 0.1237, Train: 100.00%, Valid: 70.20% Test: 74.00%\n",
      "Run: 06, Epoch: 16, Loss: 0.0948, Train: 100.00%, Valid: 70.00% Test: 73.90%\n",
      "Run: 06, Epoch: 17, Loss: 0.1320, Train: 100.00%, Valid: 69.80% Test: 73.80%\n",
      "Run: 06, Epoch: 18, Loss: 0.0955, Train: 100.00%, Valid: 70.40% Test: 73.90%\n",
      "Run: 06, Epoch: 19, Loss: 0.1099, Train: 100.00%, Valid: 70.40% Test: 74.20%\n",
      "Run: 06, Epoch: 20, Loss: 0.0742, Train: 100.00%, Valid: 70.00% Test: 73.70%\n",
      "Run: 06, Epoch: 21, Loss: 0.0853, Train: 100.00%, Valid: 69.60% Test: 73.40%\n",
      "Run: 06, Epoch: 22, Loss: 0.0685, Train: 100.00%, Valid: 69.40% Test: 73.10%\n",
      "Run: 06, Epoch: 23, Loss: 0.0960, Train: 100.00%, Valid: 69.60% Test: 72.70%\n",
      "Run: 06, Epoch: 24, Loss: 0.0570, Train: 100.00%, Valid: 69.60% Test: 72.60%\n",
      "Run: 06, Epoch: 25, Loss: 0.0378, Train: 100.00%, Valid: 69.80% Test: 72.40%\n",
      "Run: 06, Epoch: 26, Loss: 0.0519, Train: 100.00%, Valid: 69.80% Test: 72.00%\n",
      "Run: 06, Epoch: 27, Loss: 0.0664, Train: 100.00%, Valid: 69.80% Test: 71.80%\n",
      "Run: 06, Epoch: 28, Loss: 0.0367, Train: 100.00%, Valid: 69.80% Test: 71.40%\n",
      "Run: 06, Epoch: 29, Loss: 0.0393, Train: 100.00%, Valid: 69.60% Test: 71.10%\n",
      "Run: 06, Epoch: 30, Loss: 0.0413, Train: 100.00%, Valid: 69.60% Test: 71.10%\n",
      "Run: 06, Epoch: 31, Loss: 0.0379, Train: 100.00%, Valid: 69.80% Test: 70.80%\n",
      "Run: 06, Epoch: 32, Loss: 0.0293, Train: 100.00%, Valid: 70.00% Test: 70.80%\n",
      "Run: 06, Epoch: 33, Loss: 0.0345, Train: 100.00%, Valid: 69.80% Test: 70.70%\n",
      "Run: 06, Epoch: 34, Loss: 0.0247, Train: 100.00%, Valid: 69.80% Test: 70.30%\n",
      "Run: 06, Epoch: 35, Loss: 0.0386, Train: 100.00%, Valid: 70.00% Test: 70.30%\n",
      "Run: 06, Epoch: 36, Loss: 0.0365, Train: 100.00%, Valid: 70.00% Test: 70.30%\n",
      "Run: 06, Epoch: 37, Loss: 0.0454, Train: 100.00%, Valid: 70.00% Test: 70.20%\n",
      "Run: 06, Epoch: 38, Loss: 0.0254, Train: 100.00%, Valid: 70.20% Test: 70.00%\n",
      "Run: 06, Epoch: 39, Loss: 0.0158, Train: 100.00%, Valid: 70.00% Test: 69.80%\n",
      "Run: 06, Epoch: 40, Loss: 0.0276, Train: 100.00%, Valid: 70.00% Test: 69.90%\n",
      "Run: 06, Epoch: 41, Loss: 0.0364, Train: 100.00%, Valid: 69.80% Test: 70.10%\n",
      "Run: 06, Epoch: 42, Loss: 0.0141, Train: 100.00%, Valid: 69.80% Test: 70.20%\n",
      "Run: 06, Epoch: 43, Loss: 0.0202, Train: 100.00%, Valid: 69.40% Test: 70.10%\n",
      "Run: 06, Epoch: 44, Loss: 0.0175, Train: 100.00%, Valid: 69.20% Test: 70.10%\n",
      "Run: 06, Epoch: 45, Loss: 0.0376, Train: 100.00%, Valid: 68.80% Test: 70.10%\n",
      "Run: 06, Epoch: 46, Loss: 0.0185, Train: 100.00%, Valid: 68.80% Test: 70.10%\n",
      "Run: 06, Epoch: 47, Loss: 0.0287, Train: 100.00%, Valid: 68.80% Test: 70.10%\n",
      "Run: 06, Epoch: 48, Loss: 0.0302, Train: 100.00%, Valid: 69.00% Test: 70.20%\n",
      "Run: 06, Epoch: 49, Loss: 0.0166, Train: 100.00%, Valid: 69.00% Test: 70.20%\n",
      "Run: 06, Epoch: 50, Loss: 0.0229, Train: 100.00%, Valid: 69.00% Test: 70.50%\n",
      "Run: 06, Epoch: 51, Loss: 0.0253, Train: 100.00%, Valid: 68.60% Test: 70.50%\n",
      "Run: 06, Epoch: 52, Loss: 0.0220, Train: 100.00%, Valid: 68.20% Test: 70.70%\n",
      "Run: 06, Epoch: 53, Loss: 0.0348, Train: 100.00%, Valid: 68.20% Test: 70.30%\n",
      "Run: 06, Epoch: 54, Loss: 0.0210, Train: 100.00%, Valid: 68.00% Test: 70.20%\n",
      "Run: 06, Epoch: 55, Loss: 0.0190, Train: 100.00%, Valid: 67.80% Test: 70.20%\n",
      "Run: 06, Epoch: 56, Loss: 0.0303, Train: 100.00%, Valid: 67.80% Test: 70.10%\n",
      "Run: 06, Epoch: 57, Loss: 0.0240, Train: 100.00%, Valid: 67.80% Test: 70.30%\n",
      "Run: 06, Epoch: 58, Loss: 0.0370, Train: 100.00%, Valid: 67.60% Test: 70.20%\n",
      "Run: 06, Epoch: 59, Loss: 0.0335, Train: 100.00%, Valid: 67.60% Test: 70.30%\n",
      "Run: 06, Epoch: 60, Loss: 0.0275, Train: 100.00%, Valid: 67.60% Test: 70.50%\n",
      "Run: 06, Epoch: 61, Loss: 0.0213, Train: 100.00%, Valid: 67.60% Test: 70.60%\n",
      "Run: 06, Epoch: 62, Loss: 0.0188, Train: 100.00%, Valid: 67.40% Test: 70.60%\n",
      "Run: 06, Epoch: 63, Loss: 0.0146, Train: 100.00%, Valid: 67.40% Test: 70.60%\n",
      "Run: 06, Epoch: 64, Loss: 0.0115, Train: 100.00%, Valid: 67.40% Test: 70.50%\n",
      "Run: 06, Epoch: 65, Loss: 0.0288, Train: 100.00%, Valid: 67.40% Test: 70.50%\n",
      "Run: 06, Epoch: 66, Loss: 0.0327, Train: 100.00%, Valid: 67.40% Test: 70.40%\n",
      "Run: 06, Epoch: 67, Loss: 0.0320, Train: 100.00%, Valid: 67.40% Test: 70.30%\n",
      "Run: 06, Epoch: 68, Loss: 0.0193, Train: 100.00%, Valid: 67.60% Test: 70.30%\n",
      "Run: 06, Epoch: 69, Loss: 0.0365, Train: 100.00%, Valid: 67.80% Test: 70.30%\n",
      "Run: 06, Epoch: 70, Loss: 0.0213, Train: 100.00%, Valid: 67.80% Test: 70.30%\n",
      "Run: 06, Epoch: 71, Loss: 0.0295, Train: 100.00%, Valid: 67.80% Test: 70.20%\n",
      "Run: 06, Epoch: 72, Loss: 0.0154, Train: 100.00%, Valid: 67.80% Test: 70.10%\n",
      "Run: 06, Epoch: 73, Loss: 0.0231, Train: 100.00%, Valid: 67.60% Test: 70.10%\n",
      "Run: 06, Epoch: 74, Loss: 0.0141, Train: 100.00%, Valid: 67.40% Test: 70.10%\n",
      "Run: 06, Epoch: 75, Loss: 0.0110, Train: 100.00%, Valid: 67.60% Test: 69.90%\n",
      "Run: 06, Epoch: 76, Loss: 0.0112, Train: 100.00%, Valid: 68.00% Test: 69.90%\n",
      "Run: 06, Epoch: 77, Loss: 0.0162, Train: 100.00%, Valid: 68.20% Test: 69.90%\n",
      "Run: 06, Epoch: 78, Loss: 0.0246, Train: 100.00%, Valid: 68.20% Test: 70.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 79, Loss: 0.0394, Train: 100.00%, Valid: 68.20% Test: 69.70%\n",
      "Run: 06, Epoch: 80, Loss: 0.0139, Train: 100.00%, Valid: 68.20% Test: 69.50%\n",
      "Run: 06, Epoch: 81, Loss: 0.0134, Train: 100.00%, Valid: 68.20% Test: 69.50%\n",
      "Run: 06, Epoch: 82, Loss: 0.0161, Train: 100.00%, Valid: 68.60% Test: 69.50%\n",
      "Run: 06, Epoch: 83, Loss: 0.0352, Train: 100.00%, Valid: 68.20% Test: 69.60%\n",
      "Run: 06, Epoch: 84, Loss: 0.0089, Train: 100.00%, Valid: 68.40% Test: 69.40%\n",
      "Run: 06, Epoch: 85, Loss: 0.0128, Train: 100.00%, Valid: 68.40% Test: 69.60%\n",
      "Run: 06, Epoch: 86, Loss: 0.0177, Train: 100.00%, Valid: 68.20% Test: 69.70%\n",
      "Run: 06, Epoch: 87, Loss: 0.0285, Train: 100.00%, Valid: 68.40% Test: 69.90%\n",
      "Run: 06, Epoch: 88, Loss: 0.0107, Train: 100.00%, Valid: 68.00% Test: 69.60%\n",
      "Run: 06, Epoch: 89, Loss: 0.0087, Train: 100.00%, Valid: 67.80% Test: 69.50%\n",
      "Run: 06, Epoch: 90, Loss: 0.0278, Train: 100.00%, Valid: 67.60% Test: 69.30%\n",
      "Run: 06, Epoch: 91, Loss: 0.0192, Train: 100.00%, Valid: 66.80% Test: 69.50%\n",
      "Run: 06, Epoch: 92, Loss: 0.0056, Train: 100.00%, Valid: 66.80% Test: 69.40%\n",
      "Run: 06, Epoch: 93, Loss: 0.0265, Train: 100.00%, Valid: 66.80% Test: 69.30%\n",
      "Run: 06, Epoch: 94, Loss: 0.0285, Train: 100.00%, Valid: 66.80% Test: 69.20%\n",
      "Run: 06, Epoch: 95, Loss: 0.0123, Train: 100.00%, Valid: 66.60% Test: 69.20%\n",
      "Run: 06, Epoch: 96, Loss: 0.0025, Train: 100.00%, Valid: 66.20% Test: 69.00%\n",
      "Run: 06, Epoch: 97, Loss: 0.0158, Train: 100.00%, Valid: 66.40% Test: 68.80%\n",
      "Run: 06, Epoch: 98, Loss: 0.0125, Train: 100.00%, Valid: 66.60% Test: 68.80%\n",
      "Run: 06, Epoch: 99, Loss: 0.0175, Train: 100.00%, Valid: 66.80% Test: 68.90%\n",
      "Run: 06, Epoch: 100, Loss: 0.0213, Train: 100.00%, Valid: 66.60% Test: 68.40%\n",
      "Run: 06, Epoch: 101, Loss: 0.0077, Train: 100.00%, Valid: 66.60% Test: 68.30%\n",
      "Run: 06, Epoch: 102, Loss: 0.0170, Train: 100.00%, Valid: 66.60% Test: 68.30%\n",
      "Run: 06, Epoch: 103, Loss: 0.0110, Train: 100.00%, Valid: 66.20% Test: 68.30%\n",
      "Run: 06, Epoch: 104, Loss: 0.0109, Train: 100.00%, Valid: 66.20% Test: 68.10%\n",
      "Run: 06, Epoch: 105, Loss: 0.0133, Train: 100.00%, Valid: 66.20% Test: 68.30%\n",
      "Run: 06, Epoch: 106, Loss: 0.0046, Train: 100.00%, Valid: 66.40% Test: 68.40%\n",
      "Run: 06, Epoch: 107, Loss: 0.0098, Train: 100.00%, Valid: 66.20% Test: 68.50%\n",
      "Run: 06, Epoch: 108, Loss: 0.0034, Train: 100.00%, Valid: 66.60% Test: 68.40%\n",
      "Run: 06, Epoch: 109, Loss: 0.0075, Train: 100.00%, Valid: 66.40% Test: 68.50%\n",
      "Run: 06, Epoch: 110, Loss: 0.0104, Train: 100.00%, Valid: 66.20% Test: 68.50%\n",
      "Run: 06, Epoch: 111, Loss: 0.0221, Train: 100.00%, Valid: 66.60% Test: 68.60%\n",
      "Run: 06, Epoch: 112, Loss: 0.0085, Train: 100.00%, Valid: 66.60% Test: 68.50%\n",
      "Run: 06, Epoch: 113, Loss: 0.0037, Train: 100.00%, Valid: 66.60% Test: 68.70%\n",
      "Run: 06, Epoch: 114, Loss: 0.0329, Train: 100.00%, Valid: 66.40% Test: 68.70%\n",
      "Run: 06, Epoch: 115, Loss: 0.0165, Train: 100.00%, Valid: 67.00% Test: 68.50%\n",
      "Run: 06, Epoch: 116, Loss: 0.0058, Train: 100.00%, Valid: 67.00% Test: 68.20%\n",
      "Run: 06, Epoch: 117, Loss: 0.0070, Train: 100.00%, Valid: 67.00% Test: 68.20%\n",
      "Run: 06, Epoch: 118, Loss: 0.0165, Train: 100.00%, Valid: 67.20% Test: 68.20%\n",
      "Run: 06, Epoch: 119, Loss: 0.0066, Train: 100.00%, Valid: 67.20% Test: 68.10%\n",
      "Run: 06, Epoch: 120, Loss: 0.0144, Train: 100.00%, Valid: 67.00% Test: 68.00%\n",
      "Run: 06, Epoch: 121, Loss: 0.0085, Train: 100.00%, Valid: 66.80% Test: 68.00%\n",
      "Run: 06, Epoch: 122, Loss: 0.0387, Train: 100.00%, Valid: 66.60% Test: 68.00%\n",
      "Run: 06, Epoch: 123, Loss: 0.0095, Train: 100.00%, Valid: 66.00% Test: 68.00%\n",
      "Run: 06, Epoch: 124, Loss: 0.0219, Train: 100.00%, Valid: 66.00% Test: 67.70%\n",
      "Run: 06, Epoch: 125, Loss: 0.0164, Train: 100.00%, Valid: 65.80% Test: 67.40%\n",
      "Run: 06, Epoch: 126, Loss: 0.0097, Train: 100.00%, Valid: 65.40% Test: 67.50%\n",
      "Run: 06, Epoch: 127, Loss: 0.0021, Train: 100.00%, Valid: 65.40% Test: 67.60%\n",
      "Run: 06, Epoch: 128, Loss: 0.0037, Train: 100.00%, Valid: 65.60% Test: 67.60%\n",
      "Run: 06, Epoch: 129, Loss: 0.0044, Train: 100.00%, Valid: 65.60% Test: 67.70%\n",
      "Run: 06, Epoch: 130, Loss: 0.0150, Train: 100.00%, Valid: 65.60% Test: 67.50%\n",
      "Run: 06, Epoch: 131, Loss: 0.0258, Train: 100.00%, Valid: 65.80% Test: 67.80%\n",
      "Run: 06, Epoch: 132, Loss: 0.0038, Train: 100.00%, Valid: 65.60% Test: 67.80%\n",
      "Run: 06, Epoch: 133, Loss: 0.0130, Train: 100.00%, Valid: 65.20% Test: 67.80%\n",
      "Run: 06, Epoch: 134, Loss: 0.0153, Train: 100.00%, Valid: 65.00% Test: 67.40%\n",
      "Run: 06, Epoch: 135, Loss: 0.0251, Train: 100.00%, Valid: 64.80% Test: 67.50%\n",
      "Run: 06, Epoch: 136, Loss: 0.0309, Train: 100.00%, Valid: 64.80% Test: 67.60%\n",
      "Run: 06, Epoch: 137, Loss: 0.0301, Train: 100.00%, Valid: 65.00% Test: 67.50%\n",
      "Run: 06, Epoch: 138, Loss: 0.0047, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 06, Epoch: 139, Loss: 0.0193, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 06, Epoch: 140, Loss: 0.0057, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 06, Epoch: 141, Loss: 0.0071, Train: 100.00%, Valid: 65.40% Test: 67.60%\n",
      "Run: 06, Epoch: 142, Loss: 0.0051, Train: 100.00%, Valid: 65.80% Test: 67.60%\n",
      "Run: 06, Epoch: 143, Loss: 0.0171, Train: 100.00%, Valid: 66.00% Test: 67.50%\n",
      "Run: 06, Epoch: 144, Loss: 0.0051, Train: 100.00%, Valid: 66.60% Test: 67.50%\n",
      "Run: 06, Epoch: 145, Loss: 0.0029, Train: 100.00%, Valid: 66.80% Test: 67.70%\n",
      "Run: 06, Epoch: 146, Loss: 0.0025, Train: 100.00%, Valid: 66.80% Test: 67.70%\n",
      "Run: 06, Epoch: 147, Loss: 0.0135, Train: 100.00%, Valid: 66.80% Test: 67.70%\n",
      "Run: 06, Epoch: 148, Loss: 0.0081, Train: 100.00%, Valid: 66.40% Test: 67.60%\n",
      "Run: 06, Epoch: 149, Loss: 0.0050, Train: 100.00%, Valid: 66.40% Test: 67.80%\n",
      "Run: 06, Epoch: 150, Loss: 0.0207, Train: 100.00%, Valid: 66.40% Test: 67.80%\n",
      "Run: 06, Epoch: 151, Loss: 0.0093, Train: 100.00%, Valid: 66.80% Test: 67.90%\n",
      "Run: 06, Epoch: 152, Loss: 0.0095, Train: 100.00%, Valid: 66.40% Test: 67.90%\n",
      "Run: 06, Epoch: 153, Loss: 0.0118, Train: 100.00%, Valid: 66.20% Test: 67.90%\n",
      "Run: 06, Epoch: 154, Loss: 0.0055, Train: 100.00%, Valid: 66.00% Test: 67.90%\n",
      "Run: 06, Epoch: 155, Loss: 0.0059, Train: 100.00%, Valid: 65.60% Test: 68.00%\n",
      "Run: 06, Epoch: 156, Loss: 0.0050, Train: 100.00%, Valid: 65.60% Test: 68.00%\n",
      "Run: 06, Epoch: 157, Loss: 0.0235, Train: 100.00%, Valid: 65.60% Test: 67.90%\n",
      "Run: 06, Epoch: 158, Loss: 0.0176, Train: 100.00%, Valid: 65.60% Test: 67.80%\n",
      "Run: 06, Epoch: 159, Loss: 0.0033, Train: 100.00%, Valid: 65.40% Test: 67.90%\n",
      "Run: 06, Epoch: 160, Loss: 0.0041, Train: 100.00%, Valid: 65.00% Test: 68.20%\n",
      "Run: 06, Epoch: 161, Loss: 0.0082, Train: 100.00%, Valid: 65.00% Test: 68.00%\n",
      "Run: 06, Epoch: 162, Loss: 0.0035, Train: 100.00%, Valid: 64.80% Test: 67.80%\n",
      "Run: 06, Epoch: 163, Loss: 0.0182, Train: 100.00%, Valid: 64.80% Test: 68.00%\n",
      "Run: 06, Epoch: 164, Loss: 0.0155, Train: 100.00%, Valid: 64.80% Test: 68.00%\n",
      "Run: 06, Epoch: 165, Loss: 0.0132, Train: 100.00%, Valid: 64.80% Test: 68.00%\n",
      "Run: 06, Epoch: 166, Loss: 0.0090, Train: 100.00%, Valid: 64.80% Test: 68.00%\n",
      "Run: 06, Epoch: 167, Loss: 0.0075, Train: 100.00%, Valid: 64.80% Test: 68.00%\n",
      "Run: 06, Epoch: 168, Loss: 0.0079, Train: 100.00%, Valid: 64.80% Test: 68.00%\n",
      "Run: 06, Epoch: 169, Loss: 0.0080, Train: 100.00%, Valid: 65.00% Test: 67.90%\n",
      "Run: 06, Epoch: 170, Loss: 0.0115, Train: 100.00%, Valid: 65.00% Test: 67.90%\n",
      "Run: 06, Epoch: 171, Loss: 0.0061, Train: 100.00%, Valid: 65.00% Test: 67.80%\n",
      "Run: 06, Epoch: 172, Loss: 0.0127, Train: 100.00%, Valid: 65.00% Test: 67.70%\n",
      "Run: 06, Epoch: 173, Loss: 0.0112, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 06, Epoch: 174, Loss: 0.0050, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 06, Epoch: 175, Loss: 0.0027, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 06, Epoch: 176, Loss: 0.0034, Train: 100.00%, Valid: 65.20% Test: 67.50%\n",
      "Run: 06, Epoch: 177, Loss: 0.0020, Train: 100.00%, Valid: 65.00% Test: 67.50%\n",
      "Run: 06, Epoch: 178, Loss: 0.0142, Train: 100.00%, Valid: 65.20% Test: 67.50%\n",
      "Run: 06, Epoch: 179, Loss: 0.0206, Train: 100.00%, Valid: 65.40% Test: 67.50%\n",
      "Run: 06, Epoch: 180, Loss: 0.0054, Train: 100.00%, Valid: 65.80% Test: 67.50%\n",
      "Run: 06, Epoch: 181, Loss: 0.0051, Train: 100.00%, Valid: 66.40% Test: 67.50%\n",
      "Run: 06, Epoch: 182, Loss: 0.0171, Train: 100.00%, Valid: 66.40% Test: 67.40%\n",
      "Run: 06, Epoch: 183, Loss: 0.0112, Train: 100.00%, Valid: 66.40% Test: 67.30%\n",
      "Run: 06, Epoch: 184, Loss: 0.0146, Train: 100.00%, Valid: 66.20% Test: 67.20%\n",
      "Run: 06, Epoch: 185, Loss: 0.0028, Train: 100.00%, Valid: 66.20% Test: 67.10%\n",
      "Run: 06, Epoch: 186, Loss: 0.0156, Train: 100.00%, Valid: 66.60% Test: 67.00%\n",
      "Run: 06, Epoch: 187, Loss: 0.0037, Train: 100.00%, Valid: 66.40% Test: 67.10%\n",
      "Run: 06, Epoch: 188, Loss: 0.0032, Train: 100.00%, Valid: 66.60% Test: 67.00%\n",
      "Run: 06, Epoch: 189, Loss: 0.0046, Train: 100.00%, Valid: 66.20% Test: 67.00%\n",
      "Run: 06, Epoch: 190, Loss: 0.0015, Train: 100.00%, Valid: 66.20% Test: 67.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 191, Loss: 0.0062, Train: 100.00%, Valid: 66.40% Test: 67.20%\n",
      "Run: 06, Epoch: 192, Loss: 0.0081, Train: 100.00%, Valid: 66.60% Test: 67.30%\n",
      "Run: 06, Epoch: 193, Loss: 0.0015, Train: 100.00%, Valid: 66.60% Test: 67.30%\n",
      "Run: 06, Epoch: 194, Loss: 0.0015, Train: 100.00%, Valid: 66.60% Test: 67.20%\n",
      "Run: 06, Epoch: 195, Loss: 0.0137, Train: 100.00%, Valid: 66.60% Test: 67.30%\n",
      "Run: 06, Epoch: 196, Loss: 0.0044, Train: 100.00%, Valid: 66.60% Test: 67.30%\n",
      "Run: 06, Epoch: 197, Loss: 0.0139, Train: 100.00%, Valid: 66.60% Test: 67.20%\n",
      "Run: 06, Epoch: 198, Loss: 0.0123, Train: 100.00%, Valid: 66.20% Test: 67.20%\n",
      "Run: 06, Epoch: 199, Loss: 0.0073, Train: 100.00%, Valid: 65.80% Test: 67.20%\n",
      "Run: 06, Epoch: 200, Loss: 0.0035, Train: 100.00%, Valid: 65.80% Test: 67.00%\n",
      "Run 06:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.40\n",
      "  Final Train: 100.00\n",
      "   Final Test: 75.40\n",
      "Run: 07, Epoch: 01, Loss: 2.2058, Train: 59.29%, Valid: 39.00% Test: 38.20%\n",
      "Run: 07, Epoch: 02, Loss: 1.3467, Train: 87.86%, Valid: 59.20% Test: 57.90%\n",
      "Run: 07, Epoch: 03, Loss: 0.9735, Train: 92.14%, Valid: 62.00% Test: 65.10%\n",
      "Run: 07, Epoch: 04, Loss: 0.7774, Train: 94.29%, Valid: 64.20% Test: 66.10%\n",
      "Run: 07, Epoch: 05, Loss: 0.6563, Train: 93.57%, Valid: 65.20% Test: 67.30%\n",
      "Run: 07, Epoch: 06, Loss: 0.5364, Train: 95.00%, Valid: 67.00% Test: 68.60%\n",
      "Run: 07, Epoch: 07, Loss: 0.4649, Train: 95.71%, Valid: 68.20% Test: 70.10%\n",
      "Run: 07, Epoch: 08, Loss: 0.4007, Train: 96.43%, Valid: 69.00% Test: 71.20%\n",
      "Run: 07, Epoch: 09, Loss: 0.3764, Train: 97.86%, Valid: 69.20% Test: 72.00%\n",
      "Run: 07, Epoch: 10, Loss: 0.3403, Train: 97.86%, Valid: 70.60% Test: 72.90%\n",
      "Run: 07, Epoch: 11, Loss: 0.2917, Train: 100.00%, Valid: 71.80% Test: 73.20%\n",
      "Run: 07, Epoch: 12, Loss: 0.2767, Train: 100.00%, Valid: 71.80% Test: 73.70%\n",
      "Run: 07, Epoch: 13, Loss: 0.2411, Train: 100.00%, Valid: 72.60% Test: 74.00%\n",
      "Run: 07, Epoch: 14, Loss: 0.2214, Train: 100.00%, Valid: 72.00% Test: 74.30%\n",
      "Run: 07, Epoch: 15, Loss: 0.1706, Train: 100.00%, Valid: 72.00% Test: 74.10%\n",
      "Run: 07, Epoch: 16, Loss: 0.1817, Train: 99.29%, Valid: 72.80% Test: 74.00%\n",
      "Run: 07, Epoch: 17, Loss: 0.1664, Train: 100.00%, Valid: 72.80% Test: 74.30%\n",
      "Run: 07, Epoch: 18, Loss: 0.1533, Train: 100.00%, Valid: 73.20% Test: 74.30%\n",
      "Run: 07, Epoch: 19, Loss: 0.1387, Train: 100.00%, Valid: 73.00% Test: 74.60%\n",
      "Run: 07, Epoch: 20, Loss: 0.1121, Train: 100.00%, Valid: 72.60% Test: 74.80%\n",
      "Run: 07, Epoch: 21, Loss: 0.1367, Train: 100.00%, Valid: 72.20% Test: 74.80%\n",
      "Run: 07, Epoch: 22, Loss: 0.1036, Train: 100.00%, Valid: 72.60% Test: 74.90%\n",
      "Run: 07, Epoch: 23, Loss: 0.0737, Train: 100.00%, Valid: 72.40% Test: 75.10%\n",
      "Run: 07, Epoch: 24, Loss: 0.0773, Train: 100.00%, Valid: 72.40% Test: 75.10%\n",
      "Run: 07, Epoch: 25, Loss: 0.0734, Train: 100.00%, Valid: 72.40% Test: 74.90%\n",
      "Run: 07, Epoch: 26, Loss: 0.0818, Train: 100.00%, Valid: 72.60% Test: 75.00%\n",
      "Run: 07, Epoch: 27, Loss: 0.0494, Train: 100.00%, Valid: 72.00% Test: 75.20%\n",
      "Run: 07, Epoch: 28, Loss: 0.0565, Train: 100.00%, Valid: 71.80% Test: 74.70%\n",
      "Run: 07, Epoch: 29, Loss: 0.0476, Train: 100.00%, Valid: 72.20% Test: 74.50%\n",
      "Run: 07, Epoch: 30, Loss: 0.0784, Train: 100.00%, Valid: 72.20% Test: 74.30%\n",
      "Run: 07, Epoch: 31, Loss: 0.0607, Train: 100.00%, Valid: 72.00% Test: 74.10%\n",
      "Run: 07, Epoch: 32, Loss: 0.0444, Train: 100.00%, Valid: 72.00% Test: 74.20%\n",
      "Run: 07, Epoch: 33, Loss: 0.0690, Train: 100.00%, Valid: 71.60% Test: 74.00%\n",
      "Run: 07, Epoch: 34, Loss: 0.0465, Train: 100.00%, Valid: 71.20% Test: 73.80%\n",
      "Run: 07, Epoch: 35, Loss: 0.0381, Train: 100.00%, Valid: 71.20% Test: 73.90%\n",
      "Run: 07, Epoch: 36, Loss: 0.0684, Train: 100.00%, Valid: 71.40% Test: 73.90%\n",
      "Run: 07, Epoch: 37, Loss: 0.0333, Train: 100.00%, Valid: 71.40% Test: 73.80%\n",
      "Run: 07, Epoch: 38, Loss: 0.0248, Train: 100.00%, Valid: 71.00% Test: 73.80%\n",
      "Run: 07, Epoch: 39, Loss: 0.0395, Train: 100.00%, Valid: 71.40% Test: 73.70%\n",
      "Run: 07, Epoch: 40, Loss: 0.0361, Train: 100.00%, Valid: 70.80% Test: 73.50%\n",
      "Run: 07, Epoch: 41, Loss: 0.0330, Train: 100.00%, Valid: 70.20% Test: 73.50%\n",
      "Run: 07, Epoch: 42, Loss: 0.0312, Train: 100.00%, Valid: 70.20% Test: 73.10%\n",
      "Run: 07, Epoch: 43, Loss: 0.0231, Train: 100.00%, Valid: 70.20% Test: 73.20%\n",
      "Run: 07, Epoch: 44, Loss: 0.0295, Train: 100.00%, Valid: 70.40% Test: 73.20%\n",
      "Run: 07, Epoch: 45, Loss: 0.0257, Train: 100.00%, Valid: 70.40% Test: 72.80%\n",
      "Run: 07, Epoch: 46, Loss: 0.0392, Train: 100.00%, Valid: 70.20% Test: 72.70%\n",
      "Run: 07, Epoch: 47, Loss: 0.0418, Train: 100.00%, Valid: 70.20% Test: 72.70%\n",
      "Run: 07, Epoch: 48, Loss: 0.0326, Train: 100.00%, Valid: 69.80% Test: 72.50%\n",
      "Run: 07, Epoch: 49, Loss: 0.0203, Train: 100.00%, Valid: 69.60% Test: 72.50%\n",
      "Run: 07, Epoch: 50, Loss: 0.0401, Train: 100.00%, Valid: 69.60% Test: 72.40%\n",
      "Run: 07, Epoch: 51, Loss: 0.0313, Train: 100.00%, Valid: 69.60% Test: 72.40%\n",
      "Run: 07, Epoch: 52, Loss: 0.0419, Train: 100.00%, Valid: 69.40% Test: 72.40%\n",
      "Run: 07, Epoch: 53, Loss: 0.0333, Train: 100.00%, Valid: 69.40% Test: 72.40%\n",
      "Run: 07, Epoch: 54, Loss: 0.0187, Train: 100.00%, Valid: 69.40% Test: 72.20%\n",
      "Run: 07, Epoch: 55, Loss: 0.0291, Train: 100.00%, Valid: 69.60% Test: 72.10%\n",
      "Run: 07, Epoch: 56, Loss: 0.0218, Train: 100.00%, Valid: 69.40% Test: 72.20%\n",
      "Run: 07, Epoch: 57, Loss: 0.0285, Train: 100.00%, Valid: 69.20% Test: 71.90%\n",
      "Run: 07, Epoch: 58, Loss: 0.0304, Train: 100.00%, Valid: 69.20% Test: 72.00%\n",
      "Run: 07, Epoch: 59, Loss: 0.0157, Train: 100.00%, Valid: 69.20% Test: 72.20%\n",
      "Run: 07, Epoch: 60, Loss: 0.0296, Train: 100.00%, Valid: 69.00% Test: 72.20%\n",
      "Run: 07, Epoch: 61, Loss: 0.0159, Train: 100.00%, Valid: 68.80% Test: 72.00%\n",
      "Run: 07, Epoch: 62, Loss: 0.0229, Train: 100.00%, Valid: 68.80% Test: 71.90%\n",
      "Run: 07, Epoch: 63, Loss: 0.0322, Train: 100.00%, Valid: 68.80% Test: 71.90%\n",
      "Run: 07, Epoch: 64, Loss: 0.0305, Train: 100.00%, Valid: 69.00% Test: 71.70%\n",
      "Run: 07, Epoch: 65, Loss: 0.0276, Train: 100.00%, Valid: 69.20% Test: 71.40%\n",
      "Run: 07, Epoch: 66, Loss: 0.0189, Train: 100.00%, Valid: 69.20% Test: 71.30%\n",
      "Run: 07, Epoch: 67, Loss: 0.0139, Train: 100.00%, Valid: 69.40% Test: 71.20%\n",
      "Run: 07, Epoch: 68, Loss: 0.0100, Train: 100.00%, Valid: 69.60% Test: 71.10%\n",
      "Run: 07, Epoch: 69, Loss: 0.0109, Train: 100.00%, Valid: 69.60% Test: 71.00%\n",
      "Run: 07, Epoch: 70, Loss: 0.0298, Train: 100.00%, Valid: 69.60% Test: 70.90%\n",
      "Run: 07, Epoch: 71, Loss: 0.0102, Train: 100.00%, Valid: 69.40% Test: 70.80%\n",
      "Run: 07, Epoch: 72, Loss: 0.0333, Train: 100.00%, Valid: 69.20% Test: 70.60%\n",
      "Run: 07, Epoch: 73, Loss: 0.0146, Train: 100.00%, Valid: 68.80% Test: 70.50%\n",
      "Run: 07, Epoch: 74, Loss: 0.0134, Train: 100.00%, Valid: 68.60% Test: 70.40%\n",
      "Run: 07, Epoch: 75, Loss: 0.0117, Train: 100.00%, Valid: 68.40% Test: 70.30%\n",
      "Run: 07, Epoch: 76, Loss: 0.0084, Train: 100.00%, Valid: 68.40% Test: 70.20%\n",
      "Run: 07, Epoch: 77, Loss: 0.0305, Train: 100.00%, Valid: 68.40% Test: 70.30%\n",
      "Run: 07, Epoch: 78, Loss: 0.0078, Train: 100.00%, Valid: 68.20% Test: 70.30%\n",
      "Run: 07, Epoch: 79, Loss: 0.0094, Train: 100.00%, Valid: 68.20% Test: 70.30%\n",
      "Run: 07, Epoch: 80, Loss: 0.0121, Train: 100.00%, Valid: 68.20% Test: 70.50%\n",
      "Run: 07, Epoch: 81, Loss: 0.0113, Train: 100.00%, Valid: 68.20% Test: 70.50%\n",
      "Run: 07, Epoch: 82, Loss: 0.0129, Train: 100.00%, Valid: 68.20% Test: 70.60%\n",
      "Run: 07, Epoch: 83, Loss: 0.0125, Train: 100.00%, Valid: 68.40% Test: 70.30%\n",
      "Run: 07, Epoch: 84, Loss: 0.0134, Train: 100.00%, Valid: 68.40% Test: 70.10%\n",
      "Run: 07, Epoch: 85, Loss: 0.0120, Train: 100.00%, Valid: 68.40% Test: 70.10%\n",
      "Run: 07, Epoch: 86, Loss: 0.0312, Train: 100.00%, Valid: 68.40% Test: 70.10%\n",
      "Run: 07, Epoch: 87, Loss: 0.0186, Train: 100.00%, Valid: 68.20% Test: 70.00%\n",
      "Run: 07, Epoch: 88, Loss: 0.0077, Train: 100.00%, Valid: 68.20% Test: 69.90%\n",
      "Run: 07, Epoch: 89, Loss: 0.0081, Train: 100.00%, Valid: 68.40% Test: 69.90%\n",
      "Run: 07, Epoch: 90, Loss: 0.0145, Train: 100.00%, Valid: 68.40% Test: 69.80%\n",
      "Run: 07, Epoch: 91, Loss: 0.0063, Train: 100.00%, Valid: 68.20% Test: 69.70%\n",
      "Run: 07, Epoch: 92, Loss: 0.0165, Train: 100.00%, Valid: 68.20% Test: 69.60%\n",
      "Run: 07, Epoch: 93, Loss: 0.0088, Train: 100.00%, Valid: 68.20% Test: 69.70%\n",
      "Run: 07, Epoch: 94, Loss: 0.0060, Train: 100.00%, Valid: 68.20% Test: 69.70%\n",
      "Run: 07, Epoch: 95, Loss: 0.0103, Train: 100.00%, Valid: 67.80% Test: 69.60%\n",
      "Run: 07, Epoch: 96, Loss: 0.0265, Train: 100.00%, Valid: 67.80% Test: 69.80%\n",
      "Run: 07, Epoch: 97, Loss: 0.0179, Train: 100.00%, Valid: 67.80% Test: 69.90%\n",
      "Run: 07, Epoch: 98, Loss: 0.0060, Train: 100.00%, Valid: 67.80% Test: 70.00%\n",
      "Run: 07, Epoch: 99, Loss: 0.0302, Train: 100.00%, Valid: 67.60% Test: 70.00%\n",
      "Run: 07, Epoch: 100, Loss: 0.0109, Train: 100.00%, Valid: 67.60% Test: 70.20%\n",
      "Run: 07, Epoch: 101, Loss: 0.0126, Train: 100.00%, Valid: 67.60% Test: 70.00%\n",
      "Run: 07, Epoch: 102, Loss: 0.0201, Train: 100.00%, Valid: 67.40% Test: 70.00%\n",
      "Run: 07, Epoch: 103, Loss: 0.0141, Train: 100.00%, Valid: 67.40% Test: 69.90%\n",
      "Run: 07, Epoch: 104, Loss: 0.0169, Train: 100.00%, Valid: 67.40% Test: 69.80%\n",
      "Run: 07, Epoch: 105, Loss: 0.0137, Train: 100.00%, Valid: 67.60% Test: 69.70%\n",
      "Run: 07, Epoch: 106, Loss: 0.0131, Train: 100.00%, Valid: 67.40% Test: 69.80%\n",
      "Run: 07, Epoch: 107, Loss: 0.0157, Train: 100.00%, Valid: 67.40% Test: 69.50%\n",
      "Run: 07, Epoch: 108, Loss: 0.0143, Train: 100.00%, Valid: 67.60% Test: 69.50%\n",
      "Run: 07, Epoch: 109, Loss: 0.0050, Train: 100.00%, Valid: 68.00% Test: 69.50%\n",
      "Run: 07, Epoch: 110, Loss: 0.0056, Train: 100.00%, Valid: 68.20% Test: 69.40%\n",
      "Run: 07, Epoch: 111, Loss: 0.0144, Train: 100.00%, Valid: 68.20% Test: 69.30%\n",
      "Run: 07, Epoch: 112, Loss: 0.0174, Train: 100.00%, Valid: 68.20% Test: 69.40%\n",
      "Run: 07, Epoch: 113, Loss: 0.0088, Train: 100.00%, Valid: 67.80% Test: 69.50%\n",
      "Run: 07, Epoch: 114, Loss: 0.0067, Train: 100.00%, Valid: 68.00% Test: 69.60%\n",
      "Run: 07, Epoch: 115, Loss: 0.0097, Train: 100.00%, Valid: 68.00% Test: 69.60%\n",
      "Run: 07, Epoch: 116, Loss: 0.0157, Train: 100.00%, Valid: 68.00% Test: 69.40%\n",
      "Run: 07, Epoch: 117, Loss: 0.0036, Train: 100.00%, Valid: 68.20% Test: 69.40%\n",
      "Run: 07, Epoch: 118, Loss: 0.0305, Train: 100.00%, Valid: 68.20% Test: 69.20%\n",
      "Run: 07, Epoch: 119, Loss: 0.0191, Train: 100.00%, Valid: 68.20% Test: 69.00%\n",
      "Run: 07, Epoch: 120, Loss: 0.0055, Train: 100.00%, Valid: 68.20% Test: 68.90%\n",
      "Run: 07, Epoch: 121, Loss: 0.0065, Train: 100.00%, Valid: 68.60% Test: 69.00%\n",
      "Run: 07, Epoch: 122, Loss: 0.0033, Train: 100.00%, Valid: 68.80% Test: 68.90%\n",
      "Run: 07, Epoch: 123, Loss: 0.0144, Train: 100.00%, Valid: 68.60% Test: 69.00%\n",
      "Run: 07, Epoch: 124, Loss: 0.0122, Train: 100.00%, Valid: 68.40% Test: 69.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 125, Loss: 0.0094, Train: 100.00%, Valid: 68.40% Test: 69.10%\n",
      "Run: 07, Epoch: 126, Loss: 0.0160, Train: 100.00%, Valid: 68.00% Test: 69.10%\n",
      "Run: 07, Epoch: 127, Loss: 0.0081, Train: 100.00%, Valid: 67.60% Test: 69.00%\n",
      "Run: 07, Epoch: 128, Loss: 0.0104, Train: 100.00%, Valid: 67.60% Test: 69.10%\n",
      "Run: 07, Epoch: 129, Loss: 0.0128, Train: 100.00%, Valid: 67.60% Test: 69.20%\n",
      "Run: 07, Epoch: 130, Loss: 0.0117, Train: 100.00%, Valid: 67.60% Test: 69.30%\n",
      "Run: 07, Epoch: 131, Loss: 0.0059, Train: 100.00%, Valid: 67.60% Test: 69.30%\n",
      "Run: 07, Epoch: 132, Loss: 0.0198, Train: 100.00%, Valid: 67.60% Test: 69.30%\n",
      "Run: 07, Epoch: 133, Loss: 0.0030, Train: 100.00%, Valid: 67.60% Test: 69.30%\n",
      "Run: 07, Epoch: 134, Loss: 0.0089, Train: 100.00%, Valid: 67.80% Test: 69.40%\n",
      "Run: 07, Epoch: 135, Loss: 0.0124, Train: 100.00%, Valid: 67.80% Test: 69.20%\n",
      "Run: 07, Epoch: 136, Loss: 0.0070, Train: 100.00%, Valid: 67.80% Test: 69.00%\n",
      "Run: 07, Epoch: 137, Loss: 0.0087, Train: 100.00%, Valid: 67.80% Test: 69.10%\n",
      "Run: 07, Epoch: 138, Loss: 0.0020, Train: 100.00%, Valid: 67.80% Test: 69.10%\n",
      "Run: 07, Epoch: 139, Loss: 0.0031, Train: 100.00%, Valid: 68.00% Test: 69.20%\n",
      "Run: 07, Epoch: 140, Loss: 0.0066, Train: 100.00%, Valid: 68.00% Test: 69.20%\n",
      "Run: 07, Epoch: 141, Loss: 0.0142, Train: 100.00%, Valid: 68.00% Test: 69.20%\n",
      "Run: 07, Epoch: 142, Loss: 0.0046, Train: 100.00%, Valid: 68.60% Test: 69.40%\n",
      "Run: 07, Epoch: 143, Loss: 0.0172, Train: 100.00%, Valid: 68.80% Test: 69.40%\n",
      "Run: 07, Epoch: 144, Loss: 0.0091, Train: 100.00%, Valid: 69.00% Test: 69.50%\n",
      "Run: 07, Epoch: 145, Loss: 0.0085, Train: 100.00%, Valid: 69.00% Test: 69.50%\n",
      "Run: 07, Epoch: 146, Loss: 0.0060, Train: 100.00%, Valid: 69.00% Test: 69.50%\n",
      "Run: 07, Epoch: 147, Loss: 0.0092, Train: 100.00%, Valid: 69.00% Test: 69.70%\n",
      "Run: 07, Epoch: 148, Loss: 0.0056, Train: 100.00%, Valid: 69.00% Test: 69.70%\n",
      "Run: 07, Epoch: 149, Loss: 0.0066, Train: 100.00%, Valid: 68.80% Test: 69.80%\n",
      "Run: 07, Epoch: 150, Loss: 0.0152, Train: 100.00%, Valid: 68.80% Test: 69.80%\n",
      "Run: 07, Epoch: 151, Loss: 0.0041, Train: 100.00%, Valid: 68.80% Test: 69.70%\n",
      "Run: 07, Epoch: 152, Loss: 0.0118, Train: 100.00%, Valid: 68.40% Test: 69.20%\n",
      "Run: 07, Epoch: 153, Loss: 0.0059, Train: 100.00%, Valid: 68.40% Test: 69.00%\n",
      "Run: 07, Epoch: 154, Loss: 0.0058, Train: 100.00%, Valid: 68.20% Test: 68.90%\n",
      "Run: 07, Epoch: 155, Loss: 0.0087, Train: 100.00%, Valid: 68.20% Test: 69.00%\n",
      "Run: 07, Epoch: 156, Loss: 0.0099, Train: 100.00%, Valid: 68.20% Test: 69.10%\n",
      "Run: 07, Epoch: 157, Loss: 0.0041, Train: 100.00%, Valid: 68.20% Test: 69.10%\n",
      "Run: 07, Epoch: 158, Loss: 0.0053, Train: 100.00%, Valid: 68.20% Test: 69.20%\n",
      "Run: 07, Epoch: 159, Loss: 0.0036, Train: 100.00%, Valid: 68.20% Test: 69.20%\n",
      "Run: 07, Epoch: 160, Loss: 0.0126, Train: 100.00%, Valid: 68.20% Test: 69.10%\n",
      "Run: 07, Epoch: 161, Loss: 0.0062, Train: 100.00%, Valid: 68.40% Test: 68.70%\n",
      "Run: 07, Epoch: 162, Loss: 0.0060, Train: 100.00%, Valid: 68.40% Test: 68.90%\n",
      "Run: 07, Epoch: 163, Loss: 0.0080, Train: 100.00%, Valid: 68.00% Test: 68.90%\n",
      "Run: 07, Epoch: 164, Loss: 0.0051, Train: 100.00%, Valid: 68.00% Test: 68.90%\n",
      "Run: 07, Epoch: 165, Loss: 0.0123, Train: 100.00%, Valid: 68.00% Test: 68.80%\n",
      "Run: 07, Epoch: 166, Loss: 0.0025, Train: 100.00%, Valid: 68.00% Test: 68.70%\n",
      "Run: 07, Epoch: 167, Loss: 0.0103, Train: 100.00%, Valid: 68.20% Test: 69.00%\n",
      "Run: 07, Epoch: 168, Loss: 0.0048, Train: 100.00%, Valid: 68.00% Test: 69.00%\n",
      "Run: 07, Epoch: 169, Loss: 0.0021, Train: 100.00%, Valid: 68.00% Test: 69.00%\n",
      "Run: 07, Epoch: 170, Loss: 0.0058, Train: 100.00%, Valid: 67.80% Test: 69.10%\n",
      "Run: 07, Epoch: 171, Loss: 0.0039, Train: 100.00%, Valid: 67.80% Test: 68.80%\n",
      "Run: 07, Epoch: 172, Loss: 0.0023, Train: 100.00%, Valid: 67.80% Test: 68.90%\n",
      "Run: 07, Epoch: 173, Loss: 0.0041, Train: 100.00%, Valid: 67.80% Test: 68.80%\n",
      "Run: 07, Epoch: 174, Loss: 0.0034, Train: 100.00%, Valid: 67.60% Test: 68.60%\n",
      "Run: 07, Epoch: 175, Loss: 0.0021, Train: 100.00%, Valid: 67.40% Test: 68.50%\n",
      "Run: 07, Epoch: 176, Loss: 0.0040, Train: 100.00%, Valid: 67.60% Test: 68.50%\n",
      "Run: 07, Epoch: 177, Loss: 0.0025, Train: 100.00%, Valid: 67.60% Test: 68.40%\n",
      "Run: 07, Epoch: 178, Loss: 0.0080, Train: 100.00%, Valid: 67.60% Test: 68.40%\n",
      "Run: 07, Epoch: 179, Loss: 0.0052, Train: 100.00%, Valid: 67.60% Test: 68.40%\n",
      "Run: 07, Epoch: 180, Loss: 0.0200, Train: 100.00%, Valid: 67.60% Test: 68.30%\n",
      "Run: 07, Epoch: 181, Loss: 0.0043, Train: 100.00%, Valid: 67.60% Test: 68.20%\n",
      "Run: 07, Epoch: 182, Loss: 0.0048, Train: 100.00%, Valid: 67.40% Test: 68.10%\n",
      "Run: 07, Epoch: 183, Loss: 0.0029, Train: 100.00%, Valid: 67.20% Test: 68.20%\n",
      "Run: 07, Epoch: 184, Loss: 0.0041, Train: 100.00%, Valid: 67.20% Test: 68.20%\n",
      "Run: 07, Epoch: 185, Loss: 0.0065, Train: 100.00%, Valid: 67.20% Test: 68.20%\n",
      "Run: 07, Epoch: 186, Loss: 0.0055, Train: 100.00%, Valid: 67.40% Test: 68.20%\n",
      "Run: 07, Epoch: 187, Loss: 0.0023, Train: 100.00%, Valid: 67.20% Test: 68.20%\n",
      "Run: 07, Epoch: 188, Loss: 0.0020, Train: 100.00%, Valid: 67.20% Test: 68.20%\n",
      "Run: 07, Epoch: 189, Loss: 0.0057, Train: 100.00%, Valid: 67.20% Test: 68.20%\n",
      "Run: 07, Epoch: 190, Loss: 0.0047, Train: 100.00%, Valid: 66.80% Test: 68.20%\n",
      "Run: 07, Epoch: 191, Loss: 0.0212, Train: 100.00%, Valid: 66.40% Test: 68.10%\n",
      "Run: 07, Epoch: 192, Loss: 0.0051, Train: 100.00%, Valid: 66.40% Test: 67.80%\n",
      "Run: 07, Epoch: 193, Loss: 0.0097, Train: 100.00%, Valid: 66.00% Test: 67.90%\n",
      "Run: 07, Epoch: 194, Loss: 0.0022, Train: 100.00%, Valid: 65.80% Test: 67.90%\n",
      "Run: 07, Epoch: 195, Loss: 0.0207, Train: 100.00%, Valid: 65.80% Test: 67.80%\n",
      "Run: 07, Epoch: 196, Loss: 0.0061, Train: 100.00%, Valid: 66.00% Test: 67.90%\n",
      "Run: 07, Epoch: 197, Loss: 0.0079, Train: 100.00%, Valid: 66.20% Test: 67.90%\n",
      "Run: 07, Epoch: 198, Loss: 0.0059, Train: 100.00%, Valid: 66.40% Test: 68.00%\n",
      "Run: 07, Epoch: 199, Loss: 0.0023, Train: 100.00%, Valid: 66.60% Test: 68.10%\n",
      "Run: 07, Epoch: 200, Loss: 0.0016, Train: 100.00%, Valid: 66.40% Test: 68.10%\n",
      "Run 07:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.20\n",
      "  Final Train: 100.00\n",
      "   Final Test: 74.30\n",
      "Run: 08, Epoch: 01, Loss: 2.1326, Train: 64.29%, Valid: 31.20% Test: 33.20%\n",
      "Run: 08, Epoch: 02, Loss: 1.3288, Train: 83.57%, Valid: 51.40% Test: 52.10%\n",
      "Run: 08, Epoch: 03, Loss: 1.0019, Train: 91.43%, Valid: 60.80% Test: 63.60%\n",
      "Run: 08, Epoch: 04, Loss: 0.8027, Train: 95.71%, Valid: 66.80% Test: 68.20%\n",
      "Run: 08, Epoch: 05, Loss: 0.7005, Train: 97.14%, Valid: 69.00% Test: 71.40%\n",
      "Run: 08, Epoch: 06, Loss: 0.5972, Train: 97.14%, Valid: 69.60% Test: 73.00%\n",
      "Run: 08, Epoch: 07, Loss: 0.5137, Train: 97.14%, Valid: 70.60% Test: 74.30%\n",
      "Run: 08, Epoch: 08, Loss: 0.4667, Train: 98.57%, Valid: 71.20% Test: 74.70%\n",
      "Run: 08, Epoch: 09, Loss: 0.4156, Train: 100.00%, Valid: 71.80% Test: 75.00%\n",
      "Run: 08, Epoch: 10, Loss: 0.3621, Train: 100.00%, Valid: 72.40% Test: 75.60%\n",
      "Run: 08, Epoch: 11, Loss: 0.3222, Train: 100.00%, Valid: 72.60% Test: 75.80%\n",
      "Run: 08, Epoch: 12, Loss: 0.3128, Train: 100.00%, Valid: 71.20% Test: 75.60%\n",
      "Run: 08, Epoch: 13, Loss: 0.2526, Train: 100.00%, Valid: 71.40% Test: 75.60%\n",
      "Run: 08, Epoch: 14, Loss: 0.2100, Train: 100.00%, Valid: 71.80% Test: 75.70%\n",
      "Run: 08, Epoch: 15, Loss: 0.1833, Train: 100.00%, Valid: 72.20% Test: 75.30%\n",
      "Run: 08, Epoch: 16, Loss: 0.1824, Train: 100.00%, Valid: 72.20% Test: 75.40%\n",
      "Run: 08, Epoch: 17, Loss: 0.1677, Train: 100.00%, Valid: 72.00% Test: 75.10%\n",
      "Run: 08, Epoch: 18, Loss: 0.1536, Train: 100.00%, Valid: 71.40% Test: 74.80%\n",
      "Run: 08, Epoch: 19, Loss: 0.1454, Train: 100.00%, Valid: 70.60% Test: 73.80%\n",
      "Run: 08, Epoch: 20, Loss: 0.1382, Train: 100.00%, Valid: 70.80% Test: 73.60%\n",
      "Run: 08, Epoch: 21, Loss: 0.1006, Train: 100.00%, Valid: 70.40% Test: 73.10%\n",
      "Run: 08, Epoch: 22, Loss: 0.1208, Train: 100.00%, Valid: 70.20% Test: 72.90%\n",
      "Run: 08, Epoch: 23, Loss: 0.0826, Train: 100.00%, Valid: 70.20% Test: 72.80%\n",
      "Run: 08, Epoch: 24, Loss: 0.0841, Train: 100.00%, Valid: 68.80% Test: 72.60%\n",
      "Run: 08, Epoch: 25, Loss: 0.0981, Train: 100.00%, Valid: 69.00% Test: 72.20%\n",
      "Run: 08, Epoch: 26, Loss: 0.0866, Train: 100.00%, Valid: 68.40% Test: 72.00%\n",
      "Run: 08, Epoch: 27, Loss: 0.0547, Train: 100.00%, Valid: 68.40% Test: 71.80%\n",
      "Run: 08, Epoch: 28, Loss: 0.0798, Train: 100.00%, Valid: 68.20% Test: 71.30%\n",
      "Run: 08, Epoch: 29, Loss: 0.0599, Train: 100.00%, Valid: 68.20% Test: 71.00%\n",
      "Run: 08, Epoch: 30, Loss: 0.0423, Train: 100.00%, Valid: 68.20% Test: 70.80%\n",
      "Run: 08, Epoch: 31, Loss: 0.0484, Train: 100.00%, Valid: 68.20% Test: 70.70%\n",
      "Run: 08, Epoch: 32, Loss: 0.0639, Train: 100.00%, Valid: 68.20% Test: 70.70%\n",
      "Run: 08, Epoch: 33, Loss: 0.0403, Train: 100.00%, Valid: 67.40% Test: 70.70%\n",
      "Run: 08, Epoch: 34, Loss: 0.0395, Train: 100.00%, Valid: 67.00% Test: 70.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 35, Loss: 0.0400, Train: 100.00%, Valid: 67.00% Test: 70.30%\n",
      "Run: 08, Epoch: 36, Loss: 0.0545, Train: 100.00%, Valid: 67.00% Test: 70.10%\n",
      "Run: 08, Epoch: 37, Loss: 0.0310, Train: 100.00%, Valid: 67.00% Test: 69.90%\n",
      "Run: 08, Epoch: 38, Loss: 0.0310, Train: 100.00%, Valid: 66.60% Test: 69.80%\n",
      "Run: 08, Epoch: 39, Loss: 0.0398, Train: 100.00%, Valid: 66.00% Test: 69.60%\n",
      "Run: 08, Epoch: 40, Loss: 0.0310, Train: 100.00%, Valid: 66.00% Test: 69.70%\n",
      "Run: 08, Epoch: 41, Loss: 0.0376, Train: 100.00%, Valid: 65.60% Test: 69.50%\n",
      "Run: 08, Epoch: 42, Loss: 0.0180, Train: 100.00%, Valid: 65.60% Test: 69.10%\n",
      "Run: 08, Epoch: 43, Loss: 0.0198, Train: 100.00%, Valid: 65.60% Test: 69.00%\n",
      "Run: 08, Epoch: 44, Loss: 0.0305, Train: 100.00%, Valid: 65.60% Test: 68.60%\n",
      "Run: 08, Epoch: 45, Loss: 0.0661, Train: 100.00%, Valid: 65.40% Test: 68.40%\n",
      "Run: 08, Epoch: 46, Loss: 0.0227, Train: 100.00%, Valid: 65.00% Test: 68.30%\n",
      "Run: 08, Epoch: 47, Loss: 0.0382, Train: 100.00%, Valid: 64.80% Test: 68.20%\n",
      "Run: 08, Epoch: 48, Loss: 0.0181, Train: 100.00%, Valid: 64.80% Test: 68.10%\n",
      "Run: 08, Epoch: 49, Loss: 0.0343, Train: 100.00%, Valid: 64.40% Test: 68.10%\n",
      "Run: 08, Epoch: 50, Loss: 0.0232, Train: 100.00%, Valid: 64.40% Test: 68.20%\n",
      "Run: 08, Epoch: 51, Loss: 0.0490, Train: 100.00%, Valid: 64.40% Test: 68.20%\n",
      "Run: 08, Epoch: 52, Loss: 0.0328, Train: 100.00%, Valid: 64.40% Test: 68.10%\n",
      "Run: 08, Epoch: 53, Loss: 0.0260, Train: 100.00%, Valid: 64.40% Test: 68.20%\n",
      "Run: 08, Epoch: 54, Loss: 0.0145, Train: 100.00%, Valid: 64.40% Test: 68.10%\n",
      "Run: 08, Epoch: 55, Loss: 0.0311, Train: 100.00%, Valid: 64.60% Test: 68.00%\n",
      "Run: 08, Epoch: 56, Loss: 0.0163, Train: 100.00%, Valid: 64.60% Test: 67.80%\n",
      "Run: 08, Epoch: 57, Loss: 0.0207, Train: 100.00%, Valid: 64.60% Test: 67.80%\n",
      "Run: 08, Epoch: 58, Loss: 0.0294, Train: 100.00%, Valid: 64.80% Test: 67.80%\n",
      "Run: 08, Epoch: 59, Loss: 0.0255, Train: 100.00%, Valid: 64.60% Test: 67.70%\n",
      "Run: 08, Epoch: 60, Loss: 0.0177, Train: 100.00%, Valid: 64.60% Test: 67.60%\n",
      "Run: 08, Epoch: 61, Loss: 0.0189, Train: 100.00%, Valid: 64.80% Test: 67.90%\n",
      "Run: 08, Epoch: 62, Loss: 0.0397, Train: 100.00%, Valid: 65.00% Test: 67.50%\n",
      "Run: 08, Epoch: 63, Loss: 0.0184, Train: 100.00%, Valid: 65.00% Test: 67.40%\n",
      "Run: 08, Epoch: 64, Loss: 0.0133, Train: 100.00%, Valid: 65.00% Test: 67.60%\n",
      "Run: 08, Epoch: 65, Loss: 0.0156, Train: 100.00%, Valid: 65.00% Test: 67.80%\n",
      "Run: 08, Epoch: 66, Loss: 0.0113, Train: 100.00%, Valid: 65.00% Test: 67.70%\n",
      "Run: 08, Epoch: 67, Loss: 0.0231, Train: 100.00%, Valid: 64.80% Test: 67.80%\n",
      "Run: 08, Epoch: 68, Loss: 0.0256, Train: 100.00%, Valid: 64.60% Test: 67.90%\n",
      "Run: 08, Epoch: 69, Loss: 0.0217, Train: 100.00%, Valid: 64.20% Test: 67.90%\n",
      "Run: 08, Epoch: 70, Loss: 0.0115, Train: 100.00%, Valid: 64.20% Test: 68.00%\n",
      "Run: 08, Epoch: 71, Loss: 0.0248, Train: 100.00%, Valid: 64.20% Test: 68.10%\n",
      "Run: 08, Epoch: 72, Loss: 0.0314, Train: 100.00%, Valid: 64.40% Test: 68.20%\n",
      "Run: 08, Epoch: 73, Loss: 0.0085, Train: 100.00%, Valid: 64.40% Test: 68.30%\n",
      "Run: 08, Epoch: 74, Loss: 0.0133, Train: 100.00%, Valid: 64.60% Test: 68.30%\n",
      "Run: 08, Epoch: 75, Loss: 0.0222, Train: 100.00%, Valid: 64.60% Test: 68.20%\n",
      "Run: 08, Epoch: 76, Loss: 0.0191, Train: 100.00%, Valid: 64.60% Test: 68.10%\n",
      "Run: 08, Epoch: 77, Loss: 0.0208, Train: 100.00%, Valid: 64.60% Test: 68.10%\n",
      "Run: 08, Epoch: 78, Loss: 0.0217, Train: 100.00%, Valid: 64.40% Test: 68.10%\n",
      "Run: 08, Epoch: 79, Loss: 0.0067, Train: 100.00%, Valid: 64.20% Test: 68.30%\n",
      "Run: 08, Epoch: 80, Loss: 0.0358, Train: 100.00%, Valid: 64.20% Test: 68.30%\n",
      "Run: 08, Epoch: 81, Loss: 0.0173, Train: 100.00%, Valid: 64.20% Test: 68.30%\n",
      "Run: 08, Epoch: 82, Loss: 0.0072, Train: 100.00%, Valid: 64.40% Test: 68.30%\n",
      "Run: 08, Epoch: 83, Loss: 0.0171, Train: 100.00%, Valid: 64.20% Test: 68.20%\n",
      "Run: 08, Epoch: 84, Loss: 0.0125, Train: 100.00%, Valid: 64.20% Test: 68.40%\n",
      "Run: 08, Epoch: 85, Loss: 0.0162, Train: 100.00%, Valid: 64.20% Test: 68.30%\n",
      "Run: 08, Epoch: 86, Loss: 0.0320, Train: 100.00%, Valid: 64.20% Test: 68.20%\n",
      "Run: 08, Epoch: 87, Loss: 0.0128, Train: 100.00%, Valid: 64.20% Test: 68.20%\n",
      "Run: 08, Epoch: 88, Loss: 0.0187, Train: 100.00%, Valid: 64.00% Test: 68.00%\n",
      "Run: 08, Epoch: 89, Loss: 0.0100, Train: 100.00%, Valid: 64.00% Test: 67.80%\n",
      "Run: 08, Epoch: 90, Loss: 0.0045, Train: 100.00%, Valid: 63.80% Test: 67.70%\n",
      "Run: 08, Epoch: 91, Loss: 0.0129, Train: 100.00%, Valid: 63.80% Test: 67.50%\n",
      "Run: 08, Epoch: 92, Loss: 0.0093, Train: 100.00%, Valid: 63.80% Test: 67.40%\n",
      "Run: 08, Epoch: 93, Loss: 0.0290, Train: 100.00%, Valid: 63.60% Test: 67.30%\n",
      "Run: 08, Epoch: 94, Loss: 0.0152, Train: 100.00%, Valid: 63.40% Test: 67.30%\n",
      "Run: 08, Epoch: 95, Loss: 0.0092, Train: 100.00%, Valid: 63.40% Test: 67.10%\n",
      "Run: 08, Epoch: 96, Loss: 0.0114, Train: 100.00%, Valid: 63.60% Test: 67.10%\n",
      "Run: 08, Epoch: 97, Loss: 0.0104, Train: 100.00%, Valid: 63.60% Test: 67.10%\n",
      "Run: 08, Epoch: 98, Loss: 0.0134, Train: 100.00%, Valid: 63.40% Test: 67.00%\n",
      "Run: 08, Epoch: 99, Loss: 0.0124, Train: 100.00%, Valid: 63.60% Test: 67.00%\n",
      "Run: 08, Epoch: 100, Loss: 0.0061, Train: 100.00%, Valid: 63.60% Test: 66.90%\n",
      "Run: 08, Epoch: 101, Loss: 0.0064, Train: 100.00%, Valid: 63.60% Test: 66.90%\n",
      "Run: 08, Epoch: 102, Loss: 0.0139, Train: 100.00%, Valid: 63.60% Test: 67.00%\n",
      "Run: 08, Epoch: 103, Loss: 0.0278, Train: 100.00%, Valid: 63.80% Test: 66.90%\n",
      "Run: 08, Epoch: 104, Loss: 0.0136, Train: 100.00%, Valid: 64.00% Test: 67.00%\n",
      "Run: 08, Epoch: 105, Loss: 0.0090, Train: 100.00%, Valid: 64.00% Test: 66.90%\n",
      "Run: 08, Epoch: 106, Loss: 0.0063, Train: 100.00%, Valid: 64.20% Test: 66.80%\n",
      "Run: 08, Epoch: 107, Loss: 0.0112, Train: 100.00%, Valid: 64.00% Test: 66.80%\n",
      "Run: 08, Epoch: 108, Loss: 0.0086, Train: 100.00%, Valid: 64.20% Test: 66.80%\n",
      "Run: 08, Epoch: 109, Loss: 0.0199, Train: 100.00%, Valid: 64.20% Test: 66.80%\n",
      "Run: 08, Epoch: 110, Loss: 0.0185, Train: 100.00%, Valid: 64.20% Test: 66.90%\n",
      "Run: 08, Epoch: 111, Loss: 0.0106, Train: 100.00%, Valid: 64.00% Test: 66.80%\n",
      "Run: 08, Epoch: 112, Loss: 0.0055, Train: 100.00%, Valid: 64.20% Test: 66.80%\n",
      "Run: 08, Epoch: 113, Loss: 0.0092, Train: 100.00%, Valid: 64.40% Test: 66.90%\n",
      "Run: 08, Epoch: 114, Loss: 0.0403, Train: 100.00%, Valid: 64.20% Test: 67.00%\n",
      "Run: 08, Epoch: 115, Loss: 0.0172, Train: 100.00%, Valid: 64.00% Test: 66.90%\n",
      "Run: 08, Epoch: 116, Loss: 0.0169, Train: 100.00%, Valid: 64.00% Test: 66.90%\n",
      "Run: 08, Epoch: 117, Loss: 0.0070, Train: 100.00%, Valid: 64.00% Test: 66.50%\n",
      "Run: 08, Epoch: 118, Loss: 0.0126, Train: 100.00%, Valid: 64.20% Test: 66.10%\n",
      "Run: 08, Epoch: 119, Loss: 0.0096, Train: 100.00%, Valid: 64.00% Test: 65.90%\n",
      "Run: 08, Epoch: 120, Loss: 0.0100, Train: 100.00%, Valid: 63.80% Test: 65.90%\n",
      "Run: 08, Epoch: 121, Loss: 0.0069, Train: 100.00%, Valid: 63.80% Test: 66.30%\n",
      "Run: 08, Epoch: 122, Loss: 0.0119, Train: 100.00%, Valid: 63.60% Test: 65.90%\n",
      "Run: 08, Epoch: 123, Loss: 0.0108, Train: 100.00%, Valid: 63.60% Test: 66.10%\n",
      "Run: 08, Epoch: 124, Loss: 0.0116, Train: 100.00%, Valid: 63.80% Test: 66.00%\n",
      "Run: 08, Epoch: 125, Loss: 0.0112, Train: 100.00%, Valid: 63.80% Test: 65.70%\n",
      "Run: 08, Epoch: 126, Loss: 0.0041, Train: 100.00%, Valid: 63.80% Test: 65.70%\n",
      "Run: 08, Epoch: 127, Loss: 0.0242, Train: 100.00%, Valid: 63.60% Test: 65.80%\n",
      "Run: 08, Epoch: 128, Loss: 0.0095, Train: 100.00%, Valid: 63.60% Test: 65.90%\n",
      "Run: 08, Epoch: 129, Loss: 0.0041, Train: 100.00%, Valid: 63.40% Test: 65.90%\n",
      "Run: 08, Epoch: 130, Loss: 0.0087, Train: 100.00%, Valid: 63.40% Test: 66.10%\n",
      "Run: 08, Epoch: 131, Loss: 0.0055, Train: 100.00%, Valid: 63.40% Test: 65.80%\n",
      "Run: 08, Epoch: 132, Loss: 0.0125, Train: 100.00%, Valid: 63.60% Test: 66.00%\n",
      "Run: 08, Epoch: 133, Loss: 0.0183, Train: 100.00%, Valid: 63.60% Test: 65.90%\n",
      "Run: 08, Epoch: 134, Loss: 0.0104, Train: 100.00%, Valid: 63.60% Test: 65.90%\n",
      "Run: 08, Epoch: 135, Loss: 0.0183, Train: 100.00%, Valid: 63.60% Test: 65.80%\n",
      "Run: 08, Epoch: 136, Loss: 0.0050, Train: 100.00%, Valid: 63.60% Test: 65.80%\n",
      "Run: 08, Epoch: 137, Loss: 0.0115, Train: 100.00%, Valid: 63.40% Test: 65.60%\n",
      "Run: 08, Epoch: 138, Loss: 0.0187, Train: 100.00%, Valid: 63.40% Test: 65.70%\n",
      "Run: 08, Epoch: 139, Loss: 0.0043, Train: 100.00%, Valid: 63.60% Test: 65.60%\n",
      "Run: 08, Epoch: 140, Loss: 0.0063, Train: 100.00%, Valid: 63.60% Test: 65.60%\n",
      "Run: 08, Epoch: 141, Loss: 0.0127, Train: 100.00%, Valid: 63.60% Test: 65.70%\n",
      "Run: 08, Epoch: 142, Loss: 0.0059, Train: 100.00%, Valid: 63.60% Test: 65.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 143, Loss: 0.0109, Train: 100.00%, Valid: 63.60% Test: 65.30%\n",
      "Run: 08, Epoch: 144, Loss: 0.0143, Train: 100.00%, Valid: 63.40% Test: 65.40%\n",
      "Run: 08, Epoch: 145, Loss: 0.0134, Train: 100.00%, Valid: 63.40% Test: 65.30%\n",
      "Run: 08, Epoch: 146, Loss: 0.0079, Train: 100.00%, Valid: 63.40% Test: 65.10%\n",
      "Run: 08, Epoch: 147, Loss: 0.0068, Train: 100.00%, Valid: 63.20% Test: 65.10%\n",
      "Run: 08, Epoch: 148, Loss: 0.0049, Train: 100.00%, Valid: 62.80% Test: 65.10%\n",
      "Run: 08, Epoch: 149, Loss: 0.0014, Train: 100.00%, Valid: 62.80% Test: 65.00%\n",
      "Run: 08, Epoch: 150, Loss: 0.0028, Train: 100.00%, Valid: 62.80% Test: 65.20%\n",
      "Run: 08, Epoch: 151, Loss: 0.0067, Train: 100.00%, Valid: 62.60% Test: 65.10%\n",
      "Run: 08, Epoch: 152, Loss: 0.0054, Train: 100.00%, Valid: 62.60% Test: 65.00%\n",
      "Run: 08, Epoch: 153, Loss: 0.0113, Train: 100.00%, Valid: 62.60% Test: 65.10%\n",
      "Run: 08, Epoch: 154, Loss: 0.0044, Train: 100.00%, Valid: 63.00% Test: 65.00%\n",
      "Run: 08, Epoch: 155, Loss: 0.0175, Train: 100.00%, Valid: 63.00% Test: 64.90%\n",
      "Run: 08, Epoch: 156, Loss: 0.0082, Train: 100.00%, Valid: 63.00% Test: 64.90%\n",
      "Run: 08, Epoch: 157, Loss: 0.0040, Train: 100.00%, Valid: 63.00% Test: 65.00%\n",
      "Run: 08, Epoch: 158, Loss: 0.0067, Train: 100.00%, Valid: 62.40% Test: 64.80%\n",
      "Run: 08, Epoch: 159, Loss: 0.0073, Train: 100.00%, Valid: 62.60% Test: 64.90%\n",
      "Run: 08, Epoch: 160, Loss: 0.0038, Train: 100.00%, Valid: 62.80% Test: 64.80%\n",
      "Run: 08, Epoch: 161, Loss: 0.0040, Train: 100.00%, Valid: 62.80% Test: 64.80%\n",
      "Run: 08, Epoch: 162, Loss: 0.0053, Train: 100.00%, Valid: 62.80% Test: 64.80%\n",
      "Run: 08, Epoch: 163, Loss: 0.0092, Train: 100.00%, Valid: 63.00% Test: 64.80%\n",
      "Run: 08, Epoch: 164, Loss: 0.0044, Train: 100.00%, Valid: 62.80% Test: 64.70%\n",
      "Run: 08, Epoch: 165, Loss: 0.0026, Train: 100.00%, Valid: 62.60% Test: 64.80%\n",
      "Run: 08, Epoch: 166, Loss: 0.0224, Train: 100.00%, Valid: 62.40% Test: 64.70%\n",
      "Run: 08, Epoch: 167, Loss: 0.0037, Train: 100.00%, Valid: 62.40% Test: 64.70%\n",
      "Run: 08, Epoch: 168, Loss: 0.0121, Train: 100.00%, Valid: 62.40% Test: 64.70%\n",
      "Run: 08, Epoch: 169, Loss: 0.0054, Train: 100.00%, Valid: 62.60% Test: 64.90%\n",
      "Run: 08, Epoch: 170, Loss: 0.0026, Train: 100.00%, Valid: 62.20% Test: 65.00%\n",
      "Run: 08, Epoch: 171, Loss: 0.0118, Train: 100.00%, Valid: 62.20% Test: 65.10%\n",
      "Run: 08, Epoch: 172, Loss: 0.0118, Train: 100.00%, Valid: 62.00% Test: 65.20%\n",
      "Run: 08, Epoch: 173, Loss: 0.0188, Train: 100.00%, Valid: 62.00% Test: 65.50%\n",
      "Run: 08, Epoch: 174, Loss: 0.0230, Train: 100.00%, Valid: 62.00% Test: 65.00%\n",
      "Run: 08, Epoch: 175, Loss: 0.0112, Train: 100.00%, Valid: 61.60% Test: 64.30%\n",
      "Run: 08, Epoch: 176, Loss: 0.0016, Train: 100.00%, Valid: 61.40% Test: 64.20%\n",
      "Run: 08, Epoch: 177, Loss: 0.0170, Train: 100.00%, Valid: 61.20% Test: 64.10%\n",
      "Run: 08, Epoch: 178, Loss: 0.0134, Train: 100.00%, Valid: 61.60% Test: 64.10%\n",
      "Run: 08, Epoch: 179, Loss: 0.0039, Train: 100.00%, Valid: 61.80% Test: 64.20%\n",
      "Run: 08, Epoch: 180, Loss: 0.0052, Train: 100.00%, Valid: 62.00% Test: 64.40%\n",
      "Run: 08, Epoch: 181, Loss: 0.0146, Train: 100.00%, Valid: 62.20% Test: 64.40%\n",
      "Run: 08, Epoch: 182, Loss: 0.0087, Train: 100.00%, Valid: 62.00% Test: 64.50%\n",
      "Run: 08, Epoch: 183, Loss: 0.0097, Train: 100.00%, Valid: 61.80% Test: 64.30%\n",
      "Run: 08, Epoch: 184, Loss: 0.0030, Train: 100.00%, Valid: 62.00% Test: 64.40%\n",
      "Run: 08, Epoch: 185, Loss: 0.0095, Train: 100.00%, Valid: 62.20% Test: 64.40%\n",
      "Run: 08, Epoch: 186, Loss: 0.0134, Train: 100.00%, Valid: 62.20% Test: 64.40%\n",
      "Run: 08, Epoch: 187, Loss: 0.0186, Train: 100.00%, Valid: 61.80% Test: 64.20%\n",
      "Run: 08, Epoch: 188, Loss: 0.0142, Train: 100.00%, Valid: 61.80% Test: 64.50%\n",
      "Run: 08, Epoch: 189, Loss: 0.0054, Train: 100.00%, Valid: 61.80% Test: 64.60%\n",
      "Run: 08, Epoch: 190, Loss: 0.0035, Train: 100.00%, Valid: 61.80% Test: 64.80%\n",
      "Run: 08, Epoch: 191, Loss: 0.0175, Train: 100.00%, Valid: 62.00% Test: 65.10%\n",
      "Run: 08, Epoch: 192, Loss: 0.0033, Train: 100.00%, Valid: 62.60% Test: 65.10%\n",
      "Run: 08, Epoch: 193, Loss: 0.0033, Train: 100.00%, Valid: 62.40% Test: 64.90%\n",
      "Run: 08, Epoch: 194, Loss: 0.0056, Train: 100.00%, Valid: 62.40% Test: 65.10%\n",
      "Run: 08, Epoch: 195, Loss: 0.0181, Train: 100.00%, Valid: 62.40% Test: 65.10%\n",
      "Run: 08, Epoch: 196, Loss: 0.0173, Train: 100.00%, Valid: 62.40% Test: 65.20%\n",
      "Run: 08, Epoch: 197, Loss: 0.0155, Train: 100.00%, Valid: 62.80% Test: 65.40%\n",
      "Run: 08, Epoch: 198, Loss: 0.0016, Train: 100.00%, Valid: 63.00% Test: 65.40%\n",
      "Run: 08, Epoch: 199, Loss: 0.0036, Train: 100.00%, Valid: 63.20% Test: 65.40%\n",
      "Run: 08, Epoch: 200, Loss: 0.0110, Train: 100.00%, Valid: 63.20% Test: 65.40%\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 72.60\n",
      "  Final Train: 100.00\n",
      "   Final Test: 75.80\n",
      "Run: 09, Epoch: 01, Loss: 2.1842, Train: 61.43%, Valid: 31.00% Test: 33.80%\n",
      "Run: 09, Epoch: 02, Loss: 1.2718, Train: 74.29%, Valid: 42.20% Test: 44.90%\n",
      "Run: 09, Epoch: 03, Loss: 0.9841, Train: 88.57%, Valid: 51.80% Test: 53.30%\n",
      "Run: 09, Epoch: 04, Loss: 0.8029, Train: 94.29%, Valid: 59.80% Test: 61.20%\n",
      "Run: 09, Epoch: 05, Loss: 0.6835, Train: 95.71%, Valid: 63.20% Test: 65.90%\n",
      "Run: 09, Epoch: 06, Loss: 0.6291, Train: 96.43%, Valid: 66.20% Test: 69.40%\n",
      "Run: 09, Epoch: 07, Loss: 0.5589, Train: 97.86%, Valid: 68.80% Test: 71.40%\n",
      "Run: 09, Epoch: 08, Loss: 0.5148, Train: 98.57%, Valid: 71.40% Test: 73.00%\n",
      "Run: 09, Epoch: 09, Loss: 0.4421, Train: 98.57%, Valid: 73.00% Test: 73.90%\n",
      "Run: 09, Epoch: 10, Loss: 0.4087, Train: 98.57%, Valid: 73.40% Test: 74.40%\n",
      "Run: 09, Epoch: 11, Loss: 0.3755, Train: 99.29%, Valid: 72.80% Test: 74.80%\n",
      "Run: 09, Epoch: 12, Loss: 0.3135, Train: 99.29%, Valid: 73.40% Test: 75.60%\n",
      "Run: 09, Epoch: 13, Loss: 0.2745, Train: 100.00%, Valid: 73.40% Test: 76.40%\n",
      "Run: 09, Epoch: 14, Loss: 0.2422, Train: 100.00%, Valid: 73.20% Test: 76.50%\n",
      "Run: 09, Epoch: 15, Loss: 0.2242, Train: 100.00%, Valid: 74.00% Test: 77.10%\n",
      "Run: 09, Epoch: 16, Loss: 0.2061, Train: 100.00%, Valid: 74.80% Test: 77.10%\n",
      "Run: 09, Epoch: 17, Loss: 0.1586, Train: 100.00%, Valid: 75.20% Test: 77.30%\n",
      "Run: 09, Epoch: 18, Loss: 0.1589, Train: 100.00%, Valid: 74.40% Test: 77.70%\n",
      "Run: 09, Epoch: 19, Loss: 0.1516, Train: 100.00%, Valid: 74.40% Test: 77.80%\n",
      "Run: 09, Epoch: 20, Loss: 0.1350, Train: 100.00%, Valid: 74.00% Test: 77.90%\n",
      "Run: 09, Epoch: 21, Loss: 0.0971, Train: 100.00%, Valid: 73.80% Test: 77.40%\n",
      "Run: 09, Epoch: 22, Loss: 0.1178, Train: 100.00%, Valid: 74.20% Test: 77.20%\n",
      "Run: 09, Epoch: 23, Loss: 0.0798, Train: 100.00%, Valid: 74.40% Test: 77.30%\n",
      "Run: 09, Epoch: 24, Loss: 0.0901, Train: 100.00%, Valid: 74.20% Test: 77.30%\n",
      "Run: 09, Epoch: 25, Loss: 0.0648, Train: 100.00%, Valid: 74.00% Test: 77.10%\n",
      "Run: 09, Epoch: 26, Loss: 0.1027, Train: 100.00%, Valid: 73.60% Test: 76.80%\n",
      "Run: 09, Epoch: 27, Loss: 0.0780, Train: 100.00%, Valid: 73.40% Test: 76.30%\n",
      "Run: 09, Epoch: 28, Loss: 0.0682, Train: 100.00%, Valid: 73.00% Test: 76.20%\n",
      "Run: 09, Epoch: 29, Loss: 0.0668, Train: 100.00%, Valid: 73.00% Test: 76.20%\n",
      "Run: 09, Epoch: 30, Loss: 0.0553, Train: 100.00%, Valid: 72.40% Test: 75.90%\n",
      "Run: 09, Epoch: 31, Loss: 0.0445, Train: 100.00%, Valid: 72.40% Test: 75.90%\n",
      "Run: 09, Epoch: 32, Loss: 0.0372, Train: 100.00%, Valid: 71.60% Test: 75.90%\n",
      "Run: 09, Epoch: 33, Loss: 0.0386, Train: 100.00%, Valid: 71.00% Test: 75.80%\n",
      "Run: 09, Epoch: 34, Loss: 0.0417, Train: 100.00%, Valid: 71.00% Test: 75.50%\n",
      "Run: 09, Epoch: 35, Loss: 0.0361, Train: 100.00%, Valid: 70.80% Test: 74.80%\n",
      "Run: 09, Epoch: 36, Loss: 0.0436, Train: 100.00%, Valid: 71.00% Test: 74.80%\n",
      "Run: 09, Epoch: 37, Loss: 0.0418, Train: 100.00%, Valid: 70.80% Test: 74.60%\n",
      "Run: 09, Epoch: 38, Loss: 0.0342, Train: 100.00%, Valid: 70.80% Test: 74.20%\n",
      "Run: 09, Epoch: 39, Loss: 0.0380, Train: 100.00%, Valid: 71.20% Test: 73.90%\n",
      "Run: 09, Epoch: 40, Loss: 0.0240, Train: 100.00%, Valid: 71.00% Test: 73.80%\n",
      "Run: 09, Epoch: 41, Loss: 0.0316, Train: 100.00%, Valid: 71.00% Test: 73.70%\n",
      "Run: 09, Epoch: 42, Loss: 0.0214, Train: 100.00%, Valid: 71.00% Test: 73.40%\n",
      "Run: 09, Epoch: 43, Loss: 0.0165, Train: 100.00%, Valid: 70.80% Test: 72.90%\n",
      "Run: 09, Epoch: 44, Loss: 0.0279, Train: 100.00%, Valid: 70.60% Test: 72.50%\n",
      "Run: 09, Epoch: 45, Loss: 0.0419, Train: 100.00%, Valid: 70.60% Test: 72.40%\n",
      "Run: 09, Epoch: 46, Loss: 0.0357, Train: 100.00%, Valid: 70.00% Test: 72.60%\n",
      "Run: 09, Epoch: 47, Loss: 0.0175, Train: 100.00%, Valid: 70.20% Test: 72.20%\n",
      "Run: 09, Epoch: 48, Loss: 0.0367, Train: 100.00%, Valid: 70.00% Test: 72.30%\n",
      "Run: 09, Epoch: 49, Loss: 0.0275, Train: 100.00%, Valid: 69.60% Test: 72.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 50, Loss: 0.0156, Train: 100.00%, Valid: 69.60% Test: 71.90%\n",
      "Run: 09, Epoch: 51, Loss: 0.0121, Train: 100.00%, Valid: 69.60% Test: 72.10%\n",
      "Run: 09, Epoch: 52, Loss: 0.0142, Train: 100.00%, Valid: 69.80% Test: 72.00%\n",
      "Run: 09, Epoch: 53, Loss: 0.0230, Train: 100.00%, Valid: 69.80% Test: 72.10%\n",
      "Run: 09, Epoch: 54, Loss: 0.0320, Train: 100.00%, Valid: 69.80% Test: 71.90%\n",
      "Run: 09, Epoch: 55, Loss: 0.0162, Train: 100.00%, Valid: 69.80% Test: 71.70%\n",
      "Run: 09, Epoch: 56, Loss: 0.0273, Train: 100.00%, Valid: 69.60% Test: 71.80%\n",
      "Run: 09, Epoch: 57, Loss: 0.0269, Train: 100.00%, Valid: 69.80% Test: 71.80%\n",
      "Run: 09, Epoch: 58, Loss: 0.0345, Train: 100.00%, Valid: 69.40% Test: 71.80%\n",
      "Run: 09, Epoch: 59, Loss: 0.0182, Train: 100.00%, Valid: 69.20% Test: 71.70%\n",
      "Run: 09, Epoch: 60, Loss: 0.0262, Train: 100.00%, Valid: 69.20% Test: 71.70%\n",
      "Run: 09, Epoch: 61, Loss: 0.0245, Train: 100.00%, Valid: 69.20% Test: 71.70%\n",
      "Run: 09, Epoch: 62, Loss: 0.0344, Train: 100.00%, Valid: 69.20% Test: 71.90%\n",
      "Run: 09, Epoch: 63, Loss: 0.0331, Train: 100.00%, Valid: 69.00% Test: 71.60%\n",
      "Run: 09, Epoch: 64, Loss: 0.0099, Train: 100.00%, Valid: 69.00% Test: 71.40%\n",
      "Run: 09, Epoch: 65, Loss: 0.0302, Train: 100.00%, Valid: 69.20% Test: 71.20%\n",
      "Run: 09, Epoch: 66, Loss: 0.0194, Train: 100.00%, Valid: 69.20% Test: 71.30%\n",
      "Run: 09, Epoch: 67, Loss: 0.0064, Train: 100.00%, Valid: 69.00% Test: 71.30%\n",
      "Run: 09, Epoch: 68, Loss: 0.0251, Train: 100.00%, Valid: 69.00% Test: 71.10%\n",
      "Run: 09, Epoch: 69, Loss: 0.0254, Train: 100.00%, Valid: 69.00% Test: 71.00%\n",
      "Run: 09, Epoch: 70, Loss: 0.0077, Train: 100.00%, Valid: 69.00% Test: 71.00%\n",
      "Run: 09, Epoch: 71, Loss: 0.0206, Train: 100.00%, Valid: 69.40% Test: 71.10%\n",
      "Run: 09, Epoch: 72, Loss: 0.0128, Train: 100.00%, Valid: 69.60% Test: 70.90%\n",
      "Run: 09, Epoch: 73, Loss: 0.0139, Train: 100.00%, Valid: 69.80% Test: 71.00%\n",
      "Run: 09, Epoch: 74, Loss: 0.0233, Train: 100.00%, Valid: 69.40% Test: 71.00%\n",
      "Run: 09, Epoch: 75, Loss: 0.0265, Train: 100.00%, Valid: 69.40% Test: 71.00%\n",
      "Run: 09, Epoch: 76, Loss: 0.0074, Train: 100.00%, Valid: 69.40% Test: 71.00%\n",
      "Run: 09, Epoch: 77, Loss: 0.0094, Train: 100.00%, Valid: 69.20% Test: 71.10%\n",
      "Run: 09, Epoch: 78, Loss: 0.0363, Train: 100.00%, Valid: 69.40% Test: 71.10%\n",
      "Run: 09, Epoch: 79, Loss: 0.0143, Train: 100.00%, Valid: 69.40% Test: 71.10%\n",
      "Run: 09, Epoch: 80, Loss: 0.0122, Train: 100.00%, Valid: 69.60% Test: 71.20%\n",
      "Run: 09, Epoch: 81, Loss: 0.0094, Train: 100.00%, Valid: 69.60% Test: 71.00%\n",
      "Run: 09, Epoch: 82, Loss: 0.0123, Train: 100.00%, Valid: 69.60% Test: 71.00%\n",
      "Run: 09, Epoch: 83, Loss: 0.0124, Train: 100.00%, Valid: 69.20% Test: 70.90%\n",
      "Run: 09, Epoch: 84, Loss: 0.0122, Train: 100.00%, Valid: 69.20% Test: 70.80%\n",
      "Run: 09, Epoch: 85, Loss: 0.0149, Train: 100.00%, Valid: 69.20% Test: 70.80%\n",
      "Run: 09, Epoch: 86, Loss: 0.0189, Train: 100.00%, Valid: 69.60% Test: 70.80%\n",
      "Run: 09, Epoch: 87, Loss: 0.0082, Train: 100.00%, Valid: 69.60% Test: 70.90%\n",
      "Run: 09, Epoch: 88, Loss: 0.0206, Train: 100.00%, Valid: 69.60% Test: 70.80%\n",
      "Run: 09, Epoch: 89, Loss: 0.0105, Train: 100.00%, Valid: 69.40% Test: 70.60%\n",
      "Run: 09, Epoch: 90, Loss: 0.0078, Train: 100.00%, Valid: 69.60% Test: 70.70%\n",
      "Run: 09, Epoch: 91, Loss: 0.0035, Train: 100.00%, Valid: 69.60% Test: 70.70%\n",
      "Run: 09, Epoch: 92, Loss: 0.0052, Train: 100.00%, Valid: 69.60% Test: 70.70%\n",
      "Run: 09, Epoch: 93, Loss: 0.0212, Train: 100.00%, Valid: 69.60% Test: 70.70%\n",
      "Run: 09, Epoch: 94, Loss: 0.0093, Train: 100.00%, Valid: 69.60% Test: 70.70%\n",
      "Run: 09, Epoch: 95, Loss: 0.0194, Train: 100.00%, Valid: 69.60% Test: 70.60%\n",
      "Run: 09, Epoch: 96, Loss: 0.0266, Train: 100.00%, Valid: 69.60% Test: 70.90%\n",
      "Run: 09, Epoch: 97, Loss: 0.0075, Train: 100.00%, Valid: 69.60% Test: 70.90%\n",
      "Run: 09, Epoch: 98, Loss: 0.0073, Train: 100.00%, Valid: 69.40% Test: 70.90%\n",
      "Run: 09, Epoch: 99, Loss: 0.0090, Train: 100.00%, Valid: 69.60% Test: 70.80%\n",
      "Run: 09, Epoch: 100, Loss: 0.0089, Train: 100.00%, Valid: 69.60% Test: 70.80%\n",
      "Run: 09, Epoch: 101, Loss: 0.0211, Train: 100.00%, Valid: 69.60% Test: 70.70%\n",
      "Run: 09, Epoch: 102, Loss: 0.0089, Train: 100.00%, Valid: 69.60% Test: 70.70%\n",
      "Run: 09, Epoch: 103, Loss: 0.0092, Train: 100.00%, Valid: 69.60% Test: 70.70%\n",
      "Run: 09, Epoch: 104, Loss: 0.0137, Train: 100.00%, Valid: 69.20% Test: 70.70%\n",
      "Run: 09, Epoch: 105, Loss: 0.0073, Train: 100.00%, Valid: 69.20% Test: 70.80%\n",
      "Run: 09, Epoch: 106, Loss: 0.0063, Train: 100.00%, Valid: 68.80% Test: 70.40%\n",
      "Run: 09, Epoch: 107, Loss: 0.0103, Train: 100.00%, Valid: 68.40% Test: 70.30%\n",
      "Run: 09, Epoch: 108, Loss: 0.0073, Train: 100.00%, Valid: 68.80% Test: 70.10%\n",
      "Run: 09, Epoch: 109, Loss: 0.0200, Train: 100.00%, Valid: 68.60% Test: 70.10%\n",
      "Run: 09, Epoch: 110, Loss: 0.0061, Train: 100.00%, Valid: 68.60% Test: 70.10%\n",
      "Run: 09, Epoch: 111, Loss: 0.0194, Train: 100.00%, Valid: 68.60% Test: 70.10%\n",
      "Run: 09, Epoch: 112, Loss: 0.0054, Train: 100.00%, Valid: 68.80% Test: 70.20%\n",
      "Run: 09, Epoch: 113, Loss: 0.0140, Train: 100.00%, Valid: 69.00% Test: 70.20%\n",
      "Run: 09, Epoch: 114, Loss: 0.0241, Train: 100.00%, Valid: 69.00% Test: 70.20%\n",
      "Run: 09, Epoch: 115, Loss: 0.0087, Train: 100.00%, Valid: 69.00% Test: 70.30%\n",
      "Run: 09, Epoch: 116, Loss: 0.0198, Train: 100.00%, Valid: 69.20% Test: 70.10%\n",
      "Run: 09, Epoch: 117, Loss: 0.0039, Train: 100.00%, Valid: 69.20% Test: 70.30%\n",
      "Run: 09, Epoch: 118, Loss: 0.0058, Train: 100.00%, Valid: 69.20% Test: 70.30%\n",
      "Run: 09, Epoch: 119, Loss: 0.0109, Train: 100.00%, Valid: 69.20% Test: 70.40%\n",
      "Run: 09, Epoch: 120, Loss: 0.0114, Train: 100.00%, Valid: 69.20% Test: 70.40%\n",
      "Run: 09, Epoch: 121, Loss: 0.0104, Train: 100.00%, Valid: 69.20% Test: 70.30%\n",
      "Run: 09, Epoch: 122, Loss: 0.0121, Train: 100.00%, Valid: 69.40% Test: 70.30%\n",
      "Run: 09, Epoch: 123, Loss: 0.0198, Train: 100.00%, Valid: 69.00% Test: 70.20%\n",
      "Run: 09, Epoch: 124, Loss: 0.0031, Train: 100.00%, Valid: 68.80% Test: 70.00%\n",
      "Run: 09, Epoch: 125, Loss: 0.0029, Train: 100.00%, Valid: 69.00% Test: 69.90%\n",
      "Run: 09, Epoch: 126, Loss: 0.0029, Train: 100.00%, Valid: 69.20% Test: 70.10%\n",
      "Run: 09, Epoch: 127, Loss: 0.0060, Train: 100.00%, Valid: 69.20% Test: 70.10%\n",
      "Run: 09, Epoch: 128, Loss: 0.0096, Train: 100.00%, Valid: 68.80% Test: 70.20%\n",
      "Run: 09, Epoch: 129, Loss: 0.0034, Train: 100.00%, Valid: 68.80% Test: 70.30%\n",
      "Run: 09, Epoch: 130, Loss: 0.0056, Train: 100.00%, Valid: 68.60% Test: 70.30%\n",
      "Run: 09, Epoch: 131, Loss: 0.0053, Train: 100.00%, Valid: 68.60% Test: 70.30%\n",
      "Run: 09, Epoch: 132, Loss: 0.0133, Train: 100.00%, Valid: 68.60% Test: 70.40%\n",
      "Run: 09, Epoch: 133, Loss: 0.0060, Train: 100.00%, Valid: 68.80% Test: 70.40%\n",
      "Run: 09, Epoch: 134, Loss: 0.0111, Train: 100.00%, Valid: 68.80% Test: 70.40%\n",
      "Run: 09, Epoch: 135, Loss: 0.0036, Train: 100.00%, Valid: 68.80% Test: 70.50%\n",
      "Run: 09, Epoch: 136, Loss: 0.0101, Train: 100.00%, Valid: 68.60% Test: 70.60%\n",
      "Run: 09, Epoch: 137, Loss: 0.0069, Train: 100.00%, Valid: 68.80% Test: 70.50%\n",
      "Run: 09, Epoch: 138, Loss: 0.0110, Train: 100.00%, Valid: 69.20% Test: 70.10%\n",
      "Run: 09, Epoch: 139, Loss: 0.0054, Train: 100.00%, Valid: 69.00% Test: 70.10%\n",
      "Run: 09, Epoch: 140, Loss: 0.0188, Train: 100.00%, Valid: 68.80% Test: 70.10%\n",
      "Run: 09, Epoch: 141, Loss: 0.0081, Train: 100.00%, Valid: 68.80% Test: 70.20%\n",
      "Run: 09, Epoch: 142, Loss: 0.0038, Train: 100.00%, Valid: 68.80% Test: 70.20%\n",
      "Run: 09, Epoch: 143, Loss: 0.0096, Train: 100.00%, Valid: 68.80% Test: 70.00%\n",
      "Run: 09, Epoch: 144, Loss: 0.0032, Train: 100.00%, Valid: 69.20% Test: 70.00%\n",
      "Run: 09, Epoch: 145, Loss: 0.0101, Train: 100.00%, Valid: 69.40% Test: 70.00%\n",
      "Run: 09, Epoch: 146, Loss: 0.0052, Train: 100.00%, Valid: 69.40% Test: 70.00%\n",
      "Run: 09, Epoch: 147, Loss: 0.0043, Train: 100.00%, Valid: 69.20% Test: 69.90%\n",
      "Run: 09, Epoch: 148, Loss: 0.0080, Train: 100.00%, Valid: 69.20% Test: 69.90%\n",
      "Run: 09, Epoch: 149, Loss: 0.0106, Train: 100.00%, Valid: 69.00% Test: 69.80%\n",
      "Run: 09, Epoch: 150, Loss: 0.0103, Train: 100.00%, Valid: 68.80% Test: 69.60%\n",
      "Run: 09, Epoch: 151, Loss: 0.0053, Train: 100.00%, Valid: 68.60% Test: 69.60%\n",
      "Run: 09, Epoch: 152, Loss: 0.0050, Train: 100.00%, Valid: 68.60% Test: 69.50%\n",
      "Run: 09, Epoch: 153, Loss: 0.0043, Train: 100.00%, Valid: 68.40% Test: 69.50%\n",
      "Run: 09, Epoch: 154, Loss: 0.0089, Train: 100.00%, Valid: 68.60% Test: 69.50%\n",
      "Run: 09, Epoch: 155, Loss: 0.0032, Train: 100.00%, Valid: 68.20% Test: 69.30%\n",
      "Run: 09, Epoch: 156, Loss: 0.0112, Train: 100.00%, Valid: 68.40% Test: 69.30%\n",
      "Run: 09, Epoch: 157, Loss: 0.0049, Train: 100.00%, Valid: 68.60% Test: 69.20%\n",
      "Run: 09, Epoch: 158, Loss: 0.0039, Train: 100.00%, Valid: 68.60% Test: 69.00%\n",
      "Run: 09, Epoch: 159, Loss: 0.0078, Train: 100.00%, Valid: 68.60% Test: 68.80%\n",
      "Run: 09, Epoch: 160, Loss: 0.0229, Train: 100.00%, Valid: 68.60% Test: 68.70%\n",
      "Run: 09, Epoch: 161, Loss: 0.0162, Train: 100.00%, Valid: 68.60% Test: 68.80%\n",
      "Run: 09, Epoch: 162, Loss: 0.0072, Train: 100.00%, Valid: 68.40% Test: 68.90%\n",
      "Run: 09, Epoch: 163, Loss: 0.0025, Train: 100.00%, Valid: 68.20% Test: 68.80%\n",
      "Run: 09, Epoch: 164, Loss: 0.0076, Train: 100.00%, Valid: 68.20% Test: 68.70%\n",
      "Run: 09, Epoch: 165, Loss: 0.0074, Train: 100.00%, Valid: 68.20% Test: 68.60%\n",
      "Run: 09, Epoch: 166, Loss: 0.0093, Train: 100.00%, Valid: 68.20% Test: 68.60%\n",
      "Run: 09, Epoch: 167, Loss: 0.0146, Train: 100.00%, Valid: 67.80% Test: 68.70%\n",
      "Run: 09, Epoch: 168, Loss: 0.0143, Train: 100.00%, Valid: 67.60% Test: 68.80%\n",
      "Run: 09, Epoch: 169, Loss: 0.0056, Train: 100.00%, Valid: 67.40% Test: 68.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 170, Loss: 0.0130, Train: 100.00%, Valid: 67.60% Test: 68.50%\n",
      "Run: 09, Epoch: 171, Loss: 0.0046, Train: 100.00%, Valid: 68.00% Test: 68.60%\n",
      "Run: 09, Epoch: 172, Loss: 0.0074, Train: 100.00%, Valid: 68.20% Test: 68.50%\n",
      "Run: 09, Epoch: 173, Loss: 0.0018, Train: 100.00%, Valid: 68.60% Test: 68.50%\n",
      "Run: 09, Epoch: 174, Loss: 0.0055, Train: 100.00%, Valid: 68.80% Test: 68.70%\n",
      "Run: 09, Epoch: 175, Loss: 0.0078, Train: 100.00%, Valid: 68.80% Test: 68.50%\n",
      "Run: 09, Epoch: 176, Loss: 0.0071, Train: 100.00%, Valid: 68.80% Test: 68.80%\n",
      "Run: 09, Epoch: 177, Loss: 0.0222, Train: 100.00%, Valid: 67.80% Test: 69.00%\n",
      "Run: 09, Epoch: 178, Loss: 0.0047, Train: 100.00%, Valid: 67.80% Test: 68.80%\n",
      "Run: 09, Epoch: 179, Loss: 0.0120, Train: 100.00%, Valid: 67.80% Test: 68.70%\n",
      "Run: 09, Epoch: 180, Loss: 0.0184, Train: 100.00%, Valid: 67.60% Test: 68.60%\n",
      "Run: 09, Epoch: 181, Loss: 0.0051, Train: 100.00%, Valid: 67.00% Test: 68.30%\n",
      "Run: 09, Epoch: 182, Loss: 0.0383, Train: 100.00%, Valid: 66.60% Test: 68.40%\n",
      "Run: 09, Epoch: 183, Loss: 0.0061, Train: 100.00%, Valid: 66.80% Test: 68.20%\n",
      "Run: 09, Epoch: 184, Loss: 0.0045, Train: 100.00%, Valid: 67.00% Test: 68.30%\n",
      "Run: 09, Epoch: 185, Loss: 0.0035, Train: 100.00%, Valid: 66.60% Test: 68.10%\n",
      "Run: 09, Epoch: 186, Loss: 0.0033, Train: 100.00%, Valid: 66.20% Test: 67.90%\n",
      "Run: 09, Epoch: 187, Loss: 0.0155, Train: 100.00%, Valid: 66.00% Test: 67.70%\n",
      "Run: 09, Epoch: 188, Loss: 0.0026, Train: 100.00%, Valid: 66.20% Test: 67.70%\n",
      "Run: 09, Epoch: 189, Loss: 0.0020, Train: 100.00%, Valid: 66.00% Test: 67.80%\n",
      "Run: 09, Epoch: 190, Loss: 0.0019, Train: 100.00%, Valid: 65.60% Test: 67.70%\n",
      "Run: 09, Epoch: 191, Loss: 0.0011, Train: 100.00%, Valid: 65.60% Test: 67.70%\n",
      "Run: 09, Epoch: 192, Loss: 0.0018, Train: 100.00%, Valid: 66.00% Test: 67.70%\n",
      "Run: 09, Epoch: 193, Loss: 0.0083, Train: 100.00%, Valid: 66.00% Test: 67.60%\n",
      "Run: 09, Epoch: 194, Loss: 0.0041, Train: 100.00%, Valid: 66.00% Test: 67.70%\n",
      "Run: 09, Epoch: 195, Loss: 0.0040, Train: 100.00%, Valid: 66.00% Test: 67.70%\n",
      "Run: 09, Epoch: 196, Loss: 0.0058, Train: 100.00%, Valid: 66.00% Test: 67.70%\n",
      "Run: 09, Epoch: 197, Loss: 0.0020, Train: 100.00%, Valid: 66.00% Test: 67.80%\n",
      "Run: 09, Epoch: 198, Loss: 0.0039, Train: 100.00%, Valid: 66.00% Test: 67.80%\n",
      "Run: 09, Epoch: 199, Loss: 0.0026, Train: 100.00%, Valid: 66.00% Test: 67.90%\n",
      "Run: 09, Epoch: 200, Loss: 0.0048, Train: 100.00%, Valid: 66.00% Test: 67.80%\n",
      "Run 09:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 75.20\n",
      "  Final Train: 100.00\n",
      "   Final Test: 77.30\n",
      "Run: 10, Epoch: 01, Loss: 2.2228, Train: 62.86%, Valid: 36.00% Test: 37.60%\n",
      "Run: 10, Epoch: 02, Loss: 1.2912, Train: 92.86%, Valid: 62.60% Test: 63.40%\n",
      "Run: 10, Epoch: 03, Loss: 0.9364, Train: 94.29%, Valid: 68.40% Test: 71.40%\n",
      "Run: 10, Epoch: 04, Loss: 0.7393, Train: 95.00%, Valid: 72.00% Test: 73.50%\n",
      "Run: 10, Epoch: 05, Loss: 0.6280, Train: 95.00%, Valid: 74.20% Test: 75.30%\n",
      "Run: 10, Epoch: 06, Loss: 0.5545, Train: 95.71%, Valid: 73.80% Test: 76.20%\n",
      "Run: 10, Epoch: 07, Loss: 0.4864, Train: 95.71%, Valid: 74.20% Test: 76.20%\n",
      "Run: 10, Epoch: 08, Loss: 0.4285, Train: 96.43%, Valid: 73.60% Test: 76.00%\n",
      "Run: 10, Epoch: 09, Loss: 0.3665, Train: 97.14%, Valid: 73.20% Test: 75.40%\n",
      "Run: 10, Epoch: 10, Loss: 0.3607, Train: 97.86%, Valid: 73.20% Test: 75.30%\n",
      "Run: 10, Epoch: 11, Loss: 0.2803, Train: 99.29%, Valid: 72.60% Test: 75.30%\n",
      "Run: 10, Epoch: 12, Loss: 0.3090, Train: 100.00%, Valid: 71.60% Test: 75.40%\n",
      "Run: 10, Epoch: 13, Loss: 0.2101, Train: 100.00%, Valid: 72.40% Test: 75.00%\n",
      "Run: 10, Epoch: 14, Loss: 0.2064, Train: 100.00%, Valid: 72.00% Test: 74.60%\n",
      "Run: 10, Epoch: 15, Loss: 0.1834, Train: 100.00%, Valid: 71.20% Test: 74.60%\n",
      "Run: 10, Epoch: 16, Loss: 0.1440, Train: 100.00%, Valid: 71.40% Test: 74.80%\n",
      "Run: 10, Epoch: 17, Loss: 0.1335, Train: 100.00%, Valid: 71.60% Test: 74.50%\n",
      "Run: 10, Epoch: 18, Loss: 0.1664, Train: 100.00%, Valid: 72.00% Test: 74.40%\n",
      "Run: 10, Epoch: 19, Loss: 0.1212, Train: 100.00%, Valid: 71.80% Test: 74.40%\n",
      "Run: 10, Epoch: 20, Loss: 0.1104, Train: 100.00%, Valid: 71.40% Test: 74.30%\n",
      "Run: 10, Epoch: 21, Loss: 0.1142, Train: 100.00%, Valid: 71.60% Test: 73.90%\n",
      "Run: 10, Epoch: 22, Loss: 0.0873, Train: 100.00%, Valid: 70.60% Test: 73.50%\n",
      "Run: 10, Epoch: 23, Loss: 0.0915, Train: 100.00%, Valid: 70.20% Test: 73.60%\n",
      "Run: 10, Epoch: 24, Loss: 0.0991, Train: 100.00%, Valid: 71.00% Test: 73.20%\n",
      "Run: 10, Epoch: 25, Loss: 0.1166, Train: 100.00%, Valid: 71.40% Test: 73.10%\n",
      "Run: 10, Epoch: 26, Loss: 0.0969, Train: 100.00%, Valid: 71.20% Test: 73.10%\n",
      "Run: 10, Epoch: 27, Loss: 0.0588, Train: 100.00%, Valid: 71.20% Test: 73.40%\n",
      "Run: 10, Epoch: 28, Loss: 0.0554, Train: 100.00%, Valid: 71.20% Test: 73.30%\n",
      "Run: 10, Epoch: 29, Loss: 0.0637, Train: 100.00%, Valid: 71.40% Test: 72.80%\n",
      "Run: 10, Epoch: 30, Loss: 0.0746, Train: 100.00%, Valid: 71.40% Test: 72.70%\n",
      "Run: 10, Epoch: 31, Loss: 0.0527, Train: 100.00%, Valid: 70.80% Test: 72.30%\n",
      "Run: 10, Epoch: 32, Loss: 0.0500, Train: 100.00%, Valid: 69.80% Test: 72.60%\n",
      "Run: 10, Epoch: 33, Loss: 0.0398, Train: 100.00%, Valid: 69.80% Test: 72.40%\n",
      "Run: 10, Epoch: 34, Loss: 0.0418, Train: 100.00%, Valid: 69.40% Test: 72.50%\n",
      "Run: 10, Epoch: 35, Loss: 0.0380, Train: 100.00%, Valid: 69.20% Test: 72.20%\n",
      "Run: 10, Epoch: 36, Loss: 0.0455, Train: 100.00%, Valid: 69.20% Test: 71.60%\n",
      "Run: 10, Epoch: 37, Loss: 0.0357, Train: 100.00%, Valid: 69.20% Test: 71.50%\n",
      "Run: 10, Epoch: 38, Loss: 0.0708, Train: 100.00%, Valid: 69.20% Test: 71.40%\n",
      "Run: 10, Epoch: 39, Loss: 0.0651, Train: 100.00%, Valid: 69.00% Test: 71.30%\n",
      "Run: 10, Epoch: 40, Loss: 0.0200, Train: 100.00%, Valid: 69.20% Test: 71.40%\n",
      "Run: 10, Epoch: 41, Loss: 0.0470, Train: 100.00%, Valid: 69.00% Test: 71.40%\n",
      "Run: 10, Epoch: 42, Loss: 0.0182, Train: 100.00%, Valid: 69.00% Test: 71.30%\n",
      "Run: 10, Epoch: 43, Loss: 0.0488, Train: 100.00%, Valid: 68.80% Test: 71.50%\n",
      "Run: 10, Epoch: 44, Loss: 0.0393, Train: 100.00%, Valid: 69.00% Test: 71.50%\n",
      "Run: 10, Epoch: 45, Loss: 0.0327, Train: 100.00%, Valid: 69.20% Test: 71.20%\n",
      "Run: 10, Epoch: 46, Loss: 0.0322, Train: 100.00%, Valid: 69.40% Test: 70.90%\n",
      "Run: 10, Epoch: 47, Loss: 0.0334, Train: 100.00%, Valid: 69.20% Test: 70.70%\n",
      "Run: 10, Epoch: 48, Loss: 0.0173, Train: 100.00%, Valid: 68.80% Test: 70.70%\n",
      "Run: 10, Epoch: 49, Loss: 0.0398, Train: 100.00%, Valid: 68.80% Test: 70.40%\n",
      "Run: 10, Epoch: 50, Loss: 0.0305, Train: 100.00%, Valid: 68.80% Test: 70.50%\n",
      "Run: 10, Epoch: 51, Loss: 0.0354, Train: 100.00%, Valid: 68.60% Test: 70.40%\n",
      "Run: 10, Epoch: 52, Loss: 0.0159, Train: 100.00%, Valid: 68.80% Test: 70.50%\n",
      "Run: 10, Epoch: 53, Loss: 0.0170, Train: 100.00%, Valid: 69.00% Test: 70.70%\n",
      "Run: 10, Epoch: 54, Loss: 0.0236, Train: 100.00%, Valid: 69.40% Test: 70.70%\n",
      "Run: 10, Epoch: 55, Loss: 0.0271, Train: 100.00%, Valid: 69.40% Test: 70.70%\n",
      "Run: 10, Epoch: 56, Loss: 0.0214, Train: 100.00%, Valid: 69.40% Test: 70.80%\n",
      "Run: 10, Epoch: 57, Loss: 0.0082, Train: 100.00%, Valid: 69.40% Test: 70.90%\n",
      "Run: 10, Epoch: 58, Loss: 0.0254, Train: 100.00%, Valid: 69.60% Test: 70.80%\n",
      "Run: 10, Epoch: 59, Loss: 0.0161, Train: 100.00%, Valid: 69.80% Test: 70.90%\n",
      "Run: 10, Epoch: 60, Loss: 0.0241, Train: 100.00%, Valid: 69.80% Test: 71.10%\n",
      "Run: 10, Epoch: 61, Loss: 0.0088, Train: 100.00%, Valid: 69.80% Test: 70.90%\n",
      "Run: 10, Epoch: 62, Loss: 0.0109, Train: 100.00%, Valid: 69.80% Test: 71.00%\n",
      "Run: 10, Epoch: 63, Loss: 0.0188, Train: 100.00%, Valid: 70.00% Test: 71.00%\n",
      "Run: 10, Epoch: 64, Loss: 0.0189, Train: 100.00%, Valid: 69.80% Test: 70.90%\n",
      "Run: 10, Epoch: 65, Loss: 0.0305, Train: 100.00%, Valid: 69.80% Test: 71.00%\n",
      "Run: 10, Epoch: 66, Loss: 0.0082, Train: 100.00%, Valid: 70.00% Test: 70.90%\n",
      "Run: 10, Epoch: 67, Loss: 0.0200, Train: 100.00%, Valid: 70.40% Test: 70.90%\n",
      "Run: 10, Epoch: 68, Loss: 0.0162, Train: 100.00%, Valid: 70.00% Test: 70.80%\n",
      "Run: 10, Epoch: 69, Loss: 0.0274, Train: 100.00%, Valid: 70.20% Test: 70.60%\n",
      "Run: 10, Epoch: 70, Loss: 0.0086, Train: 100.00%, Valid: 70.20% Test: 70.50%\n",
      "Run: 10, Epoch: 71, Loss: 0.0151, Train: 100.00%, Valid: 70.00% Test: 70.50%\n",
      "Run: 10, Epoch: 72, Loss: 0.0153, Train: 100.00%, Valid: 69.80% Test: 70.40%\n",
      "Run: 10, Epoch: 73, Loss: 0.0197, Train: 100.00%, Valid: 70.00% Test: 70.40%\n",
      "Run: 10, Epoch: 74, Loss: 0.0122, Train: 100.00%, Valid: 69.80% Test: 70.50%\n",
      "Run: 10, Epoch: 75, Loss: 0.0081, Train: 100.00%, Valid: 69.80% Test: 70.40%\n",
      "Run: 10, Epoch: 76, Loss: 0.0095, Train: 100.00%, Valid: 69.80% Test: 70.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 77, Loss: 0.0225, Train: 100.00%, Valid: 69.40% Test: 70.30%\n",
      "Run: 10, Epoch: 78, Loss: 0.0312, Train: 100.00%, Valid: 69.60% Test: 70.40%\n",
      "Run: 10, Epoch: 79, Loss: 0.0163, Train: 100.00%, Valid: 69.40% Test: 70.30%\n",
      "Run: 10, Epoch: 80, Loss: 0.0059, Train: 100.00%, Valid: 69.20% Test: 70.20%\n",
      "Run: 10, Epoch: 81, Loss: 0.0062, Train: 100.00%, Valid: 69.20% Test: 70.20%\n",
      "Run: 10, Epoch: 82, Loss: 0.0193, Train: 100.00%, Valid: 69.20% Test: 70.40%\n",
      "Run: 10, Epoch: 83, Loss: 0.0124, Train: 100.00%, Valid: 69.20% Test: 70.30%\n",
      "Run: 10, Epoch: 84, Loss: 0.0079, Train: 100.00%, Valid: 69.20% Test: 70.20%\n",
      "Run: 10, Epoch: 85, Loss: 0.0339, Train: 100.00%, Valid: 69.20% Test: 70.30%\n",
      "Run: 10, Epoch: 86, Loss: 0.0111, Train: 100.00%, Valid: 69.20% Test: 70.30%\n",
      "Run: 10, Epoch: 87, Loss: 0.0571, Train: 100.00%, Valid: 69.40% Test: 70.30%\n",
      "Run: 10, Epoch: 88, Loss: 0.0120, Train: 100.00%, Valid: 69.40% Test: 70.30%\n",
      "Run: 10, Epoch: 89, Loss: 0.0279, Train: 100.00%, Valid: 69.20% Test: 70.40%\n",
      "Run: 10, Epoch: 90, Loss: 0.0095, Train: 100.00%, Valid: 69.20% Test: 70.60%\n",
      "Run: 10, Epoch: 91, Loss: 0.0185, Train: 100.00%, Valid: 69.00% Test: 70.80%\n",
      "Run: 10, Epoch: 92, Loss: 0.0085, Train: 100.00%, Valid: 68.40% Test: 70.60%\n",
      "Run: 10, Epoch: 93, Loss: 0.0275, Train: 100.00%, Valid: 68.60% Test: 70.60%\n",
      "Run: 10, Epoch: 94, Loss: 0.0313, Train: 100.00%, Valid: 68.60% Test: 70.60%\n",
      "Run: 10, Epoch: 95, Loss: 0.0034, Train: 100.00%, Valid: 68.80% Test: 70.40%\n",
      "Run: 10, Epoch: 96, Loss: 0.0302, Train: 100.00%, Valid: 68.80% Test: 70.40%\n",
      "Run: 10, Epoch: 97, Loss: 0.0209, Train: 100.00%, Valid: 69.00% Test: 70.30%\n",
      "Run: 10, Epoch: 98, Loss: 0.0101, Train: 100.00%, Valid: 68.80% Test: 70.20%\n",
      "Run: 10, Epoch: 99, Loss: 0.0096, Train: 100.00%, Valid: 69.00% Test: 70.20%\n",
      "Run: 10, Epoch: 100, Loss: 0.0085, Train: 100.00%, Valid: 69.00% Test: 70.20%\n",
      "Run: 10, Epoch: 101, Loss: 0.0055, Train: 100.00%, Valid: 69.00% Test: 70.20%\n",
      "Run: 10, Epoch: 102, Loss: 0.0146, Train: 100.00%, Valid: 69.00% Test: 70.30%\n",
      "Run: 10, Epoch: 103, Loss: 0.0257, Train: 100.00%, Valid: 69.00% Test: 70.40%\n",
      "Run: 10, Epoch: 104, Loss: 0.0061, Train: 100.00%, Valid: 68.80% Test: 70.40%\n",
      "Run: 10, Epoch: 105, Loss: 0.0092, Train: 100.00%, Valid: 68.80% Test: 70.30%\n",
      "Run: 10, Epoch: 106, Loss: 0.0206, Train: 100.00%, Valid: 68.40% Test: 70.00%\n",
      "Run: 10, Epoch: 107, Loss: 0.0091, Train: 100.00%, Valid: 68.60% Test: 69.90%\n",
      "Run: 10, Epoch: 108, Loss: 0.0033, Train: 100.00%, Valid: 68.00% Test: 69.70%\n",
      "Run: 10, Epoch: 109, Loss: 0.0182, Train: 100.00%, Valid: 68.00% Test: 69.80%\n",
      "Run: 10, Epoch: 110, Loss: 0.0103, Train: 100.00%, Valid: 68.00% Test: 69.70%\n",
      "Run: 10, Epoch: 111, Loss: 0.0035, Train: 100.00%, Valid: 67.80% Test: 69.50%\n",
      "Run: 10, Epoch: 112, Loss: 0.0223, Train: 100.00%, Valid: 67.80% Test: 69.30%\n",
      "Run: 10, Epoch: 113, Loss: 0.0043, Train: 100.00%, Valid: 67.80% Test: 69.30%\n",
      "Run: 10, Epoch: 114, Loss: 0.0112, Train: 100.00%, Valid: 67.60% Test: 69.20%\n",
      "Run: 10, Epoch: 115, Loss: 0.0052, Train: 100.00%, Valid: 67.60% Test: 69.10%\n",
      "Run: 10, Epoch: 116, Loss: 0.0052, Train: 100.00%, Valid: 67.60% Test: 69.10%\n",
      "Run: 10, Epoch: 117, Loss: 0.0097, Train: 100.00%, Valid: 67.60% Test: 69.10%\n",
      "Run: 10, Epoch: 118, Loss: 0.0096, Train: 100.00%, Valid: 67.60% Test: 69.10%\n",
      "Run: 10, Epoch: 119, Loss: 0.0070, Train: 100.00%, Valid: 67.80% Test: 69.00%\n",
      "Run: 10, Epoch: 120, Loss: 0.0058, Train: 100.00%, Valid: 68.00% Test: 69.00%\n",
      "Run: 10, Epoch: 121, Loss: 0.0236, Train: 100.00%, Valid: 68.00% Test: 68.90%\n",
      "Run: 10, Epoch: 122, Loss: 0.0057, Train: 100.00%, Valid: 67.80% Test: 68.90%\n",
      "Run: 10, Epoch: 123, Loss: 0.0137, Train: 100.00%, Valid: 67.60% Test: 69.00%\n",
      "Run: 10, Epoch: 124, Loss: 0.0049, Train: 100.00%, Valid: 67.40% Test: 69.00%\n",
      "Run: 10, Epoch: 125, Loss: 0.0119, Train: 100.00%, Valid: 67.20% Test: 69.00%\n",
      "Run: 10, Epoch: 126, Loss: 0.0093, Train: 100.00%, Valid: 67.40% Test: 69.00%\n",
      "Run: 10, Epoch: 127, Loss: 0.0111, Train: 100.00%, Valid: 67.40% Test: 69.20%\n",
      "Run: 10, Epoch: 128, Loss: 0.0348, Train: 100.00%, Valid: 67.20% Test: 69.20%\n",
      "Run: 10, Epoch: 129, Loss: 0.0094, Train: 100.00%, Valid: 67.00% Test: 69.30%\n",
      "Run: 10, Epoch: 130, Loss: 0.0036, Train: 100.00%, Valid: 67.00% Test: 69.20%\n",
      "Run: 10, Epoch: 131, Loss: 0.0455, Train: 100.00%, Valid: 67.20% Test: 68.90%\n",
      "Run: 10, Epoch: 132, Loss: 0.0128, Train: 100.00%, Valid: 67.20% Test: 68.90%\n",
      "Run: 10, Epoch: 133, Loss: 0.0103, Train: 100.00%, Valid: 67.20% Test: 69.00%\n",
      "Run: 10, Epoch: 134, Loss: 0.0084, Train: 100.00%, Valid: 67.20% Test: 68.90%\n",
      "Run: 10, Epoch: 135, Loss: 0.0109, Train: 100.00%, Valid: 67.20% Test: 68.80%\n",
      "Run: 10, Epoch: 136, Loss: 0.0022, Train: 100.00%, Valid: 67.20% Test: 68.70%\n",
      "Run: 10, Epoch: 137, Loss: 0.0045, Train: 100.00%, Valid: 67.20% Test: 68.50%\n",
      "Run: 10, Epoch: 138, Loss: 0.0058, Train: 100.00%, Valid: 67.40% Test: 68.60%\n",
      "Run: 10, Epoch: 139, Loss: 0.0042, Train: 100.00%, Valid: 67.40% Test: 68.40%\n",
      "Run: 10, Epoch: 140, Loss: 0.0191, Train: 100.00%, Valid: 67.60% Test: 68.50%\n",
      "Run: 10, Epoch: 141, Loss: 0.0081, Train: 100.00%, Valid: 67.60% Test: 68.40%\n",
      "Run: 10, Epoch: 142, Loss: 0.0111, Train: 100.00%, Valid: 67.60% Test: 68.30%\n",
      "Run: 10, Epoch: 143, Loss: 0.0094, Train: 100.00%, Valid: 67.40% Test: 68.20%\n",
      "Run: 10, Epoch: 144, Loss: 0.0091, Train: 100.00%, Valid: 67.20% Test: 68.10%\n",
      "Run: 10, Epoch: 145, Loss: 0.0152, Train: 100.00%, Valid: 67.40% Test: 68.10%\n",
      "Run: 10, Epoch: 146, Loss: 0.0085, Train: 100.00%, Valid: 67.40% Test: 68.10%\n",
      "Run: 10, Epoch: 147, Loss: 0.0108, Train: 100.00%, Valid: 67.40% Test: 68.10%\n",
      "Run: 10, Epoch: 148, Loss: 0.0075, Train: 100.00%, Valid: 67.40% Test: 68.20%\n",
      "Run: 10, Epoch: 149, Loss: 0.0054, Train: 100.00%, Valid: 67.40% Test: 68.30%\n",
      "Run: 10, Epoch: 150, Loss: 0.0232, Train: 100.00%, Valid: 67.40% Test: 68.40%\n",
      "Run: 10, Epoch: 151, Loss: 0.0065, Train: 100.00%, Valid: 67.40% Test: 68.40%\n",
      "Run: 10, Epoch: 152, Loss: 0.0065, Train: 100.00%, Valid: 67.40% Test: 68.40%\n",
      "Run: 10, Epoch: 153, Loss: 0.0013, Train: 100.00%, Valid: 67.20% Test: 68.40%\n",
      "Run: 10, Epoch: 154, Loss: 0.0120, Train: 100.00%, Valid: 67.00% Test: 68.70%\n",
      "Run: 10, Epoch: 155, Loss: 0.0258, Train: 100.00%, Valid: 67.20% Test: 68.70%\n",
      "Run: 10, Epoch: 156, Loss: 0.0107, Train: 100.00%, Valid: 66.80% Test: 68.60%\n",
      "Run: 10, Epoch: 157, Loss: 0.0058, Train: 100.00%, Valid: 66.80% Test: 68.70%\n",
      "Run: 10, Epoch: 158, Loss: 0.0057, Train: 100.00%, Valid: 66.80% Test: 68.70%\n",
      "Run: 10, Epoch: 159, Loss: 0.0014, Train: 100.00%, Valid: 66.80% Test: 68.60%\n",
      "Run: 10, Epoch: 160, Loss: 0.0055, Train: 100.00%, Valid: 66.80% Test: 68.60%\n",
      "Run: 10, Epoch: 161, Loss: 0.0055, Train: 100.00%, Valid: 66.80% Test: 68.60%\n",
      "Run: 10, Epoch: 162, Loss: 0.0033, Train: 100.00%, Valid: 66.60% Test: 68.80%\n",
      "Run: 10, Epoch: 163, Loss: 0.0132, Train: 100.00%, Valid: 66.80% Test: 68.70%\n",
      "Run: 10, Epoch: 164, Loss: 0.0139, Train: 100.00%, Valid: 66.60% Test: 68.90%\n",
      "Run: 10, Epoch: 165, Loss: 0.0058, Train: 100.00%, Valid: 66.60% Test: 68.90%\n",
      "Run: 10, Epoch: 166, Loss: 0.0133, Train: 100.00%, Valid: 66.80% Test: 68.80%\n",
      "Run: 10, Epoch: 167, Loss: 0.0023, Train: 100.00%, Valid: 66.60% Test: 68.80%\n",
      "Run: 10, Epoch: 168, Loss: 0.0048, Train: 100.00%, Valid: 66.60% Test: 68.60%\n",
      "Run: 10, Epoch: 169, Loss: 0.0060, Train: 100.00%, Valid: 66.40% Test: 68.60%\n",
      "Run: 10, Epoch: 170, Loss: 0.0054, Train: 100.00%, Valid: 66.20% Test: 68.30%\n",
      "Run: 10, Epoch: 171, Loss: 0.0044, Train: 100.00%, Valid: 66.40% Test: 68.10%\n",
      "Run: 10, Epoch: 172, Loss: 0.0040, Train: 100.00%, Valid: 66.60% Test: 68.20%\n",
      "Run: 10, Epoch: 173, Loss: 0.0250, Train: 100.00%, Valid: 66.60% Test: 68.30%\n",
      "Run: 10, Epoch: 174, Loss: 0.0107, Train: 100.00%, Valid: 66.80% Test: 68.40%\n",
      "Run: 10, Epoch: 175, Loss: 0.0082, Train: 100.00%, Valid: 66.80% Test: 68.30%\n",
      "Run: 10, Epoch: 176, Loss: 0.0037, Train: 100.00%, Valid: 66.80% Test: 68.10%\n",
      "Run: 10, Epoch: 177, Loss: 0.0021, Train: 100.00%, Valid: 66.80% Test: 68.20%\n",
      "Run: 10, Epoch: 178, Loss: 0.0097, Train: 100.00%, Valid: 66.80% Test: 68.20%\n",
      "Run: 10, Epoch: 179, Loss: 0.0182, Train: 100.00%, Valid: 66.60% Test: 68.40%\n",
      "Run: 10, Epoch: 180, Loss: 0.0129, Train: 100.00%, Valid: 66.60% Test: 68.30%\n",
      "Run: 10, Epoch: 181, Loss: 0.0045, Train: 100.00%, Valid: 66.60% Test: 68.20%\n",
      "Run: 10, Epoch: 182, Loss: 0.0065, Train: 100.00%, Valid: 66.40% Test: 68.20%\n",
      "Run: 10, Epoch: 183, Loss: 0.0171, Train: 100.00%, Valid: 66.60% Test: 68.00%\n",
      "Run: 10, Epoch: 184, Loss: 0.0118, Train: 100.00%, Valid: 66.60% Test: 68.00%\n",
      "Run: 10, Epoch: 185, Loss: 0.0093, Train: 100.00%, Valid: 66.20% Test: 68.10%\n",
      "Run: 10, Epoch: 186, Loss: 0.0069, Train: 100.00%, Valid: 66.20% Test: 68.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 187, Loss: 0.0122, Train: 100.00%, Valid: 66.40% Test: 68.10%\n",
      "Run: 10, Epoch: 188, Loss: 0.0029, Train: 100.00%, Valid: 66.40% Test: 68.10%\n",
      "Run: 10, Epoch: 189, Loss: 0.0071, Train: 100.00%, Valid: 66.20% Test: 68.10%\n",
      "Run: 10, Epoch: 190, Loss: 0.0060, Train: 100.00%, Valid: 66.20% Test: 68.10%\n",
      "Run: 10, Epoch: 191, Loss: 0.0030, Train: 100.00%, Valid: 66.20% Test: 68.20%\n",
      "Run: 10, Epoch: 192, Loss: 0.0088, Train: 100.00%, Valid: 66.20% Test: 68.10%\n",
      "Run: 10, Epoch: 193, Loss: 0.0044, Train: 100.00%, Valid: 66.20% Test: 68.10%\n",
      "Run: 10, Epoch: 194, Loss: 0.0052, Train: 100.00%, Valid: 66.20% Test: 68.30%\n",
      "Run: 10, Epoch: 195, Loss: 0.0087, Train: 100.00%, Valid: 66.40% Test: 68.20%\n",
      "Run: 10, Epoch: 196, Loss: 0.0205, Train: 100.00%, Valid: 66.60% Test: 68.20%\n",
      "Run: 10, Epoch: 197, Loss: 0.0034, Train: 100.00%, Valid: 66.60% Test: 68.30%\n",
      "Run: 10, Epoch: 198, Loss: 0.0173, Train: 100.00%, Valid: 66.60% Test: 68.20%\n",
      "Run: 10, Epoch: 199, Loss: 0.0021, Train: 100.00%, Valid: 66.80% Test: 68.00%\n",
      "Run: 10, Epoch: 200, Loss: 0.0108, Train: 100.00%, Valid: 66.80% Test: 67.90%\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 74.20\n",
      "  Final Train: 95.00\n",
      "   Final Test: 75.30\n",
      "All runs:\n",
      "Highest Train: 100.00 ± 0.00\n",
      "Highest Valid: 73.42 ± 1.62\n",
      "  Final Train: 99.07 ± 1.58\n",
      "   Final Test: 75.36 ± 2.01\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    train_idx = np.where(data.train_mask)[0]\n",
    "    valid_idx = np.where(data.val_mask)[0]\n",
    "    test_idx = np.where(data.test_mask)[0]\n",
    "    \n",
    "    model = GCN(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52f151",
   "metadata": {},
   "source": [
    "# WISE EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a09514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f82a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "      <th>1428</th>\n",
       "      <th>1429</th>\n",
       "      <th>1430</th>\n",
       "      <th>1431</th>\n",
       "      <th>1432</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  1424  1425  1426  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "   1427  1428  1429  1430  1431  1432  class  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0      0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "\n",
       "[5 rows x 1434 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Domain_Fec=pd.DataFrame(data.x.numpy())\n",
    "label=pd.DataFrame(data.y.numpy(),columns =['class'])\n",
    "Data=pd.concat([Domain_Fec,label], axis=1)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2642b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_nodes=len(data.y)\n",
    "fe_len=len(data.x[0])\n",
    "catagories=Data['class'].to_numpy()\n",
    "data_by_class = {cls: Data.loc[Data['class'] == cls].drop(['class'], axis=1) for cls in range(max(catagories) + 1)}\n",
    "basis = [[max(df[i]) for i in range(len(df.columns))] for df in data_by_class.values()]\n",
    "sel_basis = [[int(list(df[i].to_numpy()).count(1) >= int(len(df[i].index)*0.1)) \n",
    "              for i in range(len(df.columns))]\n",
    "             for df in data_by_class.values()]\n",
    "feature_names = [ii for ii in range(fe_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12133154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity(array1, array2):\n",
    "    intersection = np.sum(np.logical_and(array1, array2))\n",
    "    return intersection\n",
    "Fec=[]\n",
    "for i in range(Number_nodes):\n",
    "#for i in range(2):\n",
    "    vec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    vec.append(Similarity(f,basis[0]))\n",
    "    vec.append(Similarity(f,basis[1]))\n",
    "    vec.append(Similarity(f,basis[2]))\n",
    "    vec.append(Similarity(f,basis[3]))\n",
    "    vec.append(Similarity(f,basis[4]))\n",
    "    vec.append(Similarity(f,basis[5]))\n",
    "    vec.append(Similarity(f,basis[6]))\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    Fec.append(vec)\n",
    "SFec=[]\n",
    "for i in range(Number_nodes):\n",
    "#for i in range(2):\n",
    "    Svec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    Svec.append(Similarity(f,sel_basis[0]))\n",
    "    Svec.append(Similarity(f,sel_basis[1]))\n",
    "    Svec.append(Similarity(f,sel_basis[2]))\n",
    "    Svec.append(Similarity(f,sel_basis[3]))\n",
    "    Svec.append(Similarity(f,sel_basis[4]))\n",
    "    Svec.append(Similarity(f,sel_basis[5]))\n",
    "    Svec.append(Similarity(f,sel_basis[6]))\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    SFec.append(Svec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "054ee569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.,  7.,  9.,  ...,  1.,  0.,  0.],\n",
      "        [21., 20., 21.,  ...,  4.,  4.,  3.],\n",
      "        [19., 17., 18.,  ...,  6.,  4.,  4.],\n",
      "        ...,\n",
      "        [16., 16., 15.,  ...,  3.,  5.,  3.],\n",
      "        [12.,  9., 11.,  ...,  2.,  2.,  1.],\n",
      "        [10., 12.,  8.,  ...,  2.,  1.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inc_fe=torch.tensor(Fec)\n",
    "sel_fe=torch.tensor(SFec)\n",
    "CC_domain=torch.cat((Inc_fe, sel_fe), 1).float()\n",
    "print(CC_domain)\n",
    "CC_domain.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f7d51",
   "metadata": {},
   "source": [
    "# W-GCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c6fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 14], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4763ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x17ba04400>\n",
      "Run: 01, Epoch: 01, Loss: 2.3444, Train: 14.29%, Valid: 31.60% Test: 31.90%\n",
      "Run: 01, Epoch: 02, Loss: 2.2768, Train: 14.29%, Valid: 31.40% Test: 31.90%\n",
      "Run: 01, Epoch: 03, Loss: 2.1548, Train: 14.29%, Valid: 31.40% Test: 31.80%\n",
      "Run: 01, Epoch: 04, Loss: 2.0771, Train: 13.57%, Valid: 31.00% Test: 31.50%\n",
      "Run: 01, Epoch: 05, Loss: 1.9681, Train: 13.57%, Valid: 30.00% Test: 30.50%\n",
      "Run: 01, Epoch: 06, Loss: 1.9588, Train: 17.14%, Valid: 29.00% Test: 29.30%\n",
      "Run: 01, Epoch: 07, Loss: 1.9285, Train: 17.86%, Valid: 17.40% Test: 20.50%\n",
      "Run: 01, Epoch: 08, Loss: 1.8786, Train: 16.43%, Valid: 9.80% Test: 11.80%\n",
      "Run: 01, Epoch: 09, Loss: 1.8286, Train: 17.14%, Valid: 10.00% Test: 11.40%\n",
      "Run: 01, Epoch: 10, Loss: 1.7913, Train: 21.43%, Valid: 13.20% Test: 15.20%\n",
      "Run: 01, Epoch: 11, Loss: 1.7364, Train: 21.43%, Valid: 17.00% Test: 17.70%\n",
      "Run: 01, Epoch: 12, Loss: 1.7552, Train: 23.57%, Valid: 17.60% Test: 17.70%\n",
      "Run: 01, Epoch: 13, Loss: 1.7313, Train: 20.71%, Valid: 18.20% Test: 17.60%\n",
      "Run: 01, Epoch: 14, Loss: 1.6548, Train: 25.00%, Valid: 19.80% Test: 21.30%\n",
      "Run: 01, Epoch: 15, Loss: 1.6464, Train: 29.29%, Valid: 21.60% Test: 23.70%\n",
      "Run: 01, Epoch: 16, Loss: 1.6398, Train: 30.00%, Valid: 22.20% Test: 23.60%\n",
      "Run: 01, Epoch: 17, Loss: 1.6270, Train: 30.00%, Valid: 21.20% Test: 23.40%\n",
      "Run: 01, Epoch: 18, Loss: 1.5999, Train: 33.57%, Valid: 21.60% Test: 24.00%\n",
      "Run: 01, Epoch: 19, Loss: 1.5305, Train: 37.14%, Valid: 21.80% Test: 25.20%\n",
      "Run: 01, Epoch: 20, Loss: 1.5632, Train: 43.57%, Valid: 23.00% Test: 27.70%\n",
      "Run: 01, Epoch: 21, Loss: 1.6079, Train: 47.14%, Valid: 26.40% Test: 28.60%\n",
      "Run: 01, Epoch: 22, Loss: 1.4563, Train: 43.57%, Valid: 25.40% Test: 28.90%\n",
      "Run: 01, Epoch: 23, Loss: 1.4001, Train: 43.57%, Valid: 24.60% Test: 28.00%\n",
      "Run: 01, Epoch: 24, Loss: 1.4038, Train: 42.14%, Valid: 24.80% Test: 28.20%\n",
      "Run: 01, Epoch: 25, Loss: 1.3640, Train: 42.14%, Valid: 29.40% Test: 32.20%\n",
      "Run: 01, Epoch: 26, Loss: 1.3481, Train: 47.14%, Valid: 36.20% Test: 36.60%\n",
      "Run: 01, Epoch: 27, Loss: 1.3697, Train: 50.71%, Valid: 39.40% Test: 40.40%\n",
      "Run: 01, Epoch: 28, Loss: 1.2672, Train: 57.14%, Valid: 42.00% Test: 42.30%\n",
      "Run: 01, Epoch: 29, Loss: 1.3079, Train: 59.29%, Valid: 41.40% Test: 42.40%\n",
      "Run: 01, Epoch: 30, Loss: 1.2038, Train: 53.57%, Valid: 39.00% Test: 40.70%\n",
      "Run: 01, Epoch: 31, Loss: 1.2333, Train: 50.71%, Valid: 39.40% Test: 40.70%\n",
      "Run: 01, Epoch: 32, Loss: 1.2932, Train: 50.00%, Valid: 38.60% Test: 39.30%\n",
      "Run: 01, Epoch: 33, Loss: 1.0773, Train: 52.14%, Valid: 38.80% Test: 39.20%\n",
      "Run: 01, Epoch: 34, Loss: 1.1307, Train: 55.00%, Valid: 41.20% Test: 41.50%\n",
      "Run: 01, Epoch: 35, Loss: 1.0266, Train: 60.00%, Valid: 46.20% Test: 47.70%\n",
      "Run: 01, Epoch: 36, Loss: 1.1143, Train: 62.86%, Valid: 49.40% Test: 50.90%\n",
      "Run: 01, Epoch: 37, Loss: 1.0497, Train: 66.43%, Valid: 50.40% Test: 51.70%\n",
      "Run: 01, Epoch: 38, Loss: 0.9714, Train: 67.86%, Valid: 50.40% Test: 52.10%\n",
      "Run: 01, Epoch: 39, Loss: 0.9705, Train: 65.00%, Valid: 50.00% Test: 51.80%\n",
      "Run: 01, Epoch: 40, Loss: 1.0229, Train: 62.86%, Valid: 45.80% Test: 49.00%\n",
      "Run: 01, Epoch: 41, Loss: 0.9480, Train: 59.29%, Valid: 45.20% Test: 47.40%\n",
      "Run: 01, Epoch: 42, Loss: 0.9666, Train: 55.00%, Valid: 44.80% Test: 47.20%\n",
      "Run: 01, Epoch: 43, Loss: 0.8974, Train: 53.57%, Valid: 47.80% Test: 49.10%\n",
      "Run: 01, Epoch: 44, Loss: 0.8687, Train: 58.57%, Valid: 52.00% Test: 53.60%\n",
      "Run: 01, Epoch: 45, Loss: 0.7689, Train: 63.57%, Valid: 56.40% Test: 58.10%\n",
      "Run: 01, Epoch: 46, Loss: 0.8812, Train: 67.86%, Valid: 59.80% Test: 61.20%\n",
      "Run: 01, Epoch: 47, Loss: 0.8163, Train: 75.71%, Valid: 64.60% Test: 65.70%\n",
      "Run: 01, Epoch: 48, Loss: 0.7837, Train: 82.14%, Valid: 70.00% Test: 70.50%\n",
      "Run: 01, Epoch: 49, Loss: 0.8108, Train: 80.71%, Valid: 72.20% Test: 70.60%\n",
      "Run: 01, Epoch: 50, Loss: 0.7608, Train: 75.71%, Valid: 67.80% Test: 68.50%\n",
      "Run: 01, Epoch: 51, Loss: 0.7787, Train: 75.71%, Valid: 66.40% Test: 66.50%\n",
      "Run: 01, Epoch: 52, Loss: 0.7095, Train: 75.71%, Valid: 62.60% Test: 64.50%\n",
      "Run: 01, Epoch: 53, Loss: 0.7249, Train: 74.29%, Valid: 61.00% Test: 62.50%\n",
      "Run: 01, Epoch: 54, Loss: 0.7198, Train: 75.71%, Valid: 64.60% Test: 64.80%\n",
      "Run: 01, Epoch: 55, Loss: 0.6472, Train: 76.43%, Valid: 68.40% Test: 69.00%\n",
      "Run: 01, Epoch: 56, Loss: 0.6413, Train: 77.86%, Valid: 70.60% Test: 71.30%\n",
      "Run: 01, Epoch: 57, Loss: 0.6606, Train: 80.00%, Valid: 73.20% Test: 73.70%\n",
      "Run: 01, Epoch: 58, Loss: 0.5806, Train: 82.14%, Valid: 77.00% Test: 76.80%\n",
      "Run: 01, Epoch: 59, Loss: 0.6160, Train: 83.57%, Valid: 79.20% Test: 77.60%\n",
      "Run: 01, Epoch: 60, Loss: 0.5709, Train: 80.71%, Valid: 79.20% Test: 78.20%\n",
      "Run: 01, Epoch: 61, Loss: 0.6151, Train: 82.14%, Valid: 77.80% Test: 77.10%\n",
      "Run: 01, Epoch: 62, Loss: 0.6103, Train: 85.71%, Valid: 76.20% Test: 78.00%\n",
      "Run: 01, Epoch: 63, Loss: 0.5751, Train: 86.43%, Valid: 77.20% Test: 79.20%\n",
      "Run: 01, Epoch: 64, Loss: 0.5919, Train: 85.00%, Valid: 76.40% Test: 78.00%\n",
      "Run: 01, Epoch: 65, Loss: 0.5786, Train: 80.00%, Valid: 70.60% Test: 73.10%\n",
      "Run: 01, Epoch: 66, Loss: 0.5142, Train: 79.29%, Valid: 66.80% Test: 69.50%\n",
      "Run: 01, Epoch: 67, Loss: 0.6173, Train: 80.71%, Valid: 66.60% Test: 68.90%\n",
      "Run: 01, Epoch: 68, Loss: 0.5238, Train: 82.86%, Valid: 71.80% Test: 72.70%\n",
      "Run: 01, Epoch: 69, Loss: 0.5057, Train: 85.00%, Valid: 76.20% Test: 75.20%\n",
      "Run: 01, Epoch: 70, Loss: 0.5567, Train: 82.86%, Valid: 75.00% Test: 75.80%\n",
      "Run: 01, Epoch: 71, Loss: 0.4881, Train: 84.29%, Valid: 73.20% Test: 75.80%\n",
      "Run: 01, Epoch: 72, Loss: 0.5661, Train: 85.00%, Valid: 77.00% Test: 79.80%\n",
      "Run: 01, Epoch: 73, Loss: 0.5719, Train: 89.29%, Valid: 80.60% Test: 83.70%\n",
      "Run: 01, Epoch: 74, Loss: 0.4312, Train: 86.43%, Valid: 81.80% Test: 83.30%\n",
      "Run: 01, Epoch: 75, Loss: 0.4794, Train: 87.14%, Valid: 82.00% Test: 82.60%\n",
      "Run: 01, Epoch: 76, Loss: 0.4924, Train: 90.00%, Valid: 83.20% Test: 85.40%\n",
      "Run: 01, Epoch: 77, Loss: 0.4976, Train: 91.43%, Valid: 80.00% Test: 82.90%\n",
      "Run: 01, Epoch: 78, Loss: 0.4286, Train: 87.14%, Valid: 77.40% Test: 77.40%\n",
      "Run: 01, Epoch: 79, Loss: 0.5071, Train: 87.14%, Valid: 76.60% Test: 76.80%\n",
      "Run: 01, Epoch: 80, Loss: 0.4146, Train: 86.43%, Valid: 77.20% Test: 75.40%\n",
      "Run: 01, Epoch: 81, Loss: 0.5303, Train: 87.14%, Valid: 78.40% Test: 77.50%\n",
      "Run: 01, Epoch: 82, Loss: 0.4590, Train: 89.29%, Valid: 81.00% Test: 82.40%\n",
      "Run: 01, Epoch: 83, Loss: 0.4184, Train: 89.29%, Valid: 82.00% Test: 85.30%\n",
      "Run: 01, Epoch: 84, Loss: 0.4214, Train: 87.14%, Valid: 80.20% Test: 83.30%\n",
      "Run: 01, Epoch: 85, Loss: 0.4637, Train: 88.57%, Valid: 79.80% Test: 83.00%\n",
      "Run: 01, Epoch: 86, Loss: 0.4912, Train: 87.14%, Valid: 77.40% Test: 80.90%\n",
      "Run: 01, Epoch: 87, Loss: 0.4346, Train: 87.86%, Valid: 76.40% Test: 80.80%\n",
      "Run: 01, Epoch: 88, Loss: 0.4438, Train: 90.71%, Valid: 78.40% Test: 82.20%\n",
      "Run: 01, Epoch: 89, Loss: 0.3701, Train: 89.29%, Valid: 81.80% Test: 84.60%\n",
      "Run: 01, Epoch: 90, Loss: 0.4107, Train: 86.43%, Valid: 81.40% Test: 83.00%\n",
      "Run: 01, Epoch: 91, Loss: 0.4251, Train: 84.29%, Valid: 80.40% Test: 81.40%\n",
      "Run: 01, Epoch: 92, Loss: 0.4098, Train: 83.57%, Valid: 82.00% Test: 83.40%\n",
      "Run: 01, Epoch: 93, Loss: 0.3968, Train: 90.71%, Valid: 84.80% Test: 84.30%\n",
      "Run: 01, Epoch: 94, Loss: 0.5171, Train: 93.57%, Valid: 82.40% Test: 84.80%\n",
      "Run: 01, Epoch: 95, Loss: 0.4484, Train: 94.29%, Valid: 80.60% Test: 84.40%\n",
      "Run: 01, Epoch: 96, Loss: 0.4764, Train: 94.29%, Valid: 79.60% Test: 83.50%\n",
      "Run: 01, Epoch: 97, Loss: 0.3861, Train: 92.14%, Valid: 79.40% Test: 83.00%\n",
      "Run: 01, Epoch: 98, Loss: 0.4155, Train: 90.00%, Valid: 79.00% Test: 83.10%\n",
      "Run: 01, Epoch: 99, Loss: 0.3899, Train: 89.29%, Valid: 80.40% Test: 81.80%\n",
      "Run: 01, Epoch: 100, Loss: 0.3832, Train: 90.71%, Valid: 81.20% Test: 82.30%\n",
      "Run: 01, Epoch: 101, Loss: 0.3993, Train: 90.71%, Valid: 83.60% Test: 84.60%\n",
      "Run: 01, Epoch: 102, Loss: 0.3897, Train: 92.14%, Valid: 84.20% Test: 86.10%\n",
      "Run: 01, Epoch: 103, Loss: 0.3926, Train: 91.43%, Valid: 84.60% Test: 86.40%\n",
      "Run: 01, Epoch: 104, Loss: 0.3325, Train: 90.71%, Valid: 84.20% Test: 86.50%\n",
      "Run: 01, Epoch: 105, Loss: 0.4042, Train: 90.00%, Valid: 82.60% Test: 85.80%\n",
      "Run: 01, Epoch: 106, Loss: 0.4201, Train: 92.14%, Valid: 80.60% Test: 84.80%\n",
      "Run: 01, Epoch: 107, Loss: 0.3945, Train: 92.14%, Valid: 78.20% Test: 82.60%\n",
      "Run: 01, Epoch: 108, Loss: 0.3394, Train: 92.86%, Valid: 76.60% Test: 82.10%\n",
      "Run: 01, Epoch: 109, Loss: 0.3631, Train: 91.43%, Valid: 78.80% Test: 82.50%\n",
      "Run: 01, Epoch: 110, Loss: 0.3703, Train: 91.43%, Valid: 81.00% Test: 84.70%\n",
      "Run: 01, Epoch: 111, Loss: 0.3452, Train: 91.43%, Valid: 83.40% Test: 85.90%\n",
      "Run: 01, Epoch: 112, Loss: 0.3590, Train: 90.00%, Valid: 83.20% Test: 85.70%\n",
      "Run: 01, Epoch: 113, Loss: 0.3126, Train: 86.43%, Valid: 79.60% Test: 78.70%\n",
      "Run: 01, Epoch: 114, Loss: 0.3762, Train: 84.29%, Valid: 76.00% Test: 76.20%\n",
      "Run: 01, Epoch: 115, Loss: 0.3409, Train: 85.00%, Valid: 77.20% Test: 78.70%\n",
      "Run: 01, Epoch: 116, Loss: 0.3880, Train: 90.71%, Valid: 82.60% Test: 84.20%\n",
      "Run: 01, Epoch: 117, Loss: 0.3101, Train: 93.57%, Valid: 81.80% Test: 86.50%\n",
      "Run: 01, Epoch: 118, Loss: 0.3830, Train: 92.86%, Valid: 80.60% Test: 84.70%\n",
      "Run: 01, Epoch: 119, Loss: 0.3326, Train: 91.43%, Valid: 80.60% Test: 83.70%\n",
      "Run: 01, Epoch: 120, Loss: 0.3349, Train: 90.71%, Valid: 81.20% Test: 84.10%\n",
      "Run: 01, Epoch: 121, Loss: 0.3643, Train: 93.57%, Valid: 82.20% Test: 85.90%\n",
      "Run: 01, Epoch: 122, Loss: 0.3496, Train: 92.14%, Valid: 81.40% Test: 83.60%\n",
      "Run: 01, Epoch: 123, Loss: 0.2517, Train: 89.29%, Valid: 75.00% Test: 77.10%\n",
      "Run: 01, Epoch: 124, Loss: 0.2446, Train: 87.86%, Valid: 73.00% Test: 73.80%\n",
      "Run: 01, Epoch: 125, Loss: 0.3191, Train: 84.29%, Valid: 75.80% Test: 75.50%\n",
      "Run: 01, Epoch: 126, Loss: 0.3242, Train: 87.14%, Valid: 81.80% Test: 80.50%\n",
      "Run: 01, Epoch: 127, Loss: 0.3359, Train: 92.14%, Valid: 82.60% Test: 83.20%\n",
      "Run: 01, Epoch: 128, Loss: 0.2717, Train: 92.14%, Valid: 80.00% Test: 83.20%\n",
      "Run: 01, Epoch: 129, Loss: 0.3382, Train: 87.86%, Valid: 79.40% Test: 81.60%\n",
      "Run: 01, Epoch: 130, Loss: 0.2777, Train: 90.00%, Valid: 78.60% Test: 80.30%\n",
      "Run: 01, Epoch: 131, Loss: 0.3573, Train: 87.86%, Valid: 77.60% Test: 79.20%\n",
      "Run: 01, Epoch: 132, Loss: 0.3403, Train: 89.29%, Valid: 79.20% Test: 81.00%\n",
      "Run: 01, Epoch: 133, Loss: 0.2953, Train: 93.57%, Valid: 80.40% Test: 84.50%\n",
      "Run: 01, Epoch: 134, Loss: 0.2797, Train: 95.71%, Valid: 82.00% Test: 85.50%\n",
      "Run: 01, Epoch: 135, Loss: 0.3226, Train: 92.14%, Valid: 83.20% Test: 83.50%\n",
      "Run: 01, Epoch: 136, Loss: 0.3363, Train: 90.71%, Valid: 82.40% Test: 82.70%\n",
      "Run: 01, Epoch: 137, Loss: 0.3180, Train: 90.71%, Valid: 81.40% Test: 83.10%\n",
      "Run: 01, Epoch: 138, Loss: 0.3547, Train: 90.71%, Valid: 82.20% Test: 84.50%\n",
      "Run: 01, Epoch: 139, Loss: 0.3086, Train: 94.29%, Valid: 81.60% Test: 83.90%\n",
      "Run: 01, Epoch: 140, Loss: 0.2993, Train: 95.71%, Valid: 79.60% Test: 83.30%\n",
      "Run: 01, Epoch: 141, Loss: 0.2943, Train: 95.00%, Valid: 78.20% Test: 84.10%\n",
      "Run: 01, Epoch: 142, Loss: 0.2412, Train: 92.86%, Valid: 79.00% Test: 83.60%\n",
      "Run: 01, Epoch: 143, Loss: 0.2403, Train: 93.57%, Valid: 80.20% Test: 84.80%\n",
      "Run: 01, Epoch: 144, Loss: 0.2607, Train: 92.14%, Valid: 82.60% Test: 84.90%\n",
      "Run: 01, Epoch: 145, Loss: 0.2777, Train: 90.00%, Valid: 83.60% Test: 84.60%\n",
      "Run: 01, Epoch: 146, Loss: 0.2634, Train: 87.14%, Valid: 83.60% Test: 83.40%\n",
      "Run: 01, Epoch: 147, Loss: 0.3250, Train: 83.57%, Valid: 82.20% Test: 83.10%\n",
      "Run: 01, Epoch: 148, Loss: 0.2730, Train: 86.43%, Valid: 83.20% Test: 84.00%\n",
      "Run: 01, Epoch: 149, Loss: 0.2804, Train: 90.71%, Valid: 83.20% Test: 85.20%\n",
      "Run: 01, Epoch: 150, Loss: 0.3658, Train: 93.57%, Valid: 80.00% Test: 84.60%\n",
      "Run: 01, Epoch: 151, Loss: 0.2478, Train: 92.86%, Valid: 78.00% Test: 83.30%\n",
      "Run: 01, Epoch: 152, Loss: 0.2728, Train: 92.14%, Valid: 77.60% Test: 81.90%\n",
      "Run: 01, Epoch: 153, Loss: 0.2425, Train: 91.43%, Valid: 77.00% Test: 81.30%\n",
      "Run: 01, Epoch: 154, Loss: 0.2492, Train: 86.43%, Valid: 76.60% Test: 80.60%\n",
      "Run: 01, Epoch: 155, Loss: 0.3122, Train: 89.29%, Valid: 78.20% Test: 81.40%\n",
      "Run: 01, Epoch: 156, Loss: 0.3006, Train: 92.14%, Valid: 80.40% Test: 83.00%\n",
      "Run: 01, Epoch: 157, Loss: 0.3247, Train: 91.43%, Valid: 79.60% Test: 81.10%\n",
      "Run: 01, Epoch: 158, Loss: 0.2422, Train: 89.29%, Valid: 77.40% Test: 79.30%\n",
      "Run: 01, Epoch: 159, Loss: 0.2953, Train: 89.29%, Valid: 81.60% Test: 83.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 160, Loss: 0.2718, Train: 88.57%, Valid: 82.60% Test: 85.00%\n",
      "Run: 01, Epoch: 161, Loss: 0.2338, Train: 89.29%, Valid: 81.60% Test: 84.70%\n",
      "Run: 01, Epoch: 162, Loss: 0.2966, Train: 92.14%, Valid: 82.20% Test: 84.20%\n",
      "Run: 01, Epoch: 163, Loss: 0.2386, Train: 90.71%, Valid: 79.40% Test: 83.60%\n",
      "Run: 01, Epoch: 164, Loss: 0.2252, Train: 88.57%, Valid: 78.80% Test: 82.50%\n",
      "Run: 01, Epoch: 165, Loss: 0.2479, Train: 92.86%, Valid: 79.00% Test: 83.50%\n",
      "Run: 01, Epoch: 166, Loss: 0.2723, Train: 93.57%, Valid: 79.80% Test: 85.40%\n",
      "Run: 01, Epoch: 167, Loss: 0.2133, Train: 90.00%, Valid: 80.40% Test: 82.40%\n",
      "Run: 01, Epoch: 168, Loss: 0.2486, Train: 90.71%, Valid: 79.80% Test: 82.50%\n",
      "Run: 01, Epoch: 169, Loss: 0.2611, Train: 92.14%, Valid: 80.00% Test: 83.90%\n",
      "Run: 01, Epoch: 170, Loss: 0.2446, Train: 95.00%, Valid: 82.40% Test: 82.50%\n",
      "Run: 01, Epoch: 171, Loss: 0.2647, Train: 92.86%, Valid: 77.80% Test: 81.10%\n",
      "Run: 01, Epoch: 172, Loss: 0.2151, Train: 94.29%, Valid: 78.00% Test: 81.20%\n",
      "Run: 01, Epoch: 173, Loss: 0.2224, Train: 92.86%, Valid: 77.00% Test: 80.80%\n",
      "Run: 01, Epoch: 174, Loss: 0.3009, Train: 95.00%, Valid: 79.80% Test: 83.20%\n",
      "Run: 01, Epoch: 175, Loss: 0.2247, Train: 89.29%, Valid: 78.60% Test: 80.90%\n",
      "Run: 01, Epoch: 176, Loss: 0.2838, Train: 87.14%, Valid: 79.40% Test: 81.10%\n",
      "Run: 01, Epoch: 177, Loss: 0.2261, Train: 90.71%, Valid: 82.60% Test: 83.70%\n",
      "Run: 01, Epoch: 178, Loss: 0.2652, Train: 92.14%, Valid: 82.80% Test: 85.80%\n",
      "Run: 01, Epoch: 179, Loss: 0.2781, Train: 90.71%, Valid: 82.40% Test: 83.40%\n",
      "Run: 01, Epoch: 180, Loss: 0.2284, Train: 90.00%, Valid: 79.80% Test: 80.80%\n",
      "Run: 01, Epoch: 181, Loss: 0.2620, Train: 91.43%, Valid: 79.60% Test: 81.80%\n",
      "Run: 01, Epoch: 182, Loss: 0.2210, Train: 91.43%, Valid: 80.00% Test: 81.80%\n",
      "Run: 01, Epoch: 183, Loss: 0.2268, Train: 91.43%, Valid: 81.20% Test: 83.60%\n",
      "Run: 01, Epoch: 184, Loss: 0.2083, Train: 91.43%, Valid: 81.00% Test: 83.60%\n",
      "Run: 01, Epoch: 185, Loss: 0.2664, Train: 94.29%, Valid: 79.20% Test: 83.70%\n",
      "Run: 01, Epoch: 186, Loss: 0.2623, Train: 95.71%, Valid: 79.20% Test: 84.20%\n",
      "Run: 01, Epoch: 187, Loss: 0.1761, Train: 95.00%, Valid: 78.80% Test: 83.80%\n",
      "Run: 01, Epoch: 188, Loss: 0.2397, Train: 95.00%, Valid: 78.40% Test: 83.00%\n",
      "Run: 01, Epoch: 189, Loss: 0.2362, Train: 92.86%, Valid: 80.20% Test: 84.10%\n",
      "Run: 01, Epoch: 190, Loss: 0.2474, Train: 90.71%, Valid: 84.40% Test: 85.00%\n",
      "Run: 01, Epoch: 191, Loss: 0.2179, Train: 85.71%, Valid: 83.80% Test: 82.20%\n",
      "Run: 01, Epoch: 192, Loss: 0.2294, Train: 85.71%, Valid: 81.80% Test: 81.30%\n",
      "Run: 01, Epoch: 193, Loss: 0.2675, Train: 88.57%, Valid: 83.80% Test: 82.50%\n",
      "Run: 01, Epoch: 194, Loss: 0.2266, Train: 91.43%, Valid: 84.20% Test: 84.40%\n",
      "Run: 01, Epoch: 195, Loss: 0.1937, Train: 94.29%, Valid: 83.00% Test: 83.40%\n",
      "Run: 01, Epoch: 196, Loss: 0.2344, Train: 95.71%, Valid: 79.20% Test: 82.80%\n",
      "Run: 01, Epoch: 197, Loss: 0.2202, Train: 94.29%, Valid: 77.80% Test: 82.10%\n",
      "Run: 01, Epoch: 198, Loss: 0.2477, Train: 92.86%, Valid: 75.20% Test: 80.40%\n",
      "Run: 01, Epoch: 199, Loss: 0.1955, Train: 94.29%, Valid: 76.60% Test: 81.50%\n",
      "Run: 01, Epoch: 200, Loss: 0.2467, Train: 96.43%, Valid: 80.20% Test: 83.00%\n",
      "Run 01:\n",
      "Highest Train: 96.43\n",
      "Highest Valid: 84.80\n",
      "  Final Train: 90.71\n",
      "   Final Test: 84.30\n",
      "Run: 02, Epoch: 01, Loss: 2.1759, Train: 14.29%, Valid: 31.60% Test: 31.90%\n",
      "Run: 02, Epoch: 02, Loss: 2.1556, Train: 14.29%, Valid: 31.80% Test: 31.90%\n",
      "Run: 02, Epoch: 03, Loss: 2.0211, Train: 13.57%, Valid: 31.60% Test: 31.70%\n",
      "Run: 02, Epoch: 04, Loss: 1.9042, Train: 22.86%, Valid: 30.20% Test: 31.20%\n",
      "Run: 02, Epoch: 05, Loss: 1.8236, Train: 18.57%, Valid: 13.40% Test: 14.50%\n",
      "Run: 02, Epoch: 06, Loss: 1.7605, Train: 32.86%, Valid: 21.60% Test: 23.10%\n",
      "Run: 02, Epoch: 07, Loss: 1.7441, Train: 32.86%, Valid: 25.00% Test: 25.10%\n",
      "Run: 02, Epoch: 08, Loss: 1.6869, Train: 30.00%, Valid: 20.00% Test: 19.70%\n",
      "Run: 02, Epoch: 09, Loss: 1.6294, Train: 23.57%, Valid: 15.80% Test: 14.50%\n",
      "Run: 02, Epoch: 10, Loss: 1.6469, Train: 24.29%, Valid: 15.20% Test: 14.30%\n",
      "Run: 02, Epoch: 11, Loss: 1.5626, Train: 27.14%, Valid: 17.20% Test: 16.10%\n",
      "Run: 02, Epoch: 12, Loss: 1.5820, Train: 32.14%, Valid: 20.40% Test: 20.20%\n",
      "Run: 02, Epoch: 13, Loss: 1.5133, Train: 38.57%, Valid: 23.80% Test: 24.80%\n",
      "Run: 02, Epoch: 14, Loss: 1.5059, Train: 41.43%, Valid: 28.00% Test: 28.60%\n",
      "Run: 02, Epoch: 15, Loss: 1.4144, Train: 45.00%, Valid: 28.20% Test: 29.60%\n",
      "Run: 02, Epoch: 16, Loss: 1.3912, Train: 45.71%, Valid: 28.40% Test: 31.00%\n",
      "Run: 02, Epoch: 17, Loss: 1.3555, Train: 48.57%, Valid: 30.00% Test: 32.80%\n",
      "Run: 02, Epoch: 18, Loss: 1.3403, Train: 55.71%, Valid: 40.80% Test: 44.30%\n",
      "Run: 02, Epoch: 19, Loss: 1.3251, Train: 55.00%, Valid: 44.60% Test: 48.10%\n",
      "Run: 02, Epoch: 20, Loss: 1.2419, Train: 55.71%, Valid: 40.20% Test: 47.30%\n",
      "Run: 02, Epoch: 21, Loss: 1.2363, Train: 54.29%, Valid: 42.20% Test: 46.50%\n",
      "Run: 02, Epoch: 22, Loss: 1.1694, Train: 53.57%, Valid: 43.00% Test: 45.60%\n",
      "Run: 02, Epoch: 23, Loss: 1.2357, Train: 52.14%, Valid: 35.80% Test: 40.40%\n",
      "Run: 02, Epoch: 24, Loss: 1.1443, Train: 51.43%, Valid: 35.60% Test: 36.90%\n",
      "Run: 02, Epoch: 25, Loss: 1.1377, Train: 51.43%, Valid: 35.60% Test: 36.60%\n",
      "Run: 02, Epoch: 26, Loss: 1.1194, Train: 55.00%, Valid: 37.00% Test: 37.40%\n",
      "Run: 02, Epoch: 27, Loss: 1.0909, Train: 58.57%, Valid: 37.20% Test: 39.10%\n",
      "Run: 02, Epoch: 28, Loss: 1.0540, Train: 63.57%, Valid: 41.60% Test: 44.60%\n",
      "Run: 02, Epoch: 29, Loss: 1.0177, Train: 66.43%, Valid: 52.40% Test: 53.00%\n",
      "Run: 02, Epoch: 30, Loss: 0.9876, Train: 70.71%, Valid: 60.20% Test: 60.10%\n",
      "Run: 02, Epoch: 31, Loss: 0.9652, Train: 73.57%, Valid: 63.60% Test: 64.40%\n",
      "Run: 02, Epoch: 32, Loss: 0.9328, Train: 77.86%, Valid: 66.60% Test: 66.00%\n",
      "Run: 02, Epoch: 33, Loss: 0.9430, Train: 82.14%, Valid: 69.00% Test: 69.00%\n",
      "Run: 02, Epoch: 34, Loss: 0.9315, Train: 80.71%, Valid: 69.60% Test: 67.10%\n",
      "Run: 02, Epoch: 35, Loss: 0.9554, Train: 80.71%, Valid: 67.80% Test: 68.70%\n",
      "Run: 02, Epoch: 36, Loss: 0.8930, Train: 78.57%, Valid: 66.40% Test: 68.70%\n",
      "Run: 02, Epoch: 37, Loss: 0.8254, Train: 74.29%, Valid: 64.20% Test: 65.50%\n",
      "Run: 02, Epoch: 38, Loss: 0.8628, Train: 64.29%, Valid: 59.20% Test: 59.20%\n",
      "Run: 02, Epoch: 39, Loss: 0.7923, Train: 61.43%, Valid: 52.40% Test: 54.10%\n",
      "Run: 02, Epoch: 40, Loss: 0.7991, Train: 52.86%, Valid: 51.80% Test: 52.40%\n",
      "Run: 02, Epoch: 41, Loss: 0.7974, Train: 45.00%, Valid: 50.00% Test: 52.30%\n",
      "Run: 02, Epoch: 42, Loss: 0.7027, Train: 43.57%, Valid: 48.00% Test: 50.20%\n",
      "Run: 02, Epoch: 43, Loss: 0.6813, Train: 42.14%, Valid: 47.40% Test: 48.90%\n",
      "Run: 02, Epoch: 44, Loss: 0.7027, Train: 47.14%, Valid: 49.60% Test: 51.90%\n",
      "Run: 02, Epoch: 45, Loss: 0.6949, Train: 58.57%, Valid: 57.80% Test: 58.80%\n",
      "Run: 02, Epoch: 46, Loss: 0.6496, Train: 75.00%, Valid: 71.80% Test: 70.00%\n",
      "Run: 02, Epoch: 47, Loss: 0.6506, Train: 82.86%, Valid: 77.20% Test: 78.10%\n",
      "Run: 02, Epoch: 48, Loss: 0.6062, Train: 82.14%, Valid: 78.40% Test: 79.40%\n",
      "Run: 02, Epoch: 49, Loss: 0.6385, Train: 81.43%, Valid: 77.80% Test: 78.90%\n",
      "Run: 02, Epoch: 50, Loss: 0.6473, Train: 82.86%, Valid: 76.20% Test: 76.20%\n",
      "Run: 02, Epoch: 51, Loss: 0.5961, Train: 82.14%, Valid: 73.20% Test: 73.20%\n",
      "Run: 02, Epoch: 52, Loss: 0.5796, Train: 83.57%, Valid: 71.40% Test: 72.50%\n",
      "Run: 02, Epoch: 53, Loss: 0.5691, Train: 81.43%, Valid: 69.60% Test: 70.80%\n",
      "Run: 02, Epoch: 54, Loss: 0.5063, Train: 83.57%, Valid: 72.40% Test: 72.90%\n",
      "Run: 02, Epoch: 55, Loss: 0.5133, Train: 87.14%, Valid: 76.60% Test: 77.00%\n",
      "Run: 02, Epoch: 56, Loss: 0.6260, Train: 88.57%, Valid: 78.80% Test: 78.60%\n",
      "Run: 02, Epoch: 57, Loss: 0.5846, Train: 90.71%, Valid: 82.40% Test: 82.50%\n",
      "Run: 02, Epoch: 58, Loss: 0.5316, Train: 92.14%, Valid: 82.60% Test: 83.20%\n",
      "Run: 02, Epoch: 59, Loss: 0.5329, Train: 88.57%, Valid: 79.40% Test: 82.30%\n",
      "Run: 02, Epoch: 60, Loss: 0.5747, Train: 89.29%, Valid: 78.60% Test: 81.40%\n",
      "Run: 02, Epoch: 61, Loss: 0.5367, Train: 85.71%, Valid: 79.20% Test: 81.10%\n",
      "Run: 02, Epoch: 62, Loss: 0.4719, Train: 84.29%, Valid: 79.20% Test: 80.90%\n",
      "Run: 02, Epoch: 63, Loss: 0.5526, Train: 87.86%, Valid: 80.60% Test: 81.60%\n",
      "Run: 02, Epoch: 64, Loss: 0.4563, Train: 88.57%, Valid: 82.20% Test: 82.30%\n",
      "Run: 02, Epoch: 65, Loss: 0.4914, Train: 89.29%, Valid: 82.60% Test: 82.60%\n",
      "Run: 02, Epoch: 66, Loss: 0.4969, Train: 88.57%, Valid: 82.20% Test: 82.10%\n",
      "Run: 02, Epoch: 67, Loss: 0.4961, Train: 85.71%, Valid: 83.00% Test: 83.00%\n",
      "Run: 02, Epoch: 68, Loss: 0.4513, Train: 87.14%, Valid: 82.60% Test: 82.90%\n",
      "Run: 02, Epoch: 69, Loss: 0.5147, Train: 89.29%, Valid: 82.40% Test: 83.50%\n",
      "Run: 02, Epoch: 70, Loss: 0.4687, Train: 88.57%, Valid: 82.00% Test: 83.60%\n",
      "Run: 02, Epoch: 71, Loss: 0.4760, Train: 88.57%, Valid: 81.40% Test: 83.60%\n",
      "Run: 02, Epoch: 72, Loss: 0.4267, Train: 89.29%, Valid: 81.80% Test: 83.40%\n",
      "Run: 02, Epoch: 73, Loss: 0.4898, Train: 90.00%, Valid: 82.00% Test: 84.50%\n",
      "Run: 02, Epoch: 74, Loss: 0.4532, Train: 90.71%, Valid: 82.40% Test: 84.90%\n",
      "Run: 02, Epoch: 75, Loss: 0.4333, Train: 90.71%, Valid: 82.60% Test: 84.60%\n",
      "Run: 02, Epoch: 76, Loss: 0.4221, Train: 89.29%, Valid: 82.60% Test: 84.20%\n",
      "Run: 02, Epoch: 77, Loss: 0.4348, Train: 88.57%, Valid: 82.60% Test: 83.50%\n",
      "Run: 02, Epoch: 78, Loss: 0.4541, Train: 89.29%, Valid: 83.20% Test: 83.40%\n",
      "Run: 02, Epoch: 79, Loss: 0.4496, Train: 90.71%, Valid: 84.20% Test: 82.50%\n",
      "Run: 02, Epoch: 80, Loss: 0.3986, Train: 87.14%, Valid: 82.20% Test: 80.60%\n",
      "Run: 02, Epoch: 81, Loss: 0.4233, Train: 87.86%, Valid: 81.80% Test: 81.80%\n",
      "Run: 02, Epoch: 82, Loss: 0.3808, Train: 88.57%, Valid: 80.60% Test: 81.20%\n",
      "Run: 02, Epoch: 83, Loss: 0.4213, Train: 87.14%, Valid: 80.00% Test: 80.60%\n",
      "Run: 02, Epoch: 84, Loss: 0.4473, Train: 86.43%, Valid: 80.20% Test: 81.30%\n",
      "Run: 02, Epoch: 85, Loss: 0.4044, Train: 89.29%, Valid: 80.60% Test: 82.60%\n",
      "Run: 02, Epoch: 86, Loss: 0.3858, Train: 90.00%, Valid: 83.60% Test: 84.80%\n",
      "Run: 02, Epoch: 87, Loss: 0.4136, Train: 93.57%, Valid: 83.80% Test: 86.00%\n",
      "Run: 02, Epoch: 88, Loss: 0.4222, Train: 95.00%, Valid: 83.40% Test: 85.70%\n",
      "Run: 02, Epoch: 89, Loss: 0.3462, Train: 93.57%, Valid: 82.00% Test: 84.60%\n",
      "Run: 02, Epoch: 90, Loss: 0.3449, Train: 87.14%, Valid: 80.00% Test: 84.90%\n",
      "Run: 02, Epoch: 91, Loss: 0.3266, Train: 87.14%, Valid: 79.40% Test: 84.70%\n",
      "Run: 02, Epoch: 92, Loss: 0.3651, Train: 90.71%, Valid: 82.20% Test: 84.90%\n",
      "Run: 02, Epoch: 93, Loss: 0.3582, Train: 92.14%, Valid: 82.20% Test: 86.50%\n",
      "Run: 02, Epoch: 94, Loss: 0.3694, Train: 90.71%, Valid: 82.40% Test: 84.70%\n",
      "Run: 02, Epoch: 95, Loss: 0.4162, Train: 88.57%, Valid: 83.00% Test: 84.40%\n",
      "Run: 02, Epoch: 96, Loss: 0.3698, Train: 88.57%, Valid: 82.60% Test: 85.20%\n",
      "Run: 02, Epoch: 97, Loss: 0.4124, Train: 90.00%, Valid: 82.20% Test: 85.90%\n",
      "Run: 02, Epoch: 98, Loss: 0.4135, Train: 92.14%, Valid: 83.00% Test: 86.30%\n",
      "Run: 02, Epoch: 99, Loss: 0.3864, Train: 91.43%, Valid: 81.20% Test: 84.60%\n",
      "Run: 02, Epoch: 100, Loss: 0.3577, Train: 91.43%, Valid: 79.60% Test: 81.70%\n",
      "Run: 02, Epoch: 101, Loss: 0.3302, Train: 86.43%, Valid: 78.20% Test: 79.90%\n",
      "Run: 02, Epoch: 102, Loss: 0.3701, Train: 87.14%, Valid: 79.20% Test: 80.70%\n",
      "Run: 02, Epoch: 103, Loss: 0.3207, Train: 89.29%, Valid: 79.60% Test: 80.60%\n",
      "Run: 02, Epoch: 104, Loss: 0.3396, Train: 89.29%, Valid: 79.80% Test: 82.30%\n",
      "Run: 02, Epoch: 105, Loss: 0.3240, Train: 93.57%, Valid: 80.00% Test: 80.80%\n",
      "Run: 02, Epoch: 106, Loss: 0.3467, Train: 90.00%, Valid: 82.60% Test: 83.30%\n",
      "Run: 02, Epoch: 107, Loss: 0.3331, Train: 90.00%, Valid: 83.20% Test: 85.30%\n",
      "Run: 02, Epoch: 108, Loss: 0.3672, Train: 91.43%, Valid: 82.80% Test: 85.10%\n",
      "Run: 02, Epoch: 109, Loss: 0.3103, Train: 90.71%, Valid: 82.80% Test: 85.10%\n",
      "Run: 02, Epoch: 110, Loss: 0.3550, Train: 92.86%, Valid: 82.20% Test: 84.20%\n",
      "Run: 02, Epoch: 111, Loss: 0.3281, Train: 93.57%, Valid: 80.20% Test: 84.00%\n",
      "Run: 02, Epoch: 112, Loss: 0.3127, Train: 90.71%, Valid: 80.00% Test: 82.20%\n",
      "Run: 02, Epoch: 113, Loss: 0.3499, Train: 88.57%, Valid: 79.60% Test: 82.10%\n",
      "Run: 02, Epoch: 114, Loss: 0.3103, Train: 90.00%, Valid: 81.00% Test: 83.80%\n",
      "Run: 02, Epoch: 115, Loss: 0.3018, Train: 92.86%, Valid: 81.20% Test: 83.90%\n",
      "Run: 02, Epoch: 116, Loss: 0.2762, Train: 92.14%, Valid: 81.00% Test: 84.70%\n",
      "Run: 02, Epoch: 117, Loss: 0.3080, Train: 92.14%, Valid: 80.20% Test: 82.60%\n",
      "Run: 02, Epoch: 118, Loss: 0.3287, Train: 89.29%, Valid: 79.40% Test: 80.10%\n",
      "Run: 02, Epoch: 119, Loss: 0.3848, Train: 89.29%, Valid: 79.80% Test: 80.60%\n",
      "Run: 02, Epoch: 120, Loss: 0.3237, Train: 88.57%, Valid: 80.40% Test: 83.00%\n",
      "Run: 02, Epoch: 121, Loss: 0.3504, Train: 91.43%, Valid: 83.00% Test: 85.40%\n",
      "Run: 02, Epoch: 122, Loss: 0.2723, Train: 91.43%, Valid: 83.80% Test: 86.50%\n",
      "Run: 02, Epoch: 123, Loss: 0.2570, Train: 92.14%, Valid: 84.00% Test: 85.80%\n",
      "Run: 02, Epoch: 124, Loss: 0.3481, Train: 92.86%, Valid: 84.00% Test: 85.60%\n",
      "Run: 02, Epoch: 125, Loss: 0.2532, Train: 92.14%, Valid: 83.40% Test: 85.20%\n",
      "Run: 02, Epoch: 126, Loss: 0.3141, Train: 91.43%, Valid: 81.60% Test: 84.00%\n",
      "Run: 02, Epoch: 127, Loss: 0.3360, Train: 92.14%, Valid: 81.00% Test: 84.30%\n",
      "Run: 02, Epoch: 128, Loss: 0.2838, Train: 92.14%, Valid: 79.60% Test: 81.70%\n",
      "Run: 02, Epoch: 129, Loss: 0.2450, Train: 90.00%, Valid: 77.20% Test: 78.80%\n",
      "Run: 02, Epoch: 130, Loss: 0.2868, Train: 88.57%, Valid: 76.20% Test: 77.70%\n",
      "Run: 02, Epoch: 131, Loss: 0.2817, Train: 92.14%, Valid: 78.00% Test: 79.70%\n",
      "Run: 02, Epoch: 132, Loss: 0.2988, Train: 92.86%, Valid: 80.80% Test: 83.40%\n",
      "Run: 02, Epoch: 133, Loss: 0.3257, Train: 90.71%, Valid: 79.80% Test: 84.10%\n",
      "Run: 02, Epoch: 134, Loss: 0.2673, Train: 91.43%, Valid: 81.60% Test: 84.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 135, Loss: 0.2533, Train: 95.00%, Valid: 82.20% Test: 85.20%\n",
      "Run: 02, Epoch: 136, Loss: 0.2673, Train: 95.00%, Valid: 83.00% Test: 84.80%\n",
      "Run: 02, Epoch: 137, Loss: 0.3236, Train: 94.29%, Valid: 82.40% Test: 85.90%\n",
      "Run: 02, Epoch: 138, Loss: 0.3303, Train: 93.57%, Valid: 82.40% Test: 83.90%\n",
      "Run: 02, Epoch: 139, Loss: 0.2704, Train: 87.86%, Valid: 76.80% Test: 77.10%\n",
      "Run: 02, Epoch: 140, Loss: 0.3042, Train: 82.86%, Valid: 71.00% Test: 71.90%\n",
      "Run: 02, Epoch: 141, Loss: 0.2729, Train: 80.00%, Valid: 71.20% Test: 72.30%\n",
      "Run: 02, Epoch: 142, Loss: 0.3378, Train: 87.14%, Valid: 77.40% Test: 77.70%\n",
      "Run: 02, Epoch: 143, Loss: 0.3286, Train: 96.43%, Valid: 83.80% Test: 85.10%\n",
      "Run: 02, Epoch: 144, Loss: 0.2793, Train: 93.57%, Valid: 83.40% Test: 85.60%\n",
      "Run: 02, Epoch: 145, Loss: 0.2950, Train: 90.71%, Valid: 82.20% Test: 83.70%\n",
      "Run: 02, Epoch: 146, Loss: 0.2197, Train: 89.29%, Valid: 82.00% Test: 83.50%\n",
      "Run: 02, Epoch: 147, Loss: 0.2606, Train: 86.43%, Valid: 80.80% Test: 82.10%\n",
      "Run: 02, Epoch: 148, Loss: 0.2736, Train: 88.57%, Valid: 81.40% Test: 82.60%\n",
      "Run: 02, Epoch: 149, Loss: 0.2738, Train: 92.86%, Valid: 83.40% Test: 84.10%\n",
      "Run: 02, Epoch: 150, Loss: 0.2580, Train: 92.14%, Valid: 82.20% Test: 80.90%\n",
      "Run: 02, Epoch: 151, Loss: 0.4113, Train: 85.71%, Valid: 77.00% Test: 75.20%\n",
      "Run: 02, Epoch: 152, Loss: 0.2936, Train: 85.00%, Valid: 78.40% Test: 76.70%\n",
      "Run: 02, Epoch: 153, Loss: 0.2825, Train: 84.29%, Valid: 77.00% Test: 78.30%\n",
      "Run: 02, Epoch: 154, Loss: 0.3141, Train: 82.86%, Valid: 75.00% Test: 76.10%\n",
      "Run: 02, Epoch: 155, Loss: 0.3238, Train: 87.14%, Valid: 79.40% Test: 79.60%\n",
      "Run: 02, Epoch: 156, Loss: 0.2275, Train: 93.57%, Valid: 81.00% Test: 82.60%\n",
      "Run: 02, Epoch: 157, Loss: 0.2093, Train: 90.71%, Valid: 79.80% Test: 82.60%\n",
      "Run: 02, Epoch: 158, Loss: 0.3270, Train: 87.14%, Valid: 77.00% Test: 79.10%\n",
      "Run: 02, Epoch: 159, Loss: 0.2582, Train: 84.29%, Valid: 76.00% Test: 77.20%\n",
      "Run: 02, Epoch: 160, Loss: 0.2959, Train: 81.43%, Valid: 74.80% Test: 77.20%\n",
      "Run: 02, Epoch: 161, Loss: 0.2583, Train: 84.29%, Valid: 75.00% Test: 77.30%\n",
      "Run: 02, Epoch: 162, Loss: 0.2957, Train: 81.43%, Valid: 72.40% Test: 76.20%\n",
      "Run: 02, Epoch: 163, Loss: 0.2369, Train: 79.29%, Valid: 72.40% Test: 73.70%\n",
      "Run: 02, Epoch: 164, Loss: 0.2798, Train: 82.14%, Valid: 73.40% Test: 72.90%\n",
      "Run: 02, Epoch: 165, Loss: 0.3048, Train: 75.00%, Valid: 66.20% Test: 64.80%\n",
      "Run: 02, Epoch: 166, Loss: 0.3579, Train: 66.43%, Valid: 60.00% Test: 59.90%\n",
      "Run: 02, Epoch: 167, Loss: 0.2689, Train: 62.86%, Valid: 59.80% Test: 59.10%\n",
      "Run: 02, Epoch: 168, Loss: 0.3449, Train: 72.86%, Valid: 74.60% Test: 69.30%\n",
      "Run: 02, Epoch: 169, Loss: 0.3077, Train: 87.14%, Valid: 83.80% Test: 84.10%\n",
      "Run: 02, Epoch: 170, Loss: 0.3222, Train: 92.14%, Valid: 83.00% Test: 84.40%\n",
      "Run: 02, Epoch: 171, Loss: 0.2179, Train: 89.29%, Valid: 78.60% Test: 80.50%\n",
      "Run: 02, Epoch: 172, Loss: 0.2285, Train: 83.57%, Valid: 73.60% Test: 77.00%\n",
      "Run: 02, Epoch: 173, Loss: 0.2622, Train: 78.57%, Valid: 70.00% Test: 72.30%\n",
      "Run: 02, Epoch: 174, Loss: 0.2563, Train: 77.86%, Valid: 67.00% Test: 70.80%\n",
      "Run: 02, Epoch: 175, Loss: 0.2608, Train: 79.29%, Valid: 71.00% Test: 72.00%\n",
      "Run: 02, Epoch: 176, Loss: 0.2612, Train: 82.14%, Valid: 75.00% Test: 74.80%\n",
      "Run: 02, Epoch: 177, Loss: 0.3144, Train: 83.57%, Valid: 72.60% Test: 74.60%\n",
      "Run: 02, Epoch: 178, Loss: 0.2815, Train: 89.29%, Valid: 76.80% Test: 76.60%\n",
      "Run: 02, Epoch: 179, Loss: 0.2509, Train: 88.57%, Valid: 77.20% Test: 78.80%\n",
      "Run: 02, Epoch: 180, Loss: 0.3105, Train: 80.71%, Valid: 76.00% Test: 75.00%\n",
      "Run: 02, Epoch: 181, Loss: 0.2484, Train: 77.14%, Valid: 73.80% Test: 72.20%\n",
      "Run: 02, Epoch: 182, Loss: 0.2452, Train: 80.00%, Valid: 75.40% Test: 76.50%\n",
      "Run: 02, Epoch: 183, Loss: 0.2531, Train: 88.57%, Valid: 82.40% Test: 82.30%\n",
      "Run: 02, Epoch: 184, Loss: 0.2330, Train: 87.86%, Valid: 82.40% Test: 83.20%\n",
      "Run: 02, Epoch: 185, Loss: 0.2961, Train: 90.00%, Valid: 82.20% Test: 81.70%\n",
      "Run: 02, Epoch: 186, Loss: 0.2335, Train: 92.14%, Valid: 82.20% Test: 81.50%\n",
      "Run: 02, Epoch: 187, Loss: 0.2626, Train: 92.14%, Valid: 81.20% Test: 81.60%\n",
      "Run: 02, Epoch: 188, Loss: 0.2262, Train: 93.57%, Valid: 78.40% Test: 80.10%\n",
      "Run: 02, Epoch: 189, Loss: 0.3107, Train: 92.14%, Valid: 76.60% Test: 76.80%\n",
      "Run: 02, Epoch: 190, Loss: 0.2178, Train: 91.43%, Valid: 76.40% Test: 78.00%\n",
      "Run: 02, Epoch: 191, Loss: 0.2253, Train: 92.14%, Valid: 77.60% Test: 79.60%\n",
      "Run: 02, Epoch: 192, Loss: 0.2611, Train: 94.29%, Valid: 78.20% Test: 81.00%\n",
      "Run: 02, Epoch: 193, Loss: 0.2908, Train: 94.29%, Valid: 81.00% Test: 81.90%\n",
      "Run: 02, Epoch: 194, Loss: 0.2633, Train: 94.29%, Valid: 81.00% Test: 82.70%\n",
      "Run: 02, Epoch: 195, Loss: 0.2460, Train: 95.00%, Valid: 81.80% Test: 82.50%\n",
      "Run: 02, Epoch: 196, Loss: 0.2034, Train: 91.43%, Valid: 79.40% Test: 79.60%\n",
      "Run: 02, Epoch: 197, Loss: 0.1966, Train: 88.57%, Valid: 79.80% Test: 79.50%\n",
      "Run: 02, Epoch: 198, Loss: 0.2712, Train: 88.57%, Valid: 78.60% Test: 79.50%\n",
      "Run: 02, Epoch: 199, Loss: 0.2574, Train: 92.14%, Valid: 79.80% Test: 80.30%\n",
      "Run: 02, Epoch: 200, Loss: 0.2816, Train: 95.00%, Valid: 80.60% Test: 81.20%\n",
      "Run 02:\n",
      "Highest Train: 96.43\n",
      "Highest Valid: 84.20\n",
      "  Final Train: 90.71\n",
      "   Final Test: 82.50\n",
      "Run: 03, Epoch: 01, Loss: 2.1255, Train: 13.57%, Valid: 16.60% Test: 14.60%\n",
      "Run: 03, Epoch: 02, Loss: 1.9746, Train: 13.57%, Valid: 16.80% Test: 14.10%\n",
      "Run: 03, Epoch: 03, Loss: 1.8379, Train: 22.86%, Valid: 20.20% Test: 20.90%\n",
      "Run: 03, Epoch: 04, Loss: 1.7802, Train: 20.00%, Valid: 17.80% Test: 16.80%\n",
      "Run: 03, Epoch: 05, Loss: 1.7810, Train: 15.71%, Valid: 13.40% Test: 12.60%\n",
      "Run: 03, Epoch: 06, Loss: 1.7183, Train: 15.00%, Valid: 12.40% Test: 12.50%\n",
      "Run: 03, Epoch: 07, Loss: 1.6527, Train: 16.43%, Valid: 12.60% Test: 13.90%\n",
      "Run: 03, Epoch: 08, Loss: 1.6376, Train: 20.71%, Valid: 18.80% Test: 18.80%\n",
      "Run: 03, Epoch: 09, Loss: 1.5839, Train: 34.29%, Valid: 28.60% Test: 30.70%\n",
      "Run: 03, Epoch: 10, Loss: 1.5239, Train: 39.29%, Valid: 35.60% Test: 36.00%\n",
      "Run: 03, Epoch: 11, Loss: 1.5085, Train: 37.14%, Valid: 31.60% Test: 30.00%\n",
      "Run: 03, Epoch: 12, Loss: 1.5192, Train: 33.57%, Valid: 28.20% Test: 29.20%\n",
      "Run: 03, Epoch: 13, Loss: 1.4913, Train: 35.00%, Valid: 31.60% Test: 32.30%\n",
      "Run: 03, Epoch: 14, Loss: 1.4535, Train: 40.00%, Valid: 33.40% Test: 35.30%\n",
      "Run: 03, Epoch: 15, Loss: 1.4348, Train: 41.43%, Valid: 39.20% Test: 40.10%\n",
      "Run: 03, Epoch: 16, Loss: 1.4010, Train: 46.43%, Valid: 48.00% Test: 47.40%\n",
      "Run: 03, Epoch: 17, Loss: 1.3782, Train: 46.43%, Valid: 52.40% Test: 52.00%\n",
      "Run: 03, Epoch: 18, Loss: 1.3288, Train: 50.71%, Valid: 57.20% Test: 55.60%\n",
      "Run: 03, Epoch: 19, Loss: 1.2835, Train: 48.57%, Valid: 57.20% Test: 55.50%\n",
      "Run: 03, Epoch: 20, Loss: 1.2339, Train: 47.86%, Valid: 58.00% Test: 55.10%\n",
      "Run: 03, Epoch: 21, Loss: 1.2166, Train: 51.43%, Valid: 58.80% Test: 59.50%\n",
      "Run: 03, Epoch: 22, Loss: 1.1442, Train: 55.71%, Valid: 58.60% Test: 58.50%\n",
      "Run: 03, Epoch: 23, Loss: 1.1302, Train: 52.86%, Valid: 54.40% Test: 53.50%\n",
      "Run: 03, Epoch: 24, Loss: 1.1029, Train: 49.29%, Valid: 47.40% Test: 49.10%\n",
      "Run: 03, Epoch: 25, Loss: 1.0607, Train: 52.14%, Valid: 49.60% Test: 49.70%\n",
      "Run: 03, Epoch: 26, Loss: 1.0572, Train: 52.86%, Valid: 50.60% Test: 50.10%\n",
      "Run: 03, Epoch: 27, Loss: 0.9755, Train: 51.43%, Valid: 51.60% Test: 49.30%\n",
      "Run: 03, Epoch: 28, Loss: 1.0076, Train: 51.43%, Valid: 52.60% Test: 48.80%\n",
      "Run: 03, Epoch: 29, Loss: 0.9492, Train: 52.86%, Valid: 53.60% Test: 50.30%\n",
      "Run: 03, Epoch: 30, Loss: 0.8828, Train: 61.43%, Valid: 58.60% Test: 57.20%\n",
      "Run: 03, Epoch: 31, Loss: 0.8875, Train: 62.86%, Valid: 60.80% Test: 58.50%\n",
      "Run: 03, Epoch: 32, Loss: 0.8244, Train: 65.00%, Valid: 64.80% Test: 62.50%\n",
      "Run: 03, Epoch: 33, Loss: 0.7811, Train: 68.57%, Valid: 65.20% Test: 64.80%\n",
      "Run: 03, Epoch: 34, Loss: 0.8058, Train: 71.43%, Valid: 65.80% Test: 63.60%\n",
      "Run: 03, Epoch: 35, Loss: 0.7545, Train: 69.29%, Valid: 62.80% Test: 60.60%\n",
      "Run: 03, Epoch: 36, Loss: 0.7233, Train: 67.14%, Valid: 64.40% Test: 62.60%\n",
      "Run: 03, Epoch: 37, Loss: 0.7011, Train: 70.71%, Valid: 66.00% Test: 66.50%\n",
      "Run: 03, Epoch: 38, Loss: 0.7550, Train: 74.29%, Valid: 71.40% Test: 71.30%\n",
      "Run: 03, Epoch: 39, Loss: 0.7090, Train: 81.43%, Valid: 78.00% Test: 77.20%\n",
      "Run: 03, Epoch: 40, Loss: 0.6629, Train: 84.29%, Valid: 80.60% Test: 80.40%\n",
      "Run: 03, Epoch: 41, Loss: 0.6297, Train: 86.43%, Valid: 80.60% Test: 80.80%\n",
      "Run: 03, Epoch: 42, Loss: 0.6920, Train: 87.86%, Valid: 81.20% Test: 79.70%\n",
      "Run: 03, Epoch: 43, Loss: 0.6782, Train: 87.14%, Valid: 78.80% Test: 77.90%\n",
      "Run: 03, Epoch: 44, Loss: 0.5844, Train: 86.43%, Valid: 78.00% Test: 77.10%\n",
      "Run: 03, Epoch: 45, Loss: 0.6031, Train: 84.29%, Valid: 80.60% Test: 80.20%\n",
      "Run: 03, Epoch: 46, Loss: 0.6075, Train: 85.00%, Valid: 82.20% Test: 79.60%\n",
      "Run: 03, Epoch: 47, Loss: 0.6074, Train: 83.57%, Valid: 80.40% Test: 78.90%\n",
      "Run: 03, Epoch: 48, Loss: 0.6119, Train: 83.57%, Valid: 78.40% Test: 78.50%\n",
      "Run: 03, Epoch: 49, Loss: 0.5396, Train: 82.14%, Valid: 75.40% Test: 74.10%\n",
      "Run: 03, Epoch: 50, Loss: 0.4983, Train: 82.14%, Valid: 72.80% Test: 72.30%\n",
      "Run: 03, Epoch: 51, Loss: 0.5122, Train: 83.57%, Valid: 74.60% Test: 72.90%\n",
      "Run: 03, Epoch: 52, Loss: 0.5075, Train: 86.43%, Valid: 75.20% Test: 74.50%\n",
      "Run: 03, Epoch: 53, Loss: 0.5496, Train: 87.86%, Valid: 77.60% Test: 77.50%\n",
      "Run: 03, Epoch: 54, Loss: 0.5056, Train: 90.71%, Valid: 82.20% Test: 82.00%\n",
      "Run: 03, Epoch: 55, Loss: 0.4642, Train: 90.71%, Valid: 84.40% Test: 83.50%\n",
      "Run: 03, Epoch: 56, Loss: 0.4631, Train: 90.71%, Valid: 85.40% Test: 83.80%\n",
      "Run: 03, Epoch: 57, Loss: 0.4457, Train: 91.43%, Valid: 84.60% Test: 84.50%\n",
      "Run: 03, Epoch: 58, Loss: 0.4422, Train: 92.86%, Valid: 83.00% Test: 84.80%\n",
      "Run: 03, Epoch: 59, Loss: 0.4918, Train: 92.14%, Valid: 82.80% Test: 84.50%\n",
      "Run: 03, Epoch: 60, Loss: 0.4479, Train: 92.86%, Valid: 83.60% Test: 84.00%\n",
      "Run: 03, Epoch: 61, Loss: 0.4596, Train: 93.57%, Valid: 83.20% Test: 84.20%\n",
      "Run: 03, Epoch: 62, Loss: 0.4341, Train: 93.57%, Valid: 83.80% Test: 84.10%\n",
      "Run: 03, Epoch: 63, Loss: 0.4971, Train: 93.57%, Valid: 83.20% Test: 85.40%\n",
      "Run: 03, Epoch: 64, Loss: 0.3718, Train: 92.14%, Valid: 82.00% Test: 83.00%\n",
      "Run: 03, Epoch: 65, Loss: 0.4028, Train: 87.86%, Valid: 79.80% Test: 80.60%\n",
      "Run: 03, Epoch: 66, Loss: 0.4341, Train: 87.14%, Valid: 77.60% Test: 77.50%\n",
      "Run: 03, Epoch: 67, Loss: 0.4161, Train: 87.14%, Valid: 80.00% Test: 79.00%\n",
      "Run: 03, Epoch: 68, Loss: 0.4836, Train: 89.29%, Valid: 79.80% Test: 81.80%\n",
      "Run: 03, Epoch: 69, Loss: 0.3806, Train: 90.71%, Valid: 79.60% Test: 81.90%\n",
      "Run: 03, Epoch: 70, Loss: 0.3753, Train: 91.43%, Valid: 79.40% Test: 82.10%\n",
      "Run: 03, Epoch: 71, Loss: 0.5029, Train: 90.00%, Valid: 81.40% Test: 82.80%\n",
      "Run: 03, Epoch: 72, Loss: 0.3935, Train: 88.57%, Valid: 81.40% Test: 81.60%\n",
      "Run: 03, Epoch: 73, Loss: 0.4117, Train: 89.29%, Valid: 81.00% Test: 80.70%\n",
      "Run: 03, Epoch: 74, Loss: 0.3734, Train: 87.86%, Valid: 80.80% Test: 80.70%\n",
      "Run: 03, Epoch: 75, Loss: 0.4723, Train: 93.57%, Valid: 82.60% Test: 83.10%\n",
      "Run: 03, Epoch: 76, Loss: 0.5016, Train: 93.57%, Valid: 82.60% Test: 83.00%\n",
      "Run: 03, Epoch: 77, Loss: 0.3962, Train: 92.86%, Valid: 83.60% Test: 82.80%\n",
      "Run: 03, Epoch: 78, Loss: 0.3909, Train: 90.00%, Valid: 81.80% Test: 81.90%\n",
      "Run: 03, Epoch: 79, Loss: 0.3606, Train: 90.00%, Valid: 82.00% Test: 81.90%\n",
      "Run: 03, Epoch: 80, Loss: 0.4362, Train: 89.29%, Valid: 81.80% Test: 82.80%\n",
      "Run: 03, Epoch: 81, Loss: 0.3645, Train: 90.71%, Valid: 82.40% Test: 83.60%\n",
      "Run: 03, Epoch: 82, Loss: 0.3861, Train: 90.00%, Valid: 81.00% Test: 82.90%\n",
      "Run: 03, Epoch: 83, Loss: 0.3664, Train: 86.43%, Valid: 79.80% Test: 79.70%\n",
      "Run: 03, Epoch: 84, Loss: 0.3068, Train: 87.86%, Valid: 75.00% Test: 76.80%\n",
      "Run: 03, Epoch: 85, Loss: 0.4189, Train: 87.14%, Valid: 73.00% Test: 75.30%\n",
      "Run: 03, Epoch: 86, Loss: 0.3474, Train: 89.29%, Valid: 78.80% Test: 78.50%\n",
      "Run: 03, Epoch: 87, Loss: 0.3454, Train: 92.14%, Valid: 84.20% Test: 84.00%\n",
      "Run: 03, Epoch: 88, Loss: 0.3194, Train: 90.00%, Valid: 80.60% Test: 83.60%\n",
      "Run: 03, Epoch: 89, Loss: 0.3506, Train: 87.86%, Valid: 78.80% Test: 80.30%\n",
      "Run: 03, Epoch: 90, Loss: 0.4055, Train: 87.86%, Valid: 79.00% Test: 81.90%\n",
      "Run: 03, Epoch: 91, Loss: 0.3681, Train: 92.14%, Valid: 81.80% Test: 83.90%\n",
      "Run: 03, Epoch: 92, Loss: 0.3313, Train: 94.29%, Valid: 82.40% Test: 83.70%\n",
      "Run: 03, Epoch: 93, Loss: 0.3596, Train: 92.14%, Valid: 80.60% Test: 80.40%\n",
      "Run: 03, Epoch: 94, Loss: 0.3423, Train: 90.00%, Valid: 79.60% Test: 79.60%\n",
      "Run: 03, Epoch: 95, Loss: 0.3240, Train: 90.00%, Valid: 78.80% Test: 78.60%\n",
      "Run: 03, Epoch: 96, Loss: 0.3487, Train: 88.57%, Valid: 78.60% Test: 80.70%\n",
      "Run: 03, Epoch: 97, Loss: 0.3181, Train: 85.71%, Valid: 78.20% Test: 80.00%\n",
      "Run: 03, Epoch: 98, Loss: 0.3513, Train: 91.43%, Valid: 81.00% Test: 82.10%\n",
      "Run: 03, Epoch: 99, Loss: 0.3312, Train: 91.43%, Valid: 81.60% Test: 82.60%\n",
      "Run: 03, Epoch: 100, Loss: 0.2863, Train: 90.71%, Valid: 80.00% Test: 82.90%\n",
      "Run: 03, Epoch: 101, Loss: 0.3559, Train: 90.71%, Valid: 80.40% Test: 83.10%\n",
      "Run: 03, Epoch: 102, Loss: 0.2912, Train: 86.43%, Valid: 79.60% Test: 81.70%\n",
      "Run: 03, Epoch: 103, Loss: 0.3010, Train: 90.71%, Valid: 82.60% Test: 83.70%\n",
      "Run: 03, Epoch: 104, Loss: 0.2892, Train: 93.57%, Valid: 83.80% Test: 85.20%\n",
      "Run: 03, Epoch: 105, Loss: 0.3560, Train: 91.43%, Valid: 82.60% Test: 84.10%\n",
      "Run: 03, Epoch: 106, Loss: 0.3505, Train: 88.57%, Valid: 79.80% Test: 80.20%\n",
      "Run: 03, Epoch: 107, Loss: 0.4147, Train: 90.00%, Valid: 82.00% Test: 81.10%\n",
      "Run: 03, Epoch: 108, Loss: 0.3713, Train: 93.57%, Valid: 80.80% Test: 83.00%\n",
      "Run: 03, Epoch: 109, Loss: 0.3665, Train: 94.29%, Valid: 81.00% Test: 83.50%\n",
      "Run: 03, Epoch: 110, Loss: 0.2920, Train: 96.43%, Valid: 82.20% Test: 83.70%\n",
      "Run: 03, Epoch: 111, Loss: 0.2451, Train: 94.29%, Valid: 80.40% Test: 83.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 112, Loss: 0.3136, Train: 91.43%, Valid: 79.80% Test: 83.50%\n",
      "Run: 03, Epoch: 113, Loss: 0.3011, Train: 87.14%, Valid: 79.60% Test: 81.50%\n",
      "Run: 03, Epoch: 114, Loss: 0.3364, Train: 87.14%, Valid: 79.60% Test: 81.50%\n",
      "Run: 03, Epoch: 115, Loss: 0.2860, Train: 90.00%, Valid: 80.00% Test: 82.90%\n",
      "Run: 03, Epoch: 116, Loss: 0.2738, Train: 89.29%, Valid: 82.00% Test: 83.00%\n",
      "Run: 03, Epoch: 117, Loss: 0.3027, Train: 88.57%, Valid: 80.60% Test: 81.20%\n",
      "Run: 03, Epoch: 118, Loss: 0.3027, Train: 91.43%, Valid: 80.60% Test: 80.30%\n",
      "Run: 03, Epoch: 119, Loss: 0.2702, Train: 90.71%, Valid: 81.00% Test: 79.80%\n",
      "Run: 03, Epoch: 120, Loss: 0.2964, Train: 90.71%, Valid: 79.40% Test: 79.00%\n",
      "Run: 03, Epoch: 121, Loss: 0.2664, Train: 91.43%, Valid: 82.00% Test: 81.80%\n",
      "Run: 03, Epoch: 122, Loss: 0.2916, Train: 91.43%, Valid: 82.40% Test: 83.10%\n",
      "Run: 03, Epoch: 123, Loss: 0.3141, Train: 89.29%, Valid: 82.00% Test: 82.00%\n",
      "Run: 03, Epoch: 124, Loss: 0.3065, Train: 91.43%, Valid: 81.40% Test: 84.50%\n",
      "Run: 03, Epoch: 125, Loss: 0.2760, Train: 92.86%, Valid: 83.00% Test: 83.20%\n",
      "Run: 03, Epoch: 126, Loss: 0.2979, Train: 90.00%, Valid: 79.00% Test: 81.90%\n",
      "Run: 03, Epoch: 127, Loss: 0.3680, Train: 86.43%, Valid: 77.20% Test: 80.00%\n",
      "Run: 03, Epoch: 128, Loss: 0.2331, Train: 85.00%, Valid: 76.20% Test: 77.60%\n",
      "Run: 03, Epoch: 129, Loss: 0.2514, Train: 87.86%, Valid: 78.60% Test: 79.90%\n",
      "Run: 03, Epoch: 130, Loss: 0.2712, Train: 90.71%, Valid: 79.80% Test: 82.50%\n",
      "Run: 03, Epoch: 131, Loss: 0.3023, Train: 94.29%, Valid: 81.60% Test: 81.30%\n",
      "Run: 03, Epoch: 132, Loss: 0.2792, Train: 90.71%, Valid: 77.20% Test: 76.90%\n",
      "Run: 03, Epoch: 133, Loss: 0.2552, Train: 85.00%, Valid: 74.60% Test: 75.60%\n",
      "Run: 03, Epoch: 134, Loss: 0.2669, Train: 85.71%, Valid: 78.20% Test: 78.10%\n",
      "Run: 03, Epoch: 135, Loss: 0.3127, Train: 90.00%, Valid: 81.60% Test: 82.00%\n",
      "Run: 03, Epoch: 136, Loss: 0.2548, Train: 91.43%, Valid: 81.80% Test: 83.70%\n",
      "Run: 03, Epoch: 137, Loss: 0.2595, Train: 93.57%, Valid: 83.20% Test: 84.20%\n",
      "Run: 03, Epoch: 138, Loss: 0.2551, Train: 95.71%, Valid: 82.80% Test: 84.70%\n",
      "Run: 03, Epoch: 139, Loss: 0.3035, Train: 93.57%, Valid: 82.00% Test: 84.60%\n",
      "Run: 03, Epoch: 140, Loss: 0.2817, Train: 92.86%, Valid: 79.80% Test: 83.80%\n",
      "Run: 03, Epoch: 141, Loss: 0.2063, Train: 91.43%, Valid: 78.80% Test: 82.30%\n",
      "Run: 03, Epoch: 142, Loss: 0.2614, Train: 92.14%, Valid: 80.00% Test: 82.60%\n",
      "Run: 03, Epoch: 143, Loss: 0.2172, Train: 97.14%, Valid: 82.60% Test: 82.80%\n",
      "Run: 03, Epoch: 144, Loss: 0.2680, Train: 92.14%, Valid: 81.80% Test: 82.30%\n",
      "Run: 03, Epoch: 145, Loss: 0.2301, Train: 87.86%, Valid: 81.20% Test: 81.80%\n",
      "Run: 03, Epoch: 146, Loss: 0.2509, Train: 90.00%, Valid: 81.80% Test: 82.00%\n",
      "Run: 03, Epoch: 147, Loss: 0.3014, Train: 91.43%, Valid: 81.20% Test: 82.70%\n",
      "Run: 03, Epoch: 148, Loss: 0.2840, Train: 95.00%, Valid: 81.40% Test: 84.20%\n",
      "Run: 03, Epoch: 149, Loss: 0.2919, Train: 92.14%, Valid: 81.00% Test: 84.50%\n",
      "Run: 03, Epoch: 150, Loss: 0.2645, Train: 90.71%, Valid: 80.00% Test: 82.90%\n",
      "Run: 03, Epoch: 151, Loss: 0.2727, Train: 94.29%, Valid: 80.80% Test: 83.70%\n",
      "Run: 03, Epoch: 152, Loss: 0.2101, Train: 92.86%, Valid: 80.00% Test: 82.70%\n",
      "Run: 03, Epoch: 153, Loss: 0.2322, Train: 90.00%, Valid: 80.40% Test: 81.70%\n",
      "Run: 03, Epoch: 154, Loss: 0.3138, Train: 92.14%, Valid: 82.80% Test: 83.00%\n",
      "Run: 03, Epoch: 155, Loss: 0.2974, Train: 90.71%, Valid: 80.60% Test: 80.60%\n",
      "Run: 03, Epoch: 156, Loss: 0.2523, Train: 90.71%, Valid: 79.20% Test: 81.10%\n",
      "Run: 03, Epoch: 157, Loss: 0.2235, Train: 94.29%, Valid: 82.20% Test: 83.60%\n",
      "Run: 03, Epoch: 158, Loss: 0.2320, Train: 93.57%, Valid: 81.20% Test: 82.30%\n",
      "Run: 03, Epoch: 159, Loss: 0.2090, Train: 89.29%, Valid: 77.20% Test: 78.10%\n",
      "Run: 03, Epoch: 160, Loss: 0.2817, Train: 85.71%, Valid: 75.00% Test: 76.20%\n",
      "Run: 03, Epoch: 161, Loss: 0.1784, Train: 87.14%, Valid: 73.40% Test: 74.90%\n",
      "Run: 03, Epoch: 162, Loss: 0.2344, Train: 91.43%, Valid: 78.60% Test: 78.80%\n",
      "Run: 03, Epoch: 163, Loss: 0.2020, Train: 95.71%, Valid: 83.40% Test: 83.40%\n",
      "Run: 03, Epoch: 164, Loss: 0.2146, Train: 95.00%, Valid: 84.60% Test: 85.40%\n",
      "Run: 03, Epoch: 165, Loss: 0.2289, Train: 95.71%, Valid: 85.20% Test: 85.60%\n",
      "Run: 03, Epoch: 166, Loss: 0.2713, Train: 94.29%, Valid: 85.40% Test: 84.80%\n",
      "Run: 03, Epoch: 167, Loss: 0.2380, Train: 94.29%, Valid: 84.40% Test: 84.90%\n",
      "Run: 03, Epoch: 168, Loss: 0.1800, Train: 92.86%, Valid: 83.20% Test: 85.20%\n",
      "Run: 03, Epoch: 169, Loss: 0.2591, Train: 91.43%, Valid: 79.80% Test: 83.70%\n",
      "Run: 03, Epoch: 170, Loss: 0.2358, Train: 94.29%, Valid: 80.60% Test: 84.00%\n",
      "Run: 03, Epoch: 171, Loss: 0.2655, Train: 94.29%, Valid: 79.80% Test: 82.50%\n",
      "Run: 03, Epoch: 172, Loss: 0.2886, Train: 98.57%, Valid: 82.00% Test: 84.10%\n",
      "Run: 03, Epoch: 173, Loss: 0.2623, Train: 96.43%, Valid: 83.80% Test: 83.90%\n",
      "Run: 03, Epoch: 174, Loss: 0.1859, Train: 95.71%, Valid: 83.20% Test: 83.60%\n",
      "Run: 03, Epoch: 175, Loss: 0.2435, Train: 94.29%, Valid: 82.40% Test: 83.30%\n",
      "Run: 03, Epoch: 176, Loss: 0.2451, Train: 93.57%, Valid: 82.20% Test: 83.80%\n",
      "Run: 03, Epoch: 177, Loss: 0.2877, Train: 95.71%, Valid: 83.60% Test: 83.90%\n",
      "Run: 03, Epoch: 178, Loss: 0.2228, Train: 93.57%, Valid: 83.20% Test: 84.50%\n",
      "Run: 03, Epoch: 179, Loss: 0.2286, Train: 92.14%, Valid: 82.20% Test: 83.60%\n",
      "Run: 03, Epoch: 180, Loss: 0.1865, Train: 92.14%, Valid: 80.20% Test: 83.10%\n",
      "Run: 03, Epoch: 181, Loss: 0.2379, Train: 91.43%, Valid: 81.20% Test: 83.10%\n",
      "Run: 03, Epoch: 182, Loss: 0.2155, Train: 90.71%, Valid: 83.60% Test: 83.40%\n",
      "Run: 03, Epoch: 183, Loss: 0.2127, Train: 94.29%, Valid: 83.40% Test: 84.10%\n",
      "Run: 03, Epoch: 184, Loss: 0.1885, Train: 94.29%, Valid: 83.40% Test: 83.60%\n",
      "Run: 03, Epoch: 185, Loss: 0.2272, Train: 95.00%, Valid: 82.60% Test: 83.70%\n",
      "Run: 03, Epoch: 186, Loss: 0.2289, Train: 96.43%, Valid: 82.60% Test: 83.30%\n",
      "Run: 03, Epoch: 187, Loss: 0.2620, Train: 94.29%, Valid: 81.40% Test: 84.10%\n",
      "Run: 03, Epoch: 188, Loss: 0.2064, Train: 86.43%, Valid: 77.00% Test: 78.90%\n",
      "Run: 03, Epoch: 189, Loss: 0.2288, Train: 80.71%, Valid: 75.80% Test: 75.40%\n",
      "Run: 03, Epoch: 190, Loss: 0.2222, Train: 87.14%, Valid: 78.00% Test: 80.60%\n",
      "Run: 03, Epoch: 191, Loss: 0.2694, Train: 95.71%, Valid: 83.00% Test: 83.60%\n",
      "Run: 03, Epoch: 192, Loss: 0.2456, Train: 94.29%, Valid: 80.60% Test: 81.70%\n",
      "Run: 03, Epoch: 193, Loss: 0.2070, Train: 84.29%, Valid: 73.80% Test: 75.00%\n",
      "Run: 03, Epoch: 194, Loss: 0.2356, Train: 83.57%, Valid: 73.00% Test: 73.40%\n",
      "Run: 03, Epoch: 195, Loss: 0.2519, Train: 89.29%, Valid: 76.80% Test: 77.90%\n",
      "Run: 03, Epoch: 196, Loss: 0.2002, Train: 91.43%, Valid: 80.60% Test: 82.80%\n",
      "Run: 03, Epoch: 197, Loss: 0.2354, Train: 95.71%, Valid: 83.00% Test: 84.70%\n",
      "Run: 03, Epoch: 198, Loss: 0.2427, Train: 94.29%, Valid: 84.20% Test: 85.30%\n",
      "Run: 03, Epoch: 199, Loss: 0.2763, Train: 92.14%, Valid: 83.00% Test: 83.10%\n",
      "Run: 03, Epoch: 200, Loss: 0.1931, Train: 90.00%, Valid: 81.80% Test: 81.70%\n",
      "Run 03:\n",
      "Highest Train: 98.57\n",
      "Highest Valid: 85.40\n",
      "  Final Train: 90.71\n",
      "   Final Test: 83.80\n",
      "Run: 04, Epoch: 01, Loss: 2.3161, Train: 10.00%, Valid: 20.80% Test: 21.80%\n",
      "Run: 04, Epoch: 02, Loss: 2.2241, Train: 7.86%, Valid: 3.20% Test: 5.60%\n",
      "Run: 04, Epoch: 03, Loss: 2.0646, Train: 13.57%, Valid: 7.00% Test: 9.20%\n",
      "Run: 04, Epoch: 04, Loss: 2.0797, Train: 14.29%, Valid: 7.20% Test: 9.10%\n",
      "Run: 04, Epoch: 05, Loss: 2.0068, Train: 15.00%, Valid: 7.60% Test: 9.30%\n",
      "Run: 04, Epoch: 06, Loss: 1.8854, Train: 15.00%, Valid: 8.60% Test: 11.00%\n",
      "Run: 04, Epoch: 07, Loss: 1.9119, Train: 25.71%, Valid: 19.20% Test: 20.60%\n",
      "Run: 04, Epoch: 08, Loss: 1.8242, Train: 27.86%, Valid: 22.60% Test: 23.10%\n",
      "Run: 04, Epoch: 09, Loss: 1.7281, Train: 28.57%, Valid: 23.20% Test: 23.60%\n",
      "Run: 04, Epoch: 10, Loss: 1.7298, Train: 27.86%, Valid: 25.80% Test: 24.60%\n",
      "Run: 04, Epoch: 11, Loss: 1.6709, Train: 29.29%, Valid: 29.80% Test: 28.00%\n",
      "Run: 04, Epoch: 12, Loss: 1.5908, Train: 32.86%, Valid: 31.00% Test: 30.40%\n",
      "Run: 04, Epoch: 13, Loss: 1.5498, Train: 28.57%, Valid: 29.00% Test: 27.30%\n",
      "Run: 04, Epoch: 14, Loss: 1.5636, Train: 28.57%, Valid: 27.20% Test: 25.30%\n",
      "Run: 04, Epoch: 15, Loss: 1.5970, Train: 32.14%, Valid: 29.60% Test: 28.60%\n",
      "Run: 04, Epoch: 16, Loss: 1.5323, Train: 44.29%, Valid: 39.60% Test: 37.20%\n",
      "Run: 04, Epoch: 17, Loss: 1.5124, Train: 47.86%, Valid: 44.00% Test: 41.80%\n",
      "Run: 04, Epoch: 18, Loss: 1.4490, Train: 47.14%, Valid: 42.60% Test: 41.20%\n",
      "Run: 04, Epoch: 19, Loss: 1.3841, Train: 50.00%, Valid: 43.60% Test: 42.70%\n",
      "Run: 04, Epoch: 20, Loss: 1.3609, Train: 51.43%, Valid: 43.20% Test: 42.70%\n",
      "Run: 04, Epoch: 21, Loss: 1.3431, Train: 52.14%, Valid: 45.40% Test: 45.80%\n",
      "Run: 04, Epoch: 22, Loss: 1.3167, Train: 55.71%, Valid: 50.80% Test: 50.00%\n",
      "Run: 04, Epoch: 23, Loss: 1.3130, Train: 60.00%, Valid: 53.00% Test: 51.70%\n",
      "Run: 04, Epoch: 24, Loss: 1.2645, Train: 62.86%, Valid: 50.60% Test: 50.90%\n",
      "Run: 04, Epoch: 25, Loss: 1.2311, Train: 57.86%, Valid: 48.40% Test: 46.80%\n",
      "Run: 04, Epoch: 26, Loss: 1.1054, Train: 47.86%, Valid: 43.40% Test: 43.00%\n",
      "Run: 04, Epoch: 27, Loss: 1.1704, Train: 45.71%, Valid: 42.80% Test: 41.10%\n",
      "Run: 04, Epoch: 28, Loss: 1.1907, Train: 47.86%, Valid: 43.40% Test: 41.60%\n",
      "Run: 04, Epoch: 29, Loss: 1.1441, Train: 51.43%, Valid: 45.20% Test: 43.20%\n",
      "Run: 04, Epoch: 30, Loss: 1.1208, Train: 57.14%, Valid: 48.60% Test: 46.60%\n",
      "Run: 04, Epoch: 31, Loss: 1.0628, Train: 65.71%, Valid: 58.60% Test: 56.30%\n",
      "Run: 04, Epoch: 32, Loss: 1.0175, Train: 70.00%, Valid: 69.40% Test: 66.20%\n",
      "Run: 04, Epoch: 33, Loss: 0.9897, Train: 63.57%, Valid: 69.40% Test: 68.50%\n",
      "Run: 04, Epoch: 34, Loss: 0.9863, Train: 57.14%, Valid: 62.80% Test: 62.50%\n",
      "Run: 04, Epoch: 35, Loss: 0.9412, Train: 51.43%, Valid: 61.20% Test: 60.30%\n",
      "Run: 04, Epoch: 36, Loss: 0.9635, Train: 61.43%, Valid: 68.20% Test: 66.30%\n",
      "Run: 04, Epoch: 37, Loss: 0.9270, Train: 71.43%, Valid: 76.60% Test: 75.90%\n",
      "Run: 04, Epoch: 38, Loss: 0.8694, Train: 77.14%, Valid: 75.00% Test: 74.60%\n",
      "Run: 04, Epoch: 39, Loss: 0.8969, Train: 75.71%, Valid: 69.20% Test: 67.30%\n",
      "Run: 04, Epoch: 40, Loss: 0.8328, Train: 77.14%, Valid: 68.20% Test: 66.10%\n",
      "Run: 04, Epoch: 41, Loss: 0.8328, Train: 77.86%, Valid: 68.40% Test: 67.90%\n",
      "Run: 04, Epoch: 42, Loss: 0.7840, Train: 70.00%, Valid: 65.80% Test: 66.80%\n",
      "Run: 04, Epoch: 43, Loss: 0.7116, Train: 67.86%, Valid: 60.40% Test: 61.60%\n",
      "Run: 04, Epoch: 44, Loss: 0.8511, Train: 67.14%, Valid: 61.00% Test: 62.00%\n",
      "Run: 04, Epoch: 45, Loss: 0.8049, Train: 70.00%, Valid: 64.20% Test: 63.70%\n",
      "Run: 04, Epoch: 46, Loss: 0.7319, Train: 78.57%, Valid: 66.20% Test: 63.80%\n",
      "Run: 04, Epoch: 47, Loss: 0.7640, Train: 79.29%, Valid: 66.80% Test: 66.20%\n",
      "Run: 04, Epoch: 48, Loss: 0.7121, Train: 79.29%, Valid: 70.20% Test: 70.50%\n",
      "Run: 04, Epoch: 49, Loss: 0.7123, Train: 80.00%, Valid: 75.00% Test: 75.30%\n",
      "Run: 04, Epoch: 50, Loss: 0.6479, Train: 82.86%, Valid: 77.40% Test: 77.60%\n",
      "Run: 04, Epoch: 51, Loss: 0.7078, Train: 83.57%, Valid: 76.40% Test: 77.70%\n",
      "Run: 04, Epoch: 52, Loss: 0.6230, Train: 84.29%, Valid: 79.40% Test: 79.90%\n",
      "Run: 04, Epoch: 53, Loss: 0.7050, Train: 84.29%, Valid: 82.00% Test: 81.70%\n",
      "Run: 04, Epoch: 54, Loss: 0.6566, Train: 90.00%, Valid: 82.00% Test: 81.90%\n",
      "Run: 04, Epoch: 55, Loss: 0.6779, Train: 87.86%, Valid: 82.00% Test: 81.10%\n",
      "Run: 04, Epoch: 56, Loss: 0.5513, Train: 89.29%, Valid: 75.40% Test: 76.80%\n",
      "Run: 04, Epoch: 57, Loss: 0.5592, Train: 87.86%, Valid: 70.80% Test: 71.80%\n",
      "Run: 04, Epoch: 58, Loss: 0.5642, Train: 85.71%, Valid: 70.00% Test: 68.90%\n",
      "Run: 04, Epoch: 59, Loss: 0.6532, Train: 88.57%, Valid: 73.20% Test: 73.30%\n",
      "Run: 04, Epoch: 60, Loss: 0.5098, Train: 84.29%, Valid: 75.20% Test: 73.40%\n",
      "Run: 04, Epoch: 61, Loss: 0.5785, Train: 79.29%, Valid: 73.80% Test: 72.90%\n",
      "Run: 04, Epoch: 62, Loss: 0.6032, Train: 82.86%, Valid: 76.20% Test: 76.70%\n",
      "Run: 04, Epoch: 63, Loss: 0.4510, Train: 89.29%, Valid: 78.60% Test: 81.90%\n",
      "Run: 04, Epoch: 64, Loss: 0.5402, Train: 91.43%, Valid: 81.60% Test: 84.00%\n",
      "Run: 04, Epoch: 65, Loss: 0.4160, Train: 86.43%, Valid: 82.80% Test: 83.00%\n",
      "Run: 04, Epoch: 66, Loss: 0.5835, Train: 87.14%, Valid: 82.20% Test: 81.70%\n",
      "Run: 04, Epoch: 67, Loss: 0.4954, Train: 85.71%, Valid: 82.80% Test: 81.20%\n",
      "Run: 04, Epoch: 68, Loss: 0.5122, Train: 87.14%, Valid: 82.60% Test: 82.70%\n",
      "Run: 04, Epoch: 69, Loss: 0.4821, Train: 89.29%, Valid: 82.00% Test: 82.30%\n",
      "Run: 04, Epoch: 70, Loss: 0.4830, Train: 87.86%, Valid: 81.60% Test: 82.80%\n",
      "Run: 04, Epoch: 71, Loss: 0.5135, Train: 90.00%, Valid: 81.40% Test: 82.70%\n",
      "Run: 04, Epoch: 72, Loss: 0.4536, Train: 90.71%, Valid: 82.00% Test: 83.20%\n",
      "Run: 04, Epoch: 73, Loss: 0.4531, Train: 89.29%, Valid: 81.20% Test: 80.50%\n",
      "Run: 04, Epoch: 74, Loss: 0.4635, Train: 85.00%, Valid: 74.80% Test: 74.00%\n",
      "Run: 04, Epoch: 75, Loss: 0.5390, Train: 84.29%, Valid: 69.80% Test: 69.20%\n",
      "Run: 04, Epoch: 76, Loss: 0.4694, Train: 85.00%, Valid: 70.40% Test: 70.60%\n",
      "Run: 04, Epoch: 77, Loss: 0.4520, Train: 90.00%, Valid: 74.60% Test: 74.90%\n",
      "Run: 04, Epoch: 78, Loss: 0.4747, Train: 90.71%, Valid: 76.00% Test: 77.80%\n",
      "Run: 04, Epoch: 79, Loss: 0.5026, Train: 92.14%, Valid: 79.40% Test: 80.00%\n",
      "Run: 04, Epoch: 80, Loss: 0.3830, Train: 90.00%, Valid: 78.80% Test: 80.10%\n",
      "Run: 04, Epoch: 81, Loss: 0.4457, Train: 87.86%, Valid: 79.60% Test: 82.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 82, Loss: 0.4972, Train: 84.29%, Valid: 78.80% Test: 82.90%\n",
      "Run: 04, Epoch: 83, Loss: 0.4075, Train: 87.86%, Valid: 80.80% Test: 83.20%\n",
      "Run: 04, Epoch: 84, Loss: 0.4914, Train: 90.00%, Valid: 84.20% Test: 84.70%\n",
      "Run: 04, Epoch: 85, Loss: 0.3942, Train: 90.71%, Valid: 84.60% Test: 85.90%\n",
      "Run: 04, Epoch: 86, Loss: 0.4235, Train: 87.86%, Valid: 84.00% Test: 83.70%\n",
      "Run: 04, Epoch: 87, Loss: 0.3967, Train: 81.43%, Valid: 76.60% Test: 75.00%\n",
      "Run: 04, Epoch: 88, Loss: 0.4154, Train: 82.86%, Valid: 76.00% Test: 74.30%\n",
      "Run: 04, Epoch: 89, Loss: 0.4441, Train: 91.43%, Valid: 79.20% Test: 79.40%\n",
      "Run: 04, Epoch: 90, Loss: 0.4236, Train: 93.57%, Valid: 80.20% Test: 82.90%\n",
      "Run: 04, Epoch: 91, Loss: 0.4470, Train: 90.71%, Valid: 80.40% Test: 82.10%\n",
      "Run: 04, Epoch: 92, Loss: 0.3631, Train: 89.29%, Valid: 79.80% Test: 81.70%\n",
      "Run: 04, Epoch: 93, Loss: 0.4304, Train: 90.71%, Valid: 79.80% Test: 82.80%\n",
      "Run: 04, Epoch: 94, Loss: 0.4335, Train: 94.29%, Valid: 82.40% Test: 84.90%\n",
      "Run: 04, Epoch: 95, Loss: 0.3665, Train: 93.57%, Valid: 83.40% Test: 85.10%\n",
      "Run: 04, Epoch: 96, Loss: 0.4053, Train: 93.57%, Valid: 82.60% Test: 84.60%\n",
      "Run: 04, Epoch: 97, Loss: 0.4623, Train: 95.00%, Valid: 83.60% Test: 85.60%\n",
      "Run: 04, Epoch: 98, Loss: 0.4066, Train: 94.29%, Valid: 83.60% Test: 85.60%\n",
      "Run: 04, Epoch: 99, Loss: 0.3815, Train: 95.71%, Valid: 83.40% Test: 86.80%\n",
      "Run: 04, Epoch: 100, Loss: 0.3440, Train: 95.00%, Valid: 84.20% Test: 86.20%\n",
      "Run: 04, Epoch: 101, Loss: 0.3240, Train: 94.29%, Valid: 84.20% Test: 86.30%\n",
      "Run: 04, Epoch: 102, Loss: 0.3257, Train: 94.29%, Valid: 81.80% Test: 83.50%\n",
      "Run: 04, Epoch: 103, Loss: 0.3588, Train: 91.43%, Valid: 78.40% Test: 78.50%\n",
      "Run: 04, Epoch: 104, Loss: 0.4611, Train: 90.00%, Valid: 77.80% Test: 76.00%\n",
      "Run: 04, Epoch: 105, Loss: 0.3753, Train: 91.43%, Valid: 79.80% Test: 80.10%\n",
      "Run: 04, Epoch: 106, Loss: 0.3735, Train: 90.71%, Valid: 83.80% Test: 82.60%\n",
      "Run: 04, Epoch: 107, Loss: 0.3338, Train: 91.43%, Valid: 84.00% Test: 83.10%\n",
      "Run: 04, Epoch: 108, Loss: 0.3236, Train: 90.00%, Valid: 83.00% Test: 84.30%\n",
      "Run: 04, Epoch: 109, Loss: 0.3345, Train: 90.71%, Valid: 83.00% Test: 84.70%\n",
      "Run: 04, Epoch: 110, Loss: 0.3322, Train: 93.57%, Valid: 84.40% Test: 85.90%\n",
      "Run: 04, Epoch: 111, Loss: 0.3822, Train: 95.00%, Valid: 84.20% Test: 86.70%\n",
      "Run: 04, Epoch: 112, Loss: 0.4076, Train: 95.00%, Valid: 83.00% Test: 85.30%\n",
      "Run: 04, Epoch: 113, Loss: 0.3824, Train: 94.29%, Valid: 81.60% Test: 84.20%\n",
      "Run: 04, Epoch: 114, Loss: 0.3865, Train: 92.86%, Valid: 81.00% Test: 83.20%\n",
      "Run: 04, Epoch: 115, Loss: 0.3861, Train: 92.86%, Valid: 81.20% Test: 83.40%\n",
      "Run: 04, Epoch: 116, Loss: 0.3898, Train: 92.86%, Valid: 83.60% Test: 83.90%\n",
      "Run: 04, Epoch: 117, Loss: 0.3401, Train: 92.86%, Valid: 83.00% Test: 84.20%\n",
      "Run: 04, Epoch: 118, Loss: 0.3599, Train: 86.43%, Valid: 81.00% Test: 84.00%\n",
      "Run: 04, Epoch: 119, Loss: 0.3290, Train: 87.86%, Valid: 79.80% Test: 83.40%\n",
      "Run: 04, Epoch: 120, Loss: 0.3461, Train: 95.00%, Valid: 81.40% Test: 84.20%\n",
      "Run: 04, Epoch: 121, Loss: 0.2866, Train: 95.71%, Valid: 82.60% Test: 85.40%\n",
      "Run: 04, Epoch: 122, Loss: 0.3708, Train: 94.29%, Valid: 81.20% Test: 85.50%\n",
      "Run: 04, Epoch: 123, Loss: 0.3452, Train: 92.86%, Valid: 81.80% Test: 84.90%\n",
      "Run: 04, Epoch: 124, Loss: 0.3530, Train: 91.43%, Valid: 82.40% Test: 84.40%\n",
      "Run: 04, Epoch: 125, Loss: 0.2915, Train: 92.86%, Valid: 82.40% Test: 84.40%\n",
      "Run: 04, Epoch: 126, Loss: 0.3045, Train: 92.86%, Valid: 82.60% Test: 84.30%\n",
      "Run: 04, Epoch: 127, Loss: 0.3279, Train: 95.00%, Valid: 84.00% Test: 84.70%\n",
      "Run: 04, Epoch: 128, Loss: 0.3248, Train: 97.14%, Valid: 83.40% Test: 85.80%\n",
      "Run: 04, Epoch: 129, Loss: 0.2991, Train: 92.86%, Valid: 84.00% Test: 85.50%\n",
      "Run: 04, Epoch: 130, Loss: 0.3059, Train: 92.14%, Valid: 82.60% Test: 84.10%\n",
      "Run: 04, Epoch: 131, Loss: 0.3815, Train: 95.00%, Valid: 85.20% Test: 85.60%\n",
      "Run: 04, Epoch: 132, Loss: 0.3142, Train: 93.57%, Valid: 84.40% Test: 84.40%\n",
      "Run: 04, Epoch: 133, Loss: 0.2980, Train: 91.43%, Valid: 82.20% Test: 82.90%\n",
      "Run: 04, Epoch: 134, Loss: 0.3242, Train: 92.14%, Valid: 82.20% Test: 83.10%\n",
      "Run: 04, Epoch: 135, Loss: 0.3210, Train: 93.57%, Valid: 81.40% Test: 84.10%\n",
      "Run: 04, Epoch: 136, Loss: 0.3115, Train: 95.00%, Valid: 81.40% Test: 83.30%\n",
      "Run: 04, Epoch: 137, Loss: 0.2854, Train: 92.86%, Valid: 79.80% Test: 80.00%\n",
      "Run: 04, Epoch: 138, Loss: 0.2749, Train: 88.57%, Valid: 77.40% Test: 77.30%\n",
      "Run: 04, Epoch: 139, Loss: 0.3340, Train: 92.14%, Valid: 81.20% Test: 82.10%\n",
      "Run: 04, Epoch: 140, Loss: 0.3042, Train: 96.43%, Valid: 83.20% Test: 85.90%\n",
      "Run: 04, Epoch: 141, Loss: 0.3146, Train: 95.00%, Valid: 83.60% Test: 86.40%\n",
      "Run: 04, Epoch: 142, Loss: 0.3169, Train: 94.29%, Valid: 82.80% Test: 85.40%\n",
      "Run: 04, Epoch: 143, Loss: 0.3671, Train: 93.57%, Valid: 82.00% Test: 84.20%\n",
      "Run: 04, Epoch: 144, Loss: 0.2413, Train: 93.57%, Valid: 82.40% Test: 84.50%\n",
      "Run: 04, Epoch: 145, Loss: 0.2628, Train: 95.00%, Valid: 82.80% Test: 84.40%\n",
      "Run: 04, Epoch: 146, Loss: 0.3039, Train: 97.14%, Valid: 82.00% Test: 84.70%\n",
      "Run: 04, Epoch: 147, Loss: 0.2682, Train: 97.14%, Valid: 82.80% Test: 85.00%\n",
      "Run: 04, Epoch: 148, Loss: 0.2540, Train: 97.14%, Valid: 83.80% Test: 85.30%\n",
      "Run: 04, Epoch: 149, Loss: 0.2867, Train: 95.00%, Valid: 84.00% Test: 85.10%\n",
      "Run: 04, Epoch: 150, Loss: 0.2947, Train: 95.00%, Valid: 84.00% Test: 85.70%\n",
      "Run: 04, Epoch: 151, Loss: 0.2458, Train: 95.00%, Valid: 84.00% Test: 84.70%\n",
      "Run: 04, Epoch: 152, Loss: 0.2789, Train: 95.71%, Valid: 84.20% Test: 85.50%\n",
      "Run: 04, Epoch: 153, Loss: 0.3386, Train: 95.00%, Valid: 84.80% Test: 85.60%\n",
      "Run: 04, Epoch: 154, Loss: 0.2879, Train: 93.57%, Valid: 83.00% Test: 85.70%\n",
      "Run: 04, Epoch: 155, Loss: 0.2460, Train: 93.57%, Valid: 81.60% Test: 84.70%\n",
      "Run: 04, Epoch: 156, Loss: 0.3067, Train: 94.29%, Valid: 84.60% Test: 86.00%\n",
      "Run: 04, Epoch: 157, Loss: 0.2668, Train: 92.86%, Valid: 84.20% Test: 84.80%\n",
      "Run: 04, Epoch: 158, Loss: 0.2921, Train: 95.00%, Valid: 82.20% Test: 82.80%\n",
      "Run: 04, Epoch: 159, Loss: 0.3491, Train: 90.71%, Valid: 77.60% Test: 78.60%\n",
      "Run: 04, Epoch: 160, Loss: 0.3307, Train: 91.43%, Valid: 77.80% Test: 77.50%\n",
      "Run: 04, Epoch: 161, Loss: 0.2578, Train: 93.57%, Valid: 80.60% Test: 81.60%\n",
      "Run: 04, Epoch: 162, Loss: 0.2372, Train: 94.29%, Valid: 81.60% Test: 82.40%\n",
      "Run: 04, Epoch: 163, Loss: 0.2458, Train: 97.14%, Valid: 82.80% Test: 84.50%\n",
      "Run: 04, Epoch: 164, Loss: 0.3041, Train: 94.29%, Valid: 84.20% Test: 84.40%\n",
      "Run: 04, Epoch: 165, Loss: 0.2560, Train: 94.29%, Valid: 83.80% Test: 84.90%\n",
      "Run: 04, Epoch: 166, Loss: 0.3332, Train: 94.29%, Valid: 81.40% Test: 84.10%\n",
      "Run: 04, Epoch: 167, Loss: 0.3072, Train: 93.57%, Valid: 81.40% Test: 82.90%\n",
      "Run: 04, Epoch: 168, Loss: 0.2272, Train: 92.14%, Valid: 82.20% Test: 81.90%\n",
      "Run: 04, Epoch: 169, Loss: 0.2818, Train: 96.43%, Valid: 83.00% Test: 83.40%\n",
      "Run: 04, Epoch: 170, Loss: 0.2824, Train: 95.00%, Valid: 84.60% Test: 84.70%\n",
      "Run: 04, Epoch: 171, Loss: 0.2484, Train: 93.57%, Valid: 85.80% Test: 85.90%\n",
      "Run: 04, Epoch: 172, Loss: 0.2883, Train: 92.86%, Valid: 85.00% Test: 85.90%\n",
      "Run: 04, Epoch: 173, Loss: 0.2731, Train: 92.14%, Valid: 84.60% Test: 85.70%\n",
      "Run: 04, Epoch: 174, Loss: 0.2607, Train: 94.29%, Valid: 84.20% Test: 85.60%\n",
      "Run: 04, Epoch: 175, Loss: 0.2580, Train: 95.00%, Valid: 84.80% Test: 86.10%\n",
      "Run: 04, Epoch: 176, Loss: 0.2639, Train: 96.43%, Valid: 82.60% Test: 84.10%\n",
      "Run: 04, Epoch: 177, Loss: 0.2243, Train: 92.14%, Valid: 78.80% Test: 79.30%\n",
      "Run: 04, Epoch: 178, Loss: 0.2275, Train: 91.43%, Valid: 77.20% Test: 79.00%\n",
      "Run: 04, Epoch: 179, Loss: 0.2416, Train: 92.86%, Valid: 80.20% Test: 80.10%\n",
      "Run: 04, Epoch: 180, Loss: 0.2334, Train: 96.43%, Valid: 82.00% Test: 83.10%\n",
      "Run: 04, Epoch: 181, Loss: 0.2327, Train: 94.29%, Valid: 83.60% Test: 84.10%\n",
      "Run: 04, Epoch: 182, Loss: 0.2791, Train: 94.29%, Valid: 84.20% Test: 84.20%\n",
      "Run: 04, Epoch: 183, Loss: 0.2321, Train: 95.71%, Valid: 85.40% Test: 85.40%\n",
      "Run: 04, Epoch: 184, Loss: 0.2051, Train: 97.14%, Valid: 84.00% Test: 84.80%\n",
      "Run: 04, Epoch: 185, Loss: 0.2706, Train: 89.29%, Valid: 77.20% Test: 79.30%\n",
      "Run: 04, Epoch: 186, Loss: 0.2757, Train: 88.57%, Valid: 77.00% Test: 78.30%\n",
      "Run: 04, Epoch: 187, Loss: 0.3209, Train: 95.00%, Valid: 84.00% Test: 85.20%\n",
      "Run: 04, Epoch: 188, Loss: 0.2664, Train: 92.14%, Valid: 82.40% Test: 84.60%\n",
      "Run: 04, Epoch: 189, Loss: 0.3268, Train: 91.43%, Valid: 82.00% Test: 84.30%\n",
      "Run: 04, Epoch: 190, Loss: 0.2350, Train: 92.86%, Valid: 81.80% Test: 84.20%\n",
      "Run: 04, Epoch: 191, Loss: 0.2010, Train: 91.43%, Valid: 81.00% Test: 83.70%\n",
      "Run: 04, Epoch: 192, Loss: 0.2439, Train: 88.57%, Valid: 79.80% Test: 80.90%\n",
      "Run: 04, Epoch: 193, Loss: 0.2155, Train: 82.14%, Valid: 77.80% Test: 76.80%\n",
      "Run: 04, Epoch: 194, Loss: 0.2177, Train: 88.57%, Valid: 79.40% Test: 79.20%\n",
      "Run: 04, Epoch: 195, Loss: 0.2317, Train: 90.71%, Valid: 82.80% Test: 82.70%\n",
      "Run: 04, Epoch: 196, Loss: 0.2626, Train: 92.14%, Valid: 84.00% Test: 83.80%\n",
      "Run: 04, Epoch: 197, Loss: 0.2400, Train: 90.71%, Valid: 80.80% Test: 80.70%\n",
      "Run: 04, Epoch: 198, Loss: 0.2530, Train: 78.57%, Valid: 75.00% Test: 75.30%\n",
      "Run: 04, Epoch: 199, Loss: 0.2614, Train: 77.86%, Valid: 73.20% Test: 74.20%\n",
      "Run: 04, Epoch: 200, Loss: 0.2708, Train: 87.86%, Valid: 80.00% Test: 81.60%\n",
      "Run 04:\n",
      "Highest Train: 97.14\n",
      "Highest Valid: 85.80\n",
      "  Final Train: 93.57\n",
      "   Final Test: 85.90\n",
      "Run: 05, Epoch: 01, Loss: 2.2339, Train: 14.29%, Valid: 11.40% Test: 10.30%\n",
      "Run: 05, Epoch: 02, Loss: 2.1594, Train: 9.29%, Valid: 8.40% Test: 8.20%\n",
      "Run: 05, Epoch: 03, Loss: 2.1580, Train: 5.00%, Valid: 6.60% Test: 5.40%\n",
      "Run: 05, Epoch: 04, Loss: 1.9962, Train: 4.29%, Valid: 4.80% Test: 5.90%\n",
      "Run: 05, Epoch: 05, Loss: 2.0218, Train: 7.86%, Valid: 4.80% Test: 7.40%\n",
      "Run: 05, Epoch: 06, Loss: 1.9020, Train: 14.29%, Valid: 7.40% Test: 9.60%\n",
      "Run: 05, Epoch: 07, Loss: 1.8468, Train: 14.29%, Valid: 7.20% Test: 9.10%\n",
      "Run: 05, Epoch: 08, Loss: 1.8399, Train: 14.29%, Valid: 7.20% Test: 9.10%\n",
      "Run: 05, Epoch: 09, Loss: 1.7601, Train: 14.29%, Valid: 7.40% Test: 9.40%\n",
      "Run: 05, Epoch: 10, Loss: 1.7638, Train: 15.00%, Valid: 7.40% Test: 9.40%\n",
      "Run: 05, Epoch: 11, Loss: 1.6437, Train: 14.29%, Valid: 7.60% Test: 9.40%\n",
      "Run: 05, Epoch: 12, Loss: 1.6524, Train: 14.29%, Valid: 7.80% Test: 9.50%\n",
      "Run: 05, Epoch: 13, Loss: 1.6242, Train: 15.71%, Valid: 7.80% Test: 9.60%\n",
      "Run: 05, Epoch: 14, Loss: 1.5560, Train: 15.71%, Valid: 8.00% Test: 9.80%\n",
      "Run: 05, Epoch: 15, Loss: 1.5918, Train: 16.43%, Valid: 7.80% Test: 9.60%\n",
      "Run: 05, Epoch: 16, Loss: 1.5418, Train: 17.14%, Valid: 7.80% Test: 10.10%\n",
      "Run: 05, Epoch: 17, Loss: 1.4268, Train: 17.14%, Valid: 8.40% Test: 11.10%\n",
      "Run: 05, Epoch: 18, Loss: 1.4485, Train: 20.00%, Valid: 11.20% Test: 14.10%\n",
      "Run: 05, Epoch: 19, Loss: 1.3862, Train: 26.43%, Valid: 15.20% Test: 18.70%\n",
      "Run: 05, Epoch: 20, Loss: 1.3909, Train: 28.57%, Valid: 20.20% Test: 22.40%\n",
      "Run: 05, Epoch: 21, Loss: 1.3735, Train: 34.29%, Valid: 24.60% Test: 25.10%\n",
      "Run: 05, Epoch: 22, Loss: 1.3148, Train: 34.29%, Valid: 27.00% Test: 25.80%\n",
      "Run: 05, Epoch: 23, Loss: 1.3005, Train: 40.71%, Valid: 30.00% Test: 28.20%\n",
      "Run: 05, Epoch: 24, Loss: 1.1339, Train: 50.71%, Valid: 39.60% Test: 38.40%\n",
      "Run: 05, Epoch: 25, Loss: 1.2317, Train: 60.71%, Valid: 49.60% Test: 51.60%\n",
      "Run: 05, Epoch: 26, Loss: 1.1750, Train: 63.57%, Valid: 58.40% Test: 59.00%\n",
      "Run: 05, Epoch: 27, Loss: 1.1214, Train: 65.71%, Valid: 63.80% Test: 65.10%\n",
      "Run: 05, Epoch: 28, Loss: 1.1680, Train: 68.57%, Valid: 64.20% Test: 67.40%\n",
      "Run: 05, Epoch: 29, Loss: 1.1012, Train: 65.71%, Valid: 63.00% Test: 66.00%\n",
      "Run: 05, Epoch: 30, Loss: 1.0333, Train: 62.14%, Valid: 62.00% Test: 65.80%\n",
      "Run: 05, Epoch: 31, Loss: 1.0343, Train: 60.71%, Valid: 61.40% Test: 65.50%\n",
      "Run: 05, Epoch: 32, Loss: 0.9885, Train: 65.00%, Valid: 64.40% Test: 66.00%\n",
      "Run: 05, Epoch: 33, Loss: 0.9985, Train: 69.29%, Valid: 66.20% Test: 67.50%\n",
      "Run: 05, Epoch: 34, Loss: 0.9023, Train: 65.71%, Valid: 61.80% Test: 61.10%\n",
      "Run: 05, Epoch: 35, Loss: 0.9514, Train: 67.86%, Valid: 63.40% Test: 62.40%\n",
      "Run: 05, Epoch: 36, Loss: 0.8782, Train: 67.86%, Valid: 63.80% Test: 61.90%\n",
      "Run: 05, Epoch: 37, Loss: 0.8833, Train: 62.86%, Valid: 63.00% Test: 62.00%\n",
      "Run: 05, Epoch: 38, Loss: 0.8374, Train: 60.00%, Valid: 63.20% Test: 62.80%\n",
      "Run: 05, Epoch: 39, Loss: 0.8375, Train: 60.00%, Valid: 63.40% Test: 64.40%\n",
      "Run: 05, Epoch: 40, Loss: 0.7816, Train: 66.43%, Valid: 63.40% Test: 65.10%\n",
      "Run: 05, Epoch: 41, Loss: 0.7570, Train: 66.43%, Valid: 64.20% Test: 63.80%\n",
      "Run: 05, Epoch: 42, Loss: 0.8128, Train: 70.00%, Valid: 66.40% Test: 66.60%\n",
      "Run: 05, Epoch: 43, Loss: 0.8144, Train: 76.43%, Valid: 68.60% Test: 68.80%\n",
      "Run: 05, Epoch: 44, Loss: 0.7621, Train: 81.43%, Valid: 71.00% Test: 72.00%\n",
      "Run: 05, Epoch: 45, Loss: 0.6934, Train: 84.29%, Valid: 73.80% Test: 74.90%\n",
      "Run: 05, Epoch: 46, Loss: 0.6778, Train: 85.00%, Valid: 74.60% Test: 75.60%\n",
      "Run: 05, Epoch: 47, Loss: 0.6889, Train: 85.71%, Valid: 74.40% Test: 76.20%\n",
      "Run: 05, Epoch: 48, Loss: 0.6690, Train: 83.57%, Valid: 73.40% Test: 75.90%\n",
      "Run: 05, Epoch: 49, Loss: 0.6446, Train: 83.57%, Valid: 75.00% Test: 77.20%\n",
      "Run: 05, Epoch: 50, Loss: 0.6324, Train: 85.71%, Valid: 75.00% Test: 75.70%\n",
      "Run: 05, Epoch: 51, Loss: 0.5821, Train: 87.14%, Valid: 71.20% Test: 73.30%\n",
      "Run: 05, Epoch: 52, Loss: 0.5898, Train: 82.14%, Valid: 69.60% Test: 71.90%\n",
      "Run: 05, Epoch: 53, Loss: 0.5775, Train: 81.43%, Valid: 70.20% Test: 72.20%\n",
      "Run: 05, Epoch: 54, Loss: 0.5894, Train: 85.00%, Valid: 74.20% Test: 75.60%\n",
      "Run: 05, Epoch: 55, Loss: 0.6017, Train: 85.71%, Valid: 76.60% Test: 79.00%\n",
      "Run: 05, Epoch: 56, Loss: 0.6433, Train: 87.86%, Valid: 78.60% Test: 81.60%\n",
      "Run: 05, Epoch: 57, Loss: 0.5375, Train: 87.86%, Valid: 79.60% Test: 81.90%\n",
      "Run: 05, Epoch: 58, Loss: 0.5509, Train: 90.00%, Valid: 80.60% Test: 81.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 59, Loss: 0.5927, Train: 88.57%, Valid: 79.40% Test: 79.90%\n",
      "Run: 05, Epoch: 60, Loss: 0.6138, Train: 87.14%, Valid: 77.00% Test: 78.20%\n",
      "Run: 05, Epoch: 61, Loss: 0.5301, Train: 81.43%, Valid: 73.40% Test: 74.00%\n",
      "Run: 05, Epoch: 62, Loss: 0.5338, Train: 79.29%, Valid: 70.60% Test: 71.10%\n",
      "Run: 05, Epoch: 63, Loss: 0.5094, Train: 77.86%, Valid: 71.00% Test: 70.30%\n",
      "Run: 05, Epoch: 64, Loss: 0.4877, Train: 82.14%, Valid: 74.60% Test: 73.10%\n",
      "Run: 05, Epoch: 65, Loss: 0.4662, Train: 89.29%, Valid: 80.20% Test: 80.20%\n",
      "Run: 05, Epoch: 66, Loss: 0.4757, Train: 88.57%, Valid: 80.60% Test: 80.90%\n",
      "Run: 05, Epoch: 67, Loss: 0.5155, Train: 85.71%, Valid: 77.20% Test: 79.70%\n",
      "Run: 05, Epoch: 68, Loss: 0.4939, Train: 84.29%, Valid: 75.20% Test: 77.70%\n",
      "Run: 05, Epoch: 69, Loss: 0.5524, Train: 86.43%, Valid: 80.00% Test: 83.00%\n",
      "Run: 05, Epoch: 70, Loss: 0.5005, Train: 92.14%, Valid: 82.00% Test: 83.90%\n",
      "Run: 05, Epoch: 71, Loss: 0.4513, Train: 87.14%, Valid: 79.60% Test: 81.90%\n",
      "Run: 05, Epoch: 72, Loss: 0.5404, Train: 85.71%, Valid: 77.60% Test: 78.30%\n",
      "Run: 05, Epoch: 73, Loss: 0.4208, Train: 88.57%, Valid: 79.60% Test: 80.40%\n",
      "Run: 05, Epoch: 74, Loss: 0.4507, Train: 95.00%, Valid: 83.00% Test: 83.80%\n",
      "Run: 05, Epoch: 75, Loss: 0.5157, Train: 90.71%, Valid: 81.80% Test: 85.20%\n",
      "Run: 05, Epoch: 76, Loss: 0.4410, Train: 87.14%, Valid: 79.80% Test: 82.50%\n",
      "Run: 05, Epoch: 77, Loss: 0.4209, Train: 86.43%, Valid: 79.60% Test: 81.10%\n",
      "Run: 05, Epoch: 78, Loss: 0.4565, Train: 86.43%, Valid: 80.20% Test: 81.50%\n",
      "Run: 05, Epoch: 79, Loss: 0.4524, Train: 89.29%, Valid: 81.00% Test: 83.10%\n",
      "Run: 05, Epoch: 80, Loss: 0.4356, Train: 93.57%, Valid: 82.20% Test: 83.80%\n",
      "Run: 05, Epoch: 81, Loss: 0.3901, Train: 91.43%, Valid: 80.80% Test: 82.10%\n",
      "Run: 05, Epoch: 82, Loss: 0.3749, Train: 90.00%, Valid: 80.80% Test: 82.50%\n",
      "Run: 05, Epoch: 83, Loss: 0.4469, Train: 92.14%, Valid: 81.40% Test: 83.80%\n",
      "Run: 05, Epoch: 84, Loss: 0.4869, Train: 92.14%, Valid: 83.20% Test: 84.50%\n",
      "Run: 05, Epoch: 85, Loss: 0.3967, Train: 90.00%, Valid: 84.20% Test: 83.50%\n",
      "Run: 05, Epoch: 86, Loss: 0.3712, Train: 88.57%, Valid: 83.20% Test: 81.80%\n",
      "Run: 05, Epoch: 87, Loss: 0.4423, Train: 92.86%, Valid: 83.80% Test: 84.80%\n",
      "Run: 05, Epoch: 88, Loss: 0.4222, Train: 93.57%, Valid: 83.40% Test: 84.70%\n",
      "Run: 05, Epoch: 89, Loss: 0.4061, Train: 90.71%, Valid: 79.80% Test: 82.80%\n",
      "Run: 05, Epoch: 90, Loss: 0.4668, Train: 85.00%, Valid: 76.20% Test: 79.00%\n",
      "Run: 05, Epoch: 91, Loss: 0.3931, Train: 83.57%, Valid: 75.80% Test: 77.10%\n",
      "Run: 05, Epoch: 92, Loss: 0.3992, Train: 85.00%, Valid: 78.20% Test: 77.90%\n",
      "Run: 05, Epoch: 93, Loss: 0.3327, Train: 90.71%, Valid: 81.20% Test: 81.90%\n",
      "Run: 05, Epoch: 94, Loss: 0.3567, Train: 91.43%, Valid: 81.80% Test: 84.20%\n",
      "Run: 05, Epoch: 95, Loss: 0.3879, Train: 90.71%, Valid: 80.80% Test: 83.00%\n",
      "Run: 05, Epoch: 96, Loss: 0.4426, Train: 90.71%, Valid: 81.20% Test: 83.10%\n",
      "Run: 05, Epoch: 97, Loss: 0.3624, Train: 91.43%, Valid: 81.00% Test: 82.90%\n",
      "Run: 05, Epoch: 98, Loss: 0.3883, Train: 90.71%, Valid: 80.80% Test: 83.70%\n",
      "Run: 05, Epoch: 99, Loss: 0.3481, Train: 92.86%, Valid: 81.20% Test: 84.50%\n",
      "Run: 05, Epoch: 100, Loss: 0.3401, Train: 92.14%, Valid: 82.80% Test: 85.60%\n",
      "Run: 05, Epoch: 101, Loss: 0.3880, Train: 93.57%, Valid: 83.20% Test: 85.10%\n",
      "Run: 05, Epoch: 102, Loss: 0.3546, Train: 93.57%, Valid: 83.80% Test: 84.00%\n",
      "Run: 05, Epoch: 103, Loss: 0.3484, Train: 95.71%, Valid: 81.40% Test: 83.20%\n",
      "Run: 05, Epoch: 104, Loss: 0.3721, Train: 92.86%, Valid: 79.80% Test: 82.50%\n",
      "Run: 05, Epoch: 105, Loss: 0.3834, Train: 88.57%, Valid: 79.40% Test: 82.40%\n",
      "Run: 05, Epoch: 106, Loss: 0.4504, Train: 88.57%, Valid: 80.20% Test: 81.50%\n",
      "Run: 05, Epoch: 107, Loss: 0.3520, Train: 87.86%, Valid: 81.20% Test: 83.00%\n",
      "Run: 05, Epoch: 108, Loss: 0.3300, Train: 90.00%, Valid: 82.00% Test: 84.20%\n",
      "Run: 05, Epoch: 109, Loss: 0.3165, Train: 90.00%, Valid: 81.80% Test: 83.30%\n",
      "Run: 05, Epoch: 110, Loss: 0.3794, Train: 88.57%, Valid: 80.20% Test: 80.70%\n",
      "Run: 05, Epoch: 111, Loss: 0.3225, Train: 87.86%, Valid: 79.80% Test: 77.30%\n",
      "Run: 05, Epoch: 112, Loss: 0.3636, Train: 82.86%, Valid: 74.60% Test: 73.90%\n",
      "Run: 05, Epoch: 113, Loss: 0.3799, Train: 84.29%, Valid: 74.80% Test: 74.40%\n",
      "Run: 05, Epoch: 114, Loss: 0.3737, Train: 84.29%, Valid: 79.80% Test: 78.40%\n",
      "Run: 05, Epoch: 115, Loss: 0.3357, Train: 88.57%, Valid: 82.20% Test: 83.10%\n",
      "Run: 05, Epoch: 116, Loss: 0.3687, Train: 92.86%, Valid: 82.20% Test: 85.70%\n",
      "Run: 05, Epoch: 117, Loss: 0.3682, Train: 91.43%, Valid: 82.40% Test: 84.60%\n",
      "Run: 05, Epoch: 118, Loss: 0.3317, Train: 90.00%, Valid: 81.60% Test: 84.00%\n",
      "Run: 05, Epoch: 119, Loss: 0.3193, Train: 90.71%, Valid: 83.00% Test: 84.10%\n",
      "Run: 05, Epoch: 120, Loss: 0.3193, Train: 90.00%, Valid: 80.80% Test: 82.60%\n",
      "Run: 05, Epoch: 121, Loss: 0.3531, Train: 92.14%, Valid: 81.80% Test: 84.60%\n",
      "Run: 05, Epoch: 122, Loss: 0.3003, Train: 96.43%, Valid: 81.80% Test: 84.90%\n",
      "Run: 05, Epoch: 123, Loss: 0.3558, Train: 92.86%, Valid: 78.00% Test: 82.80%\n",
      "Run: 05, Epoch: 124, Loss: 0.2897, Train: 90.00%, Valid: 75.40% Test: 79.10%\n",
      "Run: 05, Epoch: 125, Loss: 0.3030, Train: 92.14%, Valid: 78.60% Test: 80.60%\n",
      "Run: 05, Epoch: 126, Loss: 0.3079, Train: 92.14%, Valid: 83.40% Test: 83.40%\n",
      "Run: 05, Epoch: 127, Loss: 0.3411, Train: 92.14%, Valid: 83.60% Test: 83.70%\n",
      "Run: 05, Epoch: 128, Loss: 0.3070, Train: 83.57%, Valid: 81.20% Test: 81.00%\n",
      "Run: 05, Epoch: 129, Loss: 0.2700, Train: 77.14%, Valid: 75.80% Test: 75.00%\n",
      "Run: 05, Epoch: 130, Loss: 0.3190, Train: 81.43%, Valid: 77.20% Test: 78.30%\n",
      "Run: 05, Epoch: 131, Loss: 0.3496, Train: 89.29%, Valid: 82.40% Test: 83.40%\n",
      "Run: 05, Epoch: 132, Loss: 0.3194, Train: 92.86%, Valid: 81.00% Test: 82.20%\n",
      "Run: 05, Epoch: 133, Loss: 0.2481, Train: 88.57%, Valid: 77.00% Test: 80.90%\n",
      "Run: 05, Epoch: 134, Loss: 0.3600, Train: 89.29%, Valid: 75.80% Test: 80.60%\n",
      "Run: 05, Epoch: 135, Loss: 0.3222, Train: 90.71%, Valid: 76.60% Test: 79.40%\n",
      "Run: 05, Epoch: 136, Loss: 0.2567, Train: 91.43%, Valid: 77.80% Test: 81.30%\n",
      "Run: 05, Epoch: 137, Loss: 0.3871, Train: 90.00%, Valid: 80.40% Test: 84.10%\n",
      "Run: 05, Epoch: 138, Loss: 0.2575, Train: 90.71%, Valid: 81.40% Test: 84.90%\n",
      "Run: 05, Epoch: 139, Loss: 0.3016, Train: 91.43%, Valid: 81.40% Test: 85.70%\n",
      "Run: 05, Epoch: 140, Loss: 0.2480, Train: 92.86%, Valid: 82.00% Test: 84.50%\n",
      "Run: 05, Epoch: 141, Loss: 0.2839, Train: 92.86%, Valid: 81.40% Test: 84.40%\n",
      "Run: 05, Epoch: 142, Loss: 0.2564, Train: 92.86%, Valid: 82.80% Test: 85.30%\n",
      "Run: 05, Epoch: 143, Loss: 0.2296, Train: 88.57%, Valid: 80.00% Test: 83.30%\n",
      "Run: 05, Epoch: 144, Loss: 0.2538, Train: 87.86%, Valid: 79.60% Test: 82.20%\n",
      "Run: 05, Epoch: 145, Loss: 0.3090, Train: 89.29%, Valid: 78.60% Test: 80.20%\n",
      "Run: 05, Epoch: 146, Loss: 0.2900, Train: 92.14%, Valid: 80.20% Test: 82.30%\n",
      "Run: 05, Epoch: 147, Loss: 0.2880, Train: 91.43%, Valid: 83.20% Test: 83.20%\n",
      "Run: 05, Epoch: 148, Loss: 0.3514, Train: 93.57%, Valid: 84.20% Test: 84.20%\n",
      "Run: 05, Epoch: 149, Loss: 0.3097, Train: 93.57%, Valid: 84.00% Test: 85.00%\n",
      "Run: 05, Epoch: 150, Loss: 0.3549, Train: 90.71%, Valid: 81.80% Test: 84.30%\n",
      "Run: 05, Epoch: 151, Loss: 0.3166, Train: 90.00%, Valid: 81.40% Test: 83.50%\n",
      "Run: 05, Epoch: 152, Loss: 0.2150, Train: 90.00%, Valid: 79.40% Test: 81.70%\n",
      "Run: 05, Epoch: 153, Loss: 0.2624, Train: 88.57%, Valid: 78.60% Test: 82.20%\n",
      "Run: 05, Epoch: 154, Loss: 0.3322, Train: 89.29%, Valid: 78.00% Test: 80.00%\n",
      "Run: 05, Epoch: 155, Loss: 0.2719, Train: 90.00%, Valid: 78.80% Test: 79.30%\n",
      "Run: 05, Epoch: 156, Loss: 0.2516, Train: 90.00%, Valid: 80.40% Test: 80.80%\n",
      "Run: 05, Epoch: 157, Loss: 0.2934, Train: 90.71%, Valid: 81.00% Test: 81.10%\n",
      "Run: 05, Epoch: 158, Loss: 0.2715, Train: 89.29%, Valid: 81.60% Test: 80.80%\n",
      "Run: 05, Epoch: 159, Loss: 0.2426, Train: 91.43%, Valid: 81.00% Test: 82.00%\n",
      "Run: 05, Epoch: 160, Loss: 0.2647, Train: 90.71%, Valid: 80.60% Test: 81.90%\n",
      "Run: 05, Epoch: 161, Loss: 0.2735, Train: 92.14%, Valid: 85.20% Test: 83.90%\n",
      "Run: 05, Epoch: 162, Loss: 0.2734, Train: 92.14%, Valid: 85.00% Test: 85.00%\n",
      "Run: 05, Epoch: 163, Loss: 0.1901, Train: 93.57%, Valid: 82.80% Test: 83.70%\n",
      "Run: 05, Epoch: 164, Loss: 0.2747, Train: 90.71%, Valid: 79.00% Test: 80.50%\n",
      "Run: 05, Epoch: 165, Loss: 0.2905, Train: 88.57%, Valid: 75.80% Test: 76.60%\n",
      "Run: 05, Epoch: 166, Loss: 0.2587, Train: 86.43%, Valid: 76.00% Test: 76.80%\n",
      "Run: 05, Epoch: 167, Loss: 0.2934, Train: 87.14%, Valid: 75.40% Test: 78.10%\n",
      "Run: 05, Epoch: 168, Loss: 0.2644, Train: 90.00%, Valid: 78.60% Test: 81.60%\n",
      "Run: 05, Epoch: 169, Loss: 0.2487, Train: 88.57%, Valid: 81.80% Test: 82.40%\n",
      "Run: 05, Epoch: 170, Loss: 0.2758, Train: 90.71%, Valid: 83.20% Test: 83.30%\n",
      "Run: 05, Epoch: 171, Loss: 0.2400, Train: 88.57%, Valid: 80.80% Test: 82.20%\n",
      "Run: 05, Epoch: 172, Loss: 0.2853, Train: 82.86%, Valid: 77.80% Test: 81.10%\n",
      "Run: 05, Epoch: 173, Loss: 0.2186, Train: 80.71%, Valid: 75.20% Test: 78.30%\n",
      "Run: 05, Epoch: 174, Loss: 0.2119, Train: 82.86%, Valid: 76.20% Test: 78.60%\n",
      "Run: 05, Epoch: 175, Loss: 0.2794, Train: 84.29%, Valid: 76.00% Test: 77.60%\n",
      "Run: 05, Epoch: 176, Loss: 0.2556, Train: 82.86%, Valid: 71.40% Test: 75.60%\n",
      "Run: 05, Epoch: 177, Loss: 0.2815, Train: 86.43%, Valid: 74.80% Test: 76.70%\n",
      "Run: 05, Epoch: 178, Loss: 0.2997, Train: 91.43%, Valid: 79.00% Test: 81.10%\n",
      "Run: 05, Epoch: 179, Loss: 0.1750, Train: 95.00%, Valid: 80.80% Test: 83.20%\n",
      "Run: 05, Epoch: 180, Loss: 0.2403, Train: 91.43%, Valid: 79.60% Test: 79.90%\n",
      "Run: 05, Epoch: 181, Loss: 0.2533, Train: 89.29%, Valid: 80.20% Test: 79.20%\n",
      "Run: 05, Epoch: 182, Loss: 0.3430, Train: 90.00%, Valid: 81.60% Test: 81.00%\n",
      "Run: 05, Epoch: 183, Loss: 0.2463, Train: 90.71%, Valid: 82.60% Test: 83.00%\n",
      "Run: 05, Epoch: 184, Loss: 0.3304, Train: 91.43%, Valid: 82.00% Test: 82.30%\n",
      "Run: 05, Epoch: 185, Loss: 0.2488, Train: 91.43%, Valid: 80.40% Test: 81.50%\n",
      "Run: 05, Epoch: 186, Loss: 0.2072, Train: 91.43%, Valid: 79.60% Test: 81.10%\n",
      "Run: 05, Epoch: 187, Loss: 0.3154, Train: 92.14%, Valid: 79.60% Test: 82.30%\n",
      "Run: 05, Epoch: 188, Loss: 0.2009, Train: 95.00%, Valid: 81.60% Test: 82.60%\n",
      "Run: 05, Epoch: 189, Loss: 0.3322, Train: 94.29%, Valid: 82.60% Test: 83.10%\n",
      "Run: 05, Epoch: 190, Loss: 0.2748, Train: 93.57%, Valid: 80.80% Test: 82.00%\n",
      "Run: 05, Epoch: 191, Loss: 0.2352, Train: 92.86%, Valid: 81.20% Test: 83.20%\n",
      "Run: 05, Epoch: 192, Loss: 0.1842, Train: 91.43%, Valid: 82.40% Test: 83.50%\n",
      "Run: 05, Epoch: 193, Loss: 0.2080, Train: 91.43%, Valid: 82.80% Test: 83.30%\n",
      "Run: 05, Epoch: 194, Loss: 0.2567, Train: 91.43%, Valid: 83.40% Test: 83.50%\n",
      "Run: 05, Epoch: 195, Loss: 0.2096, Train: 90.71%, Valid: 82.20% Test: 83.50%\n",
      "Run: 05, Epoch: 196, Loss: 0.2021, Train: 89.29%, Valid: 83.00% Test: 83.10%\n",
      "Run: 05, Epoch: 197, Loss: 0.2192, Train: 89.29%, Valid: 83.60% Test: 83.30%\n",
      "Run: 05, Epoch: 198, Loss: 0.2763, Train: 91.43%, Valid: 84.40% Test: 84.80%\n",
      "Run: 05, Epoch: 199, Loss: 0.2651, Train: 94.29%, Valid: 83.80% Test: 84.70%\n",
      "Run: 05, Epoch: 200, Loss: 0.2121, Train: 95.71%, Valid: 83.00% Test: 85.20%\n",
      "Run 05:\n",
      "Highest Train: 96.43\n",
      "Highest Valid: 85.20\n",
      "  Final Train: 92.14\n",
      "   Final Test: 83.90\n",
      "Run: 06, Epoch: 01, Loss: 2.0966, Train: 14.29%, Valid: 31.60% Test: 31.90%\n",
      "Run: 06, Epoch: 02, Loss: 2.1007, Train: 14.29%, Valid: 31.40% Test: 31.80%\n",
      "Run: 06, Epoch: 03, Loss: 1.9279, Train: 18.57%, Valid: 31.60% Test: 32.10%\n",
      "Run: 06, Epoch: 04, Loss: 1.7935, Train: 22.14%, Valid: 30.40% Test: 30.60%\n",
      "Run: 06, Epoch: 05, Loss: 1.7671, Train: 24.29%, Valid: 20.00% Test: 20.30%\n",
      "Run: 06, Epoch: 06, Loss: 1.7943, Train: 26.43%, Valid: 13.20% Test: 14.40%\n",
      "Run: 06, Epoch: 07, Loss: 1.7224, Train: 25.71%, Valid: 11.80% Test: 14.00%\n",
      "Run: 06, Epoch: 08, Loss: 1.6624, Train: 29.29%, Valid: 16.00% Test: 17.90%\n",
      "Run: 06, Epoch: 09, Loss: 1.6658, Train: 37.86%, Valid: 21.60% Test: 22.70%\n",
      "Run: 06, Epoch: 10, Loss: 1.6159, Train: 37.14%, Valid: 24.80% Test: 24.90%\n",
      "Run: 06, Epoch: 11, Loss: 1.6000, Train: 34.29%, Valid: 23.20% Test: 23.40%\n",
      "Run: 06, Epoch: 12, Loss: 1.5658, Train: 32.14%, Valid: 21.60% Test: 21.10%\n",
      "Run: 06, Epoch: 13, Loss: 1.5363, Train: 30.71%, Valid: 20.20% Test: 20.50%\n",
      "Run: 06, Epoch: 14, Loss: 1.4375, Train: 34.29%, Valid: 20.40% Test: 20.60%\n",
      "Run: 06, Epoch: 15, Loss: 1.4773, Train: 34.29%, Valid: 22.00% Test: 22.10%\n",
      "Run: 06, Epoch: 16, Loss: 1.4234, Train: 34.29%, Valid: 25.60% Test: 24.40%\n",
      "Run: 06, Epoch: 17, Loss: 1.4901, Train: 38.57%, Valid: 30.60% Test: 28.10%\n",
      "Run: 06, Epoch: 18, Loss: 1.3444, Train: 45.71%, Valid: 33.00% Test: 31.30%\n",
      "Run: 06, Epoch: 19, Loss: 1.3037, Train: 41.43%, Valid: 33.60% Test: 31.60%\n",
      "Run: 06, Epoch: 20, Loss: 1.2790, Train: 40.71%, Valid: 31.40% Test: 31.80%\n",
      "Run: 06, Epoch: 21, Loss: 1.3196, Train: 38.57%, Valid: 29.20% Test: 29.50%\n",
      "Run: 06, Epoch: 22, Loss: 1.2420, Train: 34.29%, Valid: 26.40% Test: 26.30%\n",
      "Run: 06, Epoch: 23, Loss: 1.2194, Train: 32.14%, Valid: 26.40% Test: 24.00%\n",
      "Run: 06, Epoch: 24, Loss: 1.1710, Train: 33.57%, Valid: 27.20% Test: 24.20%\n",
      "Run: 06, Epoch: 25, Loss: 1.1490, Train: 36.43%, Valid: 33.40% Test: 29.40%\n",
      "Run: 06, Epoch: 26, Loss: 1.0897, Train: 47.86%, Valid: 40.00% Test: 38.10%\n",
      "Run: 06, Epoch: 27, Loss: 1.1601, Train: 56.43%, Valid: 50.20% Test: 48.00%\n",
      "Run: 06, Epoch: 28, Loss: 1.0628, Train: 61.43%, Valid: 56.80% Test: 55.70%\n",
      "Run: 06, Epoch: 29, Loss: 1.1053, Train: 68.57%, Valid: 61.80% Test: 60.60%\n",
      "Run: 06, Epoch: 30, Loss: 1.0988, Train: 62.86%, Valid: 60.20% Test: 58.00%\n",
      "Run: 06, Epoch: 31, Loss: 1.0391, Train: 60.71%, Valid: 54.40% Test: 54.00%\n",
      "Run: 06, Epoch: 32, Loss: 1.0149, Train: 52.14%, Valid: 46.00% Test: 44.10%\n",
      "Run: 06, Epoch: 33, Loss: 0.9497, Train: 48.57%, Valid: 39.60% Test: 39.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 34, Loss: 0.9863, Train: 45.71%, Valid: 38.40% Test: 38.50%\n",
      "Run: 06, Epoch: 35, Loss: 0.8448, Train: 50.00%, Valid: 43.00% Test: 43.10%\n",
      "Run: 06, Epoch: 36, Loss: 0.9099, Train: 59.29%, Valid: 52.20% Test: 51.70%\n",
      "Run: 06, Epoch: 37, Loss: 0.8524, Train: 69.29%, Valid: 62.00% Test: 61.00%\n",
      "Run: 06, Epoch: 38, Loss: 0.8457, Train: 72.14%, Valid: 68.00% Test: 66.40%\n",
      "Run: 06, Epoch: 39, Loss: 0.8195, Train: 75.71%, Valid: 69.20% Test: 68.00%\n",
      "Run: 06, Epoch: 40, Loss: 0.7902, Train: 75.00%, Valid: 70.60% Test: 68.00%\n",
      "Run: 06, Epoch: 41, Loss: 0.7509, Train: 74.29%, Valid: 69.00% Test: 66.60%\n",
      "Run: 06, Epoch: 42, Loss: 0.8583, Train: 75.71%, Valid: 69.60% Test: 68.00%\n",
      "Run: 06, Epoch: 43, Loss: 0.8152, Train: 78.57%, Valid: 69.60% Test: 69.10%\n",
      "Run: 06, Epoch: 44, Loss: 0.7103, Train: 77.86%, Valid: 66.60% Test: 66.60%\n",
      "Run: 06, Epoch: 45, Loss: 0.8192, Train: 71.43%, Valid: 61.80% Test: 62.10%\n",
      "Run: 06, Epoch: 46, Loss: 0.6769, Train: 75.00%, Valid: 61.60% Test: 61.80%\n",
      "Run: 06, Epoch: 47, Loss: 0.6630, Train: 82.14%, Valid: 71.20% Test: 73.10%\n",
      "Run: 06, Epoch: 48, Loss: 0.7463, Train: 86.43%, Valid: 76.60% Test: 80.40%\n",
      "Run: 06, Epoch: 49, Loss: 0.6471, Train: 85.00%, Valid: 78.60% Test: 80.50%\n",
      "Run: 06, Epoch: 50, Loss: 0.6259, Train: 85.00%, Valid: 79.20% Test: 82.10%\n",
      "Run: 06, Epoch: 51, Loss: 0.6677, Train: 83.57%, Valid: 77.20% Test: 80.00%\n",
      "Run: 06, Epoch: 52, Loss: 0.6283, Train: 84.29%, Valid: 75.80% Test: 78.50%\n",
      "Run: 06, Epoch: 53, Loss: 0.6121, Train: 87.14%, Valid: 73.60% Test: 74.80%\n",
      "Run: 06, Epoch: 54, Loss: 0.5402, Train: 86.43%, Valid: 74.00% Test: 74.10%\n",
      "Run: 06, Epoch: 55, Loss: 0.7553, Train: 85.71%, Valid: 75.20% Test: 78.80%\n",
      "Run: 06, Epoch: 56, Loss: 0.6337, Train: 83.57%, Valid: 78.20% Test: 81.50%\n",
      "Run: 06, Epoch: 57, Loss: 0.5366, Train: 87.14%, Valid: 81.60% Test: 81.70%\n",
      "Run: 06, Epoch: 58, Loss: 0.6343, Train: 88.57%, Valid: 82.80% Test: 83.20%\n",
      "Run: 06, Epoch: 59, Loss: 0.5437, Train: 91.43%, Valid: 79.60% Test: 81.30%\n",
      "Run: 06, Epoch: 60, Loss: 0.5578, Train: 84.29%, Valid: 73.80% Test: 74.90%\n",
      "Run: 06, Epoch: 61, Loss: 0.5406, Train: 82.86%, Valid: 69.00% Test: 70.70%\n",
      "Run: 06, Epoch: 62, Loss: 0.6745, Train: 80.00%, Valid: 66.00% Test: 69.50%\n",
      "Run: 06, Epoch: 63, Loss: 0.5689, Train: 84.29%, Valid: 71.40% Test: 73.50%\n",
      "Run: 06, Epoch: 64, Loss: 0.4815, Train: 88.57%, Valid: 76.60% Test: 77.80%\n",
      "Run: 06, Epoch: 65, Loss: 0.5728, Train: 85.00%, Valid: 79.20% Test: 79.20%\n",
      "Run: 06, Epoch: 66, Loss: 0.5306, Train: 80.71%, Valid: 78.20% Test: 78.00%\n",
      "Run: 06, Epoch: 67, Loss: 0.5282, Train: 80.00%, Valid: 77.20% Test: 77.30%\n",
      "Run: 06, Epoch: 68, Loss: 0.6208, Train: 82.86%, Valid: 77.60% Test: 78.20%\n",
      "Run: 06, Epoch: 69, Loss: 0.5321, Train: 85.00%, Valid: 76.20% Test: 77.20%\n",
      "Run: 06, Epoch: 70, Loss: 0.5478, Train: 88.57%, Valid: 74.00% Test: 76.70%\n",
      "Run: 06, Epoch: 71, Loss: 0.4276, Train: 88.57%, Valid: 74.60% Test: 76.90%\n",
      "Run: 06, Epoch: 72, Loss: 0.4357, Train: 88.57%, Valid: 76.40% Test: 78.20%\n",
      "Run: 06, Epoch: 73, Loss: 0.4714, Train: 90.71%, Valid: 82.60% Test: 84.40%\n",
      "Run: 06, Epoch: 74, Loss: 0.4758, Train: 89.29%, Valid: 81.00% Test: 84.70%\n",
      "Run: 06, Epoch: 75, Loss: 0.4255, Train: 84.29%, Valid: 81.00% Test: 81.30%\n",
      "Run: 06, Epoch: 76, Loss: 0.4829, Train: 83.57%, Valid: 81.20% Test: 81.90%\n",
      "Run: 06, Epoch: 77, Loss: 0.4458, Train: 88.57%, Valid: 80.00% Test: 84.70%\n",
      "Run: 06, Epoch: 78, Loss: 0.4543, Train: 89.29%, Valid: 77.40% Test: 80.90%\n",
      "Run: 06, Epoch: 79, Loss: 0.4947, Train: 85.71%, Valid: 73.20% Test: 76.00%\n",
      "Run: 06, Epoch: 80, Loss: 0.4272, Train: 84.29%, Valid: 75.40% Test: 75.70%\n",
      "Run: 06, Epoch: 81, Loss: 0.5358, Train: 84.29%, Valid: 75.80% Test: 76.40%\n",
      "Run: 06, Epoch: 82, Loss: 0.5426, Train: 83.57%, Valid: 78.60% Test: 80.10%\n",
      "Run: 06, Epoch: 83, Loss: 0.4566, Train: 82.86%, Valid: 76.60% Test: 77.30%\n",
      "Run: 06, Epoch: 84, Loss: 0.4274, Train: 85.00%, Valid: 78.00% Test: 77.60%\n",
      "Run: 06, Epoch: 85, Loss: 0.4500, Train: 87.86%, Valid: 79.20% Test: 79.50%\n",
      "Run: 06, Epoch: 86, Loss: 0.4280, Train: 89.29%, Valid: 81.00% Test: 84.20%\n",
      "Run: 06, Epoch: 87, Loss: 0.4296, Train: 86.43%, Valid: 79.20% Test: 79.50%\n",
      "Run: 06, Epoch: 88, Loss: 0.4686, Train: 83.57%, Valid: 74.40% Test: 74.80%\n",
      "Run: 06, Epoch: 89, Loss: 0.4574, Train: 84.29%, Valid: 74.80% Test: 75.40%\n",
      "Run: 06, Epoch: 90, Loss: 0.4790, Train: 87.86%, Valid: 76.00% Test: 77.00%\n",
      "Run: 06, Epoch: 91, Loss: 0.4756, Train: 90.71%, Valid: 79.60% Test: 84.10%\n",
      "Run: 06, Epoch: 92, Loss: 0.4027, Train: 90.00%, Valid: 82.00% Test: 84.50%\n",
      "Run: 06, Epoch: 93, Loss: 0.4473, Train: 85.00%, Valid: 81.80% Test: 83.10%\n",
      "Run: 06, Epoch: 94, Loss: 0.4467, Train: 86.43%, Valid: 82.60% Test: 81.40%\n",
      "Run: 06, Epoch: 95, Loss: 0.3506, Train: 87.14%, Valid: 83.00% Test: 82.10%\n",
      "Run: 06, Epoch: 96, Loss: 0.4290, Train: 89.29%, Valid: 83.00% Test: 84.30%\n",
      "Run: 06, Epoch: 97, Loss: 0.4046, Train: 90.71%, Valid: 83.20% Test: 85.00%\n",
      "Run: 06, Epoch: 98, Loss: 0.3966, Train: 93.57%, Valid: 80.00% Test: 81.70%\n",
      "Run: 06, Epoch: 99, Loss: 0.4295, Train: 85.71%, Valid: 75.00% Test: 77.10%\n",
      "Run: 06, Epoch: 100, Loss: 0.3764, Train: 85.00%, Valid: 74.40% Test: 74.80%\n",
      "Run: 06, Epoch: 101, Loss: 0.4705, Train: 89.29%, Valid: 76.40% Test: 78.80%\n",
      "Run: 06, Epoch: 102, Loss: 0.3598, Train: 92.86%, Valid: 80.00% Test: 83.80%\n",
      "Run: 06, Epoch: 103, Loss: 0.4298, Train: 90.71%, Valid: 81.40% Test: 84.50%\n",
      "Run: 06, Epoch: 104, Loss: 0.4104, Train: 90.00%, Valid: 80.80% Test: 83.70%\n",
      "Run: 06, Epoch: 105, Loss: 0.4099, Train: 90.71%, Valid: 81.40% Test: 83.40%\n",
      "Run: 06, Epoch: 106, Loss: 0.3118, Train: 90.00%, Valid: 82.00% Test: 84.70%\n",
      "Run: 06, Epoch: 107, Loss: 0.4260, Train: 92.14%, Valid: 81.20% Test: 85.10%\n",
      "Run: 06, Epoch: 108, Loss: 0.3397, Train: 93.57%, Valid: 80.40% Test: 84.90%\n",
      "Run: 06, Epoch: 109, Loss: 0.3370, Train: 88.57%, Valid: 77.20% Test: 80.80%\n",
      "Run: 06, Epoch: 110, Loss: 0.3526, Train: 85.00%, Valid: 75.40% Test: 75.10%\n",
      "Run: 06, Epoch: 111, Loss: 0.4063, Train: 82.86%, Valid: 75.20% Test: 75.50%\n",
      "Run: 06, Epoch: 112, Loss: 0.4405, Train: 89.29%, Valid: 76.20% Test: 78.00%\n",
      "Run: 06, Epoch: 113, Loss: 0.3954, Train: 90.00%, Valid: 76.00% Test: 79.10%\n",
      "Run: 06, Epoch: 114, Loss: 0.3662, Train: 87.86%, Valid: 78.40% Test: 81.40%\n",
      "Run: 06, Epoch: 115, Loss: 0.3616, Train: 85.00%, Valid: 79.00% Test: 80.40%\n",
      "Run: 06, Epoch: 116, Loss: 0.3189, Train: 86.43%, Valid: 79.20% Test: 81.10%\n",
      "Run: 06, Epoch: 117, Loss: 0.3807, Train: 87.14%, Valid: 77.40% Test: 80.40%\n",
      "Run: 06, Epoch: 118, Loss: 0.3527, Train: 90.00%, Valid: 77.60% Test: 80.30%\n",
      "Run: 06, Epoch: 119, Loss: 0.3870, Train: 90.71%, Valid: 76.60% Test: 80.20%\n",
      "Run: 06, Epoch: 120, Loss: 0.3369, Train: 85.71%, Valid: 78.60% Test: 81.80%\n",
      "Run: 06, Epoch: 121, Loss: 0.3624, Train: 85.71%, Valid: 79.60% Test: 81.70%\n",
      "Run: 06, Epoch: 122, Loss: 0.3859, Train: 85.00%, Valid: 79.60% Test: 81.30%\n",
      "Run: 06, Epoch: 123, Loss: 0.3310, Train: 89.29%, Valid: 79.60% Test: 83.10%\n",
      "Run: 06, Epoch: 124, Loss: 0.3431, Train: 93.57%, Valid: 83.40% Test: 83.70%\n",
      "Run: 06, Epoch: 125, Loss: 0.3940, Train: 87.14%, Valid: 81.60% Test: 82.50%\n",
      "Run: 06, Epoch: 126, Loss: 0.3106, Train: 85.71%, Valid: 78.60% Test: 80.30%\n",
      "Run: 06, Epoch: 127, Loss: 0.3978, Train: 85.00%, Valid: 78.60% Test: 78.50%\n",
      "Run: 06, Epoch: 128, Loss: 0.3291, Train: 85.00%, Valid: 77.20% Test: 77.10%\n",
      "Run: 06, Epoch: 129, Loss: 0.3176, Train: 84.29%, Valid: 76.80% Test: 78.30%\n",
      "Run: 06, Epoch: 130, Loss: 0.2986, Train: 85.00%, Valid: 77.20% Test: 77.20%\n",
      "Run: 06, Epoch: 131, Loss: 0.4049, Train: 85.71%, Valid: 78.20% Test: 79.60%\n",
      "Run: 06, Epoch: 132, Loss: 0.3314, Train: 89.29%, Valid: 79.20% Test: 82.10%\n",
      "Run: 06, Epoch: 133, Loss: 0.3611, Train: 90.71%, Valid: 78.00% Test: 82.00%\n",
      "Run: 06, Epoch: 134, Loss: 0.3801, Train: 89.29%, Valid: 76.60% Test: 81.70%\n",
      "Run: 06, Epoch: 135, Loss: 0.3346, Train: 86.43%, Valid: 75.60% Test: 80.10%\n",
      "Run: 06, Epoch: 136, Loss: 0.3356, Train: 86.43%, Valid: 76.00% Test: 79.90%\n",
      "Run: 06, Epoch: 137, Loss: 0.3297, Train: 91.43%, Valid: 78.40% Test: 80.90%\n",
      "Run: 06, Epoch: 138, Loss: 0.3386, Train: 86.43%, Valid: 80.40% Test: 80.10%\n",
      "Run: 06, Epoch: 139, Loss: 0.3573, Train: 86.43%, Valid: 80.80% Test: 80.80%\n",
      "Run: 06, Epoch: 140, Loss: 0.3723, Train: 88.57%, Valid: 83.20% Test: 82.60%\n",
      "Run: 06, Epoch: 141, Loss: 0.3167, Train: 90.71%, Valid: 83.00% Test: 83.50%\n",
      "Run: 06, Epoch: 142, Loss: 0.3930, Train: 86.43%, Valid: 79.00% Test: 80.00%\n",
      "Run: 06, Epoch: 143, Loss: 0.3070, Train: 85.71%, Valid: 78.80% Test: 79.90%\n",
      "Run: 06, Epoch: 144, Loss: 0.3541, Train: 88.57%, Valid: 78.60% Test: 81.40%\n",
      "Run: 06, Epoch: 145, Loss: 0.3609, Train: 92.14%, Valid: 77.40% Test: 82.20%\n",
      "Run: 06, Epoch: 146, Loss: 0.3973, Train: 90.71%, Valid: 76.80% Test: 80.60%\n",
      "Run: 06, Epoch: 147, Loss: 0.3232, Train: 89.29%, Valid: 77.80% Test: 79.10%\n",
      "Run: 06, Epoch: 148, Loss: 0.3220, Train: 90.71%, Valid: 78.40% Test: 81.40%\n",
      "Run: 06, Epoch: 149, Loss: 0.3479, Train: 92.86%, Valid: 80.20% Test: 82.00%\n",
      "Run: 06, Epoch: 150, Loss: 0.3038, Train: 84.29%, Valid: 80.40% Test: 82.80%\n",
      "Run: 06, Epoch: 151, Loss: 0.2742, Train: 80.00%, Valid: 74.80% Test: 76.80%\n",
      "Run: 06, Epoch: 152, Loss: 0.2981, Train: 79.29%, Valid: 72.00% Test: 75.10%\n",
      "Run: 06, Epoch: 153, Loss: 0.2944, Train: 85.71%, Valid: 74.40% Test: 78.10%\n",
      "Run: 06, Epoch: 154, Loss: 0.3243, Train: 91.43%, Valid: 78.40% Test: 82.30%\n",
      "Run: 06, Epoch: 155, Loss: 0.3298, Train: 88.57%, Valid: 77.20% Test: 80.20%\n",
      "Run: 06, Epoch: 156, Loss: 0.2747, Train: 88.57%, Valid: 74.40% Test: 77.90%\n",
      "Run: 06, Epoch: 157, Loss: 0.2608, Train: 92.86%, Valid: 76.00% Test: 78.40%\n",
      "Run: 06, Epoch: 158, Loss: 0.3396, Train: 90.00%, Valid: 76.80% Test: 79.50%\n",
      "Run: 06, Epoch: 159, Loss: 0.2882, Train: 88.57%, Valid: 78.40% Test: 79.50%\n",
      "Run: 06, Epoch: 160, Loss: 0.2882, Train: 86.43%, Valid: 78.60% Test: 80.70%\n",
      "Run: 06, Epoch: 161, Loss: 0.2413, Train: 86.43%, Valid: 79.20% Test: 81.50%\n",
      "Run: 06, Epoch: 162, Loss: 0.3573, Train: 89.29%, Valid: 81.60% Test: 82.20%\n",
      "Run: 06, Epoch: 163, Loss: 0.3178, Train: 91.43%, Valid: 83.80% Test: 84.60%\n",
      "Run: 06, Epoch: 164, Loss: 0.2596, Train: 95.00%, Valid: 83.00% Test: 84.90%\n",
      "Run: 06, Epoch: 165, Loss: 0.2753, Train: 92.14%, Valid: 79.80% Test: 81.70%\n",
      "Run: 06, Epoch: 166, Loss: 0.2992, Train: 86.43%, Valid: 76.00% Test: 77.80%\n",
      "Run: 06, Epoch: 167, Loss: 0.2418, Train: 85.71%, Valid: 76.60% Test: 77.90%\n",
      "Run: 06, Epoch: 168, Loss: 0.3116, Train: 92.14%, Valid: 80.40% Test: 82.70%\n",
      "Run: 06, Epoch: 169, Loss: 0.2865, Train: 94.29%, Valid: 83.20% Test: 85.30%\n",
      "Run: 06, Epoch: 170, Loss: 0.2908, Train: 95.00%, Valid: 82.80% Test: 86.40%\n",
      "Run: 06, Epoch: 171, Loss: 0.2638, Train: 95.00%, Valid: 82.60% Test: 86.30%\n",
      "Run: 06, Epoch: 172, Loss: 0.2437, Train: 94.29%, Valid: 82.60% Test: 85.30%\n",
      "Run: 06, Epoch: 173, Loss: 0.2565, Train: 95.71%, Valid: 84.00% Test: 85.40%\n",
      "Run: 06, Epoch: 174, Loss: 0.2972, Train: 93.57%, Valid: 82.40% Test: 84.30%\n",
      "Run: 06, Epoch: 175, Loss: 0.2371, Train: 95.00%, Valid: 80.80% Test: 82.80%\n",
      "Run: 06, Epoch: 176, Loss: 0.2448, Train: 94.29%, Valid: 79.80% Test: 82.00%\n",
      "Run: 06, Epoch: 177, Loss: 0.3195, Train: 97.14%, Valid: 83.20% Test: 83.90%\n",
      "Run: 06, Epoch: 178, Loss: 0.2775, Train: 95.00%, Valid: 82.60% Test: 84.50%\n",
      "Run: 06, Epoch: 179, Loss: 0.2958, Train: 96.43%, Valid: 82.20% Test: 85.10%\n",
      "Run: 06, Epoch: 180, Loss: 0.2780, Train: 94.29%, Valid: 82.40% Test: 83.30%\n",
      "Run: 06, Epoch: 181, Loss: 0.2631, Train: 90.71%, Valid: 82.20% Test: 82.60%\n",
      "Run: 06, Epoch: 182, Loss: 0.2716, Train: 92.14%, Valid: 83.20% Test: 83.60%\n",
      "Run: 06, Epoch: 183, Loss: 0.2473, Train: 92.86%, Valid: 82.60% Test: 85.00%\n",
      "Run: 06, Epoch: 184, Loss: 0.2570, Train: 93.57%, Valid: 81.00% Test: 82.90%\n",
      "Run: 06, Epoch: 185, Loss: 0.2359, Train: 92.86%, Valid: 78.80% Test: 81.20%\n",
      "Run: 06, Epoch: 186, Loss: 0.2922, Train: 94.29%, Valid: 80.20% Test: 81.00%\n",
      "Run: 06, Epoch: 187, Loss: 0.2676, Train: 95.00%, Valid: 82.20% Test: 84.50%\n",
      "Run: 06, Epoch: 188, Loss: 0.2427, Train: 93.57%, Valid: 82.80% Test: 85.20%\n",
      "Run: 06, Epoch: 189, Loss: 0.2149, Train: 92.86%, Valid: 83.20% Test: 85.10%\n",
      "Run: 06, Epoch: 190, Loss: 0.2552, Train: 92.86%, Valid: 82.80% Test: 84.70%\n",
      "Run: 06, Epoch: 191, Loss: 0.2029, Train: 92.14%, Valid: 81.40% Test: 85.40%\n",
      "Run: 06, Epoch: 192, Loss: 0.3238, Train: 94.29%, Valid: 80.40% Test: 84.80%\n",
      "Run: 06, Epoch: 193, Loss: 0.2517, Train: 95.00%, Valid: 79.00% Test: 80.90%\n",
      "Run: 06, Epoch: 194, Loss: 0.3034, Train: 92.14%, Valid: 79.20% Test: 79.70%\n",
      "Run: 06, Epoch: 195, Loss: 0.2209, Train: 90.71%, Valid: 77.60% Test: 80.10%\n",
      "Run: 06, Epoch: 196, Loss: 0.2795, Train: 91.43%, Valid: 79.00% Test: 81.50%\n",
      "Run: 06, Epoch: 197, Loss: 0.2934, Train: 94.29%, Valid: 83.00% Test: 85.50%\n",
      "Run: 06, Epoch: 198, Loss: 0.2337, Train: 92.86%, Valid: 81.20% Test: 85.20%\n",
      "Run: 06, Epoch: 199, Loss: 0.3149, Train: 85.71%, Valid: 78.00% Test: 80.60%\n",
      "Run: 06, Epoch: 200, Loss: 0.2678, Train: 85.00%, Valid: 77.20% Test: 80.20%\n",
      "Run 06:\n",
      "Highest Train: 97.14\n",
      "Highest Valid: 84.00\n",
      "  Final Train: 95.71\n",
      "   Final Test: 85.40\n",
      "Run: 07, Epoch: 01, Loss: 2.2515, Train: 14.29%, Valid: 31.60% Test: 31.90%\n",
      "Run: 07, Epoch: 02, Loss: 2.2299, Train: 14.29%, Valid: 30.80% Test: 31.10%\n",
      "Run: 07, Epoch: 03, Loss: 2.0247, Train: 19.29%, Valid: 21.60% Test: 20.60%\n",
      "Run: 07, Epoch: 04, Loss: 1.9511, Train: 15.71%, Valid: 13.60% Test: 12.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 05, Loss: 1.8707, Train: 16.43%, Valid: 12.20% Test: 11.70%\n",
      "Run: 07, Epoch: 06, Loss: 1.8324, Train: 16.43%, Valid: 12.00% Test: 12.00%\n",
      "Run: 07, Epoch: 07, Loss: 1.7924, Train: 17.86%, Valid: 13.60% Test: 12.70%\n",
      "Run: 07, Epoch: 08, Loss: 1.7172, Train: 20.71%, Valid: 16.40% Test: 15.80%\n",
      "Run: 07, Epoch: 09, Loss: 1.7650, Train: 24.29%, Valid: 18.60% Test: 18.90%\n",
      "Run: 07, Epoch: 10, Loss: 1.6659, Train: 26.43%, Valid: 20.40% Test: 21.10%\n",
      "Run: 07, Epoch: 11, Loss: 1.6885, Train: 30.71%, Valid: 22.20% Test: 22.60%\n",
      "Run: 07, Epoch: 12, Loss: 1.6419, Train: 29.29%, Valid: 21.20% Test: 22.70%\n",
      "Run: 07, Epoch: 13, Loss: 1.5411, Train: 24.29%, Valid: 17.80% Test: 18.80%\n",
      "Run: 07, Epoch: 14, Loss: 1.5617, Train: 22.14%, Valid: 18.60% Test: 18.20%\n",
      "Run: 07, Epoch: 15, Loss: 1.5230, Train: 29.29%, Valid: 29.00% Test: 29.40%\n",
      "Run: 07, Epoch: 16, Loss: 1.3793, Train: 38.57%, Valid: 34.20% Test: 33.10%\n",
      "Run: 07, Epoch: 17, Loss: 1.4323, Train: 30.71%, Valid: 29.80% Test: 29.70%\n",
      "Run: 07, Epoch: 18, Loss: 1.4896, Train: 33.57%, Valid: 30.40% Test: 30.10%\n",
      "Run: 07, Epoch: 19, Loss: 1.3792, Train: 42.14%, Valid: 36.60% Test: 35.90%\n",
      "Run: 07, Epoch: 20, Loss: 1.3247, Train: 45.00%, Valid: 41.60% Test: 40.30%\n",
      "Run: 07, Epoch: 21, Loss: 1.2930, Train: 45.71%, Valid: 43.80% Test: 41.10%\n",
      "Run: 07, Epoch: 22, Loss: 1.2464, Train: 45.00%, Valid: 42.20% Test: 40.40%\n",
      "Run: 07, Epoch: 23, Loss: 1.2382, Train: 40.71%, Valid: 41.80% Test: 39.10%\n",
      "Run: 07, Epoch: 24, Loss: 1.1768, Train: 39.29%, Valid: 38.40% Test: 37.30%\n",
      "Run: 07, Epoch: 25, Loss: 1.1853, Train: 39.29%, Valid: 35.20% Test: 33.60%\n",
      "Run: 07, Epoch: 26, Loss: 1.1647, Train: 37.14%, Valid: 32.40% Test: 32.10%\n",
      "Run: 07, Epoch: 27, Loss: 1.0274, Train: 38.57%, Valid: 32.20% Test: 33.10%\n",
      "Run: 07, Epoch: 28, Loss: 1.0971, Train: 42.14%, Valid: 34.40% Test: 34.90%\n",
      "Run: 07, Epoch: 29, Loss: 1.0246, Train: 45.71%, Valid: 33.20% Test: 35.50%\n",
      "Run: 07, Epoch: 30, Loss: 0.9762, Train: 45.71%, Valid: 35.00% Test: 36.40%\n",
      "Run: 07, Epoch: 31, Loss: 0.8955, Train: 47.86%, Valid: 36.40% Test: 39.20%\n",
      "Run: 07, Epoch: 32, Loss: 0.9544, Train: 52.86%, Valid: 42.00% Test: 42.50%\n",
      "Run: 07, Epoch: 33, Loss: 0.9265, Train: 57.86%, Valid: 46.60% Test: 47.60%\n",
      "Run: 07, Epoch: 34, Loss: 0.9137, Train: 62.14%, Valid: 53.20% Test: 52.90%\n",
      "Run: 07, Epoch: 35, Loss: 0.9731, Train: 65.71%, Valid: 60.60% Test: 59.20%\n",
      "Run: 07, Epoch: 36, Loss: 0.8560, Train: 69.29%, Valid: 66.40% Test: 65.70%\n",
      "Run: 07, Epoch: 37, Loss: 0.8381, Train: 67.86%, Valid: 66.00% Test: 67.10%\n",
      "Run: 07, Epoch: 38, Loss: 0.7836, Train: 67.86%, Valid: 66.60% Test: 64.80%\n",
      "Run: 07, Epoch: 39, Loss: 0.7786, Train: 65.00%, Valid: 65.40% Test: 62.20%\n",
      "Run: 07, Epoch: 40, Loss: 0.7543, Train: 64.29%, Valid: 65.60% Test: 61.90%\n",
      "Run: 07, Epoch: 41, Loss: 0.7292, Train: 64.29%, Valid: 66.80% Test: 62.70%\n",
      "Run: 07, Epoch: 42, Loss: 0.7296, Train: 57.14%, Valid: 65.80% Test: 60.40%\n",
      "Run: 07, Epoch: 43, Loss: 0.6635, Train: 56.43%, Valid: 63.00% Test: 58.10%\n",
      "Run: 07, Epoch: 44, Loss: 0.7232, Train: 56.43%, Valid: 59.60% Test: 55.70%\n",
      "Run: 07, Epoch: 45, Loss: 0.6462, Train: 60.71%, Valid: 61.20% Test: 58.10%\n",
      "Run: 07, Epoch: 46, Loss: 0.6526, Train: 70.00%, Valid: 66.80% Test: 63.40%\n",
      "Run: 07, Epoch: 47, Loss: 0.6498, Train: 77.14%, Valid: 75.00% Test: 72.50%\n",
      "Run: 07, Epoch: 48, Loss: 0.6085, Train: 84.29%, Valid: 78.60% Test: 76.90%\n",
      "Run: 07, Epoch: 49, Loss: 0.6735, Train: 83.57%, Valid: 78.00% Test: 76.70%\n",
      "Run: 07, Epoch: 50, Loss: 0.5929, Train: 82.86%, Valid: 77.60% Test: 76.90%\n",
      "Run: 07, Epoch: 51, Loss: 0.5895, Train: 84.29%, Valid: 77.20% Test: 77.60%\n",
      "Run: 07, Epoch: 52, Loss: 0.5650, Train: 84.29%, Valid: 77.60% Test: 77.90%\n",
      "Run: 07, Epoch: 53, Loss: 0.5918, Train: 86.43%, Valid: 79.40% Test: 79.70%\n",
      "Run: 07, Epoch: 54, Loss: 0.5707, Train: 83.57%, Valid: 75.80% Test: 75.40%\n",
      "Run: 07, Epoch: 55, Loss: 0.5814, Train: 74.29%, Valid: 67.60% Test: 67.10%\n",
      "Run: 07, Epoch: 56, Loss: 0.5406, Train: 69.29%, Valid: 59.60% Test: 57.90%\n",
      "Run: 07, Epoch: 57, Loss: 0.5373, Train: 69.29%, Valid: 58.00% Test: 57.00%\n",
      "Run: 07, Epoch: 58, Loss: 0.5202, Train: 77.86%, Valid: 68.00% Test: 66.80%\n",
      "Run: 07, Epoch: 59, Loss: 0.5626, Train: 83.57%, Valid: 76.00% Test: 77.50%\n",
      "Run: 07, Epoch: 60, Loss: 0.5496, Train: 90.71%, Valid: 82.40% Test: 83.20%\n",
      "Run: 07, Epoch: 61, Loss: 0.5266, Train: 90.00%, Valid: 82.00% Test: 82.80%\n",
      "Run: 07, Epoch: 62, Loss: 0.5018, Train: 90.71%, Valid: 81.20% Test: 81.80%\n",
      "Run: 07, Epoch: 63, Loss: 0.5029, Train: 89.29%, Valid: 80.80% Test: 81.30%\n",
      "Run: 07, Epoch: 64, Loss: 0.5481, Train: 84.29%, Valid: 77.60% Test: 78.10%\n",
      "Run: 07, Epoch: 65, Loss: 0.4583, Train: 80.71%, Valid: 72.20% Test: 73.00%\n",
      "Run: 07, Epoch: 66, Loss: 0.5509, Train: 79.29%, Valid: 71.40% Test: 71.20%\n",
      "Run: 07, Epoch: 67, Loss: 0.5484, Train: 82.86%, Valid: 72.20% Test: 71.50%\n",
      "Run: 07, Epoch: 68, Loss: 0.5538, Train: 84.29%, Valid: 75.80% Test: 75.20%\n",
      "Run: 07, Epoch: 69, Loss: 0.4123, Train: 89.29%, Valid: 82.40% Test: 81.70%\n",
      "Run: 07, Epoch: 70, Loss: 0.4875, Train: 92.14%, Valid: 83.00% Test: 84.30%\n",
      "Run: 07, Epoch: 71, Loss: 0.4123, Train: 87.86%, Valid: 80.60% Test: 81.30%\n",
      "Run: 07, Epoch: 72, Loss: 0.4550, Train: 92.14%, Valid: 84.00% Test: 84.30%\n",
      "Run: 07, Epoch: 73, Loss: 0.4069, Train: 88.57%, Valid: 81.20% Test: 82.50%\n",
      "Run: 07, Epoch: 74, Loss: 0.4161, Train: 83.57%, Valid: 77.80% Test: 77.60%\n",
      "Run: 07, Epoch: 75, Loss: 0.4785, Train: 80.00%, Valid: 75.60% Test: 73.40%\n",
      "Run: 07, Epoch: 76, Loss: 0.3866, Train: 81.43%, Valid: 75.60% Test: 75.40%\n",
      "Run: 07, Epoch: 77, Loss: 0.3694, Train: 85.71%, Valid: 77.80% Test: 78.60%\n",
      "Run: 07, Epoch: 78, Loss: 0.4108, Train: 87.86%, Valid: 80.00% Test: 81.50%\n",
      "Run: 07, Epoch: 79, Loss: 0.4036, Train: 90.00%, Valid: 81.00% Test: 83.90%\n",
      "Run: 07, Epoch: 80, Loss: 0.3717, Train: 89.29%, Valid: 80.60% Test: 82.30%\n",
      "Run: 07, Epoch: 81, Loss: 0.3355, Train: 90.00%, Valid: 82.40% Test: 82.20%\n",
      "Run: 07, Epoch: 82, Loss: 0.4326, Train: 90.71%, Valid: 81.40% Test: 82.50%\n",
      "Run: 07, Epoch: 83, Loss: 0.4350, Train: 90.71%, Valid: 81.40% Test: 82.10%\n",
      "Run: 07, Epoch: 84, Loss: 0.3753, Train: 90.71%, Valid: 78.20% Test: 82.40%\n",
      "Run: 07, Epoch: 85, Loss: 0.3665, Train: 87.86%, Valid: 77.20% Test: 80.70%\n",
      "Run: 07, Epoch: 86, Loss: 0.3605, Train: 88.57%, Valid: 77.20% Test: 80.40%\n",
      "Run: 07, Epoch: 87, Loss: 0.4183, Train: 89.29%, Valid: 79.00% Test: 81.80%\n",
      "Run: 07, Epoch: 88, Loss: 0.3594, Train: 93.57%, Valid: 82.00% Test: 84.40%\n",
      "Run: 07, Epoch: 89, Loss: 0.3495, Train: 92.86%, Valid: 83.60% Test: 85.50%\n",
      "Run: 07, Epoch: 90, Loss: 0.3514, Train: 91.43%, Valid: 82.60% Test: 85.00%\n",
      "Run: 07, Epoch: 91, Loss: 0.4017, Train: 88.57%, Valid: 82.80% Test: 84.10%\n",
      "Run: 07, Epoch: 92, Loss: 0.3262, Train: 88.57%, Valid: 82.80% Test: 84.40%\n",
      "Run: 07, Epoch: 93, Loss: 0.3478, Train: 90.71%, Valid: 84.60% Test: 85.40%\n",
      "Run: 07, Epoch: 94, Loss: 0.3620, Train: 92.14%, Valid: 85.00% Test: 86.30%\n",
      "Run: 07, Epoch: 95, Loss: 0.4109, Train: 92.14%, Valid: 83.20% Test: 85.70%\n",
      "Run: 07, Epoch: 96, Loss: 0.3377, Train: 90.71%, Valid: 80.00% Test: 83.20%\n",
      "Run: 07, Epoch: 97, Loss: 0.3948, Train: 92.86%, Valid: 82.60% Test: 84.20%\n",
      "Run: 07, Epoch: 98, Loss: 0.4183, Train: 92.86%, Valid: 82.80% Test: 85.20%\n",
      "Run: 07, Epoch: 99, Loss: 0.3297, Train: 91.43%, Valid: 82.00% Test: 85.40%\n",
      "Run: 07, Epoch: 100, Loss: 0.3609, Train: 92.14%, Valid: 83.20% Test: 85.00%\n",
      "Run: 07, Epoch: 101, Loss: 0.2977, Train: 88.57%, Valid: 84.40% Test: 83.40%\n",
      "Run: 07, Epoch: 102, Loss: 0.3423, Train: 88.57%, Valid: 82.80% Test: 81.30%\n",
      "Run: 07, Epoch: 103, Loss: 0.3472, Train: 88.57%, Valid: 82.00% Test: 81.30%\n",
      "Run: 07, Epoch: 104, Loss: 0.3504, Train: 85.71%, Valid: 81.20% Test: 81.20%\n",
      "Run: 07, Epoch: 105, Loss: 0.3564, Train: 86.43%, Valid: 82.20% Test: 82.20%\n",
      "Run: 07, Epoch: 106, Loss: 0.3601, Train: 86.43%, Valid: 83.00% Test: 83.30%\n",
      "Run: 07, Epoch: 107, Loss: 0.3435, Train: 92.14%, Valid: 83.60% Test: 84.70%\n",
      "Run: 07, Epoch: 108, Loss: 0.3163, Train: 95.00%, Valid: 84.40% Test: 86.00%\n",
      "Run: 07, Epoch: 109, Loss: 0.3352, Train: 92.14%, Valid: 80.60% Test: 84.50%\n",
      "Run: 07, Epoch: 110, Loss: 0.3148, Train: 89.29%, Valid: 80.00% Test: 83.40%\n",
      "Run: 07, Epoch: 111, Loss: 0.3531, Train: 87.86%, Valid: 78.60% Test: 82.30%\n",
      "Run: 07, Epoch: 112, Loss: 0.3478, Train: 86.43%, Valid: 78.60% Test: 80.00%\n",
      "Run: 07, Epoch: 113, Loss: 0.2896, Train: 88.57%, Valid: 78.00% Test: 78.30%\n",
      "Run: 07, Epoch: 114, Loss: 0.2984, Train: 89.29%, Valid: 79.40% Test: 79.00%\n",
      "Run: 07, Epoch: 115, Loss: 0.3485, Train: 87.14%, Valid: 75.40% Test: 75.40%\n",
      "Run: 07, Epoch: 116, Loss: 0.3832, Train: 83.57%, Valid: 71.00% Test: 72.00%\n",
      "Run: 07, Epoch: 117, Loss: 0.2872, Train: 82.14%, Valid: 70.80% Test: 70.80%\n",
      "Run: 07, Epoch: 118, Loss: 0.3206, Train: 83.57%, Valid: 76.80% Test: 76.80%\n",
      "Run: 07, Epoch: 119, Loss: 0.3269, Train: 87.86%, Valid: 81.80% Test: 82.80%\n",
      "Run: 07, Epoch: 120, Loss: 0.3533, Train: 91.43%, Valid: 84.60% Test: 86.70%\n",
      "Run: 07, Epoch: 121, Loss: 0.2446, Train: 89.29%, Valid: 82.20% Test: 83.40%\n",
      "Run: 07, Epoch: 122, Loss: 0.3735, Train: 79.29%, Valid: 79.40% Test: 81.00%\n",
      "Run: 07, Epoch: 123, Loss: 0.3189, Train: 80.00%, Valid: 77.40% Test: 78.80%\n",
      "Run: 07, Epoch: 124, Loss: 0.2890, Train: 83.57%, Valid: 76.20% Test: 78.90%\n",
      "Run: 07, Epoch: 125, Loss: 0.2923, Train: 87.14%, Valid: 80.00% Test: 82.00%\n",
      "Run: 07, Epoch: 126, Loss: 0.3284, Train: 93.57%, Valid: 84.00% Test: 84.40%\n",
      "Run: 07, Epoch: 127, Loss: 0.2374, Train: 89.29%, Valid: 80.80% Test: 82.10%\n",
      "Run: 07, Epoch: 128, Loss: 0.3083, Train: 86.43%, Valid: 76.00% Test: 76.30%\n",
      "Run: 07, Epoch: 129, Loss: 0.2935, Train: 85.00%, Valid: 75.20% Test: 75.30%\n",
      "Run: 07, Epoch: 130, Loss: 0.2465, Train: 92.14%, Valid: 77.80% Test: 79.30%\n",
      "Run: 07, Epoch: 131, Loss: 0.2992, Train: 91.43%, Valid: 80.60% Test: 81.90%\n",
      "Run: 07, Epoch: 132, Loss: 0.3156, Train: 94.29%, Valid: 80.80% Test: 83.70%\n",
      "Run: 07, Epoch: 133, Loss: 0.3259, Train: 93.57%, Valid: 79.80% Test: 84.20%\n",
      "Run: 07, Epoch: 134, Loss: 0.3033, Train: 92.14%, Valid: 79.80% Test: 83.70%\n",
      "Run: 07, Epoch: 135, Loss: 0.2333, Train: 90.00%, Valid: 79.00% Test: 81.90%\n",
      "Run: 07, Epoch: 136, Loss: 0.2926, Train: 85.71%, Valid: 78.40% Test: 80.70%\n",
      "Run: 07, Epoch: 137, Loss: 0.2712, Train: 92.14%, Valid: 81.00% Test: 83.90%\n",
      "Run: 07, Epoch: 138, Loss: 0.2945, Train: 95.71%, Valid: 83.20% Test: 85.20%\n",
      "Run: 07, Epoch: 139, Loss: 0.3128, Train: 91.43%, Valid: 82.00% Test: 83.40%\n",
      "Run: 07, Epoch: 140, Loss: 0.3052, Train: 90.00%, Valid: 81.60% Test: 81.70%\n",
      "Run: 07, Epoch: 141, Loss: 0.2683, Train: 91.43%, Valid: 80.20% Test: 82.20%\n",
      "Run: 07, Epoch: 142, Loss: 0.2223, Train: 90.00%, Valid: 78.80% Test: 80.50%\n",
      "Run: 07, Epoch: 143, Loss: 0.2804, Train: 86.43%, Valid: 73.60% Test: 75.60%\n",
      "Run: 07, Epoch: 144, Loss: 0.3310, Train: 87.14%, Valid: 77.20% Test: 78.70%\n",
      "Run: 07, Epoch: 145, Loss: 0.3114, Train: 92.14%, Valid: 80.40% Test: 81.70%\n",
      "Run: 07, Epoch: 146, Loss: 0.2206, Train: 92.86%, Valid: 79.20% Test: 81.50%\n",
      "Run: 07, Epoch: 147, Loss: 0.3057, Train: 87.86%, Valid: 74.00% Test: 76.20%\n",
      "Run: 07, Epoch: 148, Loss: 0.2875, Train: 83.57%, Valid: 69.80% Test: 73.30%\n",
      "Run: 07, Epoch: 149, Loss: 0.2853, Train: 87.14%, Valid: 75.40% Test: 76.60%\n",
      "Run: 07, Epoch: 150, Loss: 0.2784, Train: 90.00%, Valid: 79.20% Test: 81.60%\n",
      "Run: 07, Epoch: 151, Loss: 0.2270, Train: 93.57%, Valid: 81.60% Test: 84.40%\n",
      "Run: 07, Epoch: 152, Loss: 0.2427, Train: 93.57%, Valid: 83.00% Test: 83.80%\n",
      "Run: 07, Epoch: 153, Loss: 0.2592, Train: 92.86%, Valid: 82.60% Test: 82.90%\n",
      "Run: 07, Epoch: 154, Loss: 0.2472, Train: 91.43%, Valid: 81.00% Test: 82.80%\n",
      "Run: 07, Epoch: 155, Loss: 0.2564, Train: 90.71%, Valid: 80.20% Test: 81.50%\n",
      "Run: 07, Epoch: 156, Loss: 0.2772, Train: 90.71%, Valid: 81.20% Test: 82.20%\n",
      "Run: 07, Epoch: 157, Loss: 0.2190, Train: 91.43%, Valid: 81.60% Test: 81.90%\n",
      "Run: 07, Epoch: 158, Loss: 0.2065, Train: 90.71%, Valid: 81.40% Test: 82.80%\n",
      "Run: 07, Epoch: 159, Loss: 0.3220, Train: 92.86%, Valid: 82.80% Test: 85.00%\n",
      "Run: 07, Epoch: 160, Loss: 0.2276, Train: 95.00%, Valid: 84.00% Test: 84.50%\n",
      "Run: 07, Epoch: 161, Loss: 0.2264, Train: 88.57%, Valid: 81.20% Test: 82.00%\n",
      "Run: 07, Epoch: 162, Loss: 0.1811, Train: 83.57%, Valid: 75.20% Test: 76.60%\n",
      "Run: 07, Epoch: 163, Loss: 0.2393, Train: 80.00%, Valid: 70.80% Test: 74.10%\n",
      "Run: 07, Epoch: 164, Loss: 0.2698, Train: 80.71%, Valid: 73.40% Test: 76.30%\n",
      "Run: 07, Epoch: 165, Loss: 0.2598, Train: 88.57%, Valid: 78.80% Test: 81.20%\n",
      "Run: 07, Epoch: 166, Loss: 0.2267, Train: 90.71%, Valid: 79.80% Test: 81.20%\n",
      "Run: 07, Epoch: 167, Loss: 0.3012, Train: 91.43%, Valid: 80.00% Test: 82.40%\n",
      "Run: 07, Epoch: 168, Loss: 0.2487, Train: 92.14%, Valid: 82.00% Test: 81.90%\n",
      "Run: 07, Epoch: 169, Loss: 0.2629, Train: 91.43%, Valid: 83.40% Test: 81.60%\n",
      "Run: 07, Epoch: 170, Loss: 0.2395, Train: 85.71%, Valid: 81.20% Test: 79.00%\n",
      "Run: 07, Epoch: 171, Loss: 0.2026, Train: 78.57%, Valid: 79.80% Test: 77.70%\n",
      "Run: 07, Epoch: 172, Loss: 0.2412, Train: 78.57%, Valid: 77.60% Test: 76.10%\n",
      "Run: 07, Epoch: 173, Loss: 0.2599, Train: 84.29%, Valid: 79.80% Test: 78.70%\n",
      "Run: 07, Epoch: 174, Loss: 0.2106, Train: 90.00%, Valid: 82.40% Test: 82.20%\n",
      "Run: 07, Epoch: 175, Loss: 0.2993, Train: 90.00%, Valid: 82.80% Test: 83.00%\n",
      "Run: 07, Epoch: 176, Loss: 0.3099, Train: 86.43%, Valid: 79.40% Test: 79.40%\n",
      "Run: 07, Epoch: 177, Loss: 0.2055, Train: 78.57%, Valid: 74.00% Test: 74.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 178, Loss: 0.3049, Train: 77.86%, Valid: 71.20% Test: 71.70%\n",
      "Run: 07, Epoch: 179, Loss: 0.2883, Train: 83.57%, Valid: 74.80% Test: 76.80%\n",
      "Run: 07, Epoch: 180, Loss: 0.2624, Train: 91.43%, Valid: 79.20% Test: 81.50%\n",
      "Run: 07, Epoch: 181, Loss: 0.2930, Train: 92.86%, Valid: 82.20% Test: 84.10%\n",
      "Run: 07, Epoch: 182, Loss: 0.2315, Train: 90.71%, Valid: 81.40% Test: 83.00%\n",
      "Run: 07, Epoch: 183, Loss: 0.2218, Train: 89.29%, Valid: 79.20% Test: 80.20%\n",
      "Run: 07, Epoch: 184, Loss: 0.2306, Train: 89.29%, Valid: 79.80% Test: 80.20%\n",
      "Run: 07, Epoch: 185, Loss: 0.2466, Train: 93.57%, Valid: 83.60% Test: 82.90%\n",
      "Run: 07, Epoch: 186, Loss: 0.2292, Train: 87.14%, Valid: 78.20% Test: 78.20%\n",
      "Run: 07, Epoch: 187, Loss: 0.1903, Train: 86.43%, Valid: 76.60% Test: 76.70%\n",
      "Run: 07, Epoch: 188, Loss: 0.2488, Train: 92.86%, Valid: 82.20% Test: 82.10%\n",
      "Run: 07, Epoch: 189, Loss: 0.3013, Train: 94.29%, Valid: 82.80% Test: 83.50%\n",
      "Run: 07, Epoch: 190, Loss: 0.1960, Train: 91.43%, Valid: 79.80% Test: 79.60%\n",
      "Run: 07, Epoch: 191, Loss: 0.2085, Train: 87.86%, Valid: 76.80% Test: 76.40%\n",
      "Run: 07, Epoch: 192, Loss: 0.1525, Train: 85.00%, Valid: 75.00% Test: 76.40%\n",
      "Run: 07, Epoch: 193, Loss: 0.1721, Train: 85.71%, Valid: 75.80% Test: 76.60%\n",
      "Run: 07, Epoch: 194, Loss: 0.2149, Train: 86.43%, Valid: 76.00% Test: 77.70%\n",
      "Run: 07, Epoch: 195, Loss: 0.2838, Train: 90.00%, Valid: 79.40% Test: 80.40%\n",
      "Run: 07, Epoch: 196, Loss: 0.1997, Train: 91.43%, Valid: 79.80% Test: 81.60%\n",
      "Run: 07, Epoch: 197, Loss: 0.2106, Train: 91.43%, Valid: 78.20% Test: 83.00%\n",
      "Run: 07, Epoch: 198, Loss: 0.2450, Train: 88.57%, Valid: 76.20% Test: 79.80%\n",
      "Run: 07, Epoch: 199, Loss: 0.1636, Train: 87.14%, Valid: 71.60% Test: 75.70%\n",
      "Run: 07, Epoch: 200, Loss: 0.2648, Train: 82.86%, Valid: 69.80% Test: 73.10%\n",
      "Run 07:\n",
      "Highest Train: 95.71\n",
      "Highest Valid: 85.00\n",
      "  Final Train: 92.14\n",
      "   Final Test: 86.30\n",
      "Run: 08, Epoch: 01, Loss: 2.1112, Train: 17.14%, Valid: 15.40% Test: 14.90%\n",
      "Run: 08, Epoch: 02, Loss: 2.0835, Train: 17.14%, Valid: 15.40% Test: 15.40%\n",
      "Run: 08, Epoch: 03, Loss: 1.9877, Train: 18.57%, Valid: 16.60% Test: 16.50%\n",
      "Run: 08, Epoch: 04, Loss: 2.0056, Train: 16.43%, Valid: 11.20% Test: 11.50%\n",
      "Run: 08, Epoch: 05, Loss: 1.8816, Train: 23.57%, Valid: 16.60% Test: 17.20%\n",
      "Run: 08, Epoch: 06, Loss: 1.8224, Train: 22.86%, Valid: 17.80% Test: 19.00%\n",
      "Run: 08, Epoch: 07, Loss: 1.7823, Train: 25.71%, Valid: 21.00% Test: 21.60%\n",
      "Run: 08, Epoch: 08, Loss: 1.8025, Train: 30.00%, Valid: 29.60% Test: 33.00%\n",
      "Run: 08, Epoch: 09, Loss: 1.7708, Train: 29.29%, Valid: 31.20% Test: 34.70%\n",
      "Run: 08, Epoch: 10, Loss: 1.7160, Train: 22.86%, Valid: 28.20% Test: 30.10%\n",
      "Run: 08, Epoch: 11, Loss: 1.6616, Train: 22.86%, Valid: 28.20% Test: 30.50%\n",
      "Run: 08, Epoch: 12, Loss: 1.6660, Train: 29.29%, Valid: 30.00% Test: 31.70%\n",
      "Run: 08, Epoch: 13, Loss: 1.6131, Train: 25.71%, Valid: 26.60% Test: 27.80%\n",
      "Run: 08, Epoch: 14, Loss: 1.5629, Train: 24.29%, Valid: 22.00% Test: 22.70%\n",
      "Run: 08, Epoch: 15, Loss: 1.4984, Train: 24.29%, Valid: 21.80% Test: 21.60%\n",
      "Run: 08, Epoch: 16, Loss: 1.5175, Train: 23.57%, Valid: 21.60% Test: 21.70%\n",
      "Run: 08, Epoch: 17, Loss: 1.4876, Train: 23.57%, Valid: 21.60% Test: 22.00%\n",
      "Run: 08, Epoch: 18, Loss: 1.4949, Train: 25.00%, Valid: 22.40% Test: 22.80%\n",
      "Run: 08, Epoch: 19, Loss: 1.3697, Train: 25.71%, Valid: 23.40% Test: 23.90%\n",
      "Run: 08, Epoch: 20, Loss: 1.4129, Train: 32.14%, Valid: 26.60% Test: 26.60%\n",
      "Run: 08, Epoch: 21, Loss: 1.3965, Train: 41.43%, Valid: 32.40% Test: 32.30%\n",
      "Run: 08, Epoch: 22, Loss: 1.3211, Train: 54.29%, Valid: 42.40% Test: 43.00%\n",
      "Run: 08, Epoch: 23, Loss: 1.2984, Train: 53.57%, Valid: 46.40% Test: 46.50%\n",
      "Run: 08, Epoch: 24, Loss: 1.3263, Train: 51.43%, Valid: 42.20% Test: 43.60%\n",
      "Run: 08, Epoch: 25, Loss: 1.2753, Train: 50.00%, Valid: 40.80% Test: 42.00%\n",
      "Run: 08, Epoch: 26, Loss: 1.1899, Train: 48.57%, Valid: 40.20% Test: 41.20%\n",
      "Run: 08, Epoch: 27, Loss: 1.2069, Train: 47.14%, Valid: 40.40% Test: 40.20%\n",
      "Run: 08, Epoch: 28, Loss: 1.1900, Train: 51.43%, Valid: 41.60% Test: 42.00%\n",
      "Run: 08, Epoch: 29, Loss: 1.1414, Train: 49.29%, Valid: 41.60% Test: 42.20%\n",
      "Run: 08, Epoch: 30, Loss: 1.0571, Train: 46.43%, Valid: 40.40% Test: 40.80%\n",
      "Run: 08, Epoch: 31, Loss: 1.1154, Train: 47.86%, Valid: 40.60% Test: 42.70%\n",
      "Run: 08, Epoch: 32, Loss: 1.0832, Train: 46.43%, Valid: 47.20% Test: 46.10%\n",
      "Run: 08, Epoch: 33, Loss: 1.0656, Train: 50.71%, Valid: 52.00% Test: 51.90%\n",
      "Run: 08, Epoch: 34, Loss: 1.0166, Train: 56.43%, Valid: 60.00% Test: 59.50%\n",
      "Run: 08, Epoch: 35, Loss: 0.9838, Train: 69.29%, Valid: 66.00% Test: 66.10%\n",
      "Run: 08, Epoch: 36, Loss: 1.0003, Train: 70.00%, Valid: 64.40% Test: 65.50%\n",
      "Run: 08, Epoch: 37, Loss: 0.9403, Train: 67.14%, Valid: 61.20% Test: 61.50%\n",
      "Run: 08, Epoch: 38, Loss: 0.9007, Train: 65.00%, Valid: 59.20% Test: 60.80%\n",
      "Run: 08, Epoch: 39, Loss: 0.8312, Train: 62.14%, Valid: 57.00% Test: 57.30%\n",
      "Run: 08, Epoch: 40, Loss: 0.9392, Train: 62.86%, Valid: 53.80% Test: 53.80%\n",
      "Run: 08, Epoch: 41, Loss: 0.8217, Train: 64.29%, Valid: 55.80% Test: 57.40%\n",
      "Run: 08, Epoch: 42, Loss: 0.8546, Train: 65.71%, Valid: 60.00% Test: 62.10%\n",
      "Run: 08, Epoch: 43, Loss: 0.8396, Train: 70.71%, Valid: 66.20% Test: 67.40%\n",
      "Run: 08, Epoch: 44, Loss: 0.8001, Train: 74.29%, Valid: 72.80% Test: 73.50%\n",
      "Run: 08, Epoch: 45, Loss: 0.8009, Train: 75.71%, Valid: 77.60% Test: 75.80%\n",
      "Run: 08, Epoch: 46, Loss: 0.8140, Train: 80.71%, Valid: 78.00% Test: 77.40%\n",
      "Run: 08, Epoch: 47, Loss: 0.8036, Train: 82.86%, Valid: 76.00% Test: 74.90%\n",
      "Run: 08, Epoch: 48, Loss: 0.7943, Train: 80.71%, Valid: 72.60% Test: 72.90%\n",
      "Run: 08, Epoch: 49, Loss: 0.7548, Train: 75.71%, Valid: 68.80% Test: 70.60%\n",
      "Run: 08, Epoch: 50, Loss: 0.7619, Train: 78.57%, Valid: 66.20% Test: 69.50%\n",
      "Run: 08, Epoch: 51, Loss: 0.7550, Train: 80.00%, Valid: 65.60% Test: 68.70%\n",
      "Run: 08, Epoch: 52, Loss: 0.7524, Train: 74.29%, Valid: 63.20% Test: 67.20%\n",
      "Run: 08, Epoch: 53, Loss: 0.6971, Train: 75.00%, Valid: 65.80% Test: 67.80%\n",
      "Run: 08, Epoch: 54, Loss: 0.7245, Train: 75.00%, Valid: 70.00% Test: 71.50%\n",
      "Run: 08, Epoch: 55, Loss: 0.6940, Train: 80.00%, Valid: 74.00% Test: 74.00%\n",
      "Run: 08, Epoch: 56, Loss: 0.6272, Train: 77.86%, Valid: 74.00% Test: 72.70%\n",
      "Run: 08, Epoch: 57, Loss: 0.7154, Train: 75.71%, Valid: 75.40% Test: 73.70%\n",
      "Run: 08, Epoch: 58, Loss: 0.7067, Train: 78.57%, Valid: 77.40% Test: 75.70%\n",
      "Run: 08, Epoch: 59, Loss: 0.6287, Train: 84.29%, Valid: 78.00% Test: 77.90%\n",
      "Run: 08, Epoch: 60, Loss: 0.6421, Train: 85.71%, Valid: 78.60% Test: 78.80%\n",
      "Run: 08, Epoch: 61, Loss: 0.6689, Train: 86.43%, Valid: 77.80% Test: 78.50%\n",
      "Run: 08, Epoch: 62, Loss: 0.6193, Train: 85.71%, Valid: 77.40% Test: 78.30%\n",
      "Run: 08, Epoch: 63, Loss: 0.6007, Train: 83.57%, Valid: 76.60% Test: 77.00%\n",
      "Run: 08, Epoch: 64, Loss: 0.5453, Train: 83.57%, Valid: 76.60% Test: 76.90%\n",
      "Run: 08, Epoch: 65, Loss: 0.5332, Train: 82.14%, Valid: 76.20% Test: 75.80%\n",
      "Run: 08, Epoch: 66, Loss: 0.5934, Train: 82.86%, Valid: 75.40% Test: 76.10%\n",
      "Run: 08, Epoch: 67, Loss: 0.5540, Train: 82.86%, Valid: 74.40% Test: 75.20%\n",
      "Run: 08, Epoch: 68, Loss: 0.5569, Train: 85.00%, Valid: 76.00% Test: 76.40%\n",
      "Run: 08, Epoch: 69, Loss: 0.6231, Train: 87.14%, Valid: 76.60% Test: 77.00%\n",
      "Run: 08, Epoch: 70, Loss: 0.5388, Train: 87.14%, Valid: 79.20% Test: 78.80%\n",
      "Run: 08, Epoch: 71, Loss: 0.5632, Train: 86.43%, Valid: 80.80% Test: 80.80%\n",
      "Run: 08, Epoch: 72, Loss: 0.5835, Train: 85.71%, Valid: 81.40% Test: 82.90%\n",
      "Run: 08, Epoch: 73, Loss: 0.5867, Train: 85.00%, Valid: 81.60% Test: 83.50%\n",
      "Run: 08, Epoch: 74, Loss: 0.5874, Train: 87.86%, Valid: 83.20% Test: 82.60%\n",
      "Run: 08, Epoch: 75, Loss: 0.5031, Train: 84.29%, Valid: 77.60% Test: 78.00%\n",
      "Run: 08, Epoch: 76, Loss: 0.5809, Train: 87.86%, Valid: 80.20% Test: 80.70%\n",
      "Run: 08, Epoch: 77, Loss: 0.4753, Train: 89.29%, Valid: 80.00% Test: 81.40%\n",
      "Run: 08, Epoch: 78, Loss: 0.5618, Train: 87.86%, Valid: 79.40% Test: 80.10%\n",
      "Run: 08, Epoch: 79, Loss: 0.4858, Train: 87.14%, Valid: 77.80% Test: 77.50%\n",
      "Run: 08, Epoch: 80, Loss: 0.5977, Train: 83.57%, Valid: 72.60% Test: 73.60%\n",
      "Run: 08, Epoch: 81, Loss: 0.5040, Train: 78.57%, Valid: 66.80% Test: 69.50%\n",
      "Run: 08, Epoch: 82, Loss: 0.4858, Train: 80.71%, Valid: 68.80% Test: 69.60%\n",
      "Run: 08, Epoch: 83, Loss: 0.5209, Train: 86.43%, Valid: 78.00% Test: 78.40%\n",
      "Run: 08, Epoch: 84, Loss: 0.5147, Train: 90.71%, Valid: 80.60% Test: 82.10%\n",
      "Run: 08, Epoch: 85, Loss: 0.5233, Train: 86.43%, Valid: 75.80% Test: 78.20%\n",
      "Run: 08, Epoch: 86, Loss: 0.4918, Train: 81.43%, Valid: 72.60% Test: 74.50%\n",
      "Run: 08, Epoch: 87, Loss: 0.5309, Train: 85.00%, Valid: 74.40% Test: 77.20%\n",
      "Run: 08, Epoch: 88, Loss: 0.4502, Train: 87.14%, Valid: 77.60% Test: 79.70%\n",
      "Run: 08, Epoch: 89, Loss: 0.4919, Train: 89.29%, Valid: 81.60% Test: 81.80%\n",
      "Run: 08, Epoch: 90, Loss: 0.5374, Train: 90.71%, Valid: 82.20% Test: 81.20%\n",
      "Run: 08, Epoch: 91, Loss: 0.4731, Train: 89.29%, Valid: 82.00% Test: 81.40%\n",
      "Run: 08, Epoch: 92, Loss: 0.5100, Train: 89.29%, Valid: 79.40% Test: 82.00%\n",
      "Run: 08, Epoch: 93, Loss: 0.4405, Train: 82.86%, Valid: 78.60% Test: 78.70%\n",
      "Run: 08, Epoch: 94, Loss: 0.4593, Train: 88.57%, Valid: 78.60% Test: 81.30%\n",
      "Run: 08, Epoch: 95, Loss: 0.4641, Train: 89.29%, Valid: 80.00% Test: 82.20%\n",
      "Run: 08, Epoch: 96, Loss: 0.4135, Train: 88.57%, Valid: 78.80% Test: 82.40%\n",
      "Run: 08, Epoch: 97, Loss: 0.4177, Train: 88.57%, Valid: 79.60% Test: 82.40%\n",
      "Run: 08, Epoch: 98, Loss: 0.5383, Train: 87.14%, Valid: 79.40% Test: 80.40%\n",
      "Run: 08, Epoch: 99, Loss: 0.4709, Train: 88.57%, Valid: 79.80% Test: 80.10%\n",
      "Run: 08, Epoch: 100, Loss: 0.4443, Train: 90.71%, Valid: 81.40% Test: 80.20%\n",
      "Run: 08, Epoch: 101, Loss: 0.4169, Train: 91.43%, Valid: 79.60% Test: 80.50%\n",
      "Run: 08, Epoch: 102, Loss: 0.4635, Train: 90.71%, Valid: 79.60% Test: 81.10%\n",
      "Run: 08, Epoch: 103, Loss: 0.4362, Train: 90.00%, Valid: 81.20% Test: 82.00%\n",
      "Run: 08, Epoch: 104, Loss: 0.3909, Train: 91.43%, Valid: 80.40% Test: 81.70%\n",
      "Run: 08, Epoch: 105, Loss: 0.4550, Train: 90.71%, Valid: 81.20% Test: 80.90%\n",
      "Run: 08, Epoch: 106, Loss: 0.4103, Train: 90.00%, Valid: 80.40% Test: 80.80%\n",
      "Run: 08, Epoch: 107, Loss: 0.3868, Train: 90.00%, Valid: 79.00% Test: 80.10%\n",
      "Run: 08, Epoch: 108, Loss: 0.4155, Train: 90.71%, Valid: 78.80% Test: 81.80%\n",
      "Run: 08, Epoch: 109, Loss: 0.3970, Train: 90.71%, Valid: 79.40% Test: 82.40%\n",
      "Run: 08, Epoch: 110, Loss: 0.4270, Train: 90.71%, Valid: 80.20% Test: 82.90%\n",
      "Run: 08, Epoch: 111, Loss: 0.4299, Train: 92.14%, Valid: 80.80% Test: 82.30%\n",
      "Run: 08, Epoch: 112, Loss: 0.4153, Train: 92.14%, Valid: 80.20% Test: 81.30%\n",
      "Run: 08, Epoch: 113, Loss: 0.3959, Train: 92.14%, Valid: 80.60% Test: 81.90%\n",
      "Run: 08, Epoch: 114, Loss: 0.4103, Train: 92.86%, Valid: 82.40% Test: 83.20%\n",
      "Run: 08, Epoch: 115, Loss: 0.3612, Train: 92.14%, Valid: 82.00% Test: 83.60%\n",
      "Run: 08, Epoch: 116, Loss: 0.4540, Train: 90.71%, Valid: 81.60% Test: 81.80%\n",
      "Run: 08, Epoch: 117, Loss: 0.4176, Train: 88.57%, Valid: 80.80% Test: 79.80%\n",
      "Run: 08, Epoch: 118, Loss: 0.3813, Train: 87.86%, Valid: 76.60% Test: 76.80%\n",
      "Run: 08, Epoch: 119, Loss: 0.4273, Train: 85.71%, Valid: 75.00% Test: 75.60%\n",
      "Run: 08, Epoch: 120, Loss: 0.3953, Train: 86.43%, Valid: 74.20% Test: 75.80%\n",
      "Run: 08, Epoch: 121, Loss: 0.3798, Train: 82.86%, Valid: 75.40% Test: 75.80%\n",
      "Run: 08, Epoch: 122, Loss: 0.3881, Train: 84.29%, Valid: 76.00% Test: 77.20%\n",
      "Run: 08, Epoch: 123, Loss: 0.3615, Train: 80.00%, Valid: 74.60% Test: 75.80%\n",
      "Run: 08, Epoch: 124, Loss: 0.4768, Train: 85.71%, Valid: 76.80% Test: 78.30%\n",
      "Run: 08, Epoch: 125, Loss: 0.3707, Train: 87.14%, Valid: 79.80% Test: 80.60%\n",
      "Run: 08, Epoch: 126, Loss: 0.3697, Train: 90.00%, Valid: 81.80% Test: 81.70%\n",
      "Run: 08, Epoch: 127, Loss: 0.3400, Train: 89.29%, Valid: 81.00% Test: 83.30%\n",
      "Run: 08, Epoch: 128, Loss: 0.3820, Train: 89.29%, Valid: 80.60% Test: 80.20%\n",
      "Run: 08, Epoch: 129, Loss: 0.3359, Train: 86.43%, Valid: 77.80% Test: 78.50%\n",
      "Run: 08, Epoch: 130, Loss: 0.3547, Train: 85.00%, Valid: 76.40% Test: 75.60%\n",
      "Run: 08, Epoch: 131, Loss: 0.3513, Train: 85.71%, Valid: 75.80% Test: 75.20%\n",
      "Run: 08, Epoch: 132, Loss: 0.3085, Train: 87.14%, Valid: 78.20% Test: 77.30%\n",
      "Run: 08, Epoch: 133, Loss: 0.3896, Train: 88.57%, Valid: 80.40% Test: 79.80%\n",
      "Run: 08, Epoch: 134, Loss: 0.4042, Train: 90.00%, Valid: 82.20% Test: 83.40%\n",
      "Run: 08, Epoch: 135, Loss: 0.3151, Train: 91.43%, Valid: 81.60% Test: 83.60%\n",
      "Run: 08, Epoch: 136, Loss: 0.3468, Train: 91.43%, Valid: 80.80% Test: 83.50%\n",
      "Run: 08, Epoch: 137, Loss: 0.3918, Train: 88.57%, Valid: 80.20% Test: 83.20%\n",
      "Run: 08, Epoch: 138, Loss: 0.3900, Train: 90.71%, Valid: 81.00% Test: 83.90%\n",
      "Run: 08, Epoch: 139, Loss: 0.4011, Train: 90.71%, Valid: 80.80% Test: 83.30%\n",
      "Run: 08, Epoch: 140, Loss: 0.3621, Train: 90.71%, Valid: 80.00% Test: 80.50%\n",
      "Run: 08, Epoch: 141, Loss: 0.3365, Train: 90.00%, Valid: 76.60% Test: 76.50%\n",
      "Run: 08, Epoch: 142, Loss: 0.3422, Train: 89.29%, Valid: 76.60% Test: 75.20%\n",
      "Run: 08, Epoch: 143, Loss: 0.2965, Train: 88.57%, Valid: 77.40% Test: 77.30%\n",
      "Run: 08, Epoch: 144, Loss: 0.2971, Train: 88.57%, Valid: 79.20% Test: 79.40%\n",
      "Run: 08, Epoch: 145, Loss: 0.3439, Train: 93.57%, Valid: 81.40% Test: 82.00%\n",
      "Run: 08, Epoch: 146, Loss: 0.3157, Train: 90.71%, Valid: 79.40% Test: 80.30%\n",
      "Run: 08, Epoch: 147, Loss: 0.3706, Train: 90.71%, Valid: 80.20% Test: 81.20%\n",
      "Run: 08, Epoch: 148, Loss: 0.3218, Train: 87.14%, Valid: 79.80% Test: 81.20%\n",
      "Run: 08, Epoch: 149, Loss: 0.3640, Train: 87.14%, Valid: 77.80% Test: 79.40%\n",
      "Run: 08, Epoch: 150, Loss: 0.4043, Train: 84.29%, Valid: 76.40% Test: 77.70%\n",
      "Run: 08, Epoch: 151, Loss: 0.3541, Train: 85.71%, Valid: 74.40% Test: 75.90%\n",
      "Run: 08, Epoch: 152, Loss: 0.3661, Train: 87.86%, Valid: 76.40% Test: 78.60%\n",
      "Run: 08, Epoch: 153, Loss: 0.3360, Train: 91.43%, Valid: 80.40% Test: 81.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 154, Loss: 0.3694, Train: 90.00%, Valid: 82.80% Test: 84.10%\n",
      "Run: 08, Epoch: 155, Loss: 0.3541, Train: 85.71%, Valid: 78.40% Test: 78.60%\n",
      "Run: 08, Epoch: 156, Loss: 0.3155, Train: 83.57%, Valid: 76.60% Test: 76.30%\n",
      "Run: 08, Epoch: 157, Loss: 0.3511, Train: 82.86%, Valid: 76.60% Test: 76.70%\n",
      "Run: 08, Epoch: 158, Loss: 0.3057, Train: 85.71%, Valid: 80.40% Test: 79.80%\n",
      "Run: 08, Epoch: 159, Loss: 0.2861, Train: 87.14%, Valid: 80.20% Test: 82.50%\n",
      "Run: 08, Epoch: 160, Loss: 0.3184, Train: 89.29%, Valid: 80.00% Test: 82.20%\n",
      "Run: 08, Epoch: 161, Loss: 0.3200, Train: 90.00%, Valid: 79.20% Test: 79.30%\n",
      "Run: 08, Epoch: 162, Loss: 0.3654, Train: 89.29%, Valid: 78.40% Test: 78.70%\n",
      "Run: 08, Epoch: 163, Loss: 0.2809, Train: 91.43%, Valid: 79.20% Test: 80.60%\n",
      "Run: 08, Epoch: 164, Loss: 0.3465, Train: 94.29%, Valid: 81.60% Test: 83.10%\n",
      "Run: 08, Epoch: 165, Loss: 0.3217, Train: 92.14%, Valid: 82.00% Test: 83.20%\n",
      "Run: 08, Epoch: 166, Loss: 0.2905, Train: 90.00%, Valid: 81.40% Test: 80.30%\n",
      "Run: 08, Epoch: 167, Loss: 0.3264, Train: 84.29%, Valid: 80.20% Test: 79.30%\n",
      "Run: 08, Epoch: 168, Loss: 0.3136, Train: 86.43%, Valid: 81.00% Test: 79.40%\n",
      "Run: 08, Epoch: 169, Loss: 0.2982, Train: 89.29%, Valid: 81.20% Test: 81.80%\n",
      "Run: 08, Epoch: 170, Loss: 0.3673, Train: 90.71%, Valid: 80.80% Test: 82.90%\n",
      "Run: 08, Epoch: 171, Loss: 0.3182, Train: 90.00%, Valid: 80.00% Test: 81.20%\n",
      "Run: 08, Epoch: 172, Loss: 0.3336, Train: 89.29%, Valid: 80.40% Test: 81.30%\n",
      "Run: 08, Epoch: 173, Loss: 0.2995, Train: 88.57%, Valid: 79.20% Test: 80.70%\n",
      "Run: 08, Epoch: 174, Loss: 0.2910, Train: 93.57%, Valid: 79.20% Test: 80.70%\n",
      "Run: 08, Epoch: 175, Loss: 0.3285, Train: 91.43%, Valid: 81.60% Test: 81.60%\n",
      "Run: 08, Epoch: 176, Loss: 0.2779, Train: 90.00%, Valid: 81.80% Test: 80.20%\n",
      "Run: 08, Epoch: 177, Loss: 0.2790, Train: 86.43%, Valid: 80.60% Test: 80.10%\n",
      "Run: 08, Epoch: 178, Loss: 0.3119, Train: 88.57%, Valid: 79.60% Test: 81.60%\n",
      "Run: 08, Epoch: 179, Loss: 0.2630, Train: 92.86%, Valid: 80.60% Test: 83.50%\n",
      "Run: 08, Epoch: 180, Loss: 0.2797, Train: 91.43%, Valid: 82.80% Test: 84.40%\n",
      "Run: 08, Epoch: 181, Loss: 0.2392, Train: 93.57%, Valid: 83.80% Test: 85.10%\n",
      "Run: 08, Epoch: 182, Loss: 0.2382, Train: 91.43%, Valid: 82.20% Test: 85.40%\n",
      "Run: 08, Epoch: 183, Loss: 0.2620, Train: 89.29%, Valid: 81.40% Test: 83.40%\n",
      "Run: 08, Epoch: 184, Loss: 0.2799, Train: 88.57%, Valid: 79.60% Test: 81.90%\n",
      "Run: 08, Epoch: 185, Loss: 0.2378, Train: 84.29%, Valid: 73.40% Test: 75.60%\n",
      "Run: 08, Epoch: 186, Loss: 0.2599, Train: 82.14%, Valid: 72.80% Test: 72.80%\n",
      "Run: 08, Epoch: 187, Loss: 0.2953, Train: 87.14%, Valid: 77.20% Test: 78.10%\n",
      "Run: 08, Epoch: 188, Loss: 0.2433, Train: 90.71%, Valid: 82.60% Test: 83.10%\n",
      "Run: 08, Epoch: 189, Loss: 0.2730, Train: 92.86%, Valid: 81.80% Test: 83.00%\n",
      "Run: 08, Epoch: 190, Loss: 0.2917, Train: 94.29%, Valid: 82.60% Test: 84.10%\n",
      "Run: 08, Epoch: 191, Loss: 0.2410, Train: 95.71%, Valid: 81.40% Test: 83.00%\n",
      "Run: 08, Epoch: 192, Loss: 0.2503, Train: 94.29%, Valid: 80.20% Test: 82.80%\n",
      "Run: 08, Epoch: 193, Loss: 0.2859, Train: 92.14%, Valid: 78.80% Test: 82.10%\n",
      "Run: 08, Epoch: 194, Loss: 0.2394, Train: 92.86%, Valid: 78.60% Test: 81.60%\n",
      "Run: 08, Epoch: 195, Loss: 0.2891, Train: 88.57%, Valid: 80.20% Test: 81.50%\n",
      "Run: 08, Epoch: 196, Loss: 0.2448, Train: 90.71%, Valid: 81.40% Test: 82.20%\n",
      "Run: 08, Epoch: 197, Loss: 0.2457, Train: 91.43%, Valid: 80.20% Test: 81.70%\n",
      "Run: 08, Epoch: 198, Loss: 0.2441, Train: 87.86%, Valid: 80.40% Test: 81.10%\n",
      "Run: 08, Epoch: 199, Loss: 0.2613, Train: 88.57%, Valid: 80.00% Test: 79.70%\n",
      "Run: 08, Epoch: 200, Loss: 0.3011, Train: 85.71%, Valid: 79.00% Test: 77.00%\n",
      "Run 08:\n",
      "Highest Train: 95.71\n",
      "Highest Valid: 83.80\n",
      "  Final Train: 93.57\n",
      "   Final Test: 85.10\n",
      "Run: 09, Epoch: 01, Loss: 2.1076, Train: 14.29%, Valid: 12.40% Test: 13.30%\n",
      "Run: 09, Epoch: 02, Loss: 1.9900, Train: 16.43%, Valid: 13.20% Test: 14.40%\n",
      "Run: 09, Epoch: 03, Loss: 1.8924, Train: 23.57%, Valid: 18.60% Test: 19.50%\n",
      "Run: 09, Epoch: 04, Loss: 1.8151, Train: 21.43%, Valid: 18.60% Test: 18.60%\n",
      "Run: 09, Epoch: 05, Loss: 1.7923, Train: 17.14%, Valid: 16.40% Test: 17.00%\n",
      "Run: 09, Epoch: 06, Loss: 1.7942, Train: 15.71%, Valid: 19.00% Test: 19.60%\n",
      "Run: 09, Epoch: 07, Loss: 1.7380, Train: 22.14%, Valid: 32.00% Test: 31.10%\n",
      "Run: 09, Epoch: 08, Loss: 1.6825, Train: 24.29%, Valid: 38.40% Test: 38.40%\n",
      "Run: 09, Epoch: 09, Loss: 1.6259, Train: 26.43%, Valid: 39.20% Test: 39.60%\n",
      "Run: 09, Epoch: 10, Loss: 1.5360, Train: 40.00%, Valid: 45.20% Test: 45.80%\n",
      "Run: 09, Epoch: 11, Loss: 1.5423, Train: 40.00%, Valid: 47.60% Test: 47.70%\n",
      "Run: 09, Epoch: 12, Loss: 1.5254, Train: 41.43%, Valid: 46.00% Test: 44.10%\n",
      "Run: 09, Epoch: 13, Loss: 1.4842, Train: 42.86%, Valid: 45.00% Test: 42.30%\n",
      "Run: 09, Epoch: 14, Loss: 1.4353, Train: 45.71%, Valid: 46.40% Test: 45.30%\n",
      "Run: 09, Epoch: 15, Loss: 1.4451, Train: 47.14%, Valid: 45.80% Test: 47.10%\n",
      "Run: 09, Epoch: 16, Loss: 1.3715, Train: 50.71%, Valid: 46.00% Test: 48.50%\n",
      "Run: 09, Epoch: 17, Loss: 1.3702, Train: 54.29%, Valid: 49.40% Test: 50.60%\n",
      "Run: 09, Epoch: 18, Loss: 1.3458, Train: 55.00%, Valid: 52.80% Test: 53.70%\n",
      "Run: 09, Epoch: 19, Loss: 1.3081, Train: 56.43%, Valid: 58.60% Test: 57.50%\n",
      "Run: 09, Epoch: 20, Loss: 1.2653, Train: 63.57%, Valid: 64.00% Test: 60.80%\n",
      "Run: 09, Epoch: 21, Loss: 1.2481, Train: 71.43%, Valid: 65.60% Test: 62.60%\n",
      "Run: 09, Epoch: 22, Loss: 1.1687, Train: 66.43%, Valid: 62.40% Test: 61.40%\n",
      "Run: 09, Epoch: 23, Loss: 1.2193, Train: 65.00%, Valid: 58.20% Test: 58.90%\n",
      "Run: 09, Epoch: 24, Loss: 1.1072, Train: 61.43%, Valid: 55.80% Test: 55.40%\n",
      "Run: 09, Epoch: 25, Loss: 1.1090, Train: 60.71%, Valid: 53.80% Test: 52.90%\n",
      "Run: 09, Epoch: 26, Loss: 1.0674, Train: 57.86%, Valid: 54.20% Test: 53.20%\n",
      "Run: 09, Epoch: 27, Loss: 1.0393, Train: 55.71%, Valid: 53.60% Test: 52.80%\n",
      "Run: 09, Epoch: 28, Loss: 1.0514, Train: 52.86%, Valid: 52.40% Test: 50.50%\n",
      "Run: 09, Epoch: 29, Loss: 0.9997, Train: 50.00%, Valid: 50.60% Test: 47.50%\n",
      "Run: 09, Epoch: 30, Loss: 0.9396, Train: 53.57%, Valid: 47.00% Test: 45.70%\n",
      "Run: 09, Epoch: 31, Loss: 0.9248, Train: 53.57%, Valid: 42.20% Test: 44.00%\n",
      "Run: 09, Epoch: 32, Loss: 0.9103, Train: 55.00%, Valid: 43.40% Test: 44.40%\n",
      "Run: 09, Epoch: 33, Loss: 0.8395, Train: 60.00%, Valid: 51.20% Test: 52.20%\n",
      "Run: 09, Epoch: 34, Loss: 0.8665, Train: 69.29%, Valid: 65.00% Test: 63.50%\n",
      "Run: 09, Epoch: 35, Loss: 0.8212, Train: 77.14%, Valid: 71.00% Test: 70.10%\n",
      "Run: 09, Epoch: 36, Loss: 0.8201, Train: 78.57%, Valid: 73.60% Test: 71.40%\n",
      "Run: 09, Epoch: 37, Loss: 0.7418, Train: 70.00%, Valid: 72.40% Test: 69.30%\n",
      "Run: 09, Epoch: 38, Loss: 0.7967, Train: 65.71%, Valid: 69.60% Test: 67.30%\n",
      "Run: 09, Epoch: 39, Loss: 0.7322, Train: 65.00%, Valid: 71.60% Test: 68.10%\n",
      "Run: 09, Epoch: 40, Loss: 0.7049, Train: 68.57%, Valid: 74.40% Test: 71.20%\n",
      "Run: 09, Epoch: 41, Loss: 0.6767, Train: 79.29%, Valid: 77.60% Test: 76.30%\n",
      "Run: 09, Epoch: 42, Loss: 0.6718, Train: 82.86%, Valid: 77.40% Test: 77.20%\n",
      "Run: 09, Epoch: 43, Loss: 0.6922, Train: 86.43%, Valid: 77.00% Test: 77.20%\n",
      "Run: 09, Epoch: 44, Loss: 0.6342, Train: 85.00%, Valid: 76.20% Test: 76.40%\n",
      "Run: 09, Epoch: 45, Loss: 0.6408, Train: 88.57%, Valid: 77.80% Test: 77.80%\n",
      "Run: 09, Epoch: 46, Loss: 0.6081, Train: 89.29%, Valid: 78.00% Test: 79.90%\n",
      "Run: 09, Epoch: 47, Loss: 0.5331, Train: 87.86%, Valid: 79.20% Test: 80.10%\n",
      "Run: 09, Epoch: 48, Loss: 0.6200, Train: 84.29%, Valid: 78.20% Test: 77.70%\n",
      "Run: 09, Epoch: 49, Loss: 0.5689, Train: 82.14%, Valid: 76.40% Test: 76.60%\n",
      "Run: 09, Epoch: 50, Loss: 0.5802, Train: 82.86%, Valid: 75.60% Test: 75.60%\n",
      "Run: 09, Epoch: 51, Loss: 0.5916, Train: 82.86%, Valid: 74.00% Test: 75.40%\n",
      "Run: 09, Epoch: 52, Loss: 0.5268, Train: 83.57%, Valid: 73.60% Test: 72.80%\n",
      "Run: 09, Epoch: 53, Loss: 0.5591, Train: 80.71%, Valid: 72.20% Test: 70.60%\n",
      "Run: 09, Epoch: 54, Loss: 0.5551, Train: 79.29%, Valid: 70.60% Test: 69.40%\n",
      "Run: 09, Epoch: 55, Loss: 0.5069, Train: 83.57%, Valid: 69.60% Test: 68.40%\n",
      "Run: 09, Epoch: 56, Loss: 0.5224, Train: 81.43%, Valid: 69.00% Test: 68.40%\n",
      "Run: 09, Epoch: 57, Loss: 0.4989, Train: 82.86%, Valid: 71.60% Test: 71.20%\n",
      "Run: 09, Epoch: 58, Loss: 0.4873, Train: 86.43%, Valid: 76.80% Test: 75.00%\n",
      "Run: 09, Epoch: 59, Loss: 0.4826, Train: 88.57%, Valid: 81.20% Test: 80.50%\n",
      "Run: 09, Epoch: 60, Loss: 0.4540, Train: 84.29%, Valid: 81.20% Test: 81.00%\n",
      "Run: 09, Epoch: 61, Loss: 0.5136, Train: 80.71%, Valid: 80.20% Test: 79.20%\n",
      "Run: 09, Epoch: 62, Loss: 0.4850, Train: 81.43%, Valid: 77.20% Test: 76.60%\n",
      "Run: 09, Epoch: 63, Loss: 0.4791, Train: 80.00%, Valid: 76.20% Test: 76.20%\n",
      "Run: 09, Epoch: 64, Loss: 0.4276, Train: 82.86%, Valid: 76.00% Test: 77.80%\n",
      "Run: 09, Epoch: 65, Loss: 0.4711, Train: 78.57%, Valid: 73.00% Test: 76.70%\n",
      "Run: 09, Epoch: 66, Loss: 0.4931, Train: 80.71%, Valid: 72.80% Test: 76.50%\n",
      "Run: 09, Epoch: 67, Loss: 0.4949, Train: 84.29%, Valid: 76.00% Test: 79.40%\n",
      "Run: 09, Epoch: 68, Loss: 0.4938, Train: 85.00%, Valid: 77.80% Test: 80.30%\n",
      "Run: 09, Epoch: 69, Loss: 0.4388, Train: 88.57%, Valid: 79.20% Test: 81.00%\n",
      "Run: 09, Epoch: 70, Loss: 0.4844, Train: 89.29%, Valid: 80.80% Test: 82.00%\n",
      "Run: 09, Epoch: 71, Loss: 0.4629, Train: 87.86%, Valid: 81.60% Test: 81.30%\n",
      "Run: 09, Epoch: 72, Loss: 0.3894, Train: 84.29%, Valid: 79.60% Test: 78.00%\n",
      "Run: 09, Epoch: 73, Loss: 0.4006, Train: 86.43%, Valid: 80.20% Test: 81.10%\n",
      "Run: 09, Epoch: 74, Loss: 0.4195, Train: 87.86%, Valid: 82.80% Test: 82.80%\n",
      "Run: 09, Epoch: 75, Loss: 0.4169, Train: 90.00%, Valid: 83.40% Test: 85.10%\n",
      "Run: 09, Epoch: 76, Loss: 0.3916, Train: 89.29%, Valid: 80.60% Test: 83.60%\n",
      "Run: 09, Epoch: 77, Loss: 0.4260, Train: 83.57%, Valid: 75.80% Test: 77.30%\n",
      "Run: 09, Epoch: 78, Loss: 0.3758, Train: 83.57%, Valid: 74.40% Test: 74.80%\n",
      "Run: 09, Epoch: 79, Loss: 0.4044, Train: 88.57%, Valid: 76.60% Test: 76.90%\n",
      "Run: 09, Epoch: 80, Loss: 0.4570, Train: 88.57%, Valid: 80.00% Test: 79.50%\n",
      "Run: 09, Epoch: 81, Loss: 0.4143, Train: 88.57%, Valid: 81.60% Test: 81.00%\n",
      "Run: 09, Epoch: 82, Loss: 0.3750, Train: 88.57%, Valid: 81.00% Test: 80.30%\n",
      "Run: 09, Epoch: 83, Loss: 0.3994, Train: 87.14%, Valid: 80.40% Test: 78.80%\n",
      "Run: 09, Epoch: 84, Loss: 0.4022, Train: 87.86%, Valid: 82.20% Test: 79.90%\n",
      "Run: 09, Epoch: 85, Loss: 0.3574, Train: 89.29%, Valid: 83.00% Test: 80.80%\n",
      "Run: 09, Epoch: 86, Loss: 0.4151, Train: 86.43%, Valid: 79.20% Test: 80.60%\n",
      "Run: 09, Epoch: 87, Loss: 0.3701, Train: 86.43%, Valid: 75.60% Test: 77.00%\n",
      "Run: 09, Epoch: 88, Loss: 0.3724, Train: 83.57%, Valid: 76.00% Test: 76.80%\n",
      "Run: 09, Epoch: 89, Loss: 0.4152, Train: 85.71%, Valid: 76.80% Test: 77.30%\n",
      "Run: 09, Epoch: 90, Loss: 0.3912, Train: 84.29%, Valid: 74.60% Test: 76.80%\n",
      "Run: 09, Epoch: 91, Loss: 0.3650, Train: 87.14%, Valid: 79.20% Test: 79.60%\n",
      "Run: 09, Epoch: 92, Loss: 0.3391, Train: 91.43%, Valid: 81.00% Test: 81.80%\n",
      "Run: 09, Epoch: 93, Loss: 0.3665, Train: 92.14%, Valid: 83.20% Test: 83.30%\n",
      "Run: 09, Epoch: 94, Loss: 0.4136, Train: 92.86%, Valid: 78.80% Test: 81.20%\n",
      "Run: 09, Epoch: 95, Loss: 0.3227, Train: 84.29%, Valid: 75.20% Test: 75.80%\n",
      "Run: 09, Epoch: 96, Loss: 0.3890, Train: 79.29%, Valid: 71.80% Test: 72.10%\n",
      "Run: 09, Epoch: 97, Loss: 0.4071, Train: 82.86%, Valid: 74.60% Test: 75.20%\n",
      "Run: 09, Epoch: 98, Loss: 0.3588, Train: 84.29%, Valid: 77.00% Test: 78.60%\n",
      "Run: 09, Epoch: 99, Loss: 0.2726, Train: 90.00%, Valid: 79.80% Test: 82.00%\n",
      "Run: 09, Epoch: 100, Loss: 0.3266, Train: 95.71%, Valid: 81.40% Test: 84.00%\n",
      "Run: 09, Epoch: 101, Loss: 0.3391, Train: 92.86%, Valid: 81.60% Test: 84.40%\n",
      "Run: 09, Epoch: 102, Loss: 0.3615, Train: 90.00%, Valid: 81.60% Test: 82.60%\n",
      "Run: 09, Epoch: 103, Loss: 0.3295, Train: 90.00%, Valid: 80.40% Test: 81.50%\n",
      "Run: 09, Epoch: 104, Loss: 0.3414, Train: 88.57%, Valid: 78.20% Test: 82.10%\n",
      "Run: 09, Epoch: 105, Loss: 0.2866, Train: 87.86%, Valid: 75.80% Test: 80.40%\n",
      "Run: 09, Epoch: 106, Loss: 0.3788, Train: 89.29%, Valid: 76.40% Test: 80.60%\n",
      "Run: 09, Epoch: 107, Loss: 0.3293, Train: 91.43%, Valid: 79.00% Test: 82.20%\n",
      "Run: 09, Epoch: 108, Loss: 0.3191, Train: 92.14%, Valid: 81.40% Test: 82.60%\n",
      "Run: 09, Epoch: 109, Loss: 0.3080, Train: 93.57%, Valid: 82.80% Test: 83.80%\n",
      "Run: 09, Epoch: 110, Loss: 0.2955, Train: 92.14%, Valid: 84.00% Test: 84.30%\n",
      "Run: 09, Epoch: 111, Loss: 0.2467, Train: 92.14%, Valid: 82.80% Test: 84.50%\n",
      "Run: 09, Epoch: 112, Loss: 0.3335, Train: 89.29%, Valid: 82.20% Test: 83.80%\n",
      "Run: 09, Epoch: 113, Loss: 0.2745, Train: 89.29%, Valid: 82.60% Test: 82.50%\n",
      "Run: 09, Epoch: 114, Loss: 0.3451, Train: 90.00%, Valid: 82.40% Test: 82.80%\n",
      "Run: 09, Epoch: 115, Loss: 0.2906, Train: 91.43%, Valid: 82.00% Test: 81.90%\n",
      "Run: 09, Epoch: 116, Loss: 0.2702, Train: 88.57%, Valid: 79.60% Test: 81.20%\n",
      "Run: 09, Epoch: 117, Loss: 0.2908, Train: 90.00%, Valid: 78.60% Test: 81.80%\n",
      "Run: 09, Epoch: 118, Loss: 0.2451, Train: 88.57%, Valid: 76.40% Test: 79.60%\n",
      "Run: 09, Epoch: 119, Loss: 0.3024, Train: 90.71%, Valid: 76.20% Test: 78.90%\n",
      "Run: 09, Epoch: 120, Loss: 0.2912, Train: 85.71%, Valid: 78.60% Test: 81.50%\n",
      "Run: 09, Epoch: 121, Loss: 0.2659, Train: 89.29%, Valid: 77.40% Test: 81.40%\n",
      "Run: 09, Epoch: 122, Loss: 0.3436, Train: 92.14%, Valid: 80.00% Test: 82.60%\n",
      "Run: 09, Epoch: 123, Loss: 0.3044, Train: 92.14%, Valid: 82.20% Test: 82.60%\n",
      "Run: 09, Epoch: 124, Loss: 0.2892, Train: 89.29%, Valid: 80.60% Test: 81.40%\n",
      "Run: 09, Epoch: 125, Loss: 0.2703, Train: 87.86%, Valid: 80.00% Test: 80.20%\n",
      "Run: 09, Epoch: 126, Loss: 0.2898, Train: 87.86%, Valid: 82.20% Test: 82.00%\n",
      "Run: 09, Epoch: 127, Loss: 0.2953, Train: 90.71%, Valid: 83.60% Test: 84.00%\n",
      "Run: 09, Epoch: 128, Loss: 0.2713, Train: 92.14%, Valid: 83.40% Test: 84.10%\n",
      "Run: 09, Epoch: 129, Loss: 0.2764, Train: 93.57%, Valid: 81.20% Test: 83.50%\n",
      "Run: 09, Epoch: 130, Loss: 0.2503, Train: 88.57%, Valid: 77.00% Test: 77.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 131, Loss: 0.2751, Train: 88.57%, Valid: 75.00% Test: 75.20%\n",
      "Run: 09, Epoch: 132, Loss: 0.3022, Train: 87.14%, Valid: 74.20% Test: 75.20%\n",
      "Run: 09, Epoch: 133, Loss: 0.3530, Train: 92.14%, Valid: 78.00% Test: 78.80%\n",
      "Run: 09, Epoch: 134, Loss: 0.2791, Train: 87.86%, Valid: 80.00% Test: 81.10%\n",
      "Run: 09, Epoch: 135, Loss: 0.2664, Train: 85.00%, Valid: 81.40% Test: 79.80%\n",
      "Run: 09, Epoch: 136, Loss: 0.2388, Train: 82.14%, Valid: 79.60% Test: 78.00%\n",
      "Run: 09, Epoch: 137, Loss: 0.2622, Train: 81.43%, Valid: 79.80% Test: 78.90%\n",
      "Run: 09, Epoch: 138, Loss: 0.2680, Train: 87.14%, Valid: 81.60% Test: 81.40%\n",
      "Run: 09, Epoch: 139, Loss: 0.2843, Train: 92.14%, Valid: 82.20% Test: 83.70%\n",
      "Run: 09, Epoch: 140, Loss: 0.2893, Train: 90.71%, Valid: 82.40% Test: 83.70%\n",
      "Run: 09, Epoch: 141, Loss: 0.2098, Train: 90.00%, Valid: 79.80% Test: 83.10%\n",
      "Run: 09, Epoch: 142, Loss: 0.3034, Train: 86.43%, Valid: 79.00% Test: 80.60%\n",
      "Run: 09, Epoch: 143, Loss: 0.3440, Train: 85.71%, Valid: 77.20% Test: 78.60%\n",
      "Run: 09, Epoch: 144, Loss: 0.2611, Train: 85.71%, Valid: 79.80% Test: 80.30%\n",
      "Run: 09, Epoch: 145, Loss: 0.2616, Train: 89.29%, Valid: 80.80% Test: 81.10%\n",
      "Run: 09, Epoch: 146, Loss: 0.2584, Train: 95.00%, Valid: 81.00% Test: 84.10%\n",
      "Run: 09, Epoch: 147, Loss: 0.2892, Train: 95.00%, Valid: 83.20% Test: 84.80%\n",
      "Run: 09, Epoch: 148, Loss: 0.2406, Train: 88.57%, Valid: 82.00% Test: 81.70%\n",
      "Run: 09, Epoch: 149, Loss: 0.2538, Train: 85.71%, Valid: 79.60% Test: 78.60%\n",
      "Run: 09, Epoch: 150, Loss: 0.2524, Train: 83.57%, Valid: 76.20% Test: 75.80%\n",
      "Run: 09, Epoch: 151, Loss: 0.2629, Train: 87.86%, Valid: 76.60% Test: 78.50%\n",
      "Run: 09, Epoch: 152, Loss: 0.2510, Train: 87.86%, Valid: 79.00% Test: 80.80%\n",
      "Run: 09, Epoch: 153, Loss: 0.1906, Train: 90.00%, Valid: 79.60% Test: 80.10%\n",
      "Run: 09, Epoch: 154, Loss: 0.2718, Train: 89.29%, Valid: 78.60% Test: 79.90%\n",
      "Run: 09, Epoch: 155, Loss: 0.2333, Train: 85.71%, Valid: 76.80% Test: 78.30%\n",
      "Run: 09, Epoch: 156, Loss: 0.2665, Train: 88.57%, Valid: 77.80% Test: 80.00%\n",
      "Run: 09, Epoch: 157, Loss: 0.1772, Train: 91.43%, Valid: 80.00% Test: 82.40%\n",
      "Run: 09, Epoch: 158, Loss: 0.2561, Train: 92.14%, Valid: 83.40% Test: 84.20%\n",
      "Run: 09, Epoch: 159, Loss: 0.2306, Train: 95.00%, Valid: 83.20% Test: 83.80%\n",
      "Run: 09, Epoch: 160, Loss: 0.2603, Train: 94.29%, Valid: 82.20% Test: 82.00%\n",
      "Run: 09, Epoch: 161, Loss: 0.2389, Train: 95.00%, Valid: 82.20% Test: 81.10%\n",
      "Run: 09, Epoch: 162, Loss: 0.2783, Train: 95.00%, Valid: 82.00% Test: 81.50%\n",
      "Run: 09, Epoch: 163, Loss: 0.2314, Train: 92.14%, Valid: 82.40% Test: 82.20%\n",
      "Run: 09, Epoch: 164, Loss: 0.2561, Train: 93.57%, Valid: 80.00% Test: 82.50%\n",
      "Run: 09, Epoch: 165, Loss: 0.2368, Train: 93.57%, Valid: 79.40% Test: 83.60%\n",
      "Run: 09, Epoch: 166, Loss: 0.2568, Train: 94.29%, Valid: 80.20% Test: 82.40%\n",
      "Run: 09, Epoch: 167, Loss: 0.2479, Train: 96.43%, Valid: 81.80% Test: 84.30%\n",
      "Run: 09, Epoch: 168, Loss: 0.2195, Train: 95.00%, Valid: 85.00% Test: 85.00%\n",
      "Run: 09, Epoch: 169, Loss: 0.2830, Train: 95.00%, Valid: 82.40% Test: 84.20%\n",
      "Run: 09, Epoch: 170, Loss: 0.2363, Train: 96.43%, Valid: 81.80% Test: 84.30%\n",
      "Run: 09, Epoch: 171, Loss: 0.2995, Train: 94.29%, Valid: 79.60% Test: 81.00%\n",
      "Run: 09, Epoch: 172, Loss: 0.2629, Train: 92.86%, Valid: 77.40% Test: 78.60%\n",
      "Run: 09, Epoch: 173, Loss: 0.3021, Train: 90.71%, Valid: 77.20% Test: 79.20%\n",
      "Run: 09, Epoch: 174, Loss: 0.2574, Train: 92.86%, Valid: 77.80% Test: 79.90%\n",
      "Run: 09, Epoch: 175, Loss: 0.2499, Train: 87.86%, Valid: 79.40% Test: 80.50%\n",
      "Run: 09, Epoch: 176, Loss: 0.2419, Train: 89.29%, Valid: 78.40% Test: 80.00%\n",
      "Run: 09, Epoch: 177, Loss: 0.2307, Train: 89.29%, Valid: 80.00% Test: 81.00%\n",
      "Run: 09, Epoch: 178, Loss: 0.2356, Train: 91.43%, Valid: 80.60% Test: 82.90%\n",
      "Run: 09, Epoch: 179, Loss: 0.2037, Train: 95.71%, Valid: 80.00% Test: 83.10%\n",
      "Run: 09, Epoch: 180, Loss: 0.1962, Train: 92.86%, Valid: 79.80% Test: 81.10%\n",
      "Run: 09, Epoch: 181, Loss: 0.2782, Train: 90.71%, Valid: 79.80% Test: 81.00%\n",
      "Run: 09, Epoch: 182, Loss: 0.2808, Train: 88.57%, Valid: 80.00% Test: 80.30%\n",
      "Run: 09, Epoch: 183, Loss: 0.1914, Train: 92.14%, Valid: 80.00% Test: 81.30%\n",
      "Run: 09, Epoch: 184, Loss: 0.2024, Train: 93.57%, Valid: 80.20% Test: 82.10%\n",
      "Run: 09, Epoch: 185, Loss: 0.2428, Train: 92.86%, Valid: 79.60% Test: 81.80%\n",
      "Run: 09, Epoch: 186, Loss: 0.2500, Train: 92.86%, Valid: 78.60% Test: 81.40%\n",
      "Run: 09, Epoch: 187, Loss: 0.1911, Train: 94.29%, Valid: 78.80% Test: 81.20%\n",
      "Run: 09, Epoch: 188, Loss: 0.2966, Train: 95.71%, Valid: 81.00% Test: 83.20%\n",
      "Run: 09, Epoch: 189, Loss: 0.2088, Train: 94.29%, Valid: 81.60% Test: 84.10%\n",
      "Run: 09, Epoch: 190, Loss: 0.2205, Train: 94.29%, Valid: 82.20% Test: 84.70%\n",
      "Run: 09, Epoch: 191, Loss: 0.1753, Train: 91.43%, Valid: 82.40% Test: 84.50%\n",
      "Run: 09, Epoch: 192, Loss: 0.2311, Train: 92.86%, Valid: 81.40% Test: 83.60%\n",
      "Run: 09, Epoch: 193, Loss: 0.2428, Train: 93.57%, Valid: 81.60% Test: 83.00%\n",
      "Run: 09, Epoch: 194, Loss: 0.2505, Train: 92.86%, Valid: 81.40% Test: 82.30%\n",
      "Run: 09, Epoch: 195, Loss: 0.2731, Train: 91.43%, Valid: 81.20% Test: 82.10%\n",
      "Run: 09, Epoch: 196, Loss: 0.2461, Train: 95.00%, Valid: 79.40% Test: 83.10%\n",
      "Run: 09, Epoch: 197, Loss: 0.2131, Train: 94.29%, Valid: 79.80% Test: 82.30%\n",
      "Run: 09, Epoch: 198, Loss: 0.2253, Train: 93.57%, Valid: 79.60% Test: 80.60%\n",
      "Run: 09, Epoch: 199, Loss: 0.2024, Train: 95.00%, Valid: 79.60% Test: 81.40%\n",
      "Run: 09, Epoch: 200, Loss: 0.2397, Train: 94.29%, Valid: 80.60% Test: 83.30%\n",
      "Run 09:\n",
      "Highest Train: 96.43\n",
      "Highest Valid: 85.00\n",
      "  Final Train: 95.00\n",
      "   Final Test: 85.00\n",
      "Run: 10, Epoch: 01, Loss: 2.1048, Train: 7.86%, Valid: 3.20% Test: 3.90%\n",
      "Run: 10, Epoch: 02, Loss: 2.0057, Train: 14.29%, Valid: 15.20% Test: 14.30%\n",
      "Run: 10, Epoch: 03, Loss: 1.9580, Train: 14.29%, Valid: 15.60% Test: 14.50%\n",
      "Run: 10, Epoch: 04, Loss: 1.8814, Train: 14.29%, Valid: 15.80% Test: 14.50%\n",
      "Run: 10, Epoch: 05, Loss: 1.8520, Train: 14.29%, Valid: 15.80% Test: 14.40%\n",
      "Run: 10, Epoch: 06, Loss: 1.8031, Train: 14.29%, Valid: 15.20% Test: 14.40%\n",
      "Run: 10, Epoch: 07, Loss: 1.7548, Train: 15.00%, Valid: 15.20% Test: 15.10%\n",
      "Run: 10, Epoch: 08, Loss: 1.7418, Train: 14.29%, Valid: 16.00% Test: 16.80%\n",
      "Run: 10, Epoch: 09, Loss: 1.6834, Train: 21.43%, Valid: 18.60% Test: 20.20%\n",
      "Run: 10, Epoch: 10, Loss: 1.6330, Train: 26.43%, Valid: 23.00% Test: 21.20%\n",
      "Run: 10, Epoch: 11, Loss: 1.5976, Train: 20.00%, Valid: 19.40% Test: 18.80%\n",
      "Run: 10, Epoch: 12, Loss: 1.5379, Train: 18.57%, Valid: 19.80% Test: 19.10%\n",
      "Run: 10, Epoch: 13, Loss: 1.4937, Train: 18.57%, Valid: 21.40% Test: 20.50%\n",
      "Run: 10, Epoch: 14, Loss: 1.4235, Train: 23.57%, Valid: 25.40% Test: 26.00%\n",
      "Run: 10, Epoch: 15, Loss: 1.3875, Train: 35.00%, Valid: 34.60% Test: 33.40%\n",
      "Run: 10, Epoch: 16, Loss: 1.3694, Train: 36.43%, Valid: 39.20% Test: 35.90%\n",
      "Run: 10, Epoch: 17, Loss: 1.3289, Train: 33.57%, Valid: 33.20% Test: 31.60%\n",
      "Run: 10, Epoch: 18, Loss: 1.2911, Train: 26.43%, Valid: 30.20% Test: 28.00%\n",
      "Run: 10, Epoch: 19, Loss: 1.2126, Train: 26.43%, Valid: 32.80% Test: 32.50%\n",
      "Run: 10, Epoch: 20, Loss: 1.1545, Train: 30.00%, Valid: 42.40% Test: 41.80%\n",
      "Run: 10, Epoch: 21, Loss: 1.0975, Train: 36.43%, Valid: 45.60% Test: 45.70%\n",
      "Run: 10, Epoch: 22, Loss: 1.0875, Train: 38.57%, Valid: 45.40% Test: 47.30%\n",
      "Run: 10, Epoch: 23, Loss: 1.0858, Train: 40.00%, Valid: 44.60% Test: 46.90%\n",
      "Run: 10, Epoch: 24, Loss: 1.0302, Train: 50.71%, Valid: 48.00% Test: 49.40%\n",
      "Run: 10, Epoch: 25, Loss: 0.9819, Train: 63.57%, Valid: 55.60% Test: 58.40%\n",
      "Run: 10, Epoch: 26, Loss: 0.8956, Train: 71.43%, Valid: 57.40% Test: 60.10%\n",
      "Run: 10, Epoch: 27, Loss: 0.8802, Train: 77.14%, Valid: 58.20% Test: 59.80%\n",
      "Run: 10, Epoch: 28, Loss: 0.8432, Train: 73.57%, Valid: 56.40% Test: 58.00%\n",
      "Run: 10, Epoch: 29, Loss: 0.8230, Train: 73.57%, Valid: 56.20% Test: 57.90%\n",
      "Run: 10, Epoch: 30, Loss: 0.7966, Train: 72.14%, Valid: 55.60% Test: 57.30%\n",
      "Run: 10, Epoch: 31, Loss: 0.7789, Train: 71.43%, Valid: 56.60% Test: 59.00%\n",
      "Run: 10, Epoch: 32, Loss: 0.7223, Train: 72.14%, Valid: 61.40% Test: 63.70%\n",
      "Run: 10, Epoch: 33, Loss: 0.6736, Train: 72.86%, Valid: 68.00% Test: 69.50%\n",
      "Run: 10, Epoch: 34, Loss: 0.6981, Train: 77.14%, Valid: 70.60% Test: 70.70%\n",
      "Run: 10, Epoch: 35, Loss: 0.7137, Train: 81.43%, Valid: 71.20% Test: 72.30%\n",
      "Run: 10, Epoch: 36, Loss: 0.6729, Train: 77.86%, Valid: 70.60% Test: 72.90%\n",
      "Run: 10, Epoch: 37, Loss: 0.7014, Train: 80.71%, Valid: 71.60% Test: 73.80%\n",
      "Run: 10, Epoch: 38, Loss: 0.6602, Train: 77.86%, Valid: 72.40% Test: 74.70%\n",
      "Run: 10, Epoch: 39, Loss: 0.5994, Train: 80.00%, Valid: 73.00% Test: 75.60%\n",
      "Run: 10, Epoch: 40, Loss: 0.6494, Train: 82.86%, Valid: 75.00% Test: 77.10%\n",
      "Run: 10, Epoch: 41, Loss: 0.5880, Train: 82.14%, Valid: 75.00% Test: 74.50%\n",
      "Run: 10, Epoch: 42, Loss: 0.5652, Train: 80.00%, Valid: 73.40% Test: 74.30%\n",
      "Run: 10, Epoch: 43, Loss: 0.5900, Train: 78.57%, Valid: 73.20% Test: 72.90%\n",
      "Run: 10, Epoch: 44, Loss: 0.5865, Train: 80.71%, Valid: 71.20% Test: 71.60%\n",
      "Run: 10, Epoch: 45, Loss: 0.5270, Train: 80.71%, Valid: 71.20% Test: 71.50%\n",
      "Run: 10, Epoch: 46, Loss: 0.5249, Train: 77.86%, Valid: 73.40% Test: 71.60%\n",
      "Run: 10, Epoch: 47, Loss: 0.5515, Train: 79.29%, Valid: 74.00% Test: 73.90%\n",
      "Run: 10, Epoch: 48, Loss: 0.5416, Train: 85.71%, Valid: 79.20% Test: 77.70%\n",
      "Run: 10, Epoch: 49, Loss: 0.5375, Train: 86.43%, Valid: 77.00% Test: 77.50%\n",
      "Run: 10, Epoch: 50, Loss: 0.4952, Train: 85.00%, Valid: 74.40% Test: 77.00%\n",
      "Run: 10, Epoch: 51, Loss: 0.5146, Train: 84.29%, Valid: 74.00% Test: 76.80%\n",
      "Run: 10, Epoch: 52, Loss: 0.5173, Train: 87.14%, Valid: 76.00% Test: 79.10%\n",
      "Run: 10, Epoch: 53, Loss: 0.4964, Train: 87.86%, Valid: 76.20% Test: 80.60%\n",
      "Run: 10, Epoch: 54, Loss: 0.5026, Train: 87.14%, Valid: 76.40% Test: 78.70%\n",
      "Run: 10, Epoch: 55, Loss: 0.4612, Train: 85.71%, Valid: 75.60% Test: 76.20%\n",
      "Run: 10, Epoch: 56, Loss: 0.5326, Train: 85.71%, Valid: 77.00% Test: 76.00%\n",
      "Run: 10, Epoch: 57, Loss: 0.4190, Train: 86.43%, Valid: 78.60% Test: 78.70%\n",
      "Run: 10, Epoch: 58, Loss: 0.4856, Train: 88.57%, Valid: 80.40% Test: 83.00%\n",
      "Run: 10, Epoch: 59, Loss: 0.4371, Train: 89.29%, Valid: 79.80% Test: 83.80%\n",
      "Run: 10, Epoch: 60, Loss: 0.4669, Train: 90.00%, Valid: 81.20% Test: 83.10%\n",
      "Run: 10, Epoch: 61, Loss: 0.4335, Train: 87.14%, Valid: 81.20% Test: 83.00%\n",
      "Run: 10, Epoch: 62, Loss: 0.4582, Train: 89.29%, Valid: 80.40% Test: 83.20%\n",
      "Run: 10, Epoch: 63, Loss: 0.4195, Train: 87.14%, Valid: 80.40% Test: 83.10%\n",
      "Run: 10, Epoch: 64, Loss: 0.4196, Train: 86.43%, Valid: 81.00% Test: 82.30%\n",
      "Run: 10, Epoch: 65, Loss: 0.4214, Train: 86.43%, Valid: 80.60% Test: 79.30%\n",
      "Run: 10, Epoch: 66, Loss: 0.4595, Train: 86.43%, Valid: 80.20% Test: 77.90%\n",
      "Run: 10, Epoch: 67, Loss: 0.4928, Train: 87.86%, Valid: 80.80% Test: 79.70%\n",
      "Run: 10, Epoch: 68, Loss: 0.4387, Train: 90.71%, Valid: 80.60% Test: 81.00%\n",
      "Run: 10, Epoch: 69, Loss: 0.4056, Train: 92.86%, Valid: 79.80% Test: 81.70%\n",
      "Run: 10, Epoch: 70, Loss: 0.4207, Train: 89.29%, Valid: 78.80% Test: 80.50%\n",
      "Run: 10, Epoch: 71, Loss: 0.4168, Train: 89.29%, Valid: 79.80% Test: 80.20%\n",
      "Run: 10, Epoch: 72, Loss: 0.3993, Train: 95.00%, Valid: 81.40% Test: 81.90%\n",
      "Run: 10, Epoch: 73, Loss: 0.3866, Train: 89.29%, Valid: 80.80% Test: 82.00%\n",
      "Run: 10, Epoch: 74, Loss: 0.4169, Train: 88.57%, Valid: 80.20% Test: 81.50%\n",
      "Run: 10, Epoch: 75, Loss: 0.3615, Train: 87.86%, Valid: 80.80% Test: 81.80%\n",
      "Run: 10, Epoch: 76, Loss: 0.3950, Train: 88.57%, Valid: 81.40% Test: 82.20%\n",
      "Run: 10, Epoch: 77, Loss: 0.3584, Train: 88.57%, Valid: 81.40% Test: 83.20%\n",
      "Run: 10, Epoch: 78, Loss: 0.3671, Train: 90.00%, Valid: 81.60% Test: 83.80%\n",
      "Run: 10, Epoch: 79, Loss: 0.4114, Train: 91.43%, Valid: 80.00% Test: 83.70%\n",
      "Run: 10, Epoch: 80, Loss: 0.3368, Train: 85.71%, Valid: 79.60% Test: 82.50%\n",
      "Run: 10, Epoch: 81, Loss: 0.4369, Train: 84.29%, Valid: 78.60% Test: 81.60%\n",
      "Run: 10, Epoch: 82, Loss: 0.3886, Train: 84.29%, Valid: 78.80% Test: 81.40%\n",
      "Run: 10, Epoch: 83, Loss: 0.3964, Train: 90.00%, Valid: 78.20% Test: 82.70%\n",
      "Run: 10, Epoch: 84, Loss: 0.3975, Train: 92.86%, Valid: 80.20% Test: 82.50%\n",
      "Run: 10, Epoch: 85, Loss: 0.3391, Train: 87.14%, Valid: 79.60% Test: 80.00%\n",
      "Run: 10, Epoch: 86, Loss: 0.3456, Train: 82.14%, Valid: 76.80% Test: 75.60%\n",
      "Run: 10, Epoch: 87, Loss: 0.3711, Train: 83.57%, Valid: 76.80% Test: 75.20%\n",
      "Run: 10, Epoch: 88, Loss: 0.3390, Train: 90.00%, Valid: 81.40% Test: 81.10%\n",
      "Run: 10, Epoch: 89, Loss: 0.4213, Train: 88.57%, Valid: 82.00% Test: 83.60%\n",
      "Run: 10, Epoch: 90, Loss: 0.3747, Train: 89.29%, Valid: 81.80% Test: 83.60%\n",
      "Run: 10, Epoch: 91, Loss: 0.3784, Train: 88.57%, Valid: 79.40% Test: 81.60%\n",
      "Run: 10, Epoch: 92, Loss: 0.3572, Train: 86.43%, Valid: 78.00% Test: 80.50%\n",
      "Run: 10, Epoch: 93, Loss: 0.3411, Train: 88.57%, Valid: 78.80% Test: 80.70%\n",
      "Run: 10, Epoch: 94, Loss: 0.3034, Train: 88.57%, Valid: 77.80% Test: 80.00%\n",
      "Run: 10, Epoch: 95, Loss: 0.3233, Train: 89.29%, Valid: 80.20% Test: 81.00%\n",
      "Run: 10, Epoch: 96, Loss: 0.3660, Train: 88.57%, Valid: 80.00% Test: 80.30%\n",
      "Run: 10, Epoch: 97, Loss: 0.3533, Train: 88.57%, Valid: 80.80% Test: 81.10%\n",
      "Run: 10, Epoch: 98, Loss: 0.3435, Train: 89.29%, Valid: 78.00% Test: 81.70%\n",
      "Run: 10, Epoch: 99, Loss: 0.3594, Train: 87.86%, Valid: 79.20% Test: 81.20%\n",
      "Run: 10, Epoch: 100, Loss: 0.3742, Train: 87.86%, Valid: 82.60% Test: 82.80%\n",
      "Run: 10, Epoch: 101, Loss: 0.3066, Train: 92.14%, Valid: 83.60% Test: 83.80%\n",
      "Run: 10, Epoch: 102, Loss: 0.3179, Train: 93.57%, Valid: 84.00% Test: 84.60%\n",
      "Run: 10, Epoch: 103, Loss: 0.3079, Train: 94.29%, Valid: 82.20% Test: 85.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 104, Loss: 0.2801, Train: 89.29%, Valid: 80.00% Test: 84.50%\n",
      "Run: 10, Epoch: 105, Loss: 0.2695, Train: 90.00%, Valid: 80.80% Test: 84.80%\n",
      "Run: 10, Epoch: 106, Loss: 0.3234, Train: 88.57%, Valid: 79.80% Test: 84.50%\n",
      "Run: 10, Epoch: 107, Loss: 0.3400, Train: 87.86%, Valid: 79.40% Test: 81.10%\n",
      "Run: 10, Epoch: 108, Loss: 0.2895, Train: 86.43%, Valid: 79.40% Test: 80.00%\n",
      "Run: 10, Epoch: 109, Loss: 0.3666, Train: 87.86%, Valid: 80.20% Test: 79.60%\n",
      "Run: 10, Epoch: 110, Loss: 0.3307, Train: 86.43%, Valid: 81.20% Test: 81.60%\n",
      "Run: 10, Epoch: 111, Loss: 0.3371, Train: 88.57%, Valid: 82.20% Test: 83.50%\n",
      "Run: 10, Epoch: 112, Loss: 0.2968, Train: 90.71%, Valid: 82.00% Test: 84.10%\n",
      "Run: 10, Epoch: 113, Loss: 0.2440, Train: 90.71%, Valid: 80.20% Test: 81.70%\n",
      "Run: 10, Epoch: 114, Loss: 0.3226, Train: 84.29%, Valid: 78.20% Test: 79.70%\n",
      "Run: 10, Epoch: 115, Loss: 0.2439, Train: 82.86%, Valid: 78.80% Test: 80.10%\n",
      "Run: 10, Epoch: 116, Loss: 0.3709, Train: 92.14%, Valid: 78.20% Test: 82.00%\n",
      "Run: 10, Epoch: 117, Loss: 0.2552, Train: 92.14%, Valid: 79.80% Test: 82.30%\n",
      "Run: 10, Epoch: 118, Loss: 0.2735, Train: 88.57%, Valid: 77.60% Test: 81.60%\n",
      "Run: 10, Epoch: 119, Loss: 0.3236, Train: 85.71%, Valid: 73.80% Test: 74.90%\n",
      "Run: 10, Epoch: 120, Loss: 0.2557, Train: 85.00%, Valid: 71.00% Test: 73.10%\n",
      "Run: 10, Epoch: 121, Loss: 0.3022, Train: 87.14%, Valid: 75.00% Test: 77.60%\n",
      "Run: 10, Epoch: 122, Loss: 0.2783, Train: 90.00%, Valid: 79.20% Test: 80.40%\n",
      "Run: 10, Epoch: 123, Loss: 0.3377, Train: 92.86%, Valid: 81.80% Test: 82.70%\n",
      "Run: 10, Epoch: 124, Loss: 0.3348, Train: 95.00%, Valid: 81.60% Test: 83.00%\n",
      "Run: 10, Epoch: 125, Loss: 0.3439, Train: 91.43%, Valid: 81.40% Test: 83.70%\n",
      "Run: 10, Epoch: 126, Loss: 0.3008, Train: 92.14%, Valid: 81.20% Test: 83.70%\n",
      "Run: 10, Epoch: 127, Loss: 0.2589, Train: 92.14%, Valid: 80.60% Test: 83.30%\n",
      "Run: 10, Epoch: 128, Loss: 0.2195, Train: 93.57%, Valid: 81.40% Test: 82.80%\n",
      "Run: 10, Epoch: 129, Loss: 0.2990, Train: 91.43%, Valid: 81.20% Test: 80.50%\n",
      "Run: 10, Epoch: 130, Loss: 0.3346, Train: 90.71%, Valid: 80.80% Test: 80.40%\n",
      "Run: 10, Epoch: 131, Loss: 0.2960, Train: 94.29%, Valid: 83.20% Test: 83.70%\n",
      "Run: 10, Epoch: 132, Loss: 0.2956, Train: 90.00%, Valid: 80.20% Test: 82.10%\n",
      "Run: 10, Epoch: 133, Loss: 0.2739, Train: 85.71%, Valid: 77.40% Test: 79.50%\n",
      "Run: 10, Epoch: 134, Loss: 0.2834, Train: 87.14%, Valid: 78.80% Test: 81.00%\n",
      "Run: 10, Epoch: 135, Loss: 0.2629, Train: 85.00%, Valid: 77.40% Test: 82.40%\n",
      "Run: 10, Epoch: 136, Loss: 0.2979, Train: 78.57%, Valid: 73.40% Test: 74.00%\n",
      "Run: 10, Epoch: 137, Loss: 0.2441, Train: 75.71%, Valid: 66.40% Test: 68.60%\n",
      "Run: 10, Epoch: 138, Loss: 0.2513, Train: 75.71%, Valid: 63.80% Test: 65.00%\n",
      "Run: 10, Epoch: 139, Loss: 0.3266, Train: 82.14%, Valid: 67.60% Test: 67.40%\n",
      "Run: 10, Epoch: 140, Loss: 0.2435, Train: 89.29%, Valid: 76.20% Test: 76.50%\n",
      "Run: 10, Epoch: 141, Loss: 0.3558, Train: 92.14%, Valid: 81.80% Test: 81.50%\n",
      "Run: 10, Epoch: 142, Loss: 0.3010, Train: 89.29%, Valid: 79.40% Test: 80.50%\n",
      "Run: 10, Epoch: 143, Loss: 0.2943, Train: 83.57%, Valid: 77.20% Test: 77.10%\n",
      "Run: 10, Epoch: 144, Loss: 0.2884, Train: 87.14%, Valid: 78.40% Test: 79.50%\n",
      "Run: 10, Epoch: 145, Loss: 0.2997, Train: 90.71%, Valid: 80.00% Test: 81.40%\n",
      "Run: 10, Epoch: 146, Loss: 0.2721, Train: 88.57%, Valid: 77.00% Test: 80.70%\n",
      "Run: 10, Epoch: 147, Loss: 0.2617, Train: 86.43%, Valid: 76.00% Test: 77.70%\n",
      "Run: 10, Epoch: 148, Loss: 0.2639, Train: 82.86%, Valid: 74.00% Test: 73.70%\n",
      "Run: 10, Epoch: 149, Loss: 0.2827, Train: 83.57%, Valid: 75.20% Test: 74.90%\n",
      "Run: 10, Epoch: 150, Loss: 0.2663, Train: 88.57%, Valid: 81.40% Test: 81.70%\n",
      "Run: 10, Epoch: 151, Loss: 0.2128, Train: 89.29%, Valid: 81.40% Test: 83.30%\n",
      "Run: 10, Epoch: 152, Loss: 0.3055, Train: 89.29%, Valid: 80.60% Test: 81.60%\n",
      "Run: 10, Epoch: 153, Loss: 0.2478, Train: 92.14%, Valid: 80.40% Test: 82.50%\n",
      "Run: 10, Epoch: 154, Loss: 0.2221, Train: 87.86%, Valid: 78.40% Test: 79.20%\n",
      "Run: 10, Epoch: 155, Loss: 0.2013, Train: 82.14%, Valid: 72.40% Test: 74.80%\n",
      "Run: 10, Epoch: 156, Loss: 0.2730, Train: 77.14%, Valid: 67.00% Test: 66.40%\n",
      "Run: 10, Epoch: 157, Loss: 0.2779, Train: 77.14%, Valid: 66.20% Test: 67.90%\n",
      "Run: 10, Epoch: 158, Loss: 0.2687, Train: 85.00%, Valid: 75.60% Test: 76.30%\n",
      "Run: 10, Epoch: 159, Loss: 0.2630, Train: 90.71%, Valid: 81.00% Test: 81.70%\n",
      "Run: 10, Epoch: 160, Loss: 0.2416, Train: 91.43%, Valid: 82.40% Test: 83.00%\n",
      "Run: 10, Epoch: 161, Loss: 0.2719, Train: 87.86%, Valid: 79.60% Test: 81.50%\n",
      "Run: 10, Epoch: 162, Loss: 0.2299, Train: 85.71%, Valid: 78.00% Test: 80.40%\n",
      "Run: 10, Epoch: 163, Loss: 0.2304, Train: 85.71%, Valid: 78.40% Test: 81.00%\n",
      "Run: 10, Epoch: 164, Loss: 0.2533, Train: 91.43%, Valid: 82.40% Test: 84.20%\n",
      "Run: 10, Epoch: 165, Loss: 0.2039, Train: 92.86%, Valid: 81.40% Test: 83.40%\n",
      "Run: 10, Epoch: 166, Loss: 0.2489, Train: 88.57%, Valid: 76.60% Test: 80.10%\n",
      "Run: 10, Epoch: 167, Loss: 0.2795, Train: 84.29%, Valid: 72.20% Test: 74.50%\n",
      "Run: 10, Epoch: 168, Loss: 0.2749, Train: 85.00%, Valid: 73.40% Test: 75.30%\n",
      "Run: 10, Epoch: 169, Loss: 0.2650, Train: 88.57%, Valid: 77.00% Test: 78.70%\n",
      "Run: 10, Epoch: 170, Loss: 0.2418, Train: 93.57%, Valid: 79.80% Test: 82.70%\n",
      "Run: 10, Epoch: 171, Loss: 0.2669, Train: 93.57%, Valid: 81.00% Test: 83.30%\n",
      "Run: 10, Epoch: 172, Loss: 0.3178, Train: 94.29%, Valid: 80.80% Test: 84.20%\n",
      "Run: 10, Epoch: 173, Loss: 0.2451, Train: 87.14%, Valid: 79.80% Test: 80.60%\n",
      "Run: 10, Epoch: 174, Loss: 0.2509, Train: 86.43%, Valid: 81.40% Test: 81.40%\n",
      "Run: 10, Epoch: 175, Loss: 0.2437, Train: 90.71%, Valid: 81.80% Test: 83.60%\n",
      "Run: 10, Epoch: 176, Loss: 0.1992, Train: 88.57%, Valid: 82.20% Test: 82.60%\n",
      "Run: 10, Epoch: 177, Loss: 0.2135, Train: 90.00%, Valid: 83.80% Test: 83.50%\n",
      "Run: 10, Epoch: 178, Loss: 0.2304, Train: 90.71%, Valid: 84.60% Test: 84.10%\n",
      "Run: 10, Epoch: 179, Loss: 0.2231, Train: 92.86%, Valid: 84.60% Test: 84.80%\n",
      "Run: 10, Epoch: 180, Loss: 0.2353, Train: 94.29%, Valid: 84.00% Test: 84.70%\n",
      "Run: 10, Epoch: 181, Loss: 0.1784, Train: 93.57%, Valid: 81.20% Test: 84.30%\n",
      "Run: 10, Epoch: 182, Loss: 0.2541, Train: 92.86%, Valid: 81.20% Test: 84.40%\n",
      "Run: 10, Epoch: 183, Loss: 0.2138, Train: 91.43%, Valid: 81.00% Test: 83.60%\n",
      "Run: 10, Epoch: 184, Loss: 0.2393, Train: 94.29%, Valid: 82.20% Test: 84.30%\n",
      "Run: 10, Epoch: 185, Loss: 0.2377, Train: 97.86%, Valid: 82.00% Test: 84.50%\n",
      "Run: 10, Epoch: 186, Loss: 0.2027, Train: 96.43%, Valid: 82.80% Test: 84.80%\n",
      "Run: 10, Epoch: 187, Loss: 0.1650, Train: 93.57%, Valid: 82.20% Test: 84.60%\n",
      "Run: 10, Epoch: 188, Loss: 0.2455, Train: 92.86%, Valid: 81.40% Test: 84.10%\n",
      "Run: 10, Epoch: 189, Loss: 0.1907, Train: 95.00%, Valid: 82.00% Test: 83.10%\n",
      "Run: 10, Epoch: 190, Loss: 0.2164, Train: 96.43%, Valid: 81.20% Test: 83.70%\n",
      "Run: 10, Epoch: 191, Loss: 0.2379, Train: 96.43%, Valid: 81.00% Test: 84.70%\n",
      "Run: 10, Epoch: 192, Loss: 0.2305, Train: 96.43%, Valid: 81.60% Test: 84.20%\n",
      "Run: 10, Epoch: 193, Loss: 0.2527, Train: 92.86%, Valid: 80.40% Test: 81.60%\n",
      "Run: 10, Epoch: 194, Loss: 0.1696, Train: 90.71%, Valid: 79.40% Test: 81.00%\n",
      "Run: 10, Epoch: 195, Loss: 0.2190, Train: 88.57%, Valid: 77.80% Test: 81.00%\n",
      "Run: 10, Epoch: 196, Loss: 0.1579, Train: 88.57%, Valid: 78.20% Test: 81.60%\n",
      "Run: 10, Epoch: 197, Loss: 0.2136, Train: 89.29%, Valid: 79.40% Test: 82.70%\n",
      "Run: 10, Epoch: 198, Loss: 0.2619, Train: 92.14%, Valid: 80.60% Test: 84.20%\n",
      "Run: 10, Epoch: 199, Loss: 0.2106, Train: 92.14%, Valid: 81.60% Test: 84.80%\n",
      "Run: 10, Epoch: 200, Loss: 0.2615, Train: 94.29%, Valid: 83.40% Test: 86.00%\n",
      "Run 10:\n",
      "Highest Train: 97.86\n",
      "Highest Valid: 84.60\n",
      "  Final Train: 90.71\n",
      "   Final Test: 84.10\n",
      "All runs:\n",
      "Highest Train: 96.79 ± 0.91\n",
      "Highest Valid: 84.78 ± 0.64\n",
      "  Final Train: 92.50 ± 1.88\n",
      "   Final Test: 84.63 ± 1.13\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    train_idx = np.where(data.train_mask)[0]\n",
    "    valid_idx = np.where(data.val_mask)[0]\n",
    "    test_idx = np.where(data.test_mask)[0]\n",
    "    \n",
    "    model = GCN(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085c7fd",
   "metadata": {},
   "source": [
    "# Topological Encodding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e47b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "607be4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 633 1862 2582 ...  598 1473 2706]\n",
      " [   0    0    0 ... 2707 2707 2707]]\n"
     ]
    }
   ],
   "source": [
    "print(data.edge_index.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52514bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_idx=data.edge_index.numpy()\n",
    "Node=range(Number_nodes)\n",
    "Edgelist=[]\n",
    "for i in range(len(Edge_idx[1])):\n",
    "    Edgelist.append((Edge_idx[0][i],Edge_idx[1][i]))\n",
    "#print(Edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9d236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a \"plain\" graph is undirected\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# give each a node a 'name', which is a letter in this case.\n",
    "#G.add_node('a')\n",
    "\n",
    "# the add_nodes_from method allows adding nodes from a sequence, in this case a list\n",
    "#nodes_to_add = ['b', 'c', 'd']\n",
    "G.add_nodes_from(Node)\n",
    "\n",
    "# add edge from 'a' to 'b'\n",
    "# since this graph is undirected, the order doesn't matter here\n",
    "#G.add_edge('a', 'b')\n",
    "\n",
    "# just like add_nodes_from, we can add edges from a sequence\n",
    "# edges should be specified as 2-tuples\n",
    "#edges_to_add = [('a', 'c'), ('b', 'c'), ('c', 'd')]\n",
    "G.add_edges_from(Edgelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "781abc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10556\n"
     ]
    }
   ],
   "source": [
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77abd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topological_Feature_subLevel(adj,filtration_fun, Filtration):\n",
    "        betti_0=[]\n",
    "        betti_1=[]\n",
    "        for p in range(len(Filtration)):\n",
    "            n_active = np.where(np.array(filtration_fun) <= Filtration[p])[0].tolist()\n",
    "            Active_node=np.unique(n_active)\n",
    "            if (len(Active_node)==0):\n",
    "                betti_0.append(0)\n",
    "                betti_1.append(0)\n",
    "            else:\n",
    "                b=adj[Active_node,:][:,Active_node]\n",
    "                my_flag=pyflagser.flagser_unweighted(b, min_dimension=0, max_dimension=2, directed=False, coeff=2, approximation=None)\n",
    "                x = my_flag[\"betti\"]\n",
    "                betti_0.append(x[0])\n",
    "                betti_1.append(x[1])\n",
    "            n_active.clear()\n",
    "        return betti_0,betti_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e40cacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Degree_list(Graph):\n",
    "    degree_list = [Graph.degree(node) for node in Graph.nodes]\n",
    "    return np.array(degree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "118b65fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  |  485 \n",
      "\n",
      "4  |  583 \n",
      "\n",
      "6  |  553 \n",
      "\n",
      "8  |  389 \n",
      "\n",
      "10  |  281 \n",
      "\n",
      "12  |  131 \n",
      "\n",
      "14  |  82 \n",
      "\n",
      "16  |  57 \n",
      "\n",
      "18  |  25 \n",
      "\n",
      "20  |  26 \n",
      "\n",
      "22  |  14 \n",
      "\n",
      "24  |  18 \n",
      "\n",
      "26  |  5 \n",
      "\n",
      "28  |  6 \n",
      "\n",
      "30  |  6 \n",
      "\n",
      "32  |  7 \n",
      "\n",
      "34  |  8 \n",
      "\n",
      "36  |  3 \n",
      "\n",
      "38  |  5 \n",
      "\n",
      "42  |  3 \n",
      "\n",
      "44  |  1 \n",
      "\n",
      "46  |  3 \n",
      "\n",
      "52  |  1 \n",
      "\n",
      "58  |  1 \n",
      "\n",
      "60  |  2 \n",
      "\n",
      "62  |  1 \n",
      "\n",
      "64  |  2 \n",
      "\n",
      "66  |  1 \n",
      "\n",
      "68  |  1 \n",
      "\n",
      "72  |  1 \n",
      "\n",
      "80  |  1 \n",
      "\n",
      "84  |  1 \n",
      "\n",
      "88  |  1 \n",
      "\n",
      "130  |  1 \n",
      "\n",
      "148  |  1 \n",
      "\n",
      "156  |  1 \n",
      "\n",
      "336  |  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "degree_list=Degree_list(G)\n",
    "unique_list=np.unique(degree_list)\n",
    "for d in unique_list:\n",
    "    count=0\n",
    "    for i in range(len(degree_list)):\n",
    "        if degree_list[i]==d:\n",
    "            count=count+1\n",
    "    print(int(d),\" | \",count,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7080881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 2707 (100%)"
     ]
    }
   ],
   "source": [
    "import pyflagser\n",
    "Node_fil=[2,4,6,8,10,12,14,16,18,20,22,24,30,34]\n",
    "topo_betti_0=[]\n",
    "topo_betti_1=[]\n",
    "Node_Edge=[]\n",
    "for i in range(Number_nodes):\n",
    "    print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//(Number_nodes-1)), end='', flush=True)\n",
    "    subgraph=ego_graph(G, i, radius=2, center=True, undirected=True, distance=None)\n",
    "    filt=Degree_list(subgraph)\n",
    "    A_sub = nx.to_numpy_array(subgraph)# adjacency matrix of subgraph\n",
    "    fe=Topological_Feature_subLevel(A_sub,filt,Node_fil)\n",
    "    topo_betti_0.append(fe[0])\n",
    "    topo_betti_1.append(fe[1])\n",
    "    Node_Edge.append([subgraph.number_of_nodes(),subgraph.number_of_edges()])\n",
    "    #topo_with_NE.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5892bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( Node_Edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49a08a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "445f9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_betti0=torch.tensor(topo_betti_0).float()\n",
    "topo_betti1=torch.tensor(topo_betti_1).float()\n",
    "NodeEdge=torch.tensor(Node_Edge).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f7a076",
   "metadata": {},
   "source": [
    "# TOPO-W_GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbeea52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556], topo=[2708, 28])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "topo_fe=torch.cat((topo_betti0,topo_betti1),1)\n",
    "data.topo=topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c78e7b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(topo_fe[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd4668e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        #return x.log_softmax(dim=-1)\n",
    "        return x\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        #return torch.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "class MLP2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP2, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp2(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "    \n",
    "\n",
    "def train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2):\n",
    "    model.train()\n",
    "    mlp_model.train()\n",
    "    mlp_2.train()\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_mlp.zero_grad()\n",
    "    optimizer_mlp2.zero_grad()\n",
    "    gcn_embedding = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(gcn_embedding)\n",
    "    mlp_embedding = mlp_model(data.topo[train_idx])\n",
    "    #print(mlp_embedding)\n",
    "    combined_embedding = torch.cat((gcn_embedding, mlp_embedding), dim=1)\n",
    "    #print(combined_embedding)\n",
    "    mlp_emb = mlp_2(combined_embedding)\n",
    "    #print(mlp_emb)\n",
    "    loss = F.nll_loss(mlp_emb, data.y.squeeze()[train_idx])\n",
    "    #loss = F.nll_loss(combined_embedding, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer_mlp2.step()\n",
    "    optimizer.step()\n",
    "    optimizer_mlp.step()\n",
    "    \n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "    mlp_model.eval()\n",
    "    mlp_2.eval()\n",
    "\n",
    "    gcn_out = model(data.x, data.adj_t)\n",
    "    #print(gcn_out[0])\n",
    "    mlp_out=mlp_model(data.topo)\n",
    "    #print(mlp_out)\n",
    "    #out=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    Com=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    out=mlp_2(Com)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    #print(y_pred[0])\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef21f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 76.20\n",
      "  Final Train: 100.00\n",
      "   Final Test: 76.90\n",
      "Run 02:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.00\n",
      "  Final Train: 100.00\n",
      "   Final Test: 74.10\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 70.60\n",
      "  Final Train: 100.00\n",
      "   Final Test: 72.30\n",
      "Run 04:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 79.20\n",
      "  Final Train: 100.00\n",
      "   Final Test: 78.60\n",
      "Run 05:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 75.00\n",
      "  Final Train: 100.00\n",
      "   Final Test: 76.10\n",
      "Run 06:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.80\n",
      "  Final Train: 100.00\n",
      "   Final Test: 76.20\n",
      "Run 07:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 75.20\n",
      "  Final Train: 100.00\n",
      "   Final Test: 75.20\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.20\n",
      "  Final Train: 100.00\n",
      "   Final Test: 74.80\n",
      "Run 09:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.20\n",
      "  Final Train: 100.00\n",
      "   Final Test: 74.00\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.80\n",
      "  Final Train: 100.00\n",
      "   Final Test: 74.90\n",
      "All runs:\n",
      "Highest Train: 100.00 ± 0.00\n",
      "Highest Valid: 74.32 ± 2.29\n",
      "  Final Train: 100.00 ± 0.00\n",
      "   Final Test: 75.31 ± 1.75\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.2,'num_layers_mlp': 3}\n",
    "\n",
    "    args = objectview(args)\n",
    "    #print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    train_idx = np.where(data.train_mask)[0]\n",
    "    valid_idx = np.where(data.val_mask)[0]\n",
    "    test_idx = np.where(data.test_mask)[0]\n",
    "    \n",
    "    model = GCN(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 5,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(15, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.001)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                #print(f'Run: {run + 1:02d}, 'f'Epoch: {epoch:02d}, 'f'Loss: {loss:.4f}, 'f'Train: {100 * train_acc:.2f}%, '\n",
    "                #      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                 #     f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd7bbb",
   "metadata": {},
   "source": [
    "# TOPO-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "topo_fe=torch.cat((topo_betti0,topo_betti1),1)\n",
    "data.topo=topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ac320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.2,'num_layers_mlp': 3}\n",
    "\n",
    "    args = objectview(args)\n",
    "    #print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    train_idx = np.where(data.train_mask)[0]\n",
    "    valid_idx = np.where(data.val_mask)[0]\n",
    "    test_idx = np.where(data.test_mask)[0]\n",
    "    \n",
    "    model = GCN(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 5,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(15, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.001)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                #print(f'Run: {run + 1:02d}, 'f'Epoch: {epoch:02d}, 'f'Loss: {loss:.4f}, 'f'Train: {100 * train_acc:.2f}%, '\n",
    "                #      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                 #     f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
