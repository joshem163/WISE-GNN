{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af88d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx import ego_graph\n",
    "\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "\n",
    "#from logger import Logger\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import WebKB\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7babc9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=325])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Texas', name='Texas',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "print(data)\n",
    "#split_idx = dataset.get_idx_split()\n",
    "#train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91fdcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "train_index = np.where(data.train_mask)[0]\n",
    "print(len(train_index))\n",
    "valid_index = np.where(data.val_mask)[0]\n",
    "print(len(valid_index))\n",
    "test_index = np.where(data.test_mask)[0]\n",
    "print(len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0b82f",
   "metadata": {},
   "source": [
    "# GSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9ef33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, runs, info=None):\n",
    "        self.info = info\n",
    "        self.results = [[] for _ in range(runs)]\n",
    "\n",
    "    def add_result(self, run, result):\n",
    "        assert len(result) == 3\n",
    "        assert run >= 0 and run < len(self.results)\n",
    "        self.results[run].append(result)\n",
    "\n",
    "    def print_statistics(self, run=None):\n",
    "        if run is not None:\n",
    "            result = 100 * torch.tensor(self.results[run])\n",
    "            argmax = result[:, 1].argmax().item()\n",
    "            print(f'Run {run + 1:02d}:')\n",
    "            print(f'Highest Train: {result[:, 0].max():.2f}')\n",
    "            print(f'Highest Valid: {result[:, 1].max():.2f}')\n",
    "            print(f'  Final Train: {result[argmax, 0]:.2f}')\n",
    "            print(f'   Final Test: {result[argmax, 2]:.2f}')\n",
    "        else:\n",
    "            result = 100 * torch.tensor(self.results)\n",
    "\n",
    "            best_results = []\n",
    "            for r in result:\n",
    "                train1 = r[:, 0].max().item()\n",
    "                valid = r[:, 1].max().item()\n",
    "                train2 = r[r[:, 1].argmax(), 0].item()\n",
    "                test = r[r[:, 1].argmax(), 2].item()\n",
    "                best_results.append((train1, valid, train2, test))\n",
    "\n",
    "            best_result = torch.tensor(best_results)\n",
    "\n",
    "            print(f'All runs:')\n",
    "            r = best_result[:, 0]\n",
    "            print(f'Highest Train: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 1]\n",
    "            print(f'Highest Valid: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 2]\n",
    "            print(f'  Final Train: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 3]\n",
    "            print(f'   Final Test: {r.mean():.2f} ± {r.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47468ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(len(out))\n",
    "    #print(data.y.squeeze(1)[train_idx])\n",
    "    loss = F.nll_loss(out, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.adj_t)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e19e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   2   4   8  11  13  15  19  21  26  32  35  37  39  41  44  45  46\n",
      "  50  53  58  59  60  61  63  65  66  70  71  72  73  74  75  76  77  78\n",
      "  83  85  86  88  89  92  94  95  96 101 103 104 105 107 108 110 113 115\n",
      " 116 119 120 121 123 124 125 126 130 131 133 135 137 139 140 141 142 144\n",
      " 145 146 148 152 153 156 161 168 170 171 173 177 179 181 182]\n"
     ]
    }
   ],
   "source": [
    "idx=[data.train_mask[i][0] for i in range(183)]\n",
    "train_index = np.where(idx)[0]\n",
    "print(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b23796d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x16585a3b0>\n",
      "Run: 01, Epoch: 01, Loss: 1.8516, Train: 70.11%, Valid: 62.71% Test: 56.76%\n",
      "Run: 01, Epoch: 02, Loss: 0.9066, Train: 82.76%, Valid: 71.19% Test: 67.57%\n",
      "Run: 01, Epoch: 03, Loss: 0.6393, Train: 87.36%, Valid: 72.88% Test: 75.68%\n",
      "Run: 01, Epoch: 04, Loss: 0.5655, Train: 88.51%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 05, Loss: 0.4842, Train: 90.80%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 06, Loss: 0.4468, Train: 93.10%, Valid: 71.19% Test: 78.38%\n",
      "Run: 01, Epoch: 07, Loss: 0.3503, Train: 94.25%, Valid: 72.88% Test: 78.38%\n",
      "Run: 01, Epoch: 08, Loss: 0.3169, Train: 95.40%, Valid: 72.88% Test: 78.38%\n",
      "Run: 01, Epoch: 09, Loss: 0.3446, Train: 95.40%, Valid: 74.58% Test: 81.08%\n",
      "Run: 01, Epoch: 10, Loss: 0.2925, Train: 97.70%, Valid: 74.58% Test: 81.08%\n",
      "Run: 01, Epoch: 11, Loss: 0.2317, Train: 97.70%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 12, Loss: 0.2311, Train: 98.85%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 13, Loss: 0.1854, Train: 98.85%, Valid: 76.27% Test: 78.38%\n",
      "Run: 01, Epoch: 14, Loss: 0.1962, Train: 98.85%, Valid: 76.27% Test: 81.08%\n",
      "Run: 01, Epoch: 15, Loss: 0.1708, Train: 98.85%, Valid: 76.27% Test: 81.08%\n",
      "Run: 01, Epoch: 16, Loss: 0.1712, Train: 98.85%, Valid: 76.27% Test: 81.08%\n",
      "Run: 01, Epoch: 17, Loss: 0.1205, Train: 100.00%, Valid: 76.27% Test: 83.78%\n",
      "Run: 01, Epoch: 18, Loss: 0.1008, Train: 100.00%, Valid: 76.27% Test: 86.49%\n",
      "Run: 01, Epoch: 19, Loss: 0.1331, Train: 100.00%, Valid: 76.27% Test: 89.19%\n",
      "Run: 01, Epoch: 20, Loss: 0.1034, Train: 100.00%, Valid: 77.97% Test: 89.19%\n",
      "Run: 01, Epoch: 21, Loss: 0.1180, Train: 100.00%, Valid: 77.97% Test: 89.19%\n",
      "Run: 01, Epoch: 22, Loss: 0.0868, Train: 100.00%, Valid: 77.97% Test: 89.19%\n",
      "Run: 01, Epoch: 23, Loss: 0.1096, Train: 100.00%, Valid: 77.97% Test: 89.19%\n",
      "Run: 01, Epoch: 24, Loss: 0.0914, Train: 100.00%, Valid: 76.27% Test: 89.19%\n",
      "Run: 01, Epoch: 25, Loss: 0.1075, Train: 100.00%, Valid: 76.27% Test: 89.19%\n",
      "Run: 01, Epoch: 26, Loss: 0.0810, Train: 100.00%, Valid: 76.27% Test: 89.19%\n",
      "Run: 01, Epoch: 27, Loss: 0.0616, Train: 100.00%, Valid: 76.27% Test: 89.19%\n",
      "Run: 01, Epoch: 28, Loss: 0.0545, Train: 100.00%, Valid: 76.27% Test: 89.19%\n",
      "Run: 01, Epoch: 29, Loss: 0.0704, Train: 100.00%, Valid: 77.97% Test: 86.49%\n",
      "Run: 01, Epoch: 30, Loss: 0.0381, Train: 100.00%, Valid: 77.97% Test: 86.49%\n",
      "Run: 01, Epoch: 31, Loss: 0.0279, Train: 100.00%, Valid: 77.97% Test: 86.49%\n",
      "Run: 01, Epoch: 32, Loss: 0.0494, Train: 100.00%, Valid: 77.97% Test: 86.49%\n",
      "Run: 01, Epoch: 33, Loss: 0.0443, Train: 100.00%, Valid: 77.97% Test: 86.49%\n",
      "Run: 01, Epoch: 34, Loss: 0.0414, Train: 100.00%, Valid: 77.97% Test: 86.49%\n",
      "Run: 01, Epoch: 35, Loss: 0.0599, Train: 100.00%, Valid: 77.97% Test: 86.49%\n",
      "Run: 01, Epoch: 36, Loss: 0.0540, Train: 100.00%, Valid: 77.97% Test: 86.49%\n",
      "Run: 01, Epoch: 37, Loss: 0.0222, Train: 100.00%, Valid: 77.97% Test: 86.49%\n",
      "Run: 01, Epoch: 38, Loss: 0.0381, Train: 100.00%, Valid: 77.97% Test: 89.19%\n",
      "Run: 01, Epoch: 39, Loss: 0.0262, Train: 100.00%, Valid: 77.97% Test: 91.89%\n",
      "Run: 01, Epoch: 40, Loss: 0.0262, Train: 100.00%, Valid: 79.66% Test: 91.89%\n",
      "Run: 01, Epoch: 41, Loss: 0.0371, Train: 100.00%, Valid: 81.36% Test: 91.89%\n",
      "Run: 01, Epoch: 42, Loss: 0.0385, Train: 100.00%, Valid: 81.36% Test: 91.89%\n",
      "Run: 01, Epoch: 43, Loss: 0.0512, Train: 100.00%, Valid: 81.36% Test: 91.89%\n",
      "Run: 01, Epoch: 44, Loss: 0.0173, Train: 100.00%, Valid: 81.36% Test: 91.89%\n",
      "Run: 01, Epoch: 45, Loss: 0.0309, Train: 100.00%, Valid: 81.36% Test: 91.89%\n",
      "Run: 01, Epoch: 46, Loss: 0.0263, Train: 100.00%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 47, Loss: 0.0311, Train: 100.00%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 48, Loss: 0.0283, Train: 100.00%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 49, Loss: 0.0514, Train: 100.00%, Valid: 83.05% Test: 94.59%\n",
      "Run: 01, Epoch: 50, Loss: 0.0204, Train: 100.00%, Valid: 83.05% Test: 94.59%\n",
      "Run: 01, Epoch: 51, Loss: 0.0228, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 52, Loss: 0.0354, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 53, Loss: 0.0376, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 54, Loss: 0.0166, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 55, Loss: 0.0247, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 56, Loss: 0.0131, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 57, Loss: 0.0281, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 58, Loss: 0.0246, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 59, Loss: 0.0153, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 60, Loss: 0.0176, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 61, Loss: 0.0115, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 62, Loss: 0.0167, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 63, Loss: 0.0076, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 64, Loss: 0.0270, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 65, Loss: 0.0280, Train: 100.00%, Valid: 84.75% Test: 94.59%\n",
      "Run: 01, Epoch: 66, Loss: 0.0226, Train: 100.00%, Valid: 83.05% Test: 94.59%\n",
      "Run: 01, Epoch: 67, Loss: 0.0067, Train: 100.00%, Valid: 83.05% Test: 94.59%\n",
      "Run: 01, Epoch: 68, Loss: 0.0202, Train: 100.00%, Valid: 83.05% Test: 94.59%\n",
      "Run: 01, Epoch: 69, Loss: 0.0149, Train: 100.00%, Valid: 83.05% Test: 94.59%\n",
      "Run: 01, Epoch: 70, Loss: 0.0302, Train: 100.00%, Valid: 83.05% Test: 94.59%\n",
      "Run: 01, Epoch: 71, Loss: 0.0105, Train: 100.00%, Valid: 83.05% Test: 94.59%\n",
      "Run: 01, Epoch: 72, Loss: 0.0229, Train: 100.00%, Valid: 83.05% Test: 94.59%\n",
      "Run: 01, Epoch: 73, Loss: 0.0063, Train: 100.00%, Valid: 83.05% Test: 94.59%\n",
      "Run: 01, Epoch: 74, Loss: 0.0176, Train: 100.00%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 75, Loss: 0.0132, Train: 100.00%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 76, Loss: 0.0257, Train: 100.00%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 77, Loss: 0.0259, Train: 100.00%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 78, Loss: 0.0288, Train: 100.00%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 79, Loss: 0.0131, Train: 100.00%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 80, Loss: 0.0021, Train: 100.00%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 81, Loss: 0.0109, Train: 100.00%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 82, Loss: 0.0136, Train: 100.00%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 83, Loss: 0.0112, Train: 100.00%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 84, Loss: 0.0094, Train: 100.00%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 85, Loss: 0.0166, Train: 100.00%, Valid: 84.75% Test: 89.19%\n",
      "Run: 01, Epoch: 86, Loss: 0.0027, Train: 100.00%, Valid: 83.05% Test: 89.19%\n",
      "Run: 01, Epoch: 87, Loss: 0.0112, Train: 100.00%, Valid: 83.05% Test: 89.19%\n",
      "Run: 01, Epoch: 88, Loss: 0.0104, Train: 100.00%, Valid: 86.44% Test: 89.19%\n",
      "Run: 01, Epoch: 89, Loss: 0.0224, Train: 100.00%, Valid: 86.44% Test: 89.19%\n",
      "Run: 01, Epoch: 90, Loss: 0.0114, Train: 100.00%, Valid: 84.75% Test: 89.19%\n",
      "Run: 01, Epoch: 91, Loss: 0.0172, Train: 100.00%, Valid: 86.44% Test: 89.19%\n",
      "Run: 01, Epoch: 92, Loss: 0.0232, Train: 100.00%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 93, Loss: 0.0320, Train: 100.00%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 94, Loss: 0.0147, Train: 100.00%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 95, Loss: 0.0048, Train: 100.00%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 96, Loss: 0.0163, Train: 100.00%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 97, Loss: 0.0099, Train: 100.00%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 98, Loss: 0.0161, Train: 100.00%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 99, Loss: 0.0153, Train: 100.00%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 100, Loss: 0.0079, Train: 100.00%, Valid: 86.44% Test: 91.89%\n",
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 86.44\n",
      "  Final Train: 100.00\n",
      "   Final Test: 89.19\n",
      "Run: 02, Epoch: 01, Loss: 1.7072, Train: 55.17%, Valid: 30.51% Test: 48.65%\n",
      "Run: 02, Epoch: 02, Loss: 0.9721, Train: 73.56%, Valid: 45.76% Test: 54.05%\n",
      "Run: 02, Epoch: 03, Loss: 0.7687, Train: 87.36%, Valid: 62.71% Test: 67.57%\n",
      "Run: 02, Epoch: 04, Loss: 0.6287, Train: 87.36%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 05, Loss: 0.6001, Train: 87.36%, Valid: 69.49% Test: 72.97%\n",
      "Run: 02, Epoch: 06, Loss: 0.6001, Train: 87.36%, Valid: 69.49% Test: 72.97%\n",
      "Run: 02, Epoch: 07, Loss: 0.4728, Train: 88.51%, Valid: 71.19% Test: 75.68%\n",
      "Run: 02, Epoch: 08, Loss: 0.4400, Train: 88.51%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 09, Loss: 0.3315, Train: 88.51%, Valid: 71.19% Test: 75.68%\n",
      "Run: 02, Epoch: 10, Loss: 0.3792, Train: 88.51%, Valid: 69.49% Test: 75.68%\n",
      "Run: 02, Epoch: 11, Loss: 0.3451, Train: 90.80%, Valid: 69.49% Test: 81.08%\n",
      "Run: 02, Epoch: 12, Loss: 0.2990, Train: 93.10%, Valid: 69.49% Test: 81.08%\n",
      "Run: 02, Epoch: 13, Loss: 0.2336, Train: 93.10%, Valid: 71.19% Test: 81.08%\n",
      "Run: 02, Epoch: 14, Loss: 0.2383, Train: 94.25%, Valid: 71.19% Test: 78.38%\n",
      "Run: 02, Epoch: 15, Loss: 0.2070, Train: 98.85%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 16, Loss: 0.2608, Train: 98.85%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 17, Loss: 0.2465, Train: 98.85%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 18, Loss: 0.2055, Train: 98.85%, Valid: 69.49% Test: 78.38%\n",
      "Run: 02, Epoch: 19, Loss: 0.1588, Train: 98.85%, Valid: 72.88% Test: 78.38%\n",
      "Run: 02, Epoch: 20, Loss: 0.1173, Train: 98.85%, Valid: 72.88% Test: 78.38%\n",
      "Run: 02, Epoch: 21, Loss: 0.1289, Train: 98.85%, Valid: 72.88% Test: 78.38%\n",
      "Run: 02, Epoch: 22, Loss: 0.1384, Train: 98.85%, Valid: 72.88% Test: 78.38%\n",
      "Run: 02, Epoch: 23, Loss: 0.1378, Train: 100.00%, Valid: 72.88% Test: 78.38%\n",
      "Run: 02, Epoch: 24, Loss: 0.1337, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 25, Loss: 0.1180, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 26, Loss: 0.1035, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 27, Loss: 0.0804, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 28, Loss: 0.0812, Train: 100.00%, Valid: 72.88% Test: 78.38%\n",
      "Run: 02, Epoch: 29, Loss: 0.0768, Train: 100.00%, Valid: 72.88% Test: 78.38%\n",
      "Run: 02, Epoch: 30, Loss: 0.0968, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 31, Loss: 0.0743, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 32, Loss: 0.0612, Train: 100.00%, Valid: 74.58% Test: 78.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 33, Loss: 0.0795, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 34, Loss: 0.0482, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 35, Loss: 0.0573, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 36, Loss: 0.0688, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 37, Loss: 0.0554, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 38, Loss: 0.0636, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 39, Loss: 0.0545, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 40, Loss: 0.0408, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 41, Loss: 0.0458, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 42, Loss: 0.0515, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 43, Loss: 0.0368, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 44, Loss: 0.0708, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 45, Loss: 0.0454, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 46, Loss: 0.0325, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 47, Loss: 0.0224, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 48, Loss: 0.0159, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 49, Loss: 0.0251, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 50, Loss: 0.0118, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 51, Loss: 0.0198, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 52, Loss: 0.0585, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 53, Loss: 0.0306, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 54, Loss: 0.0163, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 55, Loss: 0.0311, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 56, Loss: 0.0288, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 57, Loss: 0.0346, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 58, Loss: 0.0090, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 59, Loss: 0.0176, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 60, Loss: 0.0221, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 61, Loss: 0.0343, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 62, Loss: 0.0103, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 63, Loss: 0.0132, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 64, Loss: 0.0120, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 65, Loss: 0.0249, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 66, Loss: 0.0092, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 67, Loss: 0.0180, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 68, Loss: 0.0376, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 69, Loss: 0.0152, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 70, Loss: 0.0200, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 71, Loss: 0.0270, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 72, Loss: 0.0134, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 73, Loss: 0.0111, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 74, Loss: 0.0362, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 75, Loss: 0.0237, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 76, Loss: 0.0140, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 77, Loss: 0.0062, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 78, Loss: 0.0076, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 79, Loss: 0.0205, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 80, Loss: 0.0110, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 81, Loss: 0.0022, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 82, Loss: 0.0164, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 83, Loss: 0.0143, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 84, Loss: 0.0330, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 85, Loss: 0.0141, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 86, Loss: 0.0174, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 87, Loss: 0.0112, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 88, Loss: 0.0137, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 89, Loss: 0.0077, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 90, Loss: 0.0192, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 91, Loss: 0.0121, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 92, Loss: 0.0128, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 93, Loss: 0.0141, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 94, Loss: 0.0084, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 95, Loss: 0.0042, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 96, Loss: 0.0063, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 97, Loss: 0.0193, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 98, Loss: 0.0096, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 99, Loss: 0.0063, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 100, Loss: 0.0304, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run 02:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 77.97\n",
      "  Final Train: 100.00\n",
      "   Final Test: 78.38\n",
      "Run: 03, Epoch: 01, Loss: 2.0939, Train: 60.92%, Valid: 40.68% Test: 40.54%\n",
      "Run: 03, Epoch: 02, Loss: 1.1016, Train: 81.61%, Valid: 62.71% Test: 56.76%\n",
      "Run: 03, Epoch: 03, Loss: 0.7425, Train: 80.46%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 04, Loss: 0.7259, Train: 81.61%, Valid: 77.97% Test: 67.57%\n",
      "Run: 03, Epoch: 05, Loss: 0.5703, Train: 83.91%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 06, Loss: 0.4998, Train: 85.06%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 07, Loss: 0.4141, Train: 85.06%, Valid: 77.97% Test: 67.57%\n",
      "Run: 03, Epoch: 08, Loss: 0.3860, Train: 87.36%, Valid: 77.97% Test: 67.57%\n",
      "Run: 03, Epoch: 09, Loss: 0.3896, Train: 90.80%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 10, Loss: 0.3678, Train: 91.95%, Valid: 77.97% Test: 67.57%\n",
      "Run: 03, Epoch: 11, Loss: 0.2893, Train: 94.25%, Valid: 79.66% Test: 67.57%\n",
      "Run: 03, Epoch: 12, Loss: 0.2724, Train: 95.40%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 13, Loss: 0.2578, Train: 96.55%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 14, Loss: 0.2688, Train: 96.55%, Valid: 81.36% Test: 70.27%\n",
      "Run: 03, Epoch: 15, Loss: 0.2306, Train: 98.85%, Valid: 83.05% Test: 64.86%\n",
      "Run: 03, Epoch: 16, Loss: 0.2284, Train: 98.85%, Valid: 83.05% Test: 64.86%\n",
      "Run: 03, Epoch: 17, Loss: 0.1927, Train: 98.85%, Valid: 83.05% Test: 64.86%\n",
      "Run: 03, Epoch: 18, Loss: 0.1653, Train: 100.00%, Valid: 83.05% Test: 64.86%\n",
      "Run: 03, Epoch: 19, Loss: 0.2114, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 20, Loss: 0.1199, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 21, Loss: 0.1343, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 03, Epoch: 22, Loss: 0.1601, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 03, Epoch: 23, Loss: 0.1391, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 03, Epoch: 24, Loss: 0.1244, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 25, Loss: 0.1099, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 26, Loss: 0.1203, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 27, Loss: 0.0868, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 28, Loss: 0.0737, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 29, Loss: 0.0624, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 30, Loss: 0.0520, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 31, Loss: 0.0702, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 32, Loss: 0.0783, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 33, Loss: 0.0628, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 03, Epoch: 34, Loss: 0.0371, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 35, Loss: 0.0747, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 36, Loss: 0.0401, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 37, Loss: 0.0335, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 38, Loss: 0.0245, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 39, Loss: 0.0402, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 40, Loss: 0.0394, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 41, Loss: 0.0232, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 42, Loss: 0.0358, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 43, Loss: 0.0467, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 44, Loss: 0.0318, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 45, Loss: 0.0196, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 46, Loss: 0.0187, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 47, Loss: 0.0403, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 48, Loss: 0.0179, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 49, Loss: 0.0462, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 50, Loss: 0.0266, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 51, Loss: 0.0592, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 52, Loss: 0.0197, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 53, Loss: 0.0263, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 54, Loss: 0.0469, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 55, Loss: 0.0282, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 56, Loss: 0.0218, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 57, Loss: 0.0135, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 58, Loss: 0.0175, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 59, Loss: 0.0107, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 60, Loss: 0.0138, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 61, Loss: 0.0283, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 62, Loss: 0.0265, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 63, Loss: 0.0228, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 64, Loss: 0.0430, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 65, Loss: 0.0152, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 66, Loss: 0.0412, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 67, Loss: 0.0370, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 68, Loss: 0.0081, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 69, Loss: 0.0174, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 70, Loss: 0.0109, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 71, Loss: 0.0196, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 72, Loss: 0.0575, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 73, Loss: 0.0292, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 74, Loss: 0.0141, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 75, Loss: 0.0127, Train: 100.00%, Valid: 74.58% Test: 64.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 76, Loss: 0.0049, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 03, Epoch: 77, Loss: 0.0100, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 03, Epoch: 78, Loss: 0.0167, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 03, Epoch: 79, Loss: 0.0139, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 03, Epoch: 80, Loss: 0.0093, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 81, Loss: 0.0057, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 82, Loss: 0.0054, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 83, Loss: 0.0091, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 84, Loss: 0.0109, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 85, Loss: 0.0106, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 86, Loss: 0.0092, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 03, Epoch: 87, Loss: 0.0042, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 03, Epoch: 88, Loss: 0.0119, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 03, Epoch: 89, Loss: 0.0075, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 03, Epoch: 90, Loss: 0.0080, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 03, Epoch: 91, Loss: 0.0061, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 03, Epoch: 92, Loss: 0.0054, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 03, Epoch: 93, Loss: 0.0135, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 03, Epoch: 94, Loss: 0.0087, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 03, Epoch: 95, Loss: 0.0204, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 03, Epoch: 96, Loss: 0.0066, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 03, Epoch: 97, Loss: 0.0149, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 03, Epoch: 98, Loss: 0.0198, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 03, Epoch: 99, Loss: 0.0240, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 03, Epoch: 100, Loss: 0.0073, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 83.05\n",
      "  Final Train: 98.85\n",
      "   Final Test: 64.86\n",
      "Run: 04, Epoch: 01, Loss: 1.6071, Train: 83.91%, Valid: 61.02% Test: 64.86%\n",
      "Run: 04, Epoch: 02, Loss: 0.8726, Train: 90.80%, Valid: 67.80% Test: 70.27%\n",
      "Run: 04, Epoch: 03, Loss: 0.6550, Train: 89.66%, Valid: 67.80% Test: 67.57%\n",
      "Run: 04, Epoch: 04, Loss: 0.5776, Train: 87.36%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 05, Loss: 0.4871, Train: 88.51%, Valid: 66.10% Test: 72.97%\n",
      "Run: 04, Epoch: 06, Loss: 0.4575, Train: 93.10%, Valid: 66.10% Test: 75.68%\n",
      "Run: 04, Epoch: 07, Loss: 0.3986, Train: 94.25%, Valid: 66.10% Test: 75.68%\n",
      "Run: 04, Epoch: 08, Loss: 0.3045, Train: 94.25%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 09, Loss: 0.3199, Train: 95.40%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 10, Loss: 0.3178, Train: 96.55%, Valid: 72.88% Test: 78.38%\n",
      "Run: 04, Epoch: 11, Loss: 0.2847, Train: 96.55%, Valid: 76.27% Test: 78.38%\n",
      "Run: 04, Epoch: 12, Loss: 0.2631, Train: 96.55%, Valid: 72.88% Test: 78.38%\n",
      "Run: 04, Epoch: 13, Loss: 0.2168, Train: 98.85%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 14, Loss: 0.1336, Train: 98.85%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 15, Loss: 0.1677, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 16, Loss: 0.1586, Train: 98.85%, Valid: 67.80% Test: 72.97%\n",
      "Run: 04, Epoch: 17, Loss: 0.1347, Train: 98.85%, Valid: 67.80% Test: 72.97%\n",
      "Run: 04, Epoch: 18, Loss: 0.1609, Train: 98.85%, Valid: 67.80% Test: 72.97%\n",
      "Run: 04, Epoch: 19, Loss: 0.0998, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 04, Epoch: 20, Loss: 0.0853, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 04, Epoch: 21, Loss: 0.1003, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 04, Epoch: 22, Loss: 0.0925, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 04, Epoch: 23, Loss: 0.0895, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 04, Epoch: 24, Loss: 0.0802, Train: 100.00%, Valid: 67.80% Test: 75.68%\n",
      "Run: 04, Epoch: 25, Loss: 0.0602, Train: 100.00%, Valid: 67.80% Test: 75.68%\n",
      "Run: 04, Epoch: 26, Loss: 0.0735, Train: 100.00%, Valid: 67.80% Test: 75.68%\n",
      "Run: 04, Epoch: 27, Loss: 0.0894, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 28, Loss: 0.0800, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 29, Loss: 0.0802, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 30, Loss: 0.0835, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 31, Loss: 0.0594, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 32, Loss: 0.0580, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 33, Loss: 0.0347, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 34, Loss: 0.0354, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 35, Loss: 0.0451, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 36, Loss: 0.0467, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 37, Loss: 0.0735, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 38, Loss: 0.0669, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 39, Loss: 0.0514, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 40, Loss: 0.0251, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 41, Loss: 0.0294, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 42, Loss: 0.0414, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 43, Loss: 0.0398, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 44, Loss: 0.0421, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 45, Loss: 0.0070, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 46, Loss: 0.0131, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 47, Loss: 0.0260, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 48, Loss: 0.0175, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 49, Loss: 0.0183, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 50, Loss: 0.0315, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 51, Loss: 0.0301, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 52, Loss: 0.0215, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 53, Loss: 0.0190, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 54, Loss: 0.0217, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 55, Loss: 0.0183, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 56, Loss: 0.0259, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 57, Loss: 0.0215, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 58, Loss: 0.0404, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 59, Loss: 0.0171, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 60, Loss: 0.0285, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 61, Loss: 0.0357, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 62, Loss: 0.0051, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 63, Loss: 0.0154, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 64, Loss: 0.0123, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 65, Loss: 0.0061, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 66, Loss: 0.0330, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 67, Loss: 0.0071, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 68, Loss: 0.0244, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 69, Loss: 0.0071, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 70, Loss: 0.0155, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 71, Loss: 0.0141, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 72, Loss: 0.0079, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 73, Loss: 0.0084, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 74, Loss: 0.0325, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 75, Loss: 0.0237, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 76, Loss: 0.0131, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 77, Loss: 0.0046, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 78, Loss: 0.0177, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 79, Loss: 0.0074, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 80, Loss: 0.0036, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 81, Loss: 0.0128, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 82, Loss: 0.0129, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 83, Loss: 0.0219, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 84, Loss: 0.0159, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 85, Loss: 0.0068, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 86, Loss: 0.0076, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 87, Loss: 0.0096, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 88, Loss: 0.0136, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 89, Loss: 0.0395, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 90, Loss: 0.0091, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 91, Loss: 0.0237, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 92, Loss: 0.0236, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 93, Loss: 0.0041, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 94, Loss: 0.0044, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 95, Loss: 0.0118, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 96, Loss: 0.0082, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 97, Loss: 0.0304, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 98, Loss: 0.0121, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 99, Loss: 0.0125, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 100, Loss: 0.0045, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run 04:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 76.27\n",
      "  Final Train: 96.55\n",
      "   Final Test: 78.38\n",
      "Run: 05, Epoch: 01, Loss: 1.5953, Train: 63.22%, Valid: 33.90% Test: 40.54%\n",
      "Run: 05, Epoch: 02, Loss: 0.7835, Train: 74.71%, Valid: 38.98% Test: 43.24%\n",
      "Run: 05, Epoch: 03, Loss: 0.6876, Train: 87.36%, Valid: 42.37% Test: 48.65%\n",
      "Run: 05, Epoch: 04, Loss: 0.5851, Train: 87.36%, Valid: 50.85% Test: 59.46%\n",
      "Run: 05, Epoch: 05, Loss: 0.4762, Train: 88.51%, Valid: 54.24% Test: 59.46%\n",
      "Run: 05, Epoch: 06, Loss: 0.4292, Train: 89.66%, Valid: 59.32% Test: 67.57%\n",
      "Run: 05, Epoch: 07, Loss: 0.3415, Train: 93.10%, Valid: 59.32% Test: 67.57%\n",
      "Run: 05, Epoch: 08, Loss: 0.3601, Train: 95.40%, Valid: 59.32% Test: 67.57%\n",
      "Run: 05, Epoch: 09, Loss: 0.4414, Train: 95.40%, Valid: 59.32% Test: 70.27%\n",
      "Run: 05, Epoch: 10, Loss: 0.2526, Train: 96.55%, Valid: 59.32% Test: 70.27%\n",
      "Run: 05, Epoch: 11, Loss: 0.2579, Train: 96.55%, Valid: 61.02% Test: 70.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 12, Loss: 0.2393, Train: 97.70%, Valid: 61.02% Test: 70.27%\n",
      "Run: 05, Epoch: 13, Loss: 0.1916, Train: 98.85%, Valid: 61.02% Test: 70.27%\n",
      "Run: 05, Epoch: 14, Loss: 0.1727, Train: 98.85%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 15, Loss: 0.1623, Train: 98.85%, Valid: 62.71% Test: 70.27%\n",
      "Run: 05, Epoch: 16, Loss: 0.1411, Train: 98.85%, Valid: 64.41% Test: 70.27%\n",
      "Run: 05, Epoch: 17, Loss: 0.1428, Train: 98.85%, Valid: 67.80% Test: 70.27%\n",
      "Run: 05, Epoch: 18, Loss: 0.1461, Train: 98.85%, Valid: 67.80% Test: 62.16%\n",
      "Run: 05, Epoch: 19, Loss: 0.1573, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 05, Epoch: 20, Loss: 0.0751, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 05, Epoch: 21, Loss: 0.0811, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 05, Epoch: 22, Loss: 0.0891, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 05, Epoch: 23, Loss: 0.0863, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 05, Epoch: 24, Loss: 0.0681, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 05, Epoch: 25, Loss: 0.0683, Train: 100.00%, Valid: 72.88% Test: 70.27%\n",
      "Run: 05, Epoch: 26, Loss: 0.0620, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 05, Epoch: 27, Loss: 0.0852, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 05, Epoch: 28, Loss: 0.0885, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 05, Epoch: 29, Loss: 0.0886, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 05, Epoch: 30, Loss: 0.0291, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 05, Epoch: 31, Loss: 0.0462, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 05, Epoch: 32, Loss: 0.0309, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 05, Epoch: 33, Loss: 0.0440, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 05, Epoch: 34, Loss: 0.0354, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 05, Epoch: 35, Loss: 0.0238, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 05, Epoch: 36, Loss: 0.0227, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 05, Epoch: 37, Loss: 0.0227, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 05, Epoch: 38, Loss: 0.0345, Train: 100.00%, Valid: 81.36% Test: 70.27%\n",
      "Run: 05, Epoch: 39, Loss: 0.0393, Train: 100.00%, Valid: 81.36% Test: 70.27%\n",
      "Run: 05, Epoch: 40, Loss: 0.0542, Train: 100.00%, Valid: 81.36% Test: 70.27%\n",
      "Run: 05, Epoch: 41, Loss: 0.0204, Train: 100.00%, Valid: 83.05% Test: 70.27%\n",
      "Run: 05, Epoch: 42, Loss: 0.0295, Train: 100.00%, Valid: 84.75% Test: 70.27%\n",
      "Run: 05, Epoch: 43, Loss: 0.0229, Train: 100.00%, Valid: 84.75% Test: 70.27%\n",
      "Run: 05, Epoch: 44, Loss: 0.0367, Train: 100.00%, Valid: 84.75% Test: 70.27%\n",
      "Run: 05, Epoch: 45, Loss: 0.0360, Train: 100.00%, Valid: 83.05% Test: 70.27%\n",
      "Run: 05, Epoch: 46, Loss: 0.0334, Train: 100.00%, Valid: 83.05% Test: 70.27%\n",
      "Run: 05, Epoch: 47, Loss: 0.0410, Train: 100.00%, Valid: 83.05% Test: 70.27%\n",
      "Run: 05, Epoch: 48, Loss: 0.0112, Train: 100.00%, Valid: 83.05% Test: 70.27%\n",
      "Run: 05, Epoch: 49, Loss: 0.0247, Train: 100.00%, Valid: 83.05% Test: 70.27%\n",
      "Run: 05, Epoch: 50, Loss: 0.0378, Train: 100.00%, Valid: 81.36% Test: 70.27%\n",
      "Run: 05, Epoch: 51, Loss: 0.0281, Train: 100.00%, Valid: 81.36% Test: 70.27%\n",
      "Run: 05, Epoch: 52, Loss: 0.0174, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 53, Loss: 0.0132, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 54, Loss: 0.0279, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 55, Loss: 0.0146, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 56, Loss: 0.0306, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 57, Loss: 0.0153, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 58, Loss: 0.0331, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 59, Loss: 0.0223, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 60, Loss: 0.0064, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 61, Loss: 0.0381, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 62, Loss: 0.0334, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 63, Loss: 0.0218, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 64, Loss: 0.0194, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 65, Loss: 0.0074, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 66, Loss: 0.0312, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 67, Loss: 0.0057, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 68, Loss: 0.0281, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 69, Loss: 0.0231, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 70, Loss: 0.0085, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 05, Epoch: 71, Loss: 0.0074, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 72, Loss: 0.0118, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 73, Loss: 0.0112, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 74, Loss: 0.0055, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 75, Loss: 0.0102, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 76, Loss: 0.0169, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 77, Loss: 0.0194, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 78, Loss: 0.0042, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 79, Loss: 0.0088, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 80, Loss: 0.0095, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 81, Loss: 0.0234, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 82, Loss: 0.0062, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 83, Loss: 0.0267, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 84, Loss: 0.0243, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 85, Loss: 0.0027, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 86, Loss: 0.0125, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 87, Loss: 0.0240, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 88, Loss: 0.0094, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 89, Loss: 0.0146, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 90, Loss: 0.0053, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 91, Loss: 0.0063, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 92, Loss: 0.0090, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 93, Loss: 0.0051, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 94, Loss: 0.0113, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 95, Loss: 0.0054, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 96, Loss: 0.0071, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 97, Loss: 0.0203, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 98, Loss: 0.0143, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 99, Loss: 0.0172, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 100, Loss: 0.0144, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run 05:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 84.75\n",
      "  Final Train: 100.00\n",
      "   Final Test: 70.27\n",
      "Run: 06, Epoch: 01, Loss: 1.6936, Train: 56.32%, Valid: 40.68% Test: 32.43%\n",
      "Run: 06, Epoch: 02, Loss: 0.7345, Train: 71.26%, Valid: 47.46% Test: 37.84%\n",
      "Run: 06, Epoch: 03, Loss: 0.6194, Train: 83.91%, Valid: 57.63% Test: 48.65%\n",
      "Run: 06, Epoch: 04, Loss: 0.5247, Train: 87.36%, Valid: 67.80% Test: 67.57%\n",
      "Run: 06, Epoch: 05, Loss: 0.5188, Train: 88.51%, Valid: 69.49% Test: 72.97%\n",
      "Run: 06, Epoch: 06, Loss: 0.4375, Train: 90.80%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 07, Loss: 0.3714, Train: 93.10%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 08, Loss: 0.3746, Train: 93.10%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 09, Loss: 0.4036, Train: 94.25%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 10, Loss: 0.2833, Train: 94.25%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 11, Loss: 0.2882, Train: 94.25%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 12, Loss: 0.2478, Train: 96.55%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 13, Loss: 0.2529, Train: 96.55%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 14, Loss: 0.1757, Train: 96.55%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 15, Loss: 0.1916, Train: 97.70%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 16, Loss: 0.1630, Train: 98.85%, Valid: 74.58% Test: 81.08%\n",
      "Run: 06, Epoch: 17, Loss: 0.1346, Train: 98.85%, Valid: 74.58% Test: 81.08%\n",
      "Run: 06, Epoch: 18, Loss: 0.1682, Train: 98.85%, Valid: 74.58% Test: 81.08%\n",
      "Run: 06, Epoch: 19, Loss: 0.1477, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 20, Loss: 0.1229, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 21, Loss: 0.1658, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 22, Loss: 0.1282, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 23, Loss: 0.0986, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 24, Loss: 0.1030, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 25, Loss: 0.1263, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 26, Loss: 0.0700, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 27, Loss: 0.0657, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 28, Loss: 0.0568, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 29, Loss: 0.0623, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 30, Loss: 0.0638, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 31, Loss: 0.0550, Train: 100.00%, Valid: 74.58% Test: 81.08%\n",
      "Run: 06, Epoch: 32, Loss: 0.0621, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 33, Loss: 0.0340, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 34, Loss: 0.0465, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 35, Loss: 0.0461, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 36, Loss: 0.0431, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 37, Loss: 0.0411, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 38, Loss: 0.0270, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 39, Loss: 0.0405, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 40, Loss: 0.0467, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 41, Loss: 0.0283, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 42, Loss: 0.0260, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 43, Loss: 0.0409, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 44, Loss: 0.0312, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 45, Loss: 0.0464, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 46, Loss: 0.0504, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 47, Loss: 0.0172, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 48, Loss: 0.0185, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 49, Loss: 0.0291, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 50, Loss: 0.0489, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 51, Loss: 0.0172, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 52, Loss: 0.0197, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 53, Loss: 0.0423, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 54, Loss: 0.0157, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 55, Loss: 0.0128, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 56, Loss: 0.0392, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 57, Loss: 0.0183, Train: 100.00%, Valid: 76.27% Test: 81.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 58, Loss: 0.0230, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 59, Loss: 0.0215, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 60, Loss: 0.0173, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 61, Loss: 0.0217, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 62, Loss: 0.0150, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 63, Loss: 0.0286, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 64, Loss: 0.0178, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 65, Loss: 0.0371, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 66, Loss: 0.0296, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 67, Loss: 0.0600, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 68, Loss: 0.0188, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 69, Loss: 0.0438, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 70, Loss: 0.0423, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 71, Loss: 0.0246, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 72, Loss: 0.0137, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 73, Loss: 0.0085, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 74, Loss: 0.0097, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 75, Loss: 0.0121, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 76, Loss: 0.0156, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 77, Loss: 0.0083, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 78, Loss: 0.0045, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 79, Loss: 0.0077, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 80, Loss: 0.0166, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 81, Loss: 0.0194, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 82, Loss: 0.0199, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 83, Loss: 0.0185, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 84, Loss: 0.0103, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 85, Loss: 0.0176, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 86, Loss: 0.0142, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 87, Loss: 0.0264, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 88, Loss: 0.0156, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 89, Loss: 0.0058, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 90, Loss: 0.0127, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 91, Loss: 0.0153, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 92, Loss: 0.0047, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 93, Loss: 0.0369, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 94, Loss: 0.0116, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 95, Loss: 0.0262, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 96, Loss: 0.0104, Train: 100.00%, Valid: 74.58% Test: 81.08%\n",
      "Run: 06, Epoch: 97, Loss: 0.0142, Train: 100.00%, Valid: 74.58% Test: 81.08%\n",
      "Run: 06, Epoch: 98, Loss: 0.0160, Train: 100.00%, Valid: 74.58% Test: 81.08%\n",
      "Run: 06, Epoch: 99, Loss: 0.0276, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 100, Loss: 0.0475, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run 06:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 76.27\n",
      "  Final Train: 100.00\n",
      "   Final Test: 81.08\n",
      "Run: 07, Epoch: 01, Loss: 1.7019, Train: 80.46%, Valid: 55.93% Test: 51.35%\n",
      "Run: 07, Epoch: 02, Loss: 0.7508, Train: 86.21%, Valid: 64.41% Test: 62.16%\n",
      "Run: 07, Epoch: 03, Loss: 0.5943, Train: 89.66%, Valid: 66.10% Test: 64.86%\n",
      "Run: 07, Epoch: 04, Loss: 0.5022, Train: 87.36%, Valid: 66.10% Test: 64.86%\n",
      "Run: 07, Epoch: 05, Loss: 0.4570, Train: 88.51%, Valid: 69.49% Test: 62.16%\n",
      "Run: 07, Epoch: 06, Loss: 0.4306, Train: 91.95%, Valid: 67.80% Test: 64.86%\n",
      "Run: 07, Epoch: 07, Loss: 0.4964, Train: 91.95%, Valid: 67.80% Test: 64.86%\n",
      "Run: 07, Epoch: 08, Loss: 0.3526, Train: 91.95%, Valid: 69.49% Test: 67.57%\n",
      "Run: 07, Epoch: 09, Loss: 0.2955, Train: 91.95%, Valid: 71.19% Test: 64.86%\n",
      "Run: 07, Epoch: 10, Loss: 0.2837, Train: 91.95%, Valid: 71.19% Test: 64.86%\n",
      "Run: 07, Epoch: 11, Loss: 0.3288, Train: 91.95%, Valid: 71.19% Test: 64.86%\n",
      "Run: 07, Epoch: 12, Loss: 0.2661, Train: 93.10%, Valid: 72.88% Test: 64.86%\n",
      "Run: 07, Epoch: 13, Loss: 0.2563, Train: 94.25%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 14, Loss: 0.2506, Train: 94.25%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 15, Loss: 0.2065, Train: 96.55%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 16, Loss: 0.2408, Train: 97.70%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 17, Loss: 0.2046, Train: 97.70%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 18, Loss: 0.2406, Train: 97.70%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 19, Loss: 0.1191, Train: 97.70%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 20, Loss: 0.1339, Train: 97.70%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 21, Loss: 0.1255, Train: 97.70%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 22, Loss: 0.2132, Train: 97.70%, Valid: 72.88% Test: 70.27%\n",
      "Run: 07, Epoch: 23, Loss: 0.0986, Train: 97.70%, Valid: 72.88% Test: 70.27%\n",
      "Run: 07, Epoch: 24, Loss: 0.1464, Train: 97.70%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 25, Loss: 0.0999, Train: 98.85%, Valid: 71.19% Test: 67.57%\n",
      "Run: 07, Epoch: 26, Loss: 0.1062, Train: 98.85%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 27, Loss: 0.0909, Train: 98.85%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 28, Loss: 0.0904, Train: 98.85%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 29, Loss: 0.1200, Train: 98.85%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 30, Loss: 0.0810, Train: 98.85%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 31, Loss: 0.0744, Train: 98.85%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 32, Loss: 0.1410, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 33, Loss: 0.0641, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 34, Loss: 0.0594, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 35, Loss: 0.0653, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 36, Loss: 0.0550, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 37, Loss: 0.0466, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 07, Epoch: 38, Loss: 0.0605, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 07, Epoch: 39, Loss: 0.0488, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 40, Loss: 0.0718, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 41, Loss: 0.0426, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 42, Loss: 0.0365, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 43, Loss: 0.0444, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 44, Loss: 0.0469, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 45, Loss: 0.0265, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 07, Epoch: 46, Loss: 0.0418, Train: 100.00%, Valid: 72.88% Test: 70.27%\n",
      "Run: 07, Epoch: 47, Loss: 0.0729, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 48, Loss: 0.0316, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 49, Loss: 0.0460, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 50, Loss: 0.0170, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 51, Loss: 0.0615, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 52, Loss: 0.0153, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 53, Loss: 0.0392, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 54, Loss: 0.0414, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 55, Loss: 0.0263, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 56, Loss: 0.0210, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 57, Loss: 0.0261, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 07, Epoch: 58, Loss: 0.0179, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 07, Epoch: 59, Loss: 0.0181, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 07, Epoch: 60, Loss: 0.0166, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 07, Epoch: 61, Loss: 0.0136, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 62, Loss: 0.0646, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 07, Epoch: 63, Loss: 0.0326, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 07, Epoch: 64, Loss: 0.0101, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 07, Epoch: 65, Loss: 0.0136, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 07, Epoch: 66, Loss: 0.0117, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 07, Epoch: 67, Loss: 0.0070, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 07, Epoch: 68, Loss: 0.0325, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 07, Epoch: 69, Loss: 0.0157, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 07, Epoch: 70, Loss: 0.0200, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 07, Epoch: 71, Loss: 0.0172, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 07, Epoch: 72, Loss: 0.0112, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 07, Epoch: 73, Loss: 0.0104, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 07, Epoch: 74, Loss: 0.0403, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 07, Epoch: 75, Loss: 0.0217, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 07, Epoch: 76, Loss: 0.0183, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 07, Epoch: 77, Loss: 0.0205, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 07, Epoch: 78, Loss: 0.0298, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 07, Epoch: 79, Loss: 0.0216, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 07, Epoch: 80, Loss: 0.0117, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 07, Epoch: 81, Loss: 0.0216, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 82, Loss: 0.0099, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 83, Loss: 0.0099, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 84, Loss: 0.0081, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 85, Loss: 0.0175, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 86, Loss: 0.0088, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 87, Loss: 0.0142, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 88, Loss: 0.0430, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 89, Loss: 0.0090, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 90, Loss: 0.0074, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 91, Loss: 0.0444, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 92, Loss: 0.0101, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 93, Loss: 0.0101, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 94, Loss: 0.0157, Train: 100.00%, Valid: 74.58% Test: 75.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 95, Loss: 0.0148, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 96, Loss: 0.0042, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 97, Loss: 0.0144, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 98, Loss: 0.0104, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 99, Loss: 0.0378, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 07, Epoch: 100, Loss: 0.0080, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run 07:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 77.97\n",
      "  Final Train: 97.70\n",
      "   Final Test: 67.57\n",
      "Run: 08, Epoch: 01, Loss: 1.7273, Train: 62.07%, Valid: 42.37% Test: 40.54%\n",
      "Run: 08, Epoch: 02, Loss: 0.8206, Train: 74.71%, Valid: 49.15% Test: 48.65%\n",
      "Run: 08, Epoch: 03, Loss: 0.7147, Train: 83.91%, Valid: 55.93% Test: 48.65%\n",
      "Run: 08, Epoch: 04, Loss: 0.5940, Train: 87.36%, Valid: 61.02% Test: 54.05%\n",
      "Run: 08, Epoch: 05, Loss: 0.4821, Train: 87.36%, Valid: 62.71% Test: 59.46%\n",
      "Run: 08, Epoch: 06, Loss: 0.4101, Train: 89.66%, Valid: 62.71% Test: 59.46%\n",
      "Run: 08, Epoch: 07, Loss: 0.3878, Train: 91.95%, Valid: 62.71% Test: 59.46%\n",
      "Run: 08, Epoch: 08, Loss: 0.3492, Train: 94.25%, Valid: 62.71% Test: 59.46%\n",
      "Run: 08, Epoch: 09, Loss: 0.3138, Train: 96.55%, Valid: 64.41% Test: 56.76%\n",
      "Run: 08, Epoch: 10, Loss: 0.3052, Train: 97.70%, Valid: 64.41% Test: 56.76%\n",
      "Run: 08, Epoch: 11, Loss: 0.2304, Train: 98.85%, Valid: 66.10% Test: 56.76%\n",
      "Run: 08, Epoch: 12, Loss: 0.2220, Train: 100.00%, Valid: 64.41% Test: 54.05%\n",
      "Run: 08, Epoch: 13, Loss: 0.1900, Train: 100.00%, Valid: 64.41% Test: 54.05%\n",
      "Run: 08, Epoch: 14, Loss: 0.1545, Train: 100.00%, Valid: 66.10% Test: 54.05%\n",
      "Run: 08, Epoch: 15, Loss: 0.1477, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 08, Epoch: 16, Loss: 0.1444, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 08, Epoch: 17, Loss: 0.1547, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 08, Epoch: 18, Loss: 0.0987, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 08, Epoch: 19, Loss: 0.1016, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 08, Epoch: 20, Loss: 0.1079, Train: 100.00%, Valid: 64.41% Test: 54.05%\n",
      "Run: 08, Epoch: 21, Loss: 0.1168, Train: 100.00%, Valid: 66.10% Test: 54.05%\n",
      "Run: 08, Epoch: 22, Loss: 0.0881, Train: 100.00%, Valid: 66.10% Test: 54.05%\n",
      "Run: 08, Epoch: 23, Loss: 0.0801, Train: 100.00%, Valid: 66.10% Test: 54.05%\n",
      "Run: 08, Epoch: 24, Loss: 0.0693, Train: 100.00%, Valid: 66.10% Test: 54.05%\n",
      "Run: 08, Epoch: 25, Loss: 0.0576, Train: 100.00%, Valid: 66.10% Test: 54.05%\n",
      "Run: 08, Epoch: 26, Loss: 0.0367, Train: 100.00%, Valid: 66.10% Test: 54.05%\n",
      "Run: 08, Epoch: 27, Loss: 0.0502, Train: 100.00%, Valid: 66.10% Test: 54.05%\n",
      "Run: 08, Epoch: 28, Loss: 0.0584, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 08, Epoch: 29, Loss: 0.0505, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 08, Epoch: 30, Loss: 0.0499, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 08, Epoch: 31, Loss: 0.0334, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 08, Epoch: 32, Loss: 0.0357, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 08, Epoch: 33, Loss: 0.0292, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 08, Epoch: 34, Loss: 0.0234, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 08, Epoch: 35, Loss: 0.0324, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 08, Epoch: 36, Loss: 0.0270, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 08, Epoch: 37, Loss: 0.0270, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 08, Epoch: 38, Loss: 0.0607, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 08, Epoch: 39, Loss: 0.0403, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 08, Epoch: 40, Loss: 0.0296, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 08, Epoch: 41, Loss: 0.0245, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 42, Loss: 0.0292, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 43, Loss: 0.0238, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 44, Loss: 0.0228, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 45, Loss: 0.0178, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 46, Loss: 0.0262, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 47, Loss: 0.0524, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 48, Loss: 0.0168, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 49, Loss: 0.0296, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 50, Loss: 0.0268, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 51, Loss: 0.0277, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 52, Loss: 0.0169, Train: 100.00%, Valid: 71.19% Test: 72.97%\n",
      "Run: 08, Epoch: 53, Loss: 0.0259, Train: 100.00%, Valid: 71.19% Test: 72.97%\n",
      "Run: 08, Epoch: 54, Loss: 0.0084, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 55, Loss: 0.0118, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 56, Loss: 0.0102, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 57, Loss: 0.0106, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 58, Loss: 0.0137, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 08, Epoch: 59, Loss: 0.0057, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 08, Epoch: 60, Loss: 0.0175, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 08, Epoch: 61, Loss: 0.0145, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 08, Epoch: 62, Loss: 0.0103, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 63, Loss: 0.0123, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 64, Loss: 0.0070, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 65, Loss: 0.0114, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 66, Loss: 0.0097, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 67, Loss: 0.0058, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 68, Loss: 0.0122, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 69, Loss: 0.0050, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 70, Loss: 0.0269, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 71, Loss: 0.0161, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 72, Loss: 0.0263, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 73, Loss: 0.0057, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 74, Loss: 0.0066, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 75, Loss: 0.0207, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 76, Loss: 0.0108, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 77, Loss: 0.0065, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 78, Loss: 0.0073, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 79, Loss: 0.0075, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 80, Loss: 0.0065, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 81, Loss: 0.0289, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 82, Loss: 0.0192, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 83, Loss: 0.0125, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 84, Loss: 0.0191, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 08, Epoch: 85, Loss: 0.0150, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 08, Epoch: 86, Loss: 0.0086, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 87, Loss: 0.0146, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 88, Loss: 0.0081, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 89, Loss: 0.0065, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 90, Loss: 0.0111, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 91, Loss: 0.0080, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 92, Loss: 0.0072, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 93, Loss: 0.0083, Train: 100.00%, Valid: 71.19% Test: 72.97%\n",
      "Run: 08, Epoch: 94, Loss: 0.0031, Train: 100.00%, Valid: 71.19% Test: 72.97%\n",
      "Run: 08, Epoch: 95, Loss: 0.0316, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 08, Epoch: 96, Loss: 0.0018, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 08, Epoch: 97, Loss: 0.0093, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 98, Loss: 0.0116, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 99, Loss: 0.0153, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 100, Loss: 0.0080, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 71.19\n",
      "  Final Train: 100.00\n",
      "   Final Test: 70.27\n",
      "Run: 09, Epoch: 01, Loss: 1.4978, Train: 78.16%, Valid: 52.54% Test: 67.57%\n",
      "Run: 09, Epoch: 02, Loss: 0.7393, Train: 86.21%, Valid: 59.32% Test: 75.68%\n",
      "Run: 09, Epoch: 03, Loss: 0.5917, Train: 90.80%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 04, Loss: 0.5529, Train: 94.25%, Valid: 64.41% Test: 75.68%\n",
      "Run: 09, Epoch: 05, Loss: 0.4544, Train: 95.40%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 06, Loss: 0.4578, Train: 94.25%, Valid: 69.49% Test: 72.97%\n",
      "Run: 09, Epoch: 07, Loss: 0.3669, Train: 94.25%, Valid: 74.58% Test: 72.97%\n",
      "Run: 09, Epoch: 08, Loss: 0.4148, Train: 95.40%, Valid: 74.58% Test: 72.97%\n",
      "Run: 09, Epoch: 09, Loss: 0.3783, Train: 95.40%, Valid: 76.27% Test: 75.68%\n",
      "Run: 09, Epoch: 10, Loss: 0.3568, Train: 95.40%, Valid: 72.88% Test: 72.97%\n",
      "Run: 09, Epoch: 11, Loss: 0.2538, Train: 95.40%, Valid: 71.19% Test: 75.68%\n",
      "Run: 09, Epoch: 12, Loss: 0.2454, Train: 96.55%, Valid: 71.19% Test: 75.68%\n",
      "Run: 09, Epoch: 13, Loss: 0.2276, Train: 98.85%, Valid: 74.58% Test: 75.68%\n",
      "Run: 09, Epoch: 14, Loss: 0.2536, Train: 98.85%, Valid: 74.58% Test: 75.68%\n",
      "Run: 09, Epoch: 15, Loss: 0.1767, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 09, Epoch: 16, Loss: 0.1651, Train: 100.00%, Valid: 72.88% Test: 78.38%\n",
      "Run: 09, Epoch: 17, Loss: 0.1733, Train: 100.00%, Valid: 71.19% Test: 78.38%\n",
      "Run: 09, Epoch: 18, Loss: 0.1079, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 09, Epoch: 19, Loss: 0.1053, Train: 100.00%, Valid: 71.19% Test: 78.38%\n",
      "Run: 09, Epoch: 20, Loss: 0.0987, Train: 100.00%, Valid: 71.19% Test: 78.38%\n",
      "Run: 09, Epoch: 21, Loss: 0.1277, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 09, Epoch: 22, Loss: 0.1351, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 09, Epoch: 23, Loss: 0.0665, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 09, Epoch: 24, Loss: 0.1035, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 09, Epoch: 25, Loss: 0.0879, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 09, Epoch: 26, Loss: 0.0905, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 09, Epoch: 27, Loss: 0.0898, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 28, Loss: 0.0486, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 29, Loss: 0.0684, Train: 100.00%, Valid: 67.80% Test: 81.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 30, Loss: 0.0414, Train: 100.00%, Valid: 67.80% Test: 81.08%\n",
      "Run: 09, Epoch: 31, Loss: 0.0496, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 32, Loss: 0.0466, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 33, Loss: 0.0292, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 34, Loss: 0.0768, Train: 100.00%, Valid: 64.41% Test: 81.08%\n",
      "Run: 09, Epoch: 35, Loss: 0.0738, Train: 100.00%, Valid: 64.41% Test: 81.08%\n",
      "Run: 09, Epoch: 36, Loss: 0.0585, Train: 100.00%, Valid: 64.41% Test: 81.08%\n",
      "Run: 09, Epoch: 37, Loss: 0.0287, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 38, Loss: 0.0635, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 39, Loss: 0.0332, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 40, Loss: 0.0283, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 41, Loss: 0.0165, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 42, Loss: 0.0659, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 43, Loss: 0.0404, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 44, Loss: 0.0560, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 45, Loss: 0.0109, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 46, Loss: 0.0287, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 47, Loss: 0.0195, Train: 100.00%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 48, Loss: 0.0145, Train: 100.00%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 49, Loss: 0.0262, Train: 100.00%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 50, Loss: 0.0211, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 51, Loss: 0.0725, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 52, Loss: 0.0195, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 53, Loss: 0.0225, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 54, Loss: 0.0091, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 55, Loss: 0.0290, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 09, Epoch: 56, Loss: 0.0454, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 09, Epoch: 57, Loss: 0.0045, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 58, Loss: 0.0190, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 59, Loss: 0.0172, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 60, Loss: 0.0122, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 61, Loss: 0.0249, Train: 100.00%, Valid: 71.19% Test: 81.08%\n",
      "Run: 09, Epoch: 62, Loss: 0.0172, Train: 100.00%, Valid: 71.19% Test: 81.08%\n",
      "Run: 09, Epoch: 63, Loss: 0.0177, Train: 100.00%, Valid: 71.19% Test: 81.08%\n",
      "Run: 09, Epoch: 64, Loss: 0.0066, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 65, Loss: 0.0325, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 66, Loss: 0.0357, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 67, Loss: 0.0088, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 68, Loss: 0.0214, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 69, Loss: 0.0368, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 70, Loss: 0.0124, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 71, Loss: 0.0221, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 72, Loss: 0.0490, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 73, Loss: 0.0102, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 74, Loss: 0.0204, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 75, Loss: 0.0213, Train: 100.00%, Valid: 69.49% Test: 83.78%\n",
      "Run: 09, Epoch: 76, Loss: 0.0058, Train: 100.00%, Valid: 67.80% Test: 83.78%\n",
      "Run: 09, Epoch: 77, Loss: 0.0401, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 78, Loss: 0.0062, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 79, Loss: 0.0158, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 80, Loss: 0.0100, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 81, Loss: 0.0118, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 82, Loss: 0.0100, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 83, Loss: 0.0034, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 84, Loss: 0.0063, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 85, Loss: 0.0302, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 86, Loss: 0.0222, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 87, Loss: 0.0115, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 88, Loss: 0.0177, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 89, Loss: 0.0042, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 90, Loss: 0.0128, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 91, Loss: 0.0053, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 92, Loss: 0.0365, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 93, Loss: 0.0186, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 94, Loss: 0.0052, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 95, Loss: 0.0286, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 96, Loss: 0.0180, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 97, Loss: 0.0232, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 98, Loss: 0.0100, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 99, Loss: 0.0165, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 100, Loss: 0.0071, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run 09:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 76.27\n",
      "  Final Train: 95.40\n",
      "   Final Test: 75.68\n",
      "Run: 10, Epoch: 01, Loss: 1.5853, Train: 89.66%, Valid: 59.32% Test: 70.27%\n",
      "Run: 10, Epoch: 02, Loss: 0.7868, Train: 93.10%, Valid: 62.71% Test: 83.78%\n",
      "Run: 10, Epoch: 03, Loss: 0.5127, Train: 89.66%, Valid: 61.02% Test: 81.08%\n",
      "Run: 10, Epoch: 04, Loss: 0.4494, Train: 90.80%, Valid: 57.63% Test: 81.08%\n",
      "Run: 10, Epoch: 05, Loss: 0.4273, Train: 93.10%, Valid: 61.02% Test: 81.08%\n",
      "Run: 10, Epoch: 06, Loss: 0.3639, Train: 94.25%, Valid: 64.41% Test: 81.08%\n",
      "Run: 10, Epoch: 07, Loss: 0.3592, Train: 93.10%, Valid: 66.10% Test: 81.08%\n",
      "Run: 10, Epoch: 08, Loss: 0.3079, Train: 94.25%, Valid: 66.10% Test: 81.08%\n",
      "Run: 10, Epoch: 09, Loss: 0.2889, Train: 95.40%, Valid: 66.10% Test: 83.78%\n",
      "Run: 10, Epoch: 10, Loss: 0.2826, Train: 95.40%, Valid: 69.49% Test: 83.78%\n",
      "Run: 10, Epoch: 11, Loss: 0.2155, Train: 95.40%, Valid: 69.49% Test: 83.78%\n",
      "Run: 10, Epoch: 12, Loss: 0.2277, Train: 95.40%, Valid: 69.49% Test: 83.78%\n",
      "Run: 10, Epoch: 13, Loss: 0.1724, Train: 95.40%, Valid: 71.19% Test: 83.78%\n",
      "Run: 10, Epoch: 14, Loss: 0.1415, Train: 97.70%, Valid: 69.49% Test: 83.78%\n",
      "Run: 10, Epoch: 15, Loss: 0.1597, Train: 97.70%, Valid: 69.49% Test: 81.08%\n",
      "Run: 10, Epoch: 16, Loss: 0.1331, Train: 97.70%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 17, Loss: 0.1200, Train: 98.85%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 18, Loss: 0.1201, Train: 98.85%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 19, Loss: 0.1086, Train: 98.85%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 20, Loss: 0.0992, Train: 98.85%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 21, Loss: 0.1036, Train: 98.85%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 22, Loss: 0.0963, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 23, Loss: 0.0721, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 24, Loss: 0.0688, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 25, Loss: 0.0583, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 26, Loss: 0.0576, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 27, Loss: 0.0895, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 28, Loss: 0.0649, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 29, Loss: 0.0803, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 30, Loss: 0.0898, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 31, Loss: 0.0409, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 32, Loss: 0.0878, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 10, Epoch: 33, Loss: 0.0269, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 10, Epoch: 34, Loss: 0.0479, Train: 100.00%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 35, Loss: 0.0648, Train: 100.00%, Valid: 72.88% Test: 78.38%\n",
      "Run: 10, Epoch: 36, Loss: 0.0222, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 37, Loss: 0.0320, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 38, Loss: 0.0614, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 39, Loss: 0.0340, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 40, Loss: 0.0263, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 41, Loss: 0.0283, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 42, Loss: 0.0391, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 43, Loss: 0.0294, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 44, Loss: 0.0163, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 45, Loss: 0.0265, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 46, Loss: 0.0138, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 47, Loss: 0.0494, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 48, Loss: 0.0318, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 49, Loss: 0.0484, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 50, Loss: 0.0232, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 51, Loss: 0.0295, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 52, Loss: 0.0077, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 53, Loss: 0.0205, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 54, Loss: 0.0374, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 55, Loss: 0.0090, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 10, Epoch: 56, Loss: 0.0310, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 57, Loss: 0.0262, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 58, Loss: 0.0112, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 59, Loss: 0.0159, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 60, Loss: 0.0128, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 10, Epoch: 61, Loss: 0.0155, Train: 100.00%, Valid: 72.88% Test: 75.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 62, Loss: 0.0210, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 63, Loss: 0.0218, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 64, Loss: 0.0441, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 65, Loss: 0.0219, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 66, Loss: 0.0097, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 67, Loss: 0.0143, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 68, Loss: 0.0269, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 69, Loss: 0.0192, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 70, Loss: 0.0067, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 71, Loss: 0.0589, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 72, Loss: 0.0072, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 73, Loss: 0.0065, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 74, Loss: 0.0204, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 75, Loss: 0.0207, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 76, Loss: 0.0172, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 77, Loss: 0.0037, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 78, Loss: 0.0059, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 79, Loss: 0.0225, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 80, Loss: 0.0183, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 81, Loss: 0.0044, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 82, Loss: 0.0115, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 83, Loss: 0.0178, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 84, Loss: 0.0126, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 85, Loss: 0.0285, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 86, Loss: 0.0305, Train: 100.00%, Valid: 71.19% Test: 72.97%\n",
      "Run: 10, Epoch: 87, Loss: 0.0261, Train: 100.00%, Valid: 71.19% Test: 72.97%\n",
      "Run: 10, Epoch: 88, Loss: 0.0239, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 89, Loss: 0.0116, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 90, Loss: 0.0266, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 10, Epoch: 91, Loss: 0.0085, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 10, Epoch: 92, Loss: 0.0140, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 10, Epoch: 93, Loss: 0.0036, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 94, Loss: 0.0094, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 95, Loss: 0.0276, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 96, Loss: 0.0111, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 97, Loss: 0.0118, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 98, Loss: 0.0111, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 99, Loss: 0.0167, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 100, Loss: 0.0043, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 72.88\n",
      "  Final Train: 100.00\n",
      "   Final Test: 78.38\n",
      "All runs:\n",
      "Highest Train: 100.00 ± 0.00\n",
      "Highest Valid: 78.31 ± 4.98\n",
      "  Final Train: 98.85 ± 1.71\n",
      "   Final Test: 75.41 ± 7.26\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 32, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-6, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    dataset = WebKB(root='/tmp/Texas', name='Texas',transform=T.ToSparseTensor())\n",
    "    data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    #idx_train=[data.train_mask[i][0] for i in range(len(data.y))]\n",
    "    #train_idx = np.where(idx_train)[0]\n",
    "    #idx_val=[data.val_mask[i][0] for i in range(len(data.y))]\n",
    "    #valid_idx = np.where(idx_val)[0]\n",
    "    #idx_test=[data.test_mask[i][0] for i in range(len(data.y))]\n",
    "    #test_idx = np.where(idx_test)[0]\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52f151",
   "metadata": {},
   "source": [
    "# WISE EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a09514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=325])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Texas', name='Texas',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f82a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "      <th>1701</th>\n",
       "      <th>1702</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1704 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  1694  1695  1696  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "   1697  1698  1699  1700  1701  1702  class  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0      0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0      2  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "\n",
       "[5 rows x 1704 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Domain_Fec=pd.DataFrame(data.x.numpy())\n",
    "label=pd.DataFrame(data.y.numpy(),columns =['class'])\n",
    "Data=pd.concat([Domain_Fec,label], axis=1)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2642b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_nodes=len(data.y)\n",
    "fe_len=len(data.x[0])\n",
    "catagories=Data['class'].to_numpy()\n",
    "data_by_class = {cls: Data.loc[Data['class'] == cls].drop(['class'], axis=1) for cls in range(max(catagories) + 1)}\n",
    "basis = [[max(df[i]) for i in range(len(df.columns))] for df in data_by_class.values()]\n",
    "sel_basis = [[int(list(df[i].to_numpy()).count(1) >= int(len(df[i].index)*0.1)) \n",
    "              for i in range(len(df.columns))]\n",
    "             for df in data_by_class.values()]\n",
    "feature_names = [ii for ii in range(fe_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12133154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It takes long time\n",
    "Fec=[]\n",
    "for i in range(23):\n",
    "    vec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=np.zeros(7)\n",
    "    for j in range(1433):\n",
    "        for i in range(max(catagories)+1):\n",
    "            if f[j]==1 and basis[i][j]==1:\n",
    "                count[i]=count[i]+1;\n",
    "\n",
    "    for i in range(max(catagories)+1):\n",
    "        vec.append(count[i])\n",
    "    f.clear()\n",
    "    Fec.append(vec)\n",
    "print(Fec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4db5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fec=[]\n",
    "for i in range(Number_nodes):\n",
    "    vec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=0\n",
    "    count1=0\n",
    "    count2=0\n",
    "    count3=0\n",
    "    count4=0\n",
    "    for j in range(fe_len):\n",
    "        if f[j]==1 and basis[0][j]==1:\n",
    "            count=count+1;\n",
    "        if f[j]==1 and basis[1][j]==1:\n",
    "            count1=count1+1;\n",
    "        if f[j]==1 and basis[2][j]==1:\n",
    "            count2=count2+1;\n",
    "        if f[j]==1 and basis[3][j]==1:\n",
    "            count3=count3+1;\n",
    "        if f[j]==1 and basis[4][j]==1:\n",
    "            count4=count4+1;\n",
    "    vec.append(count)\n",
    "    vec.append(count1)\n",
    "    vec.append(count2)\n",
    "    vec.append(count3)\n",
    "    vec.append(count4)\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    Fec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a920e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFec=[]\n",
    "for i in range(Number_nodes):\n",
    "    Svec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=0\n",
    "    count1=0\n",
    "    count2=0\n",
    "    count3=0\n",
    "    count4=0\n",
    "    for j in range(fe_len):\n",
    "        if f[j]==1 and sel_basis[0][j]==1:\n",
    "            count=count+1;\n",
    "        if f[j]==1 and sel_basis[1][j]==1:\n",
    "            count1=count1+1;\n",
    "        if f[j]==1 and sel_basis[2][j]==1:\n",
    "            count2=count2+1;\n",
    "        if f[j]==1 and sel_basis[3][j]==1:\n",
    "            count3=count3+1;\n",
    "        if f[j]==1 and sel_basis[4][j]==1:\n",
    "            count4=count4+1;\n",
    "    Svec.append(count)\n",
    "    Svec.append(count1)\n",
    "    Svec.append(count2)\n",
    "    Svec.append(count3)\n",
    "    Svec.append(count4)\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    SFec.append(Svec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "054ee569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 39.,  20.,  40.,  ...,  40.,  30.,  32.],\n",
      "        [231.,  25., 155.,  ..., 155.,  64.,  92.],\n",
      "        [ 25.,  20.,  26.,  ...,  26.,  23.,  23.],\n",
      "        ...,\n",
      "        [ 77.,  32.,  73.,  ...,  73.,  49.,  67.],\n",
      "        [ 61.,  28.,  56.,  ...,  56.,  54.,  51.],\n",
      "        [ 41.,  23.,  37.,  ...,  37.,  36.,  32.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inc_fe=torch.tensor(Fec)\n",
    "sel_fe=torch.tensor(SFec)\n",
    "CC_domain=torch.cat((Inc_fe, sel_fe), 1).float()\n",
    "print(CC_domain)\n",
    "CC_domain.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f7d51",
   "metadata": {},
   "source": [
    "# WISE EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c6fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 10], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=325])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4763ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x166bbb040>\n",
      "Run: 01, Epoch: 01, Loss: 1.8323, Train: 50.57%, Valid: 55.93% Test: 62.16%\n",
      "Run: 01, Epoch: 02, Loss: 1.5578, Train: 32.18%, Valid: 28.81% Test: 45.95%\n",
      "Run: 01, Epoch: 03, Loss: 1.3837, Train: 25.29%, Valid: 28.81% Test: 13.51%\n",
      "Run: 01, Epoch: 04, Loss: 1.1562, Train: 35.63%, Valid: 30.51% Test: 18.92%\n",
      "Run: 01, Epoch: 05, Loss: 1.1102, Train: 36.78%, Valid: 32.20% Test: 21.62%\n",
      "Run: 01, Epoch: 06, Loss: 1.0226, Train: 35.63%, Valid: 28.81% Test: 27.03%\n",
      "Run: 01, Epoch: 07, Loss: 0.9775, Train: 35.63%, Valid: 22.03% Test: 29.73%\n",
      "Run: 01, Epoch: 08, Loss: 0.9065, Train: 37.93%, Valid: 27.12% Test: 29.73%\n",
      "Run: 01, Epoch: 09, Loss: 0.8176, Train: 43.68%, Valid: 38.98% Test: 37.84%\n",
      "Run: 01, Epoch: 10, Loss: 0.8674, Train: 54.02%, Valid: 42.37% Test: 40.54%\n",
      "Run: 01, Epoch: 11, Loss: 0.7775, Train: 57.47%, Valid: 55.93% Test: 43.24%\n",
      "Run: 01, Epoch: 12, Loss: 0.8891, Train: 64.37%, Valid: 61.02% Test: 51.35%\n",
      "Run: 01, Epoch: 13, Loss: 0.7206, Train: 73.56%, Valid: 67.80% Test: 64.86%\n",
      "Run: 01, Epoch: 14, Loss: 0.6809, Train: 75.86%, Valid: 71.19% Test: 70.27%\n",
      "Run: 01, Epoch: 15, Loss: 0.7289, Train: 71.26%, Valid: 72.88% Test: 75.68%\n",
      "Run: 01, Epoch: 16, Loss: 0.6293, Train: 71.26%, Valid: 71.19% Test: 75.68%\n",
      "Run: 01, Epoch: 17, Loss: 0.5829, Train: 68.97%, Valid: 72.88% Test: 72.97%\n",
      "Run: 01, Epoch: 18, Loss: 0.5529, Train: 66.67%, Valid: 69.49% Test: 70.27%\n",
      "Run: 01, Epoch: 19, Loss: 0.5781, Train: 64.37%, Valid: 66.10% Test: 70.27%\n",
      "Run: 01, Epoch: 20, Loss: 0.5104, Train: 64.37%, Valid: 66.10% Test: 70.27%\n",
      "Run: 01, Epoch: 21, Loss: 0.4269, Train: 64.37%, Valid: 64.41% Test: 72.97%\n",
      "Run: 01, Epoch: 22, Loss: 0.5206, Train: 68.97%, Valid: 69.49% Test: 75.68%\n",
      "Run: 01, Epoch: 23, Loss: 0.4810, Train: 68.97%, Valid: 69.49% Test: 75.68%\n",
      "Run: 01, Epoch: 24, Loss: 0.4935, Train: 73.56%, Valid: 71.19% Test: 78.38%\n",
      "Run: 01, Epoch: 25, Loss: 0.4400, Train: 78.16%, Valid: 74.58% Test: 83.78%\n",
      "Run: 01, Epoch: 26, Loss: 0.4183, Train: 83.91%, Valid: 76.27% Test: 89.19%\n",
      "Run: 01, Epoch: 27, Loss: 0.4520, Train: 90.80%, Valid: 77.97% Test: 94.59%\n",
      "Run: 01, Epoch: 28, Loss: 0.3823, Train: 90.80%, Valid: 77.97% Test: 94.59%\n",
      "Run: 01, Epoch: 29, Loss: 0.3764, Train: 91.95%, Valid: 74.58% Test: 94.59%\n",
      "Run: 01, Epoch: 30, Loss: 0.4274, Train: 90.80%, Valid: 77.97% Test: 91.89%\n",
      "Run: 01, Epoch: 31, Loss: 0.2802, Train: 89.66%, Valid: 79.66% Test: 89.19%\n",
      "Run: 01, Epoch: 32, Loss: 0.2789, Train: 86.21%, Valid: 72.88% Test: 86.49%\n",
      "Run: 01, Epoch: 33, Loss: 0.3516, Train: 85.06%, Valid: 72.88% Test: 81.08%\n",
      "Run: 01, Epoch: 34, Loss: 0.2835, Train: 78.16%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 35, Loss: 0.2777, Train: 78.16%, Valid: 74.58% Test: 81.08%\n",
      "Run: 01, Epoch: 36, Loss: 0.2978, Train: 79.31%, Valid: 71.19% Test: 81.08%\n",
      "Run: 01, Epoch: 37, Loss: 0.2803, Train: 79.31%, Valid: 71.19% Test: 81.08%\n",
      "Run: 01, Epoch: 38, Loss: 0.2665, Train: 80.46%, Valid: 71.19% Test: 89.19%\n",
      "Run: 01, Epoch: 39, Loss: 0.2683, Train: 81.61%, Valid: 71.19% Test: 89.19%\n",
      "Run: 01, Epoch: 40, Loss: 0.2428, Train: 80.46%, Valid: 69.49% Test: 89.19%\n",
      "Run: 01, Epoch: 41, Loss: 0.2335, Train: 80.46%, Valid: 69.49% Test: 89.19%\n",
      "Run: 01, Epoch: 42, Loss: 0.2127, Train: 78.16%, Valid: 71.19% Test: 86.49%\n",
      "Run: 01, Epoch: 43, Loss: 0.1910, Train: 80.46%, Valid: 71.19% Test: 86.49%\n",
      "Run: 01, Epoch: 44, Loss: 0.2006, Train: 86.21%, Valid: 72.88% Test: 86.49%\n",
      "Run: 01, Epoch: 45, Loss: 0.1759, Train: 86.21%, Valid: 72.88% Test: 89.19%\n",
      "Run: 01, Epoch: 46, Loss: 0.1826, Train: 87.36%, Valid: 72.88% Test: 89.19%\n",
      "Run: 01, Epoch: 47, Loss: 0.1468, Train: 83.91%, Valid: 72.88% Test: 86.49%\n",
      "Run: 01, Epoch: 48, Loss: 0.2611, Train: 83.91%, Valid: 72.88% Test: 91.89%\n",
      "Run: 01, Epoch: 49, Loss: 0.1766, Train: 85.06%, Valid: 69.49% Test: 89.19%\n",
      "Run: 01, Epoch: 50, Loss: 0.2248, Train: 88.51%, Valid: 72.88% Test: 89.19%\n",
      "Run: 01, Epoch: 51, Loss: 0.1574, Train: 89.66%, Valid: 72.88% Test: 89.19%\n",
      "Run: 01, Epoch: 52, Loss: 0.1876, Train: 89.66%, Valid: 74.58% Test: 89.19%\n",
      "Run: 01, Epoch: 53, Loss: 0.1237, Train: 89.66%, Valid: 76.27% Test: 89.19%\n",
      "Run: 01, Epoch: 54, Loss: 0.1529, Train: 91.95%, Valid: 74.58% Test: 89.19%\n",
      "Run: 01, Epoch: 55, Loss: 0.1683, Train: 91.95%, Valid: 83.05% Test: 89.19%\n",
      "Run: 01, Epoch: 56, Loss: 0.1289, Train: 94.25%, Valid: 86.44% Test: 89.19%\n",
      "Run: 01, Epoch: 57, Loss: 0.1702, Train: 97.70%, Valid: 89.83% Test: 89.19%\n",
      "Run: 01, Epoch: 58, Loss: 0.1299, Train: 100.00%, Valid: 88.14% Test: 91.89%\n",
      "Run: 01, Epoch: 59, Loss: 0.1443, Train: 100.00%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 60, Loss: 0.1689, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 61, Loss: 0.1479, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 62, Loss: 0.1159, Train: 94.25%, Valid: 88.14% Test: 89.19%\n",
      "Run: 01, Epoch: 63, Loss: 0.1408, Train: 93.10%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 64, Loss: 0.1109, Train: 94.25%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 65, Loss: 0.1137, Train: 96.55%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 66, Loss: 0.0949, Train: 96.55%, Valid: 93.22% Test: 94.59%\n",
      "Run: 01, Epoch: 67, Loss: 0.1813, Train: 96.55%, Valid: 94.92% Test: 91.89%\n",
      "Run: 01, Epoch: 68, Loss: 0.1672, Train: 94.25%, Valid: 93.22% Test: 89.19%\n",
      "Run: 01, Epoch: 69, Loss: 0.1419, Train: 95.40%, Valid: 93.22% Test: 91.89%\n",
      "Run: 01, Epoch: 70, Loss: 0.1089, Train: 95.40%, Valid: 91.53% Test: 89.19%\n",
      "Run: 01, Epoch: 71, Loss: 0.1658, Train: 95.40%, Valid: 93.22% Test: 89.19%\n",
      "Run: 01, Epoch: 72, Loss: 0.1071, Train: 95.40%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 73, Loss: 0.1741, Train: 95.40%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 74, Loss: 0.1454, Train: 95.40%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 75, Loss: 0.1361, Train: 95.40%, Valid: 89.83% Test: 89.19%\n",
      "Run: 01, Epoch: 76, Loss: 0.1188, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 77, Loss: 0.0734, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 78, Loss: 0.1145, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 79, Loss: 0.1456, Train: 94.25%, Valid: 88.14% Test: 89.19%\n",
      "Run: 01, Epoch: 80, Loss: 0.1810, Train: 94.25%, Valid: 84.75% Test: 89.19%\n",
      "Run: 01, Epoch: 81, Loss: 0.1120, Train: 93.10%, Valid: 81.36% Test: 86.49%\n",
      "Run: 01, Epoch: 82, Loss: 0.0868, Train: 94.25%, Valid: 84.75% Test: 89.19%\n",
      "Run: 01, Epoch: 83, Loss: 0.0804, Train: 94.25%, Valid: 86.44% Test: 89.19%\n",
      "Run: 01, Epoch: 84, Loss: 0.0801, Train: 94.25%, Valid: 89.83% Test: 89.19%\n",
      "Run: 01, Epoch: 85, Loss: 0.0896, Train: 98.85%, Valid: 89.83% Test: 89.19%\n",
      "Run: 01, Epoch: 86, Loss: 0.1203, Train: 98.85%, Valid: 88.14% Test: 94.59%\n",
      "Run: 01, Epoch: 87, Loss: 0.0663, Train: 100.00%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 88, Loss: 0.0892, Train: 100.00%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 89, Loss: 0.0931, Train: 100.00%, Valid: 91.53% Test: 94.59%\n",
      "Run: 01, Epoch: 90, Loss: 0.0975, Train: 100.00%, Valid: 93.22% Test: 94.59%\n",
      "Run: 01, Epoch: 91, Loss: 0.0673, Train: 96.55%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 92, Loss: 0.0816, Train: 93.10%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 93, Loss: 0.1141, Train: 93.10%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 94, Loss: 0.1128, Train: 93.10%, Valid: 91.53% Test: 89.19%\n",
      "Run: 01, Epoch: 95, Loss: 0.1263, Train: 94.25%, Valid: 91.53% Test: 89.19%\n",
      "Run: 01, Epoch: 96, Loss: 0.0732, Train: 94.25%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 97, Loss: 0.0700, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 01, Epoch: 98, Loss: 0.0855, Train: 100.00%, Valid: 91.53% Test: 86.49%\n",
      "Run: 01, Epoch: 99, Loss: 0.0842, Train: 100.00%, Valid: 91.53% Test: 89.19%\n",
      "Run: 01, Epoch: 100, Loss: 0.0906, Train: 100.00%, Valid: 94.92% Test: 91.89%\n",
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 94.92\n",
      "  Final Train: 96.55\n",
      "   Final Test: 91.89\n",
      "Run: 02, Epoch: 01, Loss: 1.5396, Train: 21.84%, Valid: 15.25% Test: 18.92%\n",
      "Run: 02, Epoch: 02, Loss: 1.3083, Train: 19.54%, Valid: 15.25% Test: 16.22%\n",
      "Run: 02, Epoch: 03, Loss: 1.1734, Train: 18.39%, Valid: 15.25% Test: 16.22%\n",
      "Run: 02, Epoch: 04, Loss: 1.2330, Train: 19.54%, Valid: 15.25% Test: 16.22%\n",
      "Run: 02, Epoch: 05, Loss: 1.0175, Train: 20.69%, Valid: 15.25% Test: 16.22%\n",
      "Run: 02, Epoch: 06, Loss: 1.0668, Train: 22.99%, Valid: 16.95% Test: 21.62%\n",
      "Run: 02, Epoch: 07, Loss: 1.0167, Train: 26.44%, Valid: 18.64% Test: 21.62%\n",
      "Run: 02, Epoch: 08, Loss: 0.9098, Train: 29.89%, Valid: 28.81% Test: 18.92%\n",
      "Run: 02, Epoch: 09, Loss: 0.8400, Train: 36.78%, Valid: 32.20% Test: 37.84%\n",
      "Run: 02, Epoch: 10, Loss: 0.7985, Train: 50.57%, Valid: 47.46% Test: 54.05%\n",
      "Run: 02, Epoch: 11, Loss: 0.8151, Train: 70.11%, Valid: 57.63% Test: 67.57%\n",
      "Run: 02, Epoch: 12, Loss: 0.7248, Train: 78.16%, Valid: 64.41% Test: 81.08%\n",
      "Run: 02, Epoch: 13, Loss: 0.7195, Train: 81.61%, Valid: 69.49% Test: 81.08%\n",
      "Run: 02, Epoch: 14, Loss: 0.7086, Train: 81.61%, Valid: 71.19% Test: 75.68%\n",
      "Run: 02, Epoch: 15, Loss: 0.6516, Train: 78.16%, Valid: 69.49% Test: 72.97%\n",
      "Run: 02, Epoch: 16, Loss: 0.6017, Train: 79.31%, Valid: 64.41% Test: 72.97%\n",
      "Run: 02, Epoch: 17, Loss: 0.7169, Train: 74.71%, Valid: 64.41% Test: 72.97%\n",
      "Run: 02, Epoch: 18, Loss: 0.5541, Train: 71.26%, Valid: 67.80% Test: 70.27%\n",
      "Run: 02, Epoch: 19, Loss: 0.5500, Train: 68.97%, Valid: 67.80% Test: 70.27%\n",
      "Run: 02, Epoch: 20, Loss: 0.5225, Train: 68.97%, Valid: 69.49% Test: 72.97%\n",
      "Run: 02, Epoch: 21, Loss: 0.4572, Train: 70.11%, Valid: 67.80% Test: 72.97%\n",
      "Run: 02, Epoch: 22, Loss: 0.6492, Train: 73.56%, Valid: 67.80% Test: 75.68%\n",
      "Run: 02, Epoch: 23, Loss: 0.5091, Train: 74.71%, Valid: 67.80% Test: 75.68%\n",
      "Run: 02, Epoch: 24, Loss: 0.5788, Train: 78.16%, Valid: 69.49% Test: 75.68%\n",
      "Run: 02, Epoch: 25, Loss: 0.4760, Train: 80.46%, Valid: 69.49% Test: 75.68%\n",
      "Run: 02, Epoch: 26, Loss: 0.4216, Train: 81.61%, Valid: 69.49% Test: 75.68%\n",
      "Run: 02, Epoch: 27, Loss: 0.4556, Train: 81.61%, Valid: 71.19% Test: 81.08%\n",
      "Run: 02, Epoch: 28, Loss: 0.4232, Train: 78.16%, Valid: 69.49% Test: 81.08%\n",
      "Run: 02, Epoch: 29, Loss: 0.4710, Train: 80.46%, Valid: 71.19% Test: 81.08%\n",
      "Run: 02, Epoch: 30, Loss: 0.4812, Train: 79.31%, Valid: 72.88% Test: 81.08%\n",
      "Run: 02, Epoch: 31, Loss: 0.3983, Train: 79.31%, Valid: 76.27% Test: 81.08%\n",
      "Run: 02, Epoch: 32, Loss: 0.4017, Train: 79.31%, Valid: 76.27% Test: 81.08%\n",
      "Run: 02, Epoch: 33, Loss: 0.3320, Train: 80.46%, Valid: 72.88% Test: 83.78%\n",
      "Run: 02, Epoch: 34, Loss: 0.4172, Train: 82.76%, Valid: 74.58% Test: 83.78%\n",
      "Run: 02, Epoch: 35, Loss: 0.3502, Train: 83.91%, Valid: 77.97% Test: 81.08%\n",
      "Run: 02, Epoch: 36, Loss: 0.3664, Train: 82.76%, Valid: 76.27% Test: 81.08%\n",
      "Run: 02, Epoch: 37, Loss: 0.4175, Train: 85.06%, Valid: 76.27% Test: 81.08%\n",
      "Run: 02, Epoch: 38, Loss: 0.3423, Train: 85.06%, Valid: 76.27% Test: 81.08%\n",
      "Run: 02, Epoch: 39, Loss: 0.3703, Train: 83.91%, Valid: 79.66% Test: 81.08%\n",
      "Run: 02, Epoch: 40, Loss: 0.3059, Train: 79.31%, Valid: 77.97% Test: 81.08%\n",
      "Run: 02, Epoch: 41, Loss: 0.3004, Train: 78.16%, Valid: 76.27% Test: 81.08%\n",
      "Run: 02, Epoch: 42, Loss: 0.3574, Train: 78.16%, Valid: 77.97% Test: 81.08%\n",
      "Run: 02, Epoch: 43, Loss: 0.2528, Train: 79.31%, Valid: 79.66% Test: 81.08%\n",
      "Run: 02, Epoch: 44, Loss: 0.2839, Train: 78.16%, Valid: 79.66% Test: 81.08%\n",
      "Run: 02, Epoch: 45, Loss: 0.3431, Train: 79.31%, Valid: 76.27% Test: 81.08%\n",
      "Run: 02, Epoch: 46, Loss: 0.2791, Train: 78.16%, Valid: 79.66% Test: 81.08%\n",
      "Run: 02, Epoch: 47, Loss: 0.2815, Train: 75.86%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 48, Loss: 0.2575, Train: 73.56%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 49, Loss: 0.2553, Train: 68.97%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 50, Loss: 0.2104, Train: 67.82%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 51, Loss: 0.2688, Train: 71.26%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 52, Loss: 0.2346, Train: 75.86%, Valid: 77.97% Test: 81.08%\n",
      "Run: 02, Epoch: 53, Loss: 0.2868, Train: 78.16%, Valid: 81.36% Test: 83.78%\n",
      "Run: 02, Epoch: 54, Loss: 0.2478, Train: 83.91%, Valid: 83.05% Test: 83.78%\n",
      "Run: 02, Epoch: 55, Loss: 0.2588, Train: 91.95%, Valid: 88.14% Test: 86.49%\n",
      "Run: 02, Epoch: 56, Loss: 0.2325, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 02, Epoch: 57, Loss: 0.2839, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 02, Epoch: 58, Loss: 0.2071, Train: 96.55%, Valid: 89.83% Test: 86.49%\n",
      "Run: 02, Epoch: 59, Loss: 0.2313, Train: 95.40%, Valid: 86.44% Test: 86.49%\n",
      "Run: 02, Epoch: 60, Loss: 0.2749, Train: 95.40%, Valid: 84.75% Test: 86.49%\n",
      "Run: 02, Epoch: 61, Loss: 0.2744, Train: 94.25%, Valid: 84.75% Test: 83.78%\n",
      "Run: 02, Epoch: 62, Loss: 0.1851, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 63, Loss: 0.1894, Train: 85.06%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 64, Loss: 0.2493, Train: 82.76%, Valid: 84.75% Test: 83.78%\n",
      "Run: 02, Epoch: 65, Loss: 0.2127, Train: 82.76%, Valid: 84.75% Test: 81.08%\n",
      "Run: 02, Epoch: 66, Loss: 0.2180, Train: 88.51%, Valid: 84.75% Test: 83.78%\n",
      "Run: 02, Epoch: 67, Loss: 0.1688, Train: 89.66%, Valid: 84.75% Test: 83.78%\n",
      "Run: 02, Epoch: 68, Loss: 0.2089, Train: 89.66%, Valid: 84.75% Test: 83.78%\n",
      "Run: 02, Epoch: 69, Loss: 0.1711, Train: 90.80%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 70, Loss: 0.1980, Train: 93.10%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 71, Loss: 0.2389, Train: 93.10%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 72, Loss: 0.1720, Train: 93.10%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 73, Loss: 0.1426, Train: 94.25%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 74, Loss: 0.2206, Train: 95.40%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 75, Loss: 0.1818, Train: 95.40%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 76, Loss: 0.1784, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 02, Epoch: 77, Loss: 0.2333, Train: 94.25%, Valid: 89.83% Test: 86.49%\n",
      "Run: 02, Epoch: 78, Loss: 0.2084, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 02, Epoch: 79, Loss: 0.2035, Train: 95.40%, Valid: 88.14% Test: 86.49%\n",
      "Run: 02, Epoch: 80, Loss: 0.1048, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 02, Epoch: 81, Loss: 0.1409, Train: 94.25%, Valid: 88.14% Test: 86.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 82, Loss: 0.1493, Train: 94.25%, Valid: 91.53% Test: 86.49%\n",
      "Run: 02, Epoch: 83, Loss: 0.2097, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 02, Epoch: 84, Loss: 0.2039, Train: 97.70%, Valid: 96.61% Test: 89.19%\n",
      "Run: 02, Epoch: 85, Loss: 0.1672, Train: 98.85%, Valid: 96.61% Test: 94.59%\n",
      "Run: 02, Epoch: 86, Loss: 0.1789, Train: 97.70%, Valid: 96.61% Test: 94.59%\n",
      "Run: 02, Epoch: 87, Loss: 0.1417, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 02, Epoch: 88, Loss: 0.2361, Train: 96.55%, Valid: 94.92% Test: 89.19%\n",
      "Run: 02, Epoch: 89, Loss: 0.1597, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 02, Epoch: 90, Loss: 0.1618, Train: 95.40%, Valid: 86.44% Test: 86.49%\n",
      "Run: 02, Epoch: 91, Loss: 0.1594, Train: 90.80%, Valid: 88.14% Test: 81.08%\n",
      "Run: 02, Epoch: 92, Loss: 0.1236, Train: 88.51%, Valid: 86.44% Test: 81.08%\n",
      "Run: 02, Epoch: 93, Loss: 0.1469, Train: 85.06%, Valid: 88.14% Test: 81.08%\n",
      "Run: 02, Epoch: 94, Loss: 0.1897, Train: 87.36%, Valid: 86.44% Test: 81.08%\n",
      "Run: 02, Epoch: 95, Loss: 0.1662, Train: 94.25%, Valid: 89.83% Test: 83.78%\n",
      "Run: 02, Epoch: 96, Loss: 0.1314, Train: 97.70%, Valid: 93.22% Test: 83.78%\n",
      "Run: 02, Epoch: 97, Loss: 0.1535, Train: 97.70%, Valid: 94.92% Test: 83.78%\n",
      "Run: 02, Epoch: 98, Loss: 0.1583, Train: 97.70%, Valid: 96.61% Test: 86.49%\n",
      "Run: 02, Epoch: 99, Loss: 0.1619, Train: 96.55%, Valid: 96.61% Test: 86.49%\n",
      "Run: 02, Epoch: 100, Loss: 0.1217, Train: 96.55%, Valid: 96.61% Test: 86.49%\n",
      "Run 02:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 96.61\n",
      "  Final Train: 97.70\n",
      "   Final Test: 89.19\n",
      "Run: 03, Epoch: 01, Loss: 1.9943, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 02, Loss: 1.5831, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 03, Loss: 1.3642, Train: 60.92%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 04, Loss: 1.2067, Train: 55.17%, Valid: 57.63% Test: 45.95%\n",
      "Run: 03, Epoch: 05, Loss: 1.0822, Train: 26.44%, Valid: 42.37% Test: 27.03%\n",
      "Run: 03, Epoch: 06, Loss: 0.9712, Train: 26.44%, Valid: 44.07% Test: 24.32%\n",
      "Run: 03, Epoch: 07, Loss: 1.0140, Train: 26.44%, Valid: 40.68% Test: 24.32%\n",
      "Run: 03, Epoch: 08, Loss: 0.8912, Train: 25.29%, Valid: 40.68% Test: 29.73%\n",
      "Run: 03, Epoch: 09, Loss: 0.8971, Train: 25.29%, Valid: 44.07% Test: 29.73%\n",
      "Run: 03, Epoch: 10, Loss: 0.8348, Train: 27.59%, Valid: 45.76% Test: 32.43%\n",
      "Run: 03, Epoch: 11, Loss: 0.9822, Train: 42.53%, Valid: 54.24% Test: 37.84%\n",
      "Run: 03, Epoch: 12, Loss: 0.7979, Train: 55.17%, Valid: 59.32% Test: 45.95%\n",
      "Run: 03, Epoch: 13, Loss: 0.8033, Train: 67.82%, Valid: 59.32% Test: 51.35%\n",
      "Run: 03, Epoch: 14, Loss: 0.9419, Train: 67.82%, Valid: 61.02% Test: 54.05%\n",
      "Run: 03, Epoch: 15, Loss: 0.7304, Train: 68.97%, Valid: 64.41% Test: 54.05%\n",
      "Run: 03, Epoch: 16, Loss: 0.6893, Train: 71.26%, Valid: 61.02% Test: 54.05%\n",
      "Run: 03, Epoch: 17, Loss: 0.7506, Train: 70.11%, Valid: 62.71% Test: 56.76%\n",
      "Run: 03, Epoch: 18, Loss: 0.7586, Train: 68.97%, Valid: 61.02% Test: 54.05%\n",
      "Run: 03, Epoch: 19, Loss: 0.6616, Train: 68.97%, Valid: 59.32% Test: 54.05%\n",
      "Run: 03, Epoch: 20, Loss: 0.6512, Train: 70.11%, Valid: 64.41% Test: 54.05%\n",
      "Run: 03, Epoch: 21, Loss: 0.6730, Train: 71.26%, Valid: 66.10% Test: 54.05%\n",
      "Run: 03, Epoch: 22, Loss: 0.7285, Train: 74.71%, Valid: 71.19% Test: 54.05%\n",
      "Run: 03, Epoch: 23, Loss: 0.6073, Train: 74.71%, Valid: 72.88% Test: 59.46%\n",
      "Run: 03, Epoch: 24, Loss: 0.6014, Train: 74.71%, Valid: 72.88% Test: 59.46%\n",
      "Run: 03, Epoch: 25, Loss: 0.5634, Train: 74.71%, Valid: 69.49% Test: 59.46%\n",
      "Run: 03, Epoch: 26, Loss: 0.5967, Train: 75.86%, Valid: 67.80% Test: 59.46%\n",
      "Run: 03, Epoch: 27, Loss: 0.5561, Train: 74.71%, Valid: 62.71% Test: 59.46%\n",
      "Run: 03, Epoch: 28, Loss: 0.5695, Train: 71.26%, Valid: 64.41% Test: 59.46%\n",
      "Run: 03, Epoch: 29, Loss: 0.4482, Train: 68.97%, Valid: 64.41% Test: 56.76%\n",
      "Run: 03, Epoch: 30, Loss: 0.4982, Train: 66.67%, Valid: 62.71% Test: 56.76%\n",
      "Run: 03, Epoch: 31, Loss: 0.3643, Train: 66.67%, Valid: 62.71% Test: 54.05%\n",
      "Run: 03, Epoch: 32, Loss: 0.4156, Train: 68.97%, Valid: 62.71% Test: 54.05%\n",
      "Run: 03, Epoch: 33, Loss: 0.4121, Train: 68.97%, Valid: 62.71% Test: 54.05%\n",
      "Run: 03, Epoch: 34, Loss: 0.4320, Train: 70.11%, Valid: 64.41% Test: 56.76%\n",
      "Run: 03, Epoch: 35, Loss: 0.4141, Train: 71.26%, Valid: 66.10% Test: 56.76%\n",
      "Run: 03, Epoch: 36, Loss: 0.4448, Train: 72.41%, Valid: 66.10% Test: 56.76%\n",
      "Run: 03, Epoch: 37, Loss: 0.3877, Train: 71.26%, Valid: 64.41% Test: 54.05%\n",
      "Run: 03, Epoch: 38, Loss: 0.4506, Train: 72.41%, Valid: 66.10% Test: 56.76%\n",
      "Run: 03, Epoch: 39, Loss: 0.3267, Train: 75.86%, Valid: 67.80% Test: 56.76%\n",
      "Run: 03, Epoch: 40, Loss: 0.3076, Train: 75.86%, Valid: 67.80% Test: 59.46%\n",
      "Run: 03, Epoch: 41, Loss: 0.3168, Train: 74.71%, Valid: 69.49% Test: 59.46%\n",
      "Run: 03, Epoch: 42, Loss: 0.3609, Train: 77.01%, Valid: 71.19% Test: 64.86%\n",
      "Run: 03, Epoch: 43, Loss: 0.3616, Train: 75.86%, Valid: 71.19% Test: 64.86%\n",
      "Run: 03, Epoch: 44, Loss: 0.3054, Train: 74.71%, Valid: 71.19% Test: 64.86%\n",
      "Run: 03, Epoch: 45, Loss: 0.2807, Train: 74.71%, Valid: 71.19% Test: 64.86%\n",
      "Run: 03, Epoch: 46, Loss: 0.2274, Train: 73.56%, Valid: 74.58% Test: 64.86%\n",
      "Run: 03, Epoch: 47, Loss: 0.2798, Train: 75.86%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 48, Loss: 0.2550, Train: 79.31%, Valid: 76.27% Test: 64.86%\n",
      "Run: 03, Epoch: 49, Loss: 0.2276, Train: 79.31%, Valid: 76.27% Test: 62.16%\n",
      "Run: 03, Epoch: 50, Loss: 0.1861, Train: 81.61%, Valid: 72.88% Test: 64.86%\n",
      "Run: 03, Epoch: 51, Loss: 0.2079, Train: 85.06%, Valid: 79.66% Test: 64.86%\n",
      "Run: 03, Epoch: 52, Loss: 0.2139, Train: 82.76%, Valid: 79.66% Test: 64.86%\n",
      "Run: 03, Epoch: 53, Loss: 0.2207, Train: 81.61%, Valid: 79.66% Test: 62.16%\n",
      "Run: 03, Epoch: 54, Loss: 0.2160, Train: 81.61%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 55, Loss: 0.2859, Train: 83.91%, Valid: 83.05% Test: 67.57%\n",
      "Run: 03, Epoch: 56, Loss: 0.2920, Train: 87.36%, Valid: 86.44% Test: 75.68%\n",
      "Run: 03, Epoch: 57, Loss: 0.2120, Train: 94.25%, Valid: 89.83% Test: 78.38%\n",
      "Run: 03, Epoch: 58, Loss: 0.2476, Train: 95.40%, Valid: 91.53% Test: 78.38%\n",
      "Run: 03, Epoch: 59, Loss: 0.2285, Train: 94.25%, Valid: 89.83% Test: 78.38%\n",
      "Run: 03, Epoch: 60, Loss: 0.2530, Train: 93.10%, Valid: 89.83% Test: 81.08%\n",
      "Run: 03, Epoch: 61, Loss: 0.1710, Train: 91.95%, Valid: 89.83% Test: 81.08%\n",
      "Run: 03, Epoch: 62, Loss: 0.2019, Train: 89.66%, Valid: 88.14% Test: 75.68%\n",
      "Run: 03, Epoch: 63, Loss: 0.2602, Train: 87.36%, Valid: 86.44% Test: 72.97%\n",
      "Run: 03, Epoch: 64, Loss: 0.2105, Train: 85.06%, Valid: 83.05% Test: 70.27%\n",
      "Run: 03, Epoch: 65, Loss: 0.2220, Train: 85.06%, Valid: 84.75% Test: 64.86%\n",
      "Run: 03, Epoch: 66, Loss: 0.2324, Train: 87.36%, Valid: 84.75% Test: 67.57%\n",
      "Run: 03, Epoch: 67, Loss: 0.1832, Train: 91.95%, Valid: 84.75% Test: 70.27%\n",
      "Run: 03, Epoch: 68, Loss: 0.2034, Train: 91.95%, Valid: 83.05% Test: 70.27%\n",
      "Run: 03, Epoch: 69, Loss: 0.2471, Train: 91.95%, Valid: 86.44% Test: 70.27%\n",
      "Run: 03, Epoch: 70, Loss: 0.1744, Train: 90.80%, Valid: 88.14% Test: 75.68%\n",
      "Run: 03, Epoch: 71, Loss: 0.1544, Train: 90.80%, Valid: 88.14% Test: 75.68%\n",
      "Run: 03, Epoch: 72, Loss: 0.1996, Train: 90.80%, Valid: 88.14% Test: 75.68%\n",
      "Run: 03, Epoch: 73, Loss: 0.2087, Train: 91.95%, Valid: 83.05% Test: 75.68%\n",
      "Run: 03, Epoch: 74, Loss: 0.2222, Train: 90.80%, Valid: 77.97% Test: 75.68%\n",
      "Run: 03, Epoch: 75, Loss: 0.1611, Train: 87.36%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 76, Loss: 0.1691, Train: 89.66%, Valid: 77.97% Test: 75.68%\n",
      "Run: 03, Epoch: 77, Loss: 0.1406, Train: 88.51%, Valid: 77.97% Test: 75.68%\n",
      "Run: 03, Epoch: 78, Loss: 0.1749, Train: 89.66%, Valid: 79.66% Test: 72.97%\n",
      "Run: 03, Epoch: 79, Loss: 0.1791, Train: 90.80%, Valid: 81.36% Test: 72.97%\n",
      "Run: 03, Epoch: 80, Loss: 0.1666, Train: 89.66%, Valid: 86.44% Test: 72.97%\n",
      "Run: 03, Epoch: 81, Loss: 0.1878, Train: 89.66%, Valid: 84.75% Test: 72.97%\n",
      "Run: 03, Epoch: 82, Loss: 0.0786, Train: 89.66%, Valid: 84.75% Test: 72.97%\n",
      "Run: 03, Epoch: 83, Loss: 0.1426, Train: 88.51%, Valid: 86.44% Test: 72.97%\n",
      "Run: 03, Epoch: 84, Loss: 0.1559, Train: 89.66%, Valid: 86.44% Test: 75.68%\n",
      "Run: 03, Epoch: 85, Loss: 0.1791, Train: 88.51%, Valid: 88.14% Test: 75.68%\n",
      "Run: 03, Epoch: 86, Loss: 0.1801, Train: 89.66%, Valid: 88.14% Test: 67.57%\n",
      "Run: 03, Epoch: 87, Loss: 0.1557, Train: 89.66%, Valid: 86.44% Test: 67.57%\n",
      "Run: 03, Epoch: 88, Loss: 0.0854, Train: 90.80%, Valid: 86.44% Test: 67.57%\n",
      "Run: 03, Epoch: 89, Loss: 0.1438, Train: 90.80%, Valid: 86.44% Test: 67.57%\n",
      "Run: 03, Epoch: 90, Loss: 0.1209, Train: 89.66%, Valid: 86.44% Test: 67.57%\n",
      "Run: 03, Epoch: 91, Loss: 0.1527, Train: 90.80%, Valid: 86.44% Test: 67.57%\n",
      "Run: 03, Epoch: 92, Loss: 0.1251, Train: 97.70%, Valid: 88.14% Test: 78.38%\n",
      "Run: 03, Epoch: 93, Loss: 0.1571, Train: 100.00%, Valid: 93.22% Test: 81.08%\n",
      "Run: 03, Epoch: 94, Loss: 0.1465, Train: 100.00%, Valid: 96.61% Test: 83.78%\n",
      "Run: 03, Epoch: 95, Loss: 0.1841, Train: 100.00%, Valid: 96.61% Test: 83.78%\n",
      "Run: 03, Epoch: 96, Loss: 0.1182, Train: 98.85%, Valid: 96.61% Test: 83.78%\n",
      "Run: 03, Epoch: 97, Loss: 0.0888, Train: 98.85%, Valid: 96.61% Test: 78.38%\n",
      "Run: 03, Epoch: 98, Loss: 0.1342, Train: 94.25%, Valid: 93.22% Test: 78.38%\n",
      "Run: 03, Epoch: 99, Loss: 0.0805, Train: 91.95%, Valid: 88.14% Test: 78.38%\n",
      "Run: 03, Epoch: 100, Loss: 0.1291, Train: 90.80%, Valid: 84.75% Test: 75.68%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 96.61\n",
      "  Final Train: 100.00\n",
      "   Final Test: 83.78\n",
      "Run: 04, Epoch: 01, Loss: 1.8208, Train: 21.84%, Valid: 11.86% Test: 16.22%\n",
      "Run: 04, Epoch: 02, Loss: 1.4612, Train: 26.44%, Valid: 13.56% Test: 18.92%\n",
      "Run: 04, Epoch: 03, Loss: 1.2587, Train: 26.44%, Valid: 22.03% Test: 18.92%\n",
      "Run: 04, Epoch: 04, Loss: 1.1887, Train: 27.59%, Valid: 28.81% Test: 21.62%\n",
      "Run: 04, Epoch: 05, Loss: 1.0579, Train: 32.18%, Valid: 33.90% Test: 29.73%\n",
      "Run: 04, Epoch: 06, Loss: 0.9315, Train: 55.17%, Valid: 47.46% Test: 59.46%\n",
      "Run: 04, Epoch: 07, Loss: 0.8837, Train: 60.92%, Valid: 67.80% Test: 70.27%\n",
      "Run: 04, Epoch: 08, Loss: 0.9331, Train: 66.67%, Valid: 71.19% Test: 70.27%\n",
      "Run: 04, Epoch: 09, Loss: 0.9808, Train: 68.97%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 10, Loss: 0.8327, Train: 66.67%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 11, Loss: 0.8323, Train: 67.82%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 12, Loss: 0.8089, Train: 70.11%, Valid: 69.49% Test: 72.97%\n",
      "Run: 04, Epoch: 13, Loss: 0.7392, Train: 70.11%, Valid: 64.41% Test: 72.97%\n",
      "Run: 04, Epoch: 14, Loss: 0.7327, Train: 72.41%, Valid: 66.10% Test: 78.38%\n",
      "Run: 04, Epoch: 15, Loss: 0.7486, Train: 71.26%, Valid: 61.02% Test: 78.38%\n",
      "Run: 04, Epoch: 16, Loss: 0.6359, Train: 71.26%, Valid: 64.41% Test: 78.38%\n",
      "Run: 04, Epoch: 17, Loss: 0.7192, Train: 71.26%, Valid: 62.71% Test: 75.68%\n",
      "Run: 04, Epoch: 18, Loss: 0.6088, Train: 70.11%, Valid: 64.41% Test: 67.57%\n",
      "Run: 04, Epoch: 19, Loss: 0.6419, Train: 70.11%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 20, Loss: 0.5973, Train: 68.97%, Valid: 66.10% Test: 72.97%\n",
      "Run: 04, Epoch: 21, Loss: 0.6822, Train: 67.82%, Valid: 67.80% Test: 72.97%\n",
      "Run: 04, Epoch: 22, Loss: 0.5733, Train: 63.22%, Valid: 64.41% Test: 70.27%\n",
      "Run: 04, Epoch: 23, Loss: 0.6353, Train: 62.07%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 24, Loss: 0.4226, Train: 62.07%, Valid: 69.49% Test: 70.27%\n",
      "Run: 04, Epoch: 25, Loss: 0.4684, Train: 62.07%, Valid: 69.49% Test: 70.27%\n",
      "Run: 04, Epoch: 26, Loss: 0.5442, Train: 64.37%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 27, Loss: 0.4635, Train: 64.37%, Valid: 62.71% Test: 70.27%\n",
      "Run: 04, Epoch: 28, Loss: 0.4958, Train: 64.37%, Valid: 62.71% Test: 70.27%\n",
      "Run: 04, Epoch: 29, Loss: 0.4764, Train: 67.82%, Valid: 64.41% Test: 70.27%\n",
      "Run: 04, Epoch: 30, Loss: 0.4223, Train: 70.11%, Valid: 72.88% Test: 70.27%\n",
      "Run: 04, Epoch: 31, Loss: 0.4360, Train: 72.41%, Valid: 72.88% Test: 70.27%\n",
      "Run: 04, Epoch: 32, Loss: 0.4419, Train: 73.56%, Valid: 79.66% Test: 75.68%\n",
      "Run: 04, Epoch: 33, Loss: 0.3851, Train: 75.86%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 34, Loss: 0.3882, Train: 73.56%, Valid: 79.66% Test: 78.38%\n",
      "Run: 04, Epoch: 35, Loss: 0.3686, Train: 75.86%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 36, Loss: 0.3341, Train: 79.31%, Valid: 83.05% Test: 81.08%\n",
      "Run: 04, Epoch: 37, Loss: 0.3384, Train: 78.16%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 38, Loss: 0.2397, Train: 79.31%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 39, Loss: 0.3555, Train: 80.46%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 40, Loss: 0.3107, Train: 80.46%, Valid: 81.36% Test: 83.78%\n",
      "Run: 04, Epoch: 41, Loss: 0.3170, Train: 80.46%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 42, Loss: 0.3068, Train: 80.46%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 43, Loss: 0.2753, Train: 81.61%, Valid: 77.97% Test: 83.78%\n",
      "Run: 04, Epoch: 44, Loss: 0.3169, Train: 83.91%, Valid: 77.97% Test: 86.49%\n",
      "Run: 04, Epoch: 45, Loss: 0.2308, Train: 86.21%, Valid: 76.27% Test: 86.49%\n",
      "Run: 04, Epoch: 46, Loss: 0.2677, Train: 86.21%, Valid: 77.97% Test: 86.49%\n",
      "Run: 04, Epoch: 47, Loss: 0.2639, Train: 86.21%, Valid: 83.05% Test: 86.49%\n",
      "Run: 04, Epoch: 48, Loss: 0.2566, Train: 89.66%, Valid: 86.44% Test: 86.49%\n",
      "Run: 04, Epoch: 49, Loss: 0.2101, Train: 87.36%, Valid: 86.44% Test: 86.49%\n",
      "Run: 04, Epoch: 50, Loss: 0.3394, Train: 86.21%, Valid: 86.44% Test: 86.49%\n",
      "Run: 04, Epoch: 51, Loss: 0.2210, Train: 85.06%, Valid: 83.05% Test: 89.19%\n",
      "Run: 04, Epoch: 52, Loss: 0.2409, Train: 83.91%, Valid: 86.44% Test: 89.19%\n",
      "Run: 04, Epoch: 53, Loss: 0.2251, Train: 86.21%, Valid: 88.14% Test: 91.89%\n",
      "Run: 04, Epoch: 54, Loss: 0.2154, Train: 91.95%, Valid: 88.14% Test: 94.59%\n",
      "Run: 04, Epoch: 55, Loss: 0.2058, Train: 90.80%, Valid: 88.14% Test: 94.59%\n",
      "Run: 04, Epoch: 56, Loss: 0.1946, Train: 89.66%, Valid: 86.44% Test: 94.59%\n",
      "Run: 04, Epoch: 57, Loss: 0.1905, Train: 89.66%, Valid: 88.14% Test: 97.30%\n",
      "Run: 04, Epoch: 58, Loss: 0.1764, Train: 88.51%, Valid: 89.83% Test: 97.30%\n",
      "Run: 04, Epoch: 59, Loss: 0.1588, Train: 87.36%, Valid: 89.83% Test: 97.30%\n",
      "Run: 04, Epoch: 60, Loss: 0.1653, Train: 85.06%, Valid: 86.44% Test: 89.19%\n",
      "Run: 04, Epoch: 61, Loss: 0.1459, Train: 81.61%, Valid: 86.44% Test: 83.78%\n",
      "Run: 04, Epoch: 62, Loss: 0.1188, Train: 79.31%, Valid: 84.75% Test: 78.38%\n",
      "Run: 04, Epoch: 63, Loss: 0.1906, Train: 79.31%, Valid: 84.75% Test: 75.68%\n",
      "Run: 04, Epoch: 64, Loss: 0.1649, Train: 78.16%, Valid: 84.75% Test: 78.38%\n",
      "Run: 04, Epoch: 65, Loss: 0.1839, Train: 83.91%, Valid: 88.14% Test: 83.78%\n",
      "Run: 04, Epoch: 66, Loss: 0.1755, Train: 88.51%, Valid: 89.83% Test: 89.19%\n",
      "Run: 04, Epoch: 67, Loss: 0.2329, Train: 88.51%, Valid: 89.83% Test: 89.19%\n",
      "Run: 04, Epoch: 68, Loss: 0.2291, Train: 82.76%, Valid: 88.14% Test: 83.78%\n",
      "Run: 04, Epoch: 69, Loss: 0.2053, Train: 79.31%, Valid: 86.44% Test: 78.38%\n",
      "Run: 04, Epoch: 70, Loss: 0.1907, Train: 88.51%, Valid: 88.14% Test: 89.19%\n",
      "Run: 04, Epoch: 71, Loss: 0.1822, Train: 94.25%, Valid: 86.44% Test: 94.59%\n",
      "Run: 04, Epoch: 72, Loss: 0.1443, Train: 96.55%, Valid: 91.53% Test: 97.30%\n",
      "Run: 04, Epoch: 73, Loss: 0.1518, Train: 96.55%, Valid: 89.83% Test: 97.30%\n",
      "Run: 04, Epoch: 74, Loss: 0.2073, Train: 96.55%, Valid: 88.14% Test: 94.59%\n",
      "Run: 04, Epoch: 75, Loss: 0.1537, Train: 96.55%, Valid: 88.14% Test: 89.19%\n",
      "Run: 04, Epoch: 76, Loss: 0.1677, Train: 95.40%, Valid: 88.14% Test: 89.19%\n",
      "Run: 04, Epoch: 77, Loss: 0.1360, Train: 98.85%, Valid: 86.44% Test: 89.19%\n",
      "Run: 04, Epoch: 78, Loss: 0.2189, Train: 97.70%, Valid: 83.05% Test: 94.59%\n",
      "Run: 04, Epoch: 79, Loss: 0.1331, Train: 96.55%, Valid: 83.05% Test: 94.59%\n",
      "Run: 04, Epoch: 80, Loss: 0.2255, Train: 94.25%, Valid: 79.66% Test: 94.59%\n",
      "Run: 04, Epoch: 81, Loss: 0.2065, Train: 91.95%, Valid: 83.05% Test: 97.30%\n",
      "Run: 04, Epoch: 82, Loss: 0.1427, Train: 94.25%, Valid: 89.83% Test: 97.30%\n",
      "Run: 04, Epoch: 83, Loss: 0.1765, Train: 94.25%, Valid: 89.83% Test: 100.00%\n",
      "Run: 04, Epoch: 84, Loss: 0.1455, Train: 95.40%, Valid: 89.83% Test: 100.00%\n",
      "Run: 04, Epoch: 85, Loss: 0.1273, Train: 96.55%, Valid: 89.83% Test: 100.00%\n",
      "Run: 04, Epoch: 86, Loss: 0.1482, Train: 94.25%, Valid: 88.14% Test: 100.00%\n",
      "Run: 04, Epoch: 87, Loss: 0.1443, Train: 91.95%, Valid: 83.05% Test: 94.59%\n",
      "Run: 04, Epoch: 88, Loss: 0.1821, Train: 88.51%, Valid: 83.05% Test: 94.59%\n",
      "Run: 04, Epoch: 89, Loss: 0.1259, Train: 90.80%, Valid: 84.75% Test: 94.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 90, Loss: 0.1171, Train: 93.10%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 91, Loss: 0.0719, Train: 95.40%, Valid: 89.83% Test: 97.30%\n",
      "Run: 04, Epoch: 92, Loss: 0.1574, Train: 95.40%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 93, Loss: 0.0934, Train: 95.40%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 94, Loss: 0.1080, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 04, Epoch: 95, Loss: 0.1115, Train: 96.55%, Valid: 91.53% Test: 91.89%\n",
      "Run: 04, Epoch: 96, Loss: 0.1508, Train: 100.00%, Valid: 93.22% Test: 94.59%\n",
      "Run: 04, Epoch: 97, Loss: 0.1330, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 04, Epoch: 98, Loss: 0.0855, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 04, Epoch: 99, Loss: 0.0834, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 04, Epoch: 100, Loss: 0.1232, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run 04:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 93.22\n",
      "  Final Train: 100.00\n",
      "   Final Test: 94.59\n",
      "Run: 05, Epoch: 01, Loss: 1.8110, Train: 48.28%, Valid: 57.63% Test: 37.84%\n",
      "Run: 05, Epoch: 02, Loss: 1.7084, Train: 47.13%, Valid: 55.93% Test: 45.95%\n",
      "Run: 05, Epoch: 03, Loss: 1.3586, Train: 37.93%, Valid: 20.34% Test: 27.03%\n",
      "Run: 05, Epoch: 04, Loss: 1.3642, Train: 24.14%, Valid: 8.47% Test: 16.22%\n",
      "Run: 05, Epoch: 05, Loss: 1.1778, Train: 24.14%, Valid: 8.47% Test: 16.22%\n",
      "Run: 05, Epoch: 06, Loss: 1.0145, Train: 25.29%, Valid: 10.17% Test: 16.22%\n",
      "Run: 05, Epoch: 07, Loss: 0.9571, Train: 28.74%, Valid: 10.17% Test: 18.92%\n",
      "Run: 05, Epoch: 08, Loss: 1.0345, Train: 28.74%, Valid: 11.86% Test: 18.92%\n",
      "Run: 05, Epoch: 09, Loss: 1.0122, Train: 37.93%, Valid: 22.03% Test: 29.73%\n",
      "Run: 05, Epoch: 10, Loss: 0.9718, Train: 41.38%, Valid: 32.20% Test: 35.14%\n",
      "Run: 05, Epoch: 11, Loss: 0.9750, Train: 51.72%, Valid: 42.37% Test: 37.84%\n",
      "Run: 05, Epoch: 12, Loss: 0.8898, Train: 58.62%, Valid: 55.93% Test: 43.24%\n",
      "Run: 05, Epoch: 13, Loss: 0.8246, Train: 65.52%, Valid: 62.71% Test: 45.95%\n",
      "Run: 05, Epoch: 14, Loss: 0.7569, Train: 64.37%, Valid: 62.71% Test: 51.35%\n",
      "Run: 05, Epoch: 15, Loss: 0.7771, Train: 72.41%, Valid: 71.19% Test: 64.86%\n",
      "Run: 05, Epoch: 16, Loss: 0.6769, Train: 78.16%, Valid: 74.58% Test: 64.86%\n",
      "Run: 05, Epoch: 17, Loss: 0.7258, Train: 80.46%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 18, Loss: 0.8125, Train: 77.01%, Valid: 81.36% Test: 70.27%\n",
      "Run: 05, Epoch: 19, Loss: 0.7343, Train: 75.86%, Valid: 79.66% Test: 70.27%\n",
      "Run: 05, Epoch: 20, Loss: 0.5698, Train: 73.56%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 21, Loss: 0.6262, Train: 66.67%, Valid: 72.88% Test: 59.46%\n",
      "Run: 05, Epoch: 22, Loss: 0.5719, Train: 66.67%, Valid: 72.88% Test: 56.76%\n",
      "Run: 05, Epoch: 23, Loss: 0.6013, Train: 66.67%, Valid: 71.19% Test: 56.76%\n",
      "Run: 05, Epoch: 24, Loss: 0.5884, Train: 64.37%, Valid: 71.19% Test: 56.76%\n",
      "Run: 05, Epoch: 25, Loss: 0.6209, Train: 64.37%, Valid: 72.88% Test: 59.46%\n",
      "Run: 05, Epoch: 26, Loss: 0.3886, Train: 65.52%, Valid: 76.27% Test: 62.16%\n",
      "Run: 05, Epoch: 27, Loss: 0.4888, Train: 65.52%, Valid: 76.27% Test: 62.16%\n",
      "Run: 05, Epoch: 28, Loss: 0.4698, Train: 67.82%, Valid: 77.97% Test: 64.86%\n",
      "Run: 05, Epoch: 29, Loss: 0.4030, Train: 70.11%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 30, Loss: 0.4279, Train: 70.11%, Valid: 84.75% Test: 67.57%\n",
      "Run: 05, Epoch: 31, Loss: 0.4365, Train: 70.11%, Valid: 88.14% Test: 72.97%\n",
      "Run: 05, Epoch: 32, Loss: 0.4938, Train: 74.71%, Valid: 88.14% Test: 72.97%\n",
      "Run: 05, Epoch: 33, Loss: 0.3886, Train: 77.01%, Valid: 88.14% Test: 70.27%\n",
      "Run: 05, Epoch: 34, Loss: 0.3529, Train: 77.01%, Valid: 88.14% Test: 72.97%\n",
      "Run: 05, Epoch: 35, Loss: 0.2887, Train: 75.86%, Valid: 84.75% Test: 72.97%\n",
      "Run: 05, Epoch: 36, Loss: 0.3791, Train: 74.71%, Valid: 84.75% Test: 72.97%\n",
      "Run: 05, Epoch: 37, Loss: 0.3175, Train: 73.56%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 38, Loss: 0.3976, Train: 74.71%, Valid: 84.75% Test: 72.97%\n",
      "Run: 05, Epoch: 39, Loss: 0.3178, Train: 79.31%, Valid: 89.83% Test: 72.97%\n",
      "Run: 05, Epoch: 40, Loss: 0.3257, Train: 85.06%, Valid: 91.53% Test: 72.97%\n",
      "Run: 05, Epoch: 41, Loss: 0.2622, Train: 87.36%, Valid: 96.61% Test: 81.08%\n",
      "Run: 05, Epoch: 42, Loss: 0.2745, Train: 87.36%, Valid: 96.61% Test: 81.08%\n",
      "Run: 05, Epoch: 43, Loss: 0.3375, Train: 88.51%, Valid: 96.61% Test: 81.08%\n",
      "Run: 05, Epoch: 44, Loss: 0.3046, Train: 89.66%, Valid: 93.22% Test: 81.08%\n",
      "Run: 05, Epoch: 45, Loss: 0.3679, Train: 90.80%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 46, Loss: 0.2367, Train: 89.66%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 47, Loss: 0.2770, Train: 85.06%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 48, Loss: 0.2609, Train: 85.06%, Valid: 89.83% Test: 78.38%\n",
      "Run: 05, Epoch: 49, Loss: 0.1956, Train: 78.16%, Valid: 89.83% Test: 72.97%\n",
      "Run: 05, Epoch: 50, Loss: 0.2844, Train: 78.16%, Valid: 88.14% Test: 75.68%\n",
      "Run: 05, Epoch: 51, Loss: 0.3003, Train: 79.31%, Valid: 88.14% Test: 78.38%\n",
      "Run: 05, Epoch: 52, Loss: 0.2936, Train: 82.76%, Valid: 88.14% Test: 78.38%\n",
      "Run: 05, Epoch: 53, Loss: 0.2479, Train: 82.76%, Valid: 89.83% Test: 78.38%\n",
      "Run: 05, Epoch: 54, Loss: 0.2858, Train: 85.06%, Valid: 93.22% Test: 78.38%\n",
      "Run: 05, Epoch: 55, Loss: 0.2073, Train: 87.36%, Valid: 93.22% Test: 78.38%\n",
      "Run: 05, Epoch: 56, Loss: 0.3044, Train: 93.10%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 57, Loss: 0.2064, Train: 96.55%, Valid: 93.22% Test: 81.08%\n",
      "Run: 05, Epoch: 58, Loss: 0.1981, Train: 96.55%, Valid: 91.53% Test: 83.78%\n",
      "Run: 05, Epoch: 59, Loss: 0.1637, Train: 98.85%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 60, Loss: 0.1668, Train: 97.70%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 61, Loss: 0.2807, Train: 97.70%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 62, Loss: 0.1480, Train: 96.55%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 63, Loss: 0.1758, Train: 95.40%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 64, Loss: 0.2118, Train: 96.55%, Valid: 94.92% Test: 86.49%\n",
      "Run: 05, Epoch: 65, Loss: 0.1783, Train: 97.70%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 66, Loss: 0.1718, Train: 95.40%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 67, Loss: 0.1201, Train: 94.25%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 68, Loss: 0.1957, Train: 95.40%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 69, Loss: 0.3413, Train: 94.25%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 70, Loss: 0.1718, Train: 95.40%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 71, Loss: 0.1865, Train: 95.40%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 72, Loss: 0.1939, Train: 95.40%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 73, Loss: 0.1322, Train: 96.55%, Valid: 94.92% Test: 81.08%\n",
      "Run: 05, Epoch: 74, Loss: 0.1457, Train: 96.55%, Valid: 94.92% Test: 81.08%\n",
      "Run: 05, Epoch: 75, Loss: 0.1330, Train: 96.55%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 76, Loss: 0.1898, Train: 97.70%, Valid: 94.92% Test: 81.08%\n",
      "Run: 05, Epoch: 77, Loss: 0.1396, Train: 96.55%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 78, Loss: 0.1823, Train: 96.55%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 79, Loss: 0.1428, Train: 97.70%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 80, Loss: 0.1317, Train: 97.70%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 81, Loss: 0.1887, Train: 97.70%, Valid: 98.31% Test: 83.78%\n",
      "Run: 05, Epoch: 82, Loss: 0.1244, Train: 95.40%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 83, Loss: 0.1792, Train: 96.55%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 84, Loss: 0.1218, Train: 95.40%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 85, Loss: 0.1485, Train: 96.55%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 86, Loss: 0.1560, Train: 96.55%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 87, Loss: 0.1668, Train: 96.55%, Valid: 94.92% Test: 91.89%\n",
      "Run: 05, Epoch: 88, Loss: 0.0987, Train: 96.55%, Valid: 96.61% Test: 91.89%\n",
      "Run: 05, Epoch: 89, Loss: 0.1454, Train: 95.40%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 90, Loss: 0.1070, Train: 97.70%, Valid: 98.31% Test: 89.19%\n",
      "Run: 05, Epoch: 91, Loss: 0.1349, Train: 93.10%, Valid: 98.31% Test: 89.19%\n",
      "Run: 05, Epoch: 92, Loss: 0.1456, Train: 93.10%, Valid: 98.31% Test: 81.08%\n",
      "Run: 05, Epoch: 93, Loss: 0.1015, Train: 90.80%, Valid: 98.31% Test: 83.78%\n",
      "Run: 05, Epoch: 94, Loss: 0.1414, Train: 91.95%, Valid: 98.31% Test: 81.08%\n",
      "Run: 05, Epoch: 95, Loss: 0.1246, Train: 95.40%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 96, Loss: 0.1095, Train: 96.55%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 97, Loss: 0.1038, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 98, Loss: 0.1238, Train: 98.85%, Valid: 96.61% Test: 91.89%\n",
      "Run: 05, Epoch: 99, Loss: 0.0852, Train: 98.85%, Valid: 94.92% Test: 91.89%\n",
      "Run: 05, Epoch: 100, Loss: 0.1249, Train: 97.70%, Valid: 94.92% Test: 91.89%\n",
      "Run 05:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 98.31\n",
      "  Final Train: 97.70\n",
      "   Final Test: 83.78\n",
      "Run: 06, Epoch: 01, Loss: 1.6630, Train: 17.24%, Valid: 16.95% Test: 13.51%\n",
      "Run: 06, Epoch: 02, Loss: 1.4801, Train: 21.84%, Valid: 15.25% Test: 21.62%\n",
      "Run: 06, Epoch: 03, Loss: 1.3718, Train: 19.54%, Valid: 15.25% Test: 21.62%\n",
      "Run: 06, Epoch: 04, Loss: 1.2238, Train: 22.99%, Valid: 16.95% Test: 16.22%\n",
      "Run: 06, Epoch: 05, Loss: 1.1910, Train: 29.89%, Valid: 22.03% Test: 18.92%\n",
      "Run: 06, Epoch: 06, Loss: 1.0766, Train: 36.78%, Valid: 22.03% Test: 18.92%\n",
      "Run: 06, Epoch: 07, Loss: 1.1037, Train: 48.28%, Valid: 37.29% Test: 29.73%\n",
      "Run: 06, Epoch: 08, Loss: 1.0301, Train: 60.92%, Valid: 57.63% Test: 48.65%\n",
      "Run: 06, Epoch: 09, Loss: 0.9669, Train: 60.92%, Valid: 59.32% Test: 45.95%\n",
      "Run: 06, Epoch: 10, Loss: 0.9324, Train: 60.92%, Valid: 57.63% Test: 43.24%\n",
      "Run: 06, Epoch: 11, Loss: 0.8426, Train: 62.07%, Valid: 61.02% Test: 48.65%\n",
      "Run: 06, Epoch: 12, Loss: 0.8272, Train: 63.22%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 13, Loss: 0.8703, Train: 65.52%, Valid: 64.41% Test: 64.86%\n",
      "Run: 06, Epoch: 14, Loss: 0.7822, Train: 71.26%, Valid: 72.88% Test: 64.86%\n",
      "Run: 06, Epoch: 15, Loss: 0.7265, Train: 75.86%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 16, Loss: 0.7458, Train: 68.97%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 17, Loss: 0.6664, Train: 71.26%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 18, Loss: 0.6272, Train: 71.26%, Valid: 72.88% Test: 70.27%\n",
      "Run: 06, Epoch: 19, Loss: 0.6046, Train: 70.11%, Valid: 72.88% Test: 67.57%\n",
      "Run: 06, Epoch: 20, Loss: 0.5969, Train: 68.97%, Valid: 72.88% Test: 72.97%\n",
      "Run: 06, Epoch: 21, Loss: 0.6151, Train: 70.11%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 22, Loss: 0.5680, Train: 68.97%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 23, Loss: 0.5510, Train: 70.11%, Valid: 76.27% Test: 67.57%\n",
      "Run: 06, Epoch: 24, Loss: 0.4921, Train: 72.41%, Valid: 77.97% Test: 67.57%\n",
      "Run: 06, Epoch: 25, Loss: 0.5169, Train: 72.41%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 26, Loss: 0.5102, Train: 72.41%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 27, Loss: 0.4838, Train: 73.56%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 28, Loss: 0.4237, Train: 73.56%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 29, Loss: 0.3923, Train: 73.56%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 30, Loss: 0.3769, Train: 73.56%, Valid: 76.27% Test: 67.57%\n",
      "Run: 06, Epoch: 31, Loss: 0.3785, Train: 73.56%, Valid: 77.97% Test: 67.57%\n",
      "Run: 06, Epoch: 32, Loss: 0.4170, Train: 73.56%, Valid: 76.27% Test: 67.57%\n",
      "Run: 06, Epoch: 33, Loss: 0.3623, Train: 77.01%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 34, Loss: 0.3787, Train: 79.31%, Valid: 77.97% Test: 70.27%\n",
      "Run: 06, Epoch: 35, Loss: 0.3020, Train: 85.06%, Valid: 81.36% Test: 72.97%\n",
      "Run: 06, Epoch: 36, Loss: 0.3230, Train: 87.36%, Valid: 83.05% Test: 72.97%\n",
      "Run: 06, Epoch: 37, Loss: 0.3566, Train: 88.51%, Valid: 86.44% Test: 78.38%\n",
      "Run: 06, Epoch: 38, Loss: 0.3283, Train: 88.51%, Valid: 88.14% Test: 78.38%\n",
      "Run: 06, Epoch: 39, Loss: 0.3301, Train: 88.51%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 40, Loss: 0.3257, Train: 90.80%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 41, Loss: 0.2753, Train: 86.21%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 42, Loss: 0.2767, Train: 86.21%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 43, Loss: 0.2812, Train: 83.91%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 44, Loss: 0.2816, Train: 83.91%, Valid: 83.05% Test: 75.68%\n",
      "Run: 06, Epoch: 45, Loss: 0.3105, Train: 85.06%, Valid: 83.05% Test: 75.68%\n",
      "Run: 06, Epoch: 46, Loss: 0.2394, Train: 89.66%, Valid: 83.05% Test: 78.38%\n",
      "Run: 06, Epoch: 47, Loss: 0.2098, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 06, Epoch: 48, Loss: 0.2330, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 49, Loss: 0.2757, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 50, Loss: 0.2161, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 06, Epoch: 51, Loss: 0.1798, Train: 96.55%, Valid: 89.83% Test: 86.49%\n",
      "Run: 06, Epoch: 52, Loss: 0.1788, Train: 96.55%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 53, Loss: 0.2875, Train: 96.55%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 54, Loss: 0.2531, Train: 95.40%, Valid: 89.83% Test: 81.08%\n",
      "Run: 06, Epoch: 55, Loss: 0.1497, Train: 95.40%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 56, Loss: 0.1821, Train: 94.25%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 57, Loss: 0.2121, Train: 94.25%, Valid: 91.53% Test: 81.08%\n",
      "Run: 06, Epoch: 58, Loss: 0.2129, Train: 94.25%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 59, Loss: 0.2660, Train: 95.40%, Valid: 94.92% Test: 83.78%\n",
      "Run: 06, Epoch: 60, Loss: 0.1945, Train: 94.25%, Valid: 94.92% Test: 83.78%\n",
      "Run: 06, Epoch: 61, Loss: 0.2232, Train: 95.40%, Valid: 94.92% Test: 83.78%\n",
      "Run: 06, Epoch: 62, Loss: 0.2011, Train: 95.40%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 63, Loss: 0.1896, Train: 96.55%, Valid: 91.53% Test: 81.08%\n",
      "Run: 06, Epoch: 64, Loss: 0.2245, Train: 97.70%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 65, Loss: 0.1982, Train: 97.70%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 66, Loss: 0.1191, Train: 97.70%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 67, Loss: 0.1265, Train: 97.70%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 68, Loss: 0.1297, Train: 97.70%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 69, Loss: 0.1139, Train: 97.70%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 70, Loss: 0.1785, Train: 97.70%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 71, Loss: 0.1689, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 72, Loss: 0.1361, Train: 96.55%, Valid: 94.92% Test: 89.19%\n",
      "Run: 06, Epoch: 73, Loss: 0.1767, Train: 93.10%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 74, Loss: 0.2180, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 75, Loss: 0.1618, Train: 97.70%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 76, Loss: 0.1801, Train: 97.70%, Valid: 94.92% Test: 83.78%\n",
      "Run: 06, Epoch: 77, Loss: 0.2144, Train: 97.70%, Valid: 96.61% Test: 81.08%\n",
      "Run: 06, Epoch: 78, Loss: 0.1717, Train: 96.55%, Valid: 93.22% Test: 81.08%\n",
      "Run: 06, Epoch: 79, Loss: 0.1243, Train: 95.40%, Valid: 91.53% Test: 81.08%\n",
      "Run: 06, Epoch: 80, Loss: 0.1311, Train: 95.40%, Valid: 89.83% Test: 81.08%\n",
      "Run: 06, Epoch: 81, Loss: 0.1814, Train: 94.25%, Valid: 89.83% Test: 81.08%\n",
      "Run: 06, Epoch: 82, Loss: 0.1258, Train: 93.10%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 83, Loss: 0.2157, Train: 94.25%, Valid: 91.53% Test: 81.08%\n",
      "Run: 06, Epoch: 84, Loss: 0.2153, Train: 96.55%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 85, Loss: 0.0883, Train: 97.70%, Valid: 91.53% Test: 81.08%\n",
      "Run: 06, Epoch: 86, Loss: 0.1625, Train: 97.70%, Valid: 91.53% Test: 81.08%\n",
      "Run: 06, Epoch: 87, Loss: 0.1493, Train: 97.70%, Valid: 93.22% Test: 81.08%\n",
      "Run: 06, Epoch: 88, Loss: 0.1098, Train: 97.70%, Valid: 93.22% Test: 81.08%\n",
      "Run: 06, Epoch: 89, Loss: 0.1512, Train: 98.85%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 90, Loss: 0.1413, Train: 98.85%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 91, Loss: 0.0989, Train: 98.85%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 92, Loss: 0.1172, Train: 97.70%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 93, Loss: 0.0864, Train: 96.55%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 94, Loss: 0.1253, Train: 94.25%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 95, Loss: 0.0983, Train: 94.25%, Valid: 91.53% Test: 81.08%\n",
      "Run: 06, Epoch: 96, Loss: 0.1433, Train: 94.25%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 97, Loss: 0.1222, Train: 96.55%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 98, Loss: 0.1009, Train: 97.70%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 99, Loss: 0.0944, Train: 97.70%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 100, Loss: 0.0854, Train: 97.70%, Valid: 93.22% Test: 86.49%\n",
      "Run 06:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 96.61\n",
      "  Final Train: 97.70\n",
      "   Final Test: 81.08\n",
      "Run: 07, Epoch: 01, Loss: 1.7297, Train: 17.24%, Valid: 11.86% Test: 29.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 02, Loss: 1.6298, Train: 22.99%, Valid: 16.95% Test: 29.73%\n",
      "Run: 07, Epoch: 03, Loss: 1.4124, Train: 31.03%, Valid: 25.42% Test: 27.03%\n",
      "Run: 07, Epoch: 04, Loss: 1.1510, Train: 27.59%, Valid: 23.73% Test: 16.22%\n",
      "Run: 07, Epoch: 05, Loss: 1.2653, Train: 27.59%, Valid: 25.42% Test: 16.22%\n",
      "Run: 07, Epoch: 06, Loss: 1.1568, Train: 25.29%, Valid: 25.42% Test: 10.81%\n",
      "Run: 07, Epoch: 07, Loss: 0.9167, Train: 24.14%, Valid: 23.73% Test: 10.81%\n",
      "Run: 07, Epoch: 08, Loss: 0.8875, Train: 26.44%, Valid: 22.03% Test: 13.51%\n",
      "Run: 07, Epoch: 09, Loss: 0.8137, Train: 32.18%, Valid: 25.42% Test: 13.51%\n",
      "Run: 07, Epoch: 10, Loss: 0.7976, Train: 56.32%, Valid: 49.15% Test: 43.24%\n",
      "Run: 07, Epoch: 11, Loss: 0.8216, Train: 64.37%, Valid: 66.10% Test: 56.76%\n",
      "Run: 07, Epoch: 12, Loss: 0.8349, Train: 74.71%, Valid: 69.49% Test: 56.76%\n",
      "Run: 07, Epoch: 13, Loss: 0.6866, Train: 73.56%, Valid: 72.88% Test: 62.16%\n",
      "Run: 07, Epoch: 14, Loss: 0.7236, Train: 74.71%, Valid: 74.58% Test: 62.16%\n",
      "Run: 07, Epoch: 15, Loss: 0.6033, Train: 72.41%, Valid: 71.19% Test: 56.76%\n",
      "Run: 07, Epoch: 16, Loss: 0.6187, Train: 71.26%, Valid: 67.80% Test: 59.46%\n",
      "Run: 07, Epoch: 17, Loss: 0.5408, Train: 66.67%, Valid: 66.10% Test: 56.76%\n",
      "Run: 07, Epoch: 18, Loss: 0.5670, Train: 65.52%, Valid: 66.10% Test: 56.76%\n",
      "Run: 07, Epoch: 19, Loss: 0.5363, Train: 65.52%, Valid: 66.10% Test: 56.76%\n",
      "Run: 07, Epoch: 20, Loss: 0.5699, Train: 65.52%, Valid: 66.10% Test: 59.46%\n",
      "Run: 07, Epoch: 21, Loss: 0.4900, Train: 67.82%, Valid: 67.80% Test: 62.16%\n",
      "Run: 07, Epoch: 22, Loss: 0.4668, Train: 72.41%, Valid: 67.80% Test: 62.16%\n",
      "Run: 07, Epoch: 23, Loss: 0.4442, Train: 77.01%, Valid: 69.49% Test: 62.16%\n",
      "Run: 07, Epoch: 24, Loss: 0.3985, Train: 77.01%, Valid: 69.49% Test: 62.16%\n",
      "Run: 07, Epoch: 25, Loss: 0.4620, Train: 80.46%, Valid: 69.49% Test: 62.16%\n",
      "Run: 07, Epoch: 26, Loss: 0.4187, Train: 73.56%, Valid: 67.80% Test: 62.16%\n",
      "Run: 07, Epoch: 27, Loss: 0.3690, Train: 71.26%, Valid: 67.80% Test: 62.16%\n",
      "Run: 07, Epoch: 28, Loss: 0.4679, Train: 70.11%, Valid: 67.80% Test: 64.86%\n",
      "Run: 07, Epoch: 29, Loss: 0.4200, Train: 73.56%, Valid: 69.49% Test: 64.86%\n",
      "Run: 07, Epoch: 30, Loss: 0.3357, Train: 75.86%, Valid: 71.19% Test: 67.57%\n",
      "Run: 07, Epoch: 31, Loss: 0.3924, Train: 77.01%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 32, Loss: 0.3774, Train: 79.31%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 33, Loss: 0.3293, Train: 85.06%, Valid: 83.05% Test: 70.27%\n",
      "Run: 07, Epoch: 34, Loss: 0.3195, Train: 86.21%, Valid: 81.36% Test: 70.27%\n",
      "Run: 07, Epoch: 35, Loss: 0.3035, Train: 85.06%, Valid: 81.36% Test: 70.27%\n",
      "Run: 07, Epoch: 36, Loss: 0.3026, Train: 85.06%, Valid: 81.36% Test: 67.57%\n",
      "Run: 07, Epoch: 37, Loss: 0.2599, Train: 79.31%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 38, Loss: 0.3214, Train: 77.01%, Valid: 77.97% Test: 64.86%\n",
      "Run: 07, Epoch: 39, Loss: 0.3008, Train: 77.01%, Valid: 77.97% Test: 64.86%\n",
      "Run: 07, Epoch: 40, Loss: 0.2985, Train: 77.01%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 41, Loss: 0.2906, Train: 80.46%, Valid: 83.05% Test: 70.27%\n",
      "Run: 07, Epoch: 42, Loss: 0.2890, Train: 81.61%, Valid: 83.05% Test: 70.27%\n",
      "Run: 07, Epoch: 43, Loss: 0.2490, Train: 81.61%, Valid: 81.36% Test: 70.27%\n",
      "Run: 07, Epoch: 44, Loss: 0.3031, Train: 88.51%, Valid: 84.75% Test: 72.97%\n",
      "Run: 07, Epoch: 45, Loss: 0.2145, Train: 94.25%, Valid: 84.75% Test: 78.38%\n",
      "Run: 07, Epoch: 46, Loss: 0.1824, Train: 97.70%, Valid: 89.83% Test: 81.08%\n",
      "Run: 07, Epoch: 47, Loss: 0.2199, Train: 97.70%, Valid: 89.83% Test: 81.08%\n",
      "Run: 07, Epoch: 48, Loss: 0.1955, Train: 96.55%, Valid: 89.83% Test: 81.08%\n",
      "Run: 07, Epoch: 49, Loss: 0.2269, Train: 95.40%, Valid: 89.83% Test: 78.38%\n",
      "Run: 07, Epoch: 50, Loss: 0.2140, Train: 89.66%, Valid: 86.44% Test: 78.38%\n",
      "Run: 07, Epoch: 51, Loss: 0.1751, Train: 88.51%, Valid: 83.05% Test: 72.97%\n",
      "Run: 07, Epoch: 52, Loss: 0.2340, Train: 85.06%, Valid: 83.05% Test: 72.97%\n",
      "Run: 07, Epoch: 53, Loss: 0.2105, Train: 80.46%, Valid: 79.66% Test: 72.97%\n",
      "Run: 07, Epoch: 54, Loss: 0.2346, Train: 85.06%, Valid: 79.66% Test: 72.97%\n",
      "Run: 07, Epoch: 55, Loss: 0.1982, Train: 87.36%, Valid: 81.36% Test: 70.27%\n",
      "Run: 07, Epoch: 56, Loss: 0.1979, Train: 82.76%, Valid: 81.36% Test: 70.27%\n",
      "Run: 07, Epoch: 57, Loss: 0.1576, Train: 80.46%, Valid: 81.36% Test: 70.27%\n",
      "Run: 07, Epoch: 58, Loss: 0.1777, Train: 79.31%, Valid: 81.36% Test: 70.27%\n",
      "Run: 07, Epoch: 59, Loss: 0.1807, Train: 79.31%, Valid: 81.36% Test: 70.27%\n",
      "Run: 07, Epoch: 60, Loss: 0.1522, Train: 87.36%, Valid: 81.36% Test: 75.68%\n",
      "Run: 07, Epoch: 61, Loss: 0.2459, Train: 95.40%, Valid: 83.05% Test: 81.08%\n",
      "Run: 07, Epoch: 62, Loss: 0.1406, Train: 97.70%, Valid: 84.75% Test: 83.78%\n",
      "Run: 07, Epoch: 63, Loss: 0.2045, Train: 97.70%, Valid: 86.44% Test: 83.78%\n",
      "Run: 07, Epoch: 64, Loss: 0.1367, Train: 97.70%, Valid: 89.83% Test: 83.78%\n",
      "Run: 07, Epoch: 65, Loss: 0.1420, Train: 96.55%, Valid: 89.83% Test: 83.78%\n",
      "Run: 07, Epoch: 66, Loss: 0.1135, Train: 94.25%, Valid: 84.75% Test: 81.08%\n",
      "Run: 07, Epoch: 67, Loss: 0.0928, Train: 90.80%, Valid: 83.05% Test: 78.38%\n",
      "Run: 07, Epoch: 68, Loss: 0.1298, Train: 90.80%, Valid: 83.05% Test: 78.38%\n",
      "Run: 07, Epoch: 69, Loss: 0.1044, Train: 90.80%, Valid: 83.05% Test: 78.38%\n",
      "Run: 07, Epoch: 70, Loss: 0.1888, Train: 97.70%, Valid: 89.83% Test: 83.78%\n",
      "Run: 07, Epoch: 71, Loss: 0.0999, Train: 97.70%, Valid: 91.53% Test: 86.49%\n",
      "Run: 07, Epoch: 72, Loss: 0.0886, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 07, Epoch: 73, Loss: 0.0932, Train: 98.85%, Valid: 93.22% Test: 89.19%\n",
      "Run: 07, Epoch: 74, Loss: 0.1603, Train: 98.85%, Valid: 93.22% Test: 89.19%\n",
      "Run: 07, Epoch: 75, Loss: 0.1117, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 07, Epoch: 76, Loss: 0.1465, Train: 96.55%, Valid: 84.75% Test: 83.78%\n",
      "Run: 07, Epoch: 77, Loss: 0.1676, Train: 96.55%, Valid: 81.36% Test: 81.08%\n",
      "Run: 07, Epoch: 78, Loss: 0.0970, Train: 96.55%, Valid: 81.36% Test: 81.08%\n",
      "Run: 07, Epoch: 79, Loss: 0.1133, Train: 93.10%, Valid: 84.75% Test: 75.68%\n",
      "Run: 07, Epoch: 80, Loss: 0.0981, Train: 93.10%, Valid: 84.75% Test: 75.68%\n",
      "Run: 07, Epoch: 81, Loss: 0.0840, Train: 90.80%, Valid: 84.75% Test: 78.38%\n",
      "Run: 07, Epoch: 82, Loss: 0.1342, Train: 93.10%, Valid: 84.75% Test: 78.38%\n",
      "Run: 07, Epoch: 83, Loss: 0.1215, Train: 97.70%, Valid: 86.44% Test: 78.38%\n",
      "Run: 07, Epoch: 84, Loss: 0.0803, Train: 96.55%, Valid: 86.44% Test: 78.38%\n",
      "Run: 07, Epoch: 85, Loss: 0.1315, Train: 97.70%, Valid: 86.44% Test: 75.68%\n",
      "Run: 07, Epoch: 86, Loss: 0.0630, Train: 97.70%, Valid: 86.44% Test: 81.08%\n",
      "Run: 07, Epoch: 87, Loss: 0.1002, Train: 98.85%, Valid: 84.75% Test: 81.08%\n",
      "Run: 07, Epoch: 88, Loss: 0.0704, Train: 98.85%, Valid: 84.75% Test: 81.08%\n",
      "Run: 07, Epoch: 89, Loss: 0.1035, Train: 97.70%, Valid: 86.44% Test: 83.78%\n",
      "Run: 07, Epoch: 90, Loss: 0.1115, Train: 96.55%, Valid: 86.44% Test: 83.78%\n",
      "Run: 07, Epoch: 91, Loss: 0.1209, Train: 96.55%, Valid: 86.44% Test: 83.78%\n",
      "Run: 07, Epoch: 92, Loss: 0.0806, Train: 96.55%, Valid: 86.44% Test: 86.49%\n",
      "Run: 07, Epoch: 93, Loss: 0.1138, Train: 97.70%, Valid: 88.14% Test: 89.19%\n",
      "Run: 07, Epoch: 94, Loss: 0.1148, Train: 97.70%, Valid: 86.44% Test: 89.19%\n",
      "Run: 07, Epoch: 95, Loss: 0.0746, Train: 97.70%, Valid: 84.75% Test: 89.19%\n",
      "Run: 07, Epoch: 96, Loss: 0.0724, Train: 97.70%, Valid: 86.44% Test: 81.08%\n",
      "Run: 07, Epoch: 97, Loss: 0.0773, Train: 97.70%, Valid: 88.14% Test: 81.08%\n",
      "Run: 07, Epoch: 98, Loss: 0.1213, Train: 97.70%, Valid: 86.44% Test: 89.19%\n",
      "Run: 07, Epoch: 99, Loss: 0.1176, Train: 97.70%, Valid: 86.44% Test: 89.19%\n",
      "Run: 07, Epoch: 100, Loss: 0.0421, Train: 98.85%, Valid: 88.14% Test: 86.49%\n",
      "Run 07:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 94.92\n",
      "  Final Train: 98.85\n",
      "   Final Test: 89.19\n",
      "Run: 08, Epoch: 01, Loss: 1.6571, Train: 24.14%, Valid: 15.25% Test: 10.81%\n",
      "Run: 08, Epoch: 02, Loss: 1.5010, Train: 25.29%, Valid: 16.95% Test: 13.51%\n",
      "Run: 08, Epoch: 03, Loss: 1.3252, Train: 25.29%, Valid: 16.95% Test: 13.51%\n",
      "Run: 08, Epoch: 04, Loss: 1.2122, Train: 27.59%, Valid: 20.34% Test: 16.22%\n",
      "Run: 08, Epoch: 05, Loss: 1.1354, Train: 33.33%, Valid: 33.90% Test: 27.03%\n",
      "Run: 08, Epoch: 06, Loss: 1.2607, Train: 55.17%, Valid: 52.54% Test: 45.95%\n",
      "Run: 08, Epoch: 07, Loss: 1.1044, Train: 58.62%, Valid: 62.71% Test: 56.76%\n",
      "Run: 08, Epoch: 08, Loss: 0.9871, Train: 63.22%, Valid: 66.10% Test: 59.46%\n",
      "Run: 08, Epoch: 09, Loss: 0.9575, Train: 63.22%, Valid: 66.10% Test: 59.46%\n",
      "Run: 08, Epoch: 10, Loss: 0.9867, Train: 62.07%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 11, Loss: 0.9414, Train: 62.07%, Valid: 72.88% Test: 64.86%\n",
      "Run: 08, Epoch: 12, Loss: 0.8229, Train: 64.37%, Valid: 74.58% Test: 72.97%\n",
      "Run: 08, Epoch: 13, Loss: 0.8566, Train: 65.52%, Valid: 76.27% Test: 72.97%\n",
      "Run: 08, Epoch: 14, Loss: 0.7352, Train: 66.67%, Valid: 74.58% Test: 72.97%\n",
      "Run: 08, Epoch: 15, Loss: 0.7552, Train: 65.52%, Valid: 72.88% Test: 72.97%\n",
      "Run: 08, Epoch: 16, Loss: 0.6234, Train: 63.22%, Valid: 71.19% Test: 72.97%\n",
      "Run: 08, Epoch: 17, Loss: 0.6493, Train: 62.07%, Valid: 71.19% Test: 72.97%\n",
      "Run: 08, Epoch: 18, Loss: 0.6027, Train: 56.32%, Valid: 71.19% Test: 72.97%\n",
      "Run: 08, Epoch: 19, Loss: 0.5840, Train: 56.32%, Valid: 71.19% Test: 72.97%\n",
      "Run: 08, Epoch: 20, Loss: 0.4868, Train: 56.32%, Valid: 69.49% Test: 70.27%\n",
      "Run: 08, Epoch: 21, Loss: 0.4949, Train: 55.17%, Valid: 69.49% Test: 70.27%\n",
      "Run: 08, Epoch: 22, Loss: 0.4851, Train: 55.17%, Valid: 69.49% Test: 70.27%\n",
      "Run: 08, Epoch: 23, Loss: 0.4500, Train: 56.32%, Valid: 69.49% Test: 70.27%\n",
      "Run: 08, Epoch: 24, Loss: 0.4084, Train: 58.62%, Valid: 66.10% Test: 70.27%\n",
      "Run: 08, Epoch: 25, Loss: 0.4757, Train: 66.67%, Valid: 71.19% Test: 78.38%\n",
      "Run: 08, Epoch: 26, Loss: 0.4004, Train: 68.97%, Valid: 72.88% Test: 83.78%\n",
      "Run: 08, Epoch: 27, Loss: 0.4257, Train: 71.26%, Valid: 72.88% Test: 83.78%\n",
      "Run: 08, Epoch: 28, Loss: 0.4153, Train: 70.11%, Valid: 76.27% Test: 81.08%\n",
      "Run: 08, Epoch: 29, Loss: 0.2887, Train: 70.11%, Valid: 74.58% Test: 78.38%\n",
      "Run: 08, Epoch: 30, Loss: 0.3697, Train: 70.11%, Valid: 74.58% Test: 78.38%\n",
      "Run: 08, Epoch: 31, Loss: 0.4139, Train: 74.71%, Valid: 71.19% Test: 83.78%\n",
      "Run: 08, Epoch: 32, Loss: 0.3584, Train: 79.31%, Valid: 76.27% Test: 86.49%\n",
      "Run: 08, Epoch: 33, Loss: 0.3966, Train: 86.21%, Valid: 81.36% Test: 86.49%\n",
      "Run: 08, Epoch: 34, Loss: 0.3449, Train: 85.06%, Valid: 81.36% Test: 86.49%\n",
      "Run: 08, Epoch: 35, Loss: 0.2973, Train: 88.51%, Valid: 81.36% Test: 86.49%\n",
      "Run: 08, Epoch: 36, Loss: 0.3197, Train: 87.36%, Valid: 83.05% Test: 86.49%\n",
      "Run: 08, Epoch: 37, Loss: 0.3332, Train: 90.80%, Valid: 86.44% Test: 86.49%\n",
      "Run: 08, Epoch: 38, Loss: 0.2824, Train: 86.21%, Valid: 89.83% Test: 83.78%\n",
      "Run: 08, Epoch: 39, Loss: 0.3155, Train: 77.01%, Valid: 84.75% Test: 83.78%\n",
      "Run: 08, Epoch: 40, Loss: 0.3050, Train: 79.31%, Valid: 84.75% Test: 83.78%\n",
      "Run: 08, Epoch: 41, Loss: 0.2222, Train: 80.46%, Valid: 88.14% Test: 83.78%\n",
      "Run: 08, Epoch: 42, Loss: 0.2599, Train: 83.91%, Valid: 88.14% Test: 83.78%\n",
      "Run: 08, Epoch: 43, Loss: 0.1830, Train: 82.76%, Valid: 88.14% Test: 83.78%\n",
      "Run: 08, Epoch: 44, Loss: 0.2562, Train: 80.46%, Valid: 86.44% Test: 86.49%\n",
      "Run: 08, Epoch: 45, Loss: 0.1932, Train: 79.31%, Valid: 83.05% Test: 86.49%\n",
      "Run: 08, Epoch: 46, Loss: 0.2384, Train: 77.01%, Valid: 77.97% Test: 86.49%\n",
      "Run: 08, Epoch: 47, Loss: 0.2270, Train: 75.86%, Valid: 79.66% Test: 83.78%\n",
      "Run: 08, Epoch: 48, Loss: 0.2577, Train: 82.76%, Valid: 81.36% Test: 83.78%\n",
      "Run: 08, Epoch: 49, Loss: 0.1786, Train: 87.36%, Valid: 84.75% Test: 83.78%\n",
      "Run: 08, Epoch: 50, Loss: 0.2647, Train: 90.80%, Valid: 83.05% Test: 86.49%\n",
      "Run: 08, Epoch: 51, Loss: 0.1438, Train: 90.80%, Valid: 84.75% Test: 86.49%\n",
      "Run: 08, Epoch: 52, Loss: 0.2150, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 08, Epoch: 53, Loss: 0.2861, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 08, Epoch: 54, Loss: 0.1663, Train: 95.40%, Valid: 86.44% Test: 86.49%\n",
      "Run: 08, Epoch: 55, Loss: 0.2750, Train: 95.40%, Valid: 91.53% Test: 89.19%\n",
      "Run: 08, Epoch: 56, Loss: 0.2132, Train: 95.40%, Valid: 91.53% Test: 94.59%\n",
      "Run: 08, Epoch: 57, Loss: 0.1844, Train: 95.40%, Valid: 91.53% Test: 94.59%\n",
      "Run: 08, Epoch: 58, Loss: 0.2377, Train: 93.10%, Valid: 91.53% Test: 94.59%\n",
      "Run: 08, Epoch: 59, Loss: 0.2605, Train: 93.10%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 60, Loss: 0.1666, Train: 94.25%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 61, Loss: 0.1930, Train: 93.10%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 62, Loss: 0.1923, Train: 89.66%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 63, Loss: 0.1353, Train: 86.21%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 64, Loss: 0.1969, Train: 87.36%, Valid: 86.44% Test: 89.19%\n",
      "Run: 08, Epoch: 65, Loss: 0.1827, Train: 86.21%, Valid: 86.44% Test: 89.19%\n",
      "Run: 08, Epoch: 66, Loss: 0.1264, Train: 88.51%, Valid: 88.14% Test: 86.49%\n",
      "Run: 08, Epoch: 67, Loss: 0.2254, Train: 94.25%, Valid: 88.14% Test: 89.19%\n",
      "Run: 08, Epoch: 68, Loss: 0.1828, Train: 94.25%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 69, Loss: 0.1970, Train: 94.25%, Valid: 89.83% Test: 89.19%\n",
      "Run: 08, Epoch: 70, Loss: 0.1636, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 08, Epoch: 71, Loss: 0.1504, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 08, Epoch: 72, Loss: 0.2354, Train: 95.40%, Valid: 88.14% Test: 89.19%\n",
      "Run: 08, Epoch: 73, Loss: 0.1293, Train: 95.40%, Valid: 86.44% Test: 89.19%\n",
      "Run: 08, Epoch: 74, Loss: 0.1909, Train: 94.25%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 75, Loss: 0.1573, Train: 93.10%, Valid: 81.36% Test: 91.89%\n",
      "Run: 08, Epoch: 76, Loss: 0.1168, Train: 89.66%, Valid: 81.36% Test: 89.19%\n",
      "Run: 08, Epoch: 77, Loss: 0.1355, Train: 89.66%, Valid: 84.75% Test: 89.19%\n",
      "Run: 08, Epoch: 78, Loss: 0.1344, Train: 91.95%, Valid: 84.75% Test: 91.89%\n",
      "Run: 08, Epoch: 79, Loss: 0.1755, Train: 90.80%, Valid: 86.44% Test: 89.19%\n",
      "Run: 08, Epoch: 80, Loss: 0.1053, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 81, Loss: 0.0767, Train: 96.55%, Valid: 94.92% Test: 91.89%\n",
      "Run: 08, Epoch: 82, Loss: 0.1018, Train: 97.70%, Valid: 94.92% Test: 94.59%\n",
      "Run: 08, Epoch: 83, Loss: 0.1241, Train: 97.70%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 84, Loss: 0.1121, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 85, Loss: 0.1420, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 86, Loss: 0.1657, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 87, Loss: 0.1814, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 88, Loss: 0.1722, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 89, Loss: 0.1144, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 08, Epoch: 90, Loss: 0.0841, Train: 98.85%, Valid: 91.53% Test: 94.59%\n",
      "Run: 08, Epoch: 91, Loss: 0.1284, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 08, Epoch: 92, Loss: 0.1315, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 08, Epoch: 93, Loss: 0.1250, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 08, Epoch: 94, Loss: 0.1194, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 08, Epoch: 95, Loss: 0.1158, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 08, Epoch: 96, Loss: 0.1276, Train: 97.70%, Valid: 91.53% Test: 97.30%\n",
      "Run: 08, Epoch: 97, Loss: 0.0950, Train: 96.55%, Valid: 86.44% Test: 97.30%\n",
      "Run: 08, Epoch: 98, Loss: 0.1106, Train: 96.55%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 99, Loss: 0.0676, Train: 96.55%, Valid: 84.75% Test: 89.19%\n",
      "Run: 08, Epoch: 100, Loss: 0.1077, Train: 96.55%, Valid: 86.44% Test: 89.19%\n",
      "Run 08:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 94.92\n",
      "  Final Train: 96.55\n",
      "   Final Test: 91.89\n",
      "Run: 09, Epoch: 01, Loss: 1.7160, Train: 17.24%, Valid: 16.95% Test: 21.62%\n",
      "Run: 09, Epoch: 02, Loss: 1.4351, Train: 24.14%, Valid: 23.73% Test: 24.32%\n",
      "Run: 09, Epoch: 03, Loss: 1.3532, Train: 25.29%, Valid: 38.98% Test: 32.43%\n",
      "Run: 09, Epoch: 04, Loss: 1.1540, Train: 21.84%, Valid: 30.51% Test: 32.43%\n",
      "Run: 09, Epoch: 05, Loss: 1.1352, Train: 36.78%, Valid: 35.59% Test: 32.43%\n",
      "Run: 09, Epoch: 06, Loss: 1.0321, Train: 74.71%, Valid: 61.02% Test: 64.86%\n",
      "Run: 09, Epoch: 07, Loss: 0.9631, Train: 70.11%, Valid: 64.41% Test: 75.68%\n",
      "Run: 09, Epoch: 08, Loss: 0.8822, Train: 67.82%, Valid: 59.32% Test: 72.97%\n",
      "Run: 09, Epoch: 09, Loss: 0.9190, Train: 66.67%, Valid: 59.32% Test: 75.68%\n",
      "Run: 09, Epoch: 10, Loss: 0.9016, Train: 66.67%, Valid: 59.32% Test: 72.97%\n",
      "Run: 09, Epoch: 11, Loss: 0.8621, Train: 64.37%, Valid: 57.63% Test: 72.97%\n",
      "Run: 09, Epoch: 12, Loss: 0.8143, Train: 64.37%, Valid: 57.63% Test: 67.57%\n",
      "Run: 09, Epoch: 13, Loss: 0.7278, Train: 65.52%, Valid: 57.63% Test: 64.86%\n",
      "Run: 09, Epoch: 14, Loss: 0.7654, Train: 65.52%, Valid: 59.32% Test: 64.86%\n",
      "Run: 09, Epoch: 15, Loss: 0.7132, Train: 64.37%, Valid: 59.32% Test: 67.57%\n",
      "Run: 09, Epoch: 16, Loss: 0.6881, Train: 64.37%, Valid: 61.02% Test: 67.57%\n",
      "Run: 09, Epoch: 17, Loss: 0.6774, Train: 63.22%, Valid: 61.02% Test: 64.86%\n",
      "Run: 09, Epoch: 18, Loss: 0.6463, Train: 63.22%, Valid: 61.02% Test: 64.86%\n",
      "Run: 09, Epoch: 19, Loss: 0.6834, Train: 63.22%, Valid: 61.02% Test: 64.86%\n",
      "Run: 09, Epoch: 20, Loss: 0.5758, Train: 65.52%, Valid: 62.71% Test: 67.57%\n",
      "Run: 09, Epoch: 21, Loss: 0.5808, Train: 67.82%, Valid: 62.71% Test: 70.27%\n",
      "Run: 09, Epoch: 22, Loss: 0.5823, Train: 68.97%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 23, Loss: 0.5416, Train: 71.26%, Valid: 67.80% Test: 78.38%\n",
      "Run: 09, Epoch: 24, Loss: 0.5580, Train: 72.41%, Valid: 67.80% Test: 78.38%\n",
      "Run: 09, Epoch: 25, Loss: 0.4722, Train: 77.01%, Valid: 67.80% Test: 78.38%\n",
      "Run: 09, Epoch: 26, Loss: 0.5098, Train: 78.16%, Valid: 67.80% Test: 78.38%\n",
      "Run: 09, Epoch: 27, Loss: 0.4671, Train: 79.31%, Valid: 67.80% Test: 81.08%\n",
      "Run: 09, Epoch: 28, Loss: 0.4525, Train: 81.61%, Valid: 72.88% Test: 81.08%\n",
      "Run: 09, Epoch: 29, Loss: 0.4434, Train: 82.76%, Valid: 69.49% Test: 83.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 30, Loss: 0.4454, Train: 81.61%, Valid: 71.19% Test: 83.78%\n",
      "Run: 09, Epoch: 31, Loss: 0.4429, Train: 80.46%, Valid: 72.88% Test: 83.78%\n",
      "Run: 09, Epoch: 32, Loss: 0.4442, Train: 82.76%, Valid: 72.88% Test: 83.78%\n",
      "Run: 09, Epoch: 33, Loss: 0.4128, Train: 80.46%, Valid: 74.58% Test: 83.78%\n",
      "Run: 09, Epoch: 34, Loss: 0.4176, Train: 79.31%, Valid: 74.58% Test: 83.78%\n",
      "Run: 09, Epoch: 35, Loss: 0.3388, Train: 79.31%, Valid: 74.58% Test: 83.78%\n",
      "Run: 09, Epoch: 36, Loss: 0.3010, Train: 81.61%, Valid: 74.58% Test: 83.78%\n",
      "Run: 09, Epoch: 37, Loss: 0.3246, Train: 85.06%, Valid: 74.58% Test: 83.78%\n",
      "Run: 09, Epoch: 38, Loss: 0.3635, Train: 88.51%, Valid: 77.97% Test: 86.49%\n",
      "Run: 09, Epoch: 39, Loss: 0.3054, Train: 91.95%, Valid: 77.97% Test: 83.78%\n",
      "Run: 09, Epoch: 40, Loss: 0.2907, Train: 94.25%, Valid: 81.36% Test: 83.78%\n",
      "Run: 09, Epoch: 41, Loss: 0.3363, Train: 94.25%, Valid: 79.66% Test: 86.49%\n",
      "Run: 09, Epoch: 42, Loss: 0.3433, Train: 93.10%, Valid: 81.36% Test: 89.19%\n",
      "Run: 09, Epoch: 43, Loss: 0.2418, Train: 91.95%, Valid: 81.36% Test: 89.19%\n",
      "Run: 09, Epoch: 44, Loss: 0.3180, Train: 93.10%, Valid: 81.36% Test: 86.49%\n",
      "Run: 09, Epoch: 45, Loss: 0.3048, Train: 95.40%, Valid: 81.36% Test: 86.49%\n",
      "Run: 09, Epoch: 46, Loss: 0.2889, Train: 94.25%, Valid: 81.36% Test: 86.49%\n",
      "Run: 09, Epoch: 47, Loss: 0.2522, Train: 93.10%, Valid: 81.36% Test: 83.78%\n",
      "Run: 09, Epoch: 48, Loss: 0.2391, Train: 93.10%, Valid: 83.05% Test: 86.49%\n",
      "Run: 09, Epoch: 49, Loss: 0.3119, Train: 90.80%, Valid: 83.05% Test: 86.49%\n",
      "Run: 09, Epoch: 50, Loss: 0.2032, Train: 90.80%, Valid: 83.05% Test: 86.49%\n",
      "Run: 09, Epoch: 51, Loss: 0.2025, Train: 90.80%, Valid: 83.05% Test: 83.78%\n",
      "Run: 09, Epoch: 52, Loss: 0.2071, Train: 88.51%, Valid: 83.05% Test: 83.78%\n",
      "Run: 09, Epoch: 53, Loss: 0.2434, Train: 88.51%, Valid: 81.36% Test: 86.49%\n",
      "Run: 09, Epoch: 54, Loss: 0.1976, Train: 89.66%, Valid: 81.36% Test: 86.49%\n",
      "Run: 09, Epoch: 55, Loss: 0.1929, Train: 91.95%, Valid: 81.36% Test: 86.49%\n",
      "Run: 09, Epoch: 56, Loss: 0.2238, Train: 91.95%, Valid: 81.36% Test: 86.49%\n",
      "Run: 09, Epoch: 57, Loss: 0.2290, Train: 91.95%, Valid: 84.75% Test: 86.49%\n",
      "Run: 09, Epoch: 58, Loss: 0.2961, Train: 91.95%, Valid: 84.75% Test: 86.49%\n",
      "Run: 09, Epoch: 59, Loss: 0.2405, Train: 94.25%, Valid: 84.75% Test: 89.19%\n",
      "Run: 09, Epoch: 60, Loss: 0.1790, Train: 94.25%, Valid: 86.44% Test: 89.19%\n",
      "Run: 09, Epoch: 61, Loss: 0.2196, Train: 91.95%, Valid: 84.75% Test: 83.78%\n",
      "Run: 09, Epoch: 62, Loss: 0.1847, Train: 91.95%, Valid: 84.75% Test: 86.49%\n",
      "Run: 09, Epoch: 63, Loss: 0.1643, Train: 94.25%, Valid: 86.44% Test: 89.19%\n",
      "Run: 09, Epoch: 64, Loss: 0.1616, Train: 94.25%, Valid: 86.44% Test: 89.19%\n",
      "Run: 09, Epoch: 65, Loss: 0.2474, Train: 98.85%, Valid: 88.14% Test: 89.19%\n",
      "Run: 09, Epoch: 66, Loss: 0.2119, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 09, Epoch: 67, Loss: 0.1679, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 09, Epoch: 68, Loss: 0.2147, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 09, Epoch: 69, Loss: 0.1877, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 09, Epoch: 70, Loss: 0.1628, Train: 97.70%, Valid: 93.22% Test: 91.89%\n",
      "Run: 09, Epoch: 71, Loss: 0.1192, Train: 96.55%, Valid: 91.53% Test: 89.19%\n",
      "Run: 09, Epoch: 72, Loss: 0.1681, Train: 96.55%, Valid: 91.53% Test: 89.19%\n",
      "Run: 09, Epoch: 73, Loss: 0.2037, Train: 96.55%, Valid: 91.53% Test: 89.19%\n",
      "Run: 09, Epoch: 74, Loss: 0.1906, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 75, Loss: 0.1391, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 76, Loss: 0.1539, Train: 91.95%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 77, Loss: 0.1061, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 09, Epoch: 78, Loss: 0.1163, Train: 90.80%, Valid: 84.75% Test: 83.78%\n",
      "Run: 09, Epoch: 79, Loss: 0.1664, Train: 95.40%, Valid: 89.83% Test: 83.78%\n",
      "Run: 09, Epoch: 80, Loss: 0.1804, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 81, Loss: 0.1266, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 09, Epoch: 82, Loss: 0.1809, Train: 97.70%, Valid: 93.22% Test: 91.89%\n",
      "Run: 09, Epoch: 83, Loss: 0.1637, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 09, Epoch: 84, Loss: 0.1250, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 09, Epoch: 85, Loss: 0.1433, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 09, Epoch: 86, Loss: 0.0843, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 09, Epoch: 87, Loss: 0.1138, Train: 98.85%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 88, Loss: 0.1256, Train: 97.70%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 89, Loss: 0.1188, Train: 97.70%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 90, Loss: 0.1105, Train: 95.40%, Valid: 88.14% Test: 86.49%\n",
      "Run: 09, Epoch: 91, Loss: 0.1404, Train: 91.95%, Valid: 88.14% Test: 86.49%\n",
      "Run: 09, Epoch: 92, Loss: 0.1212, Train: 91.95%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 93, Loss: 0.1207, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 94, Loss: 0.0895, Train: 94.25%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 95, Loss: 0.0825, Train: 94.25%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 96, Loss: 0.1202, Train: 94.25%, Valid: 86.44% Test: 89.19%\n",
      "Run: 09, Epoch: 97, Loss: 0.1116, Train: 98.85%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 98, Loss: 0.1012, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 09, Epoch: 99, Loss: 0.1270, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 09, Epoch: 100, Loss: 0.1349, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run 09:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 93.22\n",
      "  Final Train: 97.70\n",
      "   Final Test: 91.89\n",
      "Run: 10, Epoch: 01, Loss: 1.6386, Train: 59.77%, Valid: 47.46% Test: 62.16%\n",
      "Run: 10, Epoch: 02, Loss: 1.2085, Train: 60.92%, Valid: 49.15% Test: 64.86%\n",
      "Run: 10, Epoch: 03, Loss: 1.2281, Train: 59.77%, Valid: 54.24% Test: 62.16%\n",
      "Run: 10, Epoch: 04, Loss: 1.0341, Train: 48.28%, Valid: 40.68% Test: 40.54%\n",
      "Run: 10, Epoch: 05, Loss: 1.0607, Train: 55.17%, Valid: 50.85% Test: 59.46%\n",
      "Run: 10, Epoch: 06, Loss: 0.9012, Train: 63.22%, Valid: 61.02% Test: 62.16%\n",
      "Run: 10, Epoch: 07, Loss: 0.8261, Train: 63.22%, Valid: 69.49% Test: 78.38%\n",
      "Run: 10, Epoch: 08, Loss: 0.8711, Train: 72.41%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 09, Loss: 0.8948, Train: 73.56%, Valid: 62.71% Test: 72.97%\n",
      "Run: 10, Epoch: 10, Loss: 0.7886, Train: 73.56%, Valid: 57.63% Test: 70.27%\n",
      "Run: 10, Epoch: 11, Loss: 0.8005, Train: 68.97%, Valid: 61.02% Test: 67.57%\n",
      "Run: 10, Epoch: 12, Loss: 0.7458, Train: 64.37%, Valid: 55.93% Test: 67.57%\n",
      "Run: 10, Epoch: 13, Loss: 0.7179, Train: 65.52%, Valid: 54.24% Test: 67.57%\n",
      "Run: 10, Epoch: 14, Loss: 0.6781, Train: 65.52%, Valid: 57.63% Test: 67.57%\n",
      "Run: 10, Epoch: 15, Loss: 0.6243, Train: 71.26%, Valid: 55.93% Test: 70.27%\n",
      "Run: 10, Epoch: 16, Loss: 0.6374, Train: 71.26%, Valid: 55.93% Test: 70.27%\n",
      "Run: 10, Epoch: 17, Loss: 0.5237, Train: 70.11%, Valid: 57.63% Test: 70.27%\n",
      "Run: 10, Epoch: 18, Loss: 0.6080, Train: 68.97%, Valid: 55.93% Test: 67.57%\n",
      "Run: 10, Epoch: 19, Loss: 0.5231, Train: 70.11%, Valid: 55.93% Test: 67.57%\n",
      "Run: 10, Epoch: 20, Loss: 0.5454, Train: 70.11%, Valid: 59.32% Test: 67.57%\n",
      "Run: 10, Epoch: 21, Loss: 0.6299, Train: 74.71%, Valid: 67.80% Test: 75.68%\n",
      "Run: 10, Epoch: 22, Loss: 0.5240, Train: 78.16%, Valid: 67.80% Test: 75.68%\n",
      "Run: 10, Epoch: 23, Loss: 0.5223, Train: 80.46%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 24, Loss: 0.4679, Train: 80.46%, Valid: 66.10% Test: 75.68%\n",
      "Run: 10, Epoch: 25, Loss: 0.4361, Train: 80.46%, Valid: 67.80% Test: 78.38%\n",
      "Run: 10, Epoch: 26, Loss: 0.3728, Train: 82.76%, Valid: 67.80% Test: 78.38%\n",
      "Run: 10, Epoch: 27, Loss: 0.4043, Train: 83.91%, Valid: 69.49% Test: 81.08%\n",
      "Run: 10, Epoch: 28, Loss: 0.4034, Train: 86.21%, Valid: 71.19% Test: 81.08%\n",
      "Run: 10, Epoch: 29, Loss: 0.3809, Train: 88.51%, Valid: 71.19% Test: 81.08%\n",
      "Run: 10, Epoch: 30, Loss: 0.3924, Train: 88.51%, Valid: 71.19% Test: 81.08%\n",
      "Run: 10, Epoch: 31, Loss: 0.4057, Train: 88.51%, Valid: 76.27% Test: 81.08%\n",
      "Run: 10, Epoch: 32, Loss: 0.3280, Train: 91.95%, Valid: 76.27% Test: 78.38%\n",
      "Run: 10, Epoch: 33, Loss: 0.3823, Train: 93.10%, Valid: 79.66% Test: 78.38%\n",
      "Run: 10, Epoch: 34, Loss: 0.2669, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 10, Epoch: 35, Loss: 0.3771, Train: 91.95%, Valid: 77.97% Test: 81.08%\n",
      "Run: 10, Epoch: 36, Loss: 0.2625, Train: 85.06%, Valid: 76.27% Test: 78.38%\n",
      "Run: 10, Epoch: 37, Loss: 0.2686, Train: 83.91%, Valid: 74.58% Test: 78.38%\n",
      "Run: 10, Epoch: 38, Loss: 0.3859, Train: 85.06%, Valid: 74.58% Test: 78.38%\n",
      "Run: 10, Epoch: 39, Loss: 0.3171, Train: 85.06%, Valid: 74.58% Test: 78.38%\n",
      "Run: 10, Epoch: 40, Loss: 0.2692, Train: 85.06%, Valid: 76.27% Test: 78.38%\n",
      "Run: 10, Epoch: 41, Loss: 0.2903, Train: 87.36%, Valid: 79.66% Test: 78.38%\n",
      "Run: 10, Epoch: 42, Loss: 0.3690, Train: 91.95%, Valid: 77.97% Test: 78.38%\n",
      "Run: 10, Epoch: 43, Loss: 0.2448, Train: 94.25%, Valid: 77.97% Test: 78.38%\n",
      "Run: 10, Epoch: 44, Loss: 0.3266, Train: 94.25%, Valid: 77.97% Test: 78.38%\n",
      "Run: 10, Epoch: 45, Loss: 0.2998, Train: 94.25%, Valid: 77.97% Test: 81.08%\n",
      "Run: 10, Epoch: 46, Loss: 0.2038, Train: 93.10%, Valid: 76.27% Test: 81.08%\n",
      "Run: 10, Epoch: 47, Loss: 0.2782, Train: 91.95%, Valid: 76.27% Test: 81.08%\n",
      "Run: 10, Epoch: 48, Loss: 0.2164, Train: 88.51%, Valid: 74.58% Test: 81.08%\n",
      "Run: 10, Epoch: 49, Loss: 0.1974, Train: 86.21%, Valid: 71.19% Test: 81.08%\n",
      "Run: 10, Epoch: 50, Loss: 0.1631, Train: 87.36%, Valid: 72.88% Test: 81.08%\n",
      "Run: 10, Epoch: 51, Loss: 0.2299, Train: 90.80%, Valid: 72.88% Test: 81.08%\n",
      "Run: 10, Epoch: 52, Loss: 0.2259, Train: 93.10%, Valid: 81.36% Test: 81.08%\n",
      "Run: 10, Epoch: 53, Loss: 0.2458, Train: 95.40%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 54, Loss: 0.1736, Train: 95.40%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 55, Loss: 0.2003, Train: 94.25%, Valid: 83.05% Test: 89.19%\n",
      "Run: 10, Epoch: 56, Loss: 0.1951, Train: 94.25%, Valid: 83.05% Test: 89.19%\n",
      "Run: 10, Epoch: 57, Loss: 0.1416, Train: 93.10%, Valid: 79.66% Test: 86.49%\n",
      "Run: 10, Epoch: 58, Loss: 0.2076, Train: 94.25%, Valid: 76.27% Test: 86.49%\n",
      "Run: 10, Epoch: 59, Loss: 0.1846, Train: 91.95%, Valid: 76.27% Test: 86.49%\n",
      "Run: 10, Epoch: 60, Loss: 0.1744, Train: 90.80%, Valid: 74.58% Test: 78.38%\n",
      "Run: 10, Epoch: 61, Loss: 0.1496, Train: 88.51%, Valid: 76.27% Test: 78.38%\n",
      "Run: 10, Epoch: 62, Loss: 0.1916, Train: 87.36%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 63, Loss: 0.2054, Train: 90.80%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 64, Loss: 0.1388, Train: 90.80%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 65, Loss: 0.1530, Train: 91.95%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 66, Loss: 0.1066, Train: 93.10%, Valid: 72.88% Test: 78.38%\n",
      "Run: 10, Epoch: 67, Loss: 0.1243, Train: 91.95%, Valid: 72.88% Test: 78.38%\n",
      "Run: 10, Epoch: 68, Loss: 0.1124, Train: 93.10%, Valid: 76.27% Test: 78.38%\n",
      "Run: 10, Epoch: 69, Loss: 0.2042, Train: 91.95%, Valid: 76.27% Test: 81.08%\n",
      "Run: 10, Epoch: 70, Loss: 0.1567, Train: 91.95%, Valid: 72.88% Test: 78.38%\n",
      "Run: 10, Epoch: 71, Loss: 0.1352, Train: 90.80%, Valid: 74.58% Test: 78.38%\n",
      "Run: 10, Epoch: 72, Loss: 0.1005, Train: 93.10%, Valid: 74.58% Test: 78.38%\n",
      "Run: 10, Epoch: 73, Loss: 0.1385, Train: 93.10%, Valid: 72.88% Test: 78.38%\n",
      "Run: 10, Epoch: 74, Loss: 0.1607, Train: 89.66%, Valid: 72.88% Test: 78.38%\n",
      "Run: 10, Epoch: 75, Loss: 0.1840, Train: 90.80%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 76, Loss: 0.1206, Train: 90.80%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 77, Loss: 0.1740, Train: 89.66%, Valid: 72.88% Test: 78.38%\n",
      "Run: 10, Epoch: 78, Loss: 0.1093, Train: 90.80%, Valid: 74.58% Test: 78.38%\n",
      "Run: 10, Epoch: 79, Loss: 0.1043, Train: 88.51%, Valid: 72.88% Test: 78.38%\n",
      "Run: 10, Epoch: 80, Loss: 0.1462, Train: 86.21%, Valid: 72.88% Test: 78.38%\n",
      "Run: 10, Epoch: 81, Loss: 0.1337, Train: 86.21%, Valid: 74.58% Test: 78.38%\n",
      "Run: 10, Epoch: 82, Loss: 0.1981, Train: 87.36%, Valid: 77.97% Test: 78.38%\n",
      "Run: 10, Epoch: 83, Loss: 0.1370, Train: 87.36%, Valid: 76.27% Test: 78.38%\n",
      "Run: 10, Epoch: 84, Loss: 0.1062, Train: 86.21%, Valid: 74.58% Test: 78.38%\n",
      "Run: 10, Epoch: 85, Loss: 0.1012, Train: 88.51%, Valid: 76.27% Test: 78.38%\n",
      "Run: 10, Epoch: 86, Loss: 0.1144, Train: 90.80%, Valid: 81.36% Test: 78.38%\n",
      "Run: 10, Epoch: 87, Loss: 0.0912, Train: 94.25%, Valid: 81.36% Test: 78.38%\n",
      "Run: 10, Epoch: 88, Loss: 0.1348, Train: 94.25%, Valid: 83.05% Test: 81.08%\n",
      "Run: 10, Epoch: 89, Loss: 0.0998, Train: 94.25%, Valid: 83.05% Test: 81.08%\n",
      "Run: 10, Epoch: 90, Loss: 0.1290, Train: 93.10%, Valid: 77.97% Test: 78.38%\n",
      "Run: 10, Epoch: 91, Loss: 0.0608, Train: 93.10%, Valid: 77.97% Test: 78.38%\n",
      "Run: 10, Epoch: 92, Loss: 0.0557, Train: 93.10%, Valid: 77.97% Test: 81.08%\n",
      "Run: 10, Epoch: 93, Loss: 0.1602, Train: 93.10%, Valid: 77.97% Test: 81.08%\n",
      "Run: 10, Epoch: 94, Loss: 0.0825, Train: 94.25%, Valid: 77.97% Test: 81.08%\n",
      "Run: 10, Epoch: 95, Loss: 0.0627, Train: 94.25%, Valid: 79.66% Test: 81.08%\n",
      "Run: 10, Epoch: 96, Loss: 0.0618, Train: 91.95%, Valid: 77.97% Test: 81.08%\n",
      "Run: 10, Epoch: 97, Loss: 0.0711, Train: 95.40%, Valid: 81.36% Test: 83.78%\n",
      "Run: 10, Epoch: 98, Loss: 0.0533, Train: 95.40%, Valid: 83.05% Test: 81.08%\n",
      "Run: 10, Epoch: 99, Loss: 0.0551, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 10, Epoch: 100, Loss: 0.1051, Train: 90.80%, Valid: 76.27% Test: 78.38%\n",
      "Run 10:\n",
      "Highest Train: 95.40\n",
      "Highest Valid: 83.05\n",
      "  Final Train: 95.40\n",
      "   Final Test: 86.49\n",
      "All runs:\n",
      "Highest Train: 98.85 ± 1.33\n",
      "Highest Valid: 94.24 ± 4.24\n",
      "  Final Train: 97.82 ± 1.48\n",
      "   Final Test: 88.38 ± 4.42\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 32, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-6, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = WebKB(root='/tmp/Texas', name='Texas',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    #idx_train=[data.train_mask[i][0] for i in range(len(data.y))]\n",
    "    #train_idx = np.where(idx_train)[0]\n",
    "    #idx_val=[data.val_mask[i][0] for i in range(len(data.y))]\n",
    "    #valid_idx = np.where(idx_val)[0]\n",
    "    #idx_test=[data.test_mask[i][0] for i in range(len(data.y))]\n",
    "    #test_idx = np.where(idx_test)[0]\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085c7fd",
   "metadata": {},
   "source": [
    "# Topological ENCODDING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e47b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], edge_index=[2, 325], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Texas', name='Texas')\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607be4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1   2   4   4   4   7   7  10  11  11  13  13  15  15  15  15\n",
      "   15  17  18  20  20  20  20  23  23  25  25  28  28  29  29  29  30  30\n",
      "   34  34  34  36  36  39  40  41  41  41  41  42  42  44  45  45  46  47\n",
      "   47  50  50  50  51  53  54  55  56  56  56  56  56  56  56  56  56  56\n",
      "   56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56\n",
      "   56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56\n",
      "   56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56\n",
      "   56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56\n",
      "   56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56  56\n",
      "   56  56  56  56  57  57  57  57  57  57  57  58  58  58  58  58  59  59\n",
      "   60  60  61  63  64  66  67  70  72  73  73  73  74  74  75  78  78  79\n",
      "   80  81  82  82  82  82  83  83  83  84  84  84  84  84  84  84  84  85\n",
      "   86  87  88  89  90  90  92  95  95  95  95  95  99  99  99 100 101 102\n",
      "  102 102 105 106 107 108 108 108 111 114 116 117 119 120 120 122 123 125\n",
      "  126 126 126 127 127 127 127 127 127 127 127 130 131 131 131 131 131 133\n",
      "  133 133 133 134 139 140 140 140 141 141 144 145 148 148 148 151 151 151\n",
      "  156 158 159 159 159 160 161 162 162 163 163 164 168 171 171 171 171 171\n",
      "  172 173 173 173 173 173 173 173 174 175 176 177 177 177 180 180 180 180\n",
      "  182]\n",
      " [ 58 121  80   8  66 146 164  14  34 108  94 108  13  58  15  16  22  65\n",
      "  165  29 126   5  15  16 115 127 147  84 167  80 146  17  97 162 146 159\n",
      "   34  66  84  21  60 140  24  66  84 104 118  34  93 159  45 108  95  84\n",
      "  180  34  68 150 116  71 125 116   3   5   6   9  11  12  16  17  19  21\n",
      "   22  23  24  26  27  29  30  31  32  33  34  35  37  38  39  41  43  44\n",
      "   46  47  49  52  53  54  55  57  59  61  62  63  64  65  68  69  74  75\n",
      "   77  79  80  81  82  84  85  87  89  90  91  93  94  97  98 103 104 109\n",
      "  110 112 116 117 118 119 124 125 127 128 129 131 132 134 135 136 137 139\n",
      "  142 143 144 146 147 149 150 153 154 155 159 161 165 166 167 169 170 171\n",
      "  172 178 179 181  15  22  65  67 110 165 170  13  88 102 119 163  16 159\n",
      "   16  21  84  58  82  86  67 147 108  66  73 158  22  48 116  34 146  82\n",
      "   66  58  64  79 133 144  37  39 140  23  31  34  47  62 127 147 153  16\n",
      "   86 116 102 151  90 140  15  46  66  76  95 157  79  94 132 131   5  58\n",
      "   66 102 144   9 108  11  45  72  85  49  76 146  58 140 156 167  16  54\n",
      "   16  18  29  23  31  55  62  84 129 153 171  24  66  84 100 138 168  16\n",
      "   64  82 178 134  18  39  83  90  48 116  82 168 146 148 159  66  89 152\n",
      "  156  73  44  59 150 116 116  29  66  58 163 146 131   6  66  84 113 129\n",
      "  113   8  55  84  96 131 145 175  15 175  80  84 156 167  47  66  84 180\n",
      "   29]]\n"
     ]
    }
   ],
   "source": [
    "print(data.edge_index.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52514bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_nodes=len(data.y)\n",
    "Edge_idx=data.edge_index.numpy()\n",
    "Node=range(Number_nodes)\n",
    "Edgelist=[]\n",
    "for i in range(len(Edge_idx[1])):\n",
    "    Edgelist.append((Edge_idx[0][i],Edge_idx[1][i]))\n",
    "#print(Edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f9d236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a \"plain\" graph is undirected\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# give each a node a 'name', which is a letter in this case.\n",
    "#G.add_node('a')\n",
    "\n",
    "# the add_nodes_from method allows adding nodes from a sequence, in this case a list\n",
    "#nodes_to_add = ['b', 'c', 'd']\n",
    "G.add_nodes_from(Node)\n",
    "\n",
    "# add edge from 'a' to 'b'\n",
    "# since this graph is undirected, the order doesn't matter here\n",
    "#G.add_edge('a', 'b')\n",
    "\n",
    "# just like add_nodes_from, we can add edges from a sequence\n",
    "# edges should be specified as 2-tuples\n",
    "#edges_to_add = [('a', 'c'), ('b', 'c'), ('c', 'd')]\n",
    "G.add_edges_from(Edgelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "781abc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    }
   ],
   "source": [
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77abd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topological_Feature_subLevel(adj,filtration_fun, Filtration):\n",
    "        betti_0=[]\n",
    "        betti_1=[]\n",
    "        for p in range(len(Filtration)):\n",
    "            n_active = np.where(np.array(filtration_fun) <= Filtration[p])[0].tolist()\n",
    "            Active_node=np.unique(n_active)\n",
    "            if (len(Active_node)==0):\n",
    "                betti_0.append(0)\n",
    "                betti_1.append(0)\n",
    "            else:\n",
    "                b=adj[Active_node,:][:,Active_node]\n",
    "                my_flag=pyflagser.flagser_unweighted(b, min_dimension=0, max_dimension=2, directed=False, coeff=2, approximation=None)\n",
    "                x = my_flag[\"betti\"]\n",
    "                betti_0.append(x[0])\n",
    "                betti_1.append(x[1])\n",
    "            n_active.clear()\n",
    "        return betti_0,betti_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e40cacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Degree_list(Graph):\n",
    "    degree_list = [Graph.degree(node) for node in Graph.nodes]\n",
    "    return np.array(degree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "118b65fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  |  60 \n",
      "\n",
      "2  |  42 \n",
      "\n",
      "3  |  33 \n",
      "\n",
      "4  |  19 \n",
      "\n",
      "5  |  7 \n",
      "\n",
      "6  |  2 \n",
      "\n",
      "7  |  4 \n",
      "\n",
      "8  |  5 \n",
      "\n",
      "9  |  4 \n",
      "\n",
      "10  |  2 \n",
      "\n",
      "11  |  1 \n",
      "\n",
      "12  |  1 \n",
      "\n",
      "13  |  1 \n",
      "\n",
      "20  |  1 \n",
      "\n",
      "104  |  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "degree_list=Degree_list(G)\n",
    "unique_list=np.unique(degree_list)\n",
    "for d in unique_list:\n",
    "    count=0\n",
    "    for i in range(len(degree_list)):\n",
    "        if degree_list[i]==d:\n",
    "            count=count+1\n",
    "    print(int(d),\" | \",count,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7080881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 182 (100%)"
     ]
    }
   ],
   "source": [
    "import pyflagser\n",
    "Node_fil=[1,2,3,4,5,6,7,8,9,10,20,100]\n",
    "topo_betti_0=[]\n",
    "topo_betti_1=[]\n",
    "Node_Edge=[]\n",
    "for i in range(Number_nodes):\n",
    "    print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//(Number_nodes-1)), end='', flush=True)\n",
    "    subgraph=ego_graph(G, i, radius=2, center=True, undirected=True, distance=None)\n",
    "    filt=Degree_list(subgraph)\n",
    "    A_sub = nx.to_numpy_array(subgraph)# adjacency matrix of subgraph\n",
    "    fe=Topological_Feature_subLevel(A_sub,filt,Node_fil)\n",
    "    topo_betti_0.append(fe[0])\n",
    "    topo_betti_1.append(fe[1])\n",
    "    Node_Edge.append([subgraph.number_of_nodes(),subgraph.number_of_edges()])\n",
    "    #topo_with_NE.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49a08a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=325])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Texas', name='Texas',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "445f9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_betti0=torch.tensor(topo_betti_0).float()\n",
    "topo_betti1=torch.tensor(topo_betti_1).float()\n",
    "NodeEdge=torch.tensor(Node_Edge).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbeea52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 10], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=325], topo=[183, 24])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "topo_fe=torch.cat((topo_betti0,topo_betti1),1)\n",
    "data.topo=topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2734f",
   "metadata": {},
   "source": [
    "# TOPO-W-GSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd4668e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "        #return x.log_softmax(dim=-1)\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        #return torch.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "class MLP2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP2, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp2(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "    \n",
    "\n",
    "def train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2):\n",
    "    model.train()\n",
    "    mlp_model.train()\n",
    "    mlp_2.train()\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_mlp.zero_grad()\n",
    "    optimizer_mlp2.zero_grad()\n",
    "    gcn_embedding = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(gcn_embedding)\n",
    "    mlp_embedding = mlp_model(data.topo[train_idx])\n",
    "    #print(mlp_embedding)\n",
    "    combined_embedding = torch.cat((gcn_embedding, mlp_embedding), dim=1)\n",
    "    #print(combined_embedding)\n",
    "    mlp_emb = mlp_2(combined_embedding)\n",
    "    #print(mlp_emb)\n",
    "    loss = F.nll_loss(mlp_emb, data.y.squeeze()[train_idx])\n",
    "    #loss = F.nll_loss(combined_embedding, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer_mlp2.step()\n",
    "    optimizer.step()\n",
    "    optimizer_mlp.step()\n",
    "    \n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "    mlp_model.eval()\n",
    "    mlp_2.eval()\n",
    "\n",
    "    gcn_out = model(data.x, data.adj_t)\n",
    "    #print(gcn_out[0])\n",
    "    mlp_out=mlp_model(data.topo)\n",
    "    #print(mlp_out)\n",
    "    #out=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    Com=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    out=mlp_2(Com)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    #print(y_pred[0])\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef21f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x1674d6530>\n",
      "Run: 01, Epoch: 01, Loss: 1.6149, Train: 48.28%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 02, Loss: 1.5501, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 03, Loss: 1.4962, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 04, Loss: 1.4376, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 05, Loss: 1.4008, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 06, Loss: 1.3555, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 07, Loss: 1.2673, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 08, Loss: 1.2453, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 09, Loss: 1.1866, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 10, Loss: 1.1425, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 11, Loss: 1.1071, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 12, Loss: 1.0309, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 13, Loss: 1.0598, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 14, Loss: 0.9995, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 15, Loss: 0.9589, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 16, Loss: 0.9053, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 17, Loss: 0.9314, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 18, Loss: 0.8968, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 19, Loss: 0.8573, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 20, Loss: 0.7706, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 21, Loss: 0.7590, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 22, Loss: 0.7664, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 23, Loss: 0.8114, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 24, Loss: 0.7767, Train: 55.17%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 25, Loss: 0.7088, Train: 55.17%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 26, Loss: 0.7715, Train: 57.47%, Valid: 54.24% Test: 67.57%\n",
      "Run: 01, Epoch: 27, Loss: 0.7897, Train: 58.62%, Valid: 54.24% Test: 67.57%\n",
      "Run: 01, Epoch: 28, Loss: 0.6655, Train: 58.62%, Valid: 54.24% Test: 70.27%\n",
      "Run: 01, Epoch: 29, Loss: 0.7613, Train: 58.62%, Valid: 54.24% Test: 70.27%\n",
      "Run: 01, Epoch: 30, Loss: 0.6735, Train: 58.62%, Valid: 52.54% Test: 70.27%\n",
      "Run: 01, Epoch: 31, Loss: 0.6893, Train: 56.32%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 32, Loss: 0.6576, Train: 57.47%, Valid: 52.54% Test: 67.57%\n",
      "Run: 01, Epoch: 33, Loss: 0.6594, Train: 60.92%, Valid: 52.54% Test: 70.27%\n",
      "Run: 01, Epoch: 34, Loss: 0.6776, Train: 65.52%, Valid: 55.93% Test: 72.97%\n",
      "Run: 01, Epoch: 35, Loss: 0.6695, Train: 66.67%, Valid: 55.93% Test: 75.68%\n",
      "Run: 01, Epoch: 36, Loss: 0.6541, Train: 66.67%, Valid: 54.24% Test: 75.68%\n",
      "Run: 01, Epoch: 37, Loss: 0.6256, Train: 65.52%, Valid: 55.93% Test: 75.68%\n",
      "Run: 01, Epoch: 38, Loss: 0.6425, Train: 68.97%, Valid: 59.32% Test: 75.68%\n",
      "Run: 01, Epoch: 39, Loss: 0.5883, Train: 72.41%, Valid: 61.02% Test: 75.68%\n",
      "Run: 01, Epoch: 40, Loss: 0.6183, Train: 70.11%, Valid: 61.02% Test: 75.68%\n",
      "Run: 01, Epoch: 41, Loss: 0.6139, Train: 68.97%, Valid: 64.41% Test: 75.68%\n",
      "Run: 01, Epoch: 42, Loss: 0.6361, Train: 66.67%, Valid: 62.71% Test: 70.27%\n",
      "Run: 01, Epoch: 43, Loss: 0.6000, Train: 64.37%, Valid: 62.71% Test: 70.27%\n",
      "Run: 01, Epoch: 44, Loss: 0.6232, Train: 67.82%, Valid: 62.71% Test: 70.27%\n",
      "Run: 01, Epoch: 45, Loss: 0.6313, Train: 70.11%, Valid: 62.71% Test: 70.27%\n",
      "Run: 01, Epoch: 46, Loss: 0.5219, Train: 67.82%, Valid: 62.71% Test: 72.97%\n",
      "Run: 01, Epoch: 47, Loss: 0.5530, Train: 68.97%, Valid: 64.41% Test: 78.38%\n",
      "Run: 01, Epoch: 48, Loss: 0.5432, Train: 66.67%, Valid: 64.41% Test: 78.38%\n",
      "Run: 01, Epoch: 49, Loss: 0.5537, Train: 66.67%, Valid: 64.41% Test: 75.68%\n",
      "Run: 01, Epoch: 50, Loss: 0.5453, Train: 62.07%, Valid: 55.93% Test: 75.68%\n",
      "Run: 01, Epoch: 51, Loss: 0.5606, Train: 64.37%, Valid: 59.32% Test: 75.68%\n",
      "Run: 01, Epoch: 52, Loss: 0.4864, Train: 63.22%, Valid: 59.32% Test: 72.97%\n",
      "Run: 01, Epoch: 53, Loss: 0.5387, Train: 59.77%, Valid: 59.32% Test: 72.97%\n",
      "Run: 01, Epoch: 54, Loss: 0.5509, Train: 60.92%, Valid: 61.02% Test: 72.97%\n",
      "Run: 01, Epoch: 55, Loss: 0.4925, Train: 66.67%, Valid: 66.10% Test: 81.08%\n",
      "Run: 01, Epoch: 56, Loss: 0.5203, Train: 67.82%, Valid: 66.10% Test: 81.08%\n",
      "Run: 01, Epoch: 57, Loss: 0.5275, Train: 73.56%, Valid: 69.49% Test: 81.08%\n",
      "Run: 01, Epoch: 58, Loss: 0.5274, Train: 81.61%, Valid: 72.88% Test: 86.49%\n",
      "Run: 01, Epoch: 59, Loss: 0.5262, Train: 91.95%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 60, Loss: 0.4625, Train: 91.95%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 61, Loss: 0.4982, Train: 87.36%, Valid: 77.97% Test: 91.89%\n",
      "Run: 01, Epoch: 62, Loss: 0.4448, Train: 82.76%, Valid: 76.27% Test: 86.49%\n",
      "Run: 01, Epoch: 63, Loss: 0.4539, Train: 72.41%, Valid: 72.88% Test: 86.49%\n",
      "Run: 01, Epoch: 64, Loss: 0.5046, Train: 63.22%, Valid: 62.71% Test: 75.68%\n",
      "Run: 01, Epoch: 65, Loss: 0.4921, Train: 63.22%, Valid: 64.41% Test: 81.08%\n",
      "Run: 01, Epoch: 66, Loss: 0.5033, Train: 70.11%, Valid: 71.19% Test: 83.78%\n",
      "Run: 01, Epoch: 67, Loss: 0.4836, Train: 88.51%, Valid: 81.36% Test: 83.78%\n",
      "Run: 01, Epoch: 68, Loss: 0.4696, Train: 96.55%, Valid: 88.14% Test: 89.19%\n",
      "Run: 01, Epoch: 69, Loss: 0.4706, Train: 95.40%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 70, Loss: 0.4700, Train: 88.51%, Valid: 86.44% Test: 89.19%\n",
      "Run: 01, Epoch: 71, Loss: 0.4273, Train: 87.36%, Valid: 83.05% Test: 89.19%\n",
      "Run: 01, Epoch: 72, Loss: 0.4592, Train: 87.36%, Valid: 79.66% Test: 89.19%\n",
      "Run: 01, Epoch: 73, Loss: 0.4726, Train: 88.51%, Valid: 79.66% Test: 89.19%\n",
      "Run: 01, Epoch: 74, Loss: 0.4303, Train: 88.51%, Valid: 84.75% Test: 83.78%\n",
      "Run: 01, Epoch: 75, Loss: 0.4160, Train: 89.66%, Valid: 91.53% Test: 83.78%\n",
      "Run: 01, Epoch: 76, Loss: 0.3659, Train: 88.51%, Valid: 89.83% Test: 83.78%\n",
      "Run: 01, Epoch: 77, Loss: 0.3875, Train: 85.06%, Valid: 88.14% Test: 81.08%\n",
      "Run: 01, Epoch: 78, Loss: 0.4138, Train: 87.36%, Valid: 88.14% Test: 83.78%\n",
      "Run: 01, Epoch: 79, Loss: 0.3852, Train: 90.80%, Valid: 93.22% Test: 86.49%\n",
      "Run: 01, Epoch: 80, Loss: 0.3980, Train: 90.80%, Valid: 93.22% Test: 89.19%\n",
      "Run: 01, Epoch: 81, Loss: 0.4006, Train: 90.80%, Valid: 93.22% Test: 89.19%\n",
      "Run: 01, Epoch: 82, Loss: 0.4151, Train: 91.95%, Valid: 91.53% Test: 86.49%\n",
      "Run: 01, Epoch: 83, Loss: 0.4177, Train: 91.95%, Valid: 89.83% Test: 89.19%\n",
      "Run: 01, Epoch: 84, Loss: 0.4251, Train: 93.10%, Valid: 89.83% Test: 89.19%\n",
      "Run: 01, Epoch: 85, Loss: 0.3728, Train: 95.40%, Valid: 89.83% Test: 89.19%\n",
      "Run: 01, Epoch: 86, Loss: 0.3875, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 01, Epoch: 87, Loss: 0.3211, Train: 96.55%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 88, Loss: 0.4056, Train: 96.55%, Valid: 88.14% Test: 89.19%\n",
      "Run: 01, Epoch: 89, Loss: 0.3642, Train: 95.40%, Valid: 88.14% Test: 89.19%\n",
      "Run: 01, Epoch: 90, Loss: 0.3501, Train: 95.40%, Valid: 88.14% Test: 89.19%\n",
      "Run: 01, Epoch: 91, Loss: 0.3887, Train: 96.55%, Valid: 91.53% Test: 86.49%\n",
      "Run: 01, Epoch: 92, Loss: 0.3907, Train: 93.10%, Valid: 88.14% Test: 89.19%\n",
      "Run: 01, Epoch: 93, Loss: 0.3778, Train: 88.51%, Valid: 88.14% Test: 89.19%\n",
      "Run: 01, Epoch: 94, Loss: 0.3295, Train: 87.36%, Valid: 84.75% Test: 89.19%\n",
      "Run: 01, Epoch: 95, Loss: 0.3623, Train: 89.66%, Valid: 84.75% Test: 89.19%\n",
      "Run: 01, Epoch: 96, Loss: 0.3258, Train: 89.66%, Valid: 84.75% Test: 91.89%\n",
      "Run: 01, Epoch: 97, Loss: 0.3178, Train: 91.95%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 98, Loss: 0.3207, Train: 91.95%, Valid: 88.14% Test: 91.89%\n",
      "Run: 01, Epoch: 99, Loss: 0.3442, Train: 93.10%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 100, Loss: 0.3534, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 101, Loss: 0.3336, Train: 97.70%, Valid: 91.53% Test: 89.19%\n",
      "Run: 01, Epoch: 102, Loss: 0.2936, Train: 96.55%, Valid: 93.22% Test: 91.89%\n",
      "Run: 01, Epoch: 103, Loss: 0.3189, Train: 96.55%, Valid: 93.22% Test: 91.89%\n",
      "Run: 01, Epoch: 104, Loss: 0.3120, Train: 97.70%, Valid: 93.22% Test: 91.89%\n",
      "Run: 01, Epoch: 105, Loss: 0.3479, Train: 97.70%, Valid: 93.22% Test: 94.59%\n",
      "Run: 01, Epoch: 106, Loss: 0.3176, Train: 97.70%, Valid: 94.92% Test: 91.89%\n",
      "Run: 01, Epoch: 107, Loss: 0.2763, Train: 97.70%, Valid: 94.92% Test: 89.19%\n",
      "Run: 01, Epoch: 108, Loss: 0.3006, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 01, Epoch: 109, Loss: 0.3256, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 01, Epoch: 110, Loss: 0.3283, Train: 97.70%, Valid: 93.22% Test: 91.89%\n",
      "Run: 01, Epoch: 111, Loss: 0.3509, Train: 95.40%, Valid: 91.53% Test: 94.59%\n",
      "Run: 01, Epoch: 112, Loss: 0.3049, Train: 90.80%, Valid: 79.66% Test: 94.59%\n",
      "Run: 01, Epoch: 113, Loss: 0.3145, Train: 87.36%, Valid: 76.27% Test: 91.89%\n",
      "Run: 01, Epoch: 114, Loss: 0.3264, Train: 86.21%, Valid: 72.88% Test: 89.19%\n",
      "Run: 01, Epoch: 115, Loss: 0.2690, Train: 91.95%, Valid: 76.27% Test: 89.19%\n",
      "Run: 01, Epoch: 116, Loss: 0.2517, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 01, Epoch: 117, Loss: 0.2923, Train: 100.00%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 118, Loss: 0.2790, Train: 100.00%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 119, Loss: 0.2564, Train: 100.00%, Valid: 89.83% Test: 91.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 120, Loss: 0.2435, Train: 100.00%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 121, Loss: 0.2742, Train: 100.00%, Valid: 91.53% Test: 89.19%\n",
      "Run: 01, Epoch: 122, Loss: 0.3262, Train: 100.00%, Valid: 91.53% Test: 89.19%\n",
      "Run: 01, Epoch: 123, Loss: 0.2966, Train: 100.00%, Valid: 93.22% Test: 91.89%\n",
      "Run: 01, Epoch: 124, Loss: 0.2764, Train: 100.00%, Valid: 93.22% Test: 94.59%\n",
      "Run: 01, Epoch: 125, Loss: 0.2114, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 01, Epoch: 126, Loss: 0.2392, Train: 100.00%, Valid: 96.61% Test: 94.59%\n",
      "Run: 01, Epoch: 127, Loss: 0.2815, Train: 100.00%, Valid: 96.61% Test: 91.89%\n",
      "Run: 01, Epoch: 128, Loss: 0.2748, Train: 100.00%, Valid: 96.61% Test: 94.59%\n",
      "Run: 01, Epoch: 129, Loss: 0.2534, Train: 100.00%, Valid: 96.61% Test: 94.59%\n",
      "Run: 01, Epoch: 130, Loss: 0.2218, Train: 97.70%, Valid: 94.92% Test: 94.59%\n",
      "Run: 01, Epoch: 131, Loss: 0.2516, Train: 96.55%, Valid: 94.92% Test: 97.30%\n",
      "Run: 01, Epoch: 132, Loss: 0.2053, Train: 96.55%, Valid: 93.22% Test: 97.30%\n",
      "Run: 01, Epoch: 133, Loss: 0.2416, Train: 95.40%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 134, Loss: 0.2191, Train: 94.25%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 135, Loss: 0.2391, Train: 94.25%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 136, Loss: 0.2149, Train: 94.25%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 137, Loss: 0.2650, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 138, Loss: 0.2245, Train: 100.00%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 139, Loss: 0.2826, Train: 100.00%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 140, Loss: 0.3098, Train: 100.00%, Valid: 93.22% Test: 94.59%\n",
      "Run: 01, Epoch: 141, Loss: 0.2928, Train: 100.00%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 142, Loss: 0.2539, Train: 100.00%, Valid: 88.14% Test: 94.59%\n",
      "Run: 01, Epoch: 143, Loss: 0.2161, Train: 97.70%, Valid: 88.14% Test: 94.59%\n",
      "Run: 01, Epoch: 144, Loss: 0.2407, Train: 100.00%, Valid: 88.14% Test: 91.89%\n",
      "Run: 01, Epoch: 145, Loss: 0.2089, Train: 100.00%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 146, Loss: 0.2092, Train: 100.00%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 147, Loss: 0.2005, Train: 100.00%, Valid: 88.14% Test: 91.89%\n",
      "Run: 01, Epoch: 148, Loss: 0.2619, Train: 100.00%, Valid: 88.14% Test: 91.89%\n",
      "Run: 01, Epoch: 149, Loss: 0.2015, Train: 100.00%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 150, Loss: 0.2013, Train: 100.00%, Valid: 91.53% Test: 94.59%\n",
      "Run: 01, Epoch: 151, Loss: 0.1812, Train: 100.00%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 152, Loss: 0.2420, Train: 100.00%, Valid: 93.22% Test: 97.30%\n",
      "Run: 01, Epoch: 153, Loss: 0.1851, Train: 100.00%, Valid: 93.22% Test: 97.30%\n",
      "Run: 01, Epoch: 154, Loss: 0.1983, Train: 100.00%, Valid: 93.22% Test: 97.30%\n",
      "Run: 01, Epoch: 155, Loss: 0.1998, Train: 100.00%, Valid: 93.22% Test: 97.30%\n",
      "Run: 01, Epoch: 156, Loss: 0.2582, Train: 100.00%, Valid: 93.22% Test: 97.30%\n",
      "Run: 01, Epoch: 157, Loss: 0.2253, Train: 100.00%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 158, Loss: 0.2218, Train: 100.00%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 159, Loss: 0.2072, Train: 100.00%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 160, Loss: 0.2521, Train: 100.00%, Valid: 91.53% Test: 91.89%\n",
      "Run: 01, Epoch: 161, Loss: 0.1666, Train: 100.00%, Valid: 96.61% Test: 94.59%\n",
      "Run: 01, Epoch: 162, Loss: 0.1746, Train: 100.00%, Valid: 96.61% Test: 91.89%\n",
      "Run: 01, Epoch: 163, Loss: 0.2275, Train: 100.00%, Valid: 94.92% Test: 91.89%\n",
      "Run: 01, Epoch: 164, Loss: 0.1664, Train: 100.00%, Valid: 96.61% Test: 91.89%\n",
      "Run: 01, Epoch: 165, Loss: 0.1986, Train: 100.00%, Valid: 96.61% Test: 94.59%\n",
      "Run: 01, Epoch: 166, Loss: 0.2139, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 01, Epoch: 167, Loss: 0.1823, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 01, Epoch: 168, Loss: 0.2106, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 01, Epoch: 169, Loss: 0.2471, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 01, Epoch: 170, Loss: 0.2067, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 01, Epoch: 171, Loss: 0.1393, Train: 96.55%, Valid: 93.22% Test: 89.19%\n",
      "Run: 01, Epoch: 172, Loss: 0.2132, Train: 95.40%, Valid: 94.92% Test: 89.19%\n",
      "Run: 01, Epoch: 173, Loss: 0.2083, Train: 95.40%, Valid: 94.92% Test: 91.89%\n",
      "Run: 01, Epoch: 174, Loss: 0.2412, Train: 97.70%, Valid: 89.83% Test: 91.89%\n",
      "Run: 01, Epoch: 175, Loss: 0.1963, Train: 98.85%, Valid: 88.14% Test: 91.89%\n",
      "Run: 01, Epoch: 176, Loss: 0.1561, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 177, Loss: 0.1908, Train: 100.00%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 178, Loss: 0.1838, Train: 100.00%, Valid: 93.22% Test: 97.30%\n",
      "Run: 01, Epoch: 179, Loss: 0.1788, Train: 100.00%, Valid: 93.22% Test: 94.59%\n",
      "Run: 01, Epoch: 180, Loss: 0.1834, Train: 100.00%, Valid: 93.22% Test: 94.59%\n",
      "Run: 01, Epoch: 181, Loss: 0.1811, Train: 100.00%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 182, Loss: 0.2523, Train: 100.00%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 183, Loss: 0.1508, Train: 100.00%, Valid: 91.53% Test: 94.59%\n",
      "Run: 01, Epoch: 184, Loss: 0.1987, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 01, Epoch: 185, Loss: 0.1679, Train: 98.85%, Valid: 93.22% Test: 97.30%\n",
      "Run: 01, Epoch: 186, Loss: 0.1900, Train: 98.85%, Valid: 96.61% Test: 97.30%\n",
      "Run: 01, Epoch: 187, Loss: 0.1790, Train: 98.85%, Valid: 96.61% Test: 94.59%\n",
      "Run: 01, Epoch: 188, Loss: 0.1854, Train: 100.00%, Valid: 96.61% Test: 100.00%\n",
      "Run: 01, Epoch: 189, Loss: 0.1793, Train: 100.00%, Valid: 96.61% Test: 94.59%\n",
      "Run: 01, Epoch: 190, Loss: 0.1723, Train: 100.00%, Valid: 93.22% Test: 94.59%\n",
      "Run: 01, Epoch: 191, Loss: 0.1460, Train: 100.00%, Valid: 93.22% Test: 94.59%\n",
      "Run: 01, Epoch: 192, Loss: 0.1556, Train: 100.00%, Valid: 91.53% Test: 94.59%\n",
      "Run: 01, Epoch: 193, Loss: 0.2399, Train: 100.00%, Valid: 91.53% Test: 94.59%\n",
      "Run: 01, Epoch: 194, Loss: 0.1843, Train: 97.70%, Valid: 91.53% Test: 94.59%\n",
      "Run: 01, Epoch: 195, Loss: 0.1423, Train: 96.55%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 196, Loss: 0.1923, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 197, Loss: 0.1441, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 198, Loss: 0.2238, Train: 97.70%, Valid: 88.14% Test: 94.59%\n",
      "Run: 01, Epoch: 199, Loss: 0.1334, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 01, Epoch: 200, Loss: 0.1788, Train: 100.00%, Valid: 91.53% Test: 94.59%\n",
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 96.61\n",
      "  Final Train: 100.00\n",
      "   Final Test: 94.59\n",
      "Run: 02, Epoch: 01, Loss: 1.8630, Train: 0.00%, Valid: 1.69% Test: 0.00%\n",
      "Run: 02, Epoch: 02, Loss: 1.7932, Train: 0.00%, Valid: 1.69% Test: 0.00%\n",
      "Run: 02, Epoch: 03, Loss: 1.7356, Train: 0.00%, Valid: 1.69% Test: 0.00%\n",
      "Run: 02, Epoch: 04, Loss: 1.6610, Train: 0.00%, Valid: 1.69% Test: 0.00%\n",
      "Run: 02, Epoch: 05, Loss: 1.5971, Train: 0.00%, Valid: 1.69% Test: 0.00%\n",
      "Run: 02, Epoch: 06, Loss: 1.5346, Train: 14.94%, Valid: 10.17% Test: 13.51%\n",
      "Run: 02, Epoch: 07, Loss: 1.4956, Train: 21.84%, Valid: 11.86% Test: 18.92%\n",
      "Run: 02, Epoch: 08, Loss: 1.4137, Train: 21.84%, Valid: 11.86% Test: 18.92%\n",
      "Run: 02, Epoch: 09, Loss: 1.3667, Train: 40.23%, Valid: 33.90% Test: 43.24%\n",
      "Run: 02, Epoch: 10, Loss: 1.3208, Train: 66.67%, Valid: 62.71% Test: 72.97%\n",
      "Run: 02, Epoch: 11, Loss: 1.2757, Train: 68.97%, Valid: 61.02% Test: 72.97%\n",
      "Run: 02, Epoch: 12, Loss: 1.2222, Train: 67.82%, Valid: 61.02% Test: 75.68%\n",
      "Run: 02, Epoch: 13, Loss: 1.1659, Train: 70.11%, Valid: 59.32% Test: 75.68%\n",
      "Run: 02, Epoch: 14, Loss: 1.1465, Train: 68.97%, Valid: 59.32% Test: 75.68%\n",
      "Run: 02, Epoch: 15, Loss: 1.1042, Train: 68.97%, Valid: 59.32% Test: 70.27%\n",
      "Run: 02, Epoch: 16, Loss: 1.0757, Train: 62.07%, Valid: 59.32% Test: 70.27%\n",
      "Run: 02, Epoch: 17, Loss: 1.0591, Train: 62.07%, Valid: 57.63% Test: 70.27%\n",
      "Run: 02, Epoch: 18, Loss: 0.9935, Train: 54.02%, Valid: 57.63% Test: 70.27%\n",
      "Run: 02, Epoch: 19, Loss: 0.9813, Train: 56.32%, Valid: 57.63% Test: 70.27%\n",
      "Run: 02, Epoch: 20, Loss: 0.9513, Train: 62.07%, Valid: 59.32% Test: 70.27%\n",
      "Run: 02, Epoch: 21, Loss: 0.9346, Train: 62.07%, Valid: 57.63% Test: 70.27%\n",
      "Run: 02, Epoch: 22, Loss: 0.9098, Train: 64.37%, Valid: 59.32% Test: 70.27%\n",
      "Run: 02, Epoch: 23, Loss: 0.9228, Train: 67.82%, Valid: 61.02% Test: 70.27%\n",
      "Run: 02, Epoch: 24, Loss: 0.8596, Train: 65.52%, Valid: 61.02% Test: 70.27%\n",
      "Run: 02, Epoch: 25, Loss: 0.8383, Train: 62.07%, Valid: 59.32% Test: 70.27%\n",
      "Run: 02, Epoch: 26, Loss: 0.8314, Train: 62.07%, Valid: 59.32% Test: 70.27%\n",
      "Run: 02, Epoch: 27, Loss: 0.8488, Train: 65.52%, Valid: 61.02% Test: 70.27%\n",
      "Run: 02, Epoch: 28, Loss: 0.8052, Train: 66.67%, Valid: 61.02% Test: 70.27%\n",
      "Run: 02, Epoch: 29, Loss: 0.7818, Train: 67.82%, Valid: 61.02% Test: 70.27%\n",
      "Run: 02, Epoch: 30, Loss: 0.7580, Train: 68.97%, Valid: 61.02% Test: 72.97%\n",
      "Run: 02, Epoch: 31, Loss: 0.7200, Train: 67.82%, Valid: 59.32% Test: 72.97%\n",
      "Run: 02, Epoch: 32, Loss: 0.7305, Train: 67.82%, Valid: 59.32% Test: 72.97%\n",
      "Run: 02, Epoch: 33, Loss: 0.7433, Train: 67.82%, Valid: 59.32% Test: 72.97%\n",
      "Run: 02, Epoch: 34, Loss: 0.6960, Train: 67.82%, Valid: 59.32% Test: 72.97%\n",
      "Run: 02, Epoch: 35, Loss: 0.7164, Train: 68.97%, Valid: 62.71% Test: 72.97%\n",
      "Run: 02, Epoch: 36, Loss: 0.6775, Train: 71.26%, Valid: 62.71% Test: 72.97%\n",
      "Run: 02, Epoch: 37, Loss: 0.7174, Train: 74.71%, Valid: 61.02% Test: 72.97%\n",
      "Run: 02, Epoch: 38, Loss: 0.7176, Train: 77.01%, Valid: 64.41% Test: 72.97%\n",
      "Run: 02, Epoch: 39, Loss: 0.6619, Train: 75.86%, Valid: 64.41% Test: 75.68%\n",
      "Run: 02, Epoch: 40, Loss: 0.6628, Train: 75.86%, Valid: 64.41% Test: 75.68%\n",
      "Run: 02, Epoch: 41, Loss: 0.6900, Train: 74.71%, Valid: 64.41% Test: 75.68%\n",
      "Run: 02, Epoch: 42, Loss: 0.6706, Train: 74.71%, Valid: 66.10% Test: 75.68%\n",
      "Run: 02, Epoch: 43, Loss: 0.6590, Train: 74.71%, Valid: 67.80% Test: 75.68%\n",
      "Run: 02, Epoch: 44, Loss: 0.6643, Train: 74.71%, Valid: 67.80% Test: 75.68%\n",
      "Run: 02, Epoch: 45, Loss: 0.6925, Train: 75.86%, Valid: 67.80% Test: 75.68%\n",
      "Run: 02, Epoch: 46, Loss: 0.6583, Train: 80.46%, Valid: 69.49% Test: 81.08%\n",
      "Run: 02, Epoch: 47, Loss: 0.6220, Train: 79.31%, Valid: 69.49% Test: 81.08%\n",
      "Run: 02, Epoch: 48, Loss: 0.6236, Train: 78.16%, Valid: 67.80% Test: 83.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 49, Loss: 0.5821, Train: 79.31%, Valid: 67.80% Test: 75.68%\n",
      "Run: 02, Epoch: 50, Loss: 0.6255, Train: 73.56%, Valid: 64.41% Test: 75.68%\n",
      "Run: 02, Epoch: 51, Loss: 0.6046, Train: 73.56%, Valid: 66.10% Test: 72.97%\n",
      "Run: 02, Epoch: 52, Loss: 0.5852, Train: 73.56%, Valid: 66.10% Test: 72.97%\n",
      "Run: 02, Epoch: 53, Loss: 0.5619, Train: 74.71%, Valid: 66.10% Test: 72.97%\n",
      "Run: 02, Epoch: 54, Loss: 0.5634, Train: 72.41%, Valid: 66.10% Test: 72.97%\n",
      "Run: 02, Epoch: 55, Loss: 0.5762, Train: 77.01%, Valid: 67.80% Test: 72.97%\n",
      "Run: 02, Epoch: 56, Loss: 0.5655, Train: 78.16%, Valid: 67.80% Test: 75.68%\n",
      "Run: 02, Epoch: 57, Loss: 0.5512, Train: 79.31%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 58, Loss: 0.5571, Train: 78.16%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 59, Loss: 0.5576, Train: 79.31%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 60, Loss: 0.5436, Train: 79.31%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 61, Loss: 0.5074, Train: 80.46%, Valid: 69.49% Test: 78.38%\n",
      "Run: 02, Epoch: 62, Loss: 0.5694, Train: 80.46%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 63, Loss: 0.5006, Train: 79.31%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 64, Loss: 0.5507, Train: 82.76%, Valid: 69.49% Test: 78.38%\n",
      "Run: 02, Epoch: 65, Loss: 0.5283, Train: 81.61%, Valid: 74.58% Test: 83.78%\n",
      "Run: 02, Epoch: 66, Loss: 0.5280, Train: 82.76%, Valid: 71.19% Test: 83.78%\n",
      "Run: 02, Epoch: 67, Loss: 0.5233, Train: 82.76%, Valid: 72.88% Test: 78.38%\n",
      "Run: 02, Epoch: 68, Loss: 0.5220, Train: 78.16%, Valid: 71.19% Test: 78.38%\n",
      "Run: 02, Epoch: 69, Loss: 0.5064, Train: 74.71%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 70, Loss: 0.4933, Train: 74.71%, Valid: 67.80% Test: 75.68%\n",
      "Run: 02, Epoch: 71, Loss: 0.5018, Train: 74.71%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 72, Loss: 0.4863, Train: 79.31%, Valid: 69.49% Test: 78.38%\n",
      "Run: 02, Epoch: 73, Loss: 0.5227, Train: 82.76%, Valid: 72.88% Test: 83.78%\n",
      "Run: 02, Epoch: 74, Loss: 0.4811, Train: 88.51%, Valid: 79.66% Test: 83.78%\n",
      "Run: 02, Epoch: 75, Loss: 0.4213, Train: 88.51%, Valid: 83.05% Test: 81.08%\n",
      "Run: 02, Epoch: 76, Loss: 0.4782, Train: 87.36%, Valid: 81.36% Test: 83.78%\n",
      "Run: 02, Epoch: 77, Loss: 0.4817, Train: 85.06%, Valid: 83.05% Test: 83.78%\n",
      "Run: 02, Epoch: 78, Loss: 0.4815, Train: 87.36%, Valid: 84.75% Test: 81.08%\n",
      "Run: 02, Epoch: 79, Loss: 0.4684, Train: 83.91%, Valid: 84.75% Test: 78.38%\n",
      "Run: 02, Epoch: 80, Loss: 0.5016, Train: 78.16%, Valid: 81.36% Test: 78.38%\n",
      "Run: 02, Epoch: 81, Loss: 0.4449, Train: 74.71%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 82, Loss: 0.4388, Train: 74.71%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 83, Loss: 0.4110, Train: 75.86%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 84, Loss: 0.4688, Train: 75.86%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 85, Loss: 0.3761, Train: 78.16%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 86, Loss: 0.4331, Train: 80.46%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 87, Loss: 0.4587, Train: 82.76%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 88, Loss: 0.4399, Train: 86.21%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 89, Loss: 0.3752, Train: 86.21%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 90, Loss: 0.3797, Train: 86.21%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 91, Loss: 0.4263, Train: 88.51%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 92, Loss: 0.3838, Train: 90.80%, Valid: 77.97% Test: 81.08%\n",
      "Run: 02, Epoch: 93, Loss: 0.4274, Train: 91.95%, Valid: 76.27% Test: 83.78%\n",
      "Run: 02, Epoch: 94, Loss: 0.3905, Train: 91.95%, Valid: 81.36% Test: 83.78%\n",
      "Run: 02, Epoch: 95, Loss: 0.4118, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 96, Loss: 0.4095, Train: 93.10%, Valid: 84.75% Test: 83.78%\n",
      "Run: 02, Epoch: 97, Loss: 0.4159, Train: 93.10%, Valid: 91.53% Test: 83.78%\n",
      "Run: 02, Epoch: 98, Loss: 0.4594, Train: 94.25%, Valid: 93.22% Test: 81.08%\n",
      "Run: 02, Epoch: 99, Loss: 0.3879, Train: 93.10%, Valid: 89.83% Test: 81.08%\n",
      "Run: 02, Epoch: 100, Loss: 0.3429, Train: 93.10%, Valid: 89.83% Test: 81.08%\n",
      "Run: 02, Epoch: 101, Loss: 0.3560, Train: 90.80%, Valid: 89.83% Test: 81.08%\n",
      "Run: 02, Epoch: 102, Loss: 0.4121, Train: 88.51%, Valid: 89.83% Test: 81.08%\n",
      "Run: 02, Epoch: 103, Loss: 0.3893, Train: 87.36%, Valid: 88.14% Test: 81.08%\n",
      "Run: 02, Epoch: 104, Loss: 0.3798, Train: 82.76%, Valid: 88.14% Test: 81.08%\n",
      "Run: 02, Epoch: 105, Loss: 0.3717, Train: 85.06%, Valid: 86.44% Test: 81.08%\n",
      "Run: 02, Epoch: 106, Loss: 0.3583, Train: 86.21%, Valid: 88.14% Test: 81.08%\n",
      "Run: 02, Epoch: 107, Loss: 0.3624, Train: 89.66%, Valid: 86.44% Test: 81.08%\n",
      "Run: 02, Epoch: 108, Loss: 0.3395, Train: 91.95%, Valid: 89.83% Test: 83.78%\n",
      "Run: 02, Epoch: 109, Loss: 0.3917, Train: 93.10%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 110, Loss: 0.3616, Train: 93.10%, Valid: 81.36% Test: 83.78%\n",
      "Run: 02, Epoch: 111, Loss: 0.4219, Train: 93.10%, Valid: 81.36% Test: 83.78%\n",
      "Run: 02, Epoch: 112, Loss: 0.2894, Train: 91.95%, Valid: 83.05% Test: 83.78%\n",
      "Run: 02, Epoch: 113, Loss: 0.4011, Train: 90.80%, Valid: 81.36% Test: 89.19%\n",
      "Run: 02, Epoch: 114, Loss: 0.3499, Train: 91.95%, Valid: 83.05% Test: 86.49%\n",
      "Run: 02, Epoch: 115, Loss: 0.3128, Train: 89.66%, Valid: 81.36% Test: 89.19%\n",
      "Run: 02, Epoch: 116, Loss: 0.3285, Train: 91.95%, Valid: 86.44% Test: 89.19%\n",
      "Run: 02, Epoch: 117, Loss: 0.3640, Train: 93.10%, Valid: 89.83% Test: 89.19%\n",
      "Run: 02, Epoch: 118, Loss: 0.3158, Train: 93.10%, Valid: 91.53% Test: 89.19%\n",
      "Run: 02, Epoch: 119, Loss: 0.3670, Train: 95.40%, Valid: 86.44% Test: 83.78%\n",
      "Run: 02, Epoch: 120, Loss: 0.3783, Train: 94.25%, Valid: 88.14% Test: 83.78%\n",
      "Run: 02, Epoch: 121, Loss: 0.3677, Train: 90.80%, Valid: 88.14% Test: 81.08%\n",
      "Run: 02, Epoch: 122, Loss: 0.3589, Train: 90.80%, Valid: 84.75% Test: 81.08%\n",
      "Run: 02, Epoch: 123, Loss: 0.2873, Train: 87.36%, Valid: 83.05% Test: 81.08%\n",
      "Run: 02, Epoch: 124, Loss: 0.3270, Train: 88.51%, Valid: 84.75% Test: 81.08%\n",
      "Run: 02, Epoch: 125, Loss: 0.3698, Train: 93.10%, Valid: 86.44% Test: 81.08%\n",
      "Run: 02, Epoch: 126, Loss: 0.3148, Train: 96.55%, Valid: 91.53% Test: 83.78%\n",
      "Run: 02, Epoch: 127, Loss: 0.3165, Train: 96.55%, Valid: 94.92% Test: 83.78%\n",
      "Run: 02, Epoch: 128, Loss: 0.2990, Train: 95.40%, Valid: 96.61% Test: 89.19%\n",
      "Run: 02, Epoch: 129, Loss: 0.3497, Train: 94.25%, Valid: 96.61% Test: 89.19%\n",
      "Run: 02, Epoch: 130, Loss: 0.3182, Train: 95.40%, Valid: 96.61% Test: 94.59%\n",
      "Run: 02, Epoch: 131, Loss: 0.2996, Train: 95.40%, Valid: 96.61% Test: 94.59%\n",
      "Run: 02, Epoch: 132, Loss: 0.2926, Train: 93.10%, Valid: 96.61% Test: 94.59%\n",
      "Run: 02, Epoch: 133, Loss: 0.2967, Train: 91.95%, Valid: 93.22% Test: 91.89%\n",
      "Run: 02, Epoch: 134, Loss: 0.2945, Train: 93.10%, Valid: 91.53% Test: 91.89%\n",
      "Run: 02, Epoch: 135, Loss: 0.3135, Train: 91.95%, Valid: 89.83% Test: 91.89%\n",
      "Run: 02, Epoch: 136, Loss: 0.2939, Train: 91.95%, Valid: 91.53% Test: 91.89%\n",
      "Run: 02, Epoch: 137, Loss: 0.3394, Train: 91.95%, Valid: 94.92% Test: 89.19%\n",
      "Run: 02, Epoch: 138, Loss: 0.2800, Train: 91.95%, Valid: 94.92% Test: 89.19%\n",
      "Run: 02, Epoch: 139, Loss: 0.3010, Train: 93.10%, Valid: 96.61% Test: 89.19%\n",
      "Run: 02, Epoch: 140, Loss: 0.2676, Train: 95.40%, Valid: 94.92% Test: 89.19%\n",
      "Run: 02, Epoch: 141, Loss: 0.2737, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 02, Epoch: 142, Loss: 0.2739, Train: 98.85%, Valid: 96.61% Test: 86.49%\n",
      "Run: 02, Epoch: 143, Loss: 0.3393, Train: 97.70%, Valid: 98.31% Test: 86.49%\n",
      "Run: 02, Epoch: 144, Loss: 0.2662, Train: 97.70%, Valid: 96.61% Test: 86.49%\n",
      "Run: 02, Epoch: 145, Loss: 0.2564, Train: 96.55%, Valid: 94.92% Test: 86.49%\n",
      "Run: 02, Epoch: 146, Loss: 0.2974, Train: 96.55%, Valid: 94.92% Test: 86.49%\n",
      "Run: 02, Epoch: 147, Loss: 0.2775, Train: 96.55%, Valid: 94.92% Test: 86.49%\n",
      "Run: 02, Epoch: 148, Loss: 0.2971, Train: 97.70%, Valid: 91.53% Test: 83.78%\n",
      "Run: 02, Epoch: 149, Loss: 0.3269, Train: 97.70%, Valid: 88.14% Test: 83.78%\n",
      "Run: 02, Epoch: 150, Loss: 0.2234, Train: 97.70%, Valid: 88.14% Test: 83.78%\n",
      "Run: 02, Epoch: 151, Loss: 0.3087, Train: 97.70%, Valid: 88.14% Test: 86.49%\n",
      "Run: 02, Epoch: 152, Loss: 0.2520, Train: 96.55%, Valid: 88.14% Test: 86.49%\n",
      "Run: 02, Epoch: 153, Loss: 0.2777, Train: 96.55%, Valid: 88.14% Test: 86.49%\n",
      "Run: 02, Epoch: 154, Loss: 0.2642, Train: 95.40%, Valid: 86.44% Test: 89.19%\n",
      "Run: 02, Epoch: 155, Loss: 0.2721, Train: 93.10%, Valid: 88.14% Test: 89.19%\n",
      "Run: 02, Epoch: 156, Loss: 0.2473, Train: 91.95%, Valid: 89.83% Test: 89.19%\n",
      "Run: 02, Epoch: 157, Loss: 0.2928, Train: 91.95%, Valid: 93.22% Test: 86.49%\n",
      "Run: 02, Epoch: 158, Loss: 0.2500, Train: 91.95%, Valid: 88.14% Test: 89.19%\n",
      "Run: 02, Epoch: 159, Loss: 0.2280, Train: 93.10%, Valid: 86.44% Test: 89.19%\n",
      "Run: 02, Epoch: 160, Loss: 0.2571, Train: 94.25%, Valid: 86.44% Test: 94.59%\n",
      "Run: 02, Epoch: 161, Loss: 0.2504, Train: 96.55%, Valid: 94.92% Test: 97.30%\n",
      "Run: 02, Epoch: 162, Loss: 0.2289, Train: 98.85%, Valid: 96.61% Test: 97.30%\n",
      "Run: 02, Epoch: 163, Loss: 0.2577, Train: 98.85%, Valid: 96.61% Test: 97.30%\n",
      "Run: 02, Epoch: 164, Loss: 0.2224, Train: 100.00%, Valid: 96.61% Test: 94.59%\n",
      "Run: 02, Epoch: 165, Loss: 0.2632, Train: 98.85%, Valid: 96.61% Test: 91.89%\n",
      "Run: 02, Epoch: 166, Loss: 0.2269, Train: 97.70%, Valid: 96.61% Test: 89.19%\n",
      "Run: 02, Epoch: 167, Loss: 0.2925, Train: 95.40%, Valid: 96.61% Test: 91.89%\n",
      "Run: 02, Epoch: 168, Loss: 0.2279, Train: 94.25%, Valid: 96.61% Test: 91.89%\n",
      "Run: 02, Epoch: 169, Loss: 0.2347, Train: 95.40%, Valid: 96.61% Test: 91.89%\n",
      "Run: 02, Epoch: 170, Loss: 0.2493, Train: 95.40%, Valid: 94.92% Test: 91.89%\n",
      "Run: 02, Epoch: 171, Loss: 0.2813, Train: 96.55%, Valid: 96.61% Test: 97.30%\n",
      "Run: 02, Epoch: 172, Loss: 0.2856, Train: 98.85%, Valid: 96.61% Test: 97.30%\n",
      "Run: 02, Epoch: 173, Loss: 0.3250, Train: 98.85%, Valid: 96.61% Test: 97.30%\n",
      "Run: 02, Epoch: 174, Loss: 0.3415, Train: 98.85%, Valid: 96.61% Test: 100.00%\n",
      "Run: 02, Epoch: 175, Loss: 0.2983, Train: 98.85%, Valid: 96.61% Test: 94.59%\n",
      "Run: 02, Epoch: 176, Loss: 0.2446, Train: 98.85%, Valid: 96.61% Test: 94.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 177, Loss: 0.2187, Train: 98.85%, Valid: 96.61% Test: 91.89%\n",
      "Run: 02, Epoch: 178, Loss: 0.2560, Train: 100.00%, Valid: 96.61% Test: 91.89%\n",
      "Run: 02, Epoch: 179, Loss: 0.2505, Train: 98.85%, Valid: 96.61% Test: 91.89%\n",
      "Run: 02, Epoch: 180, Loss: 0.2800, Train: 100.00%, Valid: 96.61% Test: 89.19%\n",
      "Run: 02, Epoch: 181, Loss: 0.2469, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 02, Epoch: 182, Loss: 0.2015, Train: 98.85%, Valid: 89.83% Test: 86.49%\n",
      "Run: 02, Epoch: 183, Loss: 0.2390, Train: 98.85%, Valid: 91.53% Test: 86.49%\n",
      "Run: 02, Epoch: 184, Loss: 0.2786, Train: 96.55%, Valid: 89.83% Test: 86.49%\n",
      "Run: 02, Epoch: 185, Loss: 0.2757, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 02, Epoch: 186, Loss: 0.2882, Train: 96.55%, Valid: 91.53% Test: 89.19%\n",
      "Run: 02, Epoch: 187, Loss: 0.2960, Train: 97.70%, Valid: 98.31% Test: 86.49%\n",
      "Run: 02, Epoch: 188, Loss: 0.2221, Train: 96.55%, Valid: 98.31% Test: 86.49%\n",
      "Run: 02, Epoch: 189, Loss: 0.2067, Train: 96.55%, Valid: 98.31% Test: 86.49%\n",
      "Run: 02, Epoch: 190, Loss: 0.2603, Train: 96.55%, Valid: 98.31% Test: 83.78%\n",
      "Run: 02, Epoch: 191, Loss: 0.2377, Train: 97.70%, Valid: 98.31% Test: 83.78%\n",
      "Run: 02, Epoch: 192, Loss: 0.2633, Train: 96.55%, Valid: 98.31% Test: 83.78%\n",
      "Run: 02, Epoch: 193, Loss: 0.2311, Train: 95.40%, Valid: 98.31% Test: 83.78%\n",
      "Run: 02, Epoch: 194, Loss: 0.2251, Train: 95.40%, Valid: 98.31% Test: 83.78%\n",
      "Run: 02, Epoch: 195, Loss: 0.2212, Train: 95.40%, Valid: 96.61% Test: 83.78%\n",
      "Run: 02, Epoch: 196, Loss: 0.2031, Train: 96.55%, Valid: 94.92% Test: 83.78%\n",
      "Run: 02, Epoch: 197, Loss: 0.1585, Train: 96.55%, Valid: 96.61% Test: 83.78%\n",
      "Run: 02, Epoch: 198, Loss: 0.2266, Train: 94.25%, Valid: 96.61% Test: 86.49%\n",
      "Run: 02, Epoch: 199, Loss: 0.2691, Train: 91.95%, Valid: 96.61% Test: 86.49%\n",
      "Run: 02, Epoch: 200, Loss: 0.2671, Train: 96.55%, Valid: 96.61% Test: 89.19%\n",
      "Run 02:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 98.31\n",
      "  Final Train: 97.70\n",
      "   Final Test: 86.49\n",
      "Run: 03, Epoch: 01, Loss: 1.5370, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 02, Loss: 1.4841, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 03, Loss: 1.4365, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 04, Loss: 1.3975, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 05, Loss: 1.3669, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 06, Loss: 1.2791, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 07, Loss: 1.2439, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 08, Loss: 1.2162, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 09, Loss: 1.1804, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 10, Loss: 1.1508, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 11, Loss: 1.0957, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 12, Loss: 1.0838, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 13, Loss: 1.0307, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 14, Loss: 1.0344, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 15, Loss: 0.9809, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 16, Loss: 0.9265, Train: 59.77%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 17, Loss: 0.9524, Train: 59.77%, Valid: 55.93% Test: 48.65%\n",
      "Run: 03, Epoch: 18, Loss: 0.9064, Train: 59.77%, Valid: 55.93% Test: 48.65%\n",
      "Run: 03, Epoch: 19, Loss: 0.9111, Train: 60.92%, Valid: 55.93% Test: 48.65%\n",
      "Run: 03, Epoch: 20, Loss: 0.8683, Train: 60.92%, Valid: 55.93% Test: 48.65%\n",
      "Run: 03, Epoch: 21, Loss: 0.8743, Train: 63.22%, Valid: 55.93% Test: 48.65%\n",
      "Run: 03, Epoch: 22, Loss: 0.8560, Train: 63.22%, Valid: 55.93% Test: 48.65%\n",
      "Run: 03, Epoch: 23, Loss: 0.8137, Train: 63.22%, Valid: 55.93% Test: 48.65%\n",
      "Run: 03, Epoch: 24, Loss: 0.8335, Train: 63.22%, Valid: 55.93% Test: 48.65%\n",
      "Run: 03, Epoch: 25, Loss: 0.8097, Train: 63.22%, Valid: 57.63% Test: 48.65%\n",
      "Run: 03, Epoch: 26, Loss: 0.7581, Train: 63.22%, Valid: 59.32% Test: 48.65%\n",
      "Run: 03, Epoch: 27, Loss: 0.7613, Train: 64.37%, Valid: 59.32% Test: 51.35%\n",
      "Run: 03, Epoch: 28, Loss: 0.7491, Train: 64.37%, Valid: 59.32% Test: 51.35%\n",
      "Run: 03, Epoch: 29, Loss: 0.7460, Train: 64.37%, Valid: 57.63% Test: 48.65%\n",
      "Run: 03, Epoch: 30, Loss: 0.7609, Train: 64.37%, Valid: 57.63% Test: 48.65%\n",
      "Run: 03, Epoch: 31, Loss: 0.7095, Train: 64.37%, Valid: 61.02% Test: 48.65%\n",
      "Run: 03, Epoch: 32, Loss: 0.7449, Train: 66.67%, Valid: 62.71% Test: 48.65%\n",
      "Run: 03, Epoch: 33, Loss: 0.7003, Train: 66.67%, Valid: 62.71% Test: 54.05%\n",
      "Run: 03, Epoch: 34, Loss: 0.6973, Train: 68.97%, Valid: 67.80% Test: 56.76%\n",
      "Run: 03, Epoch: 35, Loss: 0.6750, Train: 71.26%, Valid: 69.49% Test: 56.76%\n",
      "Run: 03, Epoch: 36, Loss: 0.6682, Train: 72.41%, Valid: 71.19% Test: 56.76%\n",
      "Run: 03, Epoch: 37, Loss: 0.6396, Train: 72.41%, Valid: 69.49% Test: 56.76%\n",
      "Run: 03, Epoch: 38, Loss: 0.6241, Train: 70.11%, Valid: 67.80% Test: 56.76%\n",
      "Run: 03, Epoch: 39, Loss: 0.6367, Train: 68.97%, Valid: 66.10% Test: 56.76%\n",
      "Run: 03, Epoch: 40, Loss: 0.6145, Train: 67.82%, Valid: 64.41% Test: 56.76%\n",
      "Run: 03, Epoch: 41, Loss: 0.6233, Train: 67.82%, Valid: 61.02% Test: 54.05%\n",
      "Run: 03, Epoch: 42, Loss: 0.6177, Train: 67.82%, Valid: 62.71% Test: 56.76%\n",
      "Run: 03, Epoch: 43, Loss: 0.5662, Train: 70.11%, Valid: 62.71% Test: 54.05%\n",
      "Run: 03, Epoch: 44, Loss: 0.6307, Train: 72.41%, Valid: 67.80% Test: 54.05%\n",
      "Run: 03, Epoch: 45, Loss: 0.5874, Train: 74.71%, Valid: 71.19% Test: 54.05%\n",
      "Run: 03, Epoch: 46, Loss: 0.5973, Train: 78.16%, Valid: 74.58% Test: 62.16%\n",
      "Run: 03, Epoch: 47, Loss: 0.6069, Train: 79.31%, Valid: 77.97% Test: 62.16%\n",
      "Run: 03, Epoch: 48, Loss: 0.5437, Train: 85.06%, Valid: 81.36% Test: 67.57%\n",
      "Run: 03, Epoch: 49, Loss: 0.6087, Train: 85.06%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 50, Loss: 0.5043, Train: 80.46%, Valid: 71.19% Test: 64.86%\n",
      "Run: 03, Epoch: 51, Loss: 0.5314, Train: 79.31%, Valid: 71.19% Test: 64.86%\n",
      "Run: 03, Epoch: 52, Loss: 0.5073, Train: 77.01%, Valid: 71.19% Test: 62.16%\n",
      "Run: 03, Epoch: 53, Loss: 0.5077, Train: 74.71%, Valid: 66.10% Test: 59.46%\n",
      "Run: 03, Epoch: 54, Loss: 0.5307, Train: 73.56%, Valid: 64.41% Test: 59.46%\n",
      "Run: 03, Epoch: 55, Loss: 0.5408, Train: 73.56%, Valid: 69.49% Test: 62.16%\n",
      "Run: 03, Epoch: 56, Loss: 0.4711, Train: 73.56%, Valid: 67.80% Test: 62.16%\n",
      "Run: 03, Epoch: 57, Loss: 0.4980, Train: 73.56%, Valid: 66.10% Test: 62.16%\n",
      "Run: 03, Epoch: 58, Loss: 0.4568, Train: 78.16%, Valid: 71.19% Test: 64.86%\n",
      "Run: 03, Epoch: 59, Loss: 0.4858, Train: 88.51%, Valid: 77.97% Test: 67.57%\n",
      "Run: 03, Epoch: 60, Loss: 0.4878, Train: 91.95%, Valid: 83.05% Test: 72.97%\n",
      "Run: 03, Epoch: 61, Loss: 0.4611, Train: 93.10%, Valid: 86.44% Test: 78.38%\n",
      "Run: 03, Epoch: 62, Loss: 0.4456, Train: 91.95%, Valid: 86.44% Test: 78.38%\n",
      "Run: 03, Epoch: 63, Loss: 0.4861, Train: 90.80%, Valid: 86.44% Test: 75.68%\n",
      "Run: 03, Epoch: 64, Loss: 0.3933, Train: 90.80%, Valid: 84.75% Test: 75.68%\n",
      "Run: 03, Epoch: 65, Loss: 0.4355, Train: 91.95%, Valid: 93.22% Test: 81.08%\n",
      "Run: 03, Epoch: 66, Loss: 0.4542, Train: 95.40%, Valid: 91.53% Test: 81.08%\n",
      "Run: 03, Epoch: 67, Loss: 0.4587, Train: 95.40%, Valid: 88.14% Test: 75.68%\n",
      "Run: 03, Epoch: 68, Loss: 0.4265, Train: 91.95%, Valid: 84.75% Test: 75.68%\n",
      "Run: 03, Epoch: 69, Loss: 0.4208, Train: 91.95%, Valid: 83.05% Test: 75.68%\n",
      "Run: 03, Epoch: 70, Loss: 0.4260, Train: 91.95%, Valid: 86.44% Test: 75.68%\n",
      "Run: 03, Epoch: 71, Loss: 0.4352, Train: 91.95%, Valid: 86.44% Test: 72.97%\n",
      "Run: 03, Epoch: 72, Loss: 0.4241, Train: 91.95%, Valid: 83.05% Test: 72.97%\n",
      "Run: 03, Epoch: 73, Loss: 0.4487, Train: 90.80%, Valid: 77.97% Test: 70.27%\n",
      "Run: 03, Epoch: 74, Loss: 0.4235, Train: 86.21%, Valid: 74.58% Test: 64.86%\n",
      "Run: 03, Epoch: 75, Loss: 0.4007, Train: 80.46%, Valid: 67.80% Test: 59.46%\n",
      "Run: 03, Epoch: 76, Loss: 0.4045, Train: 81.61%, Valid: 69.49% Test: 59.46%\n",
      "Run: 03, Epoch: 77, Loss: 0.4109, Train: 87.36%, Valid: 71.19% Test: 62.16%\n",
      "Run: 03, Epoch: 78, Loss: 0.3700, Train: 88.51%, Valid: 81.36% Test: 72.97%\n",
      "Run: 03, Epoch: 79, Loss: 0.3999, Train: 94.25%, Valid: 88.14% Test: 78.38%\n",
      "Run: 03, Epoch: 80, Loss: 0.3780, Train: 94.25%, Valid: 91.53% Test: 81.08%\n",
      "Run: 03, Epoch: 81, Loss: 0.3701, Train: 98.85%, Valid: 89.83% Test: 83.78%\n",
      "Run: 03, Epoch: 82, Loss: 0.3299, Train: 96.55%, Valid: 89.83% Test: 78.38%\n",
      "Run: 03, Epoch: 83, Loss: 0.3482, Train: 95.40%, Valid: 91.53% Test: 78.38%\n",
      "Run: 03, Epoch: 84, Loss: 0.3744, Train: 95.40%, Valid: 91.53% Test: 75.68%\n",
      "Run: 03, Epoch: 85, Loss: 0.3702, Train: 94.25%, Valid: 91.53% Test: 75.68%\n",
      "Run: 03, Epoch: 86, Loss: 0.3440, Train: 90.80%, Valid: 89.83% Test: 81.08%\n",
      "Run: 03, Epoch: 87, Loss: 0.3185, Train: 89.66%, Valid: 89.83% Test: 81.08%\n",
      "Run: 03, Epoch: 88, Loss: 0.3614, Train: 93.10%, Valid: 89.83% Test: 81.08%\n",
      "Run: 03, Epoch: 89, Loss: 0.3483, Train: 93.10%, Valid: 89.83% Test: 81.08%\n",
      "Run: 03, Epoch: 90, Loss: 0.3606, Train: 93.10%, Valid: 86.44% Test: 78.38%\n",
      "Run: 03, Epoch: 91, Loss: 0.3909, Train: 94.25%, Valid: 93.22% Test: 83.78%\n",
      "Run: 03, Epoch: 92, Loss: 0.3227, Train: 97.70%, Valid: 93.22% Test: 86.49%\n",
      "Run: 03, Epoch: 93, Loss: 0.3645, Train: 98.85%, Valid: 94.92% Test: 83.78%\n",
      "Run: 03, Epoch: 94, Loss: 0.3214, Train: 98.85%, Valid: 98.31% Test: 83.78%\n",
      "Run: 03, Epoch: 95, Loss: 0.3513, Train: 98.85%, Valid: 96.61% Test: 83.78%\n",
      "Run: 03, Epoch: 96, Loss: 0.3168, Train: 98.85%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 97, Loss: 0.2929, Train: 97.70%, Valid: 89.83% Test: 78.38%\n",
      "Run: 03, Epoch: 98, Loss: 0.3447, Train: 97.70%, Valid: 88.14% Test: 78.38%\n",
      "Run: 03, Epoch: 99, Loss: 0.2760, Train: 97.70%, Valid: 91.53% Test: 78.38%\n",
      "Run: 03, Epoch: 100, Loss: 0.3000, Train: 98.85%, Valid: 93.22% Test: 81.08%\n",
      "Run: 03, Epoch: 101, Loss: 0.2856, Train: 98.85%, Valid: 93.22% Test: 81.08%\n",
      "Run: 03, Epoch: 102, Loss: 0.2968, Train: 97.70%, Valid: 94.92% Test: 78.38%\n",
      "Run: 03, Epoch: 103, Loss: 0.3060, Train: 97.70%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 104, Loss: 0.3008, Train: 97.70%, Valid: 93.22% Test: 81.08%\n",
      "Run: 03, Epoch: 105, Loss: 0.2748, Train: 98.85%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 106, Loss: 0.2941, Train: 98.85%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 107, Loss: 0.3174, Train: 100.00%, Valid: 94.92% Test: 83.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 108, Loss: 0.2729, Train: 100.00%, Valid: 94.92% Test: 86.49%\n",
      "Run: 03, Epoch: 109, Loss: 0.2609, Train: 100.00%, Valid: 96.61% Test: 86.49%\n",
      "Run: 03, Epoch: 110, Loss: 0.2958, Train: 100.00%, Valid: 98.31% Test: 83.78%\n",
      "Run: 03, Epoch: 111, Loss: 0.3287, Train: 100.00%, Valid: 96.61% Test: 81.08%\n",
      "Run: 03, Epoch: 112, Loss: 0.2247, Train: 98.85%, Valid: 96.61% Test: 86.49%\n",
      "Run: 03, Epoch: 113, Loss: 0.2587, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 03, Epoch: 114, Loss: 0.2547, Train: 98.85%, Valid: 98.31% Test: 91.89%\n",
      "Run: 03, Epoch: 115, Loss: 0.2192, Train: 98.85%, Valid: 100.00% Test: 89.19%\n",
      "Run: 03, Epoch: 116, Loss: 0.2348, Train: 98.85%, Valid: 100.00% Test: 89.19%\n",
      "Run: 03, Epoch: 117, Loss: 0.2441, Train: 97.70%, Valid: 98.31% Test: 91.89%\n",
      "Run: 03, Epoch: 118, Loss: 0.3031, Train: 96.55%, Valid: 94.92% Test: 91.89%\n",
      "Run: 03, Epoch: 119, Loss: 0.2369, Train: 96.55%, Valid: 94.92% Test: 86.49%\n",
      "Run: 03, Epoch: 120, Loss: 0.2563, Train: 97.70%, Valid: 93.22% Test: 83.78%\n",
      "Run: 03, Epoch: 121, Loss: 0.2141, Train: 96.55%, Valid: 93.22% Test: 83.78%\n",
      "Run: 03, Epoch: 122, Loss: 0.2761, Train: 97.70%, Valid: 91.53% Test: 83.78%\n",
      "Run: 03, Epoch: 123, Loss: 0.2563, Train: 96.55%, Valid: 91.53% Test: 78.38%\n",
      "Run: 03, Epoch: 124, Loss: 0.2943, Train: 94.25%, Valid: 88.14% Test: 75.68%\n",
      "Run: 03, Epoch: 125, Loss: 0.2201, Train: 93.10%, Valid: 84.75% Test: 72.97%\n",
      "Run: 03, Epoch: 126, Loss: 0.2832, Train: 95.40%, Valid: 86.44% Test: 72.97%\n",
      "Run: 03, Epoch: 127, Loss: 0.1947, Train: 95.40%, Valid: 93.22% Test: 72.97%\n",
      "Run: 03, Epoch: 128, Loss: 0.2524, Train: 97.70%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 129, Loss: 0.2432, Train: 98.85%, Valid: 96.61% Test: 81.08%\n",
      "Run: 03, Epoch: 130, Loss: 0.2544, Train: 98.85%, Valid: 96.61% Test: 83.78%\n",
      "Run: 03, Epoch: 131, Loss: 0.1930, Train: 98.85%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 132, Loss: 0.2381, Train: 100.00%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 133, Loss: 0.2253, Train: 100.00%, Valid: 91.53% Test: 81.08%\n",
      "Run: 03, Epoch: 134, Loss: 0.2423, Train: 100.00%, Valid: 89.83% Test: 81.08%\n",
      "Run: 03, Epoch: 135, Loss: 0.2048, Train: 100.00%, Valid: 89.83% Test: 81.08%\n",
      "Run: 03, Epoch: 136, Loss: 0.2246, Train: 100.00%, Valid: 88.14% Test: 81.08%\n",
      "Run: 03, Epoch: 137, Loss: 0.2330, Train: 100.00%, Valid: 93.22% Test: 83.78%\n",
      "Run: 03, Epoch: 138, Loss: 0.2178, Train: 100.00%, Valid: 94.92% Test: 83.78%\n",
      "Run: 03, Epoch: 139, Loss: 0.2285, Train: 100.00%, Valid: 96.61% Test: 89.19%\n",
      "Run: 03, Epoch: 140, Loss: 0.2180, Train: 100.00%, Valid: 96.61% Test: 86.49%\n",
      "Run: 03, Epoch: 141, Loss: 0.1976, Train: 98.85%, Valid: 94.92% Test: 86.49%\n",
      "Run: 03, Epoch: 142, Loss: 0.2482, Train: 96.55%, Valid: 94.92% Test: 89.19%\n",
      "Run: 03, Epoch: 143, Loss: 0.2072, Train: 96.55%, Valid: 93.22% Test: 89.19%\n",
      "Run: 03, Epoch: 144, Loss: 0.2312, Train: 98.85%, Valid: 96.61% Test: 86.49%\n",
      "Run: 03, Epoch: 145, Loss: 0.2658, Train: 98.85%, Valid: 96.61% Test: 83.78%\n",
      "Run: 03, Epoch: 146, Loss: 0.2211, Train: 97.70%, Valid: 96.61% Test: 83.78%\n",
      "Run: 03, Epoch: 147, Loss: 0.2128, Train: 97.70%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 148, Loss: 0.2128, Train: 97.70%, Valid: 93.22% Test: 81.08%\n",
      "Run: 03, Epoch: 149, Loss: 0.2401, Train: 100.00%, Valid: 93.22% Test: 81.08%\n",
      "Run: 03, Epoch: 150, Loss: 0.2261, Train: 100.00%, Valid: 91.53% Test: 81.08%\n",
      "Run: 03, Epoch: 151, Loss: 0.1769, Train: 97.70%, Valid: 93.22% Test: 81.08%\n",
      "Run: 03, Epoch: 152, Loss: 0.2157, Train: 97.70%, Valid: 91.53% Test: 83.78%\n",
      "Run: 03, Epoch: 153, Loss: 0.1843, Train: 98.85%, Valid: 91.53% Test: 83.78%\n",
      "Run: 03, Epoch: 154, Loss: 0.2202, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 03, Epoch: 155, Loss: 0.2113, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 03, Epoch: 156, Loss: 0.1974, Train: 93.10%, Valid: 89.83% Test: 81.08%\n",
      "Run: 03, Epoch: 157, Loss: 0.2072, Train: 90.80%, Valid: 86.44% Test: 78.38%\n",
      "Run: 03, Epoch: 158, Loss: 0.1860, Train: 94.25%, Valid: 88.14% Test: 78.38%\n",
      "Run: 03, Epoch: 159, Loss: 0.2136, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 03, Epoch: 160, Loss: 0.1568, Train: 96.55%, Valid: 93.22% Test: 91.89%\n",
      "Run: 03, Epoch: 161, Loss: 0.1693, Train: 94.25%, Valid: 96.61% Test: 89.19%\n",
      "Run: 03, Epoch: 162, Loss: 0.1874, Train: 96.55%, Valid: 96.61% Test: 89.19%\n",
      "Run: 03, Epoch: 163, Loss: 0.1811, Train: 97.70%, Valid: 96.61% Test: 86.49%\n",
      "Run: 03, Epoch: 164, Loss: 0.1303, Train: 98.85%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 165, Loss: 0.1567, Train: 100.00%, Valid: 93.22% Test: 81.08%\n",
      "Run: 03, Epoch: 166, Loss: 0.2096, Train: 100.00%, Valid: 91.53% Test: 78.38%\n",
      "Run: 03, Epoch: 167, Loss: 0.1491, Train: 100.00%, Valid: 89.83% Test: 75.68%\n",
      "Run: 03, Epoch: 168, Loss: 0.1841, Train: 100.00%, Valid: 89.83% Test: 75.68%\n",
      "Run: 03, Epoch: 169, Loss: 0.2292, Train: 100.00%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 170, Loss: 0.1784, Train: 100.00%, Valid: 98.31% Test: 81.08%\n",
      "Run: 03, Epoch: 171, Loss: 0.2054, Train: 100.00%, Valid: 94.92% Test: 81.08%\n",
      "Run: 03, Epoch: 172, Loss: 0.1702, Train: 100.00%, Valid: 94.92% Test: 83.78%\n",
      "Run: 03, Epoch: 173, Loss: 0.1920, Train: 100.00%, Valid: 94.92% Test: 83.78%\n",
      "Run: 03, Epoch: 174, Loss: 0.1701, Train: 100.00%, Valid: 94.92% Test: 83.78%\n",
      "Run: 03, Epoch: 175, Loss: 0.1732, Train: 100.00%, Valid: 94.92% Test: 86.49%\n",
      "Run: 03, Epoch: 176, Loss: 0.1641, Train: 100.00%, Valid: 93.22% Test: 86.49%\n",
      "Run: 03, Epoch: 177, Loss: 0.1788, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 03, Epoch: 178, Loss: 0.1464, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 03, Epoch: 179, Loss: 0.1671, Train: 100.00%, Valid: 94.92% Test: 89.19%\n",
      "Run: 03, Epoch: 180, Loss: 0.1553, Train: 100.00%, Valid: 96.61% Test: 91.89%\n",
      "Run: 03, Epoch: 181, Loss: 0.1577, Train: 98.85%, Valid: 96.61% Test: 91.89%\n",
      "Run: 03, Epoch: 182, Loss: 0.1471, Train: 100.00%, Valid: 96.61% Test: 91.89%\n",
      "Run: 03, Epoch: 183, Loss: 0.1883, Train: 100.00%, Valid: 98.31% Test: 89.19%\n",
      "Run: 03, Epoch: 184, Loss: 0.1921, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 03, Epoch: 185, Loss: 0.2173, Train: 98.85%, Valid: 96.61% Test: 86.49%\n",
      "Run: 03, Epoch: 186, Loss: 0.2004, Train: 98.85%, Valid: 96.61% Test: 86.49%\n",
      "Run: 03, Epoch: 187, Loss: 0.1680, Train: 100.00%, Valid: 96.61% Test: 86.49%\n",
      "Run: 03, Epoch: 188, Loss: 0.1422, Train: 100.00%, Valid: 94.92% Test: 83.78%\n",
      "Run: 03, Epoch: 189, Loss: 0.1946, Train: 100.00%, Valid: 96.61% Test: 83.78%\n",
      "Run: 03, Epoch: 190, Loss: 0.2004, Train: 100.00%, Valid: 96.61% Test: 86.49%\n",
      "Run: 03, Epoch: 191, Loss: 0.1540, Train: 100.00%, Valid: 98.31% Test: 83.78%\n",
      "Run: 03, Epoch: 192, Loss: 0.1912, Train: 100.00%, Valid: 96.61% Test: 83.78%\n",
      "Run: 03, Epoch: 193, Loss: 0.1769, Train: 100.00%, Valid: 96.61% Test: 83.78%\n",
      "Run: 03, Epoch: 194, Loss: 0.1690, Train: 100.00%, Valid: 98.31% Test: 89.19%\n",
      "Run: 03, Epoch: 195, Loss: 0.1583, Train: 100.00%, Valid: 96.61% Test: 86.49%\n",
      "Run: 03, Epoch: 196, Loss: 0.1275, Train: 100.00%, Valid: 98.31% Test: 86.49%\n",
      "Run: 03, Epoch: 197, Loss: 0.1580, Train: 100.00%, Valid: 98.31% Test: 86.49%\n",
      "Run: 03, Epoch: 198, Loss: 0.1698, Train: 100.00%, Valid: 98.31% Test: 86.49%\n",
      "Run: 03, Epoch: 199, Loss: 0.1195, Train: 100.00%, Valid: 100.00% Test: 83.78%\n",
      "Run: 03, Epoch: 200, Loss: 0.2192, Train: 100.00%, Valid: 98.31% Test: 83.78%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 100.00\n",
      "  Final Train: 98.85\n",
      "   Final Test: 89.19\n",
      "Run: 04, Epoch: 01, Loss: 1.5827, Train: 13.79%, Valid: 28.81% Test: 10.81%\n",
      "Run: 04, Epoch: 02, Loss: 1.5043, Train: 13.79%, Valid: 28.81% Test: 10.81%\n",
      "Run: 04, Epoch: 03, Loss: 1.4481, Train: 20.69%, Valid: 40.68% Test: 21.62%\n",
      "Run: 04, Epoch: 04, Loss: 1.3920, Train: 60.92%, Valid: 59.32% Test: 64.86%\n",
      "Run: 04, Epoch: 05, Loss: 1.3275, Train: 59.77%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 06, Loss: 1.2784, Train: 57.47%, Valid: 50.85% Test: 62.16%\n",
      "Run: 04, Epoch: 07, Loss: 1.2373, Train: 55.17%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 08, Loss: 1.2037, Train: 55.17%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 09, Loss: 1.1431, Train: 55.17%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 10, Loss: 1.1402, Train: 55.17%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 11, Loss: 1.1051, Train: 55.17%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 12, Loss: 1.0109, Train: 54.02%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 13, Loss: 1.0341, Train: 54.02%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 14, Loss: 0.9920, Train: 54.02%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 15, Loss: 0.9654, Train: 54.02%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 16, Loss: 0.9545, Train: 54.02%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 17, Loss: 0.9143, Train: 55.17%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 18, Loss: 0.8868, Train: 56.32%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 19, Loss: 0.8948, Train: 56.32%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 20, Loss: 0.9223, Train: 55.17%, Valid: 54.24% Test: 59.46%\n",
      "Run: 04, Epoch: 21, Loss: 0.9173, Train: 55.17%, Valid: 54.24% Test: 59.46%\n",
      "Run: 04, Epoch: 22, Loss: 0.8778, Train: 56.32%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 23, Loss: 0.8456, Train: 58.62%, Valid: 54.24% Test: 59.46%\n",
      "Run: 04, Epoch: 24, Loss: 0.7849, Train: 56.32%, Valid: 54.24% Test: 62.16%\n",
      "Run: 04, Epoch: 25, Loss: 0.7998, Train: 56.32%, Valid: 55.93% Test: 62.16%\n",
      "Run: 04, Epoch: 26, Loss: 0.7752, Train: 56.32%, Valid: 55.93% Test: 64.86%\n",
      "Run: 04, Epoch: 27, Loss: 0.7617, Train: 57.47%, Valid: 55.93% Test: 64.86%\n",
      "Run: 04, Epoch: 28, Loss: 0.7843, Train: 57.47%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 29, Loss: 0.7295, Train: 59.77%, Valid: 54.24% Test: 64.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 30, Loss: 0.7197, Train: 60.92%, Valid: 55.93% Test: 64.86%\n",
      "Run: 04, Epoch: 31, Loss: 0.7419, Train: 60.92%, Valid: 57.63% Test: 64.86%\n",
      "Run: 04, Epoch: 32, Loss: 0.7161, Train: 60.92%, Valid: 59.32% Test: 64.86%\n",
      "Run: 04, Epoch: 33, Loss: 0.7714, Train: 60.92%, Valid: 59.32% Test: 64.86%\n",
      "Run: 04, Epoch: 34, Loss: 0.6574, Train: 62.07%, Valid: 59.32% Test: 64.86%\n",
      "Run: 04, Epoch: 35, Loss: 0.7049, Train: 65.52%, Valid: 55.93% Test: 64.86%\n",
      "Run: 04, Epoch: 36, Loss: 0.7018, Train: 70.11%, Valid: 62.71% Test: 70.27%\n",
      "Run: 04, Epoch: 37, Loss: 0.6754, Train: 72.41%, Valid: 64.41% Test: 70.27%\n",
      "Run: 04, Epoch: 38, Loss: 0.6552, Train: 72.41%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 39, Loss: 0.7021, Train: 71.26%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 40, Loss: 0.6375, Train: 71.26%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 41, Loss: 0.6945, Train: 71.26%, Valid: 67.80% Test: 70.27%\n",
      "Run: 04, Epoch: 42, Loss: 0.6573, Train: 67.82%, Valid: 69.49% Test: 70.27%\n",
      "Run: 04, Epoch: 43, Loss: 0.6080, Train: 72.41%, Valid: 71.19% Test: 72.97%\n",
      "Run: 04, Epoch: 44, Loss: 0.6240, Train: 70.11%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 45, Loss: 0.6277, Train: 71.26%, Valid: 76.27% Test: 75.68%\n",
      "Run: 04, Epoch: 46, Loss: 0.6207, Train: 72.41%, Valid: 79.66% Test: 75.68%\n",
      "Run: 04, Epoch: 47, Loss: 0.5990, Train: 73.56%, Valid: 76.27% Test: 75.68%\n",
      "Run: 04, Epoch: 48, Loss: 0.6137, Train: 77.01%, Valid: 81.36% Test: 72.97%\n",
      "Run: 04, Epoch: 49, Loss: 0.6114, Train: 83.91%, Valid: 83.05% Test: 81.08%\n",
      "Run: 04, Epoch: 50, Loss: 0.5367, Train: 83.91%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 51, Loss: 0.5576, Train: 86.21%, Valid: 83.05% Test: 81.08%\n",
      "Run: 04, Epoch: 52, Loss: 0.6054, Train: 88.51%, Valid: 84.75% Test: 86.49%\n",
      "Run: 04, Epoch: 53, Loss: 0.5783, Train: 88.51%, Valid: 86.44% Test: 86.49%\n",
      "Run: 04, Epoch: 54, Loss: 0.5291, Train: 87.36%, Valid: 88.14% Test: 86.49%\n",
      "Run: 04, Epoch: 55, Loss: 0.5951, Train: 86.21%, Valid: 88.14% Test: 83.78%\n",
      "Run: 04, Epoch: 56, Loss: 0.5498, Train: 88.51%, Valid: 88.14% Test: 86.49%\n",
      "Run: 04, Epoch: 57, Loss: 0.5427, Train: 90.80%, Valid: 86.44% Test: 89.19%\n",
      "Run: 04, Epoch: 58, Loss: 0.5073, Train: 89.66%, Valid: 86.44% Test: 89.19%\n",
      "Run: 04, Epoch: 59, Loss: 0.5433, Train: 87.36%, Valid: 86.44% Test: 89.19%\n",
      "Run: 04, Epoch: 60, Loss: 0.4738, Train: 83.91%, Valid: 84.75% Test: 89.19%\n",
      "Run: 04, Epoch: 61, Loss: 0.5071, Train: 83.91%, Valid: 79.66% Test: 89.19%\n",
      "Run: 04, Epoch: 62, Loss: 0.5653, Train: 86.21%, Valid: 86.44% Test: 86.49%\n",
      "Run: 04, Epoch: 63, Loss: 0.5299, Train: 86.21%, Valid: 84.75% Test: 89.19%\n",
      "Run: 04, Epoch: 64, Loss: 0.5242, Train: 88.51%, Valid: 89.83% Test: 86.49%\n",
      "Run: 04, Epoch: 65, Loss: 0.5119, Train: 93.10%, Valid: 88.14% Test: 89.19%\n",
      "Run: 04, Epoch: 66, Loss: 0.4757, Train: 94.25%, Valid: 89.83% Test: 91.89%\n",
      "Run: 04, Epoch: 67, Loss: 0.5070, Train: 94.25%, Valid: 91.53% Test: 91.89%\n",
      "Run: 04, Epoch: 68, Loss: 0.5193, Train: 94.25%, Valid: 91.53% Test: 89.19%\n",
      "Run: 04, Epoch: 69, Loss: 0.5513, Train: 93.10%, Valid: 91.53% Test: 89.19%\n",
      "Run: 04, Epoch: 70, Loss: 0.4975, Train: 93.10%, Valid: 88.14% Test: 94.59%\n",
      "Run: 04, Epoch: 71, Loss: 0.5164, Train: 91.95%, Valid: 88.14% Test: 91.89%\n",
      "Run: 04, Epoch: 72, Loss: 0.4428, Train: 88.51%, Valid: 84.75% Test: 89.19%\n",
      "Run: 04, Epoch: 73, Loss: 0.4624, Train: 82.76%, Valid: 84.75% Test: 83.78%\n",
      "Run: 04, Epoch: 74, Loss: 0.4738, Train: 81.61%, Valid: 84.75% Test: 83.78%\n",
      "Run: 04, Epoch: 75, Loss: 0.4594, Train: 79.31%, Valid: 84.75% Test: 86.49%\n",
      "Run: 04, Epoch: 76, Loss: 0.4952, Train: 86.21%, Valid: 89.83% Test: 89.19%\n",
      "Run: 04, Epoch: 77, Loss: 0.4589, Train: 88.51%, Valid: 91.53% Test: 89.19%\n",
      "Run: 04, Epoch: 78, Loss: 0.4122, Train: 91.95%, Valid: 89.83% Test: 86.49%\n",
      "Run: 04, Epoch: 79, Loss: 0.4471, Train: 91.95%, Valid: 89.83% Test: 86.49%\n",
      "Run: 04, Epoch: 80, Loss: 0.4274, Train: 93.10%, Valid: 89.83% Test: 86.49%\n",
      "Run: 04, Epoch: 81, Loss: 0.4371, Train: 93.10%, Valid: 89.83% Test: 86.49%\n",
      "Run: 04, Epoch: 82, Loss: 0.4688, Train: 91.95%, Valid: 89.83% Test: 86.49%\n",
      "Run: 04, Epoch: 83, Loss: 0.4148, Train: 96.55%, Valid: 88.14% Test: 86.49%\n",
      "Run: 04, Epoch: 84, Loss: 0.3995, Train: 95.40%, Valid: 88.14% Test: 91.89%\n",
      "Run: 04, Epoch: 85, Loss: 0.3877, Train: 96.55%, Valid: 88.14% Test: 94.59%\n",
      "Run: 04, Epoch: 86, Loss: 0.4049, Train: 95.40%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 87, Loss: 0.4016, Train: 94.25%, Valid: 89.83% Test: 91.89%\n",
      "Run: 04, Epoch: 88, Loss: 0.3599, Train: 93.10%, Valid: 88.14% Test: 91.89%\n",
      "Run: 04, Epoch: 89, Loss: 0.4082, Train: 96.55%, Valid: 86.44% Test: 89.19%\n",
      "Run: 04, Epoch: 90, Loss: 0.4201, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 04, Epoch: 91, Loss: 0.3783, Train: 96.55%, Valid: 88.14% Test: 91.89%\n",
      "Run: 04, Epoch: 92, Loss: 0.3996, Train: 95.40%, Valid: 86.44% Test: 94.59%\n",
      "Run: 04, Epoch: 93, Loss: 0.3545, Train: 95.40%, Valid: 86.44% Test: 94.59%\n",
      "Run: 04, Epoch: 94, Loss: 0.3800, Train: 94.25%, Valid: 86.44% Test: 94.59%\n",
      "Run: 04, Epoch: 95, Loss: 0.3546, Train: 95.40%, Valid: 86.44% Test: 91.89%\n",
      "Run: 04, Epoch: 96, Loss: 0.3585, Train: 95.40%, Valid: 86.44% Test: 91.89%\n",
      "Run: 04, Epoch: 97, Loss: 0.3802, Train: 94.25%, Valid: 86.44% Test: 91.89%\n",
      "Run: 04, Epoch: 98, Loss: 0.3682, Train: 95.40%, Valid: 89.83% Test: 91.89%\n",
      "Run: 04, Epoch: 99, Loss: 0.3825, Train: 93.10%, Valid: 89.83% Test: 91.89%\n",
      "Run: 04, Epoch: 100, Loss: 0.3268, Train: 91.95%, Valid: 89.83% Test: 91.89%\n",
      "Run: 04, Epoch: 101, Loss: 0.3181, Train: 90.80%, Valid: 86.44% Test: 91.89%\n",
      "Run: 04, Epoch: 102, Loss: 0.3600, Train: 90.80%, Valid: 84.75% Test: 97.30%\n",
      "Run: 04, Epoch: 103, Loss: 0.3821, Train: 95.40%, Valid: 89.83% Test: 97.30%\n",
      "Run: 04, Epoch: 104, Loss: 0.3480, Train: 95.40%, Valid: 89.83% Test: 97.30%\n",
      "Run: 04, Epoch: 105, Loss: 0.3854, Train: 94.25%, Valid: 89.83% Test: 97.30%\n",
      "Run: 04, Epoch: 106, Loss: 0.3605, Train: 95.40%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 107, Loss: 0.2902, Train: 96.55%, Valid: 91.53% Test: 91.89%\n",
      "Run: 04, Epoch: 108, Loss: 0.3422, Train: 96.55%, Valid: 94.92% Test: 91.89%\n",
      "Run: 04, Epoch: 109, Loss: 0.3970, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 04, Epoch: 110, Loss: 0.2933, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 04, Epoch: 111, Loss: 0.3207, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 04, Epoch: 112, Loss: 0.3208, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 04, Epoch: 113, Loss: 0.3528, Train: 96.55%, Valid: 91.53% Test: 89.19%\n",
      "Run: 04, Epoch: 114, Loss: 0.3032, Train: 96.55%, Valid: 93.22% Test: 89.19%\n",
      "Run: 04, Epoch: 115, Loss: 0.3529, Train: 96.55%, Valid: 94.92% Test: 89.19%\n",
      "Run: 04, Epoch: 116, Loss: 0.3101, Train: 96.55%, Valid: 94.92% Test: 89.19%\n",
      "Run: 04, Epoch: 117, Loss: 0.2927, Train: 97.70%, Valid: 94.92% Test: 91.89%\n",
      "Run: 04, Epoch: 118, Loss: 0.3253, Train: 97.70%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 119, Loss: 0.2878, Train: 97.70%, Valid: 93.22% Test: 94.59%\n",
      "Run: 04, Epoch: 120, Loss: 0.3370, Train: 96.55%, Valid: 93.22% Test: 89.19%\n",
      "Run: 04, Epoch: 121, Loss: 0.2765, Train: 97.70%, Valid: 93.22% Test: 91.89%\n",
      "Run: 04, Epoch: 122, Loss: 0.2561, Train: 96.55%, Valid: 93.22% Test: 91.89%\n",
      "Run: 04, Epoch: 123, Loss: 0.3617, Train: 96.55%, Valid: 93.22% Test: 89.19%\n",
      "Run: 04, Epoch: 124, Loss: 0.2828, Train: 97.70%, Valid: 94.92% Test: 91.89%\n",
      "Run: 04, Epoch: 125, Loss: 0.2863, Train: 97.70%, Valid: 96.61% Test: 94.59%\n",
      "Run: 04, Epoch: 126, Loss: 0.2971, Train: 97.70%, Valid: 96.61% Test: 94.59%\n",
      "Run: 04, Epoch: 127, Loss: 0.3308, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 128, Loss: 0.3231, Train: 96.55%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 129, Loss: 0.2728, Train: 96.55%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 130, Loss: 0.2843, Train: 98.85%, Valid: 88.14% Test: 94.59%\n",
      "Run: 04, Epoch: 131, Loss: 0.2967, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 132, Loss: 0.2631, Train: 97.70%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 133, Loss: 0.2710, Train: 97.70%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 134, Loss: 0.2261, Train: 97.70%, Valid: 94.92% Test: 94.59%\n",
      "Run: 04, Epoch: 135, Loss: 0.2807, Train: 97.70%, Valid: 89.83% Test: 97.30%\n",
      "Run: 04, Epoch: 136, Loss: 0.2700, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 04, Epoch: 137, Loss: 0.2889, Train: 97.70%, Valid: 89.83% Test: 91.89%\n",
      "Run: 04, Epoch: 138, Loss: 0.3355, Train: 93.10%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 139, Loss: 0.2338, Train: 94.25%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 140, Loss: 0.3361, Train: 97.70%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 141, Loss: 0.3760, Train: 96.55%, Valid: 93.22% Test: 94.59%\n",
      "Run: 04, Epoch: 142, Loss: 0.3064, Train: 96.55%, Valid: 93.22% Test: 91.89%\n",
      "Run: 04, Epoch: 143, Loss: 0.2827, Train: 90.80%, Valid: 86.44% Test: 91.89%\n",
      "Run: 04, Epoch: 144, Loss: 0.2389, Train: 87.36%, Valid: 77.97% Test: 89.19%\n",
      "Run: 04, Epoch: 145, Loss: 0.2645, Train: 90.80%, Valid: 79.66% Test: 89.19%\n",
      "Run: 04, Epoch: 146, Loss: 0.2978, Train: 95.40%, Valid: 83.05% Test: 91.89%\n",
      "Run: 04, Epoch: 147, Loss: 0.2963, Train: 97.70%, Valid: 86.44% Test: 89.19%\n",
      "Run: 04, Epoch: 148, Loss: 0.3124, Train: 97.70%, Valid: 88.14% Test: 89.19%\n",
      "Run: 04, Epoch: 149, Loss: 0.3262, Train: 95.40%, Valid: 91.53% Test: 91.89%\n",
      "Run: 04, Epoch: 150, Loss: 0.2698, Train: 95.40%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 151, Loss: 0.2739, Train: 95.40%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 152, Loss: 0.2473, Train: 96.55%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 153, Loss: 0.3050, Train: 98.85%, Valid: 93.22% Test: 94.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 154, Loss: 0.2498, Train: 97.70%, Valid: 94.92% Test: 94.59%\n",
      "Run: 04, Epoch: 155, Loss: 0.2205, Train: 97.70%, Valid: 93.22% Test: 94.59%\n",
      "Run: 04, Epoch: 156, Loss: 0.2895, Train: 96.55%, Valid: 91.53% Test: 97.30%\n",
      "Run: 04, Epoch: 157, Loss: 0.2232, Train: 95.40%, Valid: 89.83% Test: 94.59%\n",
      "Run: 04, Epoch: 158, Loss: 0.2439, Train: 96.55%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 159, Loss: 0.2596, Train: 96.55%, Valid: 93.22% Test: 94.59%\n",
      "Run: 04, Epoch: 160, Loss: 0.2793, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 04, Epoch: 161, Loss: 0.2294, Train: 97.70%, Valid: 86.44% Test: 91.89%\n",
      "Run: 04, Epoch: 162, Loss: 0.2863, Train: 98.85%, Valid: 88.14% Test: 91.89%\n",
      "Run: 04, Epoch: 163, Loss: 0.2470, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 04, Epoch: 164, Loss: 0.2495, Train: 96.55%, Valid: 93.22% Test: 94.59%\n",
      "Run: 04, Epoch: 165, Loss: 0.1979, Train: 95.40%, Valid: 94.92% Test: 97.30%\n",
      "Run: 04, Epoch: 166, Loss: 0.2039, Train: 95.40%, Valid: 94.92% Test: 94.59%\n",
      "Run: 04, Epoch: 167, Loss: 0.2153, Train: 96.55%, Valid: 94.92% Test: 97.30%\n",
      "Run: 04, Epoch: 168, Loss: 0.1827, Train: 98.85%, Valid: 94.92% Test: 97.30%\n",
      "Run: 04, Epoch: 169, Loss: 0.2378, Train: 98.85%, Valid: 96.61% Test: 94.59%\n",
      "Run: 04, Epoch: 170, Loss: 0.2478, Train: 98.85%, Valid: 98.31% Test: 94.59%\n",
      "Run: 04, Epoch: 171, Loss: 0.2438, Train: 98.85%, Valid: 96.61% Test: 94.59%\n",
      "Run: 04, Epoch: 172, Loss: 0.2397, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 04, Epoch: 173, Loss: 0.2760, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 04, Epoch: 174, Loss: 0.1842, Train: 96.55%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 175, Loss: 0.2132, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 04, Epoch: 176, Loss: 0.2307, Train: 96.55%, Valid: 88.14% Test: 94.59%\n",
      "Run: 04, Epoch: 177, Loss: 0.2181, Train: 96.55%, Valid: 84.75% Test: 94.59%\n",
      "Run: 04, Epoch: 178, Loss: 0.2183, Train: 97.70%, Valid: 83.05% Test: 91.89%\n",
      "Run: 04, Epoch: 179, Loss: 0.2147, Train: 98.85%, Valid: 83.05% Test: 91.89%\n",
      "Run: 04, Epoch: 180, Loss: 0.2612, Train: 98.85%, Valid: 88.14% Test: 94.59%\n",
      "Run: 04, Epoch: 181, Loss: 0.1946, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 04, Epoch: 182, Loss: 0.2359, Train: 98.85%, Valid: 96.61% Test: 94.59%\n",
      "Run: 04, Epoch: 183, Loss: 0.2289, Train: 97.70%, Valid: 94.92% Test: 94.59%\n",
      "Run: 04, Epoch: 184, Loss: 0.1860, Train: 96.55%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 185, Loss: 0.2242, Train: 96.55%, Valid: 93.22% Test: 91.89%\n",
      "Run: 04, Epoch: 186, Loss: 0.1789, Train: 97.70%, Valid: 93.22% Test: 91.89%\n",
      "Run: 04, Epoch: 187, Loss: 0.2822, Train: 97.70%, Valid: 93.22% Test: 94.59%\n",
      "Run: 04, Epoch: 188, Loss: 0.2312, Train: 98.85%, Valid: 91.53% Test: 94.59%\n",
      "Run: 04, Epoch: 189, Loss: 0.2158, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 04, Epoch: 190, Loss: 0.2020, Train: 94.25%, Valid: 88.14% Test: 89.19%\n",
      "Run: 04, Epoch: 191, Loss: 0.2177, Train: 88.51%, Valid: 86.44% Test: 83.78%\n",
      "Run: 04, Epoch: 192, Loss: 0.1987, Train: 86.21%, Valid: 83.05% Test: 83.78%\n",
      "Run: 04, Epoch: 193, Loss: 0.2285, Train: 86.21%, Valid: 83.05% Test: 83.78%\n",
      "Run: 04, Epoch: 194, Loss: 0.1820, Train: 93.10%, Valid: 86.44% Test: 89.19%\n",
      "Run: 04, Epoch: 195, Loss: 0.1906, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 04, Epoch: 196, Loss: 0.3069, Train: 97.70%, Valid: 91.53% Test: 97.30%\n",
      "Run: 04, Epoch: 197, Loss: 0.1927, Train: 97.70%, Valid: 88.14% Test: 97.30%\n",
      "Run: 04, Epoch: 198, Loss: 0.2375, Train: 95.40%, Valid: 86.44% Test: 97.30%\n",
      "Run: 04, Epoch: 199, Loss: 0.1614, Train: 94.25%, Valid: 86.44% Test: 94.59%\n",
      "Run: 04, Epoch: 200, Loss: 0.1919, Train: 95.40%, Valid: 89.83% Test: 89.19%\n",
      "Run 04:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 98.31\n",
      "  Final Train: 98.85\n",
      "   Final Test: 94.59\n",
      "Run: 05, Epoch: 01, Loss: 1.4841, Train: 18.39%, Valid: 16.95% Test: 18.92%\n",
      "Run: 05, Epoch: 02, Loss: 1.4228, Train: 49.43%, Valid: 64.41% Test: 59.46%\n",
      "Run: 05, Epoch: 03, Loss: 1.3715, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 04, Loss: 1.3286, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 05, Loss: 1.3056, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 06, Loss: 1.2462, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 07, Loss: 1.2763, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 08, Loss: 1.1939, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 09, Loss: 1.1188, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 10, Loss: 1.1188, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 11, Loss: 1.1105, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 12, Loss: 1.0608, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 13, Loss: 1.0273, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 14, Loss: 1.0094, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 15, Loss: 0.9670, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 16, Loss: 0.9470, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 17, Loss: 0.9102, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 18, Loss: 0.8933, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 19, Loss: 0.9281, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 20, Loss: 0.8613, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 21, Loss: 0.8271, Train: 49.43%, Valid: 64.41% Test: 56.76%\n",
      "Run: 05, Epoch: 22, Loss: 0.8308, Train: 50.57%, Valid: 66.10% Test: 56.76%\n",
      "Run: 05, Epoch: 23, Loss: 0.8087, Train: 51.72%, Valid: 66.10% Test: 56.76%\n",
      "Run: 05, Epoch: 24, Loss: 0.7793, Train: 51.72%, Valid: 66.10% Test: 56.76%\n",
      "Run: 05, Epoch: 25, Loss: 0.7937, Train: 52.87%, Valid: 69.49% Test: 59.46%\n",
      "Run: 05, Epoch: 26, Loss: 0.7814, Train: 56.32%, Valid: 71.19% Test: 59.46%\n",
      "Run: 05, Epoch: 27, Loss: 0.7643, Train: 58.62%, Valid: 72.88% Test: 59.46%\n",
      "Run: 05, Epoch: 28, Loss: 0.7475, Train: 59.77%, Valid: 72.88% Test: 59.46%\n",
      "Run: 05, Epoch: 29, Loss: 0.7476, Train: 62.07%, Valid: 74.58% Test: 59.46%\n",
      "Run: 05, Epoch: 30, Loss: 0.7574, Train: 66.67%, Valid: 77.97% Test: 62.16%\n",
      "Run: 05, Epoch: 31, Loss: 0.7025, Train: 68.97%, Valid: 79.66% Test: 62.16%\n",
      "Run: 05, Epoch: 32, Loss: 0.7469, Train: 70.11%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 33, Loss: 0.6819, Train: 71.26%, Valid: 83.05% Test: 70.27%\n",
      "Run: 05, Epoch: 34, Loss: 0.6892, Train: 72.41%, Valid: 81.36% Test: 70.27%\n",
      "Run: 05, Epoch: 35, Loss: 0.6687, Train: 70.11%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 36, Loss: 0.6756, Train: 72.41%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 37, Loss: 0.6391, Train: 73.56%, Valid: 81.36% Test: 72.97%\n",
      "Run: 05, Epoch: 38, Loss: 0.6932, Train: 73.56%, Valid: 81.36% Test: 70.27%\n",
      "Run: 05, Epoch: 39, Loss: 0.6481, Train: 73.56%, Valid: 81.36% Test: 70.27%\n",
      "Run: 05, Epoch: 40, Loss: 0.6226, Train: 80.46%, Valid: 81.36% Test: 78.38%\n",
      "Run: 05, Epoch: 41, Loss: 0.6502, Train: 85.06%, Valid: 84.75% Test: 78.38%\n",
      "Run: 05, Epoch: 42, Loss: 0.6150, Train: 83.91%, Valid: 84.75% Test: 78.38%\n",
      "Run: 05, Epoch: 43, Loss: 0.6226, Train: 83.91%, Valid: 84.75% Test: 83.78%\n",
      "Run: 05, Epoch: 44, Loss: 0.5909, Train: 85.06%, Valid: 84.75% Test: 83.78%\n",
      "Run: 05, Epoch: 45, Loss: 0.5824, Train: 83.91%, Valid: 84.75% Test: 81.08%\n",
      "Run: 05, Epoch: 46, Loss: 0.6150, Train: 85.06%, Valid: 84.75% Test: 75.68%\n",
      "Run: 05, Epoch: 47, Loss: 0.5829, Train: 83.91%, Valid: 86.44% Test: 72.97%\n",
      "Run: 05, Epoch: 48, Loss: 0.6081, Train: 85.06%, Valid: 84.75% Test: 72.97%\n",
      "Run: 05, Epoch: 49, Loss: 0.5654, Train: 85.06%, Valid: 84.75% Test: 81.08%\n",
      "Run: 05, Epoch: 50, Loss: 0.5664, Train: 80.46%, Valid: 86.44% Test: 75.68%\n",
      "Run: 05, Epoch: 51, Loss: 0.5733, Train: 80.46%, Valid: 86.44% Test: 78.38%\n",
      "Run: 05, Epoch: 52, Loss: 0.5795, Train: 79.31%, Valid: 84.75% Test: 75.68%\n",
      "Run: 05, Epoch: 53, Loss: 0.5296, Train: 75.86%, Valid: 81.36% Test: 75.68%\n",
      "Run: 05, Epoch: 54, Loss: 0.5326, Train: 83.91%, Valid: 86.44% Test: 86.49%\n",
      "Run: 05, Epoch: 55, Loss: 0.5276, Train: 86.21%, Valid: 88.14% Test: 78.38%\n",
      "Run: 05, Epoch: 56, Loss: 0.5236, Train: 88.51%, Valid: 86.44% Test: 78.38%\n",
      "Run: 05, Epoch: 57, Loss: 0.5213, Train: 87.36%, Valid: 86.44% Test: 78.38%\n",
      "Run: 05, Epoch: 58, Loss: 0.5104, Train: 82.76%, Valid: 84.75% Test: 78.38%\n",
      "Run: 05, Epoch: 59, Loss: 0.5246, Train: 86.21%, Valid: 86.44% Test: 75.68%\n",
      "Run: 05, Epoch: 60, Loss: 0.5228, Train: 88.51%, Valid: 86.44% Test: 78.38%\n",
      "Run: 05, Epoch: 61, Loss: 0.5738, Train: 87.36%, Valid: 91.53% Test: 83.78%\n",
      "Run: 05, Epoch: 62, Loss: 0.5166, Train: 83.91%, Valid: 89.83% Test: 86.49%\n",
      "Run: 05, Epoch: 63, Loss: 0.4825, Train: 82.76%, Valid: 88.14% Test: 81.08%\n",
      "Run: 05, Epoch: 64, Loss: 0.5090, Train: 77.01%, Valid: 84.75% Test: 78.38%\n",
      "Run: 05, Epoch: 65, Loss: 0.4712, Train: 75.86%, Valid: 84.75% Test: 75.68%\n",
      "Run: 05, Epoch: 66, Loss: 0.5053, Train: 81.61%, Valid: 83.05% Test: 78.38%\n",
      "Run: 05, Epoch: 67, Loss: 0.4780, Train: 90.80%, Valid: 91.53% Test: 86.49%\n",
      "Run: 05, Epoch: 68, Loss: 0.4859, Train: 93.10%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 69, Loss: 0.5019, Train: 88.51%, Valid: 89.83% Test: 89.19%\n",
      "Run: 05, Epoch: 70, Loss: 0.5925, Train: 90.80%, Valid: 89.83% Test: 86.49%\n",
      "Run: 05, Epoch: 71, Loss: 0.4245, Train: 93.10%, Valid: 91.53% Test: 83.78%\n",
      "Run: 05, Epoch: 72, Loss: 0.4332, Train: 95.40%, Valid: 93.22% Test: 89.19%\n",
      "Run: 05, Epoch: 73, Loss: 0.4069, Train: 95.40%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 74, Loss: 0.4451, Train: 95.40%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 75, Loss: 0.4323, Train: 95.40%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 76, Loss: 0.4110, Train: 95.40%, Valid: 98.31% Test: 86.49%\n",
      "Run: 05, Epoch: 77, Loss: 0.4633, Train: 96.55%, Valid: 98.31% Test: 86.49%\n",
      "Run: 05, Epoch: 78, Loss: 0.4285, Train: 96.55%, Valid: 98.31% Test: 86.49%\n",
      "Run: 05, Epoch: 79, Loss: 0.4112, Train: 94.25%, Valid: 98.31% Test: 86.49%\n",
      "Run: 05, Epoch: 80, Loss: 0.4441, Train: 91.95%, Valid: 98.31% Test: 86.49%\n",
      "Run: 05, Epoch: 81, Loss: 0.4305, Train: 91.95%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 82, Loss: 0.4038, Train: 91.95%, Valid: 93.22% Test: 86.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 83, Loss: 0.4103, Train: 90.80%, Valid: 88.14% Test: 83.78%\n",
      "Run: 05, Epoch: 84, Loss: 0.4507, Train: 87.36%, Valid: 83.05% Test: 83.78%\n",
      "Run: 05, Epoch: 85, Loss: 0.4550, Train: 86.21%, Valid: 86.44% Test: 83.78%\n",
      "Run: 05, Epoch: 86, Loss: 0.3814, Train: 89.66%, Valid: 88.14% Test: 83.78%\n",
      "Run: 05, Epoch: 87, Loss: 0.4751, Train: 91.95%, Valid: 89.83% Test: 83.78%\n",
      "Run: 05, Epoch: 88, Loss: 0.4692, Train: 93.10%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 89, Loss: 0.3533, Train: 95.40%, Valid: 93.22% Test: 86.49%\n",
      "Run: 05, Epoch: 90, Loss: 0.4130, Train: 96.55%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 91, Loss: 0.4343, Train: 96.55%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 92, Loss: 0.3531, Train: 95.40%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 93, Loss: 0.3906, Train: 88.51%, Valid: 98.31% Test: 89.19%\n",
      "Run: 05, Epoch: 94, Loss: 0.3789, Train: 86.21%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 95, Loss: 0.3478, Train: 88.51%, Valid: 91.53% Test: 89.19%\n",
      "Run: 05, Epoch: 96, Loss: 0.3482, Train: 87.36%, Valid: 89.83% Test: 89.19%\n",
      "Run: 05, Epoch: 97, Loss: 0.3902, Train: 90.80%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 98, Loss: 0.3517, Train: 93.10%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 99, Loss: 0.4165, Train: 96.55%, Valid: 93.22% Test: 89.19%\n",
      "Run: 05, Epoch: 100, Loss: 0.3756, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 05, Epoch: 101, Loss: 0.3811, Train: 96.55%, Valid: 93.22% Test: 89.19%\n",
      "Run: 05, Epoch: 102, Loss: 0.3060, Train: 96.55%, Valid: 93.22% Test: 81.08%\n",
      "Run: 05, Epoch: 103, Loss: 0.3697, Train: 96.55%, Valid: 93.22% Test: 81.08%\n",
      "Run: 05, Epoch: 104, Loss: 0.3283, Train: 95.40%, Valid: 91.53% Test: 83.78%\n",
      "Run: 05, Epoch: 105, Loss: 0.3889, Train: 95.40%, Valid: 91.53% Test: 81.08%\n",
      "Run: 05, Epoch: 106, Loss: 0.3231, Train: 95.40%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 107, Loss: 0.3740, Train: 95.40%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 108, Loss: 0.3732, Train: 96.55%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 109, Loss: 0.3307, Train: 96.55%, Valid: 98.31% Test: 86.49%\n",
      "Run: 05, Epoch: 110, Loss: 0.2876, Train: 94.25%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 111, Loss: 0.3515, Train: 91.95%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 112, Loss: 0.3304, Train: 91.95%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 113, Loss: 0.3379, Train: 94.25%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 114, Loss: 0.2764, Train: 95.40%, Valid: 98.31% Test: 89.19%\n",
      "Run: 05, Epoch: 115, Loss: 0.3287, Train: 96.55%, Valid: 98.31% Test: 91.89%\n",
      "Run: 05, Epoch: 116, Loss: 0.3449, Train: 97.70%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 117, Loss: 0.3425, Train: 97.70%, Valid: 93.22% Test: 91.89%\n",
      "Run: 05, Epoch: 118, Loss: 0.3040, Train: 97.70%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 119, Loss: 0.3096, Train: 95.40%, Valid: 93.22% Test: 81.08%\n",
      "Run: 05, Epoch: 120, Loss: 0.3288, Train: 95.40%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 121, Loss: 0.2931, Train: 95.40%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 122, Loss: 0.2667, Train: 95.40%, Valid: 93.22% Test: 89.19%\n",
      "Run: 05, Epoch: 123, Loss: 0.2864, Train: 95.40%, Valid: 91.53% Test: 89.19%\n",
      "Run: 05, Epoch: 124, Loss: 0.3347, Train: 96.55%, Valid: 93.22% Test: 89.19%\n",
      "Run: 05, Epoch: 125, Loss: 0.3152, Train: 94.25%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 126, Loss: 0.3067, Train: 91.95%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 127, Loss: 0.3375, Train: 94.25%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 128, Loss: 0.3037, Train: 93.10%, Valid: 96.61% Test: 91.89%\n",
      "Run: 05, Epoch: 129, Loss: 0.2816, Train: 94.25%, Valid: 96.61% Test: 91.89%\n",
      "Run: 05, Epoch: 130, Loss: 0.3431, Train: 96.55%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 131, Loss: 0.2948, Train: 97.70%, Valid: 98.31% Test: 83.78%\n",
      "Run: 05, Epoch: 132, Loss: 0.2855, Train: 95.40%, Valid: 98.31% Test: 81.08%\n",
      "Run: 05, Epoch: 133, Loss: 0.2969, Train: 93.10%, Valid: 94.92% Test: 78.38%\n",
      "Run: 05, Epoch: 134, Loss: 0.3174, Train: 95.40%, Valid: 94.92% Test: 81.08%\n",
      "Run: 05, Epoch: 135, Loss: 0.3015, Train: 96.55%, Valid: 93.22% Test: 81.08%\n",
      "Run: 05, Epoch: 136, Loss: 0.2796, Train: 96.55%, Valid: 93.22% Test: 81.08%\n",
      "Run: 05, Epoch: 137, Loss: 0.2761, Train: 97.70%, Valid: 93.22% Test: 78.38%\n",
      "Run: 05, Epoch: 138, Loss: 0.3033, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 05, Epoch: 139, Loss: 0.3671, Train: 94.25%, Valid: 91.53% Test: 78.38%\n",
      "Run: 05, Epoch: 140, Loss: 0.2651, Train: 88.51%, Valid: 89.83% Test: 78.38%\n",
      "Run: 05, Epoch: 141, Loss: 0.3386, Train: 89.66%, Valid: 89.83% Test: 78.38%\n",
      "Run: 05, Epoch: 142, Loss: 0.2853, Train: 95.40%, Valid: 91.53% Test: 81.08%\n",
      "Run: 05, Epoch: 143, Loss: 0.3195, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 05, Epoch: 144, Loss: 0.3269, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 145, Loss: 0.3005, Train: 98.85%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 146, Loss: 0.2826, Train: 97.70%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 147, Loss: 0.2970, Train: 96.55%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 148, Loss: 0.2985, Train: 91.95%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 149, Loss: 0.2751, Train: 90.80%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 150, Loss: 0.2872, Train: 90.80%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 151, Loss: 0.2600, Train: 90.80%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 152, Loss: 0.1958, Train: 90.80%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 153, Loss: 0.2922, Train: 91.95%, Valid: 94.92% Test: 86.49%\n",
      "Run: 05, Epoch: 154, Loss: 0.3038, Train: 94.25%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 155, Loss: 0.2493, Train: 95.40%, Valid: 93.22% Test: 81.08%\n",
      "Run: 05, Epoch: 156, Loss: 0.2538, Train: 96.55%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 157, Loss: 0.2549, Train: 96.55%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 158, Loss: 0.2213, Train: 96.55%, Valid: 98.31% Test: 83.78%\n",
      "Run: 05, Epoch: 159, Loss: 0.2489, Train: 96.55%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 160, Loss: 0.3135, Train: 96.55%, Valid: 98.31% Test: 81.08%\n",
      "Run: 05, Epoch: 161, Loss: 0.2829, Train: 97.70%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 162, Loss: 0.2737, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 163, Loss: 0.2689, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 164, Loss: 0.2468, Train: 97.70%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 165, Loss: 0.2319, Train: 97.70%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 166, Loss: 0.3076, Train: 97.70%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 167, Loss: 0.2445, Train: 96.55%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 168, Loss: 0.2671, Train: 95.40%, Valid: 93.22% Test: 86.49%\n",
      "Run: 05, Epoch: 169, Loss: 0.2440, Train: 95.40%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 170, Loss: 0.2351, Train: 95.40%, Valid: 94.92% Test: 89.19%\n",
      "Run: 05, Epoch: 171, Loss: 0.2343, Train: 96.55%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 172, Loss: 0.2254, Train: 96.55%, Valid: 96.61% Test: 89.19%\n",
      "Run: 05, Epoch: 173, Loss: 0.2485, Train: 96.55%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 174, Loss: 0.2247, Train: 95.40%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 175, Loss: 0.2194, Train: 96.55%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 176, Loss: 0.2707, Train: 98.85%, Valid: 93.22% Test: 86.49%\n",
      "Run: 05, Epoch: 177, Loss: 0.2864, Train: 98.85%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 178, Loss: 0.2221, Train: 96.55%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 179, Loss: 0.1909, Train: 88.51%, Valid: 94.92% Test: 75.68%\n",
      "Run: 05, Epoch: 180, Loss: 0.2219, Train: 88.51%, Valid: 89.83% Test: 75.68%\n",
      "Run: 05, Epoch: 181, Loss: 0.2651, Train: 82.76%, Valid: 84.75% Test: 64.86%\n",
      "Run: 05, Epoch: 182, Loss: 0.2610, Train: 81.61%, Valid: 84.75% Test: 64.86%\n",
      "Run: 05, Epoch: 183, Loss: 0.2435, Train: 86.21%, Valid: 84.75% Test: 72.97%\n",
      "Run: 05, Epoch: 184, Loss: 0.2430, Train: 93.10%, Valid: 96.61% Test: 78.38%\n",
      "Run: 05, Epoch: 185, Loss: 0.2174, Train: 97.70%, Valid: 98.31% Test: 89.19%\n",
      "Run: 05, Epoch: 186, Loss: 0.2096, Train: 98.85%, Valid: 96.61% Test: 86.49%\n",
      "Run: 05, Epoch: 187, Loss: 0.1719, Train: 98.85%, Valid: 93.22% Test: 86.49%\n",
      "Run: 05, Epoch: 188, Loss: 0.1828, Train: 96.55%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 189, Loss: 0.2087, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 05, Epoch: 190, Loss: 0.2306, Train: 94.25%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 191, Loss: 0.1892, Train: 93.10%, Valid: 94.92% Test: 81.08%\n",
      "Run: 05, Epoch: 192, Loss: 0.2610, Train: 93.10%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 193, Loss: 0.1917, Train: 91.95%, Valid: 93.22% Test: 83.78%\n",
      "Run: 05, Epoch: 194, Loss: 0.2460, Train: 91.95%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 195, Loss: 0.2512, Train: 91.95%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 196, Loss: 0.2174, Train: 96.55%, Valid: 96.61% Test: 83.78%\n",
      "Run: 05, Epoch: 197, Loss: 0.1930, Train: 98.85%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 198, Loss: 0.2314, Train: 98.85%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 199, Loss: 0.2053, Train: 98.85%, Valid: 94.92% Test: 83.78%\n",
      "Run: 05, Epoch: 200, Loss: 0.2227, Train: 98.85%, Valid: 94.92% Test: 83.78%\n",
      "Run 05:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 98.31\n",
      "  Final Train: 95.40\n",
      "   Final Test: 86.49\n",
      "Run: 06, Epoch: 01, Loss: 1.6892, Train: 1.15%, Valid: 0.00% Test: 0.00%\n",
      "Run: 06, Epoch: 02, Loss: 1.6497, Train: 1.15%, Valid: 0.00% Test: 0.00%\n",
      "Run: 06, Epoch: 03, Loss: 1.5836, Train: 1.15%, Valid: 0.00% Test: 0.00%\n",
      "Run: 06, Epoch: 04, Loss: 1.5291, Train: 27.59%, Valid: 37.29% Test: 32.43%\n",
      "Run: 06, Epoch: 05, Loss: 1.4799, Train: 51.72%, Valid: 57.63% Test: 54.05%\n",
      "Run: 06, Epoch: 06, Loss: 1.4137, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 07, Loss: 1.4394, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 08, Loss: 1.3217, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 09, Loss: 1.2985, Train: 51.72%, Valid: 59.32% Test: 56.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 10, Loss: 1.2648, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 11, Loss: 1.1909, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 12, Loss: 1.1690, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 13, Loss: 1.1557, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 14, Loss: 1.0957, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 15, Loss: 1.1096, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 16, Loss: 1.0722, Train: 52.87%, Valid: 61.02% Test: 56.76%\n",
      "Run: 06, Epoch: 17, Loss: 1.0207, Train: 52.87%, Valid: 61.02% Test: 56.76%\n",
      "Run: 06, Epoch: 18, Loss: 1.0214, Train: 54.02%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 19, Loss: 0.9999, Train: 52.87%, Valid: 57.63% Test: 56.76%\n",
      "Run: 06, Epoch: 20, Loss: 0.9781, Train: 52.87%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 21, Loss: 0.9476, Train: 52.87%, Valid: 61.02% Test: 56.76%\n",
      "Run: 06, Epoch: 22, Loss: 0.9218, Train: 54.02%, Valid: 62.71% Test: 56.76%\n",
      "Run: 06, Epoch: 23, Loss: 0.8973, Train: 56.32%, Valid: 62.71% Test: 56.76%\n",
      "Run: 06, Epoch: 24, Loss: 0.8731, Train: 57.47%, Valid: 61.02% Test: 56.76%\n",
      "Run: 06, Epoch: 25, Loss: 0.8416, Train: 60.92%, Valid: 62.71% Test: 54.05%\n",
      "Run: 06, Epoch: 26, Loss: 0.8788, Train: 63.22%, Valid: 62.71% Test: 59.46%\n",
      "Run: 06, Epoch: 27, Loss: 0.8459, Train: 63.22%, Valid: 66.10% Test: 64.86%\n",
      "Run: 06, Epoch: 28, Loss: 0.8407, Train: 64.37%, Valid: 66.10% Test: 64.86%\n",
      "Run: 06, Epoch: 29, Loss: 0.8219, Train: 66.67%, Valid: 66.10% Test: 67.57%\n",
      "Run: 06, Epoch: 30, Loss: 0.8110, Train: 70.11%, Valid: 69.49% Test: 67.57%\n",
      "Run: 06, Epoch: 31, Loss: 0.7987, Train: 70.11%, Valid: 69.49% Test: 67.57%\n",
      "Run: 06, Epoch: 32, Loss: 0.8104, Train: 70.11%, Valid: 71.19% Test: 67.57%\n",
      "Run: 06, Epoch: 33, Loss: 0.7585, Train: 70.11%, Valid: 69.49% Test: 64.86%\n",
      "Run: 06, Epoch: 34, Loss: 0.7613, Train: 70.11%, Valid: 67.80% Test: 64.86%\n",
      "Run: 06, Epoch: 35, Loss: 0.7453, Train: 70.11%, Valid: 67.80% Test: 67.57%\n",
      "Run: 06, Epoch: 36, Loss: 0.7197, Train: 67.82%, Valid: 69.49% Test: 67.57%\n",
      "Run: 06, Epoch: 37, Loss: 0.7308, Train: 68.97%, Valid: 69.49% Test: 70.27%\n",
      "Run: 06, Epoch: 38, Loss: 0.7098, Train: 68.97%, Valid: 69.49% Test: 67.57%\n",
      "Run: 06, Epoch: 39, Loss: 0.7086, Train: 71.26%, Valid: 71.19% Test: 70.27%\n",
      "Run: 06, Epoch: 40, Loss: 0.6641, Train: 72.41%, Valid: 69.49% Test: 64.86%\n",
      "Run: 06, Epoch: 41, Loss: 0.6862, Train: 74.71%, Valid: 71.19% Test: 67.57%\n",
      "Run: 06, Epoch: 42, Loss: 0.6715, Train: 80.46%, Valid: 76.27% Test: 72.97%\n",
      "Run: 06, Epoch: 43, Loss: 0.6736, Train: 82.76%, Valid: 79.66% Test: 75.68%\n",
      "Run: 06, Epoch: 44, Loss: 0.6373, Train: 82.76%, Valid: 81.36% Test: 75.68%\n",
      "Run: 06, Epoch: 45, Loss: 0.6665, Train: 82.76%, Valid: 76.27% Test: 75.68%\n",
      "Run: 06, Epoch: 46, Loss: 0.6428, Train: 80.46%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 47, Loss: 0.6520, Train: 79.31%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 48, Loss: 0.6248, Train: 74.71%, Valid: 69.49% Test: 75.68%\n",
      "Run: 06, Epoch: 49, Loss: 0.5909, Train: 70.11%, Valid: 66.10% Test: 67.57%\n",
      "Run: 06, Epoch: 50, Loss: 0.5954, Train: 66.67%, Valid: 69.49% Test: 67.57%\n",
      "Run: 06, Epoch: 51, Loss: 0.6545, Train: 71.26%, Valid: 74.58% Test: 72.97%\n",
      "Run: 06, Epoch: 52, Loss: 0.7119, Train: 74.71%, Valid: 74.58% Test: 72.97%\n",
      "Run: 06, Epoch: 53, Loss: 0.5932, Train: 81.61%, Valid: 79.66% Test: 72.97%\n",
      "Run: 06, Epoch: 54, Loss: 0.5800, Train: 83.91%, Valid: 83.05% Test: 72.97%\n",
      "Run: 06, Epoch: 55, Loss: 0.5762, Train: 86.21%, Valid: 83.05% Test: 72.97%\n",
      "Run: 06, Epoch: 56, Loss: 0.5653, Train: 86.21%, Valid: 84.75% Test: 72.97%\n",
      "Run: 06, Epoch: 57, Loss: 0.5724, Train: 87.36%, Valid: 86.44% Test: 72.97%\n",
      "Run: 06, Epoch: 58, Loss: 0.6296, Train: 87.36%, Valid: 89.83% Test: 78.38%\n",
      "Run: 06, Epoch: 59, Loss: 0.5776, Train: 86.21%, Valid: 88.14% Test: 78.38%\n",
      "Run: 06, Epoch: 60, Loss: 0.5356, Train: 83.91%, Valid: 86.44% Test: 78.38%\n",
      "Run: 06, Epoch: 61, Loss: 0.5205, Train: 80.46%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 62, Loss: 0.5439, Train: 79.31%, Valid: 72.88% Test: 81.08%\n",
      "Run: 06, Epoch: 63, Loss: 0.5866, Train: 82.76%, Valid: 74.58% Test: 81.08%\n",
      "Run: 06, Epoch: 64, Loss: 0.5649, Train: 86.21%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 65, Loss: 0.5950, Train: 86.21%, Valid: 88.14% Test: 81.08%\n",
      "Run: 06, Epoch: 66, Loss: 0.5280, Train: 89.66%, Valid: 84.75% Test: 75.68%\n",
      "Run: 06, Epoch: 67, Loss: 0.5169, Train: 87.36%, Valid: 83.05% Test: 75.68%\n",
      "Run: 06, Epoch: 68, Loss: 0.5293, Train: 85.06%, Valid: 83.05% Test: 75.68%\n",
      "Run: 06, Epoch: 69, Loss: 0.4607, Train: 82.76%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 70, Loss: 0.5079, Train: 83.91%, Valid: 79.66% Test: 75.68%\n",
      "Run: 06, Epoch: 71, Loss: 0.5068, Train: 81.61%, Valid: 76.27% Test: 72.97%\n",
      "Run: 06, Epoch: 72, Loss: 0.4811, Train: 75.86%, Valid: 72.88% Test: 72.97%\n",
      "Run: 06, Epoch: 73, Loss: 0.5216, Train: 74.71%, Valid: 71.19% Test: 72.97%\n",
      "Run: 06, Epoch: 74, Loss: 0.4715, Train: 73.56%, Valid: 71.19% Test: 72.97%\n",
      "Run: 06, Epoch: 75, Loss: 0.4983, Train: 77.01%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 76, Loss: 0.5292, Train: 81.61%, Valid: 76.27% Test: 75.68%\n",
      "Run: 06, Epoch: 77, Loss: 0.4368, Train: 86.21%, Valid: 83.05% Test: 78.38%\n",
      "Run: 06, Epoch: 78, Loss: 0.4566, Train: 87.36%, Valid: 89.83% Test: 78.38%\n",
      "Run: 06, Epoch: 79, Loss: 0.5012, Train: 89.66%, Valid: 91.53% Test: 78.38%\n",
      "Run: 06, Epoch: 80, Loss: 0.4737, Train: 91.95%, Valid: 93.22% Test: 78.38%\n",
      "Run: 06, Epoch: 81, Loss: 0.4822, Train: 93.10%, Valid: 93.22% Test: 78.38%\n",
      "Run: 06, Epoch: 82, Loss: 0.4698, Train: 93.10%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 83, Loss: 0.4662, Train: 94.25%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 84, Loss: 0.4227, Train: 91.95%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 85, Loss: 0.4886, Train: 90.80%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 86, Loss: 0.4602, Train: 93.10%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 87, Loss: 0.4495, Train: 93.10%, Valid: 86.44% Test: 83.78%\n",
      "Run: 06, Epoch: 88, Loss: 0.4186, Train: 93.10%, Valid: 83.05% Test: 83.78%\n",
      "Run: 06, Epoch: 89, Loss: 0.4175, Train: 93.10%, Valid: 88.14% Test: 83.78%\n",
      "Run: 06, Epoch: 90, Loss: 0.4103, Train: 93.10%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 91, Loss: 0.3874, Train: 93.10%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 92, Loss: 0.4429, Train: 94.25%, Valid: 94.92% Test: 81.08%\n",
      "Run: 06, Epoch: 93, Loss: 0.3796, Train: 95.40%, Valid: 98.31% Test: 81.08%\n",
      "Run: 06, Epoch: 94, Loss: 0.3964, Train: 95.40%, Valid: 98.31% Test: 83.78%\n",
      "Run: 06, Epoch: 95, Loss: 0.4405, Train: 96.55%, Valid: 98.31% Test: 83.78%\n",
      "Run: 06, Epoch: 96, Loss: 0.4057, Train: 95.40%, Valid: 98.31% Test: 86.49%\n",
      "Run: 06, Epoch: 97, Loss: 0.4192, Train: 96.55%, Valid: 98.31% Test: 86.49%\n",
      "Run: 06, Epoch: 98, Loss: 0.3849, Train: 97.70%, Valid: 96.61% Test: 83.78%\n",
      "Run: 06, Epoch: 99, Loss: 0.4008, Train: 97.70%, Valid: 96.61% Test: 83.78%\n",
      "Run: 06, Epoch: 100, Loss: 0.4427, Train: 97.70%, Valid: 96.61% Test: 81.08%\n",
      "Run: 06, Epoch: 101, Loss: 0.3787, Train: 98.85%, Valid: 94.92% Test: 81.08%\n",
      "Run: 06, Epoch: 102, Loss: 0.4323, Train: 98.85%, Valid: 94.92% Test: 83.78%\n",
      "Run: 06, Epoch: 103, Loss: 0.4509, Train: 97.70%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 104, Loss: 0.3764, Train: 96.55%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 105, Loss: 0.3468, Train: 96.55%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 106, Loss: 0.3789, Train: 94.25%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 107, Loss: 0.4245, Train: 93.10%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 108, Loss: 0.4274, Train: 95.40%, Valid: 89.83% Test: 81.08%\n",
      "Run: 06, Epoch: 109, Loss: 0.3560, Train: 94.25%, Valid: 89.83% Test: 81.08%\n",
      "Run: 06, Epoch: 110, Loss: 0.3585, Train: 94.25%, Valid: 88.14% Test: 81.08%\n",
      "Run: 06, Epoch: 111, Loss: 0.3734, Train: 95.40%, Valid: 89.83% Test: 81.08%\n",
      "Run: 06, Epoch: 112, Loss: 0.3744, Train: 97.70%, Valid: 93.22% Test: 81.08%\n",
      "Run: 06, Epoch: 113, Loss: 0.3502, Train: 98.85%, Valid: 93.22% Test: 81.08%\n",
      "Run: 06, Epoch: 114, Loss: 0.3562, Train: 98.85%, Valid: 93.22% Test: 81.08%\n",
      "Run: 06, Epoch: 115, Loss: 0.3476, Train: 98.85%, Valid: 93.22% Test: 81.08%\n",
      "Run: 06, Epoch: 116, Loss: 0.3047, Train: 97.70%, Valid: 93.22% Test: 81.08%\n",
      "Run: 06, Epoch: 117, Loss: 0.3228, Train: 96.55%, Valid: 94.92% Test: 83.78%\n",
      "Run: 06, Epoch: 118, Loss: 0.3293, Train: 96.55%, Valid: 94.92% Test: 83.78%\n",
      "Run: 06, Epoch: 119, Loss: 0.3400, Train: 96.55%, Valid: 96.61% Test: 83.78%\n",
      "Run: 06, Epoch: 120, Loss: 0.4286, Train: 97.70%, Valid: 96.61% Test: 86.49%\n",
      "Run: 06, Epoch: 121, Loss: 0.3453, Train: 96.55%, Valid: 94.92% Test: 91.89%\n",
      "Run: 06, Epoch: 122, Loss: 0.3693, Train: 96.55%, Valid: 94.92% Test: 91.89%\n",
      "Run: 06, Epoch: 123, Loss: 0.3439, Train: 97.70%, Valid: 96.61% Test: 89.19%\n",
      "Run: 06, Epoch: 124, Loss: 0.3454, Train: 97.70%, Valid: 94.92% Test: 89.19%\n",
      "Run: 06, Epoch: 125, Loss: 0.3782, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 06, Epoch: 126, Loss: 0.3536, Train: 97.70%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 127, Loss: 0.3622, Train: 96.55%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 128, Loss: 0.3307, Train: 96.55%, Valid: 89.83% Test: 81.08%\n",
      "Run: 06, Epoch: 129, Loss: 0.3627, Train: 96.55%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 130, Loss: 0.3030, Train: 95.40%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 131, Loss: 0.3770, Train: 93.10%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 132, Loss: 0.3331, Train: 90.80%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 133, Loss: 0.3480, Train: 88.51%, Valid: 91.53% Test: 83.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 134, Loss: 0.3155, Train: 88.51%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 135, Loss: 0.3013, Train: 88.51%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 136, Loss: 0.2783, Train: 88.51%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 137, Loss: 0.3209, Train: 87.36%, Valid: 88.14% Test: 81.08%\n",
      "Run: 06, Epoch: 138, Loss: 0.2685, Train: 91.95%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 139, Loss: 0.3147, Train: 93.10%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 140, Loss: 0.2585, Train: 94.25%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 141, Loss: 0.3485, Train: 95.40%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 142, Loss: 0.3073, Train: 96.55%, Valid: 94.92% Test: 91.89%\n",
      "Run: 06, Epoch: 143, Loss: 0.3362, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 06, Epoch: 144, Loss: 0.3042, Train: 97.70%, Valid: 94.92% Test: 81.08%\n",
      "Run: 06, Epoch: 145, Loss: 0.2387, Train: 96.55%, Valid: 91.53% Test: 81.08%\n",
      "Run: 06, Epoch: 146, Loss: 0.2812, Train: 97.70%, Valid: 91.53% Test: 83.78%\n",
      "Run: 06, Epoch: 147, Loss: 0.3131, Train: 98.85%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 148, Loss: 0.3020, Train: 98.85%, Valid: 93.22% Test: 81.08%\n",
      "Run: 06, Epoch: 149, Loss: 0.2997, Train: 98.85%, Valid: 93.22% Test: 78.38%\n",
      "Run: 06, Epoch: 150, Loss: 0.2081, Train: 97.70%, Valid: 94.92% Test: 86.49%\n",
      "Run: 06, Epoch: 151, Loss: 0.2806, Train: 96.55%, Valid: 94.92% Test: 86.49%\n",
      "Run: 06, Epoch: 152, Loss: 0.2984, Train: 96.55%, Valid: 93.22% Test: 83.78%\n",
      "Run: 06, Epoch: 153, Loss: 0.2920, Train: 94.25%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 154, Loss: 0.2805, Train: 94.25%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 155, Loss: 0.2446, Train: 93.10%, Valid: 89.83% Test: 83.78%\n",
      "Run: 06, Epoch: 156, Loss: 0.2526, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 06, Epoch: 157, Loss: 0.2500, Train: 91.95%, Valid: 84.75% Test: 86.49%\n",
      "Run: 06, Epoch: 158, Loss: 0.2293, Train: 94.25%, Valid: 89.83% Test: 86.49%\n",
      "Run: 06, Epoch: 159, Loss: 0.2993, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 160, Loss: 0.2603, Train: 97.70%, Valid: 93.22% Test: 91.89%\n",
      "Run: 06, Epoch: 161, Loss: 0.2975, Train: 97.70%, Valid: 94.92% Test: 89.19%\n",
      "Run: 06, Epoch: 162, Loss: 0.2793, Train: 97.70%, Valid: 94.92% Test: 89.19%\n",
      "Run: 06, Epoch: 163, Loss: 0.2563, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 06, Epoch: 164, Loss: 0.3525, Train: 97.70%, Valid: 96.61% Test: 89.19%\n",
      "Run: 06, Epoch: 165, Loss: 0.1967, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 06, Epoch: 166, Loss: 0.2798, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 06, Epoch: 167, Loss: 0.2771, Train: 98.85%, Valid: 91.53% Test: 89.19%\n",
      "Run: 06, Epoch: 168, Loss: 0.2166, Train: 98.85%, Valid: 91.53% Test: 89.19%\n",
      "Run: 06, Epoch: 169, Loss: 0.3115, Train: 98.85%, Valid: 91.53% Test: 89.19%\n",
      "Run: 06, Epoch: 170, Loss: 0.2102, Train: 98.85%, Valid: 91.53% Test: 89.19%\n",
      "Run: 06, Epoch: 171, Loss: 0.3338, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 06, Epoch: 172, Loss: 0.2905, Train: 97.70%, Valid: 94.92% Test: 86.49%\n",
      "Run: 06, Epoch: 173, Loss: 0.2413, Train: 97.70%, Valid: 94.92% Test: 86.49%\n",
      "Run: 06, Epoch: 174, Loss: 0.2396, Train: 97.70%, Valid: 94.92% Test: 91.89%\n",
      "Run: 06, Epoch: 175, Loss: 0.2846, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 06, Epoch: 176, Loss: 0.2633, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 06, Epoch: 177, Loss: 0.2301, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 06, Epoch: 178, Loss: 0.2196, Train: 98.85%, Valid: 96.61% Test: 91.89%\n",
      "Run: 06, Epoch: 179, Loss: 0.2225, Train: 98.85%, Valid: 96.61% Test: 91.89%\n",
      "Run: 06, Epoch: 180, Loss: 0.2562, Train: 98.85%, Valid: 96.61% Test: 89.19%\n",
      "Run: 06, Epoch: 181, Loss: 0.2524, Train: 98.85%, Valid: 96.61% Test: 91.89%\n",
      "Run: 06, Epoch: 182, Loss: 0.2825, Train: 98.85%, Valid: 94.92% Test: 89.19%\n",
      "Run: 06, Epoch: 183, Loss: 0.2457, Train: 96.55%, Valid: 93.22% Test: 89.19%\n",
      "Run: 06, Epoch: 184, Loss: 0.2185, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 185, Loss: 0.2389, Train: 96.55%, Valid: 89.83% Test: 86.49%\n",
      "Run: 06, Epoch: 186, Loss: 0.2679, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 187, Loss: 0.1973, Train: 94.25%, Valid: 88.14% Test: 89.19%\n",
      "Run: 06, Epoch: 188, Loss: 0.2368, Train: 94.25%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 189, Loss: 0.1972, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 190, Loss: 0.2305, Train: 96.55%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 191, Loss: 0.2094, Train: 96.55%, Valid: 89.83% Test: 86.49%\n",
      "Run: 06, Epoch: 192, Loss: 0.2288, Train: 96.55%, Valid: 89.83% Test: 86.49%\n",
      "Run: 06, Epoch: 193, Loss: 0.2169, Train: 96.55%, Valid: 91.53% Test: 89.19%\n",
      "Run: 06, Epoch: 194, Loss: 0.2730, Train: 97.70%, Valid: 94.92% Test: 89.19%\n",
      "Run: 06, Epoch: 195, Loss: 0.3385, Train: 96.55%, Valid: 94.92% Test: 94.59%\n",
      "Run: 06, Epoch: 196, Loss: 0.2880, Train: 96.55%, Valid: 94.92% Test: 89.19%\n",
      "Run: 06, Epoch: 197, Loss: 0.3306, Train: 95.40%, Valid: 91.53% Test: 89.19%\n",
      "Run: 06, Epoch: 198, Loss: 0.2492, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 06, Epoch: 199, Loss: 0.2189, Train: 95.40%, Valid: 93.22% Test: 86.49%\n",
      "Run: 06, Epoch: 200, Loss: 0.2162, Train: 95.40%, Valid: 93.22% Test: 86.49%\n",
      "Run 06:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 98.31\n",
      "  Final Train: 95.40\n",
      "   Final Test: 81.08\n",
      "Run: 07, Epoch: 01, Loss: 1.4230, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 02, Loss: 1.3709, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 03, Loss: 1.3599, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 04, Loss: 1.3011, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 05, Loss: 1.2300, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 06, Loss: 1.2261, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 07, Loss: 1.1717, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 08, Loss: 1.1456, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 09, Loss: 1.0919, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 10, Loss: 1.0662, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 11, Loss: 1.0329, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 12, Loss: 1.0051, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 13, Loss: 0.9922, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 14, Loss: 1.0201, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 15, Loss: 0.9199, Train: 51.72%, Valid: 61.02% Test: 56.76%\n",
      "Run: 07, Epoch: 16, Loss: 0.9030, Train: 51.72%, Valid: 61.02% Test: 56.76%\n",
      "Run: 07, Epoch: 17, Loss: 0.8938, Train: 51.72%, Valid: 62.71% Test: 56.76%\n",
      "Run: 07, Epoch: 18, Loss: 0.8815, Train: 55.17%, Valid: 62.71% Test: 56.76%\n",
      "Run: 07, Epoch: 19, Loss: 0.8969, Train: 55.17%, Valid: 62.71% Test: 56.76%\n",
      "Run: 07, Epoch: 20, Loss: 0.8406, Train: 55.17%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 21, Loss: 0.8382, Train: 58.62%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 22, Loss: 0.7986, Train: 58.62%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 23, Loss: 0.8082, Train: 59.77%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 24, Loss: 0.7978, Train: 62.07%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 25, Loss: 0.7853, Train: 59.77%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 26, Loss: 0.7583, Train: 62.07%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 27, Loss: 0.7580, Train: 60.92%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 28, Loss: 0.7517, Train: 60.92%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 29, Loss: 0.7254, Train: 60.92%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 30, Loss: 0.7258, Train: 62.07%, Valid: 64.41% Test: 56.76%\n",
      "Run: 07, Epoch: 31, Loss: 0.7339, Train: 63.22%, Valid: 64.41% Test: 59.46%\n",
      "Run: 07, Epoch: 32, Loss: 0.7305, Train: 65.52%, Valid: 69.49% Test: 59.46%\n",
      "Run: 07, Epoch: 33, Loss: 0.6857, Train: 67.82%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 34, Loss: 0.7028, Train: 68.97%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 35, Loss: 0.6838, Train: 72.41%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 36, Loss: 0.6291, Train: 72.41%, Valid: 77.97% Test: 64.86%\n",
      "Run: 07, Epoch: 37, Loss: 0.6784, Train: 73.56%, Valid: 77.97% Test: 64.86%\n",
      "Run: 07, Epoch: 38, Loss: 0.6659, Train: 77.01%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 39, Loss: 0.5893, Train: 78.16%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 40, Loss: 0.6029, Train: 78.16%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 41, Loss: 0.6229, Train: 78.16%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 42, Loss: 0.6259, Train: 78.16%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 43, Loss: 0.5648, Train: 78.16%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 44, Loss: 0.5838, Train: 78.16%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 45, Loss: 0.6071, Train: 79.31%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 46, Loss: 0.5855, Train: 81.61%, Valid: 81.36% Test: 64.86%\n",
      "Run: 07, Epoch: 47, Loss: 0.5207, Train: 86.21%, Valid: 77.97% Test: 72.97%\n",
      "Run: 07, Epoch: 48, Loss: 0.5301, Train: 88.51%, Valid: 81.36% Test: 78.38%\n",
      "Run: 07, Epoch: 49, Loss: 0.6096, Train: 89.66%, Valid: 84.75% Test: 75.68%\n",
      "Run: 07, Epoch: 50, Loss: 0.5798, Train: 90.80%, Valid: 88.14% Test: 78.38%\n",
      "Run: 07, Epoch: 51, Loss: 0.5399, Train: 89.66%, Valid: 83.05% Test: 81.08%\n",
      "Run: 07, Epoch: 52, Loss: 0.5507, Train: 89.66%, Valid: 81.36% Test: 72.97%\n",
      "Run: 07, Epoch: 53, Loss: 0.4917, Train: 79.31%, Valid: 77.97% Test: 70.27%\n",
      "Run: 07, Epoch: 54, Loss: 0.5340, Train: 88.51%, Valid: 79.66% Test: 72.97%\n",
      "Run: 07, Epoch: 55, Loss: 0.5193, Train: 91.95%, Valid: 79.66% Test: 75.68%\n",
      "Run: 07, Epoch: 56, Loss: 0.5086, Train: 93.10%, Valid: 83.05% Test: 78.38%\n",
      "Run: 07, Epoch: 57, Loss: 0.5080, Train: 94.25%, Valid: 83.05% Test: 81.08%\n",
      "Run: 07, Epoch: 58, Loss: 0.4851, Train: 93.10%, Valid: 83.05% Test: 81.08%\n",
      "Run: 07, Epoch: 59, Loss: 0.5170, Train: 90.80%, Valid: 83.05% Test: 78.38%\n",
      "Run: 07, Epoch: 60, Loss: 0.4602, Train: 88.51%, Valid: 81.36% Test: 78.38%\n",
      "Run: 07, Epoch: 61, Loss: 0.5061, Train: 88.51%, Valid: 84.75% Test: 78.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 62, Loss: 0.4976, Train: 87.36%, Valid: 83.05% Test: 75.68%\n",
      "Run: 07, Epoch: 63, Loss: 0.4411, Train: 86.21%, Valid: 81.36% Test: 75.68%\n",
      "Run: 07, Epoch: 64, Loss: 0.4523, Train: 86.21%, Valid: 79.66% Test: 75.68%\n",
      "Run: 07, Epoch: 65, Loss: 0.4206, Train: 91.95%, Valid: 77.97% Test: 75.68%\n",
      "Run: 07, Epoch: 66, Loss: 0.4039, Train: 91.95%, Valid: 79.66% Test: 78.38%\n",
      "Run: 07, Epoch: 67, Loss: 0.4422, Train: 93.10%, Valid: 81.36% Test: 81.08%\n",
      "Run: 07, Epoch: 68, Loss: 0.3979, Train: 93.10%, Valid: 88.14% Test: 86.49%\n",
      "Run: 07, Epoch: 69, Loss: 0.4838, Train: 94.25%, Valid: 88.14% Test: 89.19%\n",
      "Run: 07, Epoch: 70, Loss: 0.4369, Train: 95.40%, Valid: 86.44% Test: 89.19%\n",
      "Run: 07, Epoch: 71, Loss: 0.3930, Train: 95.40%, Valid: 89.83% Test: 89.19%\n",
      "Run: 07, Epoch: 72, Loss: 0.4168, Train: 96.55%, Valid: 88.14% Test: 86.49%\n",
      "Run: 07, Epoch: 73, Loss: 0.4695, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 07, Epoch: 74, Loss: 0.4141, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 07, Epoch: 75, Loss: 0.3902, Train: 95.40%, Valid: 88.14% Test: 86.49%\n",
      "Run: 07, Epoch: 76, Loss: 0.4532, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 07, Epoch: 77, Loss: 0.4430, Train: 96.55%, Valid: 94.92% Test: 86.49%\n",
      "Run: 07, Epoch: 78, Loss: 0.4690, Train: 95.40%, Valid: 93.22% Test: 91.89%\n",
      "Run: 07, Epoch: 79, Loss: 0.3540, Train: 95.40%, Valid: 91.53% Test: 89.19%\n",
      "Run: 07, Epoch: 80, Loss: 0.3532, Train: 93.10%, Valid: 88.14% Test: 86.49%\n",
      "Run: 07, Epoch: 81, Loss: 0.3804, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 07, Epoch: 82, Loss: 0.4139, Train: 91.95%, Valid: 81.36% Test: 70.27%\n",
      "Run: 07, Epoch: 83, Loss: 0.3747, Train: 86.21%, Valid: 79.66% Test: 72.97%\n",
      "Run: 07, Epoch: 84, Loss: 0.4138, Train: 87.36%, Valid: 79.66% Test: 75.68%\n",
      "Run: 07, Epoch: 85, Loss: 0.3830, Train: 85.06%, Valid: 77.97% Test: 75.68%\n",
      "Run: 07, Epoch: 86, Loss: 0.3488, Train: 86.21%, Valid: 77.97% Test: 75.68%\n",
      "Run: 07, Epoch: 87, Loss: 0.4457, Train: 90.80%, Valid: 83.05% Test: 78.38%\n",
      "Run: 07, Epoch: 88, Loss: 0.4016, Train: 96.55%, Valid: 84.75% Test: 86.49%\n",
      "Run: 07, Epoch: 89, Loss: 0.3944, Train: 98.85%, Valid: 88.14% Test: 91.89%\n",
      "Run: 07, Epoch: 90, Loss: 0.3458, Train: 98.85%, Valid: 86.44% Test: 94.59%\n",
      "Run: 07, Epoch: 91, Loss: 0.3355, Train: 97.70%, Valid: 83.05% Test: 89.19%\n",
      "Run: 07, Epoch: 92, Loss: 0.3975, Train: 95.40%, Valid: 84.75% Test: 91.89%\n",
      "Run: 07, Epoch: 93, Loss: 0.4164, Train: 93.10%, Valid: 83.05% Test: 91.89%\n",
      "Run: 07, Epoch: 94, Loss: 0.3391, Train: 95.40%, Valid: 86.44% Test: 91.89%\n",
      "Run: 07, Epoch: 95, Loss: 0.3795, Train: 96.55%, Valid: 91.53% Test: 91.89%\n",
      "Run: 07, Epoch: 96, Loss: 0.3668, Train: 95.40%, Valid: 86.44% Test: 86.49%\n",
      "Run: 07, Epoch: 97, Loss: 0.3237, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 07, Epoch: 98, Loss: 0.3449, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 07, Epoch: 99, Loss: 0.3837, Train: 95.40%, Valid: 86.44% Test: 86.49%\n",
      "Run: 07, Epoch: 100, Loss: 0.3482, Train: 96.55%, Valid: 88.14% Test: 86.49%\n",
      "Run: 07, Epoch: 101, Loss: 0.3662, Train: 95.40%, Valid: 96.61% Test: 91.89%\n",
      "Run: 07, Epoch: 102, Loss: 0.3538, Train: 95.40%, Valid: 93.22% Test: 91.89%\n",
      "Run: 07, Epoch: 103, Loss: 0.3809, Train: 96.55%, Valid: 89.83% Test: 86.49%\n",
      "Run: 07, Epoch: 104, Loss: 0.3338, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 07, Epoch: 105, Loss: 0.3614, Train: 95.40%, Valid: 91.53% Test: 89.19%\n",
      "Run: 07, Epoch: 106, Loss: 0.3164, Train: 95.40%, Valid: 89.83% Test: 89.19%\n",
      "Run: 07, Epoch: 107, Loss: 0.3177, Train: 95.40%, Valid: 84.75% Test: 83.78%\n",
      "Run: 07, Epoch: 108, Loss: 0.3062, Train: 90.80%, Valid: 84.75% Test: 78.38%\n",
      "Run: 07, Epoch: 109, Loss: 0.3061, Train: 86.21%, Valid: 88.14% Test: 78.38%\n",
      "Run: 07, Epoch: 110, Loss: 0.2666, Train: 86.21%, Valid: 83.05% Test: 78.38%\n",
      "Run: 07, Epoch: 111, Loss: 0.3293, Train: 89.66%, Valid: 83.05% Test: 78.38%\n",
      "Run: 07, Epoch: 112, Loss: 0.3088, Train: 89.66%, Valid: 83.05% Test: 81.08%\n",
      "Run: 07, Epoch: 113, Loss: 0.3833, Train: 94.25%, Valid: 83.05% Test: 86.49%\n",
      "Run: 07, Epoch: 114, Loss: 0.2810, Train: 96.55%, Valid: 84.75% Test: 89.19%\n",
      "Run: 07, Epoch: 115, Loss: 0.3174, Train: 97.70%, Valid: 86.44% Test: 91.89%\n",
      "Run: 07, Epoch: 116, Loss: 0.3959, Train: 97.70%, Valid: 86.44% Test: 91.89%\n",
      "Run: 07, Epoch: 117, Loss: 0.3002, Train: 97.70%, Valid: 86.44% Test: 89.19%\n",
      "Run: 07, Epoch: 118, Loss: 0.2864, Train: 97.70%, Valid: 86.44% Test: 97.30%\n",
      "Run: 07, Epoch: 119, Loss: 0.3385, Train: 98.85%, Valid: 86.44% Test: 97.30%\n",
      "Run: 07, Epoch: 120, Loss: 0.2575, Train: 98.85%, Valid: 88.14% Test: 94.59%\n",
      "Run: 07, Epoch: 121, Loss: 0.2529, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 07, Epoch: 122, Loss: 0.2847, Train: 98.85%, Valid: 91.53% Test: 94.59%\n",
      "Run: 07, Epoch: 123, Loss: 0.2692, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 07, Epoch: 124, Loss: 0.3040, Train: 97.70%, Valid: 94.92% Test: 89.19%\n",
      "Run: 07, Epoch: 125, Loss: 0.2424, Train: 96.55%, Valid: 93.22% Test: 86.49%\n",
      "Run: 07, Epoch: 126, Loss: 0.2742, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 07, Epoch: 127, Loss: 0.3029, Train: 95.40%, Valid: 91.53% Test: 83.78%\n",
      "Run: 07, Epoch: 128, Loss: 0.2866, Train: 94.25%, Valid: 89.83% Test: 81.08%\n",
      "Run: 07, Epoch: 129, Loss: 0.2922, Train: 94.25%, Valid: 88.14% Test: 83.78%\n",
      "Run: 07, Epoch: 130, Loss: 0.2875, Train: 93.10%, Valid: 86.44% Test: 91.89%\n",
      "Run: 07, Epoch: 131, Loss: 0.2874, Train: 93.10%, Valid: 86.44% Test: 94.59%\n",
      "Run: 07, Epoch: 132, Loss: 0.3249, Train: 94.25%, Valid: 86.44% Test: 91.89%\n",
      "Run: 07, Epoch: 133, Loss: 0.3007, Train: 94.25%, Valid: 88.14% Test: 91.89%\n",
      "Run: 07, Epoch: 134, Loss: 0.2460, Train: 95.40%, Valid: 89.83% Test: 91.89%\n",
      "Run: 07, Epoch: 135, Loss: 0.2737, Train: 96.55%, Valid: 89.83% Test: 94.59%\n",
      "Run: 07, Epoch: 136, Loss: 0.3529, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 07, Epoch: 137, Loss: 0.3079, Train: 96.55%, Valid: 84.75% Test: 91.89%\n",
      "Run: 07, Epoch: 138, Loss: 0.2779, Train: 97.70%, Valid: 83.05% Test: 89.19%\n",
      "Run: 07, Epoch: 139, Loss: 0.2962, Train: 96.55%, Valid: 83.05% Test: 89.19%\n",
      "Run: 07, Epoch: 140, Loss: 0.2794, Train: 97.70%, Valid: 84.75% Test: 89.19%\n",
      "Run: 07, Epoch: 141, Loss: 0.3088, Train: 97.70%, Valid: 84.75% Test: 89.19%\n",
      "Run: 07, Epoch: 142, Loss: 0.2917, Train: 96.55%, Valid: 83.05% Test: 89.19%\n",
      "Run: 07, Epoch: 143, Loss: 0.2823, Train: 95.40%, Valid: 81.36% Test: 94.59%\n",
      "Run: 07, Epoch: 144, Loss: 0.2487, Train: 96.55%, Valid: 83.05% Test: 94.59%\n",
      "Run: 07, Epoch: 145, Loss: 0.2437, Train: 96.55%, Valid: 86.44% Test: 94.59%\n",
      "Run: 07, Epoch: 146, Loss: 0.3103, Train: 97.70%, Valid: 88.14% Test: 94.59%\n",
      "Run: 07, Epoch: 147, Loss: 0.2666, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 07, Epoch: 148, Loss: 0.2043, Train: 97.70%, Valid: 88.14% Test: 94.59%\n",
      "Run: 07, Epoch: 149, Loss: 0.2411, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 07, Epoch: 150, Loss: 0.2787, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 07, Epoch: 151, Loss: 0.2502, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 07, Epoch: 152, Loss: 0.1963, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 07, Epoch: 153, Loss: 0.2293, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 07, Epoch: 154, Loss: 0.1682, Train: 97.70%, Valid: 91.53% Test: 94.59%\n",
      "Run: 07, Epoch: 155, Loss: 0.1887, Train: 97.70%, Valid: 89.83% Test: 91.89%\n",
      "Run: 07, Epoch: 156, Loss: 0.2043, Train: 97.70%, Valid: 83.05% Test: 89.19%\n",
      "Run: 07, Epoch: 157, Loss: 0.2051, Train: 97.70%, Valid: 84.75% Test: 91.89%\n",
      "Run: 07, Epoch: 158, Loss: 0.2258, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 07, Epoch: 159, Loss: 0.2147, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 07, Epoch: 160, Loss: 0.2411, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 07, Epoch: 161, Loss: 0.2469, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 07, Epoch: 162, Loss: 0.2157, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 07, Epoch: 163, Loss: 0.2201, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 07, Epoch: 164, Loss: 0.3475, Train: 97.70%, Valid: 86.44% Test: 91.89%\n",
      "Run: 07, Epoch: 165, Loss: 0.2496, Train: 97.70%, Valid: 84.75% Test: 91.89%\n",
      "Run: 07, Epoch: 166, Loss: 0.2273, Train: 95.40%, Valid: 79.66% Test: 94.59%\n",
      "Run: 07, Epoch: 167, Loss: 0.2466, Train: 95.40%, Valid: 81.36% Test: 94.59%\n",
      "Run: 07, Epoch: 168, Loss: 0.2320, Train: 98.85%, Valid: 84.75% Test: 91.89%\n",
      "Run: 07, Epoch: 169, Loss: 0.2761, Train: 98.85%, Valid: 86.44% Test: 91.89%\n",
      "Run: 07, Epoch: 170, Loss: 0.2526, Train: 98.85%, Valid: 88.14% Test: 89.19%\n",
      "Run: 07, Epoch: 171, Loss: 0.2268, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 07, Epoch: 172, Loss: 0.2038, Train: 98.85%, Valid: 91.53% Test: 89.19%\n",
      "Run: 07, Epoch: 173, Loss: 0.2445, Train: 98.85%, Valid: 91.53% Test: 89.19%\n",
      "Run: 07, Epoch: 174, Loss: 0.2563, Train: 96.55%, Valid: 91.53% Test: 86.49%\n",
      "Run: 07, Epoch: 175, Loss: 0.2269, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 07, Epoch: 176, Loss: 0.2837, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 07, Epoch: 177, Loss: 0.2253, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 07, Epoch: 178, Loss: 0.2200, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 07, Epoch: 179, Loss: 0.3168, Train: 97.70%, Valid: 94.92% Test: 94.59%\n",
      "Run: 07, Epoch: 180, Loss: 0.2283, Train: 97.70%, Valid: 93.22% Test: 94.59%\n",
      "Run: 07, Epoch: 181, Loss: 0.2213, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 07, Epoch: 182, Loss: 0.1685, Train: 96.55%, Valid: 88.14% Test: 91.89%\n",
      "Run: 07, Epoch: 183, Loss: 0.2277, Train: 96.55%, Valid: 86.44% Test: 91.89%\n",
      "Run: 07, Epoch: 184, Loss: 0.2638, Train: 95.40%, Valid: 86.44% Test: 89.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 185, Loss: 0.1669, Train: 95.40%, Valid: 86.44% Test: 89.19%\n",
      "Run: 07, Epoch: 186, Loss: 0.2120, Train: 96.55%, Valid: 88.14% Test: 91.89%\n",
      "Run: 07, Epoch: 187, Loss: 0.2607, Train: 97.70%, Valid: 93.22% Test: 91.89%\n",
      "Run: 07, Epoch: 188, Loss: 0.1890, Train: 97.70%, Valid: 93.22% Test: 94.59%\n",
      "Run: 07, Epoch: 189, Loss: 0.1841, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 07, Epoch: 190, Loss: 0.1800, Train: 98.85%, Valid: 89.83% Test: 89.19%\n",
      "Run: 07, Epoch: 191, Loss: 0.2315, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 07, Epoch: 192, Loss: 0.2143, Train: 98.85%, Valid: 91.53% Test: 94.59%\n",
      "Run: 07, Epoch: 193, Loss: 0.1550, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 07, Epoch: 194, Loss: 0.1410, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 07, Epoch: 195, Loss: 0.1909, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 07, Epoch: 196, Loss: 0.1906, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 07, Epoch: 197, Loss: 0.2715, Train: 97.70%, Valid: 94.92% Test: 91.89%\n",
      "Run: 07, Epoch: 198, Loss: 0.1667, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 07, Epoch: 199, Loss: 0.1974, Train: 97.70%, Valid: 93.22% Test: 89.19%\n",
      "Run: 07, Epoch: 200, Loss: 0.2176, Train: 98.85%, Valid: 91.53% Test: 89.19%\n",
      "Run 07:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 96.61\n",
      "  Final Train: 95.40\n",
      "   Final Test: 91.89\n",
      "Run: 08, Epoch: 01, Loss: 1.5655, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 02, Loss: 1.5367, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 03, Loss: 1.4510, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 04, Loss: 1.4448, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 05, Loss: 1.3659, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 06, Loss: 1.3408, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 07, Loss: 1.2805, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 08, Loss: 1.2172, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 09, Loss: 1.1906, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 10, Loss: 1.1659, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 11, Loss: 1.0901, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 12, Loss: 1.0813, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 13, Loss: 1.0367, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 14, Loss: 1.0712, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 15, Loss: 0.9973, Train: 47.13%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 16, Loss: 0.9735, Train: 47.13%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 17, Loss: 0.9311, Train: 47.13%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 18, Loss: 0.9281, Train: 47.13%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 19, Loss: 0.8964, Train: 47.13%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 20, Loss: 0.8878, Train: 47.13%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 21, Loss: 0.8897, Train: 47.13%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 22, Loss: 0.8135, Train: 48.28%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 23, Loss: 0.8448, Train: 48.28%, Valid: 69.49% Test: 67.57%\n",
      "Run: 08, Epoch: 24, Loss: 0.8299, Train: 48.28%, Valid: 69.49% Test: 67.57%\n",
      "Run: 08, Epoch: 25, Loss: 0.7742, Train: 51.72%, Valid: 72.88% Test: 67.57%\n",
      "Run: 08, Epoch: 26, Loss: 0.7873, Train: 55.17%, Valid: 74.58% Test: 67.57%\n",
      "Run: 08, Epoch: 27, Loss: 0.7734, Train: 57.47%, Valid: 72.88% Test: 72.97%\n",
      "Run: 08, Epoch: 28, Loss: 0.7629, Train: 59.77%, Valid: 74.58% Test: 75.68%\n",
      "Run: 08, Epoch: 29, Loss: 0.7830, Train: 63.22%, Valid: 76.27% Test: 78.38%\n",
      "Run: 08, Epoch: 30, Loss: 0.7603, Train: 63.22%, Valid: 72.88% Test: 83.78%\n",
      "Run: 08, Epoch: 31, Loss: 0.7391, Train: 62.07%, Valid: 72.88% Test: 83.78%\n",
      "Run: 08, Epoch: 32, Loss: 0.6769, Train: 60.92%, Valid: 74.58% Test: 81.08%\n",
      "Run: 08, Epoch: 33, Loss: 0.6879, Train: 60.92%, Valid: 74.58% Test: 78.38%\n",
      "Run: 08, Epoch: 34, Loss: 0.7012, Train: 63.22%, Valid: 77.97% Test: 81.08%\n",
      "Run: 08, Epoch: 35, Loss: 0.6657, Train: 66.67%, Valid: 77.97% Test: 78.38%\n",
      "Run: 08, Epoch: 36, Loss: 0.6677, Train: 68.97%, Valid: 79.66% Test: 78.38%\n",
      "Run: 08, Epoch: 37, Loss: 0.6540, Train: 64.37%, Valid: 76.27% Test: 72.97%\n",
      "Run: 08, Epoch: 38, Loss: 0.6357, Train: 56.32%, Valid: 76.27% Test: 72.97%\n",
      "Run: 08, Epoch: 39, Loss: 0.6160, Train: 55.17%, Valid: 76.27% Test: 72.97%\n",
      "Run: 08, Epoch: 40, Loss: 0.6398, Train: 55.17%, Valid: 72.88% Test: 72.97%\n",
      "Run: 08, Epoch: 41, Loss: 0.6412, Train: 57.47%, Valid: 74.58% Test: 72.97%\n",
      "Run: 08, Epoch: 42, Loss: 0.6249, Train: 60.92%, Valid: 74.58% Test: 83.78%\n",
      "Run: 08, Epoch: 43, Loss: 0.6247, Train: 64.37%, Valid: 77.97% Test: 83.78%\n",
      "Run: 08, Epoch: 44, Loss: 0.5775, Train: 70.11%, Valid: 77.97% Test: 83.78%\n",
      "Run: 08, Epoch: 45, Loss: 0.5784, Train: 78.16%, Valid: 79.66% Test: 86.49%\n",
      "Run: 08, Epoch: 46, Loss: 0.5811, Train: 89.66%, Valid: 88.14% Test: 94.59%\n",
      "Run: 08, Epoch: 47, Loss: 0.5312, Train: 94.25%, Valid: 91.53% Test: 94.59%\n",
      "Run: 08, Epoch: 48, Loss: 0.5239, Train: 94.25%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 49, Loss: 0.6207, Train: 93.10%, Valid: 93.22% Test: 94.59%\n",
      "Run: 08, Epoch: 50, Loss: 0.5957, Train: 94.25%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 51, Loss: 0.5702, Train: 93.10%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 52, Loss: 0.5358, Train: 89.66%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 53, Loss: 0.4982, Train: 90.80%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 54, Loss: 0.5180, Train: 89.66%, Valid: 83.05% Test: 91.89%\n",
      "Run: 08, Epoch: 55, Loss: 0.4454, Train: 90.80%, Valid: 77.97% Test: 89.19%\n",
      "Run: 08, Epoch: 56, Loss: 0.5409, Train: 89.66%, Valid: 77.97% Test: 89.19%\n",
      "Run: 08, Epoch: 57, Loss: 0.4790, Train: 90.80%, Valid: 77.97% Test: 89.19%\n",
      "Run: 08, Epoch: 58, Loss: 0.5504, Train: 88.51%, Valid: 81.36% Test: 91.89%\n",
      "Run: 08, Epoch: 59, Loss: 0.4643, Train: 87.36%, Valid: 84.75% Test: 89.19%\n",
      "Run: 08, Epoch: 60, Loss: 0.5370, Train: 94.25%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 61, Loss: 0.4836, Train: 96.55%, Valid: 89.83% Test: 97.30%\n",
      "Run: 08, Epoch: 62, Loss: 0.5152, Train: 96.55%, Valid: 91.53% Test: 97.30%\n",
      "Run: 08, Epoch: 63, Loss: 0.5070, Train: 96.55%, Valid: 91.53% Test: 97.30%\n",
      "Run: 08, Epoch: 64, Loss: 0.4531, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 65, Loss: 0.4507, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 66, Loss: 0.4950, Train: 96.55%, Valid: 89.83% Test: 97.30%\n",
      "Run: 08, Epoch: 67, Loss: 0.4468, Train: 93.10%, Valid: 84.75% Test: 94.59%\n",
      "Run: 08, Epoch: 68, Loss: 0.4233, Train: 90.80%, Valid: 86.44% Test: 94.59%\n",
      "Run: 08, Epoch: 69, Loss: 0.4456, Train: 89.66%, Valid: 84.75% Test: 94.59%\n",
      "Run: 08, Epoch: 70, Loss: 0.4378, Train: 93.10%, Valid: 88.14% Test: 94.59%\n",
      "Run: 08, Epoch: 71, Loss: 0.4375, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 72, Loss: 0.4157, Train: 95.40%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 73, Loss: 0.4009, Train: 93.10%, Valid: 91.53% Test: 94.59%\n",
      "Run: 08, Epoch: 74, Loss: 0.4053, Train: 90.80%, Valid: 89.83% Test: 89.19%\n",
      "Run: 08, Epoch: 75, Loss: 0.4373, Train: 88.51%, Valid: 91.53% Test: 89.19%\n",
      "Run: 08, Epoch: 76, Loss: 0.4448, Train: 85.06%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 77, Loss: 0.4666, Train: 88.51%, Valid: 84.75% Test: 89.19%\n",
      "Run: 08, Epoch: 78, Loss: 0.3891, Train: 91.95%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 79, Loss: 0.3534, Train: 96.55%, Valid: 93.22% Test: 94.59%\n",
      "Run: 08, Epoch: 80, Loss: 0.3550, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 08, Epoch: 81, Loss: 0.4139, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 82, Loss: 0.3500, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 83, Loss: 0.3636, Train: 97.70%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 84, Loss: 0.3516, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 85, Loss: 0.3946, Train: 97.70%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 86, Loss: 0.3262, Train: 96.55%, Valid: 88.14% Test: 97.30%\n",
      "Run: 08, Epoch: 87, Loss: 0.3614, Train: 96.55%, Valid: 88.14% Test: 97.30%\n",
      "Run: 08, Epoch: 88, Loss: 0.3632, Train: 97.70%, Valid: 88.14% Test: 97.30%\n",
      "Run: 08, Epoch: 89, Loss: 0.3435, Train: 97.70%, Valid: 89.83% Test: 97.30%\n",
      "Run: 08, Epoch: 90, Loss: 0.3426, Train: 97.70%, Valid: 89.83% Test: 97.30%\n",
      "Run: 08, Epoch: 91, Loss: 0.3337, Train: 96.55%, Valid: 89.83% Test: 97.30%\n",
      "Run: 08, Epoch: 92, Loss: 0.3706, Train: 96.55%, Valid: 89.83% Test: 97.30%\n",
      "Run: 08, Epoch: 93, Loss: 0.3386, Train: 96.55%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 94, Loss: 0.3967, Train: 96.55%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 95, Loss: 0.4225, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 96, Loss: 0.3370, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 97, Loss: 0.3536, Train: 97.70%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 98, Loss: 0.3238, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 99, Loss: 0.3173, Train: 97.70%, Valid: 91.53% Test: 97.30%\n",
      "Run: 08, Epoch: 100, Loss: 0.3267, Train: 96.55%, Valid: 89.83% Test: 97.30%\n",
      "Run: 08, Epoch: 101, Loss: 0.2942, Train: 98.85%, Valid: 91.53% Test: 94.59%\n",
      "Run: 08, Epoch: 102, Loss: 0.3326, Train: 96.55%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 103, Loss: 0.2994, Train: 94.25%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 104, Loss: 0.3289, Train: 88.51%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 105, Loss: 0.3462, Train: 90.80%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 106, Loss: 0.2662, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 107, Loss: 0.3415, Train: 98.85%, Valid: 94.92% Test: 97.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 108, Loss: 0.3066, Train: 98.85%, Valid: 94.92% Test: 97.30%\n",
      "Run: 08, Epoch: 109, Loss: 0.2896, Train: 100.00%, Valid: 93.22% Test: 94.59%\n",
      "Run: 08, Epoch: 110, Loss: 0.3410, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 111, Loss: 0.3181, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 112, Loss: 0.2793, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 113, Loss: 0.2609, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 114, Loss: 0.2615, Train: 97.70%, Valid: 94.92% Test: 94.59%\n",
      "Run: 08, Epoch: 115, Loss: 0.2807, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 116, Loss: 0.2781, Train: 95.40%, Valid: 88.14% Test: 89.19%\n",
      "Run: 08, Epoch: 117, Loss: 0.2424, Train: 95.40%, Valid: 88.14% Test: 89.19%\n",
      "Run: 08, Epoch: 118, Loss: 0.3312, Train: 95.40%, Valid: 88.14% Test: 89.19%\n",
      "Run: 08, Epoch: 119, Loss: 0.2529, Train: 95.40%, Valid: 88.14% Test: 94.59%\n",
      "Run: 08, Epoch: 120, Loss: 0.2936, Train: 96.55%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 121, Loss: 0.2740, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 122, Loss: 0.2682, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 123, Loss: 0.2397, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 124, Loss: 0.2510, Train: 98.85%, Valid: 91.53% Test: 89.19%\n",
      "Run: 08, Epoch: 125, Loss: 0.2840, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 126, Loss: 0.2722, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 08, Epoch: 127, Loss: 0.2558, Train: 98.85%, Valid: 93.22% Test: 97.30%\n",
      "Run: 08, Epoch: 128, Loss: 0.2525, Train: 98.85%, Valid: 93.22% Test: 97.30%\n",
      "Run: 08, Epoch: 129, Loss: 0.2158, Train: 97.70%, Valid: 93.22% Test: 97.30%\n",
      "Run: 08, Epoch: 130, Loss: 0.2270, Train: 97.70%, Valid: 93.22% Test: 97.30%\n",
      "Run: 08, Epoch: 131, Loss: 0.2227, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 08, Epoch: 132, Loss: 0.2512, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 133, Loss: 0.2476, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 134, Loss: 0.2561, Train: 98.85%, Valid: 88.14% Test: 89.19%\n",
      "Run: 08, Epoch: 135, Loss: 0.2402, Train: 97.70%, Valid: 89.83% Test: 89.19%\n",
      "Run: 08, Epoch: 136, Loss: 0.2278, Train: 97.70%, Valid: 89.83% Test: 89.19%\n",
      "Run: 08, Epoch: 137, Loss: 0.2384, Train: 97.70%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 138, Loss: 0.2269, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 139, Loss: 0.2343, Train: 100.00%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 140, Loss: 0.2329, Train: 98.85%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 141, Loss: 0.2213, Train: 98.85%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 142, Loss: 0.2195, Train: 98.85%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 143, Loss: 0.1910, Train: 98.85%, Valid: 84.75% Test: 91.89%\n",
      "Run: 08, Epoch: 144, Loss: 0.1971, Train: 100.00%, Valid: 84.75% Test: 91.89%\n",
      "Run: 08, Epoch: 145, Loss: 0.2218, Train: 100.00%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 146, Loss: 0.2882, Train: 100.00%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 147, Loss: 0.3070, Train: 100.00%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 148, Loss: 0.2493, Train: 100.00%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 149, Loss: 0.2767, Train: 100.00%, Valid: 91.53% Test: 91.89%\n",
      "Run: 08, Epoch: 150, Loss: 0.2687, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 08, Epoch: 151, Loss: 0.2137, Train: 97.70%, Valid: 88.14% Test: 94.59%\n",
      "Run: 08, Epoch: 152, Loss: 0.2219, Train: 94.25%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 153, Loss: 0.2382, Train: 95.40%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 154, Loss: 0.2542, Train: 96.55%, Valid: 89.83% Test: 97.30%\n",
      "Run: 08, Epoch: 155, Loss: 0.2217, Train: 97.70%, Valid: 89.83% Test: 97.30%\n",
      "Run: 08, Epoch: 156, Loss: 0.2291, Train: 98.85%, Valid: 91.53% Test: 97.30%\n",
      "Run: 08, Epoch: 157, Loss: 0.2140, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 08, Epoch: 158, Loss: 0.1921, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 08, Epoch: 159, Loss: 0.2022, Train: 98.85%, Valid: 86.44% Test: 89.19%\n",
      "Run: 08, Epoch: 160, Loss: 0.2136, Train: 98.85%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 161, Loss: 0.2651, Train: 98.85%, Valid: 84.75% Test: 89.19%\n",
      "Run: 08, Epoch: 162, Loss: 0.1959, Train: 95.40%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 163, Loss: 0.2334, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 164, Loss: 0.2507, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 165, Loss: 0.2145, Train: 97.70%, Valid: 91.53% Test: 97.30%\n",
      "Run: 08, Epoch: 166, Loss: 0.1842, Train: 98.85%, Valid: 91.53% Test: 97.30%\n",
      "Run: 08, Epoch: 167, Loss: 0.2087, Train: 98.85%, Valid: 91.53% Test: 94.59%\n",
      "Run: 08, Epoch: 168, Loss: 0.1707, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 08, Epoch: 169, Loss: 0.2195, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 08, Epoch: 170, Loss: 0.2054, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 08, Epoch: 171, Loss: 0.2008, Train: 100.00%, Valid: 93.22% Test: 91.89%\n",
      "Run: 08, Epoch: 172, Loss: 0.2086, Train: 100.00%, Valid: 91.53% Test: 89.19%\n",
      "Run: 08, Epoch: 173, Loss: 0.1752, Train: 100.00%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 174, Loss: 0.1788, Train: 98.85%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 175, Loss: 0.1524, Train: 98.85%, Valid: 86.44% Test: 91.89%\n",
      "Run: 08, Epoch: 176, Loss: 0.1912, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 177, Loss: 0.1962, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 178, Loss: 0.1328, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 08, Epoch: 179, Loss: 0.2194, Train: 100.00%, Valid: 94.92% Test: 91.89%\n",
      "Run: 08, Epoch: 180, Loss: 0.1834, Train: 100.00%, Valid: 94.92% Test: 91.89%\n",
      "Run: 08, Epoch: 181, Loss: 0.1953, Train: 98.85%, Valid: 94.92% Test: 94.59%\n",
      "Run: 08, Epoch: 182, Loss: 0.1500, Train: 98.85%, Valid: 94.92% Test: 91.89%\n",
      "Run: 08, Epoch: 183, Loss: 0.1913, Train: 98.85%, Valid: 94.92% Test: 91.89%\n",
      "Run: 08, Epoch: 184, Loss: 0.1908, Train: 98.85%, Valid: 89.83% Test: 83.78%\n",
      "Run: 08, Epoch: 185, Loss: 0.1963, Train: 98.85%, Valid: 86.44% Test: 78.38%\n",
      "Run: 08, Epoch: 186, Loss: 0.1562, Train: 98.85%, Valid: 84.75% Test: 83.78%\n",
      "Run: 08, Epoch: 187, Loss: 0.1686, Train: 98.85%, Valid: 86.44% Test: 86.49%\n",
      "Run: 08, Epoch: 188, Loss: 0.1530, Train: 100.00%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 189, Loss: 0.1450, Train: 100.00%, Valid: 93.22% Test: 91.89%\n",
      "Run: 08, Epoch: 190, Loss: 0.1875, Train: 100.00%, Valid: 94.92% Test: 91.89%\n",
      "Run: 08, Epoch: 191, Loss: 0.2105, Train: 100.00%, Valid: 91.53% Test: 97.30%\n",
      "Run: 08, Epoch: 192, Loss: 0.1599, Train: 97.70%, Valid: 89.83% Test: 97.30%\n",
      "Run: 08, Epoch: 193, Loss: 0.1591, Train: 98.85%, Valid: 88.14% Test: 94.59%\n",
      "Run: 08, Epoch: 194, Loss: 0.1417, Train: 97.70%, Valid: 88.14% Test: 94.59%\n",
      "Run: 08, Epoch: 195, Loss: 0.1801, Train: 98.85%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 196, Loss: 0.1618, Train: 100.00%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 197, Loss: 0.1870, Train: 100.00%, Valid: 88.14% Test: 91.89%\n",
      "Run: 08, Epoch: 198, Loss: 0.1856, Train: 98.85%, Valid: 79.66% Test: 89.19%\n",
      "Run: 08, Epoch: 199, Loss: 0.1283, Train: 98.85%, Valid: 77.97% Test: 86.49%\n",
      "Run: 08, Epoch: 200, Loss: 0.1831, Train: 98.85%, Valid: 77.97% Test: 86.49%\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 94.92\n",
      "  Final Train: 98.85\n",
      "   Final Test: 97.30\n",
      "Run: 09, Epoch: 01, Loss: 1.6068, Train: 11.49%, Valid: 25.42% Test: 13.51%\n",
      "Run: 09, Epoch: 02, Loss: 1.5366, Train: 11.49%, Valid: 25.42% Test: 13.51%\n",
      "Run: 09, Epoch: 03, Loss: 1.4907, Train: 11.49%, Valid: 25.42% Test: 13.51%\n",
      "Run: 09, Epoch: 04, Loss: 1.4260, Train: 49.43%, Valid: 54.24% Test: 62.16%\n",
      "Run: 09, Epoch: 05, Loss: 1.3696, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 06, Loss: 1.3211, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 07, Loss: 1.2680, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 08, Loss: 1.2278, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 09, Loss: 1.1581, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 10, Loss: 1.1308, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 11, Loss: 1.1067, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 12, Loss: 1.0911, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 13, Loss: 1.0314, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 14, Loss: 1.0119, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 15, Loss: 0.9557, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 16, Loss: 0.9906, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 17, Loss: 0.9272, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 18, Loss: 0.9078, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 19, Loss: 0.9083, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 20, Loss: 0.8859, Train: 57.47%, Valid: 49.15% Test: 62.16%\n",
      "Run: 09, Epoch: 21, Loss: 0.8670, Train: 57.47%, Valid: 49.15% Test: 67.57%\n",
      "Run: 09, Epoch: 22, Loss: 0.8599, Train: 57.47%, Valid: 52.54% Test: 67.57%\n",
      "Run: 09, Epoch: 23, Loss: 0.8433, Train: 60.92%, Valid: 54.24% Test: 67.57%\n",
      "Run: 09, Epoch: 24, Loss: 0.8386, Train: 64.37%, Valid: 57.63% Test: 75.68%\n",
      "Run: 09, Epoch: 25, Loss: 0.8249, Train: 67.82%, Valid: 62.71% Test: 78.38%\n",
      "Run: 09, Epoch: 26, Loss: 0.8112, Train: 67.82%, Valid: 62.71% Test: 78.38%\n",
      "Run: 09, Epoch: 27, Loss: 0.7959, Train: 67.82%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 28, Loss: 0.8003, Train: 67.82%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 29, Loss: 0.8046, Train: 67.82%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 30, Loss: 0.7881, Train: 68.97%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 31, Loss: 0.8369, Train: 68.97%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 32, Loss: 0.7711, Train: 68.97%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 33, Loss: 0.7522, Train: 68.97%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 34, Loss: 0.7475, Train: 68.97%, Valid: 64.41% Test: 78.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 35, Loss: 0.7487, Train: 68.97%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 36, Loss: 0.7450, Train: 70.11%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 37, Loss: 0.7296, Train: 70.11%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 38, Loss: 0.6619, Train: 68.97%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 39, Loss: 0.7293, Train: 68.97%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 40, Loss: 0.6481, Train: 66.67%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 41, Loss: 0.6686, Train: 67.82%, Valid: 62.71% Test: 78.38%\n",
      "Run: 09, Epoch: 42, Loss: 0.6317, Train: 65.52%, Valid: 59.32% Test: 72.97%\n",
      "Run: 09, Epoch: 43, Loss: 0.6465, Train: 63.22%, Valid: 55.93% Test: 72.97%\n",
      "Run: 09, Epoch: 44, Loss: 0.6595, Train: 60.92%, Valid: 54.24% Test: 72.97%\n",
      "Run: 09, Epoch: 45, Loss: 0.6744, Train: 60.92%, Valid: 54.24% Test: 72.97%\n",
      "Run: 09, Epoch: 46, Loss: 0.6132, Train: 60.92%, Valid: 55.93% Test: 72.97%\n",
      "Run: 09, Epoch: 47, Loss: 0.5875, Train: 64.37%, Valid: 61.02% Test: 75.68%\n",
      "Run: 09, Epoch: 48, Loss: 0.6587, Train: 71.26%, Valid: 69.49% Test: 78.38%\n",
      "Run: 09, Epoch: 49, Loss: 0.6074, Train: 75.86%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 50, Loss: 0.5691, Train: 79.31%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 51, Loss: 0.5825, Train: 80.46%, Valid: 67.80% Test: 75.68%\n",
      "Run: 09, Epoch: 52, Loss: 0.6332, Train: 80.46%, Valid: 67.80% Test: 75.68%\n",
      "Run: 09, Epoch: 53, Loss: 0.5958, Train: 83.91%, Valid: 67.80% Test: 75.68%\n",
      "Run: 09, Epoch: 54, Loss: 0.5804, Train: 85.06%, Valid: 71.19% Test: 81.08%\n",
      "Run: 09, Epoch: 55, Loss: 0.5384, Train: 86.21%, Valid: 72.88% Test: 81.08%\n",
      "Run: 09, Epoch: 56, Loss: 0.5423, Train: 86.21%, Valid: 72.88% Test: 81.08%\n",
      "Run: 09, Epoch: 57, Loss: 0.5375, Train: 86.21%, Valid: 74.58% Test: 83.78%\n",
      "Run: 09, Epoch: 58, Loss: 0.5718, Train: 86.21%, Valid: 74.58% Test: 83.78%\n",
      "Run: 09, Epoch: 59, Loss: 0.5862, Train: 86.21%, Valid: 74.58% Test: 81.08%\n",
      "Run: 09, Epoch: 60, Loss: 0.5355, Train: 86.21%, Valid: 77.97% Test: 83.78%\n",
      "Run: 09, Epoch: 61, Loss: 0.5566, Train: 91.95%, Valid: 79.66% Test: 83.78%\n",
      "Run: 09, Epoch: 62, Loss: 0.5503, Train: 94.25%, Valid: 81.36% Test: 83.78%\n",
      "Run: 09, Epoch: 63, Loss: 0.5094, Train: 95.40%, Valid: 81.36% Test: 83.78%\n",
      "Run: 09, Epoch: 64, Loss: 0.5251, Train: 95.40%, Valid: 83.05% Test: 83.78%\n",
      "Run: 09, Epoch: 65, Loss: 0.4964, Train: 94.25%, Valid: 79.66% Test: 81.08%\n",
      "Run: 09, Epoch: 66, Loss: 0.5284, Train: 89.66%, Valid: 76.27% Test: 78.38%\n",
      "Run: 09, Epoch: 67, Loss: 0.5581, Train: 86.21%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 68, Loss: 0.5328, Train: 85.06%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 69, Loss: 0.4875, Train: 86.21%, Valid: 67.80% Test: 78.38%\n",
      "Run: 09, Epoch: 70, Loss: 0.4803, Train: 88.51%, Valid: 69.49% Test: 78.38%\n",
      "Run: 09, Epoch: 71, Loss: 0.4953, Train: 88.51%, Valid: 69.49% Test: 81.08%\n",
      "Run: 09, Epoch: 72, Loss: 0.5079, Train: 91.95%, Valid: 77.97% Test: 83.78%\n",
      "Run: 09, Epoch: 73, Loss: 0.4628, Train: 94.25%, Valid: 79.66% Test: 83.78%\n",
      "Run: 09, Epoch: 74, Loss: 0.5136, Train: 94.25%, Valid: 83.05% Test: 83.78%\n",
      "Run: 09, Epoch: 75, Loss: 0.5620, Train: 94.25%, Valid: 83.05% Test: 83.78%\n",
      "Run: 09, Epoch: 76, Loss: 0.5073, Train: 94.25%, Valid: 84.75% Test: 83.78%\n",
      "Run: 09, Epoch: 77, Loss: 0.4101, Train: 94.25%, Valid: 79.66% Test: 83.78%\n",
      "Run: 09, Epoch: 78, Loss: 0.4798, Train: 93.10%, Valid: 77.97% Test: 86.49%\n",
      "Run: 09, Epoch: 79, Loss: 0.5245, Train: 93.10%, Valid: 74.58% Test: 83.78%\n",
      "Run: 09, Epoch: 80, Loss: 0.4493, Train: 94.25%, Valid: 81.36% Test: 86.49%\n",
      "Run: 09, Epoch: 81, Loss: 0.4789, Train: 94.25%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 82, Loss: 0.4611, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 09, Epoch: 83, Loss: 0.4290, Train: 93.10%, Valid: 88.14% Test: 86.49%\n",
      "Run: 09, Epoch: 84, Loss: 0.5175, Train: 90.80%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 85, Loss: 0.4577, Train: 93.10%, Valid: 89.83% Test: 83.78%\n",
      "Run: 09, Epoch: 86, Loss: 0.5427, Train: 91.95%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 87, Loss: 0.4490, Train: 88.51%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 88, Loss: 0.4143, Train: 87.36%, Valid: 77.97% Test: 83.78%\n",
      "Run: 09, Epoch: 89, Loss: 0.3678, Train: 87.36%, Valid: 71.19% Test: 83.78%\n",
      "Run: 09, Epoch: 90, Loss: 0.3785, Train: 83.91%, Valid: 67.80% Test: 78.38%\n",
      "Run: 09, Epoch: 91, Loss: 0.3989, Train: 82.76%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 92, Loss: 0.4006, Train: 82.76%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 93, Loss: 0.4422, Train: 83.91%, Valid: 66.10% Test: 78.38%\n",
      "Run: 09, Epoch: 94, Loss: 0.4108, Train: 86.21%, Valid: 71.19% Test: 78.38%\n",
      "Run: 09, Epoch: 95, Loss: 0.4604, Train: 93.10%, Valid: 76.27% Test: 81.08%\n",
      "Run: 09, Epoch: 96, Loss: 0.3947, Train: 94.25%, Valid: 81.36% Test: 89.19%\n",
      "Run: 09, Epoch: 97, Loss: 0.4744, Train: 95.40%, Valid: 81.36% Test: 89.19%\n",
      "Run: 09, Epoch: 98, Loss: 0.3527, Train: 95.40%, Valid: 79.66% Test: 89.19%\n",
      "Run: 09, Epoch: 99, Loss: 0.3568, Train: 94.25%, Valid: 79.66% Test: 89.19%\n",
      "Run: 09, Epoch: 100, Loss: 0.4079, Train: 94.25%, Valid: 84.75% Test: 89.19%\n",
      "Run: 09, Epoch: 101, Loss: 0.3656, Train: 96.55%, Valid: 84.75% Test: 89.19%\n",
      "Run: 09, Epoch: 102, Loss: 0.3688, Train: 96.55%, Valid: 86.44% Test: 89.19%\n",
      "Run: 09, Epoch: 103, Loss: 0.3445, Train: 96.55%, Valid: 84.75% Test: 89.19%\n",
      "Run: 09, Epoch: 104, Loss: 0.3899, Train: 96.55%, Valid: 84.75% Test: 89.19%\n",
      "Run: 09, Epoch: 105, Loss: 0.3782, Train: 97.70%, Valid: 88.14% Test: 89.19%\n",
      "Run: 09, Epoch: 106, Loss: 0.3936, Train: 97.70%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 107, Loss: 0.3727, Train: 97.70%, Valid: 91.53% Test: 83.78%\n",
      "Run: 09, Epoch: 108, Loss: 0.3828, Train: 95.40%, Valid: 86.44% Test: 83.78%\n",
      "Run: 09, Epoch: 109, Loss: 0.3588, Train: 91.95%, Valid: 84.75% Test: 83.78%\n",
      "Run: 09, Epoch: 110, Loss: 0.3538, Train: 90.80%, Valid: 81.36% Test: 81.08%\n",
      "Run: 09, Epoch: 111, Loss: 0.4042, Train: 90.80%, Valid: 79.66% Test: 83.78%\n",
      "Run: 09, Epoch: 112, Loss: 0.3596, Train: 90.80%, Valid: 79.66% Test: 83.78%\n",
      "Run: 09, Epoch: 113, Loss: 0.3682, Train: 91.95%, Valid: 81.36% Test: 86.49%\n",
      "Run: 09, Epoch: 114, Loss: 0.3492, Train: 91.95%, Valid: 79.66% Test: 86.49%\n",
      "Run: 09, Epoch: 115, Loss: 0.3464, Train: 91.95%, Valid: 79.66% Test: 86.49%\n",
      "Run: 09, Epoch: 116, Loss: 0.3454, Train: 91.95%, Valid: 81.36% Test: 89.19%\n",
      "Run: 09, Epoch: 117, Loss: 0.3462, Train: 93.10%, Valid: 83.05% Test: 86.49%\n",
      "Run: 09, Epoch: 118, Loss: 0.3665, Train: 95.40%, Valid: 88.14% Test: 89.19%\n",
      "Run: 09, Epoch: 119, Loss: 0.3524, Train: 95.40%, Valid: 93.22% Test: 89.19%\n",
      "Run: 09, Epoch: 120, Loss: 0.3284, Train: 96.55%, Valid: 93.22% Test: 89.19%\n",
      "Run: 09, Epoch: 121, Loss: 0.3726, Train: 97.70%, Valid: 91.53% Test: 89.19%\n",
      "Run: 09, Epoch: 122, Loss: 0.3665, Train: 97.70%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 123, Loss: 0.3167, Train: 97.70%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 124, Loss: 0.3424, Train: 97.70%, Valid: 88.14% Test: 86.49%\n",
      "Run: 09, Epoch: 125, Loss: 0.3357, Train: 95.40%, Valid: 84.75% Test: 86.49%\n",
      "Run: 09, Epoch: 126, Loss: 0.4009, Train: 95.40%, Valid: 81.36% Test: 83.78%\n",
      "Run: 09, Epoch: 127, Loss: 0.3836, Train: 91.95%, Valid: 79.66% Test: 81.08%\n",
      "Run: 09, Epoch: 128, Loss: 0.3188, Train: 89.66%, Valid: 79.66% Test: 81.08%\n",
      "Run: 09, Epoch: 129, Loss: 0.2549, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 09, Epoch: 130, Loss: 0.3127, Train: 93.10%, Valid: 83.05% Test: 83.78%\n",
      "Run: 09, Epoch: 131, Loss: 0.3322, Train: 94.25%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 132, Loss: 0.3661, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 133, Loss: 0.2955, Train: 95.40%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 134, Loss: 0.3035, Train: 94.25%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 135, Loss: 0.3221, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 09, Epoch: 136, Loss: 0.3147, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 09, Epoch: 137, Loss: 0.2918, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 09, Epoch: 138, Loss: 0.3135, Train: 97.70%, Valid: 96.61% Test: 94.59%\n",
      "Run: 09, Epoch: 139, Loss: 0.2676, Train: 97.70%, Valid: 96.61% Test: 94.59%\n",
      "Run: 09, Epoch: 140, Loss: 0.3567, Train: 97.70%, Valid: 96.61% Test: 94.59%\n",
      "Run: 09, Epoch: 141, Loss: 0.3217, Train: 97.70%, Valid: 96.61% Test: 94.59%\n",
      "Run: 09, Epoch: 142, Loss: 0.2951, Train: 97.70%, Valid: 96.61% Test: 94.59%\n",
      "Run: 09, Epoch: 143, Loss: 0.3302, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 09, Epoch: 144, Loss: 0.3138, Train: 96.55%, Valid: 89.83% Test: 91.89%\n",
      "Run: 09, Epoch: 145, Loss: 0.2790, Train: 94.25%, Valid: 88.14% Test: 89.19%\n",
      "Run: 09, Epoch: 146, Loss: 0.2986, Train: 94.25%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 147, Loss: 0.3203, Train: 94.25%, Valid: 84.75% Test: 86.49%\n",
      "Run: 09, Epoch: 148, Loss: 0.3032, Train: 93.10%, Valid: 81.36% Test: 86.49%\n",
      "Run: 09, Epoch: 149, Loss: 0.3076, Train: 94.25%, Valid: 81.36% Test: 89.19%\n",
      "Run: 09, Epoch: 150, Loss: 0.3409, Train: 90.80%, Valid: 77.97% Test: 86.49%\n",
      "Run: 09, Epoch: 151, Loss: 0.3311, Train: 89.66%, Valid: 76.27% Test: 86.49%\n",
      "Run: 09, Epoch: 152, Loss: 0.3175, Train: 88.51%, Valid: 72.88% Test: 83.78%\n",
      "Run: 09, Epoch: 153, Loss: 0.2730, Train: 87.36%, Valid: 72.88% Test: 83.78%\n",
      "Run: 09, Epoch: 154, Loss: 0.2533, Train: 87.36%, Valid: 72.88% Test: 83.78%\n",
      "Run: 09, Epoch: 155, Loss: 0.3021, Train: 89.66%, Valid: 77.97% Test: 86.49%\n",
      "Run: 09, Epoch: 156, Loss: 0.3147, Train: 95.40%, Valid: 83.05% Test: 86.49%\n",
      "Run: 09, Epoch: 157, Loss: 0.3136, Train: 95.40%, Valid: 84.75% Test: 86.49%\n",
      "Run: 09, Epoch: 158, Loss: 0.2532, Train: 95.40%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 159, Loss: 0.2365, Train: 96.55%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 160, Loss: 0.3046, Train: 97.70%, Valid: 88.14% Test: 89.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 161, Loss: 0.2386, Train: 96.55%, Valid: 88.14% Test: 89.19%\n",
      "Run: 09, Epoch: 162, Loss: 0.3055, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 163, Loss: 0.2789, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 164, Loss: 0.2566, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 165, Loss: 0.2340, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 166, Loss: 0.2459, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 167, Loss: 0.2763, Train: 97.70%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 168, Loss: 0.2691, Train: 97.70%, Valid: 91.53% Test: 89.19%\n",
      "Run: 09, Epoch: 169, Loss: 0.2514, Train: 98.85%, Valid: 91.53% Test: 89.19%\n",
      "Run: 09, Epoch: 170, Loss: 0.2880, Train: 98.85%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 171, Loss: 0.2905, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 09, Epoch: 172, Loss: 0.2343, Train: 98.85%, Valid: 91.53% Test: 91.89%\n",
      "Run: 09, Epoch: 173, Loss: 0.2690, Train: 98.85%, Valid: 94.92% Test: 91.89%\n",
      "Run: 09, Epoch: 174, Loss: 0.2334, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 09, Epoch: 175, Loss: 0.3014, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 09, Epoch: 176, Loss: 0.2210, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 09, Epoch: 177, Loss: 0.2427, Train: 98.85%, Valid: 96.61% Test: 91.89%\n",
      "Run: 09, Epoch: 178, Loss: 0.2408, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 09, Epoch: 179, Loss: 0.2462, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 09, Epoch: 180, Loss: 0.2502, Train: 97.70%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 181, Loss: 0.2475, Train: 97.70%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 182, Loss: 0.2255, Train: 96.55%, Valid: 88.14% Test: 86.49%\n",
      "Run: 09, Epoch: 183, Loss: 0.2738, Train: 94.25%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 184, Loss: 0.2397, Train: 94.25%, Valid: 84.75% Test: 86.49%\n",
      "Run: 09, Epoch: 185, Loss: 0.2566, Train: 93.10%, Valid: 84.75% Test: 86.49%\n",
      "Run: 09, Epoch: 186, Loss: 0.2633, Train: 96.55%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 187, Loss: 0.2367, Train: 97.70%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 188, Loss: 0.2184, Train: 98.85%, Valid: 91.53% Test: 89.19%\n",
      "Run: 09, Epoch: 189, Loss: 0.2197, Train: 98.85%, Valid: 91.53% Test: 94.59%\n",
      "Run: 09, Epoch: 190, Loss: 0.1981, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 09, Epoch: 191, Loss: 0.2257, Train: 98.85%, Valid: 93.22% Test: 91.89%\n",
      "Run: 09, Epoch: 192, Loss: 0.2272, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 09, Epoch: 193, Loss: 0.2452, Train: 97.70%, Valid: 96.61% Test: 91.89%\n",
      "Run: 09, Epoch: 194, Loss: 0.2460, Train: 97.70%, Valid: 94.92% Test: 91.89%\n",
      "Run: 09, Epoch: 195, Loss: 0.2236, Train: 96.55%, Valid: 91.53% Test: 89.19%\n",
      "Run: 09, Epoch: 196, Loss: 0.1997, Train: 96.55%, Valid: 83.05% Test: 86.49%\n",
      "Run: 09, Epoch: 197, Loss: 0.2711, Train: 88.51%, Valid: 74.58% Test: 81.08%\n",
      "Run: 09, Epoch: 198, Loss: 0.2544, Train: 88.51%, Valid: 77.97% Test: 78.38%\n",
      "Run: 09, Epoch: 199, Loss: 0.2759, Train: 90.80%, Valid: 79.66% Test: 83.78%\n",
      "Run: 09, Epoch: 200, Loss: 0.2535, Train: 91.95%, Valid: 81.36% Test: 83.78%\n",
      "Run 09:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 96.61\n",
      "  Final Train: 97.70\n",
      "   Final Test: 94.59\n",
      "Run: 10, Epoch: 01, Loss: 1.5460, Train: 13.79%, Valid: 20.34% Test: 16.22%\n",
      "Run: 10, Epoch: 02, Loss: 1.4929, Train: 13.79%, Valid: 20.34% Test: 16.22%\n",
      "Run: 10, Epoch: 03, Loss: 1.4170, Train: 58.62%, Valid: 50.85% Test: 64.86%\n",
      "Run: 10, Epoch: 04, Loss: 1.3657, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 05, Loss: 1.3237, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 06, Loss: 1.2789, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 07, Loss: 1.2040, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 08, Loss: 1.1918, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 09, Loss: 1.1265, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 10, Loss: 1.1315, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 11, Loss: 1.0729, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 12, Loss: 1.0394, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 13, Loss: 0.9592, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 14, Loss: 0.9759, Train: 59.77%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 15, Loss: 0.9462, Train: 59.77%, Valid: 50.85% Test: 62.16%\n",
      "Run: 10, Epoch: 16, Loss: 0.8755, Train: 60.92%, Valid: 50.85% Test: 62.16%\n",
      "Run: 10, Epoch: 17, Loss: 0.8819, Train: 60.92%, Valid: 52.54% Test: 62.16%\n",
      "Run: 10, Epoch: 18, Loss: 0.8929, Train: 60.92%, Valid: 54.24% Test: 62.16%\n",
      "Run: 10, Epoch: 19, Loss: 0.8279, Train: 60.92%, Valid: 54.24% Test: 62.16%\n",
      "Run: 10, Epoch: 20, Loss: 0.8525, Train: 60.92%, Valid: 54.24% Test: 62.16%\n",
      "Run: 10, Epoch: 21, Loss: 0.8347, Train: 60.92%, Valid: 54.24% Test: 62.16%\n",
      "Run: 10, Epoch: 22, Loss: 0.8184, Train: 60.92%, Valid: 55.93% Test: 62.16%\n",
      "Run: 10, Epoch: 23, Loss: 0.7821, Train: 60.92%, Valid: 55.93% Test: 62.16%\n",
      "Run: 10, Epoch: 24, Loss: 0.7855, Train: 60.92%, Valid: 55.93% Test: 62.16%\n",
      "Run: 10, Epoch: 25, Loss: 0.7702, Train: 60.92%, Valid: 55.93% Test: 62.16%\n",
      "Run: 10, Epoch: 26, Loss: 0.7206, Train: 62.07%, Valid: 55.93% Test: 62.16%\n",
      "Run: 10, Epoch: 27, Loss: 0.7370, Train: 64.37%, Valid: 57.63% Test: 64.86%\n",
      "Run: 10, Epoch: 28, Loss: 0.7178, Train: 65.52%, Valid: 57.63% Test: 67.57%\n",
      "Run: 10, Epoch: 29, Loss: 0.7370, Train: 68.97%, Valid: 59.32% Test: 67.57%\n",
      "Run: 10, Epoch: 30, Loss: 0.7513, Train: 70.11%, Valid: 61.02% Test: 70.27%\n",
      "Run: 10, Epoch: 31, Loss: 0.6305, Train: 70.11%, Valid: 59.32% Test: 67.57%\n",
      "Run: 10, Epoch: 32, Loss: 0.6616, Train: 68.97%, Valid: 59.32% Test: 67.57%\n",
      "Run: 10, Epoch: 33, Loss: 0.6668, Train: 70.11%, Valid: 57.63% Test: 67.57%\n",
      "Run: 10, Epoch: 34, Loss: 0.6713, Train: 71.26%, Valid: 59.32% Test: 70.27%\n",
      "Run: 10, Epoch: 35, Loss: 0.6637, Train: 72.41%, Valid: 57.63% Test: 70.27%\n",
      "Run: 10, Epoch: 36, Loss: 0.6797, Train: 73.56%, Valid: 57.63% Test: 70.27%\n",
      "Run: 10, Epoch: 37, Loss: 0.6892, Train: 74.71%, Valid: 57.63% Test: 70.27%\n",
      "Run: 10, Epoch: 38, Loss: 0.6356, Train: 74.71%, Valid: 59.32% Test: 72.97%\n",
      "Run: 10, Epoch: 39, Loss: 0.6715, Train: 78.16%, Valid: 61.02% Test: 72.97%\n",
      "Run: 10, Epoch: 40, Loss: 0.6188, Train: 81.61%, Valid: 66.10% Test: 78.38%\n",
      "Run: 10, Epoch: 41, Loss: 0.6163, Train: 81.61%, Valid: 67.80% Test: 78.38%\n",
      "Run: 10, Epoch: 42, Loss: 0.6468, Train: 82.76%, Valid: 67.80% Test: 78.38%\n",
      "Run: 10, Epoch: 43, Loss: 0.6116, Train: 83.91%, Valid: 66.10% Test: 78.38%\n",
      "Run: 10, Epoch: 44, Loss: 0.5761, Train: 83.91%, Valid: 64.41% Test: 81.08%\n",
      "Run: 10, Epoch: 45, Loss: 0.5293, Train: 85.06%, Valid: 66.10% Test: 81.08%\n",
      "Run: 10, Epoch: 46, Loss: 0.5864, Train: 81.61%, Valid: 66.10% Test: 78.38%\n",
      "Run: 10, Epoch: 47, Loss: 0.5698, Train: 78.16%, Valid: 64.41% Test: 78.38%\n",
      "Run: 10, Epoch: 48, Loss: 0.5381, Train: 78.16%, Valid: 66.10% Test: 81.08%\n",
      "Run: 10, Epoch: 49, Loss: 0.5207, Train: 78.16%, Valid: 64.41% Test: 81.08%\n",
      "Run: 10, Epoch: 50, Loss: 0.5290, Train: 78.16%, Valid: 64.41% Test: 81.08%\n",
      "Run: 10, Epoch: 51, Loss: 0.5324, Train: 78.16%, Valid: 66.10% Test: 81.08%\n",
      "Run: 10, Epoch: 52, Loss: 0.5835, Train: 80.46%, Valid: 69.49% Test: 83.78%\n",
      "Run: 10, Epoch: 53, Loss: 0.5532, Train: 83.91%, Valid: 74.58% Test: 83.78%\n",
      "Run: 10, Epoch: 54, Loss: 0.5258, Train: 86.21%, Valid: 76.27% Test: 83.78%\n",
      "Run: 10, Epoch: 55, Loss: 0.5060, Train: 87.36%, Valid: 77.97% Test: 86.49%\n",
      "Run: 10, Epoch: 56, Loss: 0.5344, Train: 85.06%, Valid: 74.58% Test: 83.78%\n",
      "Run: 10, Epoch: 57, Loss: 0.5504, Train: 82.76%, Valid: 69.49% Test: 81.08%\n",
      "Run: 10, Epoch: 58, Loss: 0.5398, Train: 80.46%, Valid: 66.10% Test: 81.08%\n",
      "Run: 10, Epoch: 59, Loss: 0.4750, Train: 82.76%, Valid: 69.49% Test: 81.08%\n",
      "Run: 10, Epoch: 60, Loss: 0.5200, Train: 83.91%, Valid: 71.19% Test: 83.78%\n",
      "Run: 10, Epoch: 61, Loss: 0.4966, Train: 87.36%, Valid: 71.19% Test: 83.78%\n",
      "Run: 10, Epoch: 62, Loss: 0.5197, Train: 88.51%, Valid: 72.88% Test: 83.78%\n",
      "Run: 10, Epoch: 63, Loss: 0.5501, Train: 88.51%, Valid: 74.58% Test: 83.78%\n",
      "Run: 10, Epoch: 64, Loss: 0.4705, Train: 87.36%, Valid: 76.27% Test: 83.78%\n",
      "Run: 10, Epoch: 65, Loss: 0.4650, Train: 88.51%, Valid: 77.97% Test: 83.78%\n",
      "Run: 10, Epoch: 66, Loss: 0.4889, Train: 88.51%, Valid: 77.97% Test: 83.78%\n",
      "Run: 10, Epoch: 67, Loss: 0.4950, Train: 88.51%, Valid: 79.66% Test: 83.78%\n",
      "Run: 10, Epoch: 68, Loss: 0.4512, Train: 87.36%, Valid: 79.66% Test: 83.78%\n",
      "Run: 10, Epoch: 69, Loss: 0.4754, Train: 88.51%, Valid: 77.97% Test: 83.78%\n",
      "Run: 10, Epoch: 70, Loss: 0.4841, Train: 90.80%, Valid: 79.66% Test: 83.78%\n",
      "Run: 10, Epoch: 71, Loss: 0.5012, Train: 93.10%, Valid: 79.66% Test: 83.78%\n",
      "Run: 10, Epoch: 72, Loss: 0.4407, Train: 93.10%, Valid: 77.97% Test: 86.49%\n",
      "Run: 10, Epoch: 73, Loss: 0.4720, Train: 90.80%, Valid: 81.36% Test: 91.89%\n",
      "Run: 10, Epoch: 74, Loss: 0.4775, Train: 91.95%, Valid: 81.36% Test: 89.19%\n",
      "Run: 10, Epoch: 75, Loss: 0.4050, Train: 90.80%, Valid: 86.44% Test: 89.19%\n",
      "Run: 10, Epoch: 76, Loss: 0.4155, Train: 93.10%, Valid: 86.44% Test: 89.19%\n",
      "Run: 10, Epoch: 77, Loss: 0.4432, Train: 95.40%, Valid: 84.75% Test: 89.19%\n",
      "Run: 10, Epoch: 78, Loss: 0.4078, Train: 96.55%, Valid: 86.44% Test: 91.89%\n",
      "Run: 10, Epoch: 79, Loss: 0.4232, Train: 96.55%, Valid: 86.44% Test: 91.89%\n",
      "Run: 10, Epoch: 80, Loss: 0.3919, Train: 94.25%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 81, Loss: 0.3862, Train: 90.80%, Valid: 81.36% Test: 83.78%\n",
      "Run: 10, Epoch: 82, Loss: 0.4133, Train: 89.66%, Valid: 76.27% Test: 83.78%\n",
      "Run: 10, Epoch: 83, Loss: 0.3909, Train: 90.80%, Valid: 76.27% Test: 83.78%\n",
      "Run: 10, Epoch: 84, Loss: 0.4214, Train: 91.95%, Valid: 81.36% Test: 86.49%\n",
      "Run: 10, Epoch: 85, Loss: 0.4160, Train: 95.40%, Valid: 83.05% Test: 89.19%\n",
      "Run: 10, Epoch: 86, Loss: 0.3841, Train: 96.55%, Valid: 86.44% Test: 94.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 87, Loss: 0.4408, Train: 96.55%, Valid: 86.44% Test: 94.59%\n",
      "Run: 10, Epoch: 88, Loss: 0.3623, Train: 96.55%, Valid: 88.14% Test: 94.59%\n",
      "Run: 10, Epoch: 89, Loss: 0.3800, Train: 97.70%, Valid: 86.44% Test: 91.89%\n",
      "Run: 10, Epoch: 90, Loss: 0.4499, Train: 97.70%, Valid: 86.44% Test: 91.89%\n",
      "Run: 10, Epoch: 91, Loss: 0.3825, Train: 95.40%, Valid: 84.75% Test: 89.19%\n",
      "Run: 10, Epoch: 92, Loss: 0.3955, Train: 94.25%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 93, Loss: 0.3477, Train: 93.10%, Valid: 79.66% Test: 86.49%\n",
      "Run: 10, Epoch: 94, Loss: 0.4167, Train: 94.25%, Valid: 77.97% Test: 86.49%\n",
      "Run: 10, Epoch: 95, Loss: 0.3636, Train: 94.25%, Valid: 79.66% Test: 86.49%\n",
      "Run: 10, Epoch: 96, Loss: 0.4111, Train: 90.80%, Valid: 77.97% Test: 86.49%\n",
      "Run: 10, Epoch: 97, Loss: 0.3879, Train: 91.95%, Valid: 79.66% Test: 83.78%\n",
      "Run: 10, Epoch: 98, Loss: 0.3909, Train: 97.70%, Valid: 86.44% Test: 91.89%\n",
      "Run: 10, Epoch: 99, Loss: 0.3960, Train: 97.70%, Valid: 86.44% Test: 94.59%\n",
      "Run: 10, Epoch: 100, Loss: 0.3894, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 10, Epoch: 101, Loss: 0.3203, Train: 91.95%, Valid: 89.83% Test: 89.19%\n",
      "Run: 10, Epoch: 102, Loss: 0.3542, Train: 91.95%, Valid: 84.75% Test: 89.19%\n",
      "Run: 10, Epoch: 103, Loss: 0.3851, Train: 89.66%, Valid: 81.36% Test: 91.89%\n",
      "Run: 10, Epoch: 104, Loss: 0.3311, Train: 93.10%, Valid: 81.36% Test: 89.19%\n",
      "Run: 10, Epoch: 105, Loss: 0.3233, Train: 91.95%, Valid: 81.36% Test: 86.49%\n",
      "Run: 10, Epoch: 106, Loss: 0.3588, Train: 93.10%, Valid: 79.66% Test: 86.49%\n",
      "Run: 10, Epoch: 107, Loss: 0.4392, Train: 97.70%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 108, Loss: 0.3356, Train: 95.40%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 109, Loss: 0.3482, Train: 95.40%, Valid: 77.97% Test: 83.78%\n",
      "Run: 10, Epoch: 110, Loss: 0.3701, Train: 93.10%, Valid: 77.97% Test: 83.78%\n",
      "Run: 10, Epoch: 111, Loss: 0.4086, Train: 95.40%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 112, Loss: 0.3232, Train: 95.40%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 113, Loss: 0.3642, Train: 95.40%, Valid: 83.05% Test: 89.19%\n",
      "Run: 10, Epoch: 114, Loss: 0.3397, Train: 95.40%, Valid: 84.75% Test: 91.89%\n",
      "Run: 10, Epoch: 115, Loss: 0.3128, Train: 96.55%, Valid: 88.14% Test: 91.89%\n",
      "Run: 10, Epoch: 116, Loss: 0.3212, Train: 95.40%, Valid: 86.44% Test: 91.89%\n",
      "Run: 10, Epoch: 117, Loss: 0.3510, Train: 94.25%, Valid: 84.75% Test: 91.89%\n",
      "Run: 10, Epoch: 118, Loss: 0.3035, Train: 94.25%, Valid: 81.36% Test: 89.19%\n",
      "Run: 10, Epoch: 119, Loss: 0.3430, Train: 96.55%, Valid: 81.36% Test: 86.49%\n",
      "Run: 10, Epoch: 120, Loss: 0.3228, Train: 97.70%, Valid: 84.75% Test: 86.49%\n",
      "Run: 10, Epoch: 121, Loss: 0.3334, Train: 94.25%, Valid: 79.66% Test: 83.78%\n",
      "Run: 10, Epoch: 122, Loss: 0.3075, Train: 93.10%, Valid: 76.27% Test: 83.78%\n",
      "Run: 10, Epoch: 123, Loss: 0.3545, Train: 89.66%, Valid: 72.88% Test: 83.78%\n",
      "Run: 10, Epoch: 124, Loss: 0.3145, Train: 89.66%, Valid: 72.88% Test: 83.78%\n",
      "Run: 10, Epoch: 125, Loss: 0.2896, Train: 89.66%, Valid: 74.58% Test: 83.78%\n",
      "Run: 10, Epoch: 126, Loss: 0.2687, Train: 90.80%, Valid: 77.97% Test: 81.08%\n",
      "Run: 10, Epoch: 127, Loss: 0.2930, Train: 90.80%, Valid: 81.36% Test: 83.78%\n",
      "Run: 10, Epoch: 128, Loss: 0.3240, Train: 91.95%, Valid: 83.05% Test: 91.89%\n",
      "Run: 10, Epoch: 129, Loss: 0.3049, Train: 96.55%, Valid: 88.14% Test: 94.59%\n",
      "Run: 10, Epoch: 130, Loss: 0.2573, Train: 97.70%, Valid: 88.14% Test: 94.59%\n",
      "Run: 10, Epoch: 131, Loss: 0.2559, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 10, Epoch: 132, Loss: 0.2560, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 10, Epoch: 133, Loss: 0.2748, Train: 96.55%, Valid: 88.14% Test: 91.89%\n",
      "Run: 10, Epoch: 134, Loss: 0.2724, Train: 95.40%, Valid: 86.44% Test: 91.89%\n",
      "Run: 10, Epoch: 135, Loss: 0.2897, Train: 97.70%, Valid: 86.44% Test: 94.59%\n",
      "Run: 10, Epoch: 136, Loss: 0.2664, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 10, Epoch: 137, Loss: 0.2987, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 10, Epoch: 138, Loss: 0.2927, Train: 97.70%, Valid: 84.75% Test: 83.78%\n",
      "Run: 10, Epoch: 139, Loss: 0.3042, Train: 95.40%, Valid: 84.75% Test: 86.49%\n",
      "Run: 10, Epoch: 140, Loss: 0.2948, Train: 93.10%, Valid: 83.05% Test: 83.78%\n",
      "Run: 10, Epoch: 141, Loss: 0.2515, Train: 93.10%, Valid: 84.75% Test: 86.49%\n",
      "Run: 10, Epoch: 142, Loss: 0.3138, Train: 94.25%, Valid: 86.44% Test: 89.19%\n",
      "Run: 10, Epoch: 143, Loss: 0.3031, Train: 94.25%, Valid: 86.44% Test: 89.19%\n",
      "Run: 10, Epoch: 144, Loss: 0.2903, Train: 96.55%, Valid: 86.44% Test: 94.59%\n",
      "Run: 10, Epoch: 145, Loss: 0.3109, Train: 97.70%, Valid: 88.14% Test: 94.59%\n",
      "Run: 10, Epoch: 146, Loss: 0.3176, Train: 97.70%, Valid: 88.14% Test: 94.59%\n",
      "Run: 10, Epoch: 147, Loss: 0.2495, Train: 97.70%, Valid: 88.14% Test: 89.19%\n",
      "Run: 10, Epoch: 148, Loss: 0.2701, Train: 96.55%, Valid: 88.14% Test: 89.19%\n",
      "Run: 10, Epoch: 149, Loss: 0.2436, Train: 97.70%, Valid: 86.44% Test: 91.89%\n",
      "Run: 10, Epoch: 150, Loss: 0.2471, Train: 97.70%, Valid: 86.44% Test: 91.89%\n",
      "Run: 10, Epoch: 151, Loss: 0.2734, Train: 96.55%, Valid: 84.75% Test: 91.89%\n",
      "Run: 10, Epoch: 152, Loss: 0.3372, Train: 96.55%, Valid: 89.83% Test: 89.19%\n",
      "Run: 10, Epoch: 153, Loss: 0.2700, Train: 97.70%, Valid: 91.53% Test: 91.89%\n",
      "Run: 10, Epoch: 154, Loss: 0.2532, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 10, Epoch: 155, Loss: 0.2713, Train: 97.70%, Valid: 86.44% Test: 89.19%\n",
      "Run: 10, Epoch: 156, Loss: 0.2903, Train: 97.70%, Valid: 84.75% Test: 91.89%\n",
      "Run: 10, Epoch: 157, Loss: 0.2258, Train: 95.40%, Valid: 83.05% Test: 89.19%\n",
      "Run: 10, Epoch: 158, Loss: 0.2207, Train: 96.55%, Valid: 84.75% Test: 91.89%\n",
      "Run: 10, Epoch: 159, Loss: 0.2912, Train: 97.70%, Valid: 88.14% Test: 91.89%\n",
      "Run: 10, Epoch: 160, Loss: 0.2037, Train: 95.40%, Valid: 83.05% Test: 91.89%\n",
      "Run: 10, Epoch: 161, Loss: 0.2804, Train: 94.25%, Valid: 83.05% Test: 89.19%\n",
      "Run: 10, Epoch: 162, Loss: 0.2473, Train: 93.10%, Valid: 81.36% Test: 83.78%\n",
      "Run: 10, Epoch: 163, Loss: 0.2361, Train: 94.25%, Valid: 77.97% Test: 83.78%\n",
      "Run: 10, Epoch: 164, Loss: 0.2001, Train: 94.25%, Valid: 79.66% Test: 83.78%\n",
      "Run: 10, Epoch: 165, Loss: 0.2551, Train: 95.40%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 166, Loss: 0.2104, Train: 95.40%, Valid: 81.36% Test: 86.49%\n",
      "Run: 10, Epoch: 167, Loss: 0.2478, Train: 95.40%, Valid: 86.44% Test: 89.19%\n",
      "Run: 10, Epoch: 168, Loss: 0.2316, Train: 96.55%, Valid: 88.14% Test: 89.19%\n",
      "Run: 10, Epoch: 169, Loss: 0.2120, Train: 96.55%, Valid: 88.14% Test: 91.89%\n",
      "Run: 10, Epoch: 170, Loss: 0.3282, Train: 98.85%, Valid: 96.61% Test: 97.30%\n",
      "Run: 10, Epoch: 171, Loss: 0.2427, Train: 98.85%, Valid: 89.83% Test: 97.30%\n",
      "Run: 10, Epoch: 172, Loss: 0.2546, Train: 97.70%, Valid: 91.53% Test: 97.30%\n",
      "Run: 10, Epoch: 173, Loss: 0.2011, Train: 97.70%, Valid: 91.53% Test: 97.30%\n",
      "Run: 10, Epoch: 174, Loss: 0.2101, Train: 96.55%, Valid: 91.53% Test: 97.30%\n",
      "Run: 10, Epoch: 175, Loss: 0.2156, Train: 97.70%, Valid: 91.53% Test: 97.30%\n",
      "Run: 10, Epoch: 176, Loss: 0.2595, Train: 98.85%, Valid: 93.22% Test: 97.30%\n",
      "Run: 10, Epoch: 177, Loss: 0.2253, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 10, Epoch: 178, Loss: 0.2708, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 10, Epoch: 179, Loss: 0.2482, Train: 97.70%, Valid: 89.83% Test: 94.59%\n",
      "Run: 10, Epoch: 180, Loss: 0.1858, Train: 98.85%, Valid: 91.53% Test: 94.59%\n",
      "Run: 10, Epoch: 181, Loss: 0.2492, Train: 98.85%, Valid: 89.83% Test: 91.89%\n",
      "Run: 10, Epoch: 182, Loss: 0.2002, Train: 98.85%, Valid: 89.83% Test: 94.59%\n",
      "Run: 10, Epoch: 183, Loss: 0.2175, Train: 98.85%, Valid: 86.44% Test: 91.89%\n",
      "Run: 10, Epoch: 184, Loss: 0.2409, Train: 97.70%, Valid: 84.75% Test: 89.19%\n",
      "Run: 10, Epoch: 185, Loss: 0.2268, Train: 96.55%, Valid: 84.75% Test: 89.19%\n",
      "Run: 10, Epoch: 186, Loss: 0.2107, Train: 96.55%, Valid: 84.75% Test: 89.19%\n",
      "Run: 10, Epoch: 187, Loss: 0.2154, Train: 96.55%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 188, Loss: 0.1833, Train: 96.55%, Valid: 83.05% Test: 83.78%\n",
      "Run: 10, Epoch: 189, Loss: 0.2272, Train: 96.55%, Valid: 81.36% Test: 83.78%\n",
      "Run: 10, Epoch: 190, Loss: 0.2558, Train: 95.40%, Valid: 84.75% Test: 83.78%\n",
      "Run: 10, Epoch: 191, Loss: 0.2351, Train: 96.55%, Valid: 84.75% Test: 83.78%\n",
      "Run: 10, Epoch: 192, Loss: 0.1815, Train: 96.55%, Valid: 84.75% Test: 86.49%\n",
      "Run: 10, Epoch: 193, Loss: 0.1887, Train: 95.40%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 194, Loss: 0.2267, Train: 96.55%, Valid: 86.44% Test: 86.49%\n",
      "Run: 10, Epoch: 195, Loss: 0.2145, Train: 98.85%, Valid: 88.14% Test: 91.89%\n",
      "Run: 10, Epoch: 196, Loss: 0.1963, Train: 98.85%, Valid: 89.83% Test: 97.30%\n",
      "Run: 10, Epoch: 197, Loss: 0.2163, Train: 98.85%, Valid: 91.53% Test: 97.30%\n",
      "Run: 10, Epoch: 198, Loss: 0.1666, Train: 98.85%, Valid: 91.53% Test: 97.30%\n",
      "Run: 10, Epoch: 199, Loss: 0.2400, Train: 98.85%, Valid: 93.22% Test: 94.59%\n",
      "Run: 10, Epoch: 200, Loss: 0.1409, Train: 97.70%, Valid: 93.22% Test: 94.59%\n",
      "Run 10:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 96.61\n",
      "  Final Train: 98.85\n",
      "   Final Test: 97.30\n",
      "All runs:\n",
      "Highest Train: 99.31 ± 0.59\n",
      "Highest Valid: 97.46 ± 1.44\n",
      "  Final Train: 97.70 ± 1.71\n",
      "   Final Test: 91.35 ± 5.38\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.5,'num_layers_mlp': 3}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 5,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(15, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        \n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.001)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6034704",
   "metadata": {},
   "source": [
    "# TOPO-GSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceda79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=325], topo=[183, 24])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Texas', name='Texas',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "topo_fe=torch.cat((topo_betti0,topo_betti1),1)\n",
    "data.topo=topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636080e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x166c53760>\n",
      "Run: 01, Epoch: 01, Loss: 1.8315, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 02, Loss: 1.4186, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 03, Loss: 1.0686, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 04, Loss: 0.9091, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 05, Loss: 0.9059, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 06, Loss: 0.8465, Train: 52.87%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 07, Loss: 0.7807, Train: 57.47%, Valid: 54.24% Test: 64.86%\n",
      "Run: 01, Epoch: 08, Loss: 0.7179, Train: 73.56%, Valid: 54.24% Test: 67.57%\n",
      "Run: 01, Epoch: 09, Loss: 0.7145, Train: 85.06%, Valid: 64.41% Test: 70.27%\n",
      "Run: 01, Epoch: 10, Loss: 0.6540, Train: 87.36%, Valid: 67.80% Test: 75.68%\n",
      "Run: 01, Epoch: 11, Loss: 0.5992, Train: 89.66%, Valid: 69.49% Test: 75.68%\n",
      "Run: 01, Epoch: 12, Loss: 0.5798, Train: 90.80%, Valid: 69.49% Test: 75.68%\n",
      "Run: 01, Epoch: 13, Loss: 0.5890, Train: 90.80%, Valid: 71.19% Test: 75.68%\n",
      "Run: 01, Epoch: 14, Loss: 0.5233, Train: 89.66%, Valid: 71.19% Test: 72.97%\n",
      "Run: 01, Epoch: 15, Loss: 0.4814, Train: 89.66%, Valid: 72.88% Test: 78.38%\n",
      "Run: 01, Epoch: 16, Loss: 0.4712, Train: 90.80%, Valid: 72.88% Test: 78.38%\n",
      "Run: 01, Epoch: 17, Loss: 0.4429, Train: 90.80%, Valid: 74.58% Test: 83.78%\n",
      "Run: 01, Epoch: 18, Loss: 0.4257, Train: 90.80%, Valid: 74.58% Test: 81.08%\n",
      "Run: 01, Epoch: 19, Loss: 0.3847, Train: 90.80%, Valid: 74.58% Test: 86.49%\n",
      "Run: 01, Epoch: 20, Loss: 0.3578, Train: 90.80%, Valid: 74.58% Test: 86.49%\n",
      "Run: 01, Epoch: 21, Loss: 0.3236, Train: 90.80%, Valid: 72.88% Test: 86.49%\n",
      "Run: 01, Epoch: 22, Loss: 0.3147, Train: 90.80%, Valid: 72.88% Test: 83.78%\n",
      "Run: 01, Epoch: 23, Loss: 0.3180, Train: 91.95%, Valid: 74.58% Test: 83.78%\n",
      "Run: 01, Epoch: 24, Loss: 0.3431, Train: 91.95%, Valid: 74.58% Test: 86.49%\n",
      "Run: 01, Epoch: 25, Loss: 0.2376, Train: 91.95%, Valid: 74.58% Test: 86.49%\n",
      "Run: 01, Epoch: 26, Loss: 0.2998, Train: 91.95%, Valid: 72.88% Test: 86.49%\n",
      "Run: 01, Epoch: 27, Loss: 0.3160, Train: 91.95%, Valid: 72.88% Test: 86.49%\n",
      "Run: 01, Epoch: 28, Loss: 0.2651, Train: 91.95%, Valid: 72.88% Test: 86.49%\n",
      "Run: 01, Epoch: 29, Loss: 0.2556, Train: 91.95%, Valid: 72.88% Test: 86.49%\n",
      "Run: 01, Epoch: 30, Loss: 0.2023, Train: 91.95%, Valid: 76.27% Test: 83.78%\n",
      "Run: 01, Epoch: 31, Loss: 0.1822, Train: 91.95%, Valid: 74.58% Test: 83.78%\n",
      "Run: 01, Epoch: 32, Loss: 0.2813, Train: 91.95%, Valid: 76.27% Test: 83.78%\n",
      "Run: 01, Epoch: 33, Loss: 0.2178, Train: 91.95%, Valid: 74.58% Test: 83.78%\n",
      "Run: 01, Epoch: 34, Loss: 0.2551, Train: 93.10%, Valid: 74.58% Test: 83.78%\n",
      "Run: 01, Epoch: 35, Loss: 0.1656, Train: 95.40%, Valid: 74.58% Test: 83.78%\n",
      "Run: 01, Epoch: 36, Loss: 0.2386, Train: 96.55%, Valid: 76.27% Test: 83.78%\n",
      "Run: 01, Epoch: 37, Loss: 0.1776, Train: 98.85%, Valid: 76.27% Test: 83.78%\n",
      "Run: 01, Epoch: 38, Loss: 0.1501, Train: 98.85%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 39, Loss: 0.2150, Train: 98.85%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 40, Loss: 0.1458, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 41, Loss: 0.1478, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 01, Epoch: 42, Loss: 0.1220, Train: 100.00%, Valid: 74.58% Test: 81.08%\n",
      "Run: 01, Epoch: 43, Loss: 0.1146, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 44, Loss: 0.2256, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 45, Loss: 0.1100, Train: 100.00%, Valid: 74.58% Test: 81.08%\n",
      "Run: 01, Epoch: 46, Loss: 0.1486, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 01, Epoch: 47, Loss: 0.1089, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 01, Epoch: 48, Loss: 0.1915, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 01, Epoch: 49, Loss: 0.1181, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 50, Loss: 0.1374, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 51, Loss: 0.1422, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 52, Loss: 0.0754, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 53, Loss: 0.0935, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 54, Loss: 0.0926, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 55, Loss: 0.1771, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 56, Loss: 0.0657, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 57, Loss: 0.1158, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 58, Loss: 0.0765, Train: 100.00%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 59, Loss: 0.1246, Train: 100.00%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 60, Loss: 0.1149, Train: 100.00%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 61, Loss: 0.0676, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 62, Loss: 0.1166, Train: 100.00%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 63, Loss: 0.1719, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 64, Loss: 0.1068, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 65, Loss: 0.0514, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 66, Loss: 0.0843, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 01, Epoch: 67, Loss: 0.0858, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 68, Loss: 0.1169, Train: 100.00%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 69, Loss: 0.1850, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 70, Loss: 0.0705, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 71, Loss: 0.1179, Train: 100.00%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 72, Loss: 0.0514, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 73, Loss: 0.0518, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 74, Loss: 0.1186, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 75, Loss: 0.0777, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 76, Loss: 0.0847, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 77, Loss: 0.0790, Train: 100.00%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 78, Loss: 0.0384, Train: 100.00%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 79, Loss: 0.1490, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 80, Loss: 0.0906, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 81, Loss: 0.0893, Train: 100.00%, Valid: 74.58% Test: 81.08%\n",
      "Run: 01, Epoch: 82, Loss: 0.0551, Train: 100.00%, Valid: 76.27% Test: 83.78%\n",
      "Run: 01, Epoch: 83, Loss: 0.0733, Train: 100.00%, Valid: 76.27% Test: 83.78%\n",
      "Run: 01, Epoch: 84, Loss: 0.0647, Train: 100.00%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 85, Loss: 0.0609, Train: 100.00%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 86, Loss: 0.0806, Train: 100.00%, Valid: 77.97% Test: 86.49%\n",
      "Run: 01, Epoch: 87, Loss: 0.0629, Train: 100.00%, Valid: 79.66% Test: 86.49%\n",
      "Run: 01, Epoch: 88, Loss: 0.0345, Train: 100.00%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 89, Loss: 0.0849, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 90, Loss: 0.0700, Train: 100.00%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 91, Loss: 0.0763, Train: 100.00%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 92, Loss: 0.0855, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 93, Loss: 0.0485, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 94, Loss: 0.0305, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 95, Loss: 0.0473, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 96, Loss: 0.1072, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 97, Loss: 0.0269, Train: 100.00%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 98, Loss: 0.0474, Train: 100.00%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 99, Loss: 0.0574, Train: 100.00%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 100, Loss: 0.0420, Train: 100.00%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 101, Loss: 0.1059, Train: 100.00%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 102, Loss: 0.0672, Train: 100.00%, Valid: 81.36% Test: 83.78%\n",
      "Run: 01, Epoch: 103, Loss: 0.0609, Train: 100.00%, Valid: 83.05% Test: 83.78%\n",
      "Run: 01, Epoch: 104, Loss: 0.1334, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 105, Loss: 0.1147, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 106, Loss: 0.0199, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 107, Loss: 0.0958, Train: 100.00%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 108, Loss: 0.1157, Train: 100.00%, Valid: 83.05% Test: 78.38%\n",
      "Run: 01, Epoch: 109, Loss: 0.0424, Train: 100.00%, Valid: 83.05% Test: 78.38%\n",
      "Run: 01, Epoch: 110, Loss: 0.0680, Train: 100.00%, Valid: 83.05% Test: 78.38%\n",
      "Run: 01, Epoch: 111, Loss: 0.0497, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 112, Loss: 0.0523, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 113, Loss: 0.0543, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 114, Loss: 0.0487, Train: 100.00%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 115, Loss: 0.0367, Train: 100.00%, Valid: 83.05% Test: 83.78%\n",
      "Run: 01, Epoch: 116, Loss: 0.0397, Train: 100.00%, Valid: 81.36% Test: 83.78%\n",
      "Run: 01, Epoch: 117, Loss: 0.0613, Train: 100.00%, Valid: 79.66% Test: 83.78%\n",
      "Run: 01, Epoch: 118, Loss: 0.0237, Train: 100.00%, Valid: 79.66% Test: 83.78%\n",
      "Run: 01, Epoch: 119, Loss: 0.0329, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 120, Loss: 0.0814, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 01, Epoch: 121, Loss: 0.0352, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 01, Epoch: 122, Loss: 0.0517, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 01, Epoch: 123, Loss: 0.0954, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 01, Epoch: 124, Loss: 0.0948, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 125, Loss: 0.0624, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 126, Loss: 0.0770, Train: 100.00%, Valid: 74.58% Test: 83.78%\n",
      "Run: 01, Epoch: 127, Loss: 0.0585, Train: 100.00%, Valid: 74.58% Test: 83.78%\n",
      "Run: 01, Epoch: 128, Loss: 0.0795, Train: 100.00%, Valid: 74.58% Test: 83.78%\n",
      "Run: 01, Epoch: 129, Loss: 0.0364, Train: 100.00%, Valid: 77.97% Test: 83.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 130, Loss: 0.0268, Train: 100.00%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 131, Loss: 0.1123, Train: 100.00%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 132, Loss: 0.0652, Train: 100.00%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 133, Loss: 0.0191, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 134, Loss: 0.0699, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 135, Loss: 0.0847, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 136, Loss: 0.0712, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 137, Loss: 0.0293, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 138, Loss: 0.0853, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 139, Loss: 0.0344, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 140, Loss: 0.0449, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 141, Loss: 0.0651, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 142, Loss: 0.0598, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 01, Epoch: 143, Loss: 0.0186, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 144, Loss: 0.0288, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 145, Loss: 0.0637, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 01, Epoch: 146, Loss: 0.0984, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 01, Epoch: 147, Loss: 0.0308, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 01, Epoch: 148, Loss: 0.0780, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 01, Epoch: 149, Loss: 0.0342, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 01, Epoch: 150, Loss: 0.0436, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 151, Loss: 0.0364, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 152, Loss: 0.0121, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 153, Loss: 0.0350, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 154, Loss: 0.1553, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 155, Loss: 0.0714, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 01, Epoch: 156, Loss: 0.0521, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 01, Epoch: 157, Loss: 0.0558, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 01, Epoch: 158, Loss: 0.0271, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 01, Epoch: 159, Loss: 0.0159, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 01, Epoch: 160, Loss: 0.0209, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 01, Epoch: 161, Loss: 0.0588, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 01, Epoch: 162, Loss: 0.1275, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 01, Epoch: 163, Loss: 0.1207, Train: 100.00%, Valid: 72.88% Test: 78.38%\n",
      "Run: 01, Epoch: 164, Loss: 0.0679, Train: 100.00%, Valid: 72.88% Test: 78.38%\n",
      "Run: 01, Epoch: 165, Loss: 0.0360, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 01, Epoch: 166, Loss: 0.0391, Train: 100.00%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 167, Loss: 0.0156, Train: 100.00%, Valid: 79.66% Test: 83.78%\n",
      "Run: 01, Epoch: 168, Loss: 0.0565, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 169, Loss: 0.0762, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 170, Loss: 0.0346, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 171, Loss: 0.0689, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 01, Epoch: 172, Loss: 0.0336, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 173, Loss: 0.0582, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 174, Loss: 0.0607, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 175, Loss: 0.1020, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 176, Loss: 0.0306, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 177, Loss: 0.1378, Train: 100.00%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 178, Loss: 0.0376, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 01, Epoch: 179, Loss: 0.0728, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 01, Epoch: 180, Loss: 0.0406, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 181, Loss: 0.0278, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 182, Loss: 0.0561, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 183, Loss: 0.0396, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 184, Loss: 0.0170, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 185, Loss: 0.0298, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 186, Loss: 0.0417, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 01, Epoch: 187, Loss: 0.0172, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 01, Epoch: 188, Loss: 0.0589, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 01, Epoch: 189, Loss: 0.0461, Train: 100.00%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 190, Loss: 0.0732, Train: 100.00%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 191, Loss: 0.0303, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 192, Loss: 0.0489, Train: 100.00%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 193, Loss: 0.0670, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 194, Loss: 0.0918, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 195, Loss: 0.0715, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 196, Loss: 0.1457, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 197, Loss: 0.0712, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 198, Loss: 0.0310, Train: 100.00%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 199, Loss: 0.0788, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 200, Loss: 0.0342, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 83.05\n",
      "  Final Train: 100.00\n",
      "   Final Test: 81.08\n",
      "Run: 02, Epoch: 01, Loss: 1.4937, Train: 52.87%, Valid: 55.93% Test: 59.46%\n",
      "Run: 02, Epoch: 02, Loss: 1.2961, Train: 52.87%, Valid: 55.93% Test: 59.46%\n",
      "Run: 02, Epoch: 03, Loss: 1.0159, Train: 52.87%, Valid: 55.93% Test: 59.46%\n",
      "Run: 02, Epoch: 04, Loss: 0.9134, Train: 52.87%, Valid: 55.93% Test: 59.46%\n",
      "Run: 02, Epoch: 05, Loss: 0.8066, Train: 52.87%, Valid: 55.93% Test: 59.46%\n",
      "Run: 02, Epoch: 06, Loss: 0.6972, Train: 63.22%, Valid: 61.02% Test: 59.46%\n",
      "Run: 02, Epoch: 07, Loss: 0.6991, Train: 75.86%, Valid: 62.71% Test: 64.86%\n",
      "Run: 02, Epoch: 08, Loss: 0.5955, Train: 80.46%, Valid: 64.41% Test: 64.86%\n",
      "Run: 02, Epoch: 09, Loss: 0.5832, Train: 81.61%, Valid: 64.41% Test: 72.97%\n",
      "Run: 02, Epoch: 10, Loss: 0.5170, Train: 86.21%, Valid: 66.10% Test: 72.97%\n",
      "Run: 02, Epoch: 11, Loss: 0.4989, Train: 88.51%, Valid: 66.10% Test: 72.97%\n",
      "Run: 02, Epoch: 12, Loss: 0.5337, Train: 89.66%, Valid: 62.71% Test: 72.97%\n",
      "Run: 02, Epoch: 13, Loss: 0.4861, Train: 89.66%, Valid: 64.41% Test: 75.68%\n",
      "Run: 02, Epoch: 14, Loss: 0.4108, Train: 89.66%, Valid: 64.41% Test: 75.68%\n",
      "Run: 02, Epoch: 15, Loss: 0.4463, Train: 89.66%, Valid: 66.10% Test: 78.38%\n",
      "Run: 02, Epoch: 16, Loss: 0.3689, Train: 89.66%, Valid: 66.10% Test: 78.38%\n",
      "Run: 02, Epoch: 17, Loss: 0.3251, Train: 89.66%, Valid: 64.41% Test: 78.38%\n",
      "Run: 02, Epoch: 18, Loss: 0.3331, Train: 90.80%, Valid: 67.80% Test: 75.68%\n",
      "Run: 02, Epoch: 19, Loss: 0.3218, Train: 90.80%, Valid: 67.80% Test: 78.38%\n",
      "Run: 02, Epoch: 20, Loss: 0.2539, Train: 91.95%, Valid: 69.49% Test: 78.38%\n",
      "Run: 02, Epoch: 21, Loss: 0.2775, Train: 95.40%, Valid: 71.19% Test: 78.38%\n",
      "Run: 02, Epoch: 22, Loss: 0.2483, Train: 96.55%, Valid: 71.19% Test: 78.38%\n",
      "Run: 02, Epoch: 23, Loss: 0.2393, Train: 98.85%, Valid: 71.19% Test: 81.08%\n",
      "Run: 02, Epoch: 24, Loss: 0.2260, Train: 100.00%, Valid: 74.58% Test: 81.08%\n",
      "Run: 02, Epoch: 25, Loss: 0.2381, Train: 100.00%, Valid: 72.88% Test: 78.38%\n",
      "Run: 02, Epoch: 26, Loss: 0.2155, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 27, Loss: 0.1701, Train: 100.00%, Valid: 74.58% Test: 81.08%\n",
      "Run: 02, Epoch: 28, Loss: 0.2486, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 02, Epoch: 29, Loss: 0.2133, Train: 100.00%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 30, Loss: 0.1838, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 31, Loss: 0.1613, Train: 100.00%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 32, Loss: 0.1620, Train: 98.85%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 33, Loss: 0.1018, Train: 98.85%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 34, Loss: 0.1174, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 35, Loss: 0.1500, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 36, Loss: 0.0989, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 37, Loss: 0.0905, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 38, Loss: 0.0978, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 39, Loss: 0.1047, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 40, Loss: 0.1575, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 41, Loss: 0.1109, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 42, Loss: 0.1130, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 43, Loss: 0.1611, Train: 100.00%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 44, Loss: 0.0616, Train: 100.00%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 45, Loss: 0.1046, Train: 100.00%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 46, Loss: 0.0641, Train: 100.00%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 47, Loss: 0.0935, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 48, Loss: 0.0700, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 49, Loss: 0.0998, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 50, Loss: 0.0647, Train: 100.00%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 51, Loss: 0.0554, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 52, Loss: 0.0916, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 53, Loss: 0.0723, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 54, Loss: 0.0609, Train: 100.00%, Valid: 79.66% Test: 75.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 55, Loss: 0.0569, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 56, Loss: 0.0768, Train: 100.00%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 57, Loss: 0.0424, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 58, Loss: 0.0636, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 59, Loss: 0.0582, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 60, Loss: 0.1086, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 61, Loss: 0.0623, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 62, Loss: 0.1022, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 63, Loss: 0.1195, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 64, Loss: 0.0243, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 65, Loss: 0.0509, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 66, Loss: 0.1055, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 67, Loss: 0.0961, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 68, Loss: 0.0498, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 02, Epoch: 69, Loss: 0.0455, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 70, Loss: 0.0496, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 71, Loss: 0.0768, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 72, Loss: 0.0292, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 73, Loss: 0.0772, Train: 100.00%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 74, Loss: 0.0779, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 75, Loss: 0.1076, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 76, Loss: 0.0670, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 77, Loss: 0.0967, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 78, Loss: 0.0557, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 79, Loss: 0.0542, Train: 100.00%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 80, Loss: 0.0513, Train: 100.00%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 81, Loss: 0.0471, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 82, Loss: 0.0710, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 83, Loss: 0.0471, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 84, Loss: 0.0235, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 85, Loss: 0.0541, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 02, Epoch: 86, Loss: 0.0449, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 87, Loss: 0.0714, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 88, Loss: 0.0395, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 89, Loss: 0.0156, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 90, Loss: 0.0603, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 91, Loss: 0.0311, Train: 100.00%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 92, Loss: 0.0146, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 02, Epoch: 93, Loss: 0.0206, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 94, Loss: 0.0336, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 95, Loss: 0.0860, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 96, Loss: 0.1030, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 97, Loss: 0.0658, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 98, Loss: 0.0180, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 02, Epoch: 99, Loss: 0.0869, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 02, Epoch: 100, Loss: 0.0640, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 02, Epoch: 101, Loss: 0.0447, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 02, Epoch: 102, Loss: 0.0317, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 02, Epoch: 103, Loss: 0.0303, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 02, Epoch: 104, Loss: 0.0482, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 105, Loss: 0.0617, Train: 100.00%, Valid: 86.44% Test: 72.97%\n",
      "Run: 02, Epoch: 106, Loss: 0.0639, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 107, Loss: 0.0240, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 108, Loss: 0.0633, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 109, Loss: 0.0244, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 110, Loss: 0.0858, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 111, Loss: 0.0134, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 112, Loss: 0.0626, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 113, Loss: 0.0333, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 02, Epoch: 114, Loss: 0.1018, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 02, Epoch: 115, Loss: 0.0202, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 02, Epoch: 116, Loss: 0.0226, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 117, Loss: 0.0697, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 118, Loss: 0.0222, Train: 100.00%, Valid: 71.19% Test: 72.97%\n",
      "Run: 02, Epoch: 119, Loss: 0.0197, Train: 100.00%, Valid: 71.19% Test: 72.97%\n",
      "Run: 02, Epoch: 120, Loss: 0.0467, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 121, Loss: 0.0771, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 122, Loss: 0.0446, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 02, Epoch: 123, Loss: 0.0229, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 02, Epoch: 124, Loss: 0.0755, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 02, Epoch: 125, Loss: 0.0155, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 126, Loss: 0.0369, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 127, Loss: 0.1091, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 128, Loss: 0.0143, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 129, Loss: 0.0627, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 130, Loss: 0.0207, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 131, Loss: 0.0267, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 132, Loss: 0.0466, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 133, Loss: 0.0343, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 134, Loss: 0.0248, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 135, Loss: 0.0138, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 136, Loss: 0.0588, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 137, Loss: 0.0411, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 138, Loss: 0.0355, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 139, Loss: 0.0572, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 140, Loss: 0.0202, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 141, Loss: 0.0579, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 142, Loss: 0.0466, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 02, Epoch: 143, Loss: 0.0146, Train: 100.00%, Valid: 71.19% Test: 72.97%\n",
      "Run: 02, Epoch: 144, Loss: 0.0285, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 02, Epoch: 145, Loss: 0.0302, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 02, Epoch: 146, Loss: 0.0182, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 02, Epoch: 147, Loss: 0.0204, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 148, Loss: 0.0106, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 149, Loss: 0.1029, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 150, Loss: 0.0118, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 151, Loss: 0.0266, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 02, Epoch: 152, Loss: 0.0216, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 02, Epoch: 153, Loss: 0.0393, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 154, Loss: 0.0746, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 155, Loss: 0.0216, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 156, Loss: 0.0257, Train: 100.00%, Valid: 72.88% Test: 70.27%\n",
      "Run: 02, Epoch: 157, Loss: 0.0223, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 158, Loss: 0.0182, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 159, Loss: 0.0800, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 160, Loss: 0.0519, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 161, Loss: 0.0685, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 162, Loss: 0.0368, Train: 100.00%, Valid: 72.88% Test: 70.27%\n",
      "Run: 02, Epoch: 163, Loss: 0.0140, Train: 100.00%, Valid: 72.88% Test: 70.27%\n",
      "Run: 02, Epoch: 164, Loss: 0.0091, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 165, Loss: 0.0149, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 166, Loss: 0.0896, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 167, Loss: 0.0070, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 168, Loss: 0.0270, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 02, Epoch: 169, Loss: 0.0175, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 170, Loss: 0.0271, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 171, Loss: 0.0305, Train: 100.00%, Valid: 72.88% Test: 70.27%\n",
      "Run: 02, Epoch: 172, Loss: 0.0098, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 02, Epoch: 173, Loss: 0.0054, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 02, Epoch: 174, Loss: 0.0080, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 175, Loss: 0.0203, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 176, Loss: 0.0448, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 177, Loss: 0.0876, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 178, Loss: 0.0304, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 179, Loss: 0.0160, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 180, Loss: 0.0646, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 02, Epoch: 181, Loss: 0.0829, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 02, Epoch: 182, Loss: 0.0406, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 183, Loss: 0.0218, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 184, Loss: 0.0287, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 185, Loss: 0.0316, Train: 100.00%, Valid: 71.19% Test: 67.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 186, Loss: 0.0383, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 02, Epoch: 187, Loss: 0.0359, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 188, Loss: 0.0155, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 189, Loss: 0.0459, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 02, Epoch: 190, Loss: 0.0230, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 02, Epoch: 191, Loss: 0.0291, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 192, Loss: 0.0207, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 193, Loss: 0.0396, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 02, Epoch: 194, Loss: 0.0373, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 02, Epoch: 195, Loss: 0.0246, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 02, Epoch: 196, Loss: 0.0312, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 02, Epoch: 197, Loss: 0.0210, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 02, Epoch: 198, Loss: 0.0309, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 02, Epoch: 199, Loss: 0.0108, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 200, Loss: 0.0148, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run 02:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 86.44\n",
      "  Final Train: 100.00\n",
      "   Final Test: 72.97\n",
      "Run: 03, Epoch: 01, Loss: 1.6665, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 02, Loss: 1.3338, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 03, Loss: 0.9968, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 04, Loss: 0.8969, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 05, Loss: 0.7957, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 06, Loss: 0.7810, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 07, Loss: 0.7005, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 08, Loss: 0.6523, Train: 62.07%, Valid: 55.93% Test: 48.65%\n",
      "Run: 03, Epoch: 09, Loss: 0.6261, Train: 74.71%, Valid: 59.32% Test: 48.65%\n",
      "Run: 03, Epoch: 10, Loss: 0.5440, Train: 81.61%, Valid: 62.71% Test: 51.35%\n",
      "Run: 03, Epoch: 11, Loss: 0.5191, Train: 82.76%, Valid: 67.80% Test: 51.35%\n",
      "Run: 03, Epoch: 12, Loss: 0.4751, Train: 83.91%, Valid: 69.49% Test: 51.35%\n",
      "Run: 03, Epoch: 13, Loss: 0.4161, Train: 87.36%, Valid: 69.49% Test: 54.05%\n",
      "Run: 03, Epoch: 14, Loss: 0.4319, Train: 89.66%, Valid: 71.19% Test: 54.05%\n",
      "Run: 03, Epoch: 15, Loss: 0.3743, Train: 94.25%, Valid: 69.49% Test: 56.76%\n",
      "Run: 03, Epoch: 16, Loss: 0.3646, Train: 96.55%, Valid: 72.88% Test: 59.46%\n",
      "Run: 03, Epoch: 17, Loss: 0.3905, Train: 96.55%, Valid: 72.88% Test: 64.86%\n",
      "Run: 03, Epoch: 18, Loss: 0.2879, Train: 98.85%, Valid: 72.88% Test: 64.86%\n",
      "Run: 03, Epoch: 19, Loss: 0.2474, Train: 98.85%, Valid: 72.88% Test: 64.86%\n",
      "Run: 03, Epoch: 20, Loss: 0.2556, Train: 98.85%, Valid: 72.88% Test: 62.16%\n",
      "Run: 03, Epoch: 21, Loss: 0.2551, Train: 98.85%, Valid: 72.88% Test: 62.16%\n",
      "Run: 03, Epoch: 22, Loss: 0.2221, Train: 98.85%, Valid: 71.19% Test: 62.16%\n",
      "Run: 03, Epoch: 23, Loss: 0.2155, Train: 98.85%, Valid: 71.19% Test: 56.76%\n",
      "Run: 03, Epoch: 24, Loss: 0.1667, Train: 98.85%, Valid: 71.19% Test: 59.46%\n",
      "Run: 03, Epoch: 25, Loss: 0.1571, Train: 100.00%, Valid: 71.19% Test: 59.46%\n",
      "Run: 03, Epoch: 26, Loss: 0.1549, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 03, Epoch: 27, Loss: 0.1913, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 03, Epoch: 28, Loss: 0.1420, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 03, Epoch: 29, Loss: 0.1345, Train: 100.00%, Valid: 76.27% Test: 59.46%\n",
      "Run: 03, Epoch: 30, Loss: 0.1205, Train: 100.00%, Valid: 76.27% Test: 59.46%\n",
      "Run: 03, Epoch: 31, Loss: 0.1114, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 03, Epoch: 32, Loss: 0.1195, Train: 100.00%, Valid: 77.97% Test: 62.16%\n",
      "Run: 03, Epoch: 33, Loss: 0.1131, Train: 100.00%, Valid: 77.97% Test: 62.16%\n",
      "Run: 03, Epoch: 34, Loss: 0.1071, Train: 100.00%, Valid: 77.97% Test: 59.46%\n",
      "Run: 03, Epoch: 35, Loss: 0.1253, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 36, Loss: 0.1146, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 37, Loss: 0.1019, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 38, Loss: 0.1199, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 39, Loss: 0.0836, Train: 100.00%, Valid: 76.27% Test: 59.46%\n",
      "Run: 03, Epoch: 40, Loss: 0.0710, Train: 100.00%, Valid: 76.27% Test: 59.46%\n",
      "Run: 03, Epoch: 41, Loss: 0.0844, Train: 100.00%, Valid: 76.27% Test: 59.46%\n",
      "Run: 03, Epoch: 42, Loss: 0.0840, Train: 100.00%, Valid: 77.97% Test: 59.46%\n",
      "Run: 03, Epoch: 43, Loss: 0.0835, Train: 100.00%, Valid: 76.27% Test: 59.46%\n",
      "Run: 03, Epoch: 44, Loss: 0.0758, Train: 100.00%, Valid: 76.27% Test: 59.46%\n",
      "Run: 03, Epoch: 45, Loss: 0.0893, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 03, Epoch: 46, Loss: 0.0718, Train: 100.00%, Valid: 77.97% Test: 59.46%\n",
      "Run: 03, Epoch: 47, Loss: 0.0479, Train: 100.00%, Valid: 76.27% Test: 59.46%\n",
      "Run: 03, Epoch: 48, Loss: 0.0499, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 49, Loss: 0.0445, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 50, Loss: 0.1393, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 51, Loss: 0.0428, Train: 100.00%, Valid: 74.58% Test: 59.46%\n",
      "Run: 03, Epoch: 52, Loss: 0.0455, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 03, Epoch: 53, Loss: 0.0601, Train: 100.00%, Valid: 74.58% Test: 54.05%\n",
      "Run: 03, Epoch: 54, Loss: 0.0553, Train: 100.00%, Valid: 74.58% Test: 54.05%\n",
      "Run: 03, Epoch: 55, Loss: 0.0677, Train: 100.00%, Valid: 74.58% Test: 54.05%\n",
      "Run: 03, Epoch: 56, Loss: 0.0711, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 03, Epoch: 57, Loss: 0.0688, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 58, Loss: 0.0395, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 59, Loss: 0.0381, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 60, Loss: 0.0625, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 61, Loss: 0.0658, Train: 100.00%, Valid: 77.97% Test: 54.05%\n",
      "Run: 03, Epoch: 62, Loss: 0.0587, Train: 100.00%, Valid: 77.97% Test: 54.05%\n",
      "Run: 03, Epoch: 63, Loss: 0.0815, Train: 100.00%, Valid: 77.97% Test: 54.05%\n",
      "Run: 03, Epoch: 64, Loss: 0.0809, Train: 100.00%, Valid: 79.66% Test: 54.05%\n",
      "Run: 03, Epoch: 65, Loss: 0.0190, Train: 100.00%, Valid: 79.66% Test: 54.05%\n",
      "Run: 03, Epoch: 66, Loss: 0.0382, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 67, Loss: 0.0821, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 68, Loss: 0.0315, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 69, Loss: 0.0483, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 70, Loss: 0.0885, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 71, Loss: 0.0318, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 72, Loss: 0.0209, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 73, Loss: 0.0263, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 74, Loss: 0.0318, Train: 100.00%, Valid: 79.66% Test: 59.46%\n",
      "Run: 03, Epoch: 75, Loss: 0.0811, Train: 100.00%, Valid: 77.97% Test: 59.46%\n",
      "Run: 03, Epoch: 76, Loss: 0.0578, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 03, Epoch: 77, Loss: 0.0474, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 78, Loss: 0.1294, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 79, Loss: 0.0357, Train: 100.00%, Valid: 83.05% Test: 56.76%\n",
      "Run: 03, Epoch: 80, Loss: 0.0296, Train: 100.00%, Valid: 81.36% Test: 56.76%\n",
      "Run: 03, Epoch: 81, Loss: 0.0760, Train: 100.00%, Valid: 83.05% Test: 56.76%\n",
      "Run: 03, Epoch: 82, Loss: 0.0409, Train: 100.00%, Valid: 81.36% Test: 56.76%\n",
      "Run: 03, Epoch: 83, Loss: 0.0961, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 84, Loss: 0.0286, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 85, Loss: 0.0385, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 03, Epoch: 86, Loss: 0.0496, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 87, Loss: 0.0345, Train: 100.00%, Valid: 74.58% Test: 54.05%\n",
      "Run: 03, Epoch: 88, Loss: 0.0337, Train: 100.00%, Valid: 74.58% Test: 54.05%\n",
      "Run: 03, Epoch: 89, Loss: 0.0987, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 90, Loss: 0.1020, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 91, Loss: 0.0261, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 92, Loss: 0.0772, Train: 100.00%, Valid: 77.97% Test: 54.05%\n",
      "Run: 03, Epoch: 93, Loss: 0.0292, Train: 100.00%, Valid: 79.66% Test: 54.05%\n",
      "Run: 03, Epoch: 94, Loss: 0.0145, Train: 100.00%, Valid: 79.66% Test: 59.46%\n",
      "Run: 03, Epoch: 95, Loss: 0.0535, Train: 100.00%, Valid: 79.66% Test: 59.46%\n",
      "Run: 03, Epoch: 96, Loss: 0.0621, Train: 100.00%, Valid: 81.36% Test: 59.46%\n",
      "Run: 03, Epoch: 97, Loss: 0.0103, Train: 100.00%, Valid: 81.36% Test: 59.46%\n",
      "Run: 03, Epoch: 98, Loss: 0.0110, Train: 100.00%, Valid: 83.05% Test: 62.16%\n",
      "Run: 03, Epoch: 99, Loss: 0.1180, Train: 100.00%, Valid: 83.05% Test: 59.46%\n",
      "Run: 03, Epoch: 100, Loss: 0.0254, Train: 100.00%, Valid: 83.05% Test: 59.46%\n",
      "Run: 03, Epoch: 101, Loss: 0.0576, Train: 100.00%, Valid: 83.05% Test: 59.46%\n",
      "Run: 03, Epoch: 102, Loss: 0.0181, Train: 100.00%, Valid: 83.05% Test: 59.46%\n",
      "Run: 03, Epoch: 103, Loss: 0.0189, Train: 100.00%, Valid: 83.05% Test: 59.46%\n",
      "Run: 03, Epoch: 104, Loss: 0.0384, Train: 100.00%, Valid: 81.36% Test: 62.16%\n",
      "Run: 03, Epoch: 105, Loss: 0.0497, Train: 100.00%, Valid: 79.66% Test: 62.16%\n",
      "Run: 03, Epoch: 106, Loss: 0.0540, Train: 100.00%, Valid: 81.36% Test: 62.16%\n",
      "Run: 03, Epoch: 107, Loss: 0.0313, Train: 100.00%, Valid: 77.97% Test: 62.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 108, Loss: 0.0371, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 109, Loss: 0.0246, Train: 100.00%, Valid: 81.36% Test: 54.05%\n",
      "Run: 03, Epoch: 110, Loss: 0.0209, Train: 100.00%, Valid: 79.66% Test: 54.05%\n",
      "Run: 03, Epoch: 111, Loss: 0.0275, Train: 100.00%, Valid: 81.36% Test: 54.05%\n",
      "Run: 03, Epoch: 112, Loss: 0.0403, Train: 100.00%, Valid: 79.66% Test: 51.35%\n",
      "Run: 03, Epoch: 113, Loss: 0.0223, Train: 100.00%, Valid: 77.97% Test: 51.35%\n",
      "Run: 03, Epoch: 114, Loss: 0.0168, Train: 100.00%, Valid: 76.27% Test: 51.35%\n",
      "Run: 03, Epoch: 115, Loss: 0.0179, Train: 100.00%, Valid: 76.27% Test: 48.65%\n",
      "Run: 03, Epoch: 116, Loss: 0.0459, Train: 100.00%, Valid: 76.27% Test: 45.95%\n",
      "Run: 03, Epoch: 117, Loss: 0.0345, Train: 100.00%, Valid: 74.58% Test: 45.95%\n",
      "Run: 03, Epoch: 118, Loss: 0.0248, Train: 100.00%, Valid: 74.58% Test: 45.95%\n",
      "Run: 03, Epoch: 119, Loss: 0.0056, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 120, Loss: 0.0596, Train: 100.00%, Valid: 72.88% Test: 48.65%\n",
      "Run: 03, Epoch: 121, Loss: 0.0284, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 122, Loss: 0.0280, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 123, Loss: 0.0230, Train: 100.00%, Valid: 72.88% Test: 48.65%\n",
      "Run: 03, Epoch: 124, Loss: 0.0342, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 125, Loss: 0.0335, Train: 100.00%, Valid: 76.27% Test: 51.35%\n",
      "Run: 03, Epoch: 126, Loss: 0.0247, Train: 100.00%, Valid: 76.27% Test: 51.35%\n",
      "Run: 03, Epoch: 127, Loss: 0.0175, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 128, Loss: 0.0293, Train: 100.00%, Valid: 77.97% Test: 54.05%\n",
      "Run: 03, Epoch: 129, Loss: 0.1012, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 130, Loss: 0.0256, Train: 100.00%, Valid: 79.66% Test: 59.46%\n",
      "Run: 03, Epoch: 131, Loss: 0.0197, Train: 100.00%, Valid: 79.66% Test: 59.46%\n",
      "Run: 03, Epoch: 132, Loss: 0.0771, Train: 100.00%, Valid: 81.36% Test: 59.46%\n",
      "Run: 03, Epoch: 133, Loss: 0.0274, Train: 100.00%, Valid: 81.36% Test: 59.46%\n",
      "Run: 03, Epoch: 134, Loss: 0.0207, Train: 100.00%, Valid: 79.66% Test: 62.16%\n",
      "Run: 03, Epoch: 135, Loss: 0.0268, Train: 100.00%, Valid: 79.66% Test: 62.16%\n",
      "Run: 03, Epoch: 136, Loss: 0.0498, Train: 100.00%, Valid: 79.66% Test: 62.16%\n",
      "Run: 03, Epoch: 137, Loss: 0.0370, Train: 100.00%, Valid: 81.36% Test: 59.46%\n",
      "Run: 03, Epoch: 138, Loss: 0.0277, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 139, Loss: 0.0404, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 140, Loss: 0.0391, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 141, Loss: 0.0565, Train: 100.00%, Valid: 81.36% Test: 56.76%\n",
      "Run: 03, Epoch: 142, Loss: 0.0138, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 143, Loss: 0.0240, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 144, Loss: 0.0594, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 145, Loss: 0.0606, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 146, Loss: 0.0284, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 147, Loss: 0.0090, Train: 100.00%, Valid: 81.36% Test: 56.76%\n",
      "Run: 03, Epoch: 148, Loss: 0.0538, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 149, Loss: 0.0296, Train: 100.00%, Valid: 77.97% Test: 59.46%\n",
      "Run: 03, Epoch: 150, Loss: 0.0293, Train: 100.00%, Valid: 77.97% Test: 59.46%\n",
      "Run: 03, Epoch: 151, Loss: 0.0259, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 152, Loss: 0.0124, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 153, Loss: 0.0128, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 154, Loss: 0.0219, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 155, Loss: 0.0202, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 156, Loss: 0.0626, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 157, Loss: 0.0137, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 158, Loss: 0.0418, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 03, Epoch: 159, Loss: 0.0511, Train: 100.00%, Valid: 74.58% Test: 51.35%\n",
      "Run: 03, Epoch: 160, Loss: 0.0205, Train: 100.00%, Valid: 77.97% Test: 48.65%\n",
      "Run: 03, Epoch: 161, Loss: 0.0097, Train: 100.00%, Valid: 76.27% Test: 48.65%\n",
      "Run: 03, Epoch: 162, Loss: 0.0176, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 163, Loss: 0.0104, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 164, Loss: 0.0416, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 165, Loss: 0.0649, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 166, Loss: 0.0437, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 167, Loss: 0.0500, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 168, Loss: 0.0151, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 169, Loss: 0.0124, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 170, Loss: 0.0762, Train: 100.00%, Valid: 74.58% Test: 48.65%\n",
      "Run: 03, Epoch: 171, Loss: 0.0687, Train: 100.00%, Valid: 79.66% Test: 51.35%\n",
      "Run: 03, Epoch: 172, Loss: 0.0272, Train: 100.00%, Valid: 76.27% Test: 51.35%\n",
      "Run: 03, Epoch: 173, Loss: 0.0243, Train: 100.00%, Valid: 77.97% Test: 51.35%\n",
      "Run: 03, Epoch: 174, Loss: 0.0209, Train: 100.00%, Valid: 77.97% Test: 51.35%\n",
      "Run: 03, Epoch: 175, Loss: 0.0312, Train: 100.00%, Valid: 77.97% Test: 51.35%\n",
      "Run: 03, Epoch: 176, Loss: 0.0079, Train: 100.00%, Valid: 77.97% Test: 51.35%\n",
      "Run: 03, Epoch: 177, Loss: 0.0337, Train: 100.00%, Valid: 77.97% Test: 51.35%\n",
      "Run: 03, Epoch: 178, Loss: 0.0556, Train: 100.00%, Valid: 77.97% Test: 54.05%\n",
      "Run: 03, Epoch: 179, Loss: 0.0077, Train: 100.00%, Valid: 77.97% Test: 54.05%\n",
      "Run: 03, Epoch: 180, Loss: 0.0090, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 181, Loss: 0.0412, Train: 100.00%, Valid: 79.66% Test: 56.76%\n",
      "Run: 03, Epoch: 182, Loss: 0.0059, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 183, Loss: 0.0107, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 184, Loss: 0.0529, Train: 100.00%, Valid: 77.97% Test: 54.05%\n",
      "Run: 03, Epoch: 185, Loss: 0.0490, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 186, Loss: 0.0939, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 187, Loss: 0.0132, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 188, Loss: 0.0729, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 189, Loss: 0.0285, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 190, Loss: 0.0358, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 191, Loss: 0.0386, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 192, Loss: 0.0323, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 193, Loss: 0.0190, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 194, Loss: 0.0436, Train: 100.00%, Valid: 76.27% Test: 54.05%\n",
      "Run: 03, Epoch: 195, Loss: 0.0191, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 196, Loss: 0.0721, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 197, Loss: 0.0965, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 198, Loss: 0.0123, Train: 100.00%, Valid: 77.97% Test: 56.76%\n",
      "Run: 03, Epoch: 199, Loss: 0.0092, Train: 100.00%, Valid: 76.27% Test: 56.76%\n",
      "Run: 03, Epoch: 200, Loss: 0.0557, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 83.05\n",
      "  Final Train: 100.00\n",
      "   Final Test: 56.76\n",
      "Run: 04, Epoch: 01, Loss: 1.6586, Train: 54.02%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 02, Loss: 1.3393, Train: 54.02%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 03, Loss: 1.0613, Train: 54.02%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 04, Loss: 0.9279, Train: 54.02%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 05, Loss: 0.8794, Train: 54.02%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 06, Loss: 0.8394, Train: 55.17%, Valid: 52.54% Test: 59.46%\n",
      "Run: 04, Epoch: 07, Loss: 0.7870, Train: 65.52%, Valid: 55.93% Test: 62.16%\n",
      "Run: 04, Epoch: 08, Loss: 0.6860, Train: 74.71%, Valid: 57.63% Test: 72.97%\n",
      "Run: 04, Epoch: 09, Loss: 0.6425, Train: 77.01%, Valid: 55.93% Test: 75.68%\n",
      "Run: 04, Epoch: 10, Loss: 0.6169, Train: 79.31%, Valid: 57.63% Test: 75.68%\n",
      "Run: 04, Epoch: 11, Loss: 0.6220, Train: 82.76%, Valid: 66.10% Test: 72.97%\n",
      "Run: 04, Epoch: 12, Loss: 0.5759, Train: 85.06%, Valid: 69.49% Test: 72.97%\n",
      "Run: 04, Epoch: 13, Loss: 0.5650, Train: 85.06%, Valid: 71.19% Test: 78.38%\n",
      "Run: 04, Epoch: 14, Loss: 0.5183, Train: 87.36%, Valid: 72.88% Test: 72.97%\n",
      "Run: 04, Epoch: 15, Loss: 0.5053, Train: 91.95%, Valid: 72.88% Test: 72.97%\n",
      "Run: 04, Epoch: 16, Loss: 0.4414, Train: 95.40%, Valid: 74.58% Test: 72.97%\n",
      "Run: 04, Epoch: 17, Loss: 0.4393, Train: 98.85%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 18, Loss: 0.4423, Train: 97.70%, Valid: 72.88% Test: 75.68%\n",
      "Run: 04, Epoch: 19, Loss: 0.4145, Train: 97.70%, Valid: 72.88% Test: 72.97%\n",
      "Run: 04, Epoch: 20, Loss: 0.3679, Train: 98.85%, Valid: 74.58% Test: 72.97%\n",
      "Run: 04, Epoch: 21, Loss: 0.3647, Train: 98.85%, Valid: 79.66% Test: 72.97%\n",
      "Run: 04, Epoch: 22, Loss: 0.3470, Train: 98.85%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 23, Loss: 0.3031, Train: 98.85%, Valid: 81.36% Test: 75.68%\n",
      "Run: 04, Epoch: 24, Loss: 0.2964, Train: 98.85%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 25, Loss: 0.3099, Train: 98.85%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 26, Loss: 0.3654, Train: 98.85%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 27, Loss: 0.3333, Train: 98.85%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 28, Loss: 0.2573, Train: 98.85%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 29, Loss: 0.2719, Train: 98.85%, Valid: 79.66% Test: 75.68%\n",
      "Run: 04, Epoch: 30, Loss: 0.2742, Train: 98.85%, Valid: 79.66% Test: 75.68%\n",
      "Run: 04, Epoch: 31, Loss: 0.2065, Train: 98.85%, Valid: 79.66% Test: 75.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 32, Loss: 0.2558, Train: 98.85%, Valid: 77.97% Test: 75.68%\n",
      "Run: 04, Epoch: 33, Loss: 0.1693, Train: 98.85%, Valid: 77.97% Test: 75.68%\n",
      "Run: 04, Epoch: 34, Loss: 0.2743, Train: 98.85%, Valid: 77.97% Test: 75.68%\n",
      "Run: 04, Epoch: 35, Loss: 0.1491, Train: 98.85%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 36, Loss: 0.1862, Train: 98.85%, Valid: 79.66% Test: 78.38%\n",
      "Run: 04, Epoch: 37, Loss: 0.1644, Train: 98.85%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 38, Loss: 0.1534, Train: 98.85%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 39, Loss: 0.2187, Train: 98.85%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 40, Loss: 0.1371, Train: 98.85%, Valid: 86.44% Test: 78.38%\n",
      "Run: 04, Epoch: 41, Loss: 0.1127, Train: 98.85%, Valid: 88.14% Test: 78.38%\n",
      "Run: 04, Epoch: 42, Loss: 0.1394, Train: 98.85%, Valid: 88.14% Test: 81.08%\n",
      "Run: 04, Epoch: 43, Loss: 0.1070, Train: 98.85%, Valid: 88.14% Test: 81.08%\n",
      "Run: 04, Epoch: 44, Loss: 0.1831, Train: 98.85%, Valid: 88.14% Test: 81.08%\n",
      "Run: 04, Epoch: 45, Loss: 0.1193, Train: 98.85%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 46, Loss: 0.1362, Train: 98.85%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 47, Loss: 0.1597, Train: 98.85%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 48, Loss: 0.1097, Train: 98.85%, Valid: 86.44% Test: 72.97%\n",
      "Run: 04, Epoch: 49, Loss: 0.1727, Train: 98.85%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 50, Loss: 0.0800, Train: 98.85%, Valid: 84.75% Test: 75.68%\n",
      "Run: 04, Epoch: 51, Loss: 0.0770, Train: 98.85%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 52, Loss: 0.1063, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 53, Loss: 0.0997, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 54, Loss: 0.1129, Train: 100.00%, Valid: 88.14% Test: 78.38%\n",
      "Run: 04, Epoch: 55, Loss: 0.1755, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 56, Loss: 0.1047, Train: 98.85%, Valid: 88.14% Test: 78.38%\n",
      "Run: 04, Epoch: 57, Loss: 0.1123, Train: 98.85%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 58, Loss: 0.0547, Train: 98.85%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 59, Loss: 0.1404, Train: 98.85%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 60, Loss: 0.0988, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 61, Loss: 0.0652, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 62, Loss: 0.1292, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 63, Loss: 0.0960, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 64, Loss: 0.0428, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 65, Loss: 0.0677, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 66, Loss: 0.1002, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 67, Loss: 0.0590, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 68, Loss: 0.0576, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 69, Loss: 0.0881, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 70, Loss: 0.1217, Train: 100.00%, Valid: 86.44% Test: 72.97%\n",
      "Run: 04, Epoch: 71, Loss: 0.0648, Train: 100.00%, Valid: 86.44% Test: 72.97%\n",
      "Run: 04, Epoch: 72, Loss: 0.0481, Train: 100.00%, Valid: 86.44% Test: 72.97%\n",
      "Run: 04, Epoch: 73, Loss: 0.0776, Train: 100.00%, Valid: 86.44% Test: 72.97%\n",
      "Run: 04, Epoch: 74, Loss: 0.0541, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 04, Epoch: 75, Loss: 0.1001, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 04, Epoch: 76, Loss: 0.1027, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 04, Epoch: 77, Loss: 0.0728, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 04, Epoch: 78, Loss: 0.1163, Train: 100.00%, Valid: 84.75% Test: 72.97%\n",
      "Run: 04, Epoch: 79, Loss: 0.0500, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 80, Loss: 0.0513, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 81, Loss: 0.0756, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 82, Loss: 0.0409, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 83, Loss: 0.0920, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 84, Loss: 0.0364, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 85, Loss: 0.0546, Train: 100.00%, Valid: 88.14% Test: 75.68%\n",
      "Run: 04, Epoch: 86, Loss: 0.0689, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 87, Loss: 0.0312, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 88, Loss: 0.0319, Train: 100.00%, Valid: 84.75% Test: 75.68%\n",
      "Run: 04, Epoch: 89, Loss: 0.0736, Train: 100.00%, Valid: 81.36% Test: 75.68%\n",
      "Run: 04, Epoch: 90, Loss: 0.0521, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 91, Loss: 0.0884, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 92, Loss: 0.0649, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 93, Loss: 0.0733, Train: 100.00%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 94, Loss: 0.0484, Train: 100.00%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 95, Loss: 0.0590, Train: 100.00%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 96, Loss: 0.0259, Train: 100.00%, Valid: 84.75% Test: 78.38%\n",
      "Run: 04, Epoch: 97, Loss: 0.0834, Train: 100.00%, Valid: 84.75% Test: 78.38%\n",
      "Run: 04, Epoch: 98, Loss: 0.0264, Train: 100.00%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 99, Loss: 0.0581, Train: 100.00%, Valid: 84.75% Test: 78.38%\n",
      "Run: 04, Epoch: 100, Loss: 0.0407, Train: 100.00%, Valid: 84.75% Test: 78.38%\n",
      "Run: 04, Epoch: 101, Loss: 0.0329, Train: 100.00%, Valid: 84.75% Test: 75.68%\n",
      "Run: 04, Epoch: 102, Loss: 0.0789, Train: 100.00%, Valid: 84.75% Test: 75.68%\n",
      "Run: 04, Epoch: 103, Loss: 0.0563, Train: 100.00%, Valid: 84.75% Test: 75.68%\n",
      "Run: 04, Epoch: 104, Loss: 0.0337, Train: 100.00%, Valid: 84.75% Test: 75.68%\n",
      "Run: 04, Epoch: 105, Loss: 0.0606, Train: 100.00%, Valid: 83.05% Test: 75.68%\n",
      "Run: 04, Epoch: 106, Loss: 0.0648, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 107, Loss: 0.0331, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 108, Loss: 0.0399, Train: 100.00%, Valid: 84.75% Test: 75.68%\n",
      "Run: 04, Epoch: 109, Loss: 0.0853, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 110, Loss: 0.0321, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 111, Loss: 0.1129, Train: 100.00%, Valid: 86.44% Test: 75.68%\n",
      "Run: 04, Epoch: 112, Loss: 0.0844, Train: 100.00%, Valid: 86.44% Test: 78.38%\n",
      "Run: 04, Epoch: 113, Loss: 0.0093, Train: 100.00%, Valid: 88.14% Test: 78.38%\n",
      "Run: 04, Epoch: 114, Loss: 0.0757, Train: 100.00%, Valid: 86.44% Test: 78.38%\n",
      "Run: 04, Epoch: 115, Loss: 0.0976, Train: 100.00%, Valid: 83.05% Test: 75.68%\n",
      "Run: 04, Epoch: 116, Loss: 0.0421, Train: 100.00%, Valid: 84.75% Test: 75.68%\n",
      "Run: 04, Epoch: 117, Loss: 0.0447, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 04, Epoch: 118, Loss: 0.0382, Train: 100.00%, Valid: 79.66% Test: 78.38%\n",
      "Run: 04, Epoch: 119, Loss: 0.0325, Train: 100.00%, Valid: 72.88% Test: 78.38%\n",
      "Run: 04, Epoch: 120, Loss: 0.1520, Train: 100.00%, Valid: 71.19% Test: 78.38%\n",
      "Run: 04, Epoch: 121, Loss: 0.0349, Train: 100.00%, Valid: 71.19% Test: 78.38%\n",
      "Run: 04, Epoch: 122, Loss: 0.0498, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 04, Epoch: 123, Loss: 0.0778, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 04, Epoch: 124, Loss: 0.0457, Train: 100.00%, Valid: 72.88% Test: 72.97%\n",
      "Run: 04, Epoch: 125, Loss: 0.0469, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 04, Epoch: 126, Loss: 0.0447, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 04, Epoch: 127, Loss: 0.0706, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 128, Loss: 0.0683, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 129, Loss: 0.0224, Train: 100.00%, Valid: 81.36% Test: 72.97%\n",
      "Run: 04, Epoch: 130, Loss: 0.0297, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 04, Epoch: 131, Loss: 0.0627, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 04, Epoch: 132, Loss: 0.0187, Train: 100.00%, Valid: 83.05% Test: 75.68%\n",
      "Run: 04, Epoch: 133, Loss: 0.0258, Train: 100.00%, Valid: 83.05% Test: 75.68%\n",
      "Run: 04, Epoch: 134, Loss: 0.1508, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 04, Epoch: 135, Loss: 0.0546, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 136, Loss: 0.0194, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 04, Epoch: 137, Loss: 0.1100, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 04, Epoch: 138, Loss: 0.0569, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 04, Epoch: 139, Loss: 0.1580, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 04, Epoch: 140, Loss: 0.0755, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 04, Epoch: 141, Loss: 0.0235, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 04, Epoch: 142, Loss: 0.0237, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 04, Epoch: 143, Loss: 0.0350, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 04, Epoch: 144, Loss: 0.0382, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 04, Epoch: 145, Loss: 0.0750, Train: 100.00%, Valid: 81.36% Test: 70.27%\n",
      "Run: 04, Epoch: 146, Loss: 0.0205, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 04, Epoch: 147, Loss: 0.0330, Train: 100.00%, Valid: 83.05% Test: 72.97%\n",
      "Run: 04, Epoch: 148, Loss: 0.0652, Train: 100.00%, Valid: 84.75% Test: 70.27%\n",
      "Run: 04, Epoch: 149, Loss: 0.0438, Train: 100.00%, Valid: 83.05% Test: 70.27%\n",
      "Run: 04, Epoch: 150, Loss: 0.0713, Train: 100.00%, Valid: 84.75% Test: 67.57%\n",
      "Run: 04, Epoch: 151, Loss: 0.0163, Train: 100.00%, Valid: 84.75% Test: 67.57%\n",
      "Run: 04, Epoch: 152, Loss: 0.0830, Train: 100.00%, Valid: 83.05% Test: 67.57%\n",
      "Run: 04, Epoch: 153, Loss: 0.0225, Train: 100.00%, Valid: 83.05% Test: 67.57%\n",
      "Run: 04, Epoch: 154, Loss: 0.0109, Train: 100.00%, Valid: 83.05% Test: 70.27%\n",
      "Run: 04, Epoch: 155, Loss: 0.0222, Train: 100.00%, Valid: 83.05% Test: 70.27%\n",
      "Run: 04, Epoch: 156, Loss: 0.0455, Train: 100.00%, Valid: 81.36% Test: 70.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 157, Loss: 0.0126, Train: 100.00%, Valid: 81.36% Test: 70.27%\n",
      "Run: 04, Epoch: 158, Loss: 0.0105, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 04, Epoch: 159, Loss: 0.0192, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 04, Epoch: 160, Loss: 0.0654, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 04, Epoch: 161, Loss: 0.0228, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 04, Epoch: 162, Loss: 0.0113, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 04, Epoch: 163, Loss: 0.0110, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 04, Epoch: 164, Loss: 0.0135, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 04, Epoch: 165, Loss: 0.0206, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 04, Epoch: 166, Loss: 0.0203, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 04, Epoch: 167, Loss: 0.0971, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 04, Epoch: 168, Loss: 0.0355, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 04, Epoch: 169, Loss: 0.0104, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 04, Epoch: 170, Loss: 0.0119, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 04, Epoch: 171, Loss: 0.0287, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 04, Epoch: 172, Loss: 0.0281, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 04, Epoch: 173, Loss: 0.0176, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 04, Epoch: 174, Loss: 0.1133, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 175, Loss: 0.0294, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 176, Loss: 0.0921, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 177, Loss: 0.0071, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 178, Loss: 0.0371, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 04, Epoch: 179, Loss: 0.0183, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 04, Epoch: 180, Loss: 0.0358, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 04, Epoch: 181, Loss: 0.0530, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 04, Epoch: 182, Loss: 0.0270, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 04, Epoch: 183, Loss: 0.0616, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 04, Epoch: 184, Loss: 0.0203, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 04, Epoch: 185, Loss: 0.0051, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 186, Loss: 0.0091, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 04, Epoch: 187, Loss: 0.0305, Train: 100.00%, Valid: 79.66% Test: 72.97%\n",
      "Run: 04, Epoch: 188, Loss: 0.0586, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 189, Loss: 0.0104, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 04, Epoch: 190, Loss: 0.0480, Train: 100.00%, Valid: 81.36% Test: 70.27%\n",
      "Run: 04, Epoch: 191, Loss: 0.0204, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 04, Epoch: 192, Loss: 0.0231, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 04, Epoch: 193, Loss: 0.0097, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 04, Epoch: 194, Loss: 0.0099, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 195, Loss: 0.0389, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 196, Loss: 0.0143, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 04, Epoch: 197, Loss: 0.0492, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 198, Loss: 0.0370, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 199, Loss: 0.0388, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 200, Loss: 0.0128, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run 04:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 88.14\n",
      "  Final Train: 98.85\n",
      "   Final Test: 78.38\n",
      "Run: 05, Epoch: 01, Loss: 1.5889, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 02, Loss: 1.3481, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 03, Loss: 1.0589, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 04, Loss: 0.9734, Train: 49.43%, Valid: 62.71% Test: 56.76%\n",
      "Run: 05, Epoch: 05, Loss: 0.8882, Train: 55.17%, Valid: 66.10% Test: 56.76%\n",
      "Run: 05, Epoch: 06, Loss: 0.7918, Train: 67.82%, Valid: 67.80% Test: 56.76%\n",
      "Run: 05, Epoch: 07, Loss: 0.7265, Train: 79.31%, Valid: 69.49% Test: 64.86%\n",
      "Run: 05, Epoch: 08, Loss: 0.6949, Train: 85.06%, Valid: 74.58% Test: 67.57%\n",
      "Run: 05, Epoch: 09, Loss: 0.6764, Train: 88.51%, Valid: 74.58% Test: 70.27%\n",
      "Run: 05, Epoch: 10, Loss: 0.5838, Train: 89.66%, Valid: 76.27% Test: 70.27%\n",
      "Run: 05, Epoch: 11, Loss: 0.5696, Train: 91.95%, Valid: 76.27% Test: 72.97%\n",
      "Run: 05, Epoch: 12, Loss: 0.5295, Train: 95.40%, Valid: 76.27% Test: 72.97%\n",
      "Run: 05, Epoch: 13, Loss: 0.4684, Train: 97.70%, Valid: 77.97% Test: 75.68%\n",
      "Run: 05, Epoch: 14, Loss: 0.4311, Train: 97.70%, Valid: 79.66% Test: 72.97%\n",
      "Run: 05, Epoch: 15, Loss: 0.3740, Train: 98.85%, Valid: 84.75% Test: 70.27%\n",
      "Run: 05, Epoch: 16, Loss: 0.3774, Train: 98.85%, Valid: 83.05% Test: 67.57%\n",
      "Run: 05, Epoch: 17, Loss: 0.3628, Train: 98.85%, Valid: 81.36% Test: 67.57%\n",
      "Run: 05, Epoch: 18, Loss: 0.3335, Train: 98.85%, Valid: 81.36% Test: 67.57%\n",
      "Run: 05, Epoch: 19, Loss: 0.3722, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 20, Loss: 0.2681, Train: 98.85%, Valid: 83.05% Test: 67.57%\n",
      "Run: 05, Epoch: 21, Loss: 0.3000, Train: 98.85%, Valid: 83.05% Test: 67.57%\n",
      "Run: 05, Epoch: 22, Loss: 0.3023, Train: 98.85%, Valid: 83.05% Test: 67.57%\n",
      "Run: 05, Epoch: 23, Loss: 0.2398, Train: 98.85%, Valid: 83.05% Test: 67.57%\n",
      "Run: 05, Epoch: 24, Loss: 0.2510, Train: 98.85%, Valid: 81.36% Test: 67.57%\n",
      "Run: 05, Epoch: 25, Loss: 0.2383, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 26, Loss: 0.1907, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 27, Loss: 0.1995, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 28, Loss: 0.1770, Train: 98.85%, Valid: 81.36% Test: 67.57%\n",
      "Run: 05, Epoch: 29, Loss: 0.1691, Train: 98.85%, Valid: 81.36% Test: 64.86%\n",
      "Run: 05, Epoch: 30, Loss: 0.1710, Train: 98.85%, Valid: 83.05% Test: 62.16%\n",
      "Run: 05, Epoch: 31, Loss: 0.1392, Train: 98.85%, Valid: 79.66% Test: 62.16%\n",
      "Run: 05, Epoch: 32, Loss: 0.1735, Train: 98.85%, Valid: 79.66% Test: 62.16%\n",
      "Run: 05, Epoch: 33, Loss: 0.2480, Train: 98.85%, Valid: 79.66% Test: 62.16%\n",
      "Run: 05, Epoch: 34, Loss: 0.1089, Train: 98.85%, Valid: 77.97% Test: 59.46%\n",
      "Run: 05, Epoch: 35, Loss: 0.1332, Train: 98.85%, Valid: 77.97% Test: 59.46%\n",
      "Run: 05, Epoch: 36, Loss: 0.1236, Train: 98.85%, Valid: 79.66% Test: 59.46%\n",
      "Run: 05, Epoch: 37, Loss: 0.0896, Train: 98.85%, Valid: 77.97% Test: 64.86%\n",
      "Run: 05, Epoch: 38, Loss: 0.1054, Train: 98.85%, Valid: 76.27% Test: 67.57%\n",
      "Run: 05, Epoch: 39, Loss: 0.1576, Train: 98.85%, Valid: 77.97% Test: 64.86%\n",
      "Run: 05, Epoch: 40, Loss: 0.1328, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 05, Epoch: 41, Loss: 0.1154, Train: 98.85%, Valid: 76.27% Test: 64.86%\n",
      "Run: 05, Epoch: 42, Loss: 0.1161, Train: 98.85%, Valid: 77.97% Test: 64.86%\n",
      "Run: 05, Epoch: 43, Loss: 0.1249, Train: 98.85%, Valid: 77.97% Test: 64.86%\n",
      "Run: 05, Epoch: 44, Loss: 0.1693, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 45, Loss: 0.1159, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 46, Loss: 0.1277, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 47, Loss: 0.1101, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 48, Loss: 0.0789, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 49, Loss: 0.1077, Train: 98.85%, Valid: 79.66% Test: 62.16%\n",
      "Run: 05, Epoch: 50, Loss: 0.0672, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 51, Loss: 0.0952, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 52, Loss: 0.1437, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 53, Loss: 0.0831, Train: 98.85%, Valid: 77.97% Test: 64.86%\n",
      "Run: 05, Epoch: 54, Loss: 0.1454, Train: 98.85%, Valid: 76.27% Test: 67.57%\n",
      "Run: 05, Epoch: 55, Loss: 0.0495, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 56, Loss: 0.1571, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 57, Loss: 0.0938, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 58, Loss: 0.0901, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 59, Loss: 0.0615, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 05, Epoch: 60, Loss: 0.0768, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 05, Epoch: 61, Loss: 0.0747, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 05, Epoch: 62, Loss: 0.0421, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 05, Epoch: 63, Loss: 0.0536, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 05, Epoch: 64, Loss: 0.0698, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 65, Loss: 0.0615, Train: 98.85%, Valid: 76.27% Test: 64.86%\n",
      "Run: 05, Epoch: 66, Loss: 0.0455, Train: 98.85%, Valid: 76.27% Test: 64.86%\n",
      "Run: 05, Epoch: 67, Loss: 0.0511, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 68, Loss: 0.1801, Train: 98.85%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 69, Loss: 0.0568, Train: 98.85%, Valid: 81.36% Test: 64.86%\n",
      "Run: 05, Epoch: 70, Loss: 0.0528, Train: 98.85%, Valid: 81.36% Test: 67.57%\n",
      "Run: 05, Epoch: 71, Loss: 0.1209, Train: 98.85%, Valid: 81.36% Test: 67.57%\n",
      "Run: 05, Epoch: 72, Loss: 0.0593, Train: 100.00%, Valid: 84.75% Test: 67.57%\n",
      "Run: 05, Epoch: 73, Loss: 0.0733, Train: 100.00%, Valid: 84.75% Test: 67.57%\n",
      "Run: 05, Epoch: 74, Loss: 0.0455, Train: 100.00%, Valid: 84.75% Test: 67.57%\n",
      "Run: 05, Epoch: 75, Loss: 0.1208, Train: 100.00%, Valid: 84.75% Test: 67.57%\n",
      "Run: 05, Epoch: 76, Loss: 0.0555, Train: 100.00%, Valid: 86.44% Test: 67.57%\n",
      "Run: 05, Epoch: 77, Loss: 0.0701, Train: 100.00%, Valid: 84.75% Test: 67.57%\n",
      "Run: 05, Epoch: 78, Loss: 0.0550, Train: 100.00%, Valid: 81.36% Test: 70.27%\n",
      "Run: 05, Epoch: 79, Loss: 0.0423, Train: 100.00%, Valid: 81.36% Test: 70.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 80, Loss: 0.0751, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 05, Epoch: 81, Loss: 0.0576, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 82, Loss: 0.0750, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 05, Epoch: 83, Loss: 0.0301, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 05, Epoch: 84, Loss: 0.0592, Train: 100.00%, Valid: 81.36% Test: 67.57%\n",
      "Run: 05, Epoch: 85, Loss: 0.0983, Train: 100.00%, Valid: 81.36% Test: 64.86%\n",
      "Run: 05, Epoch: 86, Loss: 0.0484, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 87, Loss: 0.0410, Train: 100.00%, Valid: 79.66% Test: 62.16%\n",
      "Run: 05, Epoch: 88, Loss: 0.0350, Train: 100.00%, Valid: 79.66% Test: 62.16%\n",
      "Run: 05, Epoch: 89, Loss: 0.0933, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 90, Loss: 0.0996, Train: 100.00%, Valid: 79.66% Test: 67.57%\n",
      "Run: 05, Epoch: 91, Loss: 0.0601, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 05, Epoch: 92, Loss: 0.1152, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 05, Epoch: 93, Loss: 0.0478, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 05, Epoch: 94, Loss: 0.0374, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 05, Epoch: 95, Loss: 0.0386, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 05, Epoch: 96, Loss: 0.0267, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 05, Epoch: 97, Loss: 0.0617, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 05, Epoch: 98, Loss: 0.0842, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 05, Epoch: 99, Loss: 0.0904, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 05, Epoch: 100, Loss: 0.0340, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 05, Epoch: 101, Loss: 0.0504, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 05, Epoch: 102, Loss: 0.0911, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 05, Epoch: 103, Loss: 0.0320, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 05, Epoch: 104, Loss: 0.0416, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 05, Epoch: 105, Loss: 0.0440, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 05, Epoch: 106, Loss: 0.0156, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 05, Epoch: 107, Loss: 0.0254, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 05, Epoch: 108, Loss: 0.0246, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 109, Loss: 0.1260, Train: 100.00%, Valid: 79.66% Test: 64.86%\n",
      "Run: 05, Epoch: 110, Loss: 0.0576, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 05, Epoch: 111, Loss: 0.0395, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 05, Epoch: 112, Loss: 0.0396, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 05, Epoch: 113, Loss: 0.0545, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 05, Epoch: 114, Loss: 0.0233, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 05, Epoch: 115, Loss: 0.0303, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 05, Epoch: 116, Loss: 0.0237, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 05, Epoch: 117, Loss: 0.0859, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 05, Epoch: 118, Loss: 0.0302, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 05, Epoch: 119, Loss: 0.0592, Train: 100.00%, Valid: 72.88% Test: 70.27%\n",
      "Run: 05, Epoch: 120, Loss: 0.0291, Train: 100.00%, Valid: 72.88% Test: 70.27%\n",
      "Run: 05, Epoch: 121, Loss: 0.0289, Train: 100.00%, Valid: 72.88% Test: 70.27%\n",
      "Run: 05, Epoch: 122, Loss: 0.0566, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 05, Epoch: 123, Loss: 0.0218, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 05, Epoch: 124, Loss: 0.0781, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 05, Epoch: 125, Loss: 0.0229, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 05, Epoch: 126, Loss: 0.0683, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 05, Epoch: 127, Loss: 0.0847, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 128, Loss: 0.0262, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 05, Epoch: 129, Loss: 0.0513, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 05, Epoch: 130, Loss: 0.0171, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 131, Loss: 0.0240, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 132, Loss: 0.0568, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 05, Epoch: 133, Loss: 0.0233, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 05, Epoch: 134, Loss: 0.0374, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 05, Epoch: 135, Loss: 0.0646, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 05, Epoch: 136, Loss: 0.0136, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 137, Loss: 0.0194, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 138, Loss: 0.0114, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 139, Loss: 0.0308, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 05, Epoch: 140, Loss: 0.1119, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 05, Epoch: 141, Loss: 0.0909, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 05, Epoch: 142, Loss: 0.0269, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 05, Epoch: 143, Loss: 0.0358, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 144, Loss: 0.0123, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 05, Epoch: 145, Loss: 0.0204, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 05, Epoch: 146, Loss: 0.0946, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 147, Loss: 0.0150, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 148, Loss: 0.0262, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 149, Loss: 0.0224, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 150, Loss: 0.0112, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 05, Epoch: 151, Loss: 0.0154, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 05, Epoch: 152, Loss: 0.0346, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 05, Epoch: 153, Loss: 0.0633, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 05, Epoch: 154, Loss: 0.0466, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 155, Loss: 0.0808, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 05, Epoch: 156, Loss: 0.0527, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 157, Loss: 0.0384, Train: 100.00%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 158, Loss: 0.0482, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 159, Loss: 0.0103, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 05, Epoch: 160, Loss: 0.0485, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 05, Epoch: 161, Loss: 0.0111, Train: 100.00%, Valid: 62.71% Test: 62.16%\n",
      "Run: 05, Epoch: 162, Loss: 0.0464, Train: 100.00%, Valid: 62.71% Test: 62.16%\n",
      "Run: 05, Epoch: 163, Loss: 0.0745, Train: 100.00%, Valid: 61.02% Test: 62.16%\n",
      "Run: 05, Epoch: 164, Loss: 0.0185, Train: 100.00%, Valid: 62.71% Test: 62.16%\n",
      "Run: 05, Epoch: 165, Loss: 0.0088, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 05, Epoch: 166, Loss: 0.0129, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 05, Epoch: 167, Loss: 0.0613, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 05, Epoch: 168, Loss: 0.0185, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 05, Epoch: 169, Loss: 0.0100, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 05, Epoch: 170, Loss: 0.0085, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 05, Epoch: 171, Loss: 0.0269, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 05, Epoch: 172, Loss: 0.0214, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 05, Epoch: 173, Loss: 0.0429, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 05, Epoch: 174, Loss: 0.0584, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 05, Epoch: 175, Loss: 0.0058, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 05, Epoch: 176, Loss: 0.0135, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 05, Epoch: 177, Loss: 0.0155, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 05, Epoch: 178, Loss: 0.0409, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 179, Loss: 0.0519, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 05, Epoch: 180, Loss: 0.0277, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 05, Epoch: 181, Loss: 0.1206, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 05, Epoch: 182, Loss: 0.0400, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 05, Epoch: 183, Loss: 0.0541, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 05, Epoch: 184, Loss: 0.0501, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 05, Epoch: 185, Loss: 0.0287, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 05, Epoch: 186, Loss: 0.0256, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 05, Epoch: 187, Loss: 0.0062, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 05, Epoch: 188, Loss: 0.0177, Train: 100.00%, Valid: 61.02% Test: 62.16%\n",
      "Run: 05, Epoch: 189, Loss: 0.0953, Train: 100.00%, Valid: 62.71% Test: 62.16%\n",
      "Run: 05, Epoch: 190, Loss: 0.0675, Train: 100.00%, Valid: 62.71% Test: 62.16%\n",
      "Run: 05, Epoch: 191, Loss: 0.0742, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 05, Epoch: 192, Loss: 0.0532, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 05, Epoch: 193, Loss: 0.0207, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 194, Loss: 0.0116, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 05, Epoch: 195, Loss: 0.0883, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 05, Epoch: 196, Loss: 0.0374, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 197, Loss: 0.0406, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 198, Loss: 0.0532, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 05, Epoch: 199, Loss: 0.0434, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 05, Epoch: 200, Loss: 0.0384, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run 05:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 86.44\n",
      "  Final Train: 100.00\n",
      "   Final Test: 67.57\n",
      "Run: 06, Epoch: 01, Loss: 1.6319, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 02, Loss: 1.3216, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 03, Loss: 1.0178, Train: 51.72%, Valid: 59.32% Test: 56.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 04, Loss: 0.9478, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 05, Loss: 0.8783, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 06, Epoch: 06, Loss: 0.8346, Train: 56.32%, Valid: 59.32% Test: 59.46%\n",
      "Run: 06, Epoch: 07, Loss: 0.8121, Train: 75.86%, Valid: 61.02% Test: 67.57%\n",
      "Run: 06, Epoch: 08, Loss: 0.7622, Train: 81.61%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 09, Loss: 0.7863, Train: 86.21%, Valid: 66.10% Test: 70.27%\n",
      "Run: 06, Epoch: 10, Loss: 0.6751, Train: 88.51%, Valid: 62.71% Test: 67.57%\n",
      "Run: 06, Epoch: 11, Loss: 0.6161, Train: 88.51%, Valid: 62.71% Test: 67.57%\n",
      "Run: 06, Epoch: 12, Loss: 0.5484, Train: 88.51%, Valid: 66.10% Test: 70.27%\n",
      "Run: 06, Epoch: 13, Loss: 0.5010, Train: 88.51%, Valid: 66.10% Test: 70.27%\n",
      "Run: 06, Epoch: 14, Loss: 0.5179, Train: 88.51%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 15, Loss: 0.4817, Train: 90.80%, Valid: 66.10% Test: 70.27%\n",
      "Run: 06, Epoch: 16, Loss: 0.4665, Train: 93.10%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 17, Loss: 0.4304, Train: 95.40%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 18, Loss: 0.4175, Train: 95.40%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 19, Loss: 0.3459, Train: 94.25%, Valid: 64.41% Test: 67.57%\n",
      "Run: 06, Epoch: 20, Loss: 0.3847, Train: 94.25%, Valid: 64.41% Test: 67.57%\n",
      "Run: 06, Epoch: 21, Loss: 0.3460, Train: 91.95%, Valid: 64.41% Test: 70.27%\n",
      "Run: 06, Epoch: 22, Loss: 0.3586, Train: 93.10%, Valid: 66.10% Test: 70.27%\n",
      "Run: 06, Epoch: 23, Loss: 0.3214, Train: 93.10%, Valid: 66.10% Test: 70.27%\n",
      "Run: 06, Epoch: 24, Loss: 0.3341, Train: 91.95%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 25, Loss: 0.2672, Train: 95.40%, Valid: 67.80% Test: 78.38%\n",
      "Run: 06, Epoch: 26, Loss: 0.3143, Train: 94.25%, Valid: 69.49% Test: 81.08%\n",
      "Run: 06, Epoch: 27, Loss: 0.2970, Train: 96.55%, Valid: 69.49% Test: 81.08%\n",
      "Run: 06, Epoch: 28, Loss: 0.2246, Train: 97.70%, Valid: 69.49% Test: 81.08%\n",
      "Run: 06, Epoch: 29, Loss: 0.3242, Train: 97.70%, Valid: 69.49% Test: 81.08%\n",
      "Run: 06, Epoch: 30, Loss: 0.2221, Train: 98.85%, Valid: 67.80% Test: 81.08%\n",
      "Run: 06, Epoch: 31, Loss: 0.2514, Train: 98.85%, Valid: 67.80% Test: 81.08%\n",
      "Run: 06, Epoch: 32, Loss: 0.2433, Train: 98.85%, Valid: 67.80% Test: 81.08%\n",
      "Run: 06, Epoch: 33, Loss: 0.1765, Train: 98.85%, Valid: 67.80% Test: 81.08%\n",
      "Run: 06, Epoch: 34, Loss: 0.2099, Train: 98.85%, Valid: 67.80% Test: 81.08%\n",
      "Run: 06, Epoch: 35, Loss: 0.1806, Train: 98.85%, Valid: 67.80% Test: 81.08%\n",
      "Run: 06, Epoch: 36, Loss: 0.2009, Train: 98.85%, Valid: 67.80% Test: 81.08%\n",
      "Run: 06, Epoch: 37, Loss: 0.1387, Train: 98.85%, Valid: 69.49% Test: 81.08%\n",
      "Run: 06, Epoch: 38, Loss: 0.1562, Train: 98.85%, Valid: 69.49% Test: 81.08%\n",
      "Run: 06, Epoch: 39, Loss: 0.1911, Train: 98.85%, Valid: 69.49% Test: 81.08%\n",
      "Run: 06, Epoch: 40, Loss: 0.1796, Train: 98.85%, Valid: 71.19% Test: 81.08%\n",
      "Run: 06, Epoch: 41, Loss: 0.2376, Train: 98.85%, Valid: 71.19% Test: 78.38%\n",
      "Run: 06, Epoch: 42, Loss: 0.1943, Train: 98.85%, Valid: 71.19% Test: 78.38%\n",
      "Run: 06, Epoch: 43, Loss: 0.1550, Train: 98.85%, Valid: 71.19% Test: 78.38%\n",
      "Run: 06, Epoch: 44, Loss: 0.0859, Train: 98.85%, Valid: 71.19% Test: 78.38%\n",
      "Run: 06, Epoch: 45, Loss: 0.1872, Train: 98.85%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 46, Loss: 0.1477, Train: 98.85%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 47, Loss: 0.1693, Train: 98.85%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 48, Loss: 0.1935, Train: 98.85%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 49, Loss: 0.1384, Train: 98.85%, Valid: 71.19% Test: 75.68%\n",
      "Run: 06, Epoch: 50, Loss: 0.1752, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 06, Epoch: 51, Loss: 0.1155, Train: 98.85%, Valid: 67.80% Test: 75.68%\n",
      "Run: 06, Epoch: 52, Loss: 0.2589, Train: 98.85%, Valid: 69.49% Test: 70.27%\n",
      "Run: 06, Epoch: 53, Loss: 0.1209, Train: 98.85%, Valid: 69.49% Test: 70.27%\n",
      "Run: 06, Epoch: 54, Loss: 0.1272, Train: 98.85%, Valid: 69.49% Test: 70.27%\n",
      "Run: 06, Epoch: 55, Loss: 0.1107, Train: 98.85%, Valid: 69.49% Test: 70.27%\n",
      "Run: 06, Epoch: 56, Loss: 0.0827, Train: 98.85%, Valid: 69.49% Test: 72.97%\n",
      "Run: 06, Epoch: 57, Loss: 0.1321, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 06, Epoch: 58, Loss: 0.0913, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 06, Epoch: 59, Loss: 0.1365, Train: 98.85%, Valid: 67.80% Test: 78.38%\n",
      "Run: 06, Epoch: 60, Loss: 0.0881, Train: 98.85%, Valid: 67.80% Test: 78.38%\n",
      "Run: 06, Epoch: 61, Loss: 0.1475, Train: 98.85%, Valid: 67.80% Test: 78.38%\n",
      "Run: 06, Epoch: 62, Loss: 0.1180, Train: 98.85%, Valid: 69.49% Test: 78.38%\n",
      "Run: 06, Epoch: 63, Loss: 0.1094, Train: 98.85%, Valid: 71.19% Test: 81.08%\n",
      "Run: 06, Epoch: 64, Loss: 0.1446, Train: 98.85%, Valid: 71.19% Test: 78.38%\n",
      "Run: 06, Epoch: 65, Loss: 0.1690, Train: 98.85%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 66, Loss: 0.0819, Train: 98.85%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 67, Loss: 0.0793, Train: 98.85%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 68, Loss: 0.0859, Train: 98.85%, Valid: 71.19% Test: 75.68%\n",
      "Run: 06, Epoch: 69, Loss: 0.0894, Train: 98.85%, Valid: 71.19% Test: 75.68%\n",
      "Run: 06, Epoch: 70, Loss: 0.1232, Train: 98.85%, Valid: 71.19% Test: 75.68%\n",
      "Run: 06, Epoch: 71, Loss: 0.1018, Train: 98.85%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 72, Loss: 0.1207, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 06, Epoch: 73, Loss: 0.0459, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 74, Loss: 0.1165, Train: 100.00%, Valid: 71.19% Test: 78.38%\n",
      "Run: 06, Epoch: 75, Loss: 0.0554, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 06, Epoch: 76, Loss: 0.1175, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 06, Epoch: 77, Loss: 0.1681, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 78, Loss: 0.0630, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 79, Loss: 0.1173, Train: 100.00%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 80, Loss: 0.0817, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 81, Loss: 0.0762, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 82, Loss: 0.0742, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 83, Loss: 0.0715, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 84, Loss: 0.0958, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 06, Epoch: 85, Loss: 0.1255, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 06, Epoch: 86, Loss: 0.1129, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 87, Loss: 0.1187, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 88, Loss: 0.1253, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 89, Loss: 0.0876, Train: 100.00%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 90, Loss: 0.0444, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 91, Loss: 0.0488, Train: 100.00%, Valid: 64.41% Test: 78.38%\n",
      "Run: 06, Epoch: 92, Loss: 0.1089, Train: 100.00%, Valid: 64.41% Test: 78.38%\n",
      "Run: 06, Epoch: 93, Loss: 0.0739, Train: 100.00%, Valid: 64.41% Test: 78.38%\n",
      "Run: 06, Epoch: 94, Loss: 0.0557, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 95, Loss: 0.0553, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 96, Loss: 0.0652, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 97, Loss: 0.0512, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 98, Loss: 0.0340, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 99, Loss: 0.0657, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 100, Loss: 0.0636, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 101, Loss: 0.0269, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 102, Loss: 0.0487, Train: 100.00%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 103, Loss: 0.1285, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 06, Epoch: 104, Loss: 0.1145, Train: 100.00%, Valid: 61.02% Test: 72.97%\n",
      "Run: 06, Epoch: 105, Loss: 0.0853, Train: 100.00%, Valid: 61.02% Test: 72.97%\n",
      "Run: 06, Epoch: 106, Loss: 0.0300, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 06, Epoch: 107, Loss: 0.0389, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 06, Epoch: 108, Loss: 0.0596, Train: 100.00%, Valid: 62.71% Test: 70.27%\n",
      "Run: 06, Epoch: 109, Loss: 0.0873, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 06, Epoch: 110, Loss: 0.1015, Train: 100.00%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 111, Loss: 0.0415, Train: 100.00%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 112, Loss: 0.0260, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 113, Loss: 0.0320, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 114, Loss: 0.0396, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 06, Epoch: 115, Loss: 0.0726, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 06, Epoch: 116, Loss: 0.0973, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 06, Epoch: 117, Loss: 0.0362, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 06, Epoch: 118, Loss: 0.0279, Train: 100.00%, Valid: 64.41% Test: 78.38%\n",
      "Run: 06, Epoch: 119, Loss: 0.0400, Train: 100.00%, Valid: 64.41% Test: 78.38%\n",
      "Run: 06, Epoch: 120, Loss: 0.0680, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 121, Loss: 0.0730, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 122, Loss: 0.0428, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 123, Loss: 0.0402, Train: 100.00%, Valid: 64.41% Test: 78.38%\n",
      "Run: 06, Epoch: 124, Loss: 0.0699, Train: 100.00%, Valid: 64.41% Test: 78.38%\n",
      "Run: 06, Epoch: 125, Loss: 0.1045, Train: 100.00%, Valid: 61.02% Test: 78.38%\n",
      "Run: 06, Epoch: 126, Loss: 0.1946, Train: 100.00%, Valid: 61.02% Test: 75.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 127, Loss: 0.0389, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 128, Loss: 0.0271, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 129, Loss: 0.0412, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 130, Loss: 0.0319, Train: 100.00%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 131, Loss: 0.0372, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 132, Loss: 0.0181, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 133, Loss: 0.0444, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 134, Loss: 0.0571, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 135, Loss: 0.0512, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 136, Loss: 0.0390, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 137, Loss: 0.1589, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 138, Loss: 0.0118, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 139, Loss: 0.0172, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 140, Loss: 0.0160, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 141, Loss: 0.0453, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 142, Loss: 0.0438, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 06, Epoch: 143, Loss: 0.0875, Train: 100.00%, Valid: 64.41% Test: 81.08%\n",
      "Run: 06, Epoch: 144, Loss: 0.0439, Train: 100.00%, Valid: 64.41% Test: 81.08%\n",
      "Run: 06, Epoch: 145, Loss: 0.0811, Train: 100.00%, Valid: 64.41% Test: 81.08%\n",
      "Run: 06, Epoch: 146, Loss: 0.0437, Train: 100.00%, Valid: 64.41% Test: 81.08%\n",
      "Run: 06, Epoch: 147, Loss: 0.0299, Train: 100.00%, Valid: 67.80% Test: 75.68%\n",
      "Run: 06, Epoch: 148, Loss: 0.0290, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 149, Loss: 0.0796, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 150, Loss: 0.0362, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 06, Epoch: 151, Loss: 0.0577, Train: 100.00%, Valid: 61.02% Test: 75.68%\n",
      "Run: 06, Epoch: 152, Loss: 0.0698, Train: 100.00%, Valid: 61.02% Test: 72.97%\n",
      "Run: 06, Epoch: 153, Loss: 0.0389, Train: 100.00%, Valid: 59.32% Test: 72.97%\n",
      "Run: 06, Epoch: 154, Loss: 0.0408, Train: 100.00%, Valid: 59.32% Test: 72.97%\n",
      "Run: 06, Epoch: 155, Loss: 0.0136, Train: 100.00%, Valid: 59.32% Test: 75.68%\n",
      "Run: 06, Epoch: 156, Loss: 0.0179, Train: 100.00%, Valid: 57.63% Test: 75.68%\n",
      "Run: 06, Epoch: 157, Loss: 0.0865, Train: 100.00%, Valid: 61.02% Test: 72.97%\n",
      "Run: 06, Epoch: 158, Loss: 0.0550, Train: 100.00%, Valid: 59.32% Test: 72.97%\n",
      "Run: 06, Epoch: 159, Loss: 0.0144, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 06, Epoch: 160, Loss: 0.0423, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 06, Epoch: 161, Loss: 0.0917, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 06, Epoch: 162, Loss: 0.0250, Train: 100.00%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 163, Loss: 0.0335, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 06, Epoch: 164, Loss: 0.0223, Train: 100.00%, Valid: 64.41% Test: 70.27%\n",
      "Run: 06, Epoch: 165, Loss: 0.0449, Train: 100.00%, Valid: 64.41% Test: 70.27%\n",
      "Run: 06, Epoch: 166, Loss: 0.0118, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 06, Epoch: 167, Loss: 0.0165, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 168, Loss: 0.0180, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 169, Loss: 0.0200, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 170, Loss: 0.0209, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 171, Loss: 0.0992, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 172, Loss: 0.0206, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 173, Loss: 0.0210, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 174, Loss: 0.0535, Train: 100.00%, Valid: 67.80% Test: 75.68%\n",
      "Run: 06, Epoch: 175, Loss: 0.0446, Train: 100.00%, Valid: 67.80% Test: 75.68%\n",
      "Run: 06, Epoch: 176, Loss: 0.0642, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 177, Loss: 0.0332, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 06, Epoch: 178, Loss: 0.0332, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 06, Epoch: 179, Loss: 0.0510, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 180, Loss: 0.1273, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 181, Loss: 0.0274, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 182, Loss: 0.0071, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 183, Loss: 0.0320, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 184, Loss: 0.0175, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 185, Loss: 0.0369, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 186, Loss: 0.0308, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 06, Epoch: 187, Loss: 0.0120, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 06, Epoch: 188, Loss: 0.0221, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 189, Loss: 0.0173, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 190, Loss: 0.0192, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 06, Epoch: 191, Loss: 0.0375, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 06, Epoch: 192, Loss: 0.0173, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 06, Epoch: 193, Loss: 0.0318, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 06, Epoch: 194, Loss: 0.1187, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 06, Epoch: 195, Loss: 0.0184, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 06, Epoch: 196, Loss: 0.0154, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 06, Epoch: 197, Loss: 0.0456, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 06, Epoch: 198, Loss: 0.0285, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 06, Epoch: 199, Loss: 0.0279, Train: 100.00%, Valid: 64.41% Test: 70.27%\n",
      "Run: 06, Epoch: 200, Loss: 0.0282, Train: 100.00%, Valid: 64.41% Test: 70.27%\n",
      "Run 06:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 74.58\n",
      "  Final Train: 98.85\n",
      "   Final Test: 78.38\n",
      "Run: 07, Epoch: 01, Loss: 1.7080, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 02, Loss: 1.3676, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 03, Loss: 1.1280, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 04, Loss: 0.9509, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 05, Loss: 0.8996, Train: 51.72%, Valid: 59.32% Test: 56.76%\n",
      "Run: 07, Epoch: 06, Loss: 0.8166, Train: 66.67%, Valid: 72.88% Test: 59.46%\n",
      "Run: 07, Epoch: 07, Loss: 0.7562, Train: 77.01%, Valid: 77.97% Test: 64.86%\n",
      "Run: 07, Epoch: 08, Loss: 0.7159, Train: 82.76%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 09, Loss: 0.6747, Train: 83.91%, Valid: 81.36% Test: 70.27%\n",
      "Run: 07, Epoch: 10, Loss: 0.6408, Train: 89.66%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 11, Loss: 0.5758, Train: 91.95%, Valid: 77.97% Test: 70.27%\n",
      "Run: 07, Epoch: 12, Loss: 0.5346, Train: 93.10%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 13, Loss: 0.5234, Train: 95.40%, Valid: 83.05% Test: 70.27%\n",
      "Run: 07, Epoch: 14, Loss: 0.4759, Train: 95.40%, Valid: 84.75% Test: 70.27%\n",
      "Run: 07, Epoch: 15, Loss: 0.3803, Train: 94.25%, Valid: 84.75% Test: 70.27%\n",
      "Run: 07, Epoch: 16, Loss: 0.3649, Train: 95.40%, Valid: 84.75% Test: 70.27%\n",
      "Run: 07, Epoch: 17, Loss: 0.4509, Train: 96.55%, Valid: 84.75% Test: 70.27%\n",
      "Run: 07, Epoch: 18, Loss: 0.3935, Train: 96.55%, Valid: 84.75% Test: 72.97%\n",
      "Run: 07, Epoch: 19, Loss: 0.4414, Train: 96.55%, Valid: 86.44% Test: 72.97%\n",
      "Run: 07, Epoch: 20, Loss: 0.3567, Train: 97.70%, Valid: 86.44% Test: 72.97%\n",
      "Run: 07, Epoch: 21, Loss: 0.3396, Train: 97.70%, Valid: 83.05% Test: 72.97%\n",
      "Run: 07, Epoch: 22, Loss: 0.2762, Train: 97.70%, Valid: 81.36% Test: 72.97%\n",
      "Run: 07, Epoch: 23, Loss: 0.3271, Train: 97.70%, Valid: 77.97% Test: 75.68%\n",
      "Run: 07, Epoch: 24, Loss: 0.2994, Train: 97.70%, Valid: 77.97% Test: 72.97%\n",
      "Run: 07, Epoch: 25, Loss: 0.3054, Train: 97.70%, Valid: 77.97% Test: 72.97%\n",
      "Run: 07, Epoch: 26, Loss: 0.2583, Train: 97.70%, Valid: 83.05% Test: 72.97%\n",
      "Run: 07, Epoch: 27, Loss: 0.2045, Train: 97.70%, Valid: 81.36% Test: 72.97%\n",
      "Run: 07, Epoch: 28, Loss: 0.2228, Train: 97.70%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 29, Loss: 0.2220, Train: 97.70%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 30, Loss: 0.2509, Train: 97.70%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 31, Loss: 0.1925, Train: 97.70%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 32, Loss: 0.2274, Train: 97.70%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 33, Loss: 0.1947, Train: 97.70%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 34, Loss: 0.1992, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 35, Loss: 0.1269, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 36, Loss: 0.1395, Train: 98.85%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 37, Loss: 0.1025, Train: 98.85%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 38, Loss: 0.1338, Train: 98.85%, Valid: 77.97% Test: 72.97%\n",
      "Run: 07, Epoch: 39, Loss: 0.1280, Train: 98.85%, Valid: 79.66% Test: 75.68%\n",
      "Run: 07, Epoch: 40, Loss: 0.1344, Train: 98.85%, Valid: 79.66% Test: 72.97%\n",
      "Run: 07, Epoch: 41, Loss: 0.1373, Train: 98.85%, Valid: 79.66% Test: 72.97%\n",
      "Run: 07, Epoch: 42, Loss: 0.1461, Train: 98.85%, Valid: 79.66% Test: 72.97%\n",
      "Run: 07, Epoch: 43, Loss: 0.1257, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 44, Loss: 0.1434, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 45, Loss: 0.0963, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 46, Loss: 0.1238, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 47, Loss: 0.1786, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 48, Loss: 0.0964, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 49, Loss: 0.1165, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 50, Loss: 0.1497, Train: 97.70%, Valid: 81.36% Test: 67.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 51, Loss: 0.1098, Train: 98.85%, Valid: 79.66% Test: 67.57%\n",
      "Run: 07, Epoch: 52, Loss: 0.1235, Train: 98.85%, Valid: 77.97% Test: 64.86%\n",
      "Run: 07, Epoch: 53, Loss: 0.1275, Train: 98.85%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 54, Loss: 0.2186, Train: 98.85%, Valid: 77.97% Test: 70.27%\n",
      "Run: 07, Epoch: 55, Loss: 0.0671, Train: 98.85%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 56, Loss: 0.0793, Train: 98.85%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 57, Loss: 0.0985, Train: 98.85%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 58, Loss: 0.1433, Train: 98.85%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 59, Loss: 0.0908, Train: 98.85%, Valid: 77.97% Test: 70.27%\n",
      "Run: 07, Epoch: 60, Loss: 0.0879, Train: 98.85%, Valid: 76.27% Test: 72.97%\n",
      "Run: 07, Epoch: 61, Loss: 0.0627, Train: 98.85%, Valid: 77.97% Test: 70.27%\n",
      "Run: 07, Epoch: 62, Loss: 0.1022, Train: 98.85%, Valid: 77.97% Test: 70.27%\n",
      "Run: 07, Epoch: 63, Loss: 0.0645, Train: 97.70%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 64, Loss: 0.0936, Train: 97.70%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 65, Loss: 0.1061, Train: 97.70%, Valid: 77.97% Test: 70.27%\n",
      "Run: 07, Epoch: 66, Loss: 0.1004, Train: 98.85%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 67, Loss: 0.0736, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 68, Loss: 0.1316, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 69, Loss: 0.0821, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 70, Loss: 0.0637, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 71, Loss: 0.0730, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 72, Loss: 0.0957, Train: 98.85%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 73, Loss: 0.0558, Train: 98.85%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 74, Loss: 0.1049, Train: 98.85%, Valid: 72.88% Test: 64.86%\n",
      "Run: 07, Epoch: 75, Loss: 0.0656, Train: 98.85%, Valid: 72.88% Test: 62.16%\n",
      "Run: 07, Epoch: 76, Loss: 0.0697, Train: 98.85%, Valid: 72.88% Test: 62.16%\n",
      "Run: 07, Epoch: 77, Loss: 0.0983, Train: 98.85%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 78, Loss: 0.0503, Train: 98.85%, Valid: 72.88% Test: 70.27%\n",
      "Run: 07, Epoch: 79, Loss: 0.1257, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 80, Loss: 0.1127, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 81, Loss: 0.0665, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 82, Loss: 0.1440, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 83, Loss: 0.0750, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 84, Loss: 0.1030, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 85, Loss: 0.0565, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 86, Loss: 0.0790, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 87, Loss: 0.0919, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 88, Loss: 0.1048, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 89, Loss: 0.0816, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 90, Loss: 0.0420, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 91, Loss: 0.0426, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 07, Epoch: 92, Loss: 0.0271, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 07, Epoch: 93, Loss: 0.0495, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 07, Epoch: 94, Loss: 0.0737, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 95, Loss: 0.0337, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 07, Epoch: 96, Loss: 0.0817, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 07, Epoch: 97, Loss: 0.0577, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 98, Loss: 0.0632, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 99, Loss: 0.0543, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 100, Loss: 0.0168, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 07, Epoch: 101, Loss: 0.1294, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 07, Epoch: 102, Loss: 0.0971, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 103, Loss: 0.0668, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 104, Loss: 0.0812, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 105, Loss: 0.1152, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 106, Loss: 0.0318, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 107, Loss: 0.0613, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 108, Loss: 0.0640, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 109, Loss: 0.0344, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 110, Loss: 0.0478, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 111, Loss: 0.0627, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 112, Loss: 0.0349, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 113, Loss: 0.0574, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 114, Loss: 0.0205, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 115, Loss: 0.0574, Train: 100.00%, Valid: 74.58% Test: 72.97%\n",
      "Run: 07, Epoch: 116, Loss: 0.0908, Train: 100.00%, Valid: 76.27% Test: 72.97%\n",
      "Run: 07, Epoch: 117, Loss: 0.0530, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 118, Loss: 0.0489, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 119, Loss: 0.0360, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 120, Loss: 0.0160, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 121, Loss: 0.0427, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 122, Loss: 0.0414, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 123, Loss: 0.1066, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 124, Loss: 0.0737, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 125, Loss: 0.0388, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 126, Loss: 0.0532, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 07, Epoch: 127, Loss: 0.0599, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 128, Loss: 0.0259, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 129, Loss: 0.0964, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 130, Loss: 0.0596, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 131, Loss: 0.0171, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 132, Loss: 0.0292, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 133, Loss: 0.0183, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 134, Loss: 0.1157, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 135, Loss: 0.0722, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 136, Loss: 0.0848, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 137, Loss: 0.0417, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 07, Epoch: 138, Loss: 0.0678, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 139, Loss: 0.0396, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 140, Loss: 0.0372, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 141, Loss: 0.0809, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 142, Loss: 0.0443, Train: 100.00%, Valid: 77.97% Test: 67.57%\n",
      "Run: 07, Epoch: 143, Loss: 0.1038, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 144, Loss: 0.1012, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 145, Loss: 0.0532, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 146, Loss: 0.0546, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 147, Loss: 0.0427, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 148, Loss: 0.0379, Train: 100.00%, Valid: 79.66% Test: 70.27%\n",
      "Run: 07, Epoch: 149, Loss: 0.0528, Train: 100.00%, Valid: 77.97% Test: 70.27%\n",
      "Run: 07, Epoch: 150, Loss: 0.0898, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 151, Loss: 0.0250, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 152, Loss: 0.0309, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 153, Loss: 0.0409, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 154, Loss: 0.0247, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 155, Loss: 0.0106, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 156, Loss: 0.0141, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 157, Loss: 0.0658, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 158, Loss: 0.0699, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 159, Loss: 0.0927, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 160, Loss: 0.0203, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 161, Loss: 0.0319, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 162, Loss: 0.0391, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 163, Loss: 0.0286, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 164, Loss: 0.0198, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 165, Loss: 0.0169, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 166, Loss: 0.0098, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 167, Loss: 0.1054, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 168, Loss: 0.0199, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 169, Loss: 0.0684, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 170, Loss: 0.0311, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 171, Loss: 0.0798, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 172, Loss: 0.0380, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 173, Loss: 0.0123, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 174, Loss: 0.0265, Train: 100.00%, Valid: 74.58% Test: 70.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 175, Loss: 0.0366, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 176, Loss: 0.0856, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 07, Epoch: 177, Loss: 0.0222, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 178, Loss: 0.0179, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 179, Loss: 0.0504, Train: 100.00%, Valid: 76.27% Test: 70.27%\n",
      "Run: 07, Epoch: 180, Loss: 0.0660, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 07, Epoch: 181, Loss: 0.0280, Train: 100.00%, Valid: 77.97% Test: 72.97%\n",
      "Run: 07, Epoch: 182, Loss: 0.0778, Train: 100.00%, Valid: 74.58% Test: 70.27%\n",
      "Run: 07, Epoch: 183, Loss: 0.0239, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 07, Epoch: 184, Loss: 0.0636, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 07, Epoch: 185, Loss: 0.0475, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 186, Loss: 0.0186, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 187, Loss: 0.0231, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 07, Epoch: 188, Loss: 0.0110, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 189, Loss: 0.0477, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 190, Loss: 0.0245, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 191, Loss: 0.0746, Train: 100.00%, Valid: 77.97% Test: 64.86%\n",
      "Run: 07, Epoch: 192, Loss: 0.0312, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 07, Epoch: 193, Loss: 0.0280, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 07, Epoch: 194, Loss: 0.0527, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 07, Epoch: 195, Loss: 0.1139, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 07, Epoch: 196, Loss: 0.0613, Train: 100.00%, Valid: 74.58% Test: 64.86%\n",
      "Run: 07, Epoch: 197, Loss: 0.0248, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 07, Epoch: 198, Loss: 0.0307, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 199, Loss: 0.0118, Train: 100.00%, Valid: 76.27% Test: 67.57%\n",
      "Run: 07, Epoch: 200, Loss: 0.0253, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run 07:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 86.44\n",
      "  Final Train: 96.55\n",
      "   Final Test: 72.97\n",
      "Run: 08, Epoch: 01, Loss: 1.8067, Train: 48.28%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 02, Loss: 1.3907, Train: 47.13%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 03, Loss: 1.0427, Train: 47.13%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 04, Loss: 0.8638, Train: 47.13%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 05, Loss: 0.8184, Train: 58.62%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 06, Loss: 0.7460, Train: 68.97%, Valid: 67.80% Test: 64.86%\n",
      "Run: 08, Epoch: 07, Loss: 0.6762, Train: 77.01%, Valid: 72.88% Test: 70.27%\n",
      "Run: 08, Epoch: 08, Loss: 0.6535, Train: 81.61%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 09, Loss: 0.6225, Train: 83.91%, Valid: 69.49% Test: 72.97%\n",
      "Run: 08, Epoch: 10, Loss: 0.5279, Train: 86.21%, Valid: 67.80% Test: 75.68%\n",
      "Run: 08, Epoch: 11, Loss: 0.5370, Train: 86.21%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 12, Loss: 0.4505, Train: 86.21%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 13, Loss: 0.4055, Train: 87.36%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 14, Loss: 0.4223, Train: 87.36%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 15, Loss: 0.4010, Train: 89.66%, Valid: 66.10% Test: 75.68%\n",
      "Run: 08, Epoch: 16, Loss: 0.3555, Train: 90.80%, Valid: 66.10% Test: 75.68%\n",
      "Run: 08, Epoch: 17, Loss: 0.3082, Train: 90.80%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 18, Loss: 0.3114, Train: 93.10%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 19, Loss: 0.3176, Train: 95.40%, Valid: 67.80% Test: 81.08%\n",
      "Run: 08, Epoch: 20, Loss: 0.2555, Train: 97.70%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 21, Loss: 0.2740, Train: 97.70%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 22, Loss: 0.2804, Train: 97.70%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 23, Loss: 0.2216, Train: 97.70%, Valid: 64.41% Test: 81.08%\n",
      "Run: 08, Epoch: 24, Loss: 0.2172, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 25, Loss: 0.1863, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 26, Loss: 0.1969, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 27, Loss: 0.1945, Train: 100.00%, Valid: 64.41% Test: 81.08%\n",
      "Run: 08, Epoch: 28, Loss: 0.2269, Train: 100.00%, Valid: 64.41% Test: 83.78%\n",
      "Run: 08, Epoch: 29, Loss: 0.2537, Train: 100.00%, Valid: 62.71% Test: 83.78%\n",
      "Run: 08, Epoch: 30, Loss: 0.1656, Train: 100.00%, Valid: 64.41% Test: 83.78%\n",
      "Run: 08, Epoch: 31, Loss: 0.1218, Train: 100.00%, Valid: 64.41% Test: 83.78%\n",
      "Run: 08, Epoch: 32, Loss: 0.1386, Train: 100.00%, Valid: 64.41% Test: 83.78%\n",
      "Run: 08, Epoch: 33, Loss: 0.1394, Train: 100.00%, Valid: 64.41% Test: 83.78%\n",
      "Run: 08, Epoch: 34, Loss: 0.1045, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 35, Loss: 0.0878, Train: 100.00%, Valid: 66.10% Test: 83.78%\n",
      "Run: 08, Epoch: 36, Loss: 0.1623, Train: 100.00%, Valid: 66.10% Test: 83.78%\n",
      "Run: 08, Epoch: 37, Loss: 0.1415, Train: 100.00%, Valid: 64.41% Test: 86.49%\n",
      "Run: 08, Epoch: 38, Loss: 0.0746, Train: 100.00%, Valid: 64.41% Test: 89.19%\n",
      "Run: 08, Epoch: 39, Loss: 0.1037, Train: 100.00%, Valid: 64.41% Test: 86.49%\n",
      "Run: 08, Epoch: 40, Loss: 0.1121, Train: 100.00%, Valid: 64.41% Test: 83.78%\n",
      "Run: 08, Epoch: 41, Loss: 0.1180, Train: 100.00%, Valid: 64.41% Test: 81.08%\n",
      "Run: 08, Epoch: 42, Loss: 0.1761, Train: 100.00%, Valid: 64.41% Test: 83.78%\n",
      "Run: 08, Epoch: 43, Loss: 0.0991, Train: 100.00%, Valid: 66.10% Test: 83.78%\n",
      "Run: 08, Epoch: 44, Loss: 0.0771, Train: 100.00%, Valid: 66.10% Test: 83.78%\n",
      "Run: 08, Epoch: 45, Loss: 0.1162, Train: 100.00%, Valid: 64.41% Test: 83.78%\n",
      "Run: 08, Epoch: 46, Loss: 0.0724, Train: 100.00%, Valid: 64.41% Test: 83.78%\n",
      "Run: 08, Epoch: 47, Loss: 0.1224, Train: 100.00%, Valid: 66.10% Test: 83.78%\n",
      "Run: 08, Epoch: 48, Loss: 0.1599, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 49, Loss: 0.0580, Train: 100.00%, Valid: 71.19% Test: 83.78%\n",
      "Run: 08, Epoch: 50, Loss: 0.1347, Train: 100.00%, Valid: 71.19% Test: 83.78%\n",
      "Run: 08, Epoch: 51, Loss: 0.0737, Train: 100.00%, Valid: 71.19% Test: 83.78%\n",
      "Run: 08, Epoch: 52, Loss: 0.0619, Train: 100.00%, Valid: 71.19% Test: 78.38%\n",
      "Run: 08, Epoch: 53, Loss: 0.0727, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 08, Epoch: 54, Loss: 0.0993, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 08, Epoch: 55, Loss: 0.0696, Train: 100.00%, Valid: 72.88% Test: 75.68%\n",
      "Run: 08, Epoch: 56, Loss: 0.0848, Train: 100.00%, Valid: 76.27% Test: 75.68%\n",
      "Run: 08, Epoch: 57, Loss: 0.0563, Train: 100.00%, Valid: 76.27% Test: 81.08%\n",
      "Run: 08, Epoch: 58, Loss: 0.0901, Train: 100.00%, Valid: 71.19% Test: 78.38%\n",
      "Run: 08, Epoch: 59, Loss: 0.0549, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run: 08, Epoch: 60, Loss: 0.0734, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 61, Loss: 0.0551, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 62, Loss: 0.1671, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 63, Loss: 0.0272, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 64, Loss: 0.0641, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 65, Loss: 0.1211, Train: 100.00%, Valid: 71.19% Test: 83.78%\n",
      "Run: 08, Epoch: 66, Loss: 0.0581, Train: 100.00%, Valid: 71.19% Test: 83.78%\n",
      "Run: 08, Epoch: 67, Loss: 0.0466, Train: 100.00%, Valid: 69.49% Test: 83.78%\n",
      "Run: 08, Epoch: 68, Loss: 0.0491, Train: 100.00%, Valid: 67.80% Test: 83.78%\n",
      "Run: 08, Epoch: 69, Loss: 0.0942, Train: 100.00%, Valid: 71.19% Test: 83.78%\n",
      "Run: 08, Epoch: 70, Loss: 0.0544, Train: 100.00%, Valid: 71.19% Test: 86.49%\n",
      "Run: 08, Epoch: 71, Loss: 0.0991, Train: 100.00%, Valid: 71.19% Test: 86.49%\n",
      "Run: 08, Epoch: 72, Loss: 0.0442, Train: 100.00%, Valid: 71.19% Test: 86.49%\n",
      "Run: 08, Epoch: 73, Loss: 0.0534, Train: 100.00%, Valid: 71.19% Test: 86.49%\n",
      "Run: 08, Epoch: 74, Loss: 0.0360, Train: 100.00%, Valid: 71.19% Test: 86.49%\n",
      "Run: 08, Epoch: 75, Loss: 0.1089, Train: 100.00%, Valid: 67.80% Test: 83.78%\n",
      "Run: 08, Epoch: 76, Loss: 0.0661, Train: 100.00%, Valid: 71.19% Test: 83.78%\n",
      "Run: 08, Epoch: 77, Loss: 0.0346, Train: 100.00%, Valid: 74.58% Test: 83.78%\n",
      "Run: 08, Epoch: 78, Loss: 0.0236, Train: 100.00%, Valid: 74.58% Test: 83.78%\n",
      "Run: 08, Epoch: 79, Loss: 0.0719, Train: 100.00%, Valid: 74.58% Test: 83.78%\n",
      "Run: 08, Epoch: 80, Loss: 0.1044, Train: 100.00%, Valid: 74.58% Test: 86.49%\n",
      "Run: 08, Epoch: 81, Loss: 0.1098, Train: 100.00%, Valid: 74.58% Test: 83.78%\n",
      "Run: 08, Epoch: 82, Loss: 0.0407, Train: 100.00%, Valid: 74.58% Test: 86.49%\n",
      "Run: 08, Epoch: 83, Loss: 0.0301, Train: 100.00%, Valid: 72.88% Test: 86.49%\n",
      "Run: 08, Epoch: 84, Loss: 0.0357, Train: 100.00%, Valid: 69.49% Test: 83.78%\n",
      "Run: 08, Epoch: 85, Loss: 0.0173, Train: 100.00%, Valid: 71.19% Test: 81.08%\n",
      "Run: 08, Epoch: 86, Loss: 0.0183, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 87, Loss: 0.0781, Train: 100.00%, Valid: 69.49% Test: 78.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 88, Loss: 0.0148, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 89, Loss: 0.0582, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 90, Loss: 0.0486, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 91, Loss: 0.0737, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 92, Loss: 0.0407, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 93, Loss: 0.0606, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 08, Epoch: 94, Loss: 0.0771, Train: 100.00%, Valid: 67.80% Test: 75.68%\n",
      "Run: 08, Epoch: 95, Loss: 0.0488, Train: 100.00%, Valid: 67.80% Test: 75.68%\n",
      "Run: 08, Epoch: 96, Loss: 0.0517, Train: 100.00%, Valid: 67.80% Test: 75.68%\n",
      "Run: 08, Epoch: 97, Loss: 0.0192, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 98, Loss: 0.0293, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 99, Loss: 0.0801, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 100, Loss: 0.0354, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 101, Loss: 0.1021, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 102, Loss: 0.0546, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 08, Epoch: 103, Loss: 0.0840, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 104, Loss: 0.0149, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 105, Loss: 0.0498, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 106, Loss: 0.0844, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 107, Loss: 0.0494, Train: 100.00%, Valid: 71.19% Test: 78.38%\n",
      "Run: 08, Epoch: 108, Loss: 0.0622, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 109, Loss: 0.0537, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 110, Loss: 0.1002, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 111, Loss: 0.0188, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 112, Loss: 0.0262, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 113, Loss: 0.0713, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 114, Loss: 0.0290, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 115, Loss: 0.0516, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 08, Epoch: 116, Loss: 0.0287, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 08, Epoch: 117, Loss: 0.0225, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 08, Epoch: 118, Loss: 0.0423, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 08, Epoch: 119, Loss: 0.0255, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 08, Epoch: 120, Loss: 0.0515, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 08, Epoch: 121, Loss: 0.0375, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 122, Loss: 0.0467, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 123, Loss: 0.1218, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 124, Loss: 0.0186, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 125, Loss: 0.0178, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 126, Loss: 0.0878, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 127, Loss: 0.0252, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 128, Loss: 0.0552, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 08, Epoch: 129, Loss: 0.0180, Train: 100.00%, Valid: 64.41% Test: 81.08%\n",
      "Run: 08, Epoch: 130, Loss: 0.0467, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 131, Loss: 0.0241, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 08, Epoch: 132, Loss: 0.0253, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 08, Epoch: 133, Loss: 0.0234, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 134, Loss: 0.0489, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 135, Loss: 0.0784, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 136, Loss: 0.0094, Train: 100.00%, Valid: 71.19% Test: 72.97%\n",
      "Run: 08, Epoch: 137, Loss: 0.0198, Train: 100.00%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 138, Loss: 0.0619, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 08, Epoch: 139, Loss: 0.0210, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 08, Epoch: 140, Loss: 0.0092, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 08, Epoch: 141, Loss: 0.0410, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 08, Epoch: 142, Loss: 0.0889, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 08, Epoch: 143, Loss: 0.0644, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 144, Loss: 0.0636, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 145, Loss: 0.0777, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 146, Loss: 0.0212, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 147, Loss: 0.0752, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 148, Loss: 0.0082, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 149, Loss: 0.0712, Train: 100.00%, Valid: 69.49% Test: 75.68%\n",
      "Run: 08, Epoch: 150, Loss: 0.0516, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 151, Loss: 0.0229, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 152, Loss: 0.0573, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 153, Loss: 0.0244, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 154, Loss: 0.0624, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 155, Loss: 0.1278, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 156, Loss: 0.0292, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 157, Loss: 0.0272, Train: 100.00%, Valid: 67.80% Test: 81.08%\n",
      "Run: 08, Epoch: 158, Loss: 0.0485, Train: 100.00%, Valid: 69.49% Test: 83.78%\n",
      "Run: 08, Epoch: 159, Loss: 0.0141, Train: 100.00%, Valid: 69.49% Test: 83.78%\n",
      "Run: 08, Epoch: 160, Loss: 0.0593, Train: 100.00%, Valid: 67.80% Test: 83.78%\n",
      "Run: 08, Epoch: 161, Loss: 0.0570, Train: 100.00%, Valid: 67.80% Test: 83.78%\n",
      "Run: 08, Epoch: 162, Loss: 0.0411, Train: 100.00%, Valid: 67.80% Test: 83.78%\n",
      "Run: 08, Epoch: 163, Loss: 0.0932, Train: 100.00%, Valid: 67.80% Test: 83.78%\n",
      "Run: 08, Epoch: 164, Loss: 0.0498, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 165, Loss: 0.0359, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 166, Loss: 0.0228, Train: 100.00%, Valid: 69.49% Test: 83.78%\n",
      "Run: 08, Epoch: 167, Loss: 0.0830, Train: 100.00%, Valid: 69.49% Test: 83.78%\n",
      "Run: 08, Epoch: 168, Loss: 0.0132, Train: 100.00%, Valid: 69.49% Test: 83.78%\n",
      "Run: 08, Epoch: 169, Loss: 0.0422, Train: 100.00%, Valid: 71.19% Test: 83.78%\n",
      "Run: 08, Epoch: 170, Loss: 0.0746, Train: 100.00%, Valid: 67.80% Test: 83.78%\n",
      "Run: 08, Epoch: 171, Loss: 0.0438, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 172, Loss: 0.0738, Train: 100.00%, Valid: 69.49% Test: 83.78%\n",
      "Run: 08, Epoch: 173, Loss: 0.0329, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 174, Loss: 0.0383, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 175, Loss: 0.1261, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 176, Loss: 0.0851, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 177, Loss: 0.0995, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 178, Loss: 0.0294, Train: 100.00%, Valid: 67.80% Test: 81.08%\n",
      "Run: 08, Epoch: 179, Loss: 0.1421, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 180, Loss: 0.0293, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 181, Loss: 0.0448, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 182, Loss: 0.0308, Train: 100.00%, Valid: 71.19% Test: 81.08%\n",
      "Run: 08, Epoch: 183, Loss: 0.0805, Train: 100.00%, Valid: 71.19% Test: 81.08%\n",
      "Run: 08, Epoch: 184, Loss: 0.0910, Train: 100.00%, Valid: 71.19% Test: 81.08%\n",
      "Run: 08, Epoch: 185, Loss: 0.0220, Train: 100.00%, Valid: 72.88% Test: 81.08%\n",
      "Run: 08, Epoch: 186, Loss: 0.0405, Train: 100.00%, Valid: 71.19% Test: 81.08%\n",
      "Run: 08, Epoch: 187, Loss: 0.0390, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 188, Loss: 0.0236, Train: 100.00%, Valid: 69.49% Test: 81.08%\n",
      "Run: 08, Epoch: 189, Loss: 0.0415, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 190, Loss: 0.0227, Train: 100.00%, Valid: 66.10% Test: 81.08%\n",
      "Run: 08, Epoch: 191, Loss: 0.0524, Train: 100.00%, Valid: 67.80% Test: 78.38%\n",
      "Run: 08, Epoch: 192, Loss: 0.0620, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 193, Loss: 0.0532, Train: 100.00%, Valid: 67.80% Test: 81.08%\n",
      "Run: 08, Epoch: 194, Loss: 0.0813, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 195, Loss: 0.0176, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 196, Loss: 0.0163, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 197, Loss: 0.0069, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 08, Epoch: 198, Loss: 0.0393, Train: 100.00%, Valid: 66.10% Test: 78.38%\n",
      "Run: 08, Epoch: 199, Loss: 0.0201, Train: 100.00%, Valid: 69.49% Test: 78.38%\n",
      "Run: 08, Epoch: 200, Loss: 0.0121, Train: 100.00%, Valid: 71.19% Test: 75.68%\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 77.97\n",
      "  Final Train: 81.61\n",
      "   Final Test: 70.27\n",
      "Run: 09, Epoch: 01, Loss: 1.7983, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 02, Loss: 1.3907, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 03, Loss: 0.9674, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 04, Loss: 0.8801, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 05, Loss: 0.8685, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 06, Loss: 0.8226, Train: 57.47%, Valid: 49.15% Test: 59.46%\n",
      "Run: 09, Epoch: 07, Loss: 0.8151, Train: 57.47%, Valid: 49.15% Test: 59.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 08, Loss: 0.7558, Train: 65.52%, Valid: 50.85% Test: 64.86%\n",
      "Run: 09, Epoch: 09, Loss: 0.6775, Train: 72.41%, Valid: 55.93% Test: 70.27%\n",
      "Run: 09, Epoch: 10, Loss: 0.6538, Train: 73.56%, Valid: 61.02% Test: 70.27%\n",
      "Run: 09, Epoch: 11, Loss: 0.5746, Train: 77.01%, Valid: 62.71% Test: 70.27%\n",
      "Run: 09, Epoch: 12, Loss: 0.5221, Train: 89.66%, Valid: 62.71% Test: 72.97%\n",
      "Run: 09, Epoch: 13, Loss: 0.5223, Train: 95.40%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 14, Loss: 0.4864, Train: 97.70%, Valid: 59.32% Test: 78.38%\n",
      "Run: 09, Epoch: 15, Loss: 0.4346, Train: 97.70%, Valid: 55.93% Test: 78.38%\n",
      "Run: 09, Epoch: 16, Loss: 0.4771, Train: 97.70%, Valid: 57.63% Test: 78.38%\n",
      "Run: 09, Epoch: 17, Loss: 0.4535, Train: 97.70%, Valid: 59.32% Test: 75.68%\n",
      "Run: 09, Epoch: 18, Loss: 0.3878, Train: 97.70%, Valid: 57.63% Test: 75.68%\n",
      "Run: 09, Epoch: 19, Loss: 0.3460, Train: 98.85%, Valid: 59.32% Test: 78.38%\n",
      "Run: 09, Epoch: 20, Loss: 0.3987, Train: 98.85%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 21, Loss: 0.2965, Train: 98.85%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 22, Loss: 0.3030, Train: 98.85%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 23, Loss: 0.2702, Train: 98.85%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 24, Loss: 0.2472, Train: 98.85%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 25, Loss: 0.2805, Train: 98.85%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 26, Loss: 0.2697, Train: 98.85%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 27, Loss: 0.2147, Train: 98.85%, Valid: 62.71% Test: 78.38%\n",
      "Run: 09, Epoch: 28, Loss: 0.2248, Train: 98.85%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 29, Loss: 0.2244, Train: 98.85%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 30, Loss: 0.1981, Train: 98.85%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 31, Loss: 0.2210, Train: 98.85%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 32, Loss: 0.2526, Train: 98.85%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 33, Loss: 0.1680, Train: 98.85%, Valid: 64.41% Test: 78.38%\n",
      "Run: 09, Epoch: 34, Loss: 0.1573, Train: 98.85%, Valid: 62.71% Test: 78.38%\n",
      "Run: 09, Epoch: 35, Loss: 0.1593, Train: 98.85%, Valid: 61.02% Test: 83.78%\n",
      "Run: 09, Epoch: 36, Loss: 0.2071, Train: 98.85%, Valid: 61.02% Test: 83.78%\n",
      "Run: 09, Epoch: 37, Loss: 0.1272, Train: 98.85%, Valid: 61.02% Test: 86.49%\n",
      "Run: 09, Epoch: 38, Loss: 0.1492, Train: 98.85%, Valid: 62.71% Test: 86.49%\n",
      "Run: 09, Epoch: 39, Loss: 0.1978, Train: 98.85%, Valid: 61.02% Test: 86.49%\n",
      "Run: 09, Epoch: 40, Loss: 0.1545, Train: 98.85%, Valid: 61.02% Test: 83.78%\n",
      "Run: 09, Epoch: 41, Loss: 0.1697, Train: 98.85%, Valid: 64.41% Test: 81.08%\n",
      "Run: 09, Epoch: 42, Loss: 0.2407, Train: 98.85%, Valid: 66.10% Test: 81.08%\n",
      "Run: 09, Epoch: 43, Loss: 0.1507, Train: 98.85%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 44, Loss: 0.1584, Train: 98.85%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 45, Loss: 0.0879, Train: 98.85%, Valid: 57.63% Test: 81.08%\n",
      "Run: 09, Epoch: 46, Loss: 0.1219, Train: 98.85%, Valid: 57.63% Test: 81.08%\n",
      "Run: 09, Epoch: 47, Loss: 0.1380, Train: 98.85%, Valid: 57.63% Test: 81.08%\n",
      "Run: 09, Epoch: 48, Loss: 0.1648, Train: 98.85%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 49, Loss: 0.0764, Train: 98.85%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 50, Loss: 0.0883, Train: 98.85%, Valid: 59.32% Test: 83.78%\n",
      "Run: 09, Epoch: 51, Loss: 0.0676, Train: 98.85%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 52, Loss: 0.1209, Train: 98.85%, Valid: 57.63% Test: 75.68%\n",
      "Run: 09, Epoch: 53, Loss: 0.0882, Train: 98.85%, Valid: 57.63% Test: 75.68%\n",
      "Run: 09, Epoch: 54, Loss: 0.0907, Train: 98.85%, Valid: 57.63% Test: 72.97%\n",
      "Run: 09, Epoch: 55, Loss: 0.0821, Train: 98.85%, Valid: 57.63% Test: 75.68%\n",
      "Run: 09, Epoch: 56, Loss: 0.1594, Train: 98.85%, Valid: 57.63% Test: 78.38%\n",
      "Run: 09, Epoch: 57, Loss: 0.1746, Train: 98.85%, Valid: 57.63% Test: 81.08%\n",
      "Run: 09, Epoch: 58, Loss: 0.0976, Train: 100.00%, Valid: 57.63% Test: 81.08%\n",
      "Run: 09, Epoch: 59, Loss: 0.1087, Train: 98.85%, Valid: 57.63% Test: 83.78%\n",
      "Run: 09, Epoch: 60, Loss: 0.1601, Train: 98.85%, Valid: 54.24% Test: 86.49%\n",
      "Run: 09, Epoch: 61, Loss: 0.0952, Train: 98.85%, Valid: 55.93% Test: 81.08%\n",
      "Run: 09, Epoch: 62, Loss: 0.0670, Train: 100.00%, Valid: 59.32% Test: 78.38%\n",
      "Run: 09, Epoch: 63, Loss: 0.0793, Train: 100.00%, Valid: 62.71% Test: 78.38%\n",
      "Run: 09, Epoch: 64, Loss: 0.0751, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 09, Epoch: 65, Loss: 0.0865, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 66, Loss: 0.1049, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 67, Loss: 0.1159, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 68, Loss: 0.0931, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 69, Loss: 0.0764, Train: 100.00%, Valid: 59.32% Test: 78.38%\n",
      "Run: 09, Epoch: 70, Loss: 0.0751, Train: 100.00%, Valid: 55.93% Test: 75.68%\n",
      "Run: 09, Epoch: 71, Loss: 0.1272, Train: 100.00%, Valid: 52.54% Test: 75.68%\n",
      "Run: 09, Epoch: 72, Loss: 0.0738, Train: 100.00%, Valid: 52.54% Test: 72.97%\n",
      "Run: 09, Epoch: 73, Loss: 0.0859, Train: 100.00%, Valid: 52.54% Test: 72.97%\n",
      "Run: 09, Epoch: 74, Loss: 0.0851, Train: 100.00%, Valid: 54.24% Test: 72.97%\n",
      "Run: 09, Epoch: 75, Loss: 0.0404, Train: 100.00%, Valid: 50.85% Test: 72.97%\n",
      "Run: 09, Epoch: 76, Loss: 0.0552, Train: 100.00%, Valid: 50.85% Test: 72.97%\n",
      "Run: 09, Epoch: 77, Loss: 0.1415, Train: 100.00%, Valid: 50.85% Test: 72.97%\n",
      "Run: 09, Epoch: 78, Loss: 0.0536, Train: 100.00%, Valid: 52.54% Test: 78.38%\n",
      "Run: 09, Epoch: 79, Loss: 0.0377, Train: 100.00%, Valid: 55.93% Test: 78.38%\n",
      "Run: 09, Epoch: 80, Loss: 0.0869, Train: 100.00%, Valid: 57.63% Test: 78.38%\n",
      "Run: 09, Epoch: 81, Loss: 0.1327, Train: 100.00%, Valid: 57.63% Test: 83.78%\n",
      "Run: 09, Epoch: 82, Loss: 0.0314, Train: 100.00%, Valid: 59.32% Test: 83.78%\n",
      "Run: 09, Epoch: 83, Loss: 0.0310, Train: 100.00%, Valid: 59.32% Test: 83.78%\n",
      "Run: 09, Epoch: 84, Loss: 0.0485, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 85, Loss: 0.0761, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 86, Loss: 0.0345, Train: 100.00%, Valid: 62.71% Test: 81.08%\n",
      "Run: 09, Epoch: 87, Loss: 0.0508, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 88, Loss: 0.0767, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 89, Loss: 0.0547, Train: 100.00%, Valid: 59.32% Test: 83.78%\n",
      "Run: 09, Epoch: 90, Loss: 0.0805, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 91, Loss: 0.0473, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 92, Loss: 0.0555, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 93, Loss: 0.0515, Train: 100.00%, Valid: 57.63% Test: 81.08%\n",
      "Run: 09, Epoch: 94, Loss: 0.0659, Train: 100.00%, Valid: 57.63% Test: 81.08%\n",
      "Run: 09, Epoch: 95, Loss: 0.0987, Train: 100.00%, Valid: 57.63% Test: 81.08%\n",
      "Run: 09, Epoch: 96, Loss: 0.0508, Train: 100.00%, Valid: 59.32% Test: 72.97%\n",
      "Run: 09, Epoch: 97, Loss: 0.0833, Train: 100.00%, Valid: 59.32% Test: 75.68%\n",
      "Run: 09, Epoch: 98, Loss: 0.0758, Train: 100.00%, Valid: 59.32% Test: 72.97%\n",
      "Run: 09, Epoch: 99, Loss: 0.0528, Train: 100.00%, Valid: 57.63% Test: 75.68%\n",
      "Run: 09, Epoch: 100, Loss: 0.0418, Train: 100.00%, Valid: 57.63% Test: 75.68%\n",
      "Run: 09, Epoch: 101, Loss: 0.0864, Train: 100.00%, Valid: 54.24% Test: 75.68%\n",
      "Run: 09, Epoch: 102, Loss: 0.0655, Train: 100.00%, Valid: 52.54% Test: 75.68%\n",
      "Run: 09, Epoch: 103, Loss: 0.0476, Train: 100.00%, Valid: 52.54% Test: 75.68%\n",
      "Run: 09, Epoch: 104, Loss: 0.1056, Train: 100.00%, Valid: 52.54% Test: 75.68%\n",
      "Run: 09, Epoch: 105, Loss: 0.0340, Train: 100.00%, Valid: 50.85% Test: 75.68%\n",
      "Run: 09, Epoch: 106, Loss: 0.0662, Train: 100.00%, Valid: 54.24% Test: 78.38%\n",
      "Run: 09, Epoch: 107, Loss: 0.0546, Train: 100.00%, Valid: 57.63% Test: 78.38%\n",
      "Run: 09, Epoch: 108, Loss: 0.0752, Train: 100.00%, Valid: 55.93% Test: 78.38%\n",
      "Run: 09, Epoch: 109, Loss: 0.1027, Train: 100.00%, Valid: 55.93% Test: 81.08%\n",
      "Run: 09, Epoch: 110, Loss: 0.0613, Train: 100.00%, Valid: 57.63% Test: 81.08%\n",
      "Run: 09, Epoch: 111, Loss: 0.0987, Train: 100.00%, Valid: 57.63% Test: 81.08%\n",
      "Run: 09, Epoch: 112, Loss: 0.0243, Train: 100.00%, Valid: 55.93% Test: 81.08%\n",
      "Run: 09, Epoch: 113, Loss: 0.0324, Train: 100.00%, Valid: 55.93% Test: 81.08%\n",
      "Run: 09, Epoch: 114, Loss: 0.0780, Train: 100.00%, Valid: 57.63% Test: 83.78%\n",
      "Run: 09, Epoch: 115, Loss: 0.1030, Train: 100.00%, Valid: 57.63% Test: 83.78%\n",
      "Run: 09, Epoch: 116, Loss: 0.0420, Train: 100.00%, Valid: 59.32% Test: 83.78%\n",
      "Run: 09, Epoch: 117, Loss: 0.0693, Train: 100.00%, Valid: 59.32% Test: 78.38%\n",
      "Run: 09, Epoch: 118, Loss: 0.0386, Train: 100.00%, Valid: 57.63% Test: 78.38%\n",
      "Run: 09, Epoch: 119, Loss: 0.0807, Train: 100.00%, Valid: 59.32% Test: 78.38%\n",
      "Run: 09, Epoch: 120, Loss: 0.0315, Train: 100.00%, Valid: 59.32% Test: 78.38%\n",
      "Run: 09, Epoch: 121, Loss: 0.0591, Train: 100.00%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 122, Loss: 0.0899, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 123, Loss: 0.0250, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 124, Loss: 0.0756, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 125, Loss: 0.0483, Train: 100.00%, Valid: 59.32% Test: 81.08%\n",
      "Run: 09, Epoch: 126, Loss: 0.0639, Train: 100.00%, Valid: 61.02% Test: 81.08%\n",
      "Run: 09, Epoch: 127, Loss: 0.0184, Train: 100.00%, Valid: 61.02% Test: 75.68%\n",
      "Run: 09, Epoch: 128, Loss: 0.0428, Train: 100.00%, Valid: 59.32% Test: 78.38%\n",
      "Run: 09, Epoch: 129, Loss: 0.0741, Train: 100.00%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 130, Loss: 0.1069, Train: 100.00%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 131, Loss: 0.1078, Train: 100.00%, Valid: 57.63% Test: 75.68%\n",
      "Run: 09, Epoch: 132, Loss: 0.0240, Train: 100.00%, Valid: 55.93% Test: 72.97%\n",
      "Run: 09, Epoch: 133, Loss: 0.0456, Train: 100.00%, Valid: 55.93% Test: 72.97%\n",
      "Run: 09, Epoch: 134, Loss: 0.0747, Train: 100.00%, Valid: 54.24% Test: 72.97%\n",
      "Run: 09, Epoch: 135, Loss: 0.0963, Train: 100.00%, Valid: 54.24% Test: 67.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 136, Loss: 0.0543, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 09, Epoch: 137, Loss: 0.0401, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 09, Epoch: 138, Loss: 0.0968, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 09, Epoch: 139, Loss: 0.0335, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 09, Epoch: 140, Loss: 0.0568, Train: 100.00%, Valid: 55.93% Test: 70.27%\n",
      "Run: 09, Epoch: 141, Loss: 0.0882, Train: 100.00%, Valid: 55.93% Test: 70.27%\n",
      "Run: 09, Epoch: 142, Loss: 0.0255, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 09, Epoch: 143, Loss: 0.0471, Train: 100.00%, Valid: 59.32% Test: 70.27%\n",
      "Run: 09, Epoch: 144, Loss: 0.0429, Train: 100.00%, Valid: 61.02% Test: 72.97%\n",
      "Run: 09, Epoch: 145, Loss: 0.0085, Train: 100.00%, Valid: 61.02% Test: 75.68%\n",
      "Run: 09, Epoch: 146, Loss: 0.0295, Train: 100.00%, Valid: 59.32% Test: 78.38%\n",
      "Run: 09, Epoch: 147, Loss: 0.0244, Train: 100.00%, Valid: 59.32% Test: 78.38%\n",
      "Run: 09, Epoch: 148, Loss: 0.0149, Train: 100.00%, Valid: 61.02% Test: 75.68%\n",
      "Run: 09, Epoch: 149, Loss: 0.0254, Train: 100.00%, Valid: 61.02% Test: 75.68%\n",
      "Run: 09, Epoch: 150, Loss: 0.0811, Train: 100.00%, Valid: 61.02% Test: 75.68%\n",
      "Run: 09, Epoch: 151, Loss: 0.0165, Train: 100.00%, Valid: 62.71% Test: 78.38%\n",
      "Run: 09, Epoch: 152, Loss: 0.0850, Train: 100.00%, Valid: 62.71% Test: 78.38%\n",
      "Run: 09, Epoch: 153, Loss: 0.0798, Train: 100.00%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 154, Loss: 0.0400, Train: 100.00%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 155, Loss: 0.0355, Train: 100.00%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 156, Loss: 0.0203, Train: 100.00%, Valid: 61.02% Test: 78.38%\n",
      "Run: 09, Epoch: 157, Loss: 0.0331, Train: 100.00%, Valid: 62.71% Test: 78.38%\n",
      "Run: 09, Epoch: 158, Loss: 0.0300, Train: 100.00%, Valid: 62.71% Test: 78.38%\n",
      "Run: 09, Epoch: 159, Loss: 0.0548, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 09, Epoch: 160, Loss: 0.0218, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 09, Epoch: 161, Loss: 0.0157, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 09, Epoch: 162, Loss: 0.0562, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 09, Epoch: 163, Loss: 0.0095, Train: 100.00%, Valid: 61.02% Test: 75.68%\n",
      "Run: 09, Epoch: 164, Loss: 0.0318, Train: 100.00%, Valid: 61.02% Test: 75.68%\n",
      "Run: 09, Epoch: 165, Loss: 0.1044, Train: 100.00%, Valid: 61.02% Test: 75.68%\n",
      "Run: 09, Epoch: 166, Loss: 0.0456, Train: 100.00%, Valid: 61.02% Test: 75.68%\n",
      "Run: 09, Epoch: 167, Loss: 0.0313, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 09, Epoch: 168, Loss: 0.0169, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 09, Epoch: 169, Loss: 0.1006, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 09, Epoch: 170, Loss: 0.0351, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 09, Epoch: 171, Loss: 0.0140, Train: 100.00%, Valid: 62.71% Test: 75.68%\n",
      "Run: 09, Epoch: 172, Loss: 0.0262, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 09, Epoch: 173, Loss: 0.0409, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 09, Epoch: 174, Loss: 0.0504, Train: 100.00%, Valid: 64.41% Test: 72.97%\n",
      "Run: 09, Epoch: 175, Loss: 0.0442, Train: 100.00%, Valid: 64.41% Test: 72.97%\n",
      "Run: 09, Epoch: 176, Loss: 0.0417, Train: 100.00%, Valid: 62.71% Test: 70.27%\n",
      "Run: 09, Epoch: 177, Loss: 0.0238, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 09, Epoch: 178, Loss: 0.0263, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 09, Epoch: 179, Loss: 0.0046, Train: 100.00%, Valid: 59.32% Test: 70.27%\n",
      "Run: 09, Epoch: 180, Loss: 0.0557, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 09, Epoch: 181, Loss: 0.0984, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 09, Epoch: 182, Loss: 0.0130, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 09, Epoch: 183, Loss: 0.0268, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 09, Epoch: 184, Loss: 0.0126, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 09, Epoch: 185, Loss: 0.0183, Train: 100.00%, Valid: 59.32% Test: 67.57%\n",
      "Run: 09, Epoch: 186, Loss: 0.0657, Train: 100.00%, Valid: 59.32% Test: 67.57%\n",
      "Run: 09, Epoch: 187, Loss: 0.0446, Train: 100.00%, Valid: 62.71% Test: 70.27%\n",
      "Run: 09, Epoch: 188, Loss: 0.0345, Train: 100.00%, Valid: 62.71% Test: 70.27%\n",
      "Run: 09, Epoch: 189, Loss: 0.0604, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 09, Epoch: 190, Loss: 0.0319, Train: 100.00%, Valid: 61.02% Test: 72.97%\n",
      "Run: 09, Epoch: 191, Loss: 0.1083, Train: 100.00%, Valid: 61.02% Test: 72.97%\n",
      "Run: 09, Epoch: 192, Loss: 0.0308, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 09, Epoch: 193, Loss: 0.0120, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 09, Epoch: 194, Loss: 0.0181, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 09, Epoch: 195, Loss: 0.0235, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 09, Epoch: 196, Loss: 0.0313, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 09, Epoch: 197, Loss: 0.0155, Train: 100.00%, Valid: 62.71% Test: 70.27%\n",
      "Run: 09, Epoch: 198, Loss: 0.0492, Train: 100.00%, Valid: 62.71% Test: 70.27%\n",
      "Run: 09, Epoch: 199, Loss: 0.0104, Train: 100.00%, Valid: 61.02% Test: 70.27%\n",
      "Run: 09, Epoch: 200, Loss: 0.1575, Train: 100.00%, Valid: 62.71% Test: 70.27%\n",
      "Run 09:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 66.10\n",
      "  Final Train: 98.85\n",
      "   Final Test: 81.08\n",
      "Run: 10, Epoch: 01, Loss: 1.8300, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 02, Loss: 1.3882, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 03, Loss: 0.9299, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 04, Loss: 0.8332, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 05, Loss: 0.7967, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 06, Loss: 0.7677, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 07, Loss: 0.7141, Train: 58.62%, Valid: 45.76% Test: 62.16%\n",
      "Run: 10, Epoch: 08, Loss: 0.7393, Train: 74.71%, Valid: 49.15% Test: 67.57%\n",
      "Run: 10, Epoch: 09, Loss: 0.6020, Train: 77.01%, Valid: 55.93% Test: 67.57%\n",
      "Run: 10, Epoch: 10, Loss: 0.5852, Train: 79.31%, Valid: 55.93% Test: 67.57%\n",
      "Run: 10, Epoch: 11, Loss: 0.5113, Train: 87.36%, Valid: 61.02% Test: 67.57%\n",
      "Run: 10, Epoch: 12, Loss: 0.5013, Train: 89.66%, Valid: 64.41% Test: 75.68%\n",
      "Run: 10, Epoch: 13, Loss: 0.4552, Train: 89.66%, Valid: 66.10% Test: 78.38%\n",
      "Run: 10, Epoch: 14, Loss: 0.4353, Train: 89.66%, Valid: 71.19% Test: 78.38%\n",
      "Run: 10, Epoch: 15, Loss: 0.4173, Train: 90.80%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 16, Loss: 0.3690, Train: 91.95%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 17, Loss: 0.3708, Train: 94.25%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 18, Loss: 0.3571, Train: 95.40%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 19, Loss: 0.3461, Train: 97.70%, Valid: 72.88% Test: 78.38%\n",
      "Run: 10, Epoch: 20, Loss: 0.3239, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 21, Loss: 0.3219, Train: 98.85%, Valid: 69.49% Test: 70.27%\n",
      "Run: 10, Epoch: 22, Loss: 0.2711, Train: 98.85%, Valid: 69.49% Test: 70.27%\n",
      "Run: 10, Epoch: 23, Loss: 0.2506, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 24, Loss: 0.2273, Train: 98.85%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 25, Loss: 0.3510, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 26, Loss: 0.2165, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 27, Loss: 0.2247, Train: 98.85%, Valid: 69.49% Test: 78.38%\n",
      "Run: 10, Epoch: 28, Loss: 0.2149, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 29, Loss: 0.1978, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 30, Loss: 0.1812, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 31, Loss: 0.1884, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 32, Loss: 0.1619, Train: 98.85%, Valid: 67.80% Test: 75.68%\n",
      "Run: 10, Epoch: 33, Loss: 0.2313, Train: 98.85%, Valid: 67.80% Test: 72.97%\n",
      "Run: 10, Epoch: 34, Loss: 0.1836, Train: 98.85%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 35, Loss: 0.1375, Train: 98.85%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 36, Loss: 0.1240, Train: 98.85%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 37, Loss: 0.1094, Train: 98.85%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 38, Loss: 0.1440, Train: 98.85%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 39, Loss: 0.1599, Train: 98.85%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 40, Loss: 0.1318, Train: 98.85%, Valid: 66.10% Test: 67.57%\n",
      "Run: 10, Epoch: 41, Loss: 0.1152, Train: 98.85%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 42, Loss: 0.1173, Train: 98.85%, Valid: 67.80% Test: 67.57%\n",
      "Run: 10, Epoch: 43, Loss: 0.0947, Train: 98.85%, Valid: 66.10% Test: 67.57%\n",
      "Run: 10, Epoch: 44, Loss: 0.1035, Train: 98.85%, Valid: 67.80% Test: 67.57%\n",
      "Run: 10, Epoch: 45, Loss: 0.0991, Train: 98.85%, Valid: 67.80% Test: 67.57%\n",
      "Run: 10, Epoch: 46, Loss: 0.0913, Train: 98.85%, Valid: 67.80% Test: 67.57%\n",
      "Run: 10, Epoch: 47, Loss: 0.1034, Train: 98.85%, Valid: 69.49% Test: 67.57%\n",
      "Run: 10, Epoch: 48, Loss: 0.0829, Train: 98.85%, Valid: 69.49% Test: 67.57%\n",
      "Run: 10, Epoch: 49, Loss: 0.1045, Train: 98.85%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 50, Loss: 0.0643, Train: 98.85%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 51, Loss: 0.0901, Train: 98.85%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 52, Loss: 0.0676, Train: 98.85%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 53, Loss: 0.1037, Train: 98.85%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 54, Loss: 0.0919, Train: 98.85%, Valid: 69.49% Test: 78.38%\n",
      "Run: 10, Epoch: 55, Loss: 0.0762, Train: 98.85%, Valid: 69.49% Test: 78.38%\n",
      "Run: 10, Epoch: 56, Loss: 0.0952, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 57, Loss: 0.0730, Train: 98.85%, Valid: 69.49% Test: 72.97%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 58, Loss: 0.0849, Train: 98.85%, Valid: 67.80% Test: 72.97%\n",
      "Run: 10, Epoch: 59, Loss: 0.0554, Train: 98.85%, Valid: 67.80% Test: 72.97%\n",
      "Run: 10, Epoch: 60, Loss: 0.0629, Train: 98.85%, Valid: 67.80% Test: 72.97%\n",
      "Run: 10, Epoch: 61, Loss: 0.0974, Train: 98.85%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 62, Loss: 0.0886, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 63, Loss: 0.1084, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 64, Loss: 0.0609, Train: 98.85%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 65, Loss: 0.0607, Train: 98.85%, Valid: 71.19% Test: 75.68%\n",
      "Run: 10, Epoch: 66, Loss: 0.0541, Train: 98.85%, Valid: 71.19% Test: 72.97%\n",
      "Run: 10, Epoch: 67, Loss: 0.0773, Train: 98.85%, Valid: 71.19% Test: 70.27%\n",
      "Run: 10, Epoch: 68, Loss: 0.0759, Train: 98.85%, Valid: 69.49% Test: 70.27%\n",
      "Run: 10, Epoch: 69, Loss: 0.1411, Train: 98.85%, Valid: 71.19% Test: 72.97%\n",
      "Run: 10, Epoch: 70, Loss: 0.0821, Train: 98.85%, Valid: 71.19% Test: 72.97%\n",
      "Run: 10, Epoch: 71, Loss: 0.0845, Train: 98.85%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 72, Loss: 0.0877, Train: 98.85%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 73, Loss: 0.0773, Train: 98.85%, Valid: 69.49% Test: 75.68%\n",
      "Run: 10, Epoch: 74, Loss: 0.0496, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 10, Epoch: 75, Loss: 0.0470, Train: 98.85%, Valid: 71.19% Test: 70.27%\n",
      "Run: 10, Epoch: 76, Loss: 0.0678, Train: 98.85%, Valid: 72.88% Test: 67.57%\n",
      "Run: 10, Epoch: 77, Loss: 0.0396, Train: 98.85%, Valid: 72.88% Test: 67.57%\n",
      "Run: 10, Epoch: 78, Loss: 0.1133, Train: 98.85%, Valid: 72.88% Test: 70.27%\n",
      "Run: 10, Epoch: 79, Loss: 0.0740, Train: 98.85%, Valid: 72.88% Test: 70.27%\n",
      "Run: 10, Epoch: 80, Loss: 0.0481, Train: 98.85%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 81, Loss: 0.0475, Train: 98.85%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 82, Loss: 0.0706, Train: 98.85%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 83, Loss: 0.0870, Train: 98.85%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 84, Loss: 0.0713, Train: 98.85%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 85, Loss: 0.0687, Train: 100.00%, Valid: 66.10% Test: 75.68%\n",
      "Run: 10, Epoch: 86, Loss: 0.0595, Train: 100.00%, Valid: 64.41% Test: 72.97%\n",
      "Run: 10, Epoch: 87, Loss: 0.0806, Train: 100.00%, Valid: 64.41% Test: 75.68%\n",
      "Run: 10, Epoch: 88, Loss: 0.0478, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 89, Loss: 0.0386, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 10, Epoch: 90, Loss: 0.0896, Train: 100.00%, Valid: 62.71% Test: 72.97%\n",
      "Run: 10, Epoch: 91, Loss: 0.0904, Train: 100.00%, Valid: 62.71% Test: 67.57%\n",
      "Run: 10, Epoch: 92, Loss: 0.0514, Train: 100.00%, Valid: 62.71% Test: 70.27%\n",
      "Run: 10, Epoch: 93, Loss: 0.0786, Train: 100.00%, Valid: 61.02% Test: 67.57%\n",
      "Run: 10, Epoch: 94, Loss: 0.0510, Train: 100.00%, Valid: 62.71% Test: 67.57%\n",
      "Run: 10, Epoch: 95, Loss: 0.0288, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 10, Epoch: 96, Loss: 0.0561, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 10, Epoch: 97, Loss: 0.0298, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 10, Epoch: 98, Loss: 0.0618, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 99, Loss: 0.0326, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 100, Loss: 0.0490, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 101, Loss: 0.0264, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 10, Epoch: 102, Loss: 0.0508, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 103, Loss: 0.0279, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 10, Epoch: 104, Loss: 0.0470, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 10, Epoch: 105, Loss: 0.0282, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 10, Epoch: 106, Loss: 0.0441, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 10, Epoch: 107, Loss: 0.0555, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 10, Epoch: 108, Loss: 0.0689, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 10, Epoch: 109, Loss: 0.0341, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 10, Epoch: 110, Loss: 0.0644, Train: 100.00%, Valid: 61.02% Test: 62.16%\n",
      "Run: 10, Epoch: 111, Loss: 0.0246, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 10, Epoch: 112, Loss: 0.0268, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 10, Epoch: 113, Loss: 0.0263, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 10, Epoch: 114, Loss: 0.0674, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 10, Epoch: 115, Loss: 0.0836, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 10, Epoch: 116, Loss: 0.0757, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 117, Loss: 0.0544, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 10, Epoch: 118, Loss: 0.0706, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 10, Epoch: 119, Loss: 0.0145, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 10, Epoch: 120, Loss: 0.0701, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 10, Epoch: 121, Loss: 0.0393, Train: 100.00%, Valid: 69.49% Test: 70.27%\n",
      "Run: 10, Epoch: 122, Loss: 0.0219, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 123, Loss: 0.0474, Train: 100.00%, Valid: 69.49% Test: 72.97%\n",
      "Run: 10, Epoch: 124, Loss: 0.0210, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 125, Loss: 0.1751, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 10, Epoch: 126, Loss: 0.0420, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 10, Epoch: 127, Loss: 0.0198, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 10, Epoch: 128, Loss: 0.0306, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 129, Loss: 0.0264, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 130, Loss: 0.0234, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 131, Loss: 0.0268, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 132, Loss: 0.0196, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 10, Epoch: 133, Loss: 0.0466, Train: 100.00%, Valid: 66.10% Test: 72.97%\n",
      "Run: 10, Epoch: 134, Loss: 0.0150, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 135, Loss: 0.0595, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 136, Loss: 0.0348, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 10, Epoch: 137, Loss: 0.2458, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 10, Epoch: 138, Loss: 0.0311, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 139, Loss: 0.0370, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 10, Epoch: 140, Loss: 0.0274, Train: 100.00%, Valid: 67.80% Test: 72.97%\n",
      "Run: 10, Epoch: 141, Loss: 0.0124, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 10, Epoch: 142, Loss: 0.0239, Train: 100.00%, Valid: 67.80% Test: 70.27%\n",
      "Run: 10, Epoch: 143, Loss: 0.0237, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 10, Epoch: 144, Loss: 0.0281, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 145, Loss: 0.0468, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 146, Loss: 0.0312, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 147, Loss: 0.0194, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 10, Epoch: 148, Loss: 0.0645, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 149, Loss: 0.0353, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 150, Loss: 0.0205, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 151, Loss: 0.0196, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 152, Loss: 0.0256, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 153, Loss: 0.0388, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 154, Loss: 0.0891, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 155, Loss: 0.0202, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 10, Epoch: 156, Loss: 0.0934, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 10, Epoch: 157, Loss: 0.0298, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 10, Epoch: 158, Loss: 0.0222, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 159, Loss: 0.0123, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 160, Loss: 0.0631, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 161, Loss: 0.0557, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 162, Loss: 0.0366, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 163, Loss: 0.0312, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 10, Epoch: 164, Loss: 0.0526, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 10, Epoch: 165, Loss: 0.0142, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 10, Epoch: 166, Loss: 0.0246, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 10, Epoch: 167, Loss: 0.0489, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 168, Loss: 0.0395, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 169, Loss: 0.0428, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 170, Loss: 0.0343, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 171, Loss: 0.0218, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 172, Loss: 0.0169, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 173, Loss: 0.0602, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 174, Loss: 0.0120, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 10, Epoch: 175, Loss: 0.0381, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 10, Epoch: 176, Loss: 0.0159, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 10, Epoch: 177, Loss: 0.0084, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 10, Epoch: 178, Loss: 0.0138, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 10, Epoch: 179, Loss: 0.0547, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 10, Epoch: 180, Loss: 0.0078, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 10, Epoch: 181, Loss: 0.0600, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 182, Loss: 0.0046, Train: 100.00%, Valid: 71.19% Test: 64.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 183, Loss: 0.0103, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 10, Epoch: 184, Loss: 0.0466, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 10, Epoch: 185, Loss: 0.0301, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 186, Loss: 0.0190, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 187, Loss: 0.0133, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 10, Epoch: 188, Loss: 0.0478, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 10, Epoch: 189, Loss: 0.0350, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 10, Epoch: 190, Loss: 0.0746, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 10, Epoch: 191, Loss: 0.0185, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 10, Epoch: 192, Loss: 0.0202, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 10, Epoch: 193, Loss: 0.0144, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 10, Epoch: 194, Loss: 0.0087, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 10, Epoch: 195, Loss: 0.0657, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 10, Epoch: 196, Loss: 0.0584, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 10, Epoch: 197, Loss: 0.0694, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 198, Loss: 0.0154, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 10, Epoch: 199, Loss: 0.0131, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 10, Epoch: 200, Loss: 0.0091, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 72.88\n",
      "  Final Train: 97.70\n",
      "   Final Test: 78.38\n",
      "All runs:\n",
      "Highest Train: 100.00 ± 0.00\n",
      "Highest Valid: 80.51 ± 7.33\n",
      "  Final Train: 97.24 ± 5.61\n",
      "   Final Test: 73.78 ± 7.54\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.5,'num_layers_mlp': 3}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 5,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(15, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        \n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.01)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ab088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
