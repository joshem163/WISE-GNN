{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af88d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx import ego_graph\n",
    "\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "\n",
    "#from logger import Logger\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import WebKB\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7babc9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "print(data)\n",
    "#split_idx = dataset.get_idx_split()\n",
    "#train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91fdcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "800\n",
      "510\n"
     ]
    }
   ],
   "source": [
    "train_index = np.where(data.train_mask)[0]\n",
    "print(len(train_index))\n",
    "valid_index = np.where(data.val_mask)[0]\n",
    "print(len(valid_index))\n",
    "test_index = np.where(data.test_mask)[0]\n",
    "print(len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0b82f",
   "metadata": {},
   "source": [
    "# GSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9ef33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, runs, info=None):\n",
    "        self.info = info\n",
    "        self.results = [[] for _ in range(runs)]\n",
    "\n",
    "    def add_result(self, run, result):\n",
    "        assert len(result) == 3\n",
    "        assert run >= 0 and run < len(self.results)\n",
    "        self.results[run].append(result)\n",
    "\n",
    "    def print_statistics(self, run=None):\n",
    "        if run is not None:\n",
    "            result = 100 * torch.tensor(self.results[run])\n",
    "            argmax = result[:, 1].argmax().item()\n",
    "            print(f'Run {run + 1:02d}:')\n",
    "            print(f'Highest Train: {result[:, 0].max():.2f}')\n",
    "            print(f'Highest Valid: {result[:, 1].max():.2f}')\n",
    "            print(f'  Final Train: {result[argmax, 0]:.2f}')\n",
    "            print(f'   Final Test: {result[argmax, 2]:.2f}')\n",
    "        else:\n",
    "            result = 100 * torch.tensor(self.results)\n",
    "\n",
    "            best_results = []\n",
    "            for r in result:\n",
    "                train1 = r[:, 0].max().item()\n",
    "                valid = r[:, 1].max().item()\n",
    "                train2 = r[r[:, 1].argmax(), 0].item()\n",
    "                test = r[r[:, 1].argmax(), 2].item()\n",
    "                best_results.append((train1, valid, train2, test))\n",
    "\n",
    "            best_result = torch.tensor(best_results)\n",
    "\n",
    "            print(f'All runs:')\n",
    "            r = best_result[:, 0]\n",
    "            print(f'Highest Train: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 1]\n",
    "            print(f'Highest Valid: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 2]\n",
    "            print(f'  Final Train: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 3]\n",
    "            print(f'   Final Test: {r.mean():.2f} ± {r.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47468ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(len(out))\n",
    "    #print(data.y.squeeze(1)[train_idx])\n",
    "    loss = F.nll_loss(out, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.adj_t)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=[data.train_mask[i][0] for i in range(183)]\n",
    "train_index = np.where(idx)[0]\n",
    "print(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23796d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x176f6f3a0>\n",
      "Run: 01, Epoch: 01, Loss: 1.8861, Train: 66.67%, Valid: 45.00% Test: 33.33%\n",
      "Run: 01, Epoch: 02, Loss: 0.9793, Train: 88.33%, Valid: 62.50% Test: 60.78%\n",
      "Run: 01, Epoch: 03, Loss: 0.7278, Train: 90.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 01, Epoch: 04, Loss: 0.6498, Train: 90.83%, Valid: 71.25% Test: 62.75%\n",
      "Run: 01, Epoch: 05, Loss: 0.5245, Train: 90.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 01, Epoch: 06, Loss: 0.5035, Train: 90.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 01, Epoch: 07, Loss: 0.4193, Train: 89.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 08, Loss: 0.4050, Train: 92.50%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 09, Loss: 0.4147, Train: 93.33%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 10, Loss: 0.4192, Train: 93.33%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 11, Loss: 0.3270, Train: 93.33%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 12, Loss: 0.2525, Train: 94.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 13, Loss: 0.2610, Train: 94.17%, Valid: 71.25% Test: 72.55%\n",
      "Run: 01, Epoch: 14, Loss: 0.2294, Train: 96.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 01, Epoch: 15, Loss: 0.2629, Train: 96.67%, Valid: 72.50% Test: 68.63%\n",
      "Run: 01, Epoch: 16, Loss: 0.2261, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 17, Loss: 0.1804, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 18, Loss: 0.2039, Train: 98.33%, Valid: 76.25% Test: 66.67%\n",
      "Run: 01, Epoch: 19, Loss: 0.1717, Train: 98.33%, Valid: 75.00% Test: 64.71%\n",
      "Run: 01, Epoch: 20, Loss: 0.1531, Train: 98.33%, Valid: 75.00% Test: 64.71%\n",
      "Run: 01, Epoch: 21, Loss: 0.1427, Train: 99.17%, Valid: 75.00% Test: 66.67%\n",
      "Run: 01, Epoch: 22, Loss: 0.1606, Train: 99.17%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 23, Loss: 0.1692, Train: 99.17%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 24, Loss: 0.1225, Train: 99.17%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 25, Loss: 0.1463, Train: 99.17%, Valid: 72.50% Test: 68.63%\n",
      "Run: 01, Epoch: 26, Loss: 0.1105, Train: 99.17%, Valid: 71.25% Test: 66.67%\n",
      "Run: 01, Epoch: 27, Loss: 0.1109, Train: 99.17%, Valid: 72.50% Test: 66.67%\n",
      "Run: 01, Epoch: 28, Loss: 0.0928, Train: 99.17%, Valid: 72.50% Test: 66.67%\n",
      "Run: 01, Epoch: 29, Loss: 0.1038, Train: 99.17%, Valid: 72.50% Test: 64.71%\n",
      "Run: 01, Epoch: 30, Loss: 0.0843, Train: 99.17%, Valid: 72.50% Test: 64.71%\n",
      "Run: 01, Epoch: 31, Loss: 0.0742, Train: 99.17%, Valid: 72.50% Test: 66.67%\n",
      "Run: 01, Epoch: 32, Loss: 0.0792, Train: 100.00%, Valid: 73.75% Test: 66.67%\n",
      "Run: 01, Epoch: 33, Loss: 0.1038, Train: 100.00%, Valid: 73.75% Test: 66.67%\n",
      "Run: 01, Epoch: 34, Loss: 0.0761, Train: 100.00%, Valid: 75.00% Test: 66.67%\n",
      "Run: 01, Epoch: 35, Loss: 0.0886, Train: 100.00%, Valid: 75.00% Test: 64.71%\n",
      "Run: 01, Epoch: 36, Loss: 0.0676, Train: 100.00%, Valid: 75.00% Test: 66.67%\n",
      "Run: 01, Epoch: 37, Loss: 0.0542, Train: 100.00%, Valid: 76.25% Test: 66.67%\n",
      "Run: 01, Epoch: 38, Loss: 0.0669, Train: 100.00%, Valid: 76.25% Test: 66.67%\n",
      "Run: 01, Epoch: 39, Loss: 0.0502, Train: 100.00%, Valid: 76.25% Test: 66.67%\n",
      "Run: 01, Epoch: 40, Loss: 0.0440, Train: 100.00%, Valid: 76.25% Test: 66.67%\n",
      "Run: 01, Epoch: 41, Loss: 0.0784, Train: 100.00%, Valid: 76.25% Test: 64.71%\n",
      "Run: 01, Epoch: 42, Loss: 0.0664, Train: 100.00%, Valid: 76.25% Test: 64.71%\n",
      "Run: 01, Epoch: 43, Loss: 0.0429, Train: 100.00%, Valid: 76.25% Test: 64.71%\n",
      "Run: 01, Epoch: 44, Loss: 0.0271, Train: 100.00%, Valid: 76.25% Test: 64.71%\n",
      "Run: 01, Epoch: 45, Loss: 0.0527, Train: 100.00%, Valid: 76.25% Test: 64.71%\n",
      "Run: 01, Epoch: 46, Loss: 0.0342, Train: 100.00%, Valid: 76.25% Test: 64.71%\n",
      "Run: 01, Epoch: 47, Loss: 0.0359, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 48, Loss: 0.0318, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 49, Loss: 0.0456, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 50, Loss: 0.0325, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 51, Loss: 0.0471, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 52, Loss: 0.0253, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 53, Loss: 0.0438, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 54, Loss: 0.0225, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 55, Loss: 0.0710, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 56, Loss: 0.0313, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 57, Loss: 0.0644, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 58, Loss: 0.0260, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 59, Loss: 0.0207, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 60, Loss: 0.0291, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 61, Loss: 0.0149, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 62, Loss: 0.0343, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 63, Loss: 0.0260, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 64, Loss: 0.0469, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 65, Loss: 0.0147, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 66, Loss: 0.0329, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 67, Loss: 0.0162, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 68, Loss: 0.0273, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 69, Loss: 0.0239, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 70, Loss: 0.0192, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 71, Loss: 0.0406, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 72, Loss: 0.0193, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 73, Loss: 0.0095, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 74, Loss: 0.0292, Train: 100.00%, Valid: 77.50% Test: 64.71%\n",
      "Run: 01, Epoch: 75, Loss: 0.0367, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 76, Loss: 0.0275, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 77, Loss: 0.0110, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 78, Loss: 0.0169, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 79, Loss: 0.0112, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 80, Loss: 0.0170, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 81, Loss: 0.0102, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 82, Loss: 0.0171, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 83, Loss: 0.0278, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 84, Loss: 0.0097, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 85, Loss: 0.0263, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 86, Loss: 0.0339, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 87, Loss: 0.0159, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 88, Loss: 0.0077, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 89, Loss: 0.0224, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 90, Loss: 0.0172, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 91, Loss: 0.0232, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 92, Loss: 0.0176, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 93, Loss: 0.0141, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 94, Loss: 0.0150, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 95, Loss: 0.0116, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 96, Loss: 0.0181, Train: 100.00%, Valid: 77.50% Test: 66.67%\n",
      "Run: 01, Epoch: 97, Loss: 0.0185, Train: 100.00%, Valid: 77.50% Test: 68.63%\n",
      "Run: 01, Epoch: 98, Loss: 0.0097, Train: 100.00%, Valid: 77.50% Test: 68.63%\n",
      "Run: 01, Epoch: 99, Loss: 0.0131, Train: 100.00%, Valid: 77.50% Test: 68.63%\n",
      "Run: 01, Epoch: 100, Loss: 0.0102, Train: 100.00%, Valid: 77.50% Test: 68.63%\n",
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 77.50\n",
      "  Final Train: 100.00\n",
      "   Final Test: 64.71\n",
      "Run: 02, Epoch: 01, Loss: 1.7717, Train: 80.83%, Valid: 53.75% Test: 70.59%\n",
      "Run: 02, Epoch: 02, Loss: 0.7840, Train: 85.83%, Valid: 66.25% Test: 76.47%\n",
      "Run: 02, Epoch: 03, Loss: 0.6671, Train: 87.50%, Valid: 68.75% Test: 78.43%\n",
      "Run: 02, Epoch: 04, Loss: 0.5563, Train: 86.67%, Valid: 68.75% Test: 82.35%\n",
      "Run: 02, Epoch: 05, Loss: 0.4924, Train: 89.17%, Valid: 70.00% Test: 82.35%\n",
      "Run: 02, Epoch: 06, Loss: 0.4876, Train: 90.83%, Valid: 70.00% Test: 82.35%\n",
      "Run: 02, Epoch: 07, Loss: 0.4176, Train: 91.67%, Valid: 70.00% Test: 82.35%\n",
      "Run: 02, Epoch: 08, Loss: 0.3639, Train: 92.50%, Valid: 71.25% Test: 82.35%\n",
      "Run: 02, Epoch: 09, Loss: 0.2814, Train: 92.50%, Valid: 71.25% Test: 82.35%\n",
      "Run: 02, Epoch: 10, Loss: 0.2720, Train: 92.50%, Valid: 71.25% Test: 84.31%\n",
      "Run: 02, Epoch: 11, Loss: 0.3197, Train: 94.17%, Valid: 70.00% Test: 84.31%\n",
      "Run: 02, Epoch: 12, Loss: 0.2622, Train: 95.00%, Valid: 72.50% Test: 84.31%\n",
      "Run: 02, Epoch: 13, Loss: 0.2294, Train: 96.67%, Valid: 72.50% Test: 82.35%\n",
      "Run: 02, Epoch: 14, Loss: 0.2321, Train: 95.83%, Valid: 72.50% Test: 80.39%\n",
      "Run: 02, Epoch: 15, Loss: 0.1810, Train: 97.50%, Valid: 75.00% Test: 80.39%\n",
      "Run: 02, Epoch: 16, Loss: 0.1799, Train: 98.33%, Valid: 76.25% Test: 80.39%\n",
      "Run: 02, Epoch: 17, Loss: 0.1829, Train: 98.33%, Valid: 76.25% Test: 78.43%\n",
      "Run: 02, Epoch: 18, Loss: 0.1927, Train: 98.33%, Valid: 75.00% Test: 80.39%\n",
      "Run: 02, Epoch: 19, Loss: 0.1373, Train: 98.33%, Valid: 75.00% Test: 80.39%\n",
      "Run: 02, Epoch: 20, Loss: 0.1557, Train: 98.33%, Valid: 75.00% Test: 80.39%\n",
      "Run: 02, Epoch: 21, Loss: 0.1305, Train: 98.33%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 22, Loss: 0.1130, Train: 98.33%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 23, Loss: 0.1268, Train: 98.33%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 24, Loss: 0.1116, Train: 98.33%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 25, Loss: 0.1140, Train: 99.17%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 26, Loss: 0.0764, Train: 99.17%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 27, Loss: 0.0814, Train: 99.17%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 28, Loss: 0.1035, Train: 99.17%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 29, Loss: 0.0625, Train: 99.17%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 30, Loss: 0.0586, Train: 100.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 31, Loss: 0.0702, Train: 100.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 32, Loss: 0.0565, Train: 100.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 33, Loss: 0.0894, Train: 100.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 34, Loss: 0.0544, Train: 100.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 35, Loss: 0.0614, Train: 100.00%, Valid: 73.75% Test: 80.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 36, Loss: 0.0678, Train: 100.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 37, Loss: 0.0561, Train: 100.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 38, Loss: 0.0380, Train: 100.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 39, Loss: 0.0655, Train: 100.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 40, Loss: 0.0550, Train: 100.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 41, Loss: 0.0436, Train: 100.00%, Valid: 73.75% Test: 82.35%\n",
      "Run: 02, Epoch: 42, Loss: 0.0733, Train: 100.00%, Valid: 73.75% Test: 82.35%\n",
      "Run: 02, Epoch: 43, Loss: 0.0677, Train: 100.00%, Valid: 73.75% Test: 82.35%\n",
      "Run: 02, Epoch: 44, Loss: 0.0495, Train: 99.17%, Valid: 73.75% Test: 82.35%\n",
      "Run: 02, Epoch: 45, Loss: 0.0456, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 46, Loss: 0.0295, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 47, Loss: 0.0300, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 48, Loss: 0.0326, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 49, Loss: 0.0461, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 50, Loss: 0.0391, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 51, Loss: 0.0212, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 52, Loss: 0.0275, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 53, Loss: 0.0128, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 54, Loss: 0.0277, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 55, Loss: 0.0475, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 56, Loss: 0.0227, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 57, Loss: 0.0334, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 58, Loss: 0.0260, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 59, Loss: 0.0299, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 60, Loss: 0.0195, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 61, Loss: 0.0228, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 62, Loss: 0.0478, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 63, Loss: 0.0198, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 64, Loss: 0.0281, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 65, Loss: 0.0494, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 66, Loss: 0.0303, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 67, Loss: 0.0148, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 68, Loss: 0.0205, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 69, Loss: 0.0153, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 70, Loss: 0.0300, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 71, Loss: 0.0282, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 72, Loss: 0.0101, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 73, Loss: 0.0324, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 74, Loss: 0.0180, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 75, Loss: 0.0231, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 76, Loss: 0.0170, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 77, Loss: 0.0137, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 78, Loss: 0.0158, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 79, Loss: 0.0240, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 80, Loss: 0.0204, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 81, Loss: 0.0218, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 82, Loss: 0.0218, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 83, Loss: 0.0169, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 84, Loss: 0.0081, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 85, Loss: 0.0195, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 86, Loss: 0.0251, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 87, Loss: 0.0139, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 88, Loss: 0.0139, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 89, Loss: 0.0174, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 90, Loss: 0.0075, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 91, Loss: 0.0160, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 92, Loss: 0.0127, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 93, Loss: 0.0074, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 94, Loss: 0.0239, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 95, Loss: 0.0118, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 96, Loss: 0.0151, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 97, Loss: 0.0135, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 98, Loss: 0.0162, Train: 100.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 99, Loss: 0.0094, Train: 100.00%, Valid: 73.75% Test: 82.35%\n",
      "Run: 02, Epoch: 100, Loss: 0.0034, Train: 100.00%, Valid: 73.75% Test: 82.35%\n",
      "Run 02:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 76.25\n",
      "  Final Train: 98.33\n",
      "   Final Test: 80.39\n",
      "Run: 03, Epoch: 01, Loss: 2.0310, Train: 59.17%, Valid: 33.75% Test: 35.29%\n",
      "Run: 03, Epoch: 02, Loss: 1.0720, Train: 86.67%, Valid: 58.75% Test: 56.86%\n",
      "Run: 03, Epoch: 03, Loss: 0.8201, Train: 85.83%, Valid: 62.50% Test: 62.75%\n",
      "Run: 03, Epoch: 04, Loss: 0.6614, Train: 82.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 05, Loss: 0.6543, Train: 78.33%, Valid: 68.75% Test: 66.67%\n",
      "Run: 03, Epoch: 06, Loss: 0.5630, Train: 79.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 03, Epoch: 07, Loss: 0.5322, Train: 80.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 03, Epoch: 08, Loss: 0.4979, Train: 80.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 03, Epoch: 09, Loss: 0.5283, Train: 81.67%, Valid: 68.75% Test: 68.63%\n",
      "Run: 03, Epoch: 10, Loss: 0.4447, Train: 83.33%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 11, Loss: 0.4147, Train: 85.83%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 12, Loss: 0.3804, Train: 91.67%, Valid: 72.50% Test: 66.67%\n",
      "Run: 03, Epoch: 13, Loss: 0.3728, Train: 92.50%, Valid: 72.50% Test: 66.67%\n",
      "Run: 03, Epoch: 14, Loss: 0.3042, Train: 94.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 03, Epoch: 15, Loss: 0.3039, Train: 95.00%, Valid: 72.50% Test: 66.67%\n",
      "Run: 03, Epoch: 16, Loss: 0.2725, Train: 95.83%, Valid: 75.00% Test: 68.63%\n",
      "Run: 03, Epoch: 17, Loss: 0.2640, Train: 95.83%, Valid: 76.25% Test: 68.63%\n",
      "Run: 03, Epoch: 18, Loss: 0.2510, Train: 95.83%, Valid: 77.50% Test: 68.63%\n",
      "Run: 03, Epoch: 19, Loss: 0.2468, Train: 95.83%, Valid: 78.75% Test: 68.63%\n",
      "Run: 03, Epoch: 20, Loss: 0.2402, Train: 98.33%, Valid: 78.75% Test: 68.63%\n",
      "Run: 03, Epoch: 21, Loss: 0.2004, Train: 98.33%, Valid: 77.50% Test: 68.63%\n",
      "Run: 03, Epoch: 22, Loss: 0.2022, Train: 98.33%, Valid: 78.75% Test: 66.67%\n",
      "Run: 03, Epoch: 23, Loss: 0.1547, Train: 98.33%, Valid: 78.75% Test: 66.67%\n",
      "Run: 03, Epoch: 24, Loss: 0.1734, Train: 99.17%, Valid: 76.25% Test: 66.67%\n",
      "Run: 03, Epoch: 25, Loss: 0.1546, Train: 99.17%, Valid: 76.25% Test: 64.71%\n",
      "Run: 03, Epoch: 26, Loss: 0.1516, Train: 99.17%, Valid: 76.25% Test: 64.71%\n",
      "Run: 03, Epoch: 27, Loss: 0.1270, Train: 99.17%, Valid: 75.00% Test: 64.71%\n",
      "Run: 03, Epoch: 28, Loss: 0.1082, Train: 99.17%, Valid: 75.00% Test: 64.71%\n",
      "Run: 03, Epoch: 29, Loss: 0.1109, Train: 99.17%, Valid: 73.75% Test: 64.71%\n",
      "Run: 03, Epoch: 30, Loss: 0.1366, Train: 99.17%, Valid: 73.75% Test: 64.71%\n",
      "Run: 03, Epoch: 31, Loss: 0.1247, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 03, Epoch: 32, Loss: 0.1382, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 03, Epoch: 33, Loss: 0.1158, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 03, Epoch: 34, Loss: 0.0777, Train: 99.17%, Valid: 68.75% Test: 64.71%\n",
      "Run: 03, Epoch: 35, Loss: 0.0555, Train: 99.17%, Valid: 68.75% Test: 64.71%\n",
      "Run: 03, Epoch: 36, Loss: 0.0653, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 37, Loss: 0.0916, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 38, Loss: 0.0869, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 03, Epoch: 39, Loss: 0.0769, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 03, Epoch: 40, Loss: 0.0625, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 03, Epoch: 41, Loss: 0.0643, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 03, Epoch: 42, Loss: 0.0730, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 03, Epoch: 43, Loss: 0.0380, Train: 100.00%, Valid: 68.75% Test: 62.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 44, Loss: 0.0525, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 45, Loss: 0.0395, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 46, Loss: 0.0311, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 47, Loss: 0.0688, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 48, Loss: 0.0347, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 49, Loss: 0.0422, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 50, Loss: 0.0894, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 51, Loss: 0.0370, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 52, Loss: 0.0637, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 03, Epoch: 53, Loss: 0.0504, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 03, Epoch: 54, Loss: 0.0397, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 03, Epoch: 55, Loss: 0.0417, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 03, Epoch: 56, Loss: 0.0339, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 03, Epoch: 57, Loss: 0.0247, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 03, Epoch: 58, Loss: 0.0336, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 03, Epoch: 59, Loss: 0.0412, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 03, Epoch: 60, Loss: 0.0353, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 03, Epoch: 61, Loss: 0.0177, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 03, Epoch: 62, Loss: 0.0296, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 03, Epoch: 63, Loss: 0.0233, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 03, Epoch: 64, Loss: 0.0158, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 03, Epoch: 65, Loss: 0.0194, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 66, Loss: 0.0524, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 67, Loss: 0.0158, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 68, Loss: 0.0495, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 69, Loss: 0.0200, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 70, Loss: 0.0505, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 71, Loss: 0.0310, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 72, Loss: 0.0406, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 73, Loss: 0.0237, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 74, Loss: 0.0122, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 75, Loss: 0.0242, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 03, Epoch: 76, Loss: 0.0199, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 77, Loss: 0.0203, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 78, Loss: 0.0151, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 79, Loss: 0.0046, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 80, Loss: 0.0211, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 81, Loss: 0.0538, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 82, Loss: 0.0253, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 83, Loss: 0.0415, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 84, Loss: 0.0227, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 85, Loss: 0.0254, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 86, Loss: 0.0174, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 87, Loss: 0.0047, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 88, Loss: 0.0245, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 89, Loss: 0.0245, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 90, Loss: 0.0082, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 03, Epoch: 91, Loss: 0.0245, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 92, Loss: 0.0177, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 93, Loss: 0.0140, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 94, Loss: 0.0200, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 03, Epoch: 95, Loss: 0.0211, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 96, Loss: 0.0292, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 97, Loss: 0.0313, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 98, Loss: 0.0066, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 99, Loss: 0.0241, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 03, Epoch: 100, Loss: 0.0075, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 78.75\n",
      "  Final Train: 95.83\n",
      "   Final Test: 68.63\n",
      "Run: 04, Epoch: 01, Loss: 1.7811, Train: 84.17%, Valid: 60.00% Test: 68.63%\n",
      "Run: 04, Epoch: 02, Loss: 0.8909, Train: 85.83%, Valid: 65.00% Test: 70.59%\n",
      "Run: 04, Epoch: 03, Loss: 0.7352, Train: 88.33%, Valid: 71.25% Test: 68.63%\n",
      "Run: 04, Epoch: 04, Loss: 0.6826, Train: 90.83%, Valid: 73.75% Test: 68.63%\n",
      "Run: 04, Epoch: 05, Loss: 0.5692, Train: 90.00%, Valid: 75.00% Test: 70.59%\n",
      "Run: 04, Epoch: 06, Loss: 0.5561, Train: 90.00%, Valid: 76.25% Test: 66.67%\n",
      "Run: 04, Epoch: 07, Loss: 0.4522, Train: 90.83%, Valid: 78.75% Test: 66.67%\n",
      "Run: 04, Epoch: 08, Loss: 0.4419, Train: 90.83%, Valid: 77.50% Test: 66.67%\n",
      "Run: 04, Epoch: 09, Loss: 0.4429, Train: 90.83%, Valid: 77.50% Test: 66.67%\n",
      "Run: 04, Epoch: 10, Loss: 0.4349, Train: 91.67%, Valid: 78.75% Test: 66.67%\n",
      "Run: 04, Epoch: 11, Loss: 0.3899, Train: 92.50%, Valid: 78.75% Test: 70.59%\n",
      "Run: 04, Epoch: 12, Loss: 0.3686, Train: 93.33%, Valid: 78.75% Test: 70.59%\n",
      "Run: 04, Epoch: 13, Loss: 0.3334, Train: 94.17%, Valid: 78.75% Test: 70.59%\n",
      "Run: 04, Epoch: 14, Loss: 0.2867, Train: 95.00%, Valid: 78.75% Test: 74.51%\n",
      "Run: 04, Epoch: 15, Loss: 0.2416, Train: 95.00%, Valid: 77.50% Test: 74.51%\n",
      "Run: 04, Epoch: 16, Loss: 0.2595, Train: 95.00%, Valid: 78.75% Test: 74.51%\n",
      "Run: 04, Epoch: 17, Loss: 0.1967, Train: 95.00%, Valid: 77.50% Test: 76.47%\n",
      "Run: 04, Epoch: 18, Loss: 0.2412, Train: 96.67%, Valid: 76.25% Test: 78.43%\n",
      "Run: 04, Epoch: 19, Loss: 0.2571, Train: 97.50%, Valid: 76.25% Test: 80.39%\n",
      "Run: 04, Epoch: 20, Loss: 0.1851, Train: 97.50%, Valid: 76.25% Test: 80.39%\n",
      "Run: 04, Epoch: 21, Loss: 0.2013, Train: 97.50%, Valid: 76.25% Test: 80.39%\n",
      "Run: 04, Epoch: 22, Loss: 0.1513, Train: 97.50%, Valid: 73.75% Test: 80.39%\n",
      "Run: 04, Epoch: 23, Loss: 0.1657, Train: 97.50%, Valid: 75.00% Test: 80.39%\n",
      "Run: 04, Epoch: 24, Loss: 0.1515, Train: 97.50%, Valid: 73.75% Test: 80.39%\n",
      "Run: 04, Epoch: 25, Loss: 0.1380, Train: 97.50%, Valid: 73.75% Test: 78.43%\n",
      "Run: 04, Epoch: 26, Loss: 0.1456, Train: 97.50%, Valid: 73.75% Test: 78.43%\n",
      "Run: 04, Epoch: 27, Loss: 0.1537, Train: 97.50%, Valid: 73.75% Test: 78.43%\n",
      "Run: 04, Epoch: 28, Loss: 0.1244, Train: 97.50%, Valid: 73.75% Test: 78.43%\n",
      "Run: 04, Epoch: 29, Loss: 0.0880, Train: 97.50%, Valid: 73.75% Test: 78.43%\n",
      "Run: 04, Epoch: 30, Loss: 0.0886, Train: 99.17%, Valid: 73.75% Test: 76.47%\n",
      "Run: 04, Epoch: 31, Loss: 0.0968, Train: 99.17%, Valid: 73.75% Test: 76.47%\n",
      "Run: 04, Epoch: 32, Loss: 0.0669, Train: 98.33%, Valid: 72.50% Test: 76.47%\n",
      "Run: 04, Epoch: 33, Loss: 0.1019, Train: 98.33%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 34, Loss: 0.0696, Train: 98.33%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 35, Loss: 0.0642, Train: 98.33%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 36, Loss: 0.0676, Train: 99.17%, Valid: 72.50% Test: 80.39%\n",
      "Run: 04, Epoch: 37, Loss: 0.0886, Train: 100.00%, Valid: 72.50% Test: 80.39%\n",
      "Run: 04, Epoch: 38, Loss: 0.0699, Train: 100.00%, Valid: 72.50% Test: 80.39%\n",
      "Run: 04, Epoch: 39, Loss: 0.1105, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 40, Loss: 0.0640, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 41, Loss: 0.0511, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 42, Loss: 0.0405, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 43, Loss: 0.0526, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 44, Loss: 0.0975, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 45, Loss: 0.0596, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 46, Loss: 0.0386, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 47, Loss: 0.0353, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 48, Loss: 0.0570, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 49, Loss: 0.0445, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 50, Loss: 0.0322, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 51, Loss: 0.0517, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 52, Loss: 0.0391, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 53, Loss: 0.0738, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 54, Loss: 0.0482, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 55, Loss: 0.0309, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 56, Loss: 0.0511, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 57, Loss: 0.0383, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 58, Loss: 0.0424, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 59, Loss: 0.0365, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 60, Loss: 0.0229, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 61, Loss: 0.0311, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 62, Loss: 0.0390, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 63, Loss: 0.0478, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 64, Loss: 0.0473, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 65, Loss: 0.0767, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 66, Loss: 0.0164, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 67, Loss: 0.0235, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 68, Loss: 0.0156, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 69, Loss: 0.0420, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 70, Loss: 0.0245, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 71, Loss: 0.0261, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 72, Loss: 0.0163, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 73, Loss: 0.0280, Train: 100.00%, Valid: 71.25% Test: 80.39%\n",
      "Run: 04, Epoch: 74, Loss: 0.0300, Train: 100.00%, Valid: 71.25% Test: 80.39%\n",
      "Run: 04, Epoch: 75, Loss: 0.0206, Train: 100.00%, Valid: 71.25% Test: 80.39%\n",
      "Run: 04, Epoch: 76, Loss: 0.0293, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 77, Loss: 0.0148, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 78, Loss: 0.0495, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 79, Loss: 0.0200, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 80, Loss: 0.0262, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 81, Loss: 0.0325, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 04, Epoch: 82, Loss: 0.0271, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 04, Epoch: 83, Loss: 0.0215, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 04, Epoch: 84, Loss: 0.0290, Train: 100.00%, Valid: 72.50% Test: 76.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 85, Loss: 0.0135, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 04, Epoch: 86, Loss: 0.0196, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 04, Epoch: 87, Loss: 0.0196, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 04, Epoch: 88, Loss: 0.0222, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 04, Epoch: 89, Loss: 0.0249, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 90, Loss: 0.0280, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 91, Loss: 0.0093, Train: 100.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 04, Epoch: 92, Loss: 0.0217, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 93, Loss: 0.0075, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 94, Loss: 0.0240, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 95, Loss: 0.0117, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 96, Loss: 0.0194, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 97, Loss: 0.0173, Train: 100.00%, Valid: 71.25% Test: 78.43%\n",
      "Run: 04, Epoch: 98, Loss: 0.0122, Train: 100.00%, Valid: 71.25% Test: 80.39%\n",
      "Run: 04, Epoch: 99, Loss: 0.0202, Train: 100.00%, Valid: 71.25% Test: 80.39%\n",
      "Run: 04, Epoch: 100, Loss: 0.0164, Train: 100.00%, Valid: 71.25% Test: 80.39%\n",
      "Run 04:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 78.75\n",
      "  Final Train: 90.83\n",
      "   Final Test: 66.67\n",
      "Run: 05, Epoch: 01, Loss: 1.7287, Train: 83.33%, Valid: 53.75% Test: 68.63%\n",
      "Run: 05, Epoch: 02, Loss: 0.9415, Train: 88.33%, Valid: 63.75% Test: 62.75%\n",
      "Run: 05, Epoch: 03, Loss: 0.7487, Train: 89.17%, Valid: 63.75% Test: 64.71%\n",
      "Run: 05, Epoch: 04, Loss: 0.6750, Train: 89.17%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 05, Loss: 0.5778, Train: 89.17%, Valid: 72.50% Test: 70.59%\n",
      "Run: 05, Epoch: 06, Loss: 0.5355, Train: 90.00%, Valid: 73.75% Test: 66.67%\n",
      "Run: 05, Epoch: 07, Loss: 0.4871, Train: 92.50%, Valid: 72.50% Test: 66.67%\n",
      "Run: 05, Epoch: 08, Loss: 0.4557, Train: 92.50%, Valid: 70.00% Test: 66.67%\n",
      "Run: 05, Epoch: 09, Loss: 0.4242, Train: 95.83%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 10, Loss: 0.3728, Train: 96.67%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 11, Loss: 0.3724, Train: 97.50%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 12, Loss: 0.3477, Train: 98.33%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 13, Loss: 0.2882, Train: 98.33%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 14, Loss: 0.2805, Train: 98.33%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 15, Loss: 0.2285, Train: 98.33%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 16, Loss: 0.2452, Train: 98.33%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 17, Loss: 0.2100, Train: 98.33%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 18, Loss: 0.1826, Train: 98.33%, Valid: 70.00% Test: 66.67%\n",
      "Run: 05, Epoch: 19, Loss: 0.1767, Train: 98.33%, Valid: 68.75% Test: 64.71%\n",
      "Run: 05, Epoch: 20, Loss: 0.1671, Train: 98.33%, Valid: 68.75% Test: 64.71%\n",
      "Run: 05, Epoch: 21, Loss: 0.1553, Train: 98.33%, Valid: 68.75% Test: 64.71%\n",
      "Run: 05, Epoch: 22, Loss: 0.1734, Train: 98.33%, Valid: 68.75% Test: 64.71%\n",
      "Run: 05, Epoch: 23, Loss: 0.1329, Train: 98.33%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 24, Loss: 0.1230, Train: 99.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 05, Epoch: 25, Loss: 0.1220, Train: 99.17%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 26, Loss: 0.1017, Train: 99.17%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 27, Loss: 0.1101, Train: 99.17%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 28, Loss: 0.1169, Train: 99.17%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 29, Loss: 0.1050, Train: 99.17%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 30, Loss: 0.0712, Train: 99.17%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 31, Loss: 0.0845, Train: 99.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 32, Loss: 0.1257, Train: 99.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 33, Loss: 0.0668, Train: 99.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 34, Loss: 0.0951, Train: 99.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 35, Loss: 0.0564, Train: 99.17%, Valid: 72.50% Test: 68.63%\n",
      "Run: 05, Epoch: 36, Loss: 0.0506, Train: 99.17%, Valid: 72.50% Test: 68.63%\n",
      "Run: 05, Epoch: 37, Loss: 0.0394, Train: 99.17%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 38, Loss: 0.0355, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 39, Loss: 0.0514, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 40, Loss: 0.0521, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 41, Loss: 0.0326, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 42, Loss: 0.0448, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 43, Loss: 0.0385, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 44, Loss: 0.0377, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 45, Loss: 0.0667, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 46, Loss: 0.0619, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 47, Loss: 0.0274, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 48, Loss: 0.0386, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 49, Loss: 0.0484, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 50, Loss: 0.0490, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 51, Loss: 0.0375, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 52, Loss: 0.0330, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 53, Loss: 0.0166, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 54, Loss: 0.0280, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 55, Loss: 0.0395, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 56, Loss: 0.0292, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 57, Loss: 0.0328, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 58, Loss: 0.0207, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 59, Loss: 0.0224, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 60, Loss: 0.0331, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 61, Loss: 0.0336, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 62, Loss: 0.0139, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 63, Loss: 0.0238, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 64, Loss: 0.0359, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 65, Loss: 0.0219, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 66, Loss: 0.0130, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 67, Loss: 0.0187, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 68, Loss: 0.0117, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 69, Loss: 0.0370, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 70, Loss: 0.0120, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 71, Loss: 0.0259, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 72, Loss: 0.0302, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 73, Loss: 0.0212, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 74, Loss: 0.0340, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 75, Loss: 0.0222, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 76, Loss: 0.0163, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 77, Loss: 0.0565, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 78, Loss: 0.0237, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 79, Loss: 0.0237, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 80, Loss: 0.0229, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 81, Loss: 0.0185, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 82, Loss: 0.0200, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 83, Loss: 0.0203, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 05, Epoch: 84, Loss: 0.0166, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 05, Epoch: 85, Loss: 0.0289, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 86, Loss: 0.0373, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 87, Loss: 0.0222, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 88, Loss: 0.0169, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 89, Loss: 0.0126, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 05, Epoch: 90, Loss: 0.0257, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 05, Epoch: 91, Loss: 0.0231, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 05, Epoch: 92, Loss: 0.0159, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 05, Epoch: 93, Loss: 0.0282, Train: 100.00%, Valid: 71.25% Test: 74.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 94, Loss: 0.0057, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 05, Epoch: 95, Loss: 0.0268, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 05, Epoch: 96, Loss: 0.0119, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 05, Epoch: 97, Loss: 0.0071, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 05, Epoch: 98, Loss: 0.0148, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 05, Epoch: 99, Loss: 0.0100, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 05, Epoch: 100, Loss: 0.0193, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run 05:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.75\n",
      "  Final Train: 90.00\n",
      "   Final Test: 66.67\n",
      "Run: 06, Epoch: 01, Loss: 1.5982, Train: 77.50%, Valid: 50.00% Test: 49.02%\n",
      "Run: 06, Epoch: 02, Loss: 0.7250, Train: 80.83%, Valid: 62.50% Test: 58.82%\n",
      "Run: 06, Epoch: 03, Loss: 0.5967, Train: 86.67%, Valid: 62.50% Test: 62.75%\n",
      "Run: 06, Epoch: 04, Loss: 0.5208, Train: 88.33%, Valid: 65.00% Test: 60.78%\n",
      "Run: 06, Epoch: 05, Loss: 0.4653, Train: 88.33%, Valid: 66.25% Test: 60.78%\n",
      "Run: 06, Epoch: 06, Loss: 0.4105, Train: 90.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 07, Loss: 0.4185, Train: 91.67%, Valid: 68.75% Test: 60.78%\n",
      "Run: 06, Epoch: 08, Loss: 0.2897, Train: 91.67%, Valid: 67.50% Test: 62.75%\n",
      "Run: 06, Epoch: 09, Loss: 0.3358, Train: 92.50%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 10, Loss: 0.2983, Train: 93.33%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 11, Loss: 0.2553, Train: 93.33%, Valid: 67.50% Test: 64.71%\n",
      "Run: 06, Epoch: 12, Loss: 0.2353, Train: 93.33%, Valid: 67.50% Test: 64.71%\n",
      "Run: 06, Epoch: 13, Loss: 0.2281, Train: 96.67%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 14, Loss: 0.2034, Train: 97.50%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 15, Loss: 0.1539, Train: 97.50%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 16, Loss: 0.1337, Train: 97.50%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 17, Loss: 0.1444, Train: 97.50%, Valid: 70.00% Test: 60.78%\n",
      "Run: 06, Epoch: 18, Loss: 0.1371, Train: 98.33%, Valid: 68.75% Test: 58.82%\n",
      "Run: 06, Epoch: 19, Loss: 0.1221, Train: 98.33%, Valid: 67.50% Test: 60.78%\n",
      "Run: 06, Epoch: 20, Loss: 0.1062, Train: 99.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 06, Epoch: 21, Loss: 0.0980, Train: 99.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 06, Epoch: 22, Loss: 0.1183, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 06, Epoch: 23, Loss: 0.0834, Train: 100.00%, Valid: 65.00% Test: 66.67%\n",
      "Run: 06, Epoch: 24, Loss: 0.0947, Train: 100.00%, Valid: 65.00% Test: 66.67%\n",
      "Run: 06, Epoch: 25, Loss: 0.1075, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 06, Epoch: 26, Loss: 0.0930, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 27, Loss: 0.0620, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 28, Loss: 0.0733, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 06, Epoch: 29, Loss: 0.0452, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 30, Loss: 0.0744, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 31, Loss: 0.0447, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 32, Loss: 0.0486, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 33, Loss: 0.0361, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 34, Loss: 0.0546, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 35, Loss: 0.0331, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 06, Epoch: 36, Loss: 0.0252, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 06, Epoch: 37, Loss: 0.0576, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 06, Epoch: 38, Loss: 0.0456, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 06, Epoch: 39, Loss: 0.0412, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 40, Loss: 0.0254, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 41, Loss: 0.0699, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 42, Loss: 0.0454, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 43, Loss: 0.0210, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 44, Loss: 0.0459, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 45, Loss: 0.0263, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 46, Loss: 0.0220, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 47, Loss: 0.0301, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 48, Loss: 0.0290, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 06, Epoch: 49, Loss: 0.0224, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 06, Epoch: 50, Loss: 0.0242, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 06, Epoch: 51, Loss: 0.0172, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 06, Epoch: 52, Loss: 0.0263, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 53, Loss: 0.0178, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 54, Loss: 0.0267, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 55, Loss: 0.0150, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 56, Loss: 0.0164, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 57, Loss: 0.0111, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 06, Epoch: 58, Loss: 0.0137, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 59, Loss: 0.0200, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 60, Loss: 0.0154, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 61, Loss: 0.0289, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 62, Loss: 0.0222, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 63, Loss: 0.0304, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 64, Loss: 0.0355, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 65, Loss: 0.0126, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 66, Loss: 0.0203, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 67, Loss: 0.0140, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 68, Loss: 0.0131, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 06, Epoch: 69, Loss: 0.0231, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 06, Epoch: 70, Loss: 0.0198, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 06, Epoch: 71, Loss: 0.0095, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 06, Epoch: 72, Loss: 0.0107, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 06, Epoch: 73, Loss: 0.0201, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 06, Epoch: 74, Loss: 0.0115, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 75, Loss: 0.0137, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 06, Epoch: 76, Loss: 0.0118, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 06, Epoch: 77, Loss: 0.0246, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 06, Epoch: 78, Loss: 0.0198, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 79, Loss: 0.0220, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 80, Loss: 0.0089, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 81, Loss: 0.0084, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 82, Loss: 0.0181, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 83, Loss: 0.0091, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 84, Loss: 0.0158, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 85, Loss: 0.0171, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 86, Loss: 0.0140, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 87, Loss: 0.0091, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 88, Loss: 0.0192, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 89, Loss: 0.0101, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 90, Loss: 0.0033, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 06, Epoch: 91, Loss: 0.0035, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 92, Loss: 0.0115, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 93, Loss: 0.0451, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 94, Loss: 0.0310, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 95, Loss: 0.0099, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 96, Loss: 0.0204, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 97, Loss: 0.0048, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 98, Loss: 0.0064, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 99, Loss: 0.0155, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 100, Loss: 0.0059, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run 06:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 71.25\n",
      "  Final Train: 100.00\n",
      "   Final Test: 72.55\n",
      "Run: 07, Epoch: 01, Loss: 1.8148, Train: 73.33%, Valid: 56.25% Test: 52.94%\n",
      "Run: 07, Epoch: 02, Loss: 1.0057, Train: 90.83%, Valid: 73.75% Test: 72.55%\n",
      "Run: 07, Epoch: 03, Loss: 0.7038, Train: 92.50%, Valid: 75.00% Test: 74.51%\n",
      "Run: 07, Epoch: 04, Loss: 0.5965, Train: 94.17%, Valid: 76.25% Test: 76.47%\n",
      "Run: 07, Epoch: 05, Loss: 0.5760, Train: 94.17%, Valid: 76.25% Test: 76.47%\n",
      "Run: 07, Epoch: 06, Loss: 0.5081, Train: 92.50%, Valid: 76.25% Test: 74.51%\n",
      "Run: 07, Epoch: 07, Loss: 0.4746, Train: 92.50%, Valid: 73.75% Test: 72.55%\n",
      "Run: 07, Epoch: 08, Loss: 0.3987, Train: 92.50%, Valid: 71.25% Test: 72.55%\n",
      "Run: 07, Epoch: 09, Loss: 0.3882, Train: 93.33%, Valid: 72.50% Test: 72.55%\n",
      "Run: 07, Epoch: 10, Loss: 0.3582, Train: 94.17%, Valid: 71.25% Test: 72.55%\n",
      "Run: 07, Epoch: 11, Loss: 0.3424, Train: 94.17%, Valid: 72.50% Test: 72.55%\n",
      "Run: 07, Epoch: 12, Loss: 0.3831, Train: 96.67%, Valid: 72.50% Test: 72.55%\n",
      "Run: 07, Epoch: 13, Loss: 0.3072, Train: 97.50%, Valid: 73.75% Test: 74.51%\n",
      "Run: 07, Epoch: 14, Loss: 0.3706, Train: 97.50%, Valid: 73.75% Test: 74.51%\n",
      "Run: 07, Epoch: 15, Loss: 0.2103, Train: 97.50%, Valid: 72.50% Test: 76.47%\n",
      "Run: 07, Epoch: 16, Loss: 0.1914, Train: 97.50%, Valid: 72.50% Test: 78.43%\n",
      "Run: 07, Epoch: 17, Loss: 0.2004, Train: 98.33%, Valid: 72.50% Test: 80.39%\n",
      "Run: 07, Epoch: 18, Loss: 0.1887, Train: 98.33%, Valid: 73.75% Test: 80.39%\n",
      "Run: 07, Epoch: 19, Loss: 0.1480, Train: 98.33%, Valid: 75.00% Test: 80.39%\n",
      "Run: 07, Epoch: 20, Loss: 0.1840, Train: 98.33%, Valid: 75.00% Test: 78.43%\n",
      "Run: 07, Epoch: 21, Loss: 0.1856, Train: 98.33%, Valid: 75.00% Test: 76.47%\n",
      "Run: 07, Epoch: 22, Loss: 0.2020, Train: 98.33%, Valid: 76.25% Test: 76.47%\n",
      "Run: 07, Epoch: 23, Loss: 0.1410, Train: 98.33%, Valid: 76.25% Test: 78.43%\n",
      "Run: 07, Epoch: 24, Loss: 0.1277, Train: 99.17%, Valid: 73.75% Test: 82.35%\n",
      "Run: 07, Epoch: 25, Loss: 0.1444, Train: 99.17%, Valid: 72.50% Test: 82.35%\n",
      "Run: 07, Epoch: 26, Loss: 0.0993, Train: 99.17%, Valid: 72.50% Test: 80.39%\n",
      "Run: 07, Epoch: 27, Loss: 0.1493, Train: 99.17%, Valid: 72.50% Test: 76.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 28, Loss: 0.1086, Train: 99.17%, Valid: 72.50% Test: 76.47%\n",
      "Run: 07, Epoch: 29, Loss: 0.1020, Train: 99.17%, Valid: 72.50% Test: 76.47%\n",
      "Run: 07, Epoch: 30, Loss: 0.1077, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 07, Epoch: 31, Loss: 0.0923, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 07, Epoch: 32, Loss: 0.0779, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 07, Epoch: 33, Loss: 0.0814, Train: 100.00%, Valid: 70.00% Test: 76.47%\n",
      "Run: 07, Epoch: 34, Loss: 0.0763, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 35, Loss: 0.0596, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 36, Loss: 0.0388, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 37, Loss: 0.0748, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 38, Loss: 0.0613, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 39, Loss: 0.0488, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 40, Loss: 0.0781, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 41, Loss: 0.0923, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 42, Loss: 0.0472, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 43, Loss: 0.0425, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 44, Loss: 0.0588, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 45, Loss: 0.0456, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 46, Loss: 0.1044, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 47, Loss: 0.0332, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 48, Loss: 0.0443, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 49, Loss: 0.0639, Train: 100.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 07, Epoch: 50, Loss: 0.0586, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 51, Loss: 0.0568, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 52, Loss: 0.0375, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 53, Loss: 0.0214, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 54, Loss: 0.0595, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 55, Loss: 0.0597, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 56, Loss: 0.0339, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 57, Loss: 0.0122, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 58, Loss: 0.0253, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 59, Loss: 0.0299, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 60, Loss: 0.0450, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 61, Loss: 0.0408, Train: 100.00%, Valid: 68.75% Test: 80.39%\n",
      "Run: 07, Epoch: 62, Loss: 0.0185, Train: 100.00%, Valid: 70.00% Test: 80.39%\n",
      "Run: 07, Epoch: 63, Loss: 0.0372, Train: 100.00%, Valid: 70.00% Test: 80.39%\n",
      "Run: 07, Epoch: 64, Loss: 0.0294, Train: 100.00%, Valid: 70.00% Test: 80.39%\n",
      "Run: 07, Epoch: 65, Loss: 0.0307, Train: 100.00%, Valid: 70.00% Test: 80.39%\n",
      "Run: 07, Epoch: 66, Loss: 0.0290, Train: 100.00%, Valid: 70.00% Test: 80.39%\n",
      "Run: 07, Epoch: 67, Loss: 0.0567, Train: 100.00%, Valid: 71.25% Test: 82.35%\n",
      "Run: 07, Epoch: 68, Loss: 0.0266, Train: 100.00%, Valid: 71.25% Test: 80.39%\n",
      "Run: 07, Epoch: 69, Loss: 0.0094, Train: 100.00%, Valid: 71.25% Test: 80.39%\n",
      "Run: 07, Epoch: 70, Loss: 0.0240, Train: 100.00%, Valid: 72.50% Test: 80.39%\n",
      "Run: 07, Epoch: 71, Loss: 0.0175, Train: 100.00%, Valid: 72.50% Test: 80.39%\n",
      "Run: 07, Epoch: 72, Loss: 0.0217, Train: 100.00%, Valid: 72.50% Test: 80.39%\n",
      "Run: 07, Epoch: 73, Loss: 0.0123, Train: 100.00%, Valid: 72.50% Test: 80.39%\n",
      "Run: 07, Epoch: 74, Loss: 0.0232, Train: 100.00%, Valid: 72.50% Test: 80.39%\n",
      "Run: 07, Epoch: 75, Loss: 0.0423, Train: 100.00%, Valid: 72.50% Test: 82.35%\n",
      "Run: 07, Epoch: 76, Loss: 0.0241, Train: 100.00%, Valid: 72.50% Test: 82.35%\n",
      "Run: 07, Epoch: 77, Loss: 0.0391, Train: 100.00%, Valid: 72.50% Test: 82.35%\n",
      "Run: 07, Epoch: 78, Loss: 0.0227, Train: 100.00%, Valid: 72.50% Test: 82.35%\n",
      "Run: 07, Epoch: 79, Loss: 0.0394, Train: 100.00%, Valid: 72.50% Test: 80.39%\n",
      "Run: 07, Epoch: 80, Loss: 0.0322, Train: 100.00%, Valid: 72.50% Test: 80.39%\n",
      "Run: 07, Epoch: 81, Loss: 0.0269, Train: 100.00%, Valid: 72.50% Test: 82.35%\n",
      "Run: 07, Epoch: 82, Loss: 0.0199, Train: 100.00%, Valid: 72.50% Test: 82.35%\n",
      "Run: 07, Epoch: 83, Loss: 0.0122, Train: 100.00%, Valid: 72.50% Test: 82.35%\n",
      "Run: 07, Epoch: 84, Loss: 0.0058, Train: 100.00%, Valid: 72.50% Test: 82.35%\n",
      "Run: 07, Epoch: 85, Loss: 0.0301, Train: 100.00%, Valid: 70.00% Test: 82.35%\n",
      "Run: 07, Epoch: 86, Loss: 0.0185, Train: 100.00%, Valid: 70.00% Test: 82.35%\n",
      "Run: 07, Epoch: 87, Loss: 0.0104, Train: 100.00%, Valid: 70.00% Test: 84.31%\n",
      "Run: 07, Epoch: 88, Loss: 0.0159, Train: 100.00%, Valid: 70.00% Test: 84.31%\n",
      "Run: 07, Epoch: 89, Loss: 0.0142, Train: 100.00%, Valid: 70.00% Test: 84.31%\n",
      "Run: 07, Epoch: 90, Loss: 0.0293, Train: 100.00%, Valid: 70.00% Test: 82.35%\n",
      "Run: 07, Epoch: 91, Loss: 0.0225, Train: 100.00%, Valid: 70.00% Test: 82.35%\n",
      "Run: 07, Epoch: 92, Loss: 0.0092, Train: 100.00%, Valid: 70.00% Test: 82.35%\n",
      "Run: 07, Epoch: 93, Loss: 0.0189, Train: 100.00%, Valid: 71.25% Test: 82.35%\n",
      "Run: 07, Epoch: 94, Loss: 0.0156, Train: 100.00%, Valid: 71.25% Test: 82.35%\n",
      "Run: 07, Epoch: 95, Loss: 0.0144, Train: 100.00%, Valid: 71.25% Test: 82.35%\n",
      "Run: 07, Epoch: 96, Loss: 0.0157, Train: 100.00%, Valid: 71.25% Test: 82.35%\n",
      "Run: 07, Epoch: 97, Loss: 0.0138, Train: 100.00%, Valid: 71.25% Test: 82.35%\n",
      "Run: 07, Epoch: 98, Loss: 0.0165, Train: 100.00%, Valid: 71.25% Test: 82.35%\n",
      "Run: 07, Epoch: 99, Loss: 0.0289, Train: 100.00%, Valid: 71.25% Test: 82.35%\n",
      "Run: 07, Epoch: 100, Loss: 0.0207, Train: 100.00%, Valid: 71.25% Test: 82.35%\n",
      "Run 07:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 76.25\n",
      "  Final Train: 94.17\n",
      "   Final Test: 76.47\n",
      "Run: 08, Epoch: 01, Loss: 1.9658, Train: 59.17%, Valid: 55.00% Test: 35.29%\n",
      "Run: 08, Epoch: 02, Loss: 0.9469, Train: 75.83%, Valid: 66.25% Test: 54.90%\n",
      "Run: 08, Epoch: 03, Loss: 0.7609, Train: 79.17%, Valid: 70.00% Test: 68.63%\n",
      "Run: 08, Epoch: 04, Loss: 0.6774, Train: 80.83%, Valid: 71.25% Test: 78.43%\n",
      "Run: 08, Epoch: 05, Loss: 0.6567, Train: 83.33%, Valid: 71.25% Test: 80.39%\n",
      "Run: 08, Epoch: 06, Loss: 0.6283, Train: 83.33%, Valid: 72.50% Test: 78.43%\n",
      "Run: 08, Epoch: 07, Loss: 0.5423, Train: 84.17%, Valid: 73.75% Test: 80.39%\n",
      "Run: 08, Epoch: 08, Loss: 0.5005, Train: 84.17%, Valid: 73.75% Test: 82.35%\n",
      "Run: 08, Epoch: 09, Loss: 0.4853, Train: 87.50%, Valid: 72.50% Test: 80.39%\n",
      "Run: 08, Epoch: 10, Loss: 0.4686, Train: 89.17%, Valid: 73.75% Test: 80.39%\n",
      "Run: 08, Epoch: 11, Loss: 0.4416, Train: 91.67%, Valid: 73.75% Test: 80.39%\n",
      "Run: 08, Epoch: 12, Loss: 0.4235, Train: 90.83%, Valid: 75.00% Test: 80.39%\n",
      "Run: 08, Epoch: 13, Loss: 0.3340, Train: 90.83%, Valid: 76.25% Test: 80.39%\n",
      "Run: 08, Epoch: 14, Loss: 0.3393, Train: 91.67%, Valid: 77.50% Test: 78.43%\n",
      "Run: 08, Epoch: 15, Loss: 0.3760, Train: 93.33%, Valid: 77.50% Test: 76.47%\n",
      "Run: 08, Epoch: 16, Loss: 0.3113, Train: 95.00%, Valid: 77.50% Test: 74.51%\n",
      "Run: 08, Epoch: 17, Loss: 0.2837, Train: 95.83%, Valid: 77.50% Test: 74.51%\n",
      "Run: 08, Epoch: 18, Loss: 0.2798, Train: 95.83%, Valid: 77.50% Test: 74.51%\n",
      "Run: 08, Epoch: 19, Loss: 0.2607, Train: 97.50%, Valid: 77.50% Test: 74.51%\n",
      "Run: 08, Epoch: 20, Loss: 0.2417, Train: 97.50%, Valid: 77.50% Test: 74.51%\n",
      "Run: 08, Epoch: 21, Loss: 0.2350, Train: 97.50%, Valid: 77.50% Test: 74.51%\n",
      "Run: 08, Epoch: 22, Loss: 0.2151, Train: 98.33%, Valid: 77.50% Test: 74.51%\n",
      "Run: 08, Epoch: 23, Loss: 0.2302, Train: 98.33%, Valid: 77.50% Test: 76.47%\n",
      "Run: 08, Epoch: 24, Loss: 0.1849, Train: 98.33%, Valid: 77.50% Test: 76.47%\n",
      "Run: 08, Epoch: 25, Loss: 0.2019, Train: 98.33%, Valid: 77.50% Test: 76.47%\n",
      "Run: 08, Epoch: 26, Loss: 0.1801, Train: 98.33%, Valid: 78.75% Test: 76.47%\n",
      "Run: 08, Epoch: 27, Loss: 0.1572, Train: 98.33%, Valid: 78.75% Test: 76.47%\n",
      "Run: 08, Epoch: 28, Loss: 0.1426, Train: 98.33%, Valid: 78.75% Test: 76.47%\n",
      "Run: 08, Epoch: 29, Loss: 0.1445, Train: 98.33%, Valid: 78.75% Test: 76.47%\n",
      "Run: 08, Epoch: 30, Loss: 0.1544, Train: 98.33%, Valid: 78.75% Test: 76.47%\n",
      "Run: 08, Epoch: 31, Loss: 0.1123, Train: 98.33%, Valid: 77.50% Test: 76.47%\n",
      "Run: 08, Epoch: 32, Loss: 0.1189, Train: 99.17%, Valid: 77.50% Test: 76.47%\n",
      "Run: 08, Epoch: 33, Loss: 0.1059, Train: 99.17%, Valid: 77.50% Test: 76.47%\n",
      "Run: 08, Epoch: 34, Loss: 0.1294, Train: 99.17%, Valid: 78.75% Test: 74.51%\n",
      "Run: 08, Epoch: 35, Loss: 0.0957, Train: 99.17%, Valid: 78.75% Test: 74.51%\n",
      "Run: 08, Epoch: 36, Loss: 0.1045, Train: 99.17%, Valid: 78.75% Test: 74.51%\n",
      "Run: 08, Epoch: 37, Loss: 0.1022, Train: 100.00%, Valid: 78.75% Test: 74.51%\n",
      "Run: 08, Epoch: 38, Loss: 0.0906, Train: 100.00%, Valid: 80.00% Test: 76.47%\n",
      "Run: 08, Epoch: 39, Loss: 0.0890, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 40, Loss: 0.0950, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 41, Loss: 0.0746, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 42, Loss: 0.0855, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 43, Loss: 0.0625, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 44, Loss: 0.0921, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 45, Loss: 0.0565, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 46, Loss: 0.0701, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 47, Loss: 0.0694, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 48, Loss: 0.0527, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 49, Loss: 0.0515, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 50, Loss: 0.0367, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 51, Loss: 0.0353, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 52, Loss: 0.0635, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 53, Loss: 0.0415, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 54, Loss: 0.0597, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 55, Loss: 0.0889, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 56, Loss: 0.0366, Train: 100.00%, Valid: 82.50% Test: 74.51%\n",
      "Run: 08, Epoch: 57, Loss: 0.0358, Train: 100.00%, Valid: 82.50% Test: 74.51%\n",
      "Run: 08, Epoch: 58, Loss: 0.0499, Train: 100.00%, Valid: 82.50% Test: 74.51%\n",
      "Run: 08, Epoch: 59, Loss: 0.0383, Train: 100.00%, Valid: 82.50% Test: 74.51%\n",
      "Run: 08, Epoch: 60, Loss: 0.0464, Train: 100.00%, Valid: 82.50% Test: 76.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 61, Loss: 0.0219, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 62, Loss: 0.0335, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 63, Loss: 0.0375, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 64, Loss: 0.0566, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 65, Loss: 0.0179, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 66, Loss: 0.0585, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 67, Loss: 0.0218, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 68, Loss: 0.0348, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 69, Loss: 0.0812, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 70, Loss: 0.0349, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 71, Loss: 0.0348, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 72, Loss: 0.0430, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 73, Loss: 0.0238, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 74, Loss: 0.0201, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 75, Loss: 0.0415, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 76, Loss: 0.0425, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 77, Loss: 0.0380, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 78, Loss: 0.0333, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 79, Loss: 0.0384, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 80, Loss: 0.0184, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 81, Loss: 0.0238, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 82, Loss: 0.0319, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 83, Loss: 0.0587, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 84, Loss: 0.0259, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 85, Loss: 0.0459, Train: 100.00%, Valid: 80.00% Test: 76.47%\n",
      "Run: 08, Epoch: 86, Loss: 0.0453, Train: 100.00%, Valid: 80.00% Test: 76.47%\n",
      "Run: 08, Epoch: 87, Loss: 0.0386, Train: 100.00%, Valid: 80.00% Test: 76.47%\n",
      "Run: 08, Epoch: 88, Loss: 0.0261, Train: 100.00%, Valid: 80.00% Test: 76.47%\n",
      "Run: 08, Epoch: 89, Loss: 0.0212, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 90, Loss: 0.0369, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 91, Loss: 0.0201, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 92, Loss: 0.0363, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 93, Loss: 0.0292, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 94, Loss: 0.0187, Train: 100.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 08, Epoch: 95, Loss: 0.0180, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 96, Loss: 0.0174, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 97, Loss: 0.0543, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 98, Loss: 0.0489, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 99, Loss: 0.0303, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 100, Loss: 0.0338, Train: 100.00%, Valid: 82.50% Test: 76.47%\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 82.50\n",
      "  Final Train: 100.00\n",
      "   Final Test: 76.47\n",
      "Run: 09, Epoch: 01, Loss: 1.7009, Train: 83.33%, Valid: 65.00% Test: 66.67%\n",
      "Run: 09, Epoch: 02, Loss: 0.8290, Train: 86.67%, Valid: 63.75% Test: 66.67%\n",
      "Run: 09, Epoch: 03, Loss: 0.7251, Train: 89.17%, Valid: 65.00% Test: 64.71%\n",
      "Run: 09, Epoch: 04, Loss: 0.5988, Train: 88.33%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 05, Loss: 0.5374, Train: 88.33%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 06, Loss: 0.4213, Train: 88.33%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 07, Loss: 0.4976, Train: 89.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 08, Loss: 0.4025, Train: 89.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 09, Loss: 0.3606, Train: 92.50%, Valid: 67.50% Test: 66.67%\n",
      "Run: 09, Epoch: 10, Loss: 0.3299, Train: 96.67%, Valid: 66.25% Test: 66.67%\n",
      "Run: 09, Epoch: 11, Loss: 0.3305, Train: 96.67%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 12, Loss: 0.2575, Train: 97.50%, Valid: 65.00% Test: 64.71%\n",
      "Run: 09, Epoch: 13, Loss: 0.2482, Train: 97.50%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 14, Loss: 0.1966, Train: 97.50%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 15, Loss: 0.2262, Train: 98.33%, Valid: 66.25% Test: 68.63%\n",
      "Run: 09, Epoch: 16, Loss: 0.1985, Train: 99.17%, Valid: 66.25% Test: 70.59%\n",
      "Run: 09, Epoch: 17, Loss: 0.1778, Train: 99.17%, Valid: 66.25% Test: 70.59%\n",
      "Run: 09, Epoch: 18, Loss: 0.1738, Train: 100.00%, Valid: 66.25% Test: 70.59%\n",
      "Run: 09, Epoch: 19, Loss: 0.1406, Train: 100.00%, Valid: 66.25% Test: 70.59%\n",
      "Run: 09, Epoch: 20, Loss: 0.1368, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 09, Epoch: 21, Loss: 0.0921, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 09, Epoch: 22, Loss: 0.1106, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 09, Epoch: 23, Loss: 0.0754, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 09, Epoch: 24, Loss: 0.0945, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 09, Epoch: 25, Loss: 0.0541, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 09, Epoch: 26, Loss: 0.0696, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 09, Epoch: 27, Loss: 0.0514, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 09, Epoch: 28, Loss: 0.0718, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 09, Epoch: 29, Loss: 0.0696, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 09, Epoch: 30, Loss: 0.0411, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 31, Loss: 0.0854, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 09, Epoch: 32, Loss: 0.0768, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 09, Epoch: 33, Loss: 0.0536, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 09, Epoch: 34, Loss: 0.0512, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 09, Epoch: 35, Loss: 0.0433, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 09, Epoch: 36, Loss: 0.0225, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 37, Loss: 0.0255, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 38, Loss: 0.0503, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 39, Loss: 0.0503, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 40, Loss: 0.0419, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 41, Loss: 0.0312, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 42, Loss: 0.0440, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 43, Loss: 0.0406, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 09, Epoch: 44, Loss: 0.0386, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 09, Epoch: 45, Loss: 0.0596, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 09, Epoch: 46, Loss: 0.0147, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 09, Epoch: 47, Loss: 0.0352, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 09, Epoch: 48, Loss: 0.0321, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 09, Epoch: 49, Loss: 0.0140, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 50, Loss: 0.0225, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 51, Loss: 0.0228, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 52, Loss: 0.0240, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 53, Loss: 0.0312, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 54, Loss: 0.0097, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 55, Loss: 0.0236, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 56, Loss: 0.0139, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 57, Loss: 0.0211, Train: 100.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 09, Epoch: 58, Loss: 0.0101, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 09, Epoch: 59, Loss: 0.0298, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 09, Epoch: 60, Loss: 0.0069, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 09, Epoch: 61, Loss: 0.0326, Train: 100.00%, Valid: 71.25% Test: 76.47%\n",
      "Run: 09, Epoch: 62, Loss: 0.0106, Train: 100.00%, Valid: 71.25% Test: 76.47%\n",
      "Run: 09, Epoch: 63, Loss: 0.0392, Train: 100.00%, Valid: 71.25% Test: 76.47%\n",
      "Run: 09, Epoch: 64, Loss: 0.0090, Train: 100.00%, Valid: 71.25% Test: 76.47%\n",
      "Run: 09, Epoch: 65, Loss: 0.0414, Train: 100.00%, Valid: 71.25% Test: 76.47%\n",
      "Run: 09, Epoch: 66, Loss: 0.0152, Train: 100.00%, Valid: 71.25% Test: 76.47%\n",
      "Run: 09, Epoch: 67, Loss: 0.0225, Train: 100.00%, Valid: 71.25% Test: 76.47%\n",
      "Run: 09, Epoch: 68, Loss: 0.0120, Train: 100.00%, Valid: 70.00% Test: 76.47%\n",
      "Run: 09, Epoch: 69, Loss: 0.0125, Train: 100.00%, Valid: 70.00% Test: 76.47%\n",
      "Run: 09, Epoch: 70, Loss: 0.0261, Train: 100.00%, Valid: 70.00% Test: 76.47%\n",
      "Run: 09, Epoch: 71, Loss: 0.0259, Train: 100.00%, Valid: 70.00% Test: 76.47%\n",
      "Run: 09, Epoch: 72, Loss: 0.0147, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 73, Loss: 0.0243, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 74, Loss: 0.0300, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 75, Loss: 0.0075, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 76, Loss: 0.0157, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 77, Loss: 0.0153, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 78, Loss: 0.0265, Train: 100.00%, Valid: 67.50% Test: 76.47%\n",
      "Run: 09, Epoch: 79, Loss: 0.0247, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 80, Loss: 0.0086, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 81, Loss: 0.0233, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 82, Loss: 0.0210, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 83, Loss: 0.0169, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 84, Loss: 0.0040, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 85, Loss: 0.0225, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 86, Loss: 0.0148, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 87, Loss: 0.0095, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 88, Loss: 0.0070, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 89, Loss: 0.0177, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 90, Loss: 0.0215, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 91, Loss: 0.0140, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 92, Loss: 0.0090, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 93, Loss: 0.0041, Train: 100.00%, Valid: 68.75% Test: 76.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 94, Loss: 0.0181, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 95, Loss: 0.0180, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 96, Loss: 0.0122, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 97, Loss: 0.0066, Train: 100.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 09, Epoch: 98, Loss: 0.0058, Train: 100.00%, Valid: 70.00% Test: 76.47%\n",
      "Run: 09, Epoch: 99, Loss: 0.0169, Train: 100.00%, Valid: 68.75% Test: 74.51%\n",
      "Run: 09, Epoch: 100, Loss: 0.0070, Train: 100.00%, Valid: 68.75% Test: 74.51%\n",
      "Run 09:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 72.50\n",
      "  Final Train: 100.00\n",
      "   Final Test: 74.51\n",
      "Run: 10, Epoch: 01, Loss: 1.8049, Train: 66.67%, Valid: 57.50% Test: 52.94%\n",
      "Run: 10, Epoch: 02, Loss: 0.8613, Train: 78.33%, Valid: 62.50% Test: 60.78%\n",
      "Run: 10, Epoch: 03, Loss: 0.7309, Train: 84.17%, Valid: 66.25% Test: 64.71%\n",
      "Run: 10, Epoch: 04, Loss: 0.6518, Train: 85.00%, Valid: 65.00% Test: 72.55%\n",
      "Run: 10, Epoch: 05, Loss: 0.5694, Train: 85.00%, Valid: 65.00% Test: 70.59%\n",
      "Run: 10, Epoch: 06, Loss: 0.4787, Train: 85.00%, Valid: 65.00% Test: 70.59%\n",
      "Run: 10, Epoch: 07, Loss: 0.4736, Train: 86.67%, Valid: 63.75% Test: 72.55%\n",
      "Run: 10, Epoch: 08, Loss: 0.4347, Train: 87.50%, Valid: 65.00% Test: 72.55%\n",
      "Run: 10, Epoch: 09, Loss: 0.4089, Train: 88.33%, Valid: 68.75% Test: 72.55%\n",
      "Run: 10, Epoch: 10, Loss: 0.3595, Train: 90.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 10, Epoch: 11, Loss: 0.3176, Train: 91.67%, Valid: 70.00% Test: 72.55%\n",
      "Run: 10, Epoch: 12, Loss: 0.3097, Train: 94.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 10, Epoch: 13, Loss: 0.3302, Train: 95.00%, Valid: 70.00% Test: 74.51%\n",
      "Run: 10, Epoch: 14, Loss: 0.2251, Train: 97.50%, Valid: 70.00% Test: 74.51%\n",
      "Run: 10, Epoch: 15, Loss: 0.2247, Train: 97.50%, Valid: 71.25% Test: 76.47%\n",
      "Run: 10, Epoch: 16, Loss: 0.2399, Train: 98.33%, Valid: 72.50% Test: 76.47%\n",
      "Run: 10, Epoch: 17, Loss: 0.1878, Train: 98.33%, Valid: 71.25% Test: 76.47%\n",
      "Run: 10, Epoch: 18, Loss: 0.1855, Train: 99.17%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 19, Loss: 0.1823, Train: 99.17%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 20, Loss: 0.1725, Train: 99.17%, Valid: 73.75% Test: 72.55%\n",
      "Run: 10, Epoch: 21, Loss: 0.1652, Train: 100.00%, Valid: 73.75% Test: 74.51%\n",
      "Run: 10, Epoch: 22, Loss: 0.1456, Train: 100.00%, Valid: 73.75% Test: 74.51%\n",
      "Run: 10, Epoch: 23, Loss: 0.1322, Train: 100.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 10, Epoch: 24, Loss: 0.1072, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 25, Loss: 0.0993, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 26, Loss: 0.0989, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 10, Epoch: 27, Loss: 0.0875, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 10, Epoch: 28, Loss: 0.0594, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 10, Epoch: 29, Loss: 0.1045, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 10, Epoch: 30, Loss: 0.0940, Train: 100.00%, Valid: 72.50% Test: 76.47%\n",
      "Run: 10, Epoch: 31, Loss: 0.1065, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 32, Loss: 0.0543, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 33, Loss: 0.0597, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 34, Loss: 0.0433, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 35, Loss: 0.0430, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 36, Loss: 0.0548, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 37, Loss: 0.0477, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 38, Loss: 0.0208, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 39, Loss: 0.0361, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 40, Loss: 0.0341, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 41, Loss: 0.0523, Train: 100.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 42, Loss: 0.0410, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 43, Loss: 0.0445, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 44, Loss: 0.0310, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 45, Loss: 0.0553, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 46, Loss: 0.0332, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 47, Loss: 0.0390, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 48, Loss: 0.0404, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 49, Loss: 0.0307, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 50, Loss: 0.0383, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 51, Loss: 0.0450, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 10, Epoch: 52, Loss: 0.0334, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 10, Epoch: 53, Loss: 0.0226, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 10, Epoch: 54, Loss: 0.0253, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 10, Epoch: 55, Loss: 0.0206, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 10, Epoch: 56, Loss: 0.0208, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 10, Epoch: 57, Loss: 0.0321, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 10, Epoch: 58, Loss: 0.0180, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 59, Loss: 0.0160, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 60, Loss: 0.0207, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 61, Loss: 0.0117, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 62, Loss: 0.0352, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 63, Loss: 0.0196, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 64, Loss: 0.0170, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 65, Loss: 0.0164, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 66, Loss: 0.0238, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 67, Loss: 0.0214, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 68, Loss: 0.0406, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 69, Loss: 0.0143, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 70, Loss: 0.0322, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 71, Loss: 0.0607, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 72, Loss: 0.0141, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 73, Loss: 0.0116, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 74, Loss: 0.0133, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 75, Loss: 0.0188, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 76, Loss: 0.0209, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 77, Loss: 0.0314, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 78, Loss: 0.0314, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 79, Loss: 0.0392, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 80, Loss: 0.0111, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 81, Loss: 0.0393, Train: 100.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 10, Epoch: 82, Loss: 0.0145, Train: 100.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 10, Epoch: 83, Loss: 0.0159, Train: 100.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 10, Epoch: 84, Loss: 0.0354, Train: 100.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 10, Epoch: 85, Loss: 0.0389, Train: 100.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 10, Epoch: 86, Loss: 0.0127, Train: 100.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 10, Epoch: 87, Loss: 0.0430, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 88, Loss: 0.0153, Train: 100.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 10, Epoch: 89, Loss: 0.0115, Train: 100.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 10, Epoch: 90, Loss: 0.0134, Train: 100.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 10, Epoch: 91, Loss: 0.0195, Train: 100.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 10, Epoch: 92, Loss: 0.0177, Train: 100.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 10, Epoch: 93, Loss: 0.0185, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 10, Epoch: 94, Loss: 0.0272, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 95, Loss: 0.0137, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 96, Loss: 0.0193, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 97, Loss: 0.0404, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 98, Loss: 0.0255, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 99, Loss: 0.0021, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 100, Loss: 0.0157, Train: 100.00%, Valid: 75.00% Test: 68.63%\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 75.00\n",
      "  Final Train: 100.00\n",
      "   Final Test: 68.63\n",
      "All runs:\n",
      "Highest Train: 100.00 ± 0.00\n",
      "Highest Valid: 76.25 ± 3.33\n",
      "  Final Train: 96.92 ± 3.99\n",
      "   Final Test: 71.57 ± 5.25\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 32, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-6, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin',transform=T.ToSparseTensor())\n",
    "    data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    #idx_train=[data.train_mask[i][0] for i in range(len(data.y))]\n",
    "    #train_idx = np.where(idx_train)[0]\n",
    "    #idx_val=[data.val_mask[i][0] for i in range(len(data.y))]\n",
    "    #valid_idx = np.where(idx_val)[0]\n",
    "    #idx_test=[data.test_mask[i][0] for i in range(len(data.y))]\n",
    "    #test_idx = np.where(idx_test)[0]\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52f151",
   "metadata": {},
   "source": [
    "# WISE EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a09514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f82a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "      <th>1701</th>\n",
       "      <th>1702</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1704 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  1694  1695  1696  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "   1697  1698  1699  1700  1701  1702  class  \n",
       "0   0.0   0.0   0.0   0.0   1.0   0.0      1  \n",
       "1   0.0   0.0   0.0   0.0   1.0   0.0      2  \n",
       "2   0.0   0.0   0.0   0.0   1.0   0.0      2  \n",
       "3   0.0   0.0   0.0   0.0   1.0   0.0      2  \n",
       "4   0.0   0.0   0.0   0.0   1.0   0.0      1  \n",
       "\n",
       "[5 rows x 1704 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Domain_Fec=pd.DataFrame(data.x.numpy())\n",
    "label=pd.DataFrame(data.y.numpy(),columns =['class'])\n",
    "Data=pd.concat([Domain_Fec,label], axis=1)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2642b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_nodes=len(data.y)\n",
    "fe_len=len(data.x[0])\n",
    "catagories=Data['class'].to_numpy()\n",
    "data_by_class = {cls: Data.loc[Data['class'] == cls].drop(['class'], axis=1) for cls in range(max(catagories) + 1)}\n",
    "basis = [[max(df[i]) for i in range(len(df.columns))] for df in data_by_class.values()]\n",
    "sel_basis = [[int(list(df[i].to_numpy()).count(1) >= int(len(df[i].index)*0.1)) \n",
    "              for i in range(len(df.columns))]\n",
    "             for df in data_by_class.values()]\n",
    "feature_names = [ii for ii in range(fe_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12133154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It takes long time\n",
    "Fec=[]\n",
    "for i in range(23):\n",
    "    vec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=np.zeros(7)\n",
    "    for j in range(1433):\n",
    "        for i in range(max(catagories)+1):\n",
    "            if f[j]==1 and basis[i][j]==1:\n",
    "                count[i]=count[i]+1;\n",
    "\n",
    "    for i in range(max(catagories)+1):\n",
    "        vec.append(count[i])\n",
    "    f.clear()\n",
    "    Fec.append(vec)\n",
    "print(Fec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4db5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fec=[]\n",
    "for i in range(Number_nodes):\n",
    "    vec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=0\n",
    "    count1=0\n",
    "    count2=0\n",
    "    count3=0\n",
    "    count4=0\n",
    "    for j in range(fe_len):\n",
    "        if f[j]==1 and basis[0][j]==1:\n",
    "            count=count+1;\n",
    "        if f[j]==1 and basis[1][j]==1:\n",
    "            count1=count1+1;\n",
    "        if f[j]==1 and basis[2][j]==1:\n",
    "            count2=count2+1;\n",
    "        if f[j]==1 and basis[3][j]==1:\n",
    "            count3=count3+1;\n",
    "        if f[j]==1 and basis[4][j]==1:\n",
    "            count4=count4+1;\n",
    "    vec.append(count)\n",
    "    vec.append(count1)\n",
    "    vec.append(count2)\n",
    "    vec.append(count3)\n",
    "    vec.append(count4)\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    Fec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084212fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46, 72, 68, 59, 56], [39, 47, 49, 45, 45], [42, 48, 51, 49, 48], [27, 32, 33, 29, 27], [36, 64, 63, 58, 43], [81, 145, 129, 122, 103], [131, 242, 208, 176, 165], [35, 48, 48, 45, 37], [52, 69, 78, 67, 61], [85, 82, 83, 78, 72], [41, 43, 47, 45, 42], [52, 65, 70, 67, 60], [45, 53, 60, 55, 50], [50, 62, 74, 62, 58], [37, 42, 42, 42, 38], [50, 53, 63, 60, 56], [45, 47, 54, 45, 43], [36, 39, 41, 37, 34], [47, 61, 66, 66, 52], [22, 26, 26, 24, 22], [30, 48, 46, 39, 38], [79, 129, 115, 92, 88], [26, 30, 33, 28, 25], [44, 56, 67, 60, 56], [61, 97, 88, 76, 64], [82, 113, 116, 126, 99], [55, 94, 86, 83, 66], [81, 120, 126, 141, 120], [76, 142, 122, 112, 100], [46, 56, 69, 63, 59], [14, 14, 14, 14, 14], [75, 92, 108, 105, 92], [65, 72, 74, 65, 62], [28, 34, 36, 33, 28], [113, 205, 180, 177, 159], [138, 249, 220, 179, 168], [36, 74, 70, 68, 60], [83, 100, 114, 118, 98], [90, 152, 126, 112, 108], [36, 39, 41, 41, 38], [42, 49, 59, 44, 46], [55, 60, 67, 61, 57], [47, 84, 72, 69, 60], [42, 54, 70, 58, 48], [75, 93, 99, 104, 105], [37, 47, 48, 44, 37], [40, 67, 65, 67, 77], [83, 106, 109, 119, 105], [84, 144, 131, 114, 101], [22, 25, 25, 23, 23], [63, 71, 75, 79, 82], [95, 171, 177, 188, 202], [86, 133, 121, 107, 98], [26, 44, 39, 35, 26], [122, 200, 215, 239, 196], [48, 52, 61, 56, 47], [44, 46, 51, 48, 43], [43, 60, 63, 49, 48], [73, 105, 109, 121, 97], [33, 51, 48, 43, 42], [33, 51, 48, 43, 42], [38, 39, 42, 41, 37], [23, 25, 25, 24, 25], [63, 83, 91, 92, 94], [49, 59, 60, 57, 61], [35, 38, 42, 40, 40], [59, 76, 73, 60, 59], [190, 165, 176, 141, 137], [76, 95, 107, 96, 88], [50, 59, 70, 66, 61], [31, 37, 40, 35, 36], [74, 88, 101, 74, 80], [72, 97, 103, 90, 81], [66, 77, 94, 92, 82], [46, 67, 61, 53, 54], [111, 142, 152, 167, 143], [41, 49, 51, 46, 45], [96, 128, 157, 144, 131], [59, 100, 92, 89, 84], [39, 42, 44, 44, 44], [48, 69, 71, 65, 51], [20, 23, 23, 23, 19], [40, 66, 63, 57, 55], [32, 58, 49, 37, 33], [41, 63, 60, 55, 43], [36, 36, 40, 39, 36], [38, 41, 49, 42, 41], [42, 80, 68, 64, 52], [42, 44, 51, 44, 43], [58, 101, 96, 87, 76], [25, 25, 26, 24, 23], [58, 81, 78, 72, 69], [67, 87, 90, 85, 96], [103, 162, 169, 184, 167], [39, 41, 44, 40, 36], [46, 51, 66, 52, 48], [36, 44, 46, 43, 35], [81, 145, 129, 122, 103], [65, 87, 84, 76, 72], [37, 40, 41, 39, 38], [117, 105, 108, 100, 88], [34, 45, 45, 45, 40], [55, 64, 67, 70, 59], [19, 21, 22, 22, 20], [102, 137, 162, 136, 120], [48, 63, 79, 55, 64], [22, 23, 24, 24, 20], [121, 187, 203, 232, 187], [74, 118, 106, 98, 89], [73, 74, 87, 68, 68], [60, 94, 81, 74, 77], [71, 87, 101, 94, 84], [118, 233, 201, 185, 157], [67, 125, 111, 108, 94], [34, 32, 36, 34, 31], [81, 145, 129, 122, 103], [35, 67, 56, 44, 40], [62, 75, 81, 73, 63], [129, 165, 193, 212, 174], [41, 63, 68, 69, 78], [50, 63, 70, 67, 65], [87, 133, 141, 160, 135], [52, 58, 67, 63, 59], [39, 54, 58, 53, 45], [76, 91, 108, 101, 91], [48, 55, 61, 59, 57], [109, 165, 179, 199, 166], [176, 345, 297, 281, 248], [25, 39, 37, 38, 34], [47, 62, 73, 67, 67], [33, 51, 48, 43, 42], [100, 89, 91, 82, 78], [92, 114, 136, 109, 108], [78, 102, 121, 91, 82], [38, 41, 43, 39, 38], [35, 32, 35, 33, 32], [39, 48, 53, 37, 40], [72, 101, 110, 125, 101], [135, 114, 127, 110, 97], [48, 53, 55, 49, 43], [40, 42, 46, 44, 40], [13, 13, 14, 13, 13], [31, 36, 44, 32, 33], [136, 125, 119, 112, 101], [85, 114, 125, 134, 109], [68, 89, 97, 83, 72], [170, 267, 286, 341, 253], [177, 252, 249, 257, 304], [62, 109, 96, 80, 72], [40, 65, 57, 47, 41], [43, 80, 68, 60, 51], [31, 26, 28, 30, 31], [51, 71, 68, 64, 58], [61, 73, 81, 78, 71], [58, 71, 80, 71, 60], [59, 85, 94, 86, 78], [82, 125, 128, 126, 138], [61, 110, 116, 111, 131], [52, 95, 84, 77, 70], [31, 50, 50, 49, 57], [104, 137, 142, 168, 148], [140, 247, 247, 252, 296], [13, 13, 13, 13, 13], [44, 53, 58, 56, 51], [48, 58, 65, 64, 62], [45, 73, 75, 80, 90], [27, 30, 31, 30, 25], [49, 87, 77, 60, 55], [45, 63, 65, 59, 53], [86, 111, 129, 104, 96], [114, 174, 191, 171, 152], [56, 73, 80, 64, 56], [55, 57, 67, 60, 56], [142, 239, 258, 287, 222], [44, 49, 52, 49, 48], [76, 104, 103, 110, 95], [69, 99, 108, 114, 97], [113, 172, 203, 163, 155], [128, 203, 223, 245, 206], [72, 97, 106, 113, 103], [86, 110, 137, 123, 101], [17, 21, 21, 18, 20], [56, 82, 96, 86, 79], [71, 68, 68, 68, 66], [140, 217, 228, 236, 261], [44, 45, 49, 48, 46], [1, 1, 1, 1, 1], [164, 143, 153, 141, 133], [32, 47, 45, 43, 42], [97, 195, 162, 157, 140], [40, 45, 49, 45, 40], [175, 368, 305, 284, 266], [105, 153, 179, 189, 159], [52, 62, 68, 66, 59], [25, 26, 30, 25, 27], [86, 108, 129, 104, 98], [44, 57, 56, 46, 43], [50, 67, 67, 72, 65], [39, 46, 48, 47, 50], [58, 90, 84, 75, 65], [39, 66, 59, 49, 44], [106, 204, 178, 167, 144], [36, 47, 47, 41, 38], [42, 52, 56, 50, 46], [85, 132, 120, 106, 97], [51, 101, 88, 73, 65], [57, 100, 92, 84, 71], [27, 40, 38, 39, 34], [25, 44, 41, 41, 36], [82, 96, 120, 103, 92], [71, 95, 102, 109, 98], [40, 44, 47, 42, 40], [19, 21, 21, 21, 21], [54, 64, 75, 72, 62], [95, 177, 153, 140, 123], [44, 73, 61, 54, 51], [45, 55, 56, 49, 46], [201, 419, 348, 327, 294], [93, 140, 154, 179, 145], [68, 99, 109, 124, 99], [84, 101, 139, 98, 82], [46, 60, 62, 57, 52], [49, 85, 74, 61, 52], [55, 74, 79, 87, 72], [40, 74, 67, 62, 51], [106, 138, 161, 149, 142], [53, 64, 74, 71, 66], [58, 68, 79, 67, 65], [18, 25, 25, 25, 23], [84, 108, 115, 91, 90], [61, 68, 73, 66, 63], [83, 130, 124, 122, 146], [68, 76, 80, 75, 68], [42, 74, 61, 54, 50], [52, 55, 58, 55, 51], [58, 72, 88, 67, 57], [23, 24, 25, 23, 24], [47, 53, 56, 50, 49], [75, 90, 112, 107, 99], [27, 31, 34, 30, 29], [100, 165, 164, 195, 155], [35, 37, 46, 39, 35], [45, 71, 67, 58, 55], [131, 237, 207, 176, 163], [62, 74, 71, 61, 75], [32, 51, 48, 46, 35], [17, 19, 21, 21, 16], [22, 28, 28, 27, 27], [22, 29, 34, 30, 29], [53, 86, 77, 64, 60], [50, 72, 86, 62, 62]]\n"
     ]
    }
   ],
   "source": [
    "print(Fec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a920e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFec=[]\n",
    "for i in range(Number_nodes):\n",
    "    Svec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=0\n",
    "    count1=0\n",
    "    count2=0\n",
    "    count3=0\n",
    "    count4=0\n",
    "    for j in range(fe_len):\n",
    "        if f[j]==1 and sel_basis[0][j]==1:\n",
    "            count=count+1;\n",
    "        if f[j]==1 and sel_basis[1][j]==1:\n",
    "            count1=count1+1;\n",
    "        if f[j]==1 and sel_basis[2][j]==1:\n",
    "            count2=count2+1;\n",
    "        if f[j]==1 and sel_basis[3][j]==1:\n",
    "            count3=count3+1;\n",
    "        if f[j]==1 and sel_basis[4][j]==1:\n",
    "            count4=count4+1;\n",
    "    Svec.append(count)\n",
    "    Svec.append(count1)\n",
    "    Svec.append(count2)\n",
    "    Svec.append(count3)\n",
    "    Svec.append(count4)\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    SFec.append(Svec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3715b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46, 63, 40, 52, 44], [39, 38, 40, 44, 38], [42, 34, 40, 43, 42], [27, 27, 27, 26, 24], [36, 54, 36, 43, 35], [81, 105, 54, 81, 78], [131, 174, 63, 104, 115], [35, 35, 27, 36, 32], [52, 49, 48, 54, 49], [85, 55, 43, 60, 59], [41, 35, 39, 41, 39], [52, 42, 47, 59, 52], [45, 32, 39, 46, 41], [50, 43, 41, 55, 45], [37, 33, 37, 39, 35], [50, 40, 47, 56, 46], [45, 35, 37, 32, 37], [36, 30, 36, 32, 29], [47, 42, 41, 52, 43], [22, 21, 22, 21, 22], [30, 38, 25, 32, 30], [79, 103, 44, 66, 62], [26, 25, 28, 23, 22], [44, 37, 37, 56, 49], [61, 86, 38, 52, 45], [82, 68, 50, 97, 75], [55, 78, 39, 56, 53], [81, 53, 47, 118, 95], [76, 113, 45, 76, 70], [46, 40, 47, 61, 48], [14, 14, 14, 14, 14], [75, 56, 58, 93, 78], [65, 49, 49, 52, 51], [28, 29, 31, 28, 27], [113, 121, 58, 126, 123], [138, 182, 64, 105, 118], [36, 55, 31, 47, 44], [83, 56, 56, 105, 85], [90, 116, 43, 76, 82], [36, 34, 34, 37, 32], [42, 34, 36, 31, 35], [55, 43, 53, 55, 50], [47, 69, 40, 52, 47], [42, 32, 32, 42, 41], [75, 60, 45, 90, 95], [37, 44, 35, 35, 31], [40, 35, 23, 51, 70], [83, 55, 52, 104, 83], [84, 91, 48, 83, 72], [22, 22, 23, 21, 22], [63, 50, 49, 67, 71], [95, 77, 58, 147, 154], [86, 98, 52, 76, 71], [26, 39, 27, 28, 23], [122, 89, 64, 183, 152], [48, 36, 50, 45, 37], [44, 36, 39, 37, 35], [43, 47, 40, 38, 38], [73, 57, 47, 106, 76], [33, 44, 20, 29, 30], [33, 44, 20, 29, 30], [38, 31, 38, 40, 34], [23, 24, 23, 24, 25], [63, 52, 36, 71, 79], [49, 42, 33, 51, 56], [35, 28, 37, 38, 33], [59, 52, 30, 45, 47], [190, 85, 57, 95, 103], [76, 64, 58, 74, 72], [50, 42, 50, 57, 49], [31, 29, 30, 32, 30], [74, 49, 39, 48, 60], [72, 60, 53, 78, 69], [66, 49, 57, 81, 70], [46, 62, 35, 41, 43], [111, 71, 61, 145, 118], [41, 36, 41, 43, 40], [96, 64, 64, 119, 105], [59, 60, 40, 67, 70], [39, 37, 33, 38, 44], [48, 49, 46, 51, 43], [20, 22, 21, 20, 19], [40, 54, 31, 44, 43], [32, 57, 26, 29, 25], [41, 49, 34, 37, 28], [36, 27, 32, 37, 34], [38, 34, 40, 37, 34], [42, 62, 35, 43, 39], [42, 34, 38, 39, 40], [58, 80, 42, 64, 54], [25, 24, 24, 22, 23], [58, 60, 37, 58, 55], [67, 53, 45, 70, 84], [103, 85, 65, 148, 130], [39, 31, 38, 33, 31], [46, 38, 43, 41, 44], [36, 39, 40, 36, 30], [81, 105, 54, 81, 78], [65, 47, 45, 57, 56], [37, 34, 38, 38, 35], [117, 56, 41, 74, 67], [34, 41, 37, 41, 36], [55, 45, 48, 59, 46], [19, 19, 20, 19, 20], [102, 75, 74, 104, 95], [48, 38, 31, 39, 43], [22, 23, 24, 22, 20], [121, 83, 61, 198, 151], [74, 87, 39, 67, 67], [73, 52, 57, 56, 53], [60, 72, 38, 56, 58], [71, 50, 50, 84, 74], [118, 135, 60, 117, 111], [67, 91, 37, 73, 64], [34, 26, 30, 29, 28], [81, 105, 54, 81, 78], [35, 64, 29, 33, 28], [62, 52, 49, 51, 52], [129, 81, 70, 175, 137], [41, 27, 21, 50, 66], [50, 45, 45, 57, 61], [87, 68, 60, 130, 109], [52, 38, 48, 56, 46], [39, 42, 45, 49, 41], [76, 51, 66, 94, 74], [48, 42, 42, 54, 49], [109, 77, 74, 168, 122], [176, 166, 73, 175, 180], [25, 35, 26, 36, 29], [47, 42, 46, 56, 57], [33, 44, 20, 29, 30], [100, 54, 43, 64, 61], [92, 67, 64, 88, 88], [78, 58, 53, 64, 64], [38, 34, 41, 38, 35], [35, 29, 32, 33, 30], [39, 29, 27, 27, 32], [72, 54, 50, 115, 82], [135, 68, 52, 73, 78], [48, 43, 46, 43, 40], [40, 35, 38, 42, 37], [13, 13, 13, 13, 13], [31, 25, 20, 24, 24], [136, 76, 52, 81, 81], [85, 69, 65, 114, 90], [68, 60, 61, 64, 55], [170, 111, 84, 254, 191], [177, 115, 63, 168, 230], [62, 97, 42, 60, 52], [40, 61, 32, 37, 31], [43, 73, 33, 46, 40], [31, 23, 23, 28, 25], [51, 60, 37, 51, 49], [61, 47, 53, 70, 66], [58, 51, 50, 57, 48], [59, 60, 52, 71, 62], [82, 62, 45, 97, 126], [61, 52, 42, 82, 104], [52, 69, 39, 60, 51], [31, 28, 21, 36, 49], [104, 70, 60, 138, 118], [140, 104, 74, 177, 226], [13, 11, 12, 12, 12], [44, 38, 45, 46, 43], [48, 38, 38, 63, 56], [45, 34, 19, 50, 80], [27, 28, 26, 27, 24], [49, 81, 38, 44, 45], [45, 53, 48, 50, 44], [86, 64, 71, 79, 72], [114, 102, 70, 119, 120], [56, 54, 41, 52, 48], [55, 41, 45, 51, 48], [142, 116, 88, 234, 171], [44, 39, 47, 46, 41], [76, 62, 46, 88, 78], [69, 61, 50, 93, 75], [113, 88, 68, 106, 114], [128, 101, 78, 221, 163], [72, 63, 59, 108, 84], [86, 65, 64, 94, 84], [17, 20, 18, 16, 17], [56, 46, 55, 74, 60], [71, 44, 45, 54, 58], [140, 100, 68, 172, 223], [44, 37, 41, 45, 42], [1, 1, 1, 1, 1], [164, 76, 61, 102, 102], [32, 40, 30, 41, 39], [97, 104, 46, 102, 93], [40, 40, 45, 39, 35], [175, 195, 76, 173, 181], [105, 84, 67, 177, 119], [52, 45, 52, 53, 50], [25, 22, 23, 23, 22], [86, 60, 46, 73, 72], [44, 47, 31, 32, 35], [50, 33, 34, 66, 58], [39, 28, 23, 39, 45], [58, 79, 43, 55, 51], [39, 59, 34, 40, 35], [106, 133, 59, 110, 101], [36, 43, 36, 37, 31], [42, 39, 41, 39, 42], [85, 97, 51, 75, 70], [51, 80, 37, 52, 46], [57, 73, 42, 67, 55], [27, 34, 27, 38, 32], [25, 34, 27, 38, 30], [82, 62, 61, 88, 72], [71, 57, 55, 100, 84], [40, 35, 35, 33, 36], [19, 17, 18, 18, 21], [54, 42, 45, 63, 53], [95, 109, 44, 88, 84], [44, 70, 35, 45, 37], [45, 44, 48, 46, 40], [201, 207, 84, 195, 193], [93, 72, 55, 145, 110], [68, 53, 47, 108, 77], [84, 61, 54, 58, 58], [46, 40, 39, 49, 41], [49, 75, 39, 48, 40], [55, 46, 46, 75, 61], [40, 65, 37, 46, 40], [106, 71, 65, 128, 118], [53, 41, 50, 69, 55], [58, 46, 55, 54, 54], [18, 21, 16, 22, 21], [84, 66, 54, 63, 70], [61, 46, 49, 55, 53], [83, 76, 48, 94, 128], [68, 48, 55, 65, 58], [42, 65, 25, 38, 39], [52, 43, 44, 46, 43], [58, 50, 46, 44, 42], [23, 21, 22, 21, 21], [47, 43, 40, 41, 43], [75, 53, 60, 94, 85], [27, 24, 26, 25, 27], [100, 73, 64, 148, 111], [35, 31, 29, 31, 30], [45, 62, 39, 51, 43], [131, 176, 63, 103, 115], [62, 42, 34, 47, 59], [32, 46, 33, 35, 30], [17, 16, 17, 17, 15], [22, 24, 26, 25, 25], [22, 22, 22, 26, 27], [53, 77, 37, 49, 44], [50, 41, 35, 39, 45]]\n"
     ]
    }
   ],
   "source": [
    "print(SFec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "054ee569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[46., 72., 68.,  ..., 40., 52., 44.],\n",
      "        [39., 47., 49.,  ..., 40., 44., 38.],\n",
      "        [42., 48., 51.,  ..., 40., 43., 42.],\n",
      "        ...,\n",
      "        [22., 29., 34.,  ..., 22., 26., 27.],\n",
      "        [53., 86., 77.,  ..., 37., 49., 44.],\n",
      "        [50., 72., 86.,  ..., 35., 39., 45.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inc_fe=torch.tensor(Fec)\n",
    "sel_fe=torch.tensor(SFec)\n",
    "CC_domain=torch.cat((Inc_fe, sel_fe), 1).float()\n",
    "print(CC_domain)\n",
    "CC_domain.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f7d51",
   "metadata": {},
   "source": [
    "# W-SAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55c6fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 10], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4763ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x177466a40>\n",
      "Run: 01, Epoch: 01, Loss: 1.9758, Train: 31.67%, Valid: 25.00% Test: 23.53%\n",
      "Run: 01, Epoch: 02, Loss: 1.6533, Train: 34.17%, Valid: 25.00% Test: 21.57%\n",
      "Run: 01, Epoch: 03, Loss: 1.4110, Train: 41.67%, Valid: 42.50% Test: 35.29%\n",
      "Run: 01, Epoch: 04, Loss: 1.2888, Train: 51.67%, Valid: 57.50% Test: 62.75%\n",
      "Run: 01, Epoch: 05, Loss: 1.2015, Train: 48.33%, Valid: 55.00% Test: 62.75%\n",
      "Run: 01, Epoch: 06, Loss: 1.1371, Train: 49.17%, Valid: 53.75% Test: 60.78%\n",
      "Run: 01, Epoch: 07, Loss: 1.0975, Train: 50.83%, Valid: 53.75% Test: 58.82%\n",
      "Run: 01, Epoch: 08, Loss: 1.0935, Train: 51.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 01, Epoch: 09, Loss: 1.0101, Train: 58.33%, Valid: 57.50% Test: 64.71%\n",
      "Run: 01, Epoch: 10, Loss: 0.9803, Train: 65.83%, Valid: 66.25% Test: 68.63%\n",
      "Run: 01, Epoch: 11, Loss: 0.9253, Train: 75.83%, Valid: 70.00% Test: 72.55%\n",
      "Run: 01, Epoch: 12, Loss: 0.8705, Train: 77.50%, Valid: 75.00% Test: 76.47%\n",
      "Run: 01, Epoch: 13, Loss: 0.8772, Train: 69.17%, Valid: 72.50% Test: 68.63%\n",
      "Run: 01, Epoch: 14, Loss: 0.8956, Train: 70.83%, Valid: 71.25% Test: 66.67%\n",
      "Run: 01, Epoch: 15, Loss: 0.8717, Train: 74.17%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 16, Loss: 0.8703, Train: 73.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 17, Loss: 0.7673, Train: 74.17%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 18, Loss: 0.7353, Train: 76.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 19, Loss: 0.7297, Train: 74.17%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 20, Loss: 0.6981, Train: 70.83%, Valid: 70.00% Test: 68.63%\n",
      "Run: 01, Epoch: 21, Loss: 0.7102, Train: 71.67%, Valid: 70.00% Test: 66.67%\n",
      "Run: 01, Epoch: 22, Loss: 0.6545, Train: 71.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 23, Loss: 0.6115, Train: 71.67%, Valid: 72.50% Test: 68.63%\n",
      "Run: 01, Epoch: 24, Loss: 0.6004, Train: 71.67%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 25, Loss: 0.5623, Train: 74.17%, Valid: 73.75% Test: 72.55%\n",
      "Run: 01, Epoch: 26, Loss: 0.5238, Train: 75.83%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 27, Loss: 0.5304, Train: 77.50%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 28, Loss: 0.5749, Train: 80.00%, Valid: 75.00% Test: 74.51%\n",
      "Run: 01, Epoch: 29, Loss: 0.5610, Train: 79.17%, Valid: 75.00% Test: 76.47%\n",
      "Run: 01, Epoch: 30, Loss: 0.4939, Train: 77.50%, Valid: 76.25% Test: 76.47%\n",
      "Run: 01, Epoch: 31, Loss: 0.4536, Train: 77.50%, Valid: 76.25% Test: 76.47%\n",
      "Run: 01, Epoch: 32, Loss: 0.5130, Train: 76.67%, Valid: 75.00% Test: 76.47%\n",
      "Run: 01, Epoch: 33, Loss: 0.5011, Train: 77.50%, Valid: 75.00% Test: 76.47%\n",
      "Run: 01, Epoch: 34, Loss: 0.4802, Train: 79.17%, Valid: 76.25% Test: 78.43%\n",
      "Run: 01, Epoch: 35, Loss: 0.5197, Train: 81.67%, Valid: 76.25% Test: 78.43%\n",
      "Run: 01, Epoch: 36, Loss: 0.4344, Train: 82.50%, Valid: 76.25% Test: 80.39%\n",
      "Run: 01, Epoch: 37, Loss: 0.4246, Train: 83.33%, Valid: 77.50% Test: 78.43%\n",
      "Run: 01, Epoch: 38, Loss: 0.4133, Train: 84.17%, Valid: 77.50% Test: 80.39%\n",
      "Run: 01, Epoch: 39, Loss: 0.4656, Train: 85.00%, Valid: 77.50% Test: 82.35%\n",
      "Run: 01, Epoch: 40, Loss: 0.4104, Train: 85.83%, Valid: 77.50% Test: 82.35%\n",
      "Run: 01, Epoch: 41, Loss: 0.3549, Train: 85.00%, Valid: 77.50% Test: 82.35%\n",
      "Run: 01, Epoch: 42, Loss: 0.3982, Train: 85.00%, Valid: 77.50% Test: 82.35%\n",
      "Run: 01, Epoch: 43, Loss: 0.3663, Train: 86.67%, Valid: 77.50% Test: 82.35%\n",
      "Run: 01, Epoch: 44, Loss: 0.3424, Train: 87.50%, Valid: 80.00% Test: 82.35%\n",
      "Run: 01, Epoch: 45, Loss: 0.2644, Train: 88.33%, Valid: 82.50% Test: 82.35%\n",
      "Run: 01, Epoch: 46, Loss: 0.3373, Train: 89.17%, Valid: 83.75% Test: 84.31%\n",
      "Run: 01, Epoch: 47, Loss: 0.3187, Train: 91.67%, Valid: 86.25% Test: 84.31%\n",
      "Run: 01, Epoch: 48, Loss: 0.3396, Train: 90.00%, Valid: 86.25% Test: 86.27%\n",
      "Run: 01, Epoch: 49, Loss: 0.2781, Train: 90.83%, Valid: 85.00% Test: 86.27%\n",
      "Run: 01, Epoch: 50, Loss: 0.3531, Train: 91.67%, Valid: 86.25% Test: 84.31%\n",
      "Run: 01, Epoch: 51, Loss: 0.3439, Train: 92.50%, Valid: 87.50% Test: 86.27%\n",
      "Run: 01, Epoch: 52, Loss: 0.3075, Train: 94.17%, Valid: 86.25% Test: 84.31%\n",
      "Run: 01, Epoch: 53, Loss: 0.2820, Train: 95.00%, Valid: 87.50% Test: 84.31%\n",
      "Run: 01, Epoch: 54, Loss: 0.1928, Train: 93.33%, Valid: 85.00% Test: 82.35%\n",
      "Run: 01, Epoch: 55, Loss: 0.2428, Train: 92.50%, Valid: 81.25% Test: 84.31%\n",
      "Run: 01, Epoch: 56, Loss: 0.2931, Train: 90.83%, Valid: 81.25% Test: 84.31%\n",
      "Run: 01, Epoch: 57, Loss: 0.2735, Train: 88.33%, Valid: 80.00% Test: 86.27%\n",
      "Run: 01, Epoch: 58, Loss: 0.1756, Train: 87.50%, Valid: 80.00% Test: 86.27%\n",
      "Run: 01, Epoch: 59, Loss: 0.2665, Train: 90.83%, Valid: 83.75% Test: 84.31%\n",
      "Run: 01, Epoch: 60, Loss: 0.2871, Train: 92.50%, Valid: 85.00% Test: 86.27%\n",
      "Run: 01, Epoch: 61, Loss: 0.2524, Train: 95.83%, Valid: 87.50% Test: 84.31%\n",
      "Run: 01, Epoch: 62, Loss: 0.2178, Train: 95.00%, Valid: 88.75% Test: 84.31%\n",
      "Run: 01, Epoch: 63, Loss: 0.3170, Train: 95.00%, Valid: 87.50% Test: 84.31%\n",
      "Run: 01, Epoch: 64, Loss: 0.2077, Train: 95.00%, Valid: 87.50% Test: 84.31%\n",
      "Run: 01, Epoch: 65, Loss: 0.1725, Train: 95.00%, Valid: 86.25% Test: 84.31%\n",
      "Run: 01, Epoch: 66, Loss: 0.2457, Train: 96.67%, Valid: 86.25% Test: 84.31%\n",
      "Run: 01, Epoch: 67, Loss: 0.2095, Train: 95.00%, Valid: 86.25% Test: 82.35%\n",
      "Run: 01, Epoch: 68, Loss: 0.1890, Train: 95.00%, Valid: 86.25% Test: 82.35%\n",
      "Run: 01, Epoch: 69, Loss: 0.2110, Train: 95.83%, Valid: 86.25% Test: 82.35%\n",
      "Run: 01, Epoch: 70, Loss: 0.2148, Train: 96.67%, Valid: 87.50% Test: 82.35%\n",
      "Run: 01, Epoch: 71, Loss: 0.2522, Train: 97.50%, Valid: 88.75% Test: 84.31%\n",
      "Run: 01, Epoch: 72, Loss: 0.2199, Train: 97.50%, Valid: 90.00% Test: 86.27%\n",
      "Run: 01, Epoch: 73, Loss: 0.1572, Train: 96.67%, Valid: 90.00% Test: 88.24%\n",
      "Run: 01, Epoch: 74, Loss: 0.1677, Train: 95.83%, Valid: 88.75% Test: 86.27%\n",
      "Run: 01, Epoch: 75, Loss: 0.2056, Train: 94.17%, Valid: 87.50% Test: 84.31%\n",
      "Run: 01, Epoch: 76, Loss: 0.1721, Train: 96.67%, Valid: 90.00% Test: 86.27%\n",
      "Run: 01, Epoch: 77, Loss: 0.2613, Train: 96.67%, Valid: 90.00% Test: 86.27%\n",
      "Run: 01, Epoch: 78, Loss: 0.1573, Train: 96.67%, Valid: 90.00% Test: 86.27%\n",
      "Run: 01, Epoch: 79, Loss: 0.2223, Train: 97.50%, Valid: 91.25% Test: 80.39%\n",
      "Run: 01, Epoch: 80, Loss: 0.1843, Train: 97.50%, Valid: 92.50% Test: 80.39%\n",
      "Run: 01, Epoch: 81, Loss: 0.1657, Train: 97.50%, Valid: 92.50% Test: 82.35%\n",
      "Run: 01, Epoch: 82, Loss: 0.1906, Train: 97.50%, Valid: 91.25% Test: 78.43%\n",
      "Run: 01, Epoch: 83, Loss: 0.1717, Train: 98.33%, Valid: 91.25% Test: 78.43%\n",
      "Run: 01, Epoch: 84, Loss: 0.1976, Train: 96.67%, Valid: 91.25% Test: 76.47%\n",
      "Run: 01, Epoch: 85, Loss: 0.1630, Train: 98.33%, Valid: 93.75% Test: 80.39%\n",
      "Run: 01, Epoch: 86, Loss: 0.2078, Train: 97.50%, Valid: 93.75% Test: 84.31%\n",
      "Run: 01, Epoch: 87, Loss: 0.1488, Train: 97.50%, Valid: 92.50% Test: 86.27%\n",
      "Run: 01, Epoch: 88, Loss: 0.1940, Train: 97.50%, Valid: 90.00% Test: 86.27%\n",
      "Run: 01, Epoch: 89, Loss: 0.1699, Train: 97.50%, Valid: 91.25% Test: 86.27%\n",
      "Run: 01, Epoch: 90, Loss: 0.1770, Train: 97.50%, Valid: 91.25% Test: 86.27%\n",
      "Run: 01, Epoch: 91, Loss: 0.1920, Train: 97.50%, Valid: 92.50% Test: 86.27%\n",
      "Run: 01, Epoch: 92, Loss: 0.1519, Train: 97.50%, Valid: 92.50% Test: 86.27%\n",
      "Run: 01, Epoch: 93, Loss: 0.2009, Train: 97.50%, Valid: 92.50% Test: 84.31%\n",
      "Run: 01, Epoch: 94, Loss: 0.2323, Train: 96.67%, Valid: 90.00% Test: 86.27%\n",
      "Run: 01, Epoch: 95, Loss: 0.2073, Train: 95.83%, Valid: 86.25% Test: 86.27%\n",
      "Run: 01, Epoch: 96, Loss: 0.1080, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 01, Epoch: 97, Loss: 0.1996, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 01, Epoch: 98, Loss: 0.1979, Train: 95.83%, Valid: 85.00% Test: 88.24%\n",
      "Run: 01, Epoch: 99, Loss: 0.1263, Train: 96.67%, Valid: 87.50% Test: 88.24%\n",
      "Run: 01, Epoch: 100, Loss: 0.2060, Train: 97.50%, Valid: 88.75% Test: 88.24%\n",
      "Run 01:\n",
      "Highest Train: 98.33\n",
      "Highest Valid: 93.75\n",
      "  Final Train: 98.33\n",
      "   Final Test: 80.39\n",
      "Run: 02, Epoch: 01, Loss: 1.7685, Train: 32.50%, Valid: 32.50% Test: 21.57%\n",
      "Run: 02, Epoch: 02, Loss: 1.5438, Train: 54.17%, Valid: 46.25% Test: 66.67%\n",
      "Run: 02, Epoch: 03, Loss: 1.3999, Train: 55.00%, Valid: 46.25% Test: 70.59%\n",
      "Run: 02, Epoch: 04, Loss: 1.2839, Train: 56.67%, Valid: 46.25% Test: 68.63%\n",
      "Run: 02, Epoch: 05, Loss: 1.1816, Train: 56.67%, Valid: 48.75% Test: 72.55%\n",
      "Run: 02, Epoch: 06, Loss: 1.1197, Train: 63.33%, Valid: 56.25% Test: 74.51%\n",
      "Run: 02, Epoch: 07, Loss: 1.1038, Train: 63.33%, Valid: 52.50% Test: 72.55%\n",
      "Run: 02, Epoch: 08, Loss: 1.0997, Train: 62.50%, Valid: 53.75% Test: 70.59%\n",
      "Run: 02, Epoch: 09, Loss: 1.0195, Train: 63.33%, Valid: 51.25% Test: 70.59%\n",
      "Run: 02, Epoch: 10, Loss: 1.0220, Train: 63.33%, Valid: 53.75% Test: 68.63%\n",
      "Run: 02, Epoch: 11, Loss: 0.9667, Train: 63.33%, Valid: 52.50% Test: 70.59%\n",
      "Run: 02, Epoch: 12, Loss: 0.9608, Train: 64.17%, Valid: 52.50% Test: 70.59%\n",
      "Run: 02, Epoch: 13, Loss: 0.9067, Train: 58.33%, Valid: 53.75% Test: 62.75%\n",
      "Run: 02, Epoch: 14, Loss: 0.8583, Train: 61.67%, Valid: 57.50% Test: 62.75%\n",
      "Run: 02, Epoch: 15, Loss: 0.8590, Train: 66.67%, Valid: 60.00% Test: 72.55%\n",
      "Run: 02, Epoch: 16, Loss: 0.8991, Train: 71.67%, Valid: 65.00% Test: 82.35%\n",
      "Run: 02, Epoch: 17, Loss: 0.7549, Train: 77.50%, Valid: 63.75% Test: 86.27%\n",
      "Run: 02, Epoch: 18, Loss: 0.7806, Train: 76.67%, Valid: 62.50% Test: 86.27%\n",
      "Run: 02, Epoch: 19, Loss: 0.7739, Train: 76.67%, Valid: 62.50% Test: 88.24%\n",
      "Run: 02, Epoch: 20, Loss: 0.6575, Train: 78.33%, Valid: 65.00% Test: 86.27%\n",
      "Run: 02, Epoch: 21, Loss: 0.6566, Train: 80.00%, Valid: 65.00% Test: 90.20%\n",
      "Run: 02, Epoch: 22, Loss: 0.6399, Train: 80.00%, Valid: 68.75% Test: 90.20%\n",
      "Run: 02, Epoch: 23, Loss: 0.6302, Train: 80.00%, Valid: 72.50% Test: 88.24%\n",
      "Run: 02, Epoch: 24, Loss: 0.6358, Train: 80.83%, Valid: 72.50% Test: 88.24%\n",
      "Run: 02, Epoch: 25, Loss: 0.6171, Train: 79.17%, Valid: 71.25% Test: 88.24%\n",
      "Run: 02, Epoch: 26, Loss: 0.5447, Train: 78.33%, Valid: 70.00% Test: 88.24%\n",
      "Run: 02, Epoch: 27, Loss: 0.5900, Train: 77.50%, Valid: 67.50% Test: 88.24%\n",
      "Run: 02, Epoch: 28, Loss: 0.6099, Train: 78.33%, Valid: 67.50% Test: 88.24%\n",
      "Run: 02, Epoch: 29, Loss: 0.6295, Train: 78.33%, Valid: 65.00% Test: 88.24%\n",
      "Run: 02, Epoch: 30, Loss: 0.5207, Train: 76.67%, Valid: 62.50% Test: 88.24%\n",
      "Run: 02, Epoch: 31, Loss: 0.4712, Train: 76.67%, Valid: 62.50% Test: 88.24%\n",
      "Run: 02, Epoch: 32, Loss: 0.5472, Train: 76.67%, Valid: 62.50% Test: 88.24%\n",
      "Run: 02, Epoch: 33, Loss: 0.4672, Train: 77.50%, Valid: 66.25% Test: 88.24%\n",
      "Run: 02, Epoch: 34, Loss: 0.5151, Train: 75.83%, Valid: 66.25% Test: 88.24%\n",
      "Run: 02, Epoch: 35, Loss: 0.4800, Train: 79.17%, Valid: 66.25% Test: 88.24%\n",
      "Run: 02, Epoch: 36, Loss: 0.5196, Train: 80.83%, Valid: 68.75% Test: 88.24%\n",
      "Run: 02, Epoch: 37, Loss: 0.4406, Train: 80.83%, Valid: 68.75% Test: 88.24%\n",
      "Run: 02, Epoch: 38, Loss: 0.4177, Train: 81.67%, Valid: 68.75% Test: 88.24%\n",
      "Run: 02, Epoch: 39, Loss: 0.4305, Train: 82.50%, Valid: 75.00% Test: 90.20%\n",
      "Run: 02, Epoch: 40, Loss: 0.4188, Train: 83.33%, Valid: 73.75% Test: 90.20%\n",
      "Run: 02, Epoch: 41, Loss: 0.3670, Train: 82.50%, Valid: 73.75% Test: 86.27%\n",
      "Run: 02, Epoch: 42, Loss: 0.3858, Train: 77.50%, Valid: 70.00% Test: 86.27%\n",
      "Run: 02, Epoch: 43, Loss: 0.3691, Train: 72.50%, Valid: 70.00% Test: 86.27%\n",
      "Run: 02, Epoch: 44, Loss: 0.3324, Train: 73.33%, Valid: 68.75% Test: 84.31%\n",
      "Run: 02, Epoch: 45, Loss: 0.3589, Train: 73.33%, Valid: 66.25% Test: 84.31%\n",
      "Run: 02, Epoch: 46, Loss: 0.3416, Train: 75.00%, Valid: 65.00% Test: 84.31%\n",
      "Run: 02, Epoch: 47, Loss: 0.3136, Train: 76.67%, Valid: 65.00% Test: 88.24%\n",
      "Run: 02, Epoch: 48, Loss: 0.3295, Train: 80.83%, Valid: 68.75% Test: 88.24%\n",
      "Run: 02, Epoch: 49, Loss: 0.3127, Train: 80.83%, Valid: 68.75% Test: 88.24%\n",
      "Run: 02, Epoch: 50, Loss: 0.3460, Train: 83.33%, Valid: 71.25% Test: 88.24%\n",
      "Run: 02, Epoch: 51, Loss: 0.3162, Train: 85.00%, Valid: 71.25% Test: 90.20%\n",
      "Run: 02, Epoch: 52, Loss: 0.3043, Train: 87.50%, Valid: 73.75% Test: 90.20%\n",
      "Run: 02, Epoch: 53, Loss: 0.2312, Train: 87.50%, Valid: 77.50% Test: 90.20%\n",
      "Run: 02, Epoch: 54, Loss: 0.2750, Train: 90.00%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 55, Loss: 0.2650, Train: 91.67%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 56, Loss: 0.2719, Train: 91.67%, Valid: 81.25% Test: 90.20%\n",
      "Run: 02, Epoch: 57, Loss: 0.2654, Train: 90.83%, Valid: 82.50% Test: 90.20%\n",
      "Run: 02, Epoch: 58, Loss: 0.2688, Train: 89.17%, Valid: 81.25% Test: 88.24%\n",
      "Run: 02, Epoch: 59, Loss: 0.3255, Train: 88.33%, Valid: 76.25% Test: 88.24%\n",
      "Run: 02, Epoch: 60, Loss: 0.2481, Train: 83.33%, Valid: 76.25% Test: 88.24%\n",
      "Run: 02, Epoch: 61, Loss: 0.2620, Train: 85.83%, Valid: 73.75% Test: 88.24%\n",
      "Run: 02, Epoch: 62, Loss: 0.2946, Train: 85.83%, Valid: 76.25% Test: 90.20%\n",
      "Run: 02, Epoch: 63, Loss: 0.2781, Train: 88.33%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 64, Loss: 0.2596, Train: 94.17%, Valid: 81.25% Test: 94.12%\n",
      "Run: 02, Epoch: 65, Loss: 0.2172, Train: 95.00%, Valid: 78.75% Test: 94.12%\n",
      "Run: 02, Epoch: 66, Loss: 0.2328, Train: 94.17%, Valid: 78.75% Test: 94.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 67, Loss: 0.2314, Train: 94.17%, Valid: 78.75% Test: 94.12%\n",
      "Run: 02, Epoch: 68, Loss: 0.2890, Train: 92.50%, Valid: 77.50% Test: 94.12%\n",
      "Run: 02, Epoch: 69, Loss: 0.1805, Train: 93.33%, Valid: 77.50% Test: 94.12%\n",
      "Run: 02, Epoch: 70, Loss: 0.2059, Train: 90.83%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 71, Loss: 0.2365, Train: 90.83%, Valid: 81.25% Test: 94.12%\n",
      "Run: 02, Epoch: 72, Loss: 0.2317, Train: 91.67%, Valid: 81.25% Test: 94.12%\n",
      "Run: 02, Epoch: 73, Loss: 0.2489, Train: 90.83%, Valid: 83.75% Test: 94.12%\n",
      "Run: 02, Epoch: 74, Loss: 0.1964, Train: 90.00%, Valid: 82.50% Test: 92.16%\n",
      "Run: 02, Epoch: 75, Loss: 0.1794, Train: 90.83%, Valid: 82.50% Test: 92.16%\n",
      "Run: 02, Epoch: 76, Loss: 0.2495, Train: 90.83%, Valid: 81.25% Test: 92.16%\n",
      "Run: 02, Epoch: 77, Loss: 0.2050, Train: 94.17%, Valid: 82.50% Test: 94.12%\n",
      "Run: 02, Epoch: 78, Loss: 0.2002, Train: 94.17%, Valid: 82.50% Test: 94.12%\n",
      "Run: 02, Epoch: 79, Loss: 0.1796, Train: 95.00%, Valid: 82.50% Test: 94.12%\n",
      "Run: 02, Epoch: 80, Loss: 0.1875, Train: 95.00%, Valid: 82.50% Test: 92.16%\n",
      "Run: 02, Epoch: 81, Loss: 0.2147, Train: 92.50%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 82, Loss: 0.1989, Train: 91.67%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 83, Loss: 0.1891, Train: 92.50%, Valid: 81.25% Test: 92.16%\n",
      "Run: 02, Epoch: 84, Loss: 0.1409, Train: 96.67%, Valid: 83.75% Test: 94.12%\n",
      "Run: 02, Epoch: 85, Loss: 0.1662, Train: 96.67%, Valid: 83.75% Test: 94.12%\n",
      "Run: 02, Epoch: 86, Loss: 0.1954, Train: 95.00%, Valid: 82.50% Test: 90.20%\n",
      "Run: 02, Epoch: 87, Loss: 0.2078, Train: 93.33%, Valid: 80.00% Test: 86.27%\n",
      "Run: 02, Epoch: 88, Loss: 0.1955, Train: 93.33%, Valid: 80.00% Test: 82.35%\n",
      "Run: 02, Epoch: 89, Loss: 0.1366, Train: 94.17%, Valid: 77.50% Test: 84.31%\n",
      "Run: 02, Epoch: 90, Loss: 0.1955, Train: 94.17%, Valid: 76.25% Test: 86.27%\n",
      "Run: 02, Epoch: 91, Loss: 0.2397, Train: 95.00%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 92, Loss: 0.2363, Train: 91.67%, Valid: 77.50% Test: 92.16%\n",
      "Run: 02, Epoch: 93, Loss: 0.1579, Train: 89.17%, Valid: 76.25% Test: 92.16%\n",
      "Run: 02, Epoch: 94, Loss: 0.1926, Train: 90.83%, Valid: 77.50% Test: 90.20%\n",
      "Run: 02, Epoch: 95, Loss: 0.1817, Train: 90.83%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 96, Loss: 0.1665, Train: 92.50%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 97, Loss: 0.1646, Train: 95.00%, Valid: 83.75% Test: 94.12%\n",
      "Run: 02, Epoch: 98, Loss: 0.1922, Train: 97.50%, Valid: 82.50% Test: 92.16%\n",
      "Run: 02, Epoch: 99, Loss: 0.1597, Train: 95.83%, Valid: 85.00% Test: 86.27%\n",
      "Run: 02, Epoch: 100, Loss: 0.1536, Train: 95.83%, Valid: 83.75% Test: 86.27%\n",
      "Run 02:\n",
      "Highest Train: 97.50\n",
      "Highest Valid: 85.00\n",
      "  Final Train: 95.83\n",
      "   Final Test: 86.27\n",
      "Run: 03, Epoch: 01, Loss: 1.9510, Train: 30.00%, Valid: 36.25% Test: 35.29%\n",
      "Run: 03, Epoch: 02, Loss: 1.6229, Train: 58.33%, Valid: 53.75% Test: 56.86%\n",
      "Run: 03, Epoch: 03, Loss: 1.4660, Train: 55.00%, Valid: 43.75% Test: 60.78%\n",
      "Run: 03, Epoch: 04, Loss: 1.3343, Train: 51.67%, Valid: 48.75% Test: 56.86%\n",
      "Run: 03, Epoch: 05, Loss: 1.2312, Train: 45.00%, Valid: 42.50% Test: 52.94%\n",
      "Run: 03, Epoch: 06, Loss: 1.1017, Train: 47.50%, Valid: 42.50% Test: 54.90%\n",
      "Run: 03, Epoch: 07, Loss: 1.1520, Train: 46.67%, Valid: 42.50% Test: 50.98%\n",
      "Run: 03, Epoch: 08, Loss: 1.1176, Train: 47.50%, Valid: 47.50% Test: 50.98%\n",
      "Run: 03, Epoch: 09, Loss: 1.0809, Train: 53.33%, Valid: 46.25% Test: 56.86%\n",
      "Run: 03, Epoch: 10, Loss: 0.9759, Train: 68.33%, Valid: 67.50% Test: 72.55%\n",
      "Run: 03, Epoch: 11, Loss: 0.9790, Train: 72.50%, Valid: 72.50% Test: 76.47%\n",
      "Run: 03, Epoch: 12, Loss: 0.9497, Train: 75.83%, Valid: 73.75% Test: 74.51%\n",
      "Run: 03, Epoch: 13, Loss: 0.9652, Train: 73.33%, Valid: 71.25% Test: 68.63%\n",
      "Run: 03, Epoch: 14, Loss: 0.8605, Train: 71.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 03, Epoch: 15, Loss: 0.9085, Train: 70.83%, Valid: 70.00% Test: 70.59%\n",
      "Run: 03, Epoch: 16, Loss: 0.8867, Train: 70.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 03, Epoch: 17, Loss: 0.8754, Train: 75.83%, Valid: 72.50% Test: 74.51%\n",
      "Run: 03, Epoch: 18, Loss: 0.8303, Train: 77.50%, Valid: 72.50% Test: 76.47%\n",
      "Run: 03, Epoch: 19, Loss: 0.6883, Train: 78.33%, Valid: 76.25% Test: 76.47%\n",
      "Run: 03, Epoch: 20, Loss: 0.6986, Train: 78.33%, Valid: 76.25% Test: 78.43%\n",
      "Run: 03, Epoch: 21, Loss: 0.7534, Train: 76.67%, Valid: 75.00% Test: 78.43%\n",
      "Run: 03, Epoch: 22, Loss: 0.6678, Train: 74.17%, Valid: 72.50% Test: 78.43%\n",
      "Run: 03, Epoch: 23, Loss: 0.5827, Train: 73.33%, Valid: 72.50% Test: 78.43%\n",
      "Run: 03, Epoch: 24, Loss: 0.5675, Train: 70.83%, Valid: 71.25% Test: 76.47%\n",
      "Run: 03, Epoch: 25, Loss: 0.6266, Train: 70.00%, Valid: 70.00% Test: 74.51%\n",
      "Run: 03, Epoch: 26, Loss: 0.5115, Train: 66.67%, Valid: 68.75% Test: 72.55%\n",
      "Run: 03, Epoch: 27, Loss: 0.5500, Train: 63.33%, Valid: 68.75% Test: 72.55%\n",
      "Run: 03, Epoch: 28, Loss: 0.6192, Train: 61.67%, Valid: 68.75% Test: 70.59%\n",
      "Run: 03, Epoch: 29, Loss: 0.5084, Train: 61.67%, Valid: 67.50% Test: 68.63%\n",
      "Run: 03, Epoch: 30, Loss: 0.4487, Train: 60.83%, Valid: 68.75% Test: 68.63%\n",
      "Run: 03, Epoch: 31, Loss: 0.4221, Train: 61.67%, Valid: 68.75% Test: 68.63%\n",
      "Run: 03, Epoch: 32, Loss: 0.4976, Train: 61.67%, Valid: 68.75% Test: 70.59%\n",
      "Run: 03, Epoch: 33, Loss: 0.3998, Train: 61.67%, Valid: 70.00% Test: 72.55%\n",
      "Run: 03, Epoch: 34, Loss: 0.3819, Train: 70.00%, Valid: 72.50% Test: 74.51%\n",
      "Run: 03, Epoch: 35, Loss: 0.3978, Train: 75.00%, Valid: 73.75% Test: 76.47%\n",
      "Run: 03, Epoch: 36, Loss: 0.3564, Train: 79.17%, Valid: 76.25% Test: 80.39%\n",
      "Run: 03, Epoch: 37, Loss: 0.4705, Train: 80.83%, Valid: 80.00% Test: 80.39%\n",
      "Run: 03, Epoch: 38, Loss: 0.3873, Train: 82.50%, Valid: 82.50% Test: 82.35%\n",
      "Run: 03, Epoch: 39, Loss: 0.3580, Train: 80.00%, Valid: 82.50% Test: 80.39%\n",
      "Run: 03, Epoch: 40, Loss: 0.3930, Train: 81.67%, Valid: 81.25% Test: 80.39%\n",
      "Run: 03, Epoch: 41, Loss: 0.3429, Train: 78.33%, Valid: 76.25% Test: 78.43%\n",
      "Run: 03, Epoch: 42, Loss: 0.3711, Train: 76.67%, Valid: 75.00% Test: 78.43%\n",
      "Run: 03, Epoch: 43, Loss: 0.3507, Train: 74.17%, Valid: 73.75% Test: 78.43%\n",
      "Run: 03, Epoch: 44, Loss: 0.3507, Train: 72.50%, Valid: 73.75% Test: 78.43%\n",
      "Run: 03, Epoch: 45, Loss: 0.3128, Train: 73.33%, Valid: 73.75% Test: 78.43%\n",
      "Run: 03, Epoch: 46, Loss: 0.3195, Train: 76.67%, Valid: 76.25% Test: 78.43%\n",
      "Run: 03, Epoch: 47, Loss: 0.3937, Train: 78.33%, Valid: 76.25% Test: 78.43%\n",
      "Run: 03, Epoch: 48, Loss: 0.3215, Train: 80.83%, Valid: 76.25% Test: 80.39%\n",
      "Run: 03, Epoch: 49, Loss: 0.2501, Train: 83.33%, Valid: 77.50% Test: 80.39%\n",
      "Run: 03, Epoch: 50, Loss: 0.2976, Train: 86.67%, Valid: 81.25% Test: 80.39%\n",
      "Run: 03, Epoch: 51, Loss: 0.2995, Train: 83.33%, Valid: 80.00% Test: 80.39%\n",
      "Run: 03, Epoch: 52, Loss: 0.3164, Train: 81.67%, Valid: 80.00% Test: 82.35%\n",
      "Run: 03, Epoch: 53, Loss: 0.2797, Train: 82.50%, Valid: 81.25% Test: 82.35%\n",
      "Run: 03, Epoch: 54, Loss: 0.2965, Train: 80.83%, Valid: 81.25% Test: 82.35%\n",
      "Run: 03, Epoch: 55, Loss: 0.2991, Train: 81.67%, Valid: 77.50% Test: 84.31%\n",
      "Run: 03, Epoch: 56, Loss: 0.3265, Train: 80.83%, Valid: 76.25% Test: 84.31%\n",
      "Run: 03, Epoch: 57, Loss: 0.3082, Train: 80.83%, Valid: 77.50% Test: 84.31%\n",
      "Run: 03, Epoch: 58, Loss: 0.3273, Train: 81.67%, Valid: 77.50% Test: 84.31%\n",
      "Run: 03, Epoch: 59, Loss: 0.2628, Train: 81.67%, Valid: 78.75% Test: 84.31%\n",
      "Run: 03, Epoch: 60, Loss: 0.2827, Train: 81.67%, Valid: 81.25% Test: 84.31%\n",
      "Run: 03, Epoch: 61, Loss: 0.2589, Train: 84.17%, Valid: 82.50% Test: 84.31%\n",
      "Run: 03, Epoch: 62, Loss: 0.2601, Train: 83.33%, Valid: 83.75% Test: 84.31%\n",
      "Run: 03, Epoch: 63, Loss: 0.2509, Train: 85.83%, Valid: 82.50% Test: 82.35%\n",
      "Run: 03, Epoch: 64, Loss: 0.2332, Train: 84.17%, Valid: 83.75% Test: 84.31%\n",
      "Run: 03, Epoch: 65, Loss: 0.2972, Train: 89.17%, Valid: 86.25% Test: 86.27%\n",
      "Run: 03, Epoch: 66, Loss: 0.2449, Train: 90.83%, Valid: 87.50% Test: 88.24%\n",
      "Run: 03, Epoch: 67, Loss: 0.2491, Train: 90.00%, Valid: 88.75% Test: 88.24%\n",
      "Run: 03, Epoch: 68, Loss: 0.1913, Train: 90.83%, Valid: 88.75% Test: 88.24%\n",
      "Run: 03, Epoch: 69, Loss: 0.2341, Train: 91.67%, Valid: 91.25% Test: 88.24%\n",
      "Run: 03, Epoch: 70, Loss: 0.2519, Train: 92.50%, Valid: 92.50% Test: 86.27%\n",
      "Run: 03, Epoch: 71, Loss: 0.1807, Train: 95.83%, Valid: 92.50% Test: 88.24%\n",
      "Run: 03, Epoch: 72, Loss: 0.2351, Train: 95.83%, Valid: 92.50% Test: 88.24%\n",
      "Run: 03, Epoch: 73, Loss: 0.3085, Train: 96.67%, Valid: 92.50% Test: 88.24%\n",
      "Run: 03, Epoch: 74, Loss: 0.2147, Train: 96.67%, Valid: 90.00% Test: 92.16%\n",
      "Run: 03, Epoch: 75, Loss: 0.2433, Train: 96.67%, Valid: 88.75% Test: 92.16%\n",
      "Run: 03, Epoch: 76, Loss: 0.1959, Train: 94.17%, Valid: 87.50% Test: 94.12%\n",
      "Run: 03, Epoch: 77, Loss: 0.1998, Train: 91.67%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 78, Loss: 0.2587, Train: 91.67%, Valid: 90.00% Test: 88.24%\n",
      "Run: 03, Epoch: 79, Loss: 0.1995, Train: 90.00%, Valid: 87.50% Test: 88.24%\n",
      "Run: 03, Epoch: 80, Loss: 0.1813, Train: 88.33%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 81, Loss: 0.2372, Train: 87.50%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 82, Loss: 0.1518, Train: 90.00%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 83, Loss: 0.1727, Train: 91.67%, Valid: 90.00% Test: 90.20%\n",
      "Run: 03, Epoch: 84, Loss: 0.2073, Train: 95.83%, Valid: 91.25% Test: 88.24%\n",
      "Run: 03, Epoch: 85, Loss: 0.2123, Train: 95.83%, Valid: 90.00% Test: 86.27%\n",
      "Run: 03, Epoch: 86, Loss: 0.2159, Train: 95.83%, Valid: 88.75% Test: 86.27%\n",
      "Run: 03, Epoch: 87, Loss: 0.1760, Train: 94.17%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 88, Loss: 0.1745, Train: 93.33%, Valid: 87.50% Test: 84.31%\n",
      "Run: 03, Epoch: 89, Loss: 0.1992, Train: 92.50%, Valid: 86.25% Test: 86.27%\n",
      "Run: 03, Epoch: 90, Loss: 0.1664, Train: 93.33%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 91, Loss: 0.1802, Train: 93.33%, Valid: 88.75% Test: 86.27%\n",
      "Run: 03, Epoch: 92, Loss: 0.2292, Train: 93.33%, Valid: 91.25% Test: 86.27%\n",
      "Run: 03, Epoch: 93, Loss: 0.1265, Train: 94.17%, Valid: 90.00% Test: 86.27%\n",
      "Run: 03, Epoch: 94, Loss: 0.1568, Train: 97.50%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 95, Loss: 0.2662, Train: 97.50%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 96, Loss: 0.2003, Train: 98.33%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 97, Loss: 0.1322, Train: 98.33%, Valid: 87.50% Test: 88.24%\n",
      "Run: 03, Epoch: 98, Loss: 0.1835, Train: 98.33%, Valid: 87.50% Test: 88.24%\n",
      "Run: 03, Epoch: 99, Loss: 0.1873, Train: 98.33%, Valid: 87.50% Test: 90.20%\n",
      "Run: 03, Epoch: 100, Loss: 0.2035, Train: 97.50%, Valid: 90.00% Test: 90.20%\n",
      "Run 03:\n",
      "Highest Train: 98.33\n",
      "Highest Valid: 92.50\n",
      "  Final Train: 92.50\n",
      "   Final Test: 86.27\n",
      "Run: 04, Epoch: 01, Loss: 1.7643, Train: 48.33%, Valid: 48.75% Test: 43.14%\n",
      "Run: 04, Epoch: 02, Loss: 1.5102, Train: 54.17%, Valid: 48.75% Test: 41.18%\n",
      "Run: 04, Epoch: 03, Loss: 1.4484, Train: 55.83%, Valid: 51.25% Test: 37.25%\n",
      "Run: 04, Epoch: 04, Loss: 1.3258, Train: 55.83%, Valid: 45.00% Test: 35.29%\n",
      "Run: 04, Epoch: 05, Loss: 1.2678, Train: 53.33%, Valid: 41.25% Test: 35.29%\n",
      "Run: 04, Epoch: 06, Loss: 1.2541, Train: 52.50%, Valid: 42.50% Test: 37.25%\n",
      "Run: 04, Epoch: 07, Loss: 1.1747, Train: 51.67%, Valid: 45.00% Test: 37.25%\n",
      "Run: 04, Epoch: 08, Loss: 1.0649, Train: 50.83%, Valid: 42.50% Test: 39.22%\n",
      "Run: 04, Epoch: 09, Loss: 1.0698, Train: 56.67%, Valid: 50.00% Test: 43.14%\n",
      "Run: 04, Epoch: 10, Loss: 1.0233, Train: 62.50%, Valid: 60.00% Test: 49.02%\n",
      "Run: 04, Epoch: 11, Loss: 1.0408, Train: 65.83%, Valid: 66.25% Test: 52.94%\n",
      "Run: 04, Epoch: 12, Loss: 0.9572, Train: 65.00%, Valid: 68.75% Test: 54.90%\n",
      "Run: 04, Epoch: 13, Loss: 0.9619, Train: 60.83%, Valid: 67.50% Test: 50.98%\n",
      "Run: 04, Epoch: 14, Loss: 0.9699, Train: 59.17%, Valid: 68.75% Test: 49.02%\n",
      "Run: 04, Epoch: 15, Loss: 0.8850, Train: 58.33%, Valid: 65.00% Test: 52.94%\n",
      "Run: 04, Epoch: 16, Loss: 0.8637, Train: 60.00%, Valid: 67.50% Test: 60.78%\n",
      "Run: 04, Epoch: 17, Loss: 0.8983, Train: 67.50%, Valid: 71.25% Test: 62.75%\n",
      "Run: 04, Epoch: 18, Loss: 0.8048, Train: 75.00%, Valid: 76.25% Test: 68.63%\n",
      "Run: 04, Epoch: 19, Loss: 0.8123, Train: 78.33%, Valid: 73.75% Test: 64.71%\n",
      "Run: 04, Epoch: 20, Loss: 0.7423, Train: 78.33%, Valid: 73.75% Test: 66.67%\n",
      "Run: 04, Epoch: 21, Loss: 0.7203, Train: 76.67%, Valid: 72.50% Test: 68.63%\n",
      "Run: 04, Epoch: 22, Loss: 0.7265, Train: 75.83%, Valid: 73.75% Test: 70.59%\n",
      "Run: 04, Epoch: 23, Loss: 0.8279, Train: 75.83%, Valid: 72.50% Test: 66.67%\n",
      "Run: 04, Epoch: 24, Loss: 0.7414, Train: 75.83%, Valid: 73.75% Test: 62.75%\n",
      "Run: 04, Epoch: 25, Loss: 0.6492, Train: 72.50%, Valid: 73.75% Test: 66.67%\n",
      "Run: 04, Epoch: 26, Loss: 0.6042, Train: 71.67%, Valid: 72.50% Test: 66.67%\n",
      "Run: 04, Epoch: 27, Loss: 0.5918, Train: 72.50%, Valid: 71.25% Test: 66.67%\n",
      "Run: 04, Epoch: 28, Loss: 0.6241, Train: 70.83%, Valid: 70.00% Test: 64.71%\n",
      "Run: 04, Epoch: 29, Loss: 0.6117, Train: 70.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 04, Epoch: 30, Loss: 0.5843, Train: 66.67%, Valid: 68.75% Test: 60.78%\n",
      "Run: 04, Epoch: 31, Loss: 0.5315, Train: 68.33%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 32, Loss: 0.4896, Train: 66.67%, Valid: 71.25% Test: 66.67%\n",
      "Run: 04, Epoch: 33, Loss: 0.5667, Train: 68.33%, Valid: 73.75% Test: 66.67%\n",
      "Run: 04, Epoch: 34, Loss: 0.5870, Train: 68.33%, Valid: 75.00% Test: 68.63%\n",
      "Run: 04, Epoch: 35, Loss: 0.5212, Train: 73.33%, Valid: 76.25% Test: 68.63%\n",
      "Run: 04, Epoch: 36, Loss: 0.5550, Train: 75.83%, Valid: 77.50% Test: 72.55%\n",
      "Run: 04, Epoch: 37, Loss: 0.5044, Train: 80.00%, Valid: 81.25% Test: 74.51%\n",
      "Run: 04, Epoch: 38, Loss: 0.3960, Train: 85.00%, Valid: 82.50% Test: 74.51%\n",
      "Run: 04, Epoch: 39, Loss: 0.4766, Train: 86.67%, Valid: 83.75% Test: 80.39%\n",
      "Run: 04, Epoch: 40, Loss: 0.4487, Train: 87.50%, Valid: 85.00% Test: 80.39%\n",
      "Run: 04, Epoch: 41, Loss: 0.4794, Train: 88.33%, Valid: 83.75% Test: 88.24%\n",
      "Run: 04, Epoch: 42, Loss: 0.4858, Train: 88.33%, Valid: 83.75% Test: 86.27%\n",
      "Run: 04, Epoch: 43, Loss: 0.4440, Train: 85.83%, Valid: 83.75% Test: 82.35%\n",
      "Run: 04, Epoch: 44, Loss: 0.3873, Train: 83.33%, Valid: 81.25% Test: 80.39%\n",
      "Run: 04, Epoch: 45, Loss: 0.3771, Train: 80.00%, Valid: 80.00% Test: 72.55%\n",
      "Run: 04, Epoch: 46, Loss: 0.4069, Train: 79.17%, Valid: 78.75% Test: 68.63%\n",
      "Run: 04, Epoch: 47, Loss: 0.4055, Train: 80.00%, Valid: 76.25% Test: 70.59%\n",
      "Run: 04, Epoch: 48, Loss: 0.4550, Train: 80.83%, Valid: 76.25% Test: 72.55%\n",
      "Run: 04, Epoch: 49, Loss: 0.4187, Train: 82.50%, Valid: 77.50% Test: 74.51%\n",
      "Run: 04, Epoch: 50, Loss: 0.3255, Train: 82.50%, Valid: 77.50% Test: 76.47%\n",
      "Run: 04, Epoch: 51, Loss: 0.3898, Train: 84.17%, Valid: 77.50% Test: 76.47%\n",
      "Run: 04, Epoch: 52, Loss: 0.3009, Train: 85.00%, Valid: 78.75% Test: 76.47%\n",
      "Run: 04, Epoch: 53, Loss: 0.4043, Train: 86.67%, Valid: 80.00% Test: 76.47%\n",
      "Run: 04, Epoch: 54, Loss: 0.3613, Train: 87.50%, Valid: 81.25% Test: 82.35%\n",
      "Run: 04, Epoch: 55, Loss: 0.3826, Train: 89.17%, Valid: 82.50% Test: 82.35%\n",
      "Run: 04, Epoch: 56, Loss: 0.3412, Train: 90.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 04, Epoch: 57, Loss: 0.3378, Train: 90.00%, Valid: 86.25% Test: 84.31%\n",
      "Run: 04, Epoch: 58, Loss: 0.3791, Train: 88.33%, Valid: 87.50% Test: 86.27%\n",
      "Run: 04, Epoch: 59, Loss: 0.3526, Train: 85.83%, Valid: 91.25% Test: 78.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 60, Loss: 0.3346, Train: 88.33%, Valid: 88.75% Test: 78.43%\n",
      "Run: 04, Epoch: 61, Loss: 0.3346, Train: 88.33%, Valid: 88.75% Test: 82.35%\n",
      "Run: 04, Epoch: 62, Loss: 0.3002, Train: 89.17%, Valid: 87.50% Test: 76.47%\n",
      "Run: 04, Epoch: 63, Loss: 0.3272, Train: 90.83%, Valid: 86.25% Test: 80.39%\n",
      "Run: 04, Epoch: 64, Loss: 0.3434, Train: 90.83%, Valid: 85.00% Test: 86.27%\n",
      "Run: 04, Epoch: 65, Loss: 0.2987, Train: 92.50%, Valid: 86.25% Test: 88.24%\n",
      "Run: 04, Epoch: 66, Loss: 0.3189, Train: 92.50%, Valid: 86.25% Test: 88.24%\n",
      "Run: 04, Epoch: 67, Loss: 0.3832, Train: 91.67%, Valid: 86.25% Test: 86.27%\n",
      "Run: 04, Epoch: 68, Loss: 0.3003, Train: 91.67%, Valid: 85.00% Test: 86.27%\n",
      "Run: 04, Epoch: 69, Loss: 0.3228, Train: 94.17%, Valid: 87.50% Test: 88.24%\n",
      "Run: 04, Epoch: 70, Loss: 0.2713, Train: 94.17%, Valid: 90.00% Test: 90.20%\n",
      "Run: 04, Epoch: 71, Loss: 0.3181, Train: 92.50%, Valid: 87.50% Test: 84.31%\n",
      "Run: 04, Epoch: 72, Loss: 0.2661, Train: 91.67%, Valid: 86.25% Test: 74.51%\n",
      "Run: 04, Epoch: 73, Loss: 0.2874, Train: 90.00%, Valid: 85.00% Test: 70.59%\n",
      "Run: 04, Epoch: 74, Loss: 0.2691, Train: 84.17%, Valid: 81.25% Test: 68.63%\n",
      "Run: 04, Epoch: 75, Loss: 0.2716, Train: 84.17%, Valid: 81.25% Test: 68.63%\n",
      "Run: 04, Epoch: 76, Loss: 0.2277, Train: 85.00%, Valid: 81.25% Test: 68.63%\n",
      "Run: 04, Epoch: 77, Loss: 0.2954, Train: 90.00%, Valid: 83.75% Test: 72.55%\n",
      "Run: 04, Epoch: 78, Loss: 0.2531, Train: 92.50%, Valid: 86.25% Test: 76.47%\n",
      "Run: 04, Epoch: 79, Loss: 0.3159, Train: 93.33%, Valid: 88.75% Test: 86.27%\n",
      "Run: 04, Epoch: 80, Loss: 0.2781, Train: 92.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 04, Epoch: 81, Loss: 0.3050, Train: 91.67%, Valid: 90.00% Test: 86.27%\n",
      "Run: 04, Epoch: 82, Loss: 0.3186, Train: 93.33%, Valid: 90.00% Test: 84.31%\n",
      "Run: 04, Epoch: 83, Loss: 0.3080, Train: 92.50%, Valid: 87.50% Test: 78.43%\n",
      "Run: 04, Epoch: 84, Loss: 0.2539, Train: 92.50%, Valid: 87.50% Test: 74.51%\n",
      "Run: 04, Epoch: 85, Loss: 0.2978, Train: 91.67%, Valid: 86.25% Test: 72.55%\n",
      "Run: 04, Epoch: 86, Loss: 0.2867, Train: 91.67%, Valid: 86.25% Test: 72.55%\n",
      "Run: 04, Epoch: 87, Loss: 0.3527, Train: 92.50%, Valid: 86.25% Test: 76.47%\n",
      "Run: 04, Epoch: 88, Loss: 0.3473, Train: 93.33%, Valid: 87.50% Test: 88.24%\n",
      "Run: 04, Epoch: 89, Loss: 0.3125, Train: 93.33%, Valid: 88.75% Test: 90.20%\n",
      "Run: 04, Epoch: 90, Loss: 0.2162, Train: 90.83%, Valid: 82.50% Test: 86.27%\n",
      "Run: 04, Epoch: 91, Loss: 0.2209, Train: 90.00%, Valid: 80.00% Test: 84.31%\n",
      "Run: 04, Epoch: 92, Loss: 0.2857, Train: 90.83%, Valid: 81.25% Test: 86.27%\n",
      "Run: 04, Epoch: 93, Loss: 0.2442, Train: 92.50%, Valid: 87.50% Test: 86.27%\n",
      "Run: 04, Epoch: 94, Loss: 0.2371, Train: 93.33%, Valid: 88.75% Test: 86.27%\n",
      "Run: 04, Epoch: 95, Loss: 0.1933, Train: 93.33%, Valid: 88.75% Test: 84.31%\n",
      "Run: 04, Epoch: 96, Loss: 0.2453, Train: 93.33%, Valid: 88.75% Test: 86.27%\n",
      "Run: 04, Epoch: 97, Loss: 0.2573, Train: 92.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 04, Epoch: 98, Loss: 0.3437, Train: 94.17%, Valid: 88.75% Test: 82.35%\n",
      "Run: 04, Epoch: 99, Loss: 0.2339, Train: 93.33%, Valid: 90.00% Test: 82.35%\n",
      "Run: 04, Epoch: 100, Loss: 0.2449, Train: 93.33%, Valid: 91.25% Test: 88.24%\n",
      "Run 04:\n",
      "Highest Train: 94.17\n",
      "Highest Valid: 91.25\n",
      "  Final Train: 85.83\n",
      "   Final Test: 78.43\n",
      "Run: 05, Epoch: 01, Loss: 1.8855, Train: 24.17%, Valid: 36.25% Test: 31.37%\n",
      "Run: 05, Epoch: 02, Loss: 1.6332, Train: 32.50%, Valid: 40.00% Test: 29.41%\n",
      "Run: 05, Epoch: 03, Loss: 1.4301, Train: 36.67%, Valid: 35.00% Test: 43.14%\n",
      "Run: 05, Epoch: 04, Loss: 1.2956, Train: 35.83%, Valid: 32.50% Test: 41.18%\n",
      "Run: 05, Epoch: 05, Loss: 1.2443, Train: 37.50%, Valid: 33.75% Test: 43.14%\n",
      "Run: 05, Epoch: 06, Loss: 1.1316, Train: 38.33%, Valid: 35.00% Test: 43.14%\n",
      "Run: 05, Epoch: 07, Loss: 1.0857, Train: 39.17%, Valid: 37.50% Test: 45.10%\n",
      "Run: 05, Epoch: 08, Loss: 1.0135, Train: 42.50%, Valid: 40.00% Test: 45.10%\n",
      "Run: 05, Epoch: 09, Loss: 0.9997, Train: 45.00%, Valid: 41.25% Test: 49.02%\n",
      "Run: 05, Epoch: 10, Loss: 1.0018, Train: 60.00%, Valid: 50.00% Test: 54.90%\n",
      "Run: 05, Epoch: 11, Loss: 1.0261, Train: 70.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 05, Epoch: 12, Loss: 0.8788, Train: 69.17%, Valid: 67.50% Test: 60.78%\n",
      "Run: 05, Epoch: 13, Loss: 0.9136, Train: 70.00%, Valid: 71.25% Test: 58.82%\n",
      "Run: 05, Epoch: 14, Loss: 0.8672, Train: 68.33%, Valid: 71.25% Test: 58.82%\n",
      "Run: 05, Epoch: 15, Loss: 0.8504, Train: 69.17%, Valid: 72.50% Test: 56.86%\n",
      "Run: 05, Epoch: 16, Loss: 0.8831, Train: 68.33%, Valid: 68.75% Test: 54.90%\n",
      "Run: 05, Epoch: 17, Loss: 0.8419, Train: 65.83%, Valid: 67.50% Test: 52.94%\n",
      "Run: 05, Epoch: 18, Loss: 0.8141, Train: 61.67%, Valid: 65.00% Test: 50.98%\n",
      "Run: 05, Epoch: 19, Loss: 0.7830, Train: 61.67%, Valid: 65.00% Test: 50.98%\n",
      "Run: 05, Epoch: 20, Loss: 0.7262, Train: 60.00%, Valid: 65.00% Test: 50.98%\n",
      "Run: 05, Epoch: 21, Loss: 0.7617, Train: 60.83%, Valid: 66.25% Test: 54.90%\n",
      "Run: 05, Epoch: 22, Loss: 0.6495, Train: 65.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 05, Epoch: 23, Loss: 0.6311, Train: 70.83%, Valid: 70.00% Test: 62.75%\n",
      "Run: 05, Epoch: 24, Loss: 0.6876, Train: 71.67%, Valid: 72.50% Test: 60.78%\n",
      "Run: 05, Epoch: 25, Loss: 0.6972, Train: 72.50%, Valid: 75.00% Test: 62.75%\n",
      "Run: 05, Epoch: 26, Loss: 0.6096, Train: 72.50%, Valid: 72.50% Test: 60.78%\n",
      "Run: 05, Epoch: 27, Loss: 0.5911, Train: 70.83%, Valid: 72.50% Test: 60.78%\n",
      "Run: 05, Epoch: 28, Loss: 0.5899, Train: 70.00%, Valid: 72.50% Test: 60.78%\n",
      "Run: 05, Epoch: 29, Loss: 0.5505, Train: 70.83%, Valid: 73.75% Test: 60.78%\n",
      "Run: 05, Epoch: 30, Loss: 0.5559, Train: 71.67%, Valid: 73.75% Test: 58.82%\n",
      "Run: 05, Epoch: 31, Loss: 0.5421, Train: 74.17%, Valid: 73.75% Test: 58.82%\n",
      "Run: 05, Epoch: 32, Loss: 0.4815, Train: 72.50%, Valid: 70.00% Test: 58.82%\n",
      "Run: 05, Epoch: 33, Loss: 0.5090, Train: 72.50%, Valid: 70.00% Test: 60.78%\n",
      "Run: 05, Epoch: 34, Loss: 0.4955, Train: 71.67%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 35, Loss: 0.4922, Train: 74.17%, Valid: 75.00% Test: 64.71%\n",
      "Run: 05, Epoch: 36, Loss: 0.5012, Train: 76.67%, Valid: 75.00% Test: 62.75%\n",
      "Run: 05, Epoch: 37, Loss: 0.4397, Train: 76.67%, Valid: 76.25% Test: 62.75%\n",
      "Run: 05, Epoch: 38, Loss: 0.4852, Train: 77.50%, Valid: 78.75% Test: 62.75%\n",
      "Run: 05, Epoch: 39, Loss: 0.3579, Train: 77.50%, Valid: 77.50% Test: 62.75%\n",
      "Run: 05, Epoch: 40, Loss: 0.4254, Train: 79.17%, Valid: 78.75% Test: 68.63%\n",
      "Run: 05, Epoch: 41, Loss: 0.3933, Train: 80.00%, Valid: 78.75% Test: 68.63%\n",
      "Run: 05, Epoch: 42, Loss: 0.3522, Train: 81.67%, Valid: 77.50% Test: 70.59%\n",
      "Run: 05, Epoch: 43, Loss: 0.4225, Train: 81.67%, Valid: 77.50% Test: 68.63%\n",
      "Run: 05, Epoch: 44, Loss: 0.4207, Train: 80.83%, Valid: 77.50% Test: 70.59%\n",
      "Run: 05, Epoch: 45, Loss: 0.3891, Train: 82.50%, Valid: 78.75% Test: 72.55%\n",
      "Run: 05, Epoch: 46, Loss: 0.3417, Train: 84.17%, Valid: 80.00% Test: 78.43%\n",
      "Run: 05, Epoch: 47, Loss: 0.3342, Train: 85.83%, Valid: 78.75% Test: 82.35%\n",
      "Run: 05, Epoch: 48, Loss: 0.3528, Train: 87.50%, Valid: 80.00% Test: 84.31%\n",
      "Run: 05, Epoch: 49, Loss: 0.3336, Train: 87.50%, Valid: 81.25% Test: 84.31%\n",
      "Run: 05, Epoch: 50, Loss: 0.3929, Train: 89.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 05, Epoch: 51, Loss: 0.3499, Train: 90.00%, Valid: 80.00% Test: 88.24%\n",
      "Run: 05, Epoch: 52, Loss: 0.3159, Train: 90.83%, Valid: 80.00% Test: 92.16%\n",
      "Run: 05, Epoch: 53, Loss: 0.3001, Train: 90.83%, Valid: 80.00% Test: 86.27%\n",
      "Run: 05, Epoch: 54, Loss: 0.3631, Train: 90.00%, Valid: 81.25% Test: 84.31%\n",
      "Run: 05, Epoch: 55, Loss: 0.3089, Train: 87.50%, Valid: 81.25% Test: 82.35%\n",
      "Run: 05, Epoch: 56, Loss: 0.2900, Train: 87.50%, Valid: 80.00% Test: 80.39%\n",
      "Run: 05, Epoch: 57, Loss: 0.2580, Train: 87.50%, Valid: 80.00% Test: 80.39%\n",
      "Run: 05, Epoch: 58, Loss: 0.2628, Train: 86.67%, Valid: 80.00% Test: 84.31%\n",
      "Run: 05, Epoch: 59, Loss: 0.2228, Train: 85.83%, Valid: 80.00% Test: 82.35%\n",
      "Run: 05, Epoch: 60, Loss: 0.3025, Train: 85.83%, Valid: 78.75% Test: 82.35%\n",
      "Run: 05, Epoch: 61, Loss: 0.2651, Train: 84.17%, Valid: 80.00% Test: 80.39%\n",
      "Run: 05, Epoch: 62, Loss: 0.3389, Train: 85.00%, Valid: 80.00% Test: 82.35%\n",
      "Run: 05, Epoch: 63, Loss: 0.2900, Train: 85.83%, Valid: 80.00% Test: 86.27%\n",
      "Run: 05, Epoch: 64, Loss: 0.2345, Train: 86.67%, Valid: 78.75% Test: 86.27%\n",
      "Run: 05, Epoch: 65, Loss: 0.2138, Train: 86.67%, Valid: 78.75% Test: 88.24%\n",
      "Run: 05, Epoch: 66, Loss: 0.2878, Train: 89.17%, Valid: 80.00% Test: 92.16%\n",
      "Run: 05, Epoch: 67, Loss: 0.2436, Train: 89.17%, Valid: 80.00% Test: 92.16%\n",
      "Run: 05, Epoch: 68, Loss: 0.1589, Train: 90.00%, Valid: 81.25% Test: 92.16%\n",
      "Run: 05, Epoch: 69, Loss: 0.1944, Train: 91.67%, Valid: 81.25% Test: 90.20%\n",
      "Run: 05, Epoch: 70, Loss: 0.2206, Train: 92.50%, Valid: 83.75% Test: 88.24%\n",
      "Run: 05, Epoch: 71, Loss: 0.2360, Train: 94.17%, Valid: 85.00% Test: 86.27%\n",
      "Run: 05, Epoch: 72, Loss: 0.2508, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 05, Epoch: 73, Loss: 0.1960, Train: 95.83%, Valid: 82.50% Test: 88.24%\n",
      "Run: 05, Epoch: 74, Loss: 0.2204, Train: 96.67%, Valid: 83.75% Test: 90.20%\n",
      "Run: 05, Epoch: 75, Loss: 0.2126, Train: 96.67%, Valid: 85.00% Test: 88.24%\n",
      "Run: 05, Epoch: 76, Loss: 0.2321, Train: 95.00%, Valid: 81.25% Test: 88.24%\n",
      "Run: 05, Epoch: 77, Loss: 0.2118, Train: 95.00%, Valid: 81.25% Test: 86.27%\n",
      "Run: 05, Epoch: 78, Loss: 0.2228, Train: 96.67%, Valid: 82.50% Test: 88.24%\n",
      "Run: 05, Epoch: 79, Loss: 0.2218, Train: 96.67%, Valid: 82.50% Test: 88.24%\n",
      "Run: 05, Epoch: 80, Loss: 0.2087, Train: 96.67%, Valid: 82.50% Test: 90.20%\n",
      "Run: 05, Epoch: 81, Loss: 0.2149, Train: 95.83%, Valid: 83.75% Test: 90.20%\n",
      "Run: 05, Epoch: 82, Loss: 0.1532, Train: 96.67%, Valid: 82.50% Test: 88.24%\n",
      "Run: 05, Epoch: 83, Loss: 0.2441, Train: 96.67%, Valid: 82.50% Test: 86.27%\n",
      "Run: 05, Epoch: 84, Loss: 0.2057, Train: 97.50%, Valid: 81.25% Test: 88.24%\n",
      "Run: 05, Epoch: 85, Loss: 0.1743, Train: 97.50%, Valid: 83.75% Test: 84.31%\n",
      "Run: 05, Epoch: 86, Loss: 0.2060, Train: 96.67%, Valid: 81.25% Test: 80.39%\n",
      "Run: 05, Epoch: 87, Loss: 0.2059, Train: 95.83%, Valid: 75.00% Test: 80.39%\n",
      "Run: 05, Epoch: 88, Loss: 0.1931, Train: 94.17%, Valid: 75.00% Test: 84.31%\n",
      "Run: 05, Epoch: 89, Loss: 0.2158, Train: 96.67%, Valid: 77.50% Test: 84.31%\n",
      "Run: 05, Epoch: 90, Loss: 0.2102, Train: 97.50%, Valid: 77.50% Test: 84.31%\n",
      "Run: 05, Epoch: 91, Loss: 0.2553, Train: 96.67%, Valid: 78.75% Test: 84.31%\n",
      "Run: 05, Epoch: 92, Loss: 0.2116, Train: 96.67%, Valid: 82.50% Test: 88.24%\n",
      "Run: 05, Epoch: 93, Loss: 0.1866, Train: 96.67%, Valid: 85.00% Test: 88.24%\n",
      "Run: 05, Epoch: 94, Loss: 0.2263, Train: 96.67%, Valid: 85.00% Test: 90.20%\n",
      "Run: 05, Epoch: 95, Loss: 0.1724, Train: 95.00%, Valid: 85.00% Test: 92.16%\n",
      "Run: 05, Epoch: 96, Loss: 0.1881, Train: 96.67%, Valid: 85.00% Test: 96.08%\n",
      "Run: 05, Epoch: 97, Loss: 0.1597, Train: 96.67%, Valid: 86.25% Test: 98.04%\n",
      "Run: 05, Epoch: 98, Loss: 0.1957, Train: 97.50%, Valid: 83.75% Test: 98.04%\n",
      "Run: 05, Epoch: 99, Loss: 0.1566, Train: 96.67%, Valid: 80.00% Test: 88.24%\n",
      "Run: 05, Epoch: 100, Loss: 0.1630, Train: 95.83%, Valid: 76.25% Test: 90.20%\n",
      "Run 05:\n",
      "Highest Train: 97.50\n",
      "Highest Valid: 86.25\n",
      "  Final Train: 96.67\n",
      "   Final Test: 98.04\n",
      "Run: 06, Epoch: 01, Loss: 1.6573, Train: 54.17%, Valid: 47.50% Test: 50.98%\n",
      "Run: 06, Epoch: 02, Loss: 1.4260, Train: 53.33%, Valid: 43.75% Test: 45.10%\n",
      "Run: 06, Epoch: 03, Loss: 1.2566, Train: 62.50%, Valid: 48.75% Test: 47.06%\n",
      "Run: 06, Epoch: 04, Loss: 1.1480, Train: 66.67%, Valid: 48.75% Test: 49.02%\n",
      "Run: 06, Epoch: 05, Loss: 1.1064, Train: 65.83%, Valid: 50.00% Test: 49.02%\n",
      "Run: 06, Epoch: 06, Loss: 1.0903, Train: 64.17%, Valid: 52.50% Test: 50.98%\n",
      "Run: 06, Epoch: 07, Loss: 1.0124, Train: 66.67%, Valid: 52.50% Test: 54.90%\n",
      "Run: 06, Epoch: 08, Loss: 0.9150, Train: 69.17%, Valid: 53.75% Test: 54.90%\n",
      "Run: 06, Epoch: 09, Loss: 0.8582, Train: 71.67%, Valid: 56.25% Test: 58.82%\n",
      "Run: 06, Epoch: 10, Loss: 0.9087, Train: 74.17%, Valid: 58.75% Test: 58.82%\n",
      "Run: 06, Epoch: 11, Loss: 0.8928, Train: 73.33%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 12, Loss: 0.8568, Train: 71.67%, Valid: 67.50% Test: 62.75%\n",
      "Run: 06, Epoch: 13, Loss: 0.8383, Train: 71.67%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 14, Loss: 0.7895, Train: 75.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 15, Loss: 0.7266, Train: 74.17%, Valid: 72.50% Test: 68.63%\n",
      "Run: 06, Epoch: 16, Loss: 0.7037, Train: 76.67%, Valid: 76.25% Test: 68.63%\n",
      "Run: 06, Epoch: 17, Loss: 0.6794, Train: 75.83%, Valid: 77.50% Test: 68.63%\n",
      "Run: 06, Epoch: 18, Loss: 0.6292, Train: 75.83%, Valid: 76.25% Test: 68.63%\n",
      "Run: 06, Epoch: 19, Loss: 0.6048, Train: 75.00%, Valid: 76.25% Test: 66.67%\n",
      "Run: 06, Epoch: 20, Loss: 0.6368, Train: 76.67%, Valid: 77.50% Test: 66.67%\n",
      "Run: 06, Epoch: 21, Loss: 0.5976, Train: 80.00%, Valid: 75.00% Test: 66.67%\n",
      "Run: 06, Epoch: 22, Loss: 0.5563, Train: 81.67%, Valid: 77.50% Test: 66.67%\n",
      "Run: 06, Epoch: 23, Loss: 0.6059, Train: 82.50%, Valid: 73.75% Test: 66.67%\n",
      "Run: 06, Epoch: 24, Loss: 0.5403, Train: 83.33%, Valid: 76.25% Test: 68.63%\n",
      "Run: 06, Epoch: 25, Loss: 0.4888, Train: 81.67%, Valid: 73.75% Test: 72.55%\n",
      "Run: 06, Epoch: 26, Loss: 0.4505, Train: 84.17%, Valid: 72.50% Test: 72.55%\n",
      "Run: 06, Epoch: 27, Loss: 0.5124, Train: 86.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 06, Epoch: 28, Loss: 0.4230, Train: 88.33%, Valid: 80.00% Test: 74.51%\n",
      "Run: 06, Epoch: 29, Loss: 0.5019, Train: 87.50%, Valid: 82.50% Test: 74.51%\n",
      "Run: 06, Epoch: 30, Loss: 0.5304, Train: 87.50%, Valid: 82.50% Test: 74.51%\n",
      "Run: 06, Epoch: 31, Loss: 0.4411, Train: 85.83%, Valid: 82.50% Test: 74.51%\n",
      "Run: 06, Epoch: 32, Loss: 0.4434, Train: 86.67%, Valid: 81.25% Test: 74.51%\n",
      "Run: 06, Epoch: 33, Loss: 0.4421, Train: 88.33%, Valid: 82.50% Test: 72.55%\n",
      "Run: 06, Epoch: 34, Loss: 0.4515, Train: 88.33%, Valid: 85.00% Test: 72.55%\n",
      "Run: 06, Epoch: 35, Loss: 0.3754, Train: 90.83%, Valid: 87.50% Test: 74.51%\n",
      "Run: 06, Epoch: 36, Loss: 0.4160, Train: 90.00%, Valid: 88.75% Test: 78.43%\n",
      "Run: 06, Epoch: 37, Loss: 0.3458, Train: 91.67%, Valid: 90.00% Test: 76.47%\n",
      "Run: 06, Epoch: 38, Loss: 0.3779, Train: 90.00%, Valid: 86.25% Test: 74.51%\n",
      "Run: 06, Epoch: 39, Loss: 0.4573, Train: 88.33%, Valid: 83.75% Test: 74.51%\n",
      "Run: 06, Epoch: 40, Loss: 0.3866, Train: 89.17%, Valid: 82.50% Test: 74.51%\n",
      "Run: 06, Epoch: 41, Loss: 0.4271, Train: 90.00%, Valid: 81.25% Test: 72.55%\n",
      "Run: 06, Epoch: 42, Loss: 0.3385, Train: 90.83%, Valid: 80.00% Test: 72.55%\n",
      "Run: 06, Epoch: 43, Loss: 0.3642, Train: 88.33%, Valid: 80.00% Test: 70.59%\n",
      "Run: 06, Epoch: 44, Loss: 0.3715, Train: 88.33%, Valid: 81.25% Test: 68.63%\n",
      "Run: 06, Epoch: 45, Loss: 0.3574, Train: 87.50%, Valid: 81.25% Test: 66.67%\n",
      "Run: 06, Epoch: 46, Loss: 0.3960, Train: 87.50%, Valid: 82.50% Test: 66.67%\n",
      "Run: 06, Epoch: 47, Loss: 0.3045, Train: 90.00%, Valid: 81.25% Test: 66.67%\n",
      "Run: 06, Epoch: 48, Loss: 0.3653, Train: 88.33%, Valid: 83.75% Test: 68.63%\n",
      "Run: 06, Epoch: 49, Loss: 0.3137, Train: 90.00%, Valid: 86.25% Test: 74.51%\n",
      "Run: 06, Epoch: 50, Loss: 0.3055, Train: 89.17%, Valid: 85.00% Test: 80.39%\n",
      "Run: 06, Epoch: 51, Loss: 0.3341, Train: 90.00%, Valid: 86.25% Test: 80.39%\n",
      "Run: 06, Epoch: 52, Loss: 0.3759, Train: 91.67%, Valid: 86.25% Test: 78.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 53, Loss: 0.3297, Train: 91.67%, Valid: 85.00% Test: 76.47%\n",
      "Run: 06, Epoch: 54, Loss: 0.4072, Train: 92.50%, Valid: 85.00% Test: 78.43%\n",
      "Run: 06, Epoch: 55, Loss: 0.2803, Train: 92.50%, Valid: 86.25% Test: 78.43%\n",
      "Run: 06, Epoch: 56, Loss: 0.2691, Train: 94.17%, Valid: 87.50% Test: 78.43%\n",
      "Run: 06, Epoch: 57, Loss: 0.2531, Train: 93.33%, Valid: 87.50% Test: 80.39%\n",
      "Run: 06, Epoch: 58, Loss: 0.3567, Train: 90.00%, Valid: 87.50% Test: 78.43%\n",
      "Run: 06, Epoch: 59, Loss: 0.4147, Train: 89.17%, Valid: 87.50% Test: 76.47%\n",
      "Run: 06, Epoch: 60, Loss: 0.3090, Train: 89.17%, Valid: 87.50% Test: 74.51%\n",
      "Run: 06, Epoch: 61, Loss: 0.2594, Train: 90.83%, Valid: 87.50% Test: 76.47%\n",
      "Run: 06, Epoch: 62, Loss: 0.2814, Train: 90.83%, Valid: 88.75% Test: 78.43%\n",
      "Run: 06, Epoch: 63, Loss: 0.2999, Train: 91.67%, Valid: 90.00% Test: 78.43%\n",
      "Run: 06, Epoch: 64, Loss: 0.2127, Train: 92.50%, Valid: 91.25% Test: 78.43%\n",
      "Run: 06, Epoch: 65, Loss: 0.2840, Train: 92.50%, Valid: 92.50% Test: 78.43%\n",
      "Run: 06, Epoch: 66, Loss: 0.2591, Train: 92.50%, Valid: 88.75% Test: 78.43%\n",
      "Run: 06, Epoch: 67, Loss: 0.2467, Train: 92.50%, Valid: 90.00% Test: 78.43%\n",
      "Run: 06, Epoch: 68, Loss: 0.2751, Train: 92.50%, Valid: 88.75% Test: 74.51%\n",
      "Run: 06, Epoch: 69, Loss: 0.2853, Train: 94.17%, Valid: 86.25% Test: 76.47%\n",
      "Run: 06, Epoch: 70, Loss: 0.3007, Train: 94.17%, Valid: 86.25% Test: 78.43%\n",
      "Run: 06, Epoch: 71, Loss: 0.2890, Train: 93.33%, Valid: 86.25% Test: 74.51%\n",
      "Run: 06, Epoch: 72, Loss: 0.2257, Train: 92.50%, Valid: 83.75% Test: 72.55%\n",
      "Run: 06, Epoch: 73, Loss: 0.2048, Train: 91.67%, Valid: 81.25% Test: 70.59%\n",
      "Run: 06, Epoch: 74, Loss: 0.1987, Train: 89.17%, Valid: 81.25% Test: 68.63%\n",
      "Run: 06, Epoch: 75, Loss: 0.2562, Train: 88.33%, Valid: 81.25% Test: 68.63%\n",
      "Run: 06, Epoch: 76, Loss: 0.2246, Train: 87.50%, Valid: 80.00% Test: 68.63%\n",
      "Run: 06, Epoch: 77, Loss: 0.2126, Train: 89.17%, Valid: 80.00% Test: 70.59%\n",
      "Run: 06, Epoch: 78, Loss: 0.2006, Train: 90.00%, Valid: 82.50% Test: 72.55%\n",
      "Run: 06, Epoch: 79, Loss: 0.2712, Train: 91.67%, Valid: 83.75% Test: 72.55%\n",
      "Run: 06, Epoch: 80, Loss: 0.2652, Train: 93.33%, Valid: 86.25% Test: 74.51%\n",
      "Run: 06, Epoch: 81, Loss: 0.2181, Train: 94.17%, Valid: 86.25% Test: 78.43%\n",
      "Run: 06, Epoch: 82, Loss: 0.2254, Train: 94.17%, Valid: 90.00% Test: 80.39%\n",
      "Run: 06, Epoch: 83, Loss: 0.2129, Train: 94.17%, Valid: 88.75% Test: 78.43%\n",
      "Run: 06, Epoch: 84, Loss: 0.2388, Train: 95.00%, Valid: 90.00% Test: 80.39%\n",
      "Run: 06, Epoch: 85, Loss: 0.2372, Train: 94.17%, Valid: 91.25% Test: 82.35%\n",
      "Run: 06, Epoch: 86, Loss: 0.2059, Train: 95.00%, Valid: 88.75% Test: 82.35%\n",
      "Run: 06, Epoch: 87, Loss: 0.2595, Train: 96.67%, Valid: 92.50% Test: 88.24%\n",
      "Run: 06, Epoch: 88, Loss: 0.1743, Train: 96.67%, Valid: 93.75% Test: 86.27%\n",
      "Run: 06, Epoch: 89, Loss: 0.2798, Train: 95.00%, Valid: 91.25% Test: 84.31%\n",
      "Run: 06, Epoch: 90, Loss: 0.1847, Train: 93.33%, Valid: 90.00% Test: 84.31%\n",
      "Run: 06, Epoch: 91, Loss: 0.1771, Train: 94.17%, Valid: 90.00% Test: 86.27%\n",
      "Run: 06, Epoch: 92, Loss: 0.2234, Train: 94.17%, Valid: 91.25% Test: 86.27%\n",
      "Run: 06, Epoch: 93, Loss: 0.2704, Train: 96.67%, Valid: 91.25% Test: 82.35%\n",
      "Run: 06, Epoch: 94, Loss: 0.2015, Train: 97.50%, Valid: 90.00% Test: 78.43%\n",
      "Run: 06, Epoch: 95, Loss: 0.1294, Train: 96.67%, Valid: 85.00% Test: 74.51%\n",
      "Run: 06, Epoch: 96, Loss: 0.2051, Train: 95.00%, Valid: 83.75% Test: 74.51%\n",
      "Run: 06, Epoch: 97, Loss: 0.2458, Train: 91.67%, Valid: 83.75% Test: 72.55%\n",
      "Run: 06, Epoch: 98, Loss: 0.1843, Train: 91.67%, Valid: 83.75% Test: 72.55%\n",
      "Run: 06, Epoch: 99, Loss: 0.2589, Train: 92.50%, Valid: 85.00% Test: 74.51%\n",
      "Run: 06, Epoch: 100, Loss: 0.1663, Train: 94.17%, Valid: 86.25% Test: 74.51%\n",
      "Run 06:\n",
      "Highest Train: 97.50\n",
      "Highest Valid: 93.75\n",
      "  Final Train: 96.67\n",
      "   Final Test: 86.27\n",
      "Run: 07, Epoch: 01, Loss: 1.8531, Train: 41.67%, Valid: 43.75% Test: 45.10%\n",
      "Run: 07, Epoch: 02, Loss: 1.5647, Train: 49.17%, Valid: 52.50% Test: 49.02%\n",
      "Run: 07, Epoch: 03, Loss: 1.3574, Train: 48.33%, Valid: 51.25% Test: 50.98%\n",
      "Run: 07, Epoch: 04, Loss: 1.3058, Train: 53.33%, Valid: 55.00% Test: 56.86%\n",
      "Run: 07, Epoch: 05, Loss: 1.1477, Train: 59.17%, Valid: 58.75% Test: 60.78%\n",
      "Run: 07, Epoch: 06, Loss: 1.0563, Train: 64.17%, Valid: 63.75% Test: 64.71%\n",
      "Run: 07, Epoch: 07, Loss: 1.0012, Train: 68.33%, Valid: 67.50% Test: 66.67%\n",
      "Run: 07, Epoch: 08, Loss: 0.9696, Train: 71.67%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 09, Loss: 0.9130, Train: 73.33%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 10, Loss: 0.8627, Train: 74.17%, Valid: 66.25% Test: 70.59%\n",
      "Run: 07, Epoch: 11, Loss: 0.8988, Train: 71.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 07, Epoch: 12, Loss: 0.8572, Train: 70.00%, Valid: 63.75% Test: 58.82%\n",
      "Run: 07, Epoch: 13, Loss: 0.7891, Train: 68.33%, Valid: 66.25% Test: 62.75%\n",
      "Run: 07, Epoch: 14, Loss: 0.8183, Train: 70.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 07, Epoch: 15, Loss: 0.7419, Train: 69.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 16, Loss: 0.7184, Train: 69.17%, Valid: 63.75% Test: 68.63%\n",
      "Run: 07, Epoch: 17, Loss: 0.7740, Train: 68.33%, Valid: 63.75% Test: 68.63%\n",
      "Run: 07, Epoch: 18, Loss: 0.6563, Train: 65.83%, Valid: 62.50% Test: 68.63%\n",
      "Run: 07, Epoch: 19, Loss: 0.7013, Train: 65.83%, Valid: 61.25% Test: 66.67%\n",
      "Run: 07, Epoch: 20, Loss: 0.6579, Train: 66.67%, Valid: 61.25% Test: 62.75%\n",
      "Run: 07, Epoch: 21, Loss: 0.6360, Train: 67.50%, Valid: 65.00% Test: 68.63%\n",
      "Run: 07, Epoch: 22, Loss: 0.6142, Train: 70.83%, Valid: 66.25% Test: 70.59%\n",
      "Run: 07, Epoch: 23, Loss: 0.5490, Train: 71.67%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 24, Loss: 0.5820, Train: 72.50%, Valid: 71.25% Test: 70.59%\n",
      "Run: 07, Epoch: 25, Loss: 0.5654, Train: 70.83%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 26, Loss: 0.4775, Train: 69.17%, Valid: 66.25% Test: 66.67%\n",
      "Run: 07, Epoch: 27, Loss: 0.5075, Train: 70.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 07, Epoch: 28, Loss: 0.4266, Train: 70.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 07, Epoch: 29, Loss: 0.5046, Train: 74.17%, Valid: 72.50% Test: 74.51%\n",
      "Run: 07, Epoch: 30, Loss: 0.4226, Train: 76.67%, Valid: 72.50% Test: 78.43%\n",
      "Run: 07, Epoch: 31, Loss: 0.4206, Train: 78.33%, Valid: 71.25% Test: 78.43%\n",
      "Run: 07, Epoch: 32, Loss: 0.4367, Train: 76.67%, Valid: 71.25% Test: 76.47%\n",
      "Run: 07, Epoch: 33, Loss: 0.4089, Train: 76.67%, Valid: 71.25% Test: 76.47%\n",
      "Run: 07, Epoch: 34, Loss: 0.3912, Train: 75.83%, Valid: 71.25% Test: 74.51%\n",
      "Run: 07, Epoch: 35, Loss: 0.4079, Train: 75.83%, Valid: 71.25% Test: 78.43%\n",
      "Run: 07, Epoch: 36, Loss: 0.3358, Train: 80.00%, Valid: 75.00% Test: 78.43%\n",
      "Run: 07, Epoch: 37, Loss: 0.4049, Train: 82.50%, Valid: 76.25% Test: 78.43%\n",
      "Run: 07, Epoch: 38, Loss: 0.3499, Train: 85.83%, Valid: 77.50% Test: 80.39%\n",
      "Run: 07, Epoch: 39, Loss: 0.3401, Train: 86.67%, Valid: 77.50% Test: 82.35%\n",
      "Run: 07, Epoch: 40, Loss: 0.4262, Train: 90.83%, Valid: 77.50% Test: 82.35%\n",
      "Run: 07, Epoch: 41, Loss: 0.2966, Train: 90.83%, Valid: 77.50% Test: 88.24%\n",
      "Run: 07, Epoch: 42, Loss: 0.3231, Train: 88.33%, Valid: 77.50% Test: 82.35%\n",
      "Run: 07, Epoch: 43, Loss: 0.3222, Train: 85.83%, Valid: 77.50% Test: 82.35%\n",
      "Run: 07, Epoch: 44, Loss: 0.2422, Train: 84.17%, Valid: 77.50% Test: 82.35%\n",
      "Run: 07, Epoch: 45, Loss: 0.3051, Train: 82.50%, Valid: 76.25% Test: 82.35%\n",
      "Run: 07, Epoch: 46, Loss: 0.2737, Train: 82.50%, Valid: 75.00% Test: 78.43%\n",
      "Run: 07, Epoch: 47, Loss: 0.2469, Train: 84.17%, Valid: 76.25% Test: 80.39%\n",
      "Run: 07, Epoch: 48, Loss: 0.2799, Train: 87.50%, Valid: 76.25% Test: 82.35%\n",
      "Run: 07, Epoch: 49, Loss: 0.2169, Train: 88.33%, Valid: 76.25% Test: 82.35%\n",
      "Run: 07, Epoch: 50, Loss: 0.2560, Train: 88.33%, Valid: 73.75% Test: 84.31%\n",
      "Run: 07, Epoch: 51, Loss: 0.1942, Train: 86.67%, Valid: 72.50% Test: 80.39%\n",
      "Run: 07, Epoch: 52, Loss: 0.3172, Train: 85.83%, Valid: 72.50% Test: 78.43%\n",
      "Run: 07, Epoch: 53, Loss: 0.2432, Train: 87.50%, Valid: 76.25% Test: 80.39%\n",
      "Run: 07, Epoch: 54, Loss: 0.2844, Train: 90.83%, Valid: 76.25% Test: 82.35%\n",
      "Run: 07, Epoch: 55, Loss: 0.2327, Train: 95.00%, Valid: 80.00% Test: 88.24%\n",
      "Run: 07, Epoch: 56, Loss: 0.2535, Train: 94.17%, Valid: 82.50% Test: 90.20%\n",
      "Run: 07, Epoch: 57, Loss: 0.2371, Train: 93.33%, Valid: 82.50% Test: 88.24%\n",
      "Run: 07, Epoch: 58, Loss: 0.1987, Train: 93.33%, Valid: 83.75% Test: 88.24%\n",
      "Run: 07, Epoch: 59, Loss: 0.2321, Train: 91.67%, Valid: 82.50% Test: 84.31%\n",
      "Run: 07, Epoch: 60, Loss: 0.2190, Train: 90.00%, Valid: 81.25% Test: 84.31%\n",
      "Run: 07, Epoch: 61, Loss: 0.1967, Train: 89.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 07, Epoch: 62, Loss: 0.2424, Train: 89.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 07, Epoch: 63, Loss: 0.2662, Train: 90.83%, Valid: 81.25% Test: 84.31%\n",
      "Run: 07, Epoch: 64, Loss: 0.2073, Train: 92.50%, Valid: 80.00% Test: 86.27%\n",
      "Run: 07, Epoch: 65, Loss: 0.2345, Train: 95.00%, Valid: 81.25% Test: 84.31%\n",
      "Run: 07, Epoch: 66, Loss: 0.1512, Train: 95.00%, Valid: 80.00% Test: 84.31%\n",
      "Run: 07, Epoch: 67, Loss: 0.2300, Train: 92.50%, Valid: 80.00% Test: 84.31%\n",
      "Run: 07, Epoch: 68, Loss: 0.1899, Train: 91.67%, Valid: 78.75% Test: 84.31%\n",
      "Run: 07, Epoch: 69, Loss: 0.2668, Train: 91.67%, Valid: 80.00% Test: 86.27%\n",
      "Run: 07, Epoch: 70, Loss: 0.1809, Train: 92.50%, Valid: 80.00% Test: 86.27%\n",
      "Run: 07, Epoch: 71, Loss: 0.1759, Train: 94.17%, Valid: 80.00% Test: 90.20%\n",
      "Run: 07, Epoch: 72, Loss: 0.1749, Train: 94.17%, Valid: 81.25% Test: 88.24%\n",
      "Run: 07, Epoch: 73, Loss: 0.1612, Train: 94.17%, Valid: 82.50% Test: 88.24%\n",
      "Run: 07, Epoch: 74, Loss: 0.1918, Train: 95.00%, Valid: 83.75% Test: 88.24%\n",
      "Run: 07, Epoch: 75, Loss: 0.1879, Train: 94.17%, Valid: 83.75% Test: 84.31%\n",
      "Run: 07, Epoch: 76, Loss: 0.1894, Train: 93.33%, Valid: 83.75% Test: 84.31%\n",
      "Run: 07, Epoch: 77, Loss: 0.1742, Train: 95.00%, Valid: 86.25% Test: 86.27%\n",
      "Run: 07, Epoch: 78, Loss: 0.1704, Train: 95.00%, Valid: 87.50% Test: 86.27%\n",
      "Run: 07, Epoch: 79, Loss: 0.1872, Train: 97.50%, Valid: 87.50% Test: 90.20%\n",
      "Run: 07, Epoch: 80, Loss: 0.1268, Train: 97.50%, Valid: 88.75% Test: 90.20%\n",
      "Run: 07, Epoch: 81, Loss: 0.1283, Train: 97.50%, Valid: 90.00% Test: 92.16%\n",
      "Run: 07, Epoch: 82, Loss: 0.2058, Train: 97.50%, Valid: 86.25% Test: 92.16%\n",
      "Run: 07, Epoch: 83, Loss: 0.1822, Train: 94.17%, Valid: 86.25% Test: 88.24%\n",
      "Run: 07, Epoch: 84, Loss: 0.1655, Train: 94.17%, Valid: 83.75% Test: 86.27%\n",
      "Run: 07, Epoch: 85, Loss: 0.1993, Train: 94.17%, Valid: 85.00% Test: 86.27%\n",
      "Run: 07, Epoch: 86, Loss: 0.1666, Train: 95.83%, Valid: 85.00% Test: 88.24%\n",
      "Run: 07, Epoch: 87, Loss: 0.1187, Train: 95.00%, Valid: 86.25% Test: 86.27%\n",
      "Run: 07, Epoch: 88, Loss: 0.1198, Train: 94.17%, Valid: 85.00% Test: 88.24%\n",
      "Run: 07, Epoch: 89, Loss: 0.1266, Train: 94.17%, Valid: 83.75% Test: 88.24%\n",
      "Run: 07, Epoch: 90, Loss: 0.1426, Train: 95.83%, Valid: 83.75% Test: 88.24%\n",
      "Run: 07, Epoch: 91, Loss: 0.1341, Train: 95.83%, Valid: 86.25% Test: 88.24%\n",
      "Run: 07, Epoch: 92, Loss: 0.1453, Train: 97.50%, Valid: 87.50% Test: 88.24%\n",
      "Run: 07, Epoch: 93, Loss: 0.1525, Train: 98.33%, Valid: 87.50% Test: 90.20%\n",
      "Run: 07, Epoch: 94, Loss: 0.1356, Train: 98.33%, Valid: 86.25% Test: 90.20%\n",
      "Run: 07, Epoch: 95, Loss: 0.1305, Train: 99.17%, Valid: 86.25% Test: 88.24%\n",
      "Run: 07, Epoch: 96, Loss: 0.1265, Train: 99.17%, Valid: 86.25% Test: 86.27%\n",
      "Run: 07, Epoch: 97, Loss: 0.1566, Train: 97.50%, Valid: 87.50% Test: 84.31%\n",
      "Run: 07, Epoch: 98, Loss: 0.1365, Train: 97.50%, Valid: 85.00% Test: 84.31%\n",
      "Run: 07, Epoch: 99, Loss: 0.1147, Train: 96.67%, Valid: 86.25% Test: 84.31%\n",
      "Run: 07, Epoch: 100, Loss: 0.1250, Train: 95.83%, Valid: 86.25% Test: 84.31%\n",
      "Run 07:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 90.00\n",
      "  Final Train: 97.50\n",
      "   Final Test: 92.16\n",
      "Run: 08, Epoch: 01, Loss: 1.8957, Train: 48.33%, Valid: 55.00% Test: 50.98%\n",
      "Run: 08, Epoch: 02, Loss: 1.6460, Train: 52.50%, Valid: 51.25% Test: 52.94%\n",
      "Run: 08, Epoch: 03, Loss: 1.4915, Train: 57.50%, Valid: 56.25% Test: 54.90%\n",
      "Run: 08, Epoch: 04, Loss: 1.3255, Train: 57.50%, Valid: 57.50% Test: 52.94%\n",
      "Run: 08, Epoch: 05, Loss: 1.2526, Train: 57.50%, Valid: 52.50% Test: 54.90%\n",
      "Run: 08, Epoch: 06, Loss: 1.2072, Train: 45.83%, Valid: 36.25% Test: 49.02%\n",
      "Run: 08, Epoch: 07, Loss: 1.1406, Train: 37.50%, Valid: 31.25% Test: 37.25%\n",
      "Run: 08, Epoch: 08, Loss: 1.0891, Train: 36.67%, Valid: 25.00% Test: 29.41%\n",
      "Run: 08, Epoch: 09, Loss: 1.0839, Train: 37.50%, Valid: 26.25% Test: 27.45%\n",
      "Run: 08, Epoch: 10, Loss: 1.0532, Train: 40.83%, Valid: 28.75% Test: 27.45%\n",
      "Run: 08, Epoch: 11, Loss: 1.0335, Train: 44.17%, Valid: 32.50% Test: 33.33%\n",
      "Run: 08, Epoch: 12, Loss: 1.0342, Train: 50.00%, Valid: 41.25% Test: 37.25%\n",
      "Run: 08, Epoch: 13, Loss: 0.9192, Train: 56.67%, Valid: 51.25% Test: 47.06%\n",
      "Run: 08, Epoch: 14, Loss: 0.9238, Train: 58.33%, Valid: 53.75% Test: 43.14%\n",
      "Run: 08, Epoch: 15, Loss: 0.9181, Train: 60.00%, Valid: 51.25% Test: 45.10%\n",
      "Run: 08, Epoch: 16, Loss: 0.9212, Train: 60.00%, Valid: 55.00% Test: 49.02%\n",
      "Run: 08, Epoch: 17, Loss: 0.8598, Train: 63.33%, Valid: 57.50% Test: 54.90%\n",
      "Run: 08, Epoch: 18, Loss: 0.8391, Train: 65.83%, Valid: 62.50% Test: 58.82%\n",
      "Run: 08, Epoch: 19, Loss: 0.8035, Train: 64.17%, Valid: 63.75% Test: 52.94%\n",
      "Run: 08, Epoch: 20, Loss: 0.7645, Train: 63.33%, Valid: 61.25% Test: 54.90%\n",
      "Run: 08, Epoch: 21, Loss: 0.7428, Train: 63.33%, Valid: 60.00% Test: 54.90%\n",
      "Run: 08, Epoch: 22, Loss: 0.6633, Train: 63.33%, Valid: 58.75% Test: 54.90%\n",
      "Run: 08, Epoch: 23, Loss: 0.6981, Train: 65.00%, Valid: 62.50% Test: 58.82%\n",
      "Run: 08, Epoch: 24, Loss: 0.6822, Train: 67.50%, Valid: 66.25% Test: 58.82%\n",
      "Run: 08, Epoch: 25, Loss: 0.7265, Train: 74.17%, Valid: 73.75% Test: 60.78%\n",
      "Run: 08, Epoch: 26, Loss: 0.6809, Train: 80.00%, Valid: 75.00% Test: 72.55%\n",
      "Run: 08, Epoch: 27, Loss: 0.6804, Train: 81.67%, Valid: 77.50% Test: 78.43%\n",
      "Run: 08, Epoch: 28, Loss: 0.6633, Train: 81.67%, Valid: 80.00% Test: 78.43%\n",
      "Run: 08, Epoch: 29, Loss: 0.6553, Train: 81.67%, Valid: 80.00% Test: 78.43%\n",
      "Run: 08, Epoch: 30, Loss: 0.5971, Train: 80.83%, Valid: 78.75% Test: 78.43%\n",
      "Run: 08, Epoch: 31, Loss: 0.6125, Train: 80.83%, Valid: 82.50% Test: 78.43%\n",
      "Run: 08, Epoch: 32, Loss: 0.5901, Train: 81.67%, Valid: 81.25% Test: 78.43%\n",
      "Run: 08, Epoch: 33, Loss: 0.6163, Train: 79.17%, Valid: 80.00% Test: 80.39%\n",
      "Run: 08, Epoch: 34, Loss: 0.5794, Train: 80.83%, Valid: 78.75% Test: 80.39%\n",
      "Run: 08, Epoch: 35, Loss: 0.5676, Train: 80.83%, Valid: 80.00% Test: 76.47%\n",
      "Run: 08, Epoch: 36, Loss: 0.4900, Train: 80.83%, Valid: 78.75% Test: 76.47%\n",
      "Run: 08, Epoch: 37, Loss: 0.5650, Train: 80.83%, Valid: 80.00% Test: 78.43%\n",
      "Run: 08, Epoch: 38, Loss: 0.5847, Train: 81.67%, Valid: 81.25% Test: 78.43%\n",
      "Run: 08, Epoch: 39, Loss: 0.4889, Train: 83.33%, Valid: 82.50% Test: 78.43%\n",
      "Run: 08, Epoch: 40, Loss: 0.4752, Train: 83.33%, Valid: 82.50% Test: 74.51%\n",
      "Run: 08, Epoch: 41, Loss: 0.4641, Train: 83.33%, Valid: 78.75% Test: 76.47%\n",
      "Run: 08, Epoch: 42, Loss: 0.5018, Train: 81.67%, Valid: 75.00% Test: 76.47%\n",
      "Run: 08, Epoch: 43, Loss: 0.4479, Train: 83.33%, Valid: 76.25% Test: 76.47%\n",
      "Run: 08, Epoch: 44, Loss: 0.4359, Train: 85.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 08, Epoch: 45, Loss: 0.4393, Train: 85.00%, Valid: 88.75% Test: 78.43%\n",
      "Run: 08, Epoch: 46, Loss: 0.4880, Train: 84.17%, Valid: 87.50% Test: 78.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 47, Loss: 0.4655, Train: 84.17%, Valid: 86.25% Test: 80.39%\n",
      "Run: 08, Epoch: 48, Loss: 0.4149, Train: 83.33%, Valid: 85.00% Test: 80.39%\n",
      "Run: 08, Epoch: 49, Loss: 0.4410, Train: 85.00%, Valid: 82.50% Test: 82.35%\n",
      "Run: 08, Epoch: 50, Loss: 0.4148, Train: 86.67%, Valid: 86.25% Test: 82.35%\n",
      "Run: 08, Epoch: 51, Loss: 0.3686, Train: 86.67%, Valid: 87.50% Test: 86.27%\n",
      "Run: 08, Epoch: 52, Loss: 0.3979, Train: 86.67%, Valid: 87.50% Test: 86.27%\n",
      "Run: 08, Epoch: 53, Loss: 0.4111, Train: 86.67%, Valid: 88.75% Test: 88.24%\n",
      "Run: 08, Epoch: 54, Loss: 0.3829, Train: 87.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 08, Epoch: 55, Loss: 0.3689, Train: 87.50%, Valid: 90.00% Test: 88.24%\n",
      "Run: 08, Epoch: 56, Loss: 0.3461, Train: 87.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 08, Epoch: 57, Loss: 0.3439, Train: 88.33%, Valid: 85.00% Test: 90.20%\n",
      "Run: 08, Epoch: 58, Loss: 0.3954, Train: 86.67%, Valid: 87.50% Test: 90.20%\n",
      "Run: 08, Epoch: 59, Loss: 0.3751, Train: 88.33%, Valid: 90.00% Test: 92.16%\n",
      "Run: 08, Epoch: 60, Loss: 0.3266, Train: 86.67%, Valid: 91.25% Test: 90.20%\n",
      "Run: 08, Epoch: 61, Loss: 0.4097, Train: 88.33%, Valid: 91.25% Test: 86.27%\n",
      "Run: 08, Epoch: 62, Loss: 0.3762, Train: 86.67%, Valid: 90.00% Test: 82.35%\n",
      "Run: 08, Epoch: 63, Loss: 0.3539, Train: 86.67%, Valid: 88.75% Test: 82.35%\n",
      "Run: 08, Epoch: 64, Loss: 0.3808, Train: 87.50%, Valid: 87.50% Test: 84.31%\n",
      "Run: 08, Epoch: 65, Loss: 0.4300, Train: 86.67%, Valid: 88.75% Test: 84.31%\n",
      "Run: 08, Epoch: 66, Loss: 0.3616, Train: 89.17%, Valid: 87.50% Test: 84.31%\n",
      "Run: 08, Epoch: 67, Loss: 0.3120, Train: 87.50%, Valid: 87.50% Test: 86.27%\n",
      "Run: 08, Epoch: 68, Loss: 0.3103, Train: 87.50%, Valid: 90.00% Test: 84.31%\n",
      "Run: 08, Epoch: 69, Loss: 0.3754, Train: 87.50%, Valid: 90.00% Test: 86.27%\n",
      "Run: 08, Epoch: 70, Loss: 0.2709, Train: 88.33%, Valid: 88.75% Test: 86.27%\n",
      "Run: 08, Epoch: 71, Loss: 0.3338, Train: 88.33%, Valid: 90.00% Test: 86.27%\n",
      "Run: 08, Epoch: 72, Loss: 0.3773, Train: 89.17%, Valid: 90.00% Test: 88.24%\n",
      "Run: 08, Epoch: 73, Loss: 0.3285, Train: 90.83%, Valid: 91.25% Test: 88.24%\n",
      "Run: 08, Epoch: 74, Loss: 0.3198, Train: 87.50%, Valid: 91.25% Test: 86.27%\n",
      "Run: 08, Epoch: 75, Loss: 0.3176, Train: 86.67%, Valid: 88.75% Test: 82.35%\n",
      "Run: 08, Epoch: 76, Loss: 0.3047, Train: 85.83%, Valid: 85.00% Test: 78.43%\n",
      "Run: 08, Epoch: 77, Loss: 0.2894, Train: 86.67%, Valid: 87.50% Test: 80.39%\n",
      "Run: 08, Epoch: 78, Loss: 0.2785, Train: 90.83%, Valid: 92.50% Test: 86.27%\n",
      "Run: 08, Epoch: 79, Loss: 0.2820, Train: 92.50%, Valid: 91.25% Test: 88.24%\n",
      "Run: 08, Epoch: 80, Loss: 0.3299, Train: 91.67%, Valid: 90.00% Test: 86.27%\n",
      "Run: 08, Epoch: 81, Loss: 0.3022, Train: 90.83%, Valid: 90.00% Test: 82.35%\n",
      "Run: 08, Epoch: 82, Loss: 0.3276, Train: 90.83%, Valid: 88.75% Test: 82.35%\n",
      "Run: 08, Epoch: 83, Loss: 0.2784, Train: 92.50%, Valid: 90.00% Test: 86.27%\n",
      "Run: 08, Epoch: 84, Loss: 0.2927, Train: 92.50%, Valid: 91.25% Test: 88.24%\n",
      "Run: 08, Epoch: 85, Loss: 0.2726, Train: 92.50%, Valid: 91.25% Test: 88.24%\n",
      "Run: 08, Epoch: 86, Loss: 0.2892, Train: 94.17%, Valid: 92.50% Test: 86.27%\n",
      "Run: 08, Epoch: 87, Loss: 0.2627, Train: 94.17%, Valid: 91.25% Test: 86.27%\n",
      "Run: 08, Epoch: 88, Loss: 0.2736, Train: 93.33%, Valid: 92.50% Test: 88.24%\n",
      "Run: 08, Epoch: 89, Loss: 0.2486, Train: 88.33%, Valid: 91.25% Test: 88.24%\n",
      "Run: 08, Epoch: 90, Loss: 0.2797, Train: 89.17%, Valid: 91.25% Test: 88.24%\n",
      "Run: 08, Epoch: 91, Loss: 0.2693, Train: 90.00%, Valid: 91.25% Test: 84.31%\n",
      "Run: 08, Epoch: 92, Loss: 0.2811, Train: 91.67%, Valid: 90.00% Test: 84.31%\n",
      "Run: 08, Epoch: 93, Loss: 0.2187, Train: 93.33%, Valid: 91.25% Test: 86.27%\n",
      "Run: 08, Epoch: 94, Loss: 0.3146, Train: 95.00%, Valid: 93.75% Test: 88.24%\n",
      "Run: 08, Epoch: 95, Loss: 0.2224, Train: 93.33%, Valid: 91.25% Test: 90.20%\n",
      "Run: 08, Epoch: 96, Loss: 0.3061, Train: 90.83%, Valid: 91.25% Test: 88.24%\n",
      "Run: 08, Epoch: 97, Loss: 0.2846, Train: 90.83%, Valid: 91.25% Test: 88.24%\n",
      "Run: 08, Epoch: 98, Loss: 0.2508, Train: 90.83%, Valid: 91.25% Test: 86.27%\n",
      "Run: 08, Epoch: 99, Loss: 0.2399, Train: 90.83%, Valid: 90.00% Test: 86.27%\n",
      "Run: 08, Epoch: 100, Loss: 0.2773, Train: 90.83%, Valid: 91.25% Test: 90.20%\n",
      "Run 08:\n",
      "Highest Train: 95.00\n",
      "Highest Valid: 93.75\n",
      "  Final Train: 95.00\n",
      "   Final Test: 88.24\n",
      "Run: 09, Epoch: 01, Loss: 1.5950, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 02, Loss: 1.5250, Train: 54.17%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 03, Loss: 1.3167, Train: 60.00%, Valid: 48.75% Test: 50.98%\n",
      "Run: 09, Epoch: 04, Loss: 1.2623, Train: 57.50%, Valid: 46.25% Test: 52.94%\n",
      "Run: 09, Epoch: 05, Loss: 1.1500, Train: 55.00%, Valid: 51.25% Test: 49.02%\n",
      "Run: 09, Epoch: 06, Loss: 1.1591, Train: 57.50%, Valid: 55.00% Test: 58.82%\n",
      "Run: 09, Epoch: 07, Loss: 1.1000, Train: 64.17%, Valid: 62.50% Test: 68.63%\n",
      "Run: 09, Epoch: 08, Loss: 1.0602, Train: 68.33%, Valid: 60.00% Test: 64.71%\n",
      "Run: 09, Epoch: 09, Loss: 0.9451, Train: 70.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 09, Epoch: 10, Loss: 1.0100, Train: 67.50%, Valid: 57.50% Test: 54.90%\n",
      "Run: 09, Epoch: 11, Loss: 0.8809, Train: 64.17%, Valid: 57.50% Test: 52.94%\n",
      "Run: 09, Epoch: 12, Loss: 0.8783, Train: 65.00%, Valid: 56.25% Test: 56.86%\n",
      "Run: 09, Epoch: 13, Loss: 0.8847, Train: 64.17%, Valid: 53.75% Test: 58.82%\n",
      "Run: 09, Epoch: 14, Loss: 0.7705, Train: 67.50%, Valid: 55.00% Test: 58.82%\n",
      "Run: 09, Epoch: 15, Loss: 0.7925, Train: 65.83%, Valid: 55.00% Test: 58.82%\n",
      "Run: 09, Epoch: 16, Loss: 0.7337, Train: 67.50%, Valid: 53.75% Test: 58.82%\n",
      "Run: 09, Epoch: 17, Loss: 0.7500, Train: 68.33%, Valid: 53.75% Test: 60.78%\n",
      "Run: 09, Epoch: 18, Loss: 0.6421, Train: 69.17%, Valid: 53.75% Test: 60.78%\n",
      "Run: 09, Epoch: 19, Loss: 0.6831, Train: 70.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 09, Epoch: 20, Loss: 0.6490, Train: 70.83%, Valid: 61.25% Test: 60.78%\n",
      "Run: 09, Epoch: 21, Loss: 0.6445, Train: 71.67%, Valid: 62.50% Test: 58.82%\n",
      "Run: 09, Epoch: 22, Loss: 0.6396, Train: 71.67%, Valid: 65.00% Test: 58.82%\n",
      "Run: 09, Epoch: 23, Loss: 0.5940, Train: 70.83%, Valid: 65.00% Test: 60.78%\n",
      "Run: 09, Epoch: 24, Loss: 0.5587, Train: 70.83%, Valid: 62.50% Test: 60.78%\n",
      "Run: 09, Epoch: 25, Loss: 0.5574, Train: 71.67%, Valid: 63.75% Test: 60.78%\n",
      "Run: 09, Epoch: 26, Loss: 0.5084, Train: 70.83%, Valid: 63.75% Test: 60.78%\n",
      "Run: 09, Epoch: 27, Loss: 0.5027, Train: 70.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 09, Epoch: 28, Loss: 0.4682, Train: 74.17%, Valid: 67.50% Test: 68.63%\n",
      "Run: 09, Epoch: 29, Loss: 0.5218, Train: 77.50%, Valid: 70.00% Test: 70.59%\n",
      "Run: 09, Epoch: 30, Loss: 0.4053, Train: 79.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 09, Epoch: 31, Loss: 0.4846, Train: 80.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 09, Epoch: 32, Loss: 0.3918, Train: 79.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 09, Epoch: 33, Loss: 0.4911, Train: 77.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 09, Epoch: 34, Loss: 0.3860, Train: 76.67%, Valid: 70.00% Test: 70.59%\n",
      "Run: 09, Epoch: 35, Loss: 0.4131, Train: 80.83%, Valid: 72.50% Test: 76.47%\n",
      "Run: 09, Epoch: 36, Loss: 0.3802, Train: 81.67%, Valid: 76.25% Test: 82.35%\n",
      "Run: 09, Epoch: 37, Loss: 0.3365, Train: 84.17%, Valid: 76.25% Test: 80.39%\n",
      "Run: 09, Epoch: 38, Loss: 0.3102, Train: 83.33%, Valid: 76.25% Test: 82.35%\n",
      "Run: 09, Epoch: 39, Loss: 0.3651, Train: 82.50%, Valid: 73.75% Test: 80.39%\n",
      "Run: 09, Epoch: 40, Loss: 0.3543, Train: 84.17%, Valid: 73.75% Test: 80.39%\n",
      "Run: 09, Epoch: 41, Loss: 0.4185, Train: 83.33%, Valid: 73.75% Test: 78.43%\n",
      "Run: 09, Epoch: 42, Loss: 0.3590, Train: 83.33%, Valid: 75.00% Test: 78.43%\n",
      "Run: 09, Epoch: 43, Loss: 0.3082, Train: 80.00%, Valid: 73.75% Test: 78.43%\n",
      "Run: 09, Epoch: 44, Loss: 0.3506, Train: 83.33%, Valid: 75.00% Test: 78.43%\n",
      "Run: 09, Epoch: 45, Loss: 0.3286, Train: 86.67%, Valid: 77.50% Test: 78.43%\n",
      "Run: 09, Epoch: 46, Loss: 0.3162, Train: 86.67%, Valid: 78.75% Test: 80.39%\n",
      "Run: 09, Epoch: 47, Loss: 0.3443, Train: 85.83%, Valid: 78.75% Test: 80.39%\n",
      "Run: 09, Epoch: 48, Loss: 0.3491, Train: 85.00%, Valid: 77.50% Test: 78.43%\n",
      "Run: 09, Epoch: 49, Loss: 0.1970, Train: 85.83%, Valid: 78.75% Test: 78.43%\n",
      "Run: 09, Epoch: 50, Loss: 0.3812, Train: 88.33%, Valid: 83.75% Test: 80.39%\n",
      "Run: 09, Epoch: 51, Loss: 0.2965, Train: 92.50%, Valid: 82.50% Test: 82.35%\n",
      "Run: 09, Epoch: 52, Loss: 0.2574, Train: 93.33%, Valid: 82.50% Test: 82.35%\n",
      "Run: 09, Epoch: 53, Loss: 0.2287, Train: 89.17%, Valid: 80.00% Test: 80.39%\n",
      "Run: 09, Epoch: 54, Loss: 0.2084, Train: 86.67%, Valid: 78.75% Test: 78.43%\n",
      "Run: 09, Epoch: 55, Loss: 0.3196, Train: 87.50%, Valid: 78.75% Test: 78.43%\n",
      "Run: 09, Epoch: 56, Loss: 0.2040, Train: 87.50%, Valid: 77.50% Test: 80.39%\n",
      "Run: 09, Epoch: 57, Loss: 0.2742, Train: 90.00%, Valid: 81.25% Test: 82.35%\n",
      "Run: 09, Epoch: 58, Loss: 0.2995, Train: 90.83%, Valid: 81.25% Test: 84.31%\n",
      "Run: 09, Epoch: 59, Loss: 0.2504, Train: 90.00%, Valid: 80.00% Test: 86.27%\n",
      "Run: 09, Epoch: 60, Loss: 0.2384, Train: 89.17%, Valid: 78.75% Test: 84.31%\n",
      "Run: 09, Epoch: 61, Loss: 0.2214, Train: 88.33%, Valid: 77.50% Test: 76.47%\n",
      "Run: 09, Epoch: 62, Loss: 0.2522, Train: 86.67%, Valid: 72.50% Test: 76.47%\n",
      "Run: 09, Epoch: 63, Loss: 0.2100, Train: 85.83%, Valid: 73.75% Test: 76.47%\n",
      "Run: 09, Epoch: 64, Loss: 0.2147, Train: 90.00%, Valid: 77.50% Test: 80.39%\n",
      "Run: 09, Epoch: 65, Loss: 0.2613, Train: 91.67%, Valid: 81.25% Test: 84.31%\n",
      "Run: 09, Epoch: 66, Loss: 0.2518, Train: 94.17%, Valid: 85.00% Test: 86.27%\n",
      "Run: 09, Epoch: 67, Loss: 0.1549, Train: 95.83%, Valid: 86.25% Test: 86.27%\n",
      "Run: 09, Epoch: 68, Loss: 0.2191, Train: 95.00%, Valid: 86.25% Test: 84.31%\n",
      "Run: 09, Epoch: 69, Loss: 0.2507, Train: 94.17%, Valid: 86.25% Test: 84.31%\n",
      "Run: 09, Epoch: 70, Loss: 0.3065, Train: 95.00%, Valid: 85.00% Test: 88.24%\n",
      "Run: 09, Epoch: 71, Loss: 0.2576, Train: 96.67%, Valid: 85.00% Test: 88.24%\n",
      "Run: 09, Epoch: 72, Loss: 0.2199, Train: 96.67%, Valid: 86.25% Test: 90.20%\n",
      "Run: 09, Epoch: 73, Loss: 0.2024, Train: 96.67%, Valid: 83.75% Test: 90.20%\n",
      "Run: 09, Epoch: 74, Loss: 0.2016, Train: 93.33%, Valid: 80.00% Test: 88.24%\n",
      "Run: 09, Epoch: 75, Loss: 0.2661, Train: 90.00%, Valid: 75.00% Test: 80.39%\n",
      "Run: 09, Epoch: 76, Loss: 0.2066, Train: 85.83%, Valid: 71.25% Test: 76.47%\n",
      "Run: 09, Epoch: 77, Loss: 0.2633, Train: 85.83%, Valid: 72.50% Test: 76.47%\n",
      "Run: 09, Epoch: 78, Loss: 0.1843, Train: 85.83%, Valid: 75.00% Test: 76.47%\n",
      "Run: 09, Epoch: 79, Loss: 0.2352, Train: 90.00%, Valid: 77.50% Test: 82.35%\n",
      "Run: 09, Epoch: 80, Loss: 0.2158, Train: 93.33%, Valid: 82.50% Test: 84.31%\n",
      "Run: 09, Epoch: 81, Loss: 0.2407, Train: 93.33%, Valid: 82.50% Test: 86.27%\n",
      "Run: 09, Epoch: 82, Loss: 0.2084, Train: 93.33%, Valid: 83.75% Test: 88.24%\n",
      "Run: 09, Epoch: 83, Loss: 0.1782, Train: 93.33%, Valid: 82.50% Test: 84.31%\n",
      "Run: 09, Epoch: 84, Loss: 0.1563, Train: 90.00%, Valid: 78.75% Test: 84.31%\n",
      "Run: 09, Epoch: 85, Loss: 0.2031, Train: 89.17%, Valid: 77.50% Test: 84.31%\n",
      "Run: 09, Epoch: 86, Loss: 0.1909, Train: 86.67%, Valid: 77.50% Test: 80.39%\n",
      "Run: 09, Epoch: 87, Loss: 0.1920, Train: 88.33%, Valid: 77.50% Test: 84.31%\n",
      "Run: 09, Epoch: 88, Loss: 0.2467, Train: 90.83%, Valid: 85.00% Test: 88.24%\n",
      "Run: 09, Epoch: 89, Loss: 0.1898, Train: 95.00%, Valid: 87.50% Test: 88.24%\n",
      "Run: 09, Epoch: 90, Loss: 0.1686, Train: 96.67%, Valid: 87.50% Test: 88.24%\n",
      "Run: 09, Epoch: 91, Loss: 0.1686, Train: 96.67%, Valid: 88.75% Test: 88.24%\n",
      "Run: 09, Epoch: 92, Loss: 0.1605, Train: 95.83%, Valid: 86.25% Test: 88.24%\n",
      "Run: 09, Epoch: 93, Loss: 0.1596, Train: 96.67%, Valid: 85.00% Test: 88.24%\n",
      "Run: 09, Epoch: 94, Loss: 0.1641, Train: 95.83%, Valid: 85.00% Test: 88.24%\n",
      "Run: 09, Epoch: 95, Loss: 0.1513, Train: 97.50%, Valid: 82.50% Test: 88.24%\n",
      "Run: 09, Epoch: 96, Loss: 0.1169, Train: 95.83%, Valid: 82.50% Test: 86.27%\n",
      "Run: 09, Epoch: 97, Loss: 0.1589, Train: 92.50%, Valid: 82.50% Test: 84.31%\n",
      "Run: 09, Epoch: 98, Loss: 0.1534, Train: 91.67%, Valid: 80.00% Test: 80.39%\n",
      "Run: 09, Epoch: 99, Loss: 0.1425, Train: 93.33%, Valid: 82.50% Test: 82.35%\n",
      "Run: 09, Epoch: 100, Loss: 0.2146, Train: 96.67%, Valid: 85.00% Test: 86.27%\n",
      "Run 09:\n",
      "Highest Train: 97.50\n",
      "Highest Valid: 88.75\n",
      "  Final Train: 96.67\n",
      "   Final Test: 88.24\n",
      "Run: 10, Epoch: 01, Loss: 1.9049, Train: 21.67%, Valid: 13.75% Test: 13.73%\n",
      "Run: 10, Epoch: 02, Loss: 1.6065, Train: 31.67%, Valid: 25.00% Test: 33.33%\n",
      "Run: 10, Epoch: 03, Loss: 1.4298, Train: 44.17%, Valid: 40.00% Test: 50.98%\n",
      "Run: 10, Epoch: 04, Loss: 1.3902, Train: 46.67%, Valid: 36.25% Test: 49.02%\n",
      "Run: 10, Epoch: 05, Loss: 1.1587, Train: 42.50%, Valid: 36.25% Test: 49.02%\n",
      "Run: 10, Epoch: 06, Loss: 1.1457, Train: 44.17%, Valid: 35.00% Test: 47.06%\n",
      "Run: 10, Epoch: 07, Loss: 1.0862, Train: 45.83%, Valid: 36.25% Test: 49.02%\n",
      "Run: 10, Epoch: 08, Loss: 1.0733, Train: 44.17%, Valid: 37.50% Test: 52.94%\n",
      "Run: 10, Epoch: 09, Loss: 1.0080, Train: 47.50%, Valid: 40.00% Test: 54.90%\n",
      "Run: 10, Epoch: 10, Loss: 0.9444, Train: 50.00%, Valid: 48.75% Test: 62.75%\n",
      "Run: 10, Epoch: 11, Loss: 0.9666, Train: 53.33%, Valid: 52.50% Test: 64.71%\n",
      "Run: 10, Epoch: 12, Loss: 0.9090, Train: 58.33%, Valid: 55.00% Test: 66.67%\n",
      "Run: 10, Epoch: 13, Loss: 0.8705, Train: 63.33%, Valid: 55.00% Test: 64.71%\n",
      "Run: 10, Epoch: 14, Loss: 0.8778, Train: 62.50%, Valid: 60.00% Test: 64.71%\n",
      "Run: 10, Epoch: 15, Loss: 0.8411, Train: 64.17%, Valid: 62.50% Test: 62.75%\n",
      "Run: 10, Epoch: 16, Loss: 0.8412, Train: 63.33%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 17, Loss: 0.8397, Train: 64.17%, Valid: 61.25% Test: 62.75%\n",
      "Run: 10, Epoch: 18, Loss: 0.7758, Train: 64.17%, Valid: 62.50% Test: 66.67%\n",
      "Run: 10, Epoch: 19, Loss: 0.7716, Train: 64.17%, Valid: 62.50% Test: 68.63%\n",
      "Run: 10, Epoch: 20, Loss: 0.7023, Train: 65.00%, Valid: 63.75% Test: 68.63%\n",
      "Run: 10, Epoch: 21, Loss: 0.7247, Train: 65.00%, Valid: 63.75% Test: 70.59%\n",
      "Run: 10, Epoch: 22, Loss: 0.6786, Train: 65.00%, Valid: 65.00% Test: 72.55%\n",
      "Run: 10, Epoch: 23, Loss: 0.6751, Train: 67.50%, Valid: 67.50% Test: 74.51%\n",
      "Run: 10, Epoch: 24, Loss: 0.7189, Train: 70.00%, Valid: 68.75% Test: 76.47%\n",
      "Run: 10, Epoch: 25, Loss: 0.6532, Train: 76.67%, Valid: 68.75% Test: 78.43%\n",
      "Run: 10, Epoch: 26, Loss: 0.5840, Train: 75.00%, Valid: 71.25% Test: 76.47%\n",
      "Run: 10, Epoch: 27, Loss: 0.5827, Train: 74.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 10, Epoch: 28, Loss: 0.5715, Train: 71.67%, Valid: 68.75% Test: 72.55%\n",
      "Run: 10, Epoch: 29, Loss: 0.6134, Train: 74.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 10, Epoch: 30, Loss: 0.5136, Train: 75.00%, Valid: 68.75% Test: 74.51%\n",
      "Run: 10, Epoch: 31, Loss: 0.5550, Train: 77.50%, Valid: 70.00% Test: 76.47%\n",
      "Run: 10, Epoch: 32, Loss: 0.5280, Train: 80.00%, Valid: 71.25% Test: 76.47%\n",
      "Run: 10, Epoch: 33, Loss: 0.4933, Train: 80.83%, Valid: 72.50% Test: 78.43%\n",
      "Run: 10, Epoch: 34, Loss: 0.4284, Train: 82.50%, Valid: 75.00% Test: 80.39%\n",
      "Run: 10, Epoch: 35, Loss: 0.4109, Train: 83.33%, Valid: 76.25% Test: 82.35%\n",
      "Run: 10, Epoch: 36, Loss: 0.4878, Train: 85.83%, Valid: 77.50% Test: 82.35%\n",
      "Run: 10, Epoch: 37, Loss: 0.4462, Train: 87.50%, Valid: 78.75% Test: 82.35%\n",
      "Run: 10, Epoch: 38, Loss: 0.4396, Train: 88.33%, Valid: 81.25% Test: 84.31%\n",
      "Run: 10, Epoch: 39, Loss: 0.4094, Train: 89.17%, Valid: 78.75% Test: 78.43%\n",
      "Run: 10, Epoch: 40, Loss: 0.3953, Train: 85.00%, Valid: 76.25% Test: 78.43%\n",
      "Run: 10, Epoch: 41, Loss: 0.3970, Train: 83.33%, Valid: 71.25% Test: 78.43%\n",
      "Run: 10, Epoch: 42, Loss: 0.3582, Train: 80.00%, Valid: 68.75% Test: 78.43%\n",
      "Run: 10, Epoch: 43, Loss: 0.3641, Train: 81.67%, Valid: 71.25% Test: 78.43%\n",
      "Run: 10, Epoch: 44, Loss: 0.3658, Train: 85.00%, Valid: 77.50% Test: 80.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 45, Loss: 0.3604, Train: 88.33%, Valid: 78.75% Test: 78.43%\n",
      "Run: 10, Epoch: 46, Loss: 0.3245, Train: 90.00%, Valid: 80.00% Test: 80.39%\n",
      "Run: 10, Epoch: 47, Loss: 0.3024, Train: 88.33%, Valid: 80.00% Test: 82.35%\n",
      "Run: 10, Epoch: 48, Loss: 0.3006, Train: 85.00%, Valid: 78.75% Test: 82.35%\n",
      "Run: 10, Epoch: 49, Loss: 0.3535, Train: 84.17%, Valid: 77.50% Test: 82.35%\n",
      "Run: 10, Epoch: 50, Loss: 0.3283, Train: 84.17%, Valid: 77.50% Test: 82.35%\n",
      "Run: 10, Epoch: 51, Loss: 0.2838, Train: 85.00%, Valid: 77.50% Test: 82.35%\n",
      "Run: 10, Epoch: 52, Loss: 0.3810, Train: 86.67%, Valid: 78.75% Test: 82.35%\n",
      "Run: 10, Epoch: 53, Loss: 0.3080, Train: 84.17%, Valid: 77.50% Test: 82.35%\n",
      "Run: 10, Epoch: 54, Loss: 0.2941, Train: 82.50%, Valid: 76.25% Test: 82.35%\n",
      "Run: 10, Epoch: 55, Loss: 0.2565, Train: 86.67%, Valid: 78.75% Test: 84.31%\n",
      "Run: 10, Epoch: 56, Loss: 0.2932, Train: 92.50%, Valid: 82.50% Test: 86.27%\n",
      "Run: 10, Epoch: 57, Loss: 0.2767, Train: 93.33%, Valid: 83.75% Test: 88.24%\n",
      "Run: 10, Epoch: 58, Loss: 0.2688, Train: 94.17%, Valid: 82.50% Test: 88.24%\n",
      "Run: 10, Epoch: 59, Loss: 0.2840, Train: 94.17%, Valid: 82.50% Test: 88.24%\n",
      "Run: 10, Epoch: 60, Loss: 0.2223, Train: 94.17%, Valid: 82.50% Test: 86.27%\n",
      "Run: 10, Epoch: 61, Loss: 0.2199, Train: 92.50%, Valid: 81.25% Test: 88.24%\n",
      "Run: 10, Epoch: 62, Loss: 0.2447, Train: 90.00%, Valid: 80.00% Test: 88.24%\n",
      "Run: 10, Epoch: 63, Loss: 0.2535, Train: 86.67%, Valid: 78.75% Test: 86.27%\n",
      "Run: 10, Epoch: 64, Loss: 0.2581, Train: 88.33%, Valid: 80.00% Test: 88.24%\n",
      "Run: 10, Epoch: 65, Loss: 0.2058, Train: 92.50%, Valid: 80.00% Test: 88.24%\n",
      "Run: 10, Epoch: 66, Loss: 0.2558, Train: 92.50%, Valid: 83.75% Test: 86.27%\n",
      "Run: 10, Epoch: 67, Loss: 0.2362, Train: 93.33%, Valid: 83.75% Test: 90.20%\n",
      "Run: 10, Epoch: 68, Loss: 0.2528, Train: 94.17%, Valid: 82.50% Test: 90.20%\n",
      "Run: 10, Epoch: 69, Loss: 0.2469, Train: 94.17%, Valid: 82.50% Test: 90.20%\n",
      "Run: 10, Epoch: 70, Loss: 0.1891, Train: 93.33%, Valid: 82.50% Test: 86.27%\n",
      "Run: 10, Epoch: 71, Loss: 0.2067, Train: 93.33%, Valid: 85.00% Test: 84.31%\n",
      "Run: 10, Epoch: 72, Loss: 0.1904, Train: 93.33%, Valid: 82.50% Test: 82.35%\n",
      "Run: 10, Epoch: 73, Loss: 0.2101, Train: 93.33%, Valid: 82.50% Test: 82.35%\n",
      "Run: 10, Epoch: 74, Loss: 0.2025, Train: 93.33%, Valid: 83.75% Test: 82.35%\n",
      "Run: 10, Epoch: 75, Loss: 0.1856, Train: 94.17%, Valid: 85.00% Test: 84.31%\n",
      "Run: 10, Epoch: 76, Loss: 0.1788, Train: 93.33%, Valid: 83.75% Test: 88.24%\n",
      "Run: 10, Epoch: 77, Loss: 0.1819, Train: 92.50%, Valid: 81.25% Test: 88.24%\n",
      "Run: 10, Epoch: 78, Loss: 0.2644, Train: 94.17%, Valid: 82.50% Test: 88.24%\n",
      "Run: 10, Epoch: 79, Loss: 0.1964, Train: 95.83%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 80, Loss: 0.1554, Train: 95.83%, Valid: 86.25% Test: 88.24%\n",
      "Run: 10, Epoch: 81, Loss: 0.1678, Train: 97.50%, Valid: 85.00% Test: 90.20%\n",
      "Run: 10, Epoch: 82, Loss: 0.2199, Train: 99.17%, Valid: 85.00% Test: 90.20%\n",
      "Run: 10, Epoch: 83, Loss: 0.1700, Train: 98.33%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 84, Loss: 0.1837, Train: 97.50%, Valid: 86.25% Test: 86.27%\n",
      "Run: 10, Epoch: 85, Loss: 0.1836, Train: 95.83%, Valid: 85.00% Test: 86.27%\n",
      "Run: 10, Epoch: 86, Loss: 0.1557, Train: 95.00%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 87, Loss: 0.2133, Train: 95.00%, Valid: 83.75% Test: 88.24%\n",
      "Run: 10, Epoch: 88, Loss: 0.1709, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 10, Epoch: 89, Loss: 0.1592, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 10, Epoch: 90, Loss: 0.1019, Train: 94.17%, Valid: 85.00% Test: 86.27%\n",
      "Run: 10, Epoch: 91, Loss: 0.1442, Train: 95.83%, Valid: 82.50% Test: 86.27%\n",
      "Run: 10, Epoch: 92, Loss: 0.1596, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 10, Epoch: 93, Loss: 0.1451, Train: 94.17%, Valid: 83.75% Test: 86.27%\n",
      "Run: 10, Epoch: 94, Loss: 0.2106, Train: 91.67%, Valid: 82.50% Test: 86.27%\n",
      "Run: 10, Epoch: 95, Loss: 0.1863, Train: 95.00%, Valid: 83.75% Test: 88.24%\n",
      "Run: 10, Epoch: 96, Loss: 0.1905, Train: 95.83%, Valid: 83.75% Test: 88.24%\n",
      "Run: 10, Epoch: 97, Loss: 0.1028, Train: 95.83%, Valid: 83.75% Test: 86.27%\n",
      "Run: 10, Epoch: 98, Loss: 0.0940, Train: 96.67%, Valid: 86.25% Test: 88.24%\n",
      "Run: 10, Epoch: 99, Loss: 0.1583, Train: 96.67%, Valid: 85.00% Test: 86.27%\n",
      "Run: 10, Epoch: 100, Loss: 0.1523, Train: 96.67%, Valid: 86.25% Test: 84.31%\n",
      "Run 10:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 86.25\n",
      "  Final Train: 95.83\n",
      "   Final Test: 88.24\n",
      "All runs:\n",
      "Highest Train: 97.42 ± 1.64\n",
      "Highest Valid: 90.12 ± 3.41\n",
      "  Final Train: 95.08 ± 3.61\n",
      "   Final Test: 87.25 ± 5.49\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 32, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-6, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = WebKB(root='/tmp/Texas', name='Texas',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    #idx_train=[data.train_mask[i][0] for i in range(len(data.y))]\n",
    "    #train_idx = np.where(idx_train)[0]\n",
    "    #idx_val=[data.val_mask[i][0] for i in range(len(data.y))]\n",
    "    #valid_idx = np.where(idx_val)[0]\n",
    "    #idx_test=[data.test_mask[i][0] for i in range(len(data.y))]\n",
    "    #test_idx = np.where(idx_test)[0]\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085c7fd",
   "metadata": {},
   "source": [
    "# Topological encodding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e47b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], edge_index=[2, 515], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin')\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607be4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ... 248 249 250]\n",
      " [ 20  28  99 ... 132 117  35]]\n"
     ]
    }
   ],
   "source": [
    "print(data.edge_index.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52514bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_nodes=len(data.y)\n",
    "Edge_idx=data.edge_index.numpy()\n",
    "Node=range(Number_nodes)\n",
    "Edgelist=[]\n",
    "for i in range(len(Edge_idx[1])):\n",
    "    Edgelist.append((Edge_idx[0][i],Edge_idx[1][i]))\n",
    "#print(Edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9d236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a \"plain\" graph is undirected\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# give each a node a 'name', which is a letter in this case.\n",
    "#G.add_node('a')\n",
    "\n",
    "# the add_nodes_from method allows adding nodes from a sequence, in this case a list\n",
    "#nodes_to_add = ['b', 'c', 'd']\n",
    "G.add_nodes_from(Node)\n",
    "\n",
    "# add edge from 'a' to 'b'\n",
    "# since this graph is undirected, the order doesn't matter here\n",
    "#G.add_edge('a', 'b')\n",
    "\n",
    "# just like add_nodes_from, we can add edges from a sequence\n",
    "# edges should be specified as 2-tuples\n",
    "#edges_to_add = [('a', 'c'), ('b', 'c'), ('c', 'd')]\n",
    "G.add_edges_from(Edgelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781abc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n"
     ]
    }
   ],
   "source": [
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77abd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topological_Feature_subLevel(adj,filtration_fun, Filtration):\n",
    "        betti_0=[]\n",
    "        betti_1=[]\n",
    "        for p in range(len(Filtration)):\n",
    "            n_active = np.where(np.array(filtration_fun) <= Filtration[p])[0].tolist()\n",
    "            Active_node=np.unique(n_active)\n",
    "            if (len(Active_node)==0):\n",
    "                betti_0.append(0)\n",
    "                betti_1.append(0)\n",
    "            else:\n",
    "                b=adj[Active_node,:][:,Active_node]\n",
    "                my_flag=pyflagser.flagser_unweighted(b, min_dimension=0, max_dimension=2, directed=False, coeff=2, approximation=None)\n",
    "                x = my_flag[\"betti\"]\n",
    "                betti_0.append(x[0])\n",
    "                betti_1.append(x[1])\n",
    "            n_active.clear()\n",
    "        return betti_0,betti_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e40cacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Degree_list(Graph):\n",
    "    degree_list = [Graph.degree(node) for node in Graph.nodes]\n",
    "    return np.array(degree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "118b65fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  |  59 \n",
      "\n",
      "2  |  53 \n",
      "\n",
      "3  |  47 \n",
      "\n",
      "4  |  27 \n",
      "\n",
      "5  |  21 \n",
      "\n",
      "6  |  17 \n",
      "\n",
      "8  |  4 \n",
      "\n",
      "9  |  5 \n",
      "\n",
      "10  |  4 \n",
      "\n",
      "11  |  5 \n",
      "\n",
      "12  |  3 \n",
      "\n",
      "13  |  2 \n",
      "\n",
      "14  |  1 \n",
      "\n",
      "18  |  1 \n",
      "\n",
      "21  |  1 \n",
      "\n",
      "122  |  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "degree_list=Degree_list(G)\n",
    "unique_list=np.unique(degree_list)\n",
    "for d in unique_list:\n",
    "    count=0\n",
    "    for i in range(len(degree_list)):\n",
    "        if degree_list[i]==d:\n",
    "            count=count+1\n",
    "    print(int(d),\" | \",count,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7080881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 250 (100%)"
     ]
    }
   ],
   "source": [
    "import pyflagser\n",
    "Node_fil=[1,2,3,4,5,6,7,8,9,10,20,50]\n",
    "topo_betti_0=[]\n",
    "topo_betti_1=[]\n",
    "Node_Edge=[]\n",
    "for i in range(Number_nodes):\n",
    "    print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//(Number_nodes-1)), end='', flush=True)\n",
    "    subgraph=ego_graph(G, i, radius=2, center=True, undirected=True, distance=None)\n",
    "    filt=Degree_list(subgraph)\n",
    "    A_sub = nx.to_numpy_array(subgraph)# adjacency matrix of subgraph\n",
    "    fe=Topological_Feature_subLevel(A_sub,filt,Node_fil)\n",
    "    topo_betti_0.append(fe[0])\n",
    "    topo_betti_1.append(fe[1])\n",
    "    Node_Edge.append([subgraph.number_of_nodes(),subgraph.number_of_edges()])\n",
    "    #topo_with_NE.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49a08a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "445f9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_betti0=torch.tensor(topo_betti_0).float()\n",
    "topo_betti1=torch.tensor(topo_betti_1).float()\n",
    "NodeEdge=torch.tensor(Node_Edge).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbeea52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 10], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515], topo=[251, 24])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "topo_fe=torch.cat((topo_betti0,topo_betti1),1)\n",
    "data.topo=topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde20bc",
   "metadata": {},
   "source": [
    "# TOPO-W-GSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd4668e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "        #return x.log_softmax(dim=-1)\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        #return torch.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "class MLP2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP2, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp2(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "    \n",
    "\n",
    "def train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2):\n",
    "    model.train()\n",
    "    mlp_model.train()\n",
    "    mlp_2.train()\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_mlp.zero_grad()\n",
    "    optimizer_mlp2.zero_grad()\n",
    "    gcn_embedding = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(gcn_embedding)\n",
    "    mlp_embedding = mlp_model(data.topo[train_idx])\n",
    "    #print(mlp_embedding)\n",
    "    combined_embedding = torch.cat((gcn_embedding, mlp_embedding), dim=1)\n",
    "    #print(combined_embedding)\n",
    "    mlp_emb = mlp_2(combined_embedding)\n",
    "    #print(mlp_emb)\n",
    "    loss = F.nll_loss(mlp_emb, data.y.squeeze()[train_idx])\n",
    "    #loss = F.nll_loss(combined_embedding, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer_mlp2.step()\n",
    "    optimizer.step()\n",
    "    optimizer_mlp.step()\n",
    "    \n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "    mlp_model.eval()\n",
    "    mlp_2.eval()\n",
    "\n",
    "    gcn_out = model(data.x, data.adj_t)\n",
    "    #print(gcn_out[0])\n",
    "    mlp_out=mlp_model(data.topo)\n",
    "    #print(mlp_out)\n",
    "    #out=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    Com=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    out=mlp_2(Com)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    #print(y_pred[0])\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef21f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x177829cf0>\n",
      "Run: 01, Epoch: 01, Loss: 1.5083, Train: 14.17%, Valid: 8.75% Test: 15.69%\n",
      "Run: 01, Epoch: 02, Loss: 1.4521, Train: 14.17%, Valid: 8.75% Test: 15.69%\n",
      "Run: 01, Epoch: 03, Loss: 1.4165, Train: 54.17%, Valid: 58.75% Test: 68.63%\n",
      "Run: 01, Epoch: 04, Loss: 1.3621, Train: 52.50%, Valid: 63.75% Test: 60.78%\n",
      "Run: 01, Epoch: 05, Loss: 1.3217, Train: 52.50%, Valid: 61.25% Test: 58.82%\n",
      "Run: 01, Epoch: 06, Loss: 1.2817, Train: 53.33%, Valid: 63.75% Test: 60.78%\n",
      "Run: 01, Epoch: 07, Loss: 1.2651, Train: 55.00%, Valid: 65.00% Test: 62.75%\n",
      "Run: 01, Epoch: 08, Loss: 1.2042, Train: 57.50%, Valid: 63.75% Test: 62.75%\n",
      "Run: 01, Epoch: 09, Loss: 1.1916, Train: 58.33%, Valid: 63.75% Test: 64.71%\n",
      "Run: 01, Epoch: 10, Loss: 1.1729, Train: 57.50%, Valid: 62.50% Test: 64.71%\n",
      "Run: 01, Epoch: 11, Loss: 1.1709, Train: 60.83%, Valid: 63.75% Test: 64.71%\n",
      "Run: 01, Epoch: 12, Loss: 1.1086, Train: 61.67%, Valid: 63.75% Test: 64.71%\n",
      "Run: 01, Epoch: 13, Loss: 1.0786, Train: 60.00%, Valid: 65.00% Test: 66.67%\n",
      "Run: 01, Epoch: 14, Loss: 1.0440, Train: 62.50%, Valid: 65.00% Test: 66.67%\n",
      "Run: 01, Epoch: 15, Loss: 1.0147, Train: 65.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 01, Epoch: 16, Loss: 1.0453, Train: 67.50%, Valid: 71.25% Test: 70.59%\n",
      "Run: 01, Epoch: 17, Loss: 0.9806, Train: 70.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 01, Epoch: 18, Loss: 0.9666, Train: 70.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 01, Epoch: 19, Loss: 0.9742, Train: 67.50%, Valid: 71.25% Test: 72.55%\n",
      "Run: 01, Epoch: 20, Loss: 0.9512, Train: 67.50%, Valid: 68.75% Test: 72.55%\n",
      "Run: 01, Epoch: 21, Loss: 0.9315, Train: 68.33%, Valid: 68.75% Test: 70.59%\n",
      "Run: 01, Epoch: 22, Loss: 0.9190, Train: 68.33%, Valid: 67.50% Test: 70.59%\n",
      "Run: 01, Epoch: 23, Loss: 0.8653, Train: 65.83%, Valid: 68.75% Test: 68.63%\n",
      "Run: 01, Epoch: 24, Loss: 0.8936, Train: 66.67%, Valid: 68.75% Test: 68.63%\n",
      "Run: 01, Epoch: 25, Loss: 0.8684, Train: 65.83%, Valid: 66.25% Test: 66.67%\n",
      "Run: 01, Epoch: 26, Loss: 0.8325, Train: 65.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 01, Epoch: 27, Loss: 0.8700, Train: 63.33%, Valid: 65.00% Test: 64.71%\n",
      "Run: 01, Epoch: 28, Loss: 0.7818, Train: 64.17%, Valid: 62.50% Test: 64.71%\n",
      "Run: 01, Epoch: 29, Loss: 0.7588, Train: 63.33%, Valid: 63.75% Test: 64.71%\n",
      "Run: 01, Epoch: 30, Loss: 0.7916, Train: 64.17%, Valid: 66.25% Test: 64.71%\n",
      "Run: 01, Epoch: 31, Loss: 0.8295, Train: 65.00%, Valid: 65.00% Test: 64.71%\n",
      "Run: 01, Epoch: 32, Loss: 0.7851, Train: 68.33%, Valid: 67.50% Test: 66.67%\n",
      "Run: 01, Epoch: 33, Loss: 0.8029, Train: 71.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 34, Loss: 0.7692, Train: 73.33%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 35, Loss: 0.7497, Train: 72.50%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 36, Loss: 0.7279, Train: 75.00%, Valid: 75.00% Test: 68.63%\n",
      "Run: 01, Epoch: 37, Loss: 0.7718, Train: 75.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 38, Loss: 0.7508, Train: 76.67%, Valid: 75.00% Test: 68.63%\n",
      "Run: 01, Epoch: 39, Loss: 0.7411, Train: 77.50%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 40, Loss: 0.7249, Train: 77.50%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 41, Loss: 0.7158, Train: 76.67%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 42, Loss: 0.7006, Train: 77.50%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 43, Loss: 0.7237, Train: 76.67%, Valid: 70.00% Test: 68.63%\n",
      "Run: 01, Epoch: 44, Loss: 0.7328, Train: 70.83%, Valid: 66.25% Test: 68.63%\n",
      "Run: 01, Epoch: 45, Loss: 0.6814, Train: 68.33%, Valid: 66.25% Test: 68.63%\n",
      "Run: 01, Epoch: 46, Loss: 0.6895, Train: 70.83%, Valid: 67.50% Test: 68.63%\n",
      "Run: 01, Epoch: 47, Loss: 0.6829, Train: 71.67%, Valid: 72.50% Test: 74.51%\n",
      "Run: 01, Epoch: 48, Loss: 0.6451, Train: 80.83%, Valid: 76.25% Test: 80.39%\n",
      "Run: 01, Epoch: 49, Loss: 0.6548, Train: 83.33%, Valid: 77.50% Test: 80.39%\n",
      "Run: 01, Epoch: 50, Loss: 0.6141, Train: 86.67%, Valid: 78.75% Test: 80.39%\n",
      "Run: 01, Epoch: 51, Loss: 0.6216, Train: 89.17%, Valid: 78.75% Test: 80.39%\n",
      "Run: 01, Epoch: 52, Loss: 0.6415, Train: 89.17%, Valid: 77.50% Test: 76.47%\n",
      "Run: 01, Epoch: 53, Loss: 0.6681, Train: 89.17%, Valid: 77.50% Test: 76.47%\n",
      "Run: 01, Epoch: 54, Loss: 0.6152, Train: 86.67%, Valid: 78.75% Test: 78.43%\n",
      "Run: 01, Epoch: 55, Loss: 0.6234, Train: 86.67%, Valid: 78.75% Test: 76.47%\n",
      "Run: 01, Epoch: 56, Loss: 0.6242, Train: 85.00%, Valid: 78.75% Test: 76.47%\n",
      "Run: 01, Epoch: 57, Loss: 0.6552, Train: 89.17%, Valid: 78.75% Test: 78.43%\n",
      "Run: 01, Epoch: 58, Loss: 0.6062, Train: 90.00%, Valid: 81.25% Test: 80.39%\n",
      "Run: 01, Epoch: 59, Loss: 0.6141, Train: 90.83%, Valid: 83.75% Test: 80.39%\n",
      "Run: 01, Epoch: 60, Loss: 0.5987, Train: 90.00%, Valid: 82.50% Test: 82.35%\n",
      "Run: 01, Epoch: 61, Loss: 0.5856, Train: 88.33%, Valid: 80.00% Test: 82.35%\n",
      "Run: 01, Epoch: 62, Loss: 0.5784, Train: 85.00%, Valid: 78.75% Test: 82.35%\n",
      "Run: 01, Epoch: 63, Loss: 0.6229, Train: 82.50%, Valid: 76.25% Test: 82.35%\n",
      "Run: 01, Epoch: 64, Loss: 0.5890, Train: 80.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 01, Epoch: 65, Loss: 0.5975, Train: 80.83%, Valid: 76.25% Test: 82.35%\n",
      "Run: 01, Epoch: 66, Loss: 0.5543, Train: 82.50%, Valid: 77.50% Test: 82.35%\n",
      "Run: 01, Epoch: 67, Loss: 0.5926, Train: 83.33%, Valid: 77.50% Test: 82.35%\n",
      "Run: 01, Epoch: 68, Loss: 0.5313, Train: 84.17%, Valid: 77.50% Test: 84.31%\n",
      "Run: 01, Epoch: 69, Loss: 0.5721, Train: 89.17%, Valid: 80.00% Test: 86.27%\n",
      "Run: 01, Epoch: 70, Loss: 0.5287, Train: 90.83%, Valid: 82.50% Test: 86.27%\n",
      "Run: 01, Epoch: 71, Loss: 0.5258, Train: 90.83%, Valid: 82.50% Test: 86.27%\n",
      "Run: 01, Epoch: 72, Loss: 0.5609, Train: 90.00%, Valid: 82.50% Test: 84.31%\n",
      "Run: 01, Epoch: 73, Loss: 0.5719, Train: 87.50%, Valid: 80.00% Test: 80.39%\n",
      "Run: 01, Epoch: 74, Loss: 0.5555, Train: 88.33%, Valid: 81.25% Test: 82.35%\n",
      "Run: 01, Epoch: 75, Loss: 0.4701, Train: 90.00%, Valid: 80.00% Test: 82.35%\n",
      "Run: 01, Epoch: 76, Loss: 0.5243, Train: 89.17%, Valid: 80.00% Test: 84.31%\n",
      "Run: 01, Epoch: 77, Loss: 0.4800, Train: 89.17%, Valid: 77.50% Test: 84.31%\n",
      "Run: 01, Epoch: 78, Loss: 0.4508, Train: 88.33%, Valid: 81.25% Test: 82.35%\n",
      "Run: 01, Epoch: 79, Loss: 0.5307, Train: 90.00%, Valid: 82.50% Test: 80.39%\n",
      "Run: 01, Epoch: 80, Loss: 0.4848, Train: 90.00%, Valid: 81.25% Test: 82.35%\n",
      "Run: 01, Epoch: 81, Loss: 0.4884, Train: 90.00%, Valid: 80.00% Test: 82.35%\n",
      "Run: 01, Epoch: 82, Loss: 0.4839, Train: 88.33%, Valid: 80.00% Test: 82.35%\n",
      "Run: 01, Epoch: 83, Loss: 0.5169, Train: 87.50%, Valid: 78.75% Test: 84.31%\n",
      "Run: 01, Epoch: 84, Loss: 0.4983, Train: 89.17%, Valid: 77.50% Test: 84.31%\n",
      "Run: 01, Epoch: 85, Loss: 0.4859, Train: 90.83%, Valid: 76.25% Test: 84.31%\n",
      "Run: 01, Epoch: 86, Loss: 0.4461, Train: 91.67%, Valid: 78.75% Test: 84.31%\n",
      "Run: 01, Epoch: 87, Loss: 0.4870, Train: 92.50%, Valid: 81.25% Test: 84.31%\n",
      "Run: 01, Epoch: 88, Loss: 0.4013, Train: 93.33%, Valid: 82.50% Test: 78.43%\n",
      "Run: 01, Epoch: 89, Loss: 0.4909, Train: 93.33%, Valid: 80.00% Test: 78.43%\n",
      "Run: 01, Epoch: 90, Loss: 0.4733, Train: 93.33%, Valid: 81.25% Test: 76.47%\n",
      "Run: 01, Epoch: 91, Loss: 0.5026, Train: 93.33%, Valid: 82.50% Test: 78.43%\n",
      "Run: 01, Epoch: 92, Loss: 0.4384, Train: 92.50%, Valid: 82.50% Test: 78.43%\n",
      "Run: 01, Epoch: 93, Loss: 0.4769, Train: 95.00%, Valid: 78.75% Test: 78.43%\n",
      "Run: 01, Epoch: 94, Loss: 0.4367, Train: 95.00%, Valid: 81.25% Test: 78.43%\n",
      "Run: 01, Epoch: 95, Loss: 0.5065, Train: 94.17%, Valid: 78.75% Test: 82.35%\n",
      "Run: 01, Epoch: 96, Loss: 0.4298, Train: 95.00%, Valid: 82.50% Test: 80.39%\n",
      "Run: 01, Epoch: 97, Loss: 0.4741, Train: 94.17%, Valid: 83.75% Test: 82.35%\n",
      "Run: 01, Epoch: 98, Loss: 0.4226, Train: 93.33%, Valid: 83.75% Test: 82.35%\n",
      "Run: 01, Epoch: 99, Loss: 0.4409, Train: 91.67%, Valid: 83.75% Test: 82.35%\n",
      "Run: 01, Epoch: 100, Loss: 0.4588, Train: 90.83%, Valid: 82.50% Test: 82.35%\n",
      "Run: 01, Epoch: 101, Loss: 0.3957, Train: 90.83%, Valid: 81.25% Test: 80.39%\n",
      "Run: 01, Epoch: 102, Loss: 0.4310, Train: 90.83%, Valid: 82.50% Test: 76.47%\n",
      "Run: 01, Epoch: 103, Loss: 0.4128, Train: 90.00%, Valid: 82.50% Test: 78.43%\n",
      "Run: 01, Epoch: 104, Loss: 0.4031, Train: 92.50%, Valid: 82.50% Test: 78.43%\n",
      "Run: 01, Epoch: 105, Loss: 0.4374, Train: 94.17%, Valid: 81.25% Test: 80.39%\n",
      "Run: 01, Epoch: 106, Loss: 0.4483, Train: 95.00%, Valid: 80.00% Test: 82.35%\n",
      "Run: 01, Epoch: 107, Loss: 0.4107, Train: 95.00%, Valid: 82.50% Test: 84.31%\n",
      "Run: 01, Epoch: 108, Loss: 0.4111, Train: 95.00%, Valid: 81.25% Test: 86.27%\n",
      "Run: 01, Epoch: 109, Loss: 0.4023, Train: 95.00%, Valid: 76.25% Test: 84.31%\n",
      "Run: 01, Epoch: 110, Loss: 0.3852, Train: 95.00%, Valid: 77.50% Test: 84.31%\n",
      "Run: 01, Epoch: 111, Loss: 0.4432, Train: 93.33%, Valid: 81.25% Test: 82.35%\n",
      "Run: 01, Epoch: 112, Loss: 0.3578, Train: 92.50%, Valid: 81.25% Test: 80.39%\n",
      "Run: 01, Epoch: 113, Loss: 0.4168, Train: 90.00%, Valid: 81.25% Test: 78.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 114, Loss: 0.4015, Train: 86.67%, Valid: 80.00% Test: 78.43%\n",
      "Run: 01, Epoch: 115, Loss: 0.4004, Train: 86.67%, Valid: 80.00% Test: 78.43%\n",
      "Run: 01, Epoch: 116, Loss: 0.3957, Train: 86.67%, Valid: 80.00% Test: 78.43%\n",
      "Run: 01, Epoch: 117, Loss: 0.3633, Train: 90.83%, Valid: 81.25% Test: 80.39%\n",
      "Run: 01, Epoch: 118, Loss: 0.4275, Train: 93.33%, Valid: 81.25% Test: 80.39%\n",
      "Run: 01, Epoch: 119, Loss: 0.3990, Train: 95.83%, Valid: 80.00% Test: 82.35%\n",
      "Run: 01, Epoch: 120, Loss: 0.3879, Train: 95.83%, Valid: 80.00% Test: 84.31%\n",
      "Run: 01, Epoch: 121, Loss: 0.3687, Train: 94.17%, Valid: 80.00% Test: 80.39%\n",
      "Run: 01, Epoch: 122, Loss: 0.3509, Train: 95.00%, Valid: 83.75% Test: 80.39%\n",
      "Run: 01, Epoch: 123, Loss: 0.3334, Train: 93.33%, Valid: 82.50% Test: 78.43%\n",
      "Run: 01, Epoch: 124, Loss: 0.4049, Train: 96.67%, Valid: 85.00% Test: 80.39%\n",
      "Run: 01, Epoch: 125, Loss: 0.3412, Train: 96.67%, Valid: 85.00% Test: 84.31%\n",
      "Run: 01, Epoch: 126, Loss: 0.3734, Train: 93.33%, Valid: 82.50% Test: 88.24%\n",
      "Run: 01, Epoch: 127, Loss: 0.3687, Train: 93.33%, Valid: 83.75% Test: 86.27%\n",
      "Run: 01, Epoch: 128, Loss: 0.4186, Train: 94.17%, Valid: 83.75% Test: 86.27%\n",
      "Run: 01, Epoch: 129, Loss: 0.3600, Train: 94.17%, Valid: 83.75% Test: 84.31%\n",
      "Run: 01, Epoch: 130, Loss: 0.3574, Train: 94.17%, Valid: 85.00% Test: 82.35%\n",
      "Run: 01, Epoch: 131, Loss: 0.3710, Train: 95.00%, Valid: 85.00% Test: 80.39%\n",
      "Run: 01, Epoch: 132, Loss: 0.3575, Train: 95.00%, Valid: 85.00% Test: 80.39%\n",
      "Run: 01, Epoch: 133, Loss: 0.3240, Train: 95.00%, Valid: 85.00% Test: 84.31%\n",
      "Run: 01, Epoch: 134, Loss: 0.3824, Train: 96.67%, Valid: 83.75% Test: 82.35%\n",
      "Run: 01, Epoch: 135, Loss: 0.3585, Train: 95.83%, Valid: 83.75% Test: 82.35%\n",
      "Run: 01, Epoch: 136, Loss: 0.3873, Train: 95.00%, Valid: 83.75% Test: 82.35%\n",
      "Run: 01, Epoch: 137, Loss: 0.3499, Train: 96.67%, Valid: 83.75% Test: 86.27%\n",
      "Run: 01, Epoch: 138, Loss: 0.2900, Train: 95.83%, Valid: 83.75% Test: 86.27%\n",
      "Run: 01, Epoch: 139, Loss: 0.3381, Train: 96.67%, Valid: 83.75% Test: 82.35%\n",
      "Run: 01, Epoch: 140, Loss: 0.3295, Train: 97.50%, Valid: 83.75% Test: 80.39%\n",
      "Run: 01, Epoch: 141, Loss: 0.3400, Train: 96.67%, Valid: 82.50% Test: 80.39%\n",
      "Run: 01, Epoch: 142, Loss: 0.3657, Train: 96.67%, Valid: 82.50% Test: 76.47%\n",
      "Run: 01, Epoch: 143, Loss: 0.3945, Train: 95.83%, Valid: 81.25% Test: 78.43%\n",
      "Run: 01, Epoch: 144, Loss: 0.2888, Train: 96.67%, Valid: 82.50% Test: 80.39%\n",
      "Run: 01, Epoch: 145, Loss: 0.2855, Train: 97.50%, Valid: 85.00% Test: 78.43%\n",
      "Run: 01, Epoch: 146, Loss: 0.2873, Train: 97.50%, Valid: 86.25% Test: 80.39%\n",
      "Run: 01, Epoch: 147, Loss: 0.3504, Train: 97.50%, Valid: 86.25% Test: 80.39%\n",
      "Run: 01, Epoch: 148, Loss: 0.2995, Train: 95.83%, Valid: 85.00% Test: 80.39%\n",
      "Run: 01, Epoch: 149, Loss: 0.3096, Train: 95.83%, Valid: 86.25% Test: 84.31%\n",
      "Run: 01, Epoch: 150, Loss: 0.3927, Train: 95.00%, Valid: 87.50% Test: 86.27%\n",
      "Run: 01, Epoch: 151, Loss: 0.3639, Train: 95.00%, Valid: 90.00% Test: 86.27%\n",
      "Run: 01, Epoch: 152, Loss: 0.2869, Train: 95.83%, Valid: 91.25% Test: 86.27%\n",
      "Run: 01, Epoch: 153, Loss: 0.2793, Train: 98.33%, Valid: 90.00% Test: 88.24%\n",
      "Run: 01, Epoch: 154, Loss: 0.3566, Train: 98.33%, Valid: 88.75% Test: 82.35%\n",
      "Run: 01, Epoch: 155, Loss: 0.3007, Train: 96.67%, Valid: 87.50% Test: 82.35%\n",
      "Run: 01, Epoch: 156, Loss: 0.3270, Train: 96.67%, Valid: 85.00% Test: 76.47%\n",
      "Run: 01, Epoch: 157, Loss: 0.3309, Train: 93.33%, Valid: 82.50% Test: 72.55%\n",
      "Run: 01, Epoch: 158, Loss: 0.3119, Train: 92.50%, Valid: 80.00% Test: 72.55%\n",
      "Run: 01, Epoch: 159, Loss: 0.3005, Train: 92.50%, Valid: 82.50% Test: 80.39%\n",
      "Run: 01, Epoch: 160, Loss: 0.3471, Train: 94.17%, Valid: 83.75% Test: 80.39%\n",
      "Run: 01, Epoch: 161, Loss: 0.3150, Train: 95.83%, Valid: 85.00% Test: 80.39%\n",
      "Run: 01, Epoch: 162, Loss: 0.3205, Train: 97.50%, Valid: 87.50% Test: 80.39%\n",
      "Run: 01, Epoch: 163, Loss: 0.3111, Train: 98.33%, Valid: 87.50% Test: 82.35%\n",
      "Run: 01, Epoch: 164, Loss: 0.2865, Train: 98.33%, Valid: 85.00% Test: 84.31%\n",
      "Run: 01, Epoch: 165, Loss: 0.3120, Train: 96.67%, Valid: 86.25% Test: 84.31%\n",
      "Run: 01, Epoch: 166, Loss: 0.3308, Train: 96.67%, Valid: 83.75% Test: 82.35%\n",
      "Run: 01, Epoch: 167, Loss: 0.2876, Train: 95.83%, Valid: 85.00% Test: 82.35%\n",
      "Run: 01, Epoch: 168, Loss: 0.3138, Train: 95.00%, Valid: 81.25% Test: 78.43%\n",
      "Run: 01, Epoch: 169, Loss: 0.2859, Train: 97.50%, Valid: 83.75% Test: 82.35%\n",
      "Run: 01, Epoch: 170, Loss: 0.2796, Train: 95.83%, Valid: 83.75% Test: 82.35%\n",
      "Run: 01, Epoch: 171, Loss: 0.2930, Train: 93.33%, Valid: 85.00% Test: 80.39%\n",
      "Run: 01, Epoch: 172, Loss: 0.3164, Train: 94.17%, Valid: 85.00% Test: 82.35%\n",
      "Run: 01, Epoch: 173, Loss: 0.3095, Train: 95.00%, Valid: 87.50% Test: 80.39%\n",
      "Run: 01, Epoch: 174, Loss: 0.2795, Train: 96.67%, Valid: 86.25% Test: 80.39%\n",
      "Run: 01, Epoch: 175, Loss: 0.2534, Train: 97.50%, Valid: 83.75% Test: 80.39%\n",
      "Run: 01, Epoch: 176, Loss: 0.2670, Train: 97.50%, Valid: 82.50% Test: 80.39%\n",
      "Run: 01, Epoch: 177, Loss: 0.3553, Train: 96.67%, Valid: 82.50% Test: 80.39%\n",
      "Run: 01, Epoch: 178, Loss: 0.3092, Train: 95.83%, Valid: 83.75% Test: 80.39%\n",
      "Run: 01, Epoch: 179, Loss: 0.2486, Train: 96.67%, Valid: 83.75% Test: 80.39%\n",
      "Run: 01, Epoch: 180, Loss: 0.3045, Train: 97.50%, Valid: 83.75% Test: 84.31%\n",
      "Run: 01, Epoch: 181, Loss: 0.2514, Train: 97.50%, Valid: 82.50% Test: 86.27%\n",
      "Run: 01, Epoch: 182, Loss: 0.2686, Train: 97.50%, Valid: 85.00% Test: 88.24%\n",
      "Run: 01, Epoch: 183, Loss: 0.2823, Train: 98.33%, Valid: 86.25% Test: 88.24%\n",
      "Run: 01, Epoch: 184, Loss: 0.3049, Train: 99.17%, Valid: 87.50% Test: 88.24%\n",
      "Run: 01, Epoch: 185, Loss: 0.2656, Train: 99.17%, Valid: 86.25% Test: 88.24%\n",
      "Run: 01, Epoch: 186, Loss: 0.2500, Train: 99.17%, Valid: 88.75% Test: 88.24%\n",
      "Run: 01, Epoch: 187, Loss: 0.3007, Train: 99.17%, Valid: 88.75% Test: 88.24%\n",
      "Run: 01, Epoch: 188, Loss: 0.2718, Train: 98.33%, Valid: 87.50% Test: 86.27%\n",
      "Run: 01, Epoch: 189, Loss: 0.2848, Train: 97.50%, Valid: 85.00% Test: 86.27%\n",
      "Run: 01, Epoch: 190, Loss: 0.2921, Train: 98.33%, Valid: 88.75% Test: 84.31%\n",
      "Run: 01, Epoch: 191, Loss: 0.2687, Train: 98.33%, Valid: 85.00% Test: 82.35%\n",
      "Run: 01, Epoch: 192, Loss: 0.2720, Train: 95.83%, Valid: 81.25% Test: 80.39%\n",
      "Run: 01, Epoch: 193, Loss: 0.3428, Train: 95.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 01, Epoch: 194, Loss: 0.2589, Train: 90.83%, Valid: 77.50% Test: 74.51%\n",
      "Run: 01, Epoch: 195, Loss: 0.2967, Train: 90.83%, Valid: 76.25% Test: 74.51%\n",
      "Run: 01, Epoch: 196, Loss: 0.2379, Train: 91.67%, Valid: 78.75% Test: 74.51%\n",
      "Run: 01, Epoch: 197, Loss: 0.3601, Train: 95.00%, Valid: 82.50% Test: 80.39%\n",
      "Run: 01, Epoch: 198, Loss: 0.2521, Train: 95.83%, Valid: 85.00% Test: 82.35%\n",
      "Run: 01, Epoch: 199, Loss: 0.2869, Train: 98.33%, Valid: 88.75% Test: 84.31%\n",
      "Run: 01, Epoch: 200, Loss: 0.3182, Train: 98.33%, Valid: 88.75% Test: 84.31%\n",
      "Run 01:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 91.25\n",
      "  Final Train: 95.83\n",
      "   Final Test: 86.27\n",
      "Run: 02, Epoch: 01, Loss: 1.4953, Train: 29.17%, Valid: 28.75% Test: 23.53%\n",
      "Run: 02, Epoch: 02, Loss: 1.4422, Train: 29.17%, Valid: 28.75% Test: 23.53%\n",
      "Run: 02, Epoch: 03, Loss: 1.4108, Train: 29.17%, Valid: 30.00% Test: 25.49%\n",
      "Run: 02, Epoch: 04, Loss: 1.3613, Train: 43.33%, Valid: 36.25% Test: 47.06%\n",
      "Run: 02, Epoch: 05, Loss: 1.3201, Train: 50.83%, Valid: 45.00% Test: 72.55%\n",
      "Run: 02, Epoch: 06, Loss: 1.2887, Train: 46.67%, Valid: 40.00% Test: 64.71%\n",
      "Run: 02, Epoch: 07, Loss: 1.2413, Train: 45.83%, Valid: 40.00% Test: 64.71%\n",
      "Run: 02, Epoch: 08, Loss: 1.1989, Train: 45.83%, Valid: 40.00% Test: 64.71%\n",
      "Run: 02, Epoch: 09, Loss: 1.1946, Train: 45.83%, Valid: 40.00% Test: 64.71%\n",
      "Run: 02, Epoch: 10, Loss: 1.1642, Train: 45.83%, Valid: 40.00% Test: 64.71%\n",
      "Run: 02, Epoch: 11, Loss: 1.1006, Train: 46.67%, Valid: 40.00% Test: 64.71%\n",
      "Run: 02, Epoch: 12, Loss: 1.0833, Train: 46.67%, Valid: 40.00% Test: 64.71%\n",
      "Run: 02, Epoch: 13, Loss: 1.0433, Train: 46.67%, Valid: 40.00% Test: 64.71%\n",
      "Run: 02, Epoch: 14, Loss: 1.0747, Train: 46.67%, Valid: 40.00% Test: 66.67%\n",
      "Run: 02, Epoch: 15, Loss: 1.0179, Train: 49.17%, Valid: 42.50% Test: 66.67%\n",
      "Run: 02, Epoch: 16, Loss: 1.0063, Train: 50.83%, Valid: 43.75% Test: 66.67%\n",
      "Run: 02, Epoch: 17, Loss: 0.9603, Train: 55.00%, Valid: 45.00% Test: 70.59%\n",
      "Run: 02, Epoch: 18, Loss: 0.9307, Train: 62.50%, Valid: 50.00% Test: 78.43%\n",
      "Run: 02, Epoch: 19, Loss: 0.9150, Train: 66.67%, Valid: 56.25% Test: 82.35%\n",
      "Run: 02, Epoch: 20, Loss: 0.9446, Train: 68.33%, Valid: 58.75% Test: 82.35%\n",
      "Run: 02, Epoch: 21, Loss: 0.8923, Train: 69.17%, Valid: 58.75% Test: 82.35%\n",
      "Run: 02, Epoch: 22, Loss: 0.8798, Train: 69.17%, Valid: 58.75% Test: 82.35%\n",
      "Run: 02, Epoch: 23, Loss: 0.8504, Train: 70.00%, Valid: 60.00% Test: 82.35%\n",
      "Run: 02, Epoch: 24, Loss: 0.8935, Train: 71.67%, Valid: 61.25% Test: 84.31%\n",
      "Run: 02, Epoch: 25, Loss: 0.8103, Train: 70.83%, Valid: 61.25% Test: 84.31%\n",
      "Run: 02, Epoch: 26, Loss: 0.8100, Train: 70.83%, Valid: 62.50% Test: 84.31%\n",
      "Run: 02, Epoch: 27, Loss: 0.8163, Train: 71.67%, Valid: 63.75% Test: 84.31%\n",
      "Run: 02, Epoch: 28, Loss: 0.8033, Train: 75.83%, Valid: 66.25% Test: 84.31%\n",
      "Run: 02, Epoch: 29, Loss: 0.7722, Train: 75.83%, Valid: 66.25% Test: 84.31%\n",
      "Run: 02, Epoch: 30, Loss: 0.7551, Train: 75.00%, Valid: 66.25% Test: 86.27%\n",
      "Run: 02, Epoch: 31, Loss: 0.7804, Train: 74.17%, Valid: 66.25% Test: 86.27%\n",
      "Run: 02, Epoch: 32, Loss: 0.7375, Train: 75.00%, Valid: 66.25% Test: 86.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 33, Loss: 0.7790, Train: 75.00%, Valid: 65.00% Test: 86.27%\n",
      "Run: 02, Epoch: 34, Loss: 0.7297, Train: 76.67%, Valid: 66.25% Test: 86.27%\n",
      "Run: 02, Epoch: 35, Loss: 0.7167, Train: 77.50%, Valid: 66.25% Test: 86.27%\n",
      "Run: 02, Epoch: 36, Loss: 0.7213, Train: 77.50%, Valid: 66.25% Test: 86.27%\n",
      "Run: 02, Epoch: 37, Loss: 0.7491, Train: 80.00%, Valid: 66.25% Test: 88.24%\n",
      "Run: 02, Epoch: 38, Loss: 0.7140, Train: 80.00%, Valid: 67.50% Test: 88.24%\n",
      "Run: 02, Epoch: 39, Loss: 0.6872, Train: 81.67%, Valid: 68.75% Test: 88.24%\n",
      "Run: 02, Epoch: 40, Loss: 0.6900, Train: 82.50%, Valid: 70.00% Test: 88.24%\n",
      "Run: 02, Epoch: 41, Loss: 0.6608, Train: 84.17%, Valid: 71.25% Test: 88.24%\n",
      "Run: 02, Epoch: 42, Loss: 0.6943, Train: 83.33%, Valid: 71.25% Test: 88.24%\n",
      "Run: 02, Epoch: 43, Loss: 0.6769, Train: 84.17%, Valid: 73.75% Test: 88.24%\n",
      "Run: 02, Epoch: 44, Loss: 0.6313, Train: 84.17%, Valid: 73.75% Test: 88.24%\n",
      "Run: 02, Epoch: 45, Loss: 0.6285, Train: 85.00%, Valid: 75.00% Test: 88.24%\n",
      "Run: 02, Epoch: 46, Loss: 0.6581, Train: 83.33%, Valid: 75.00% Test: 88.24%\n",
      "Run: 02, Epoch: 47, Loss: 0.6528, Train: 85.00%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 48, Loss: 0.6234, Train: 85.83%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 49, Loss: 0.6252, Train: 85.83%, Valid: 76.25% Test: 90.20%\n",
      "Run: 02, Epoch: 50, Loss: 0.6244, Train: 85.83%, Valid: 76.25% Test: 90.20%\n",
      "Run: 02, Epoch: 51, Loss: 0.5965, Train: 85.83%, Valid: 76.25% Test: 90.20%\n",
      "Run: 02, Epoch: 52, Loss: 0.5846, Train: 85.83%, Valid: 75.00% Test: 88.24%\n",
      "Run: 02, Epoch: 53, Loss: 0.6465, Train: 81.67%, Valid: 73.75% Test: 88.24%\n",
      "Run: 02, Epoch: 54, Loss: 0.5751, Train: 79.17%, Valid: 72.50% Test: 86.27%\n",
      "Run: 02, Epoch: 55, Loss: 0.5696, Train: 80.83%, Valid: 73.75% Test: 88.24%\n",
      "Run: 02, Epoch: 56, Loss: 0.6210, Train: 85.00%, Valid: 75.00% Test: 88.24%\n",
      "Run: 02, Epoch: 57, Loss: 0.5620, Train: 85.00%, Valid: 76.25% Test: 88.24%\n",
      "Run: 02, Epoch: 58, Loss: 0.5783, Train: 88.33%, Valid: 78.75% Test: 90.20%\n",
      "Run: 02, Epoch: 59, Loss: 0.5094, Train: 89.17%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 60, Loss: 0.5480, Train: 92.50%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 61, Loss: 0.5216, Train: 90.00%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 62, Loss: 0.5196, Train: 85.00%, Valid: 76.25% Test: 88.24%\n",
      "Run: 02, Epoch: 63, Loss: 0.5591, Train: 80.00%, Valid: 70.00% Test: 86.27%\n",
      "Run: 02, Epoch: 64, Loss: 0.5480, Train: 80.00%, Valid: 67.50% Test: 86.27%\n",
      "Run: 02, Epoch: 65, Loss: 0.5382, Train: 79.17%, Valid: 66.25% Test: 86.27%\n",
      "Run: 02, Epoch: 66, Loss: 0.5741, Train: 80.00%, Valid: 71.25% Test: 86.27%\n",
      "Run: 02, Epoch: 67, Loss: 0.4815, Train: 83.33%, Valid: 71.25% Test: 86.27%\n",
      "Run: 02, Epoch: 68, Loss: 0.4767, Train: 83.33%, Valid: 71.25% Test: 88.24%\n",
      "Run: 02, Epoch: 69, Loss: 0.5191, Train: 83.33%, Valid: 73.75% Test: 88.24%\n",
      "Run: 02, Epoch: 70, Loss: 0.5282, Train: 85.00%, Valid: 75.00% Test: 90.20%\n",
      "Run: 02, Epoch: 71, Loss: 0.5197, Train: 86.67%, Valid: 77.50% Test: 90.20%\n",
      "Run: 02, Epoch: 72, Loss: 0.4968, Train: 89.17%, Valid: 82.50% Test: 90.20%\n",
      "Run: 02, Epoch: 73, Loss: 0.5048, Train: 92.50%, Valid: 82.50% Test: 92.16%\n",
      "Run: 02, Epoch: 74, Loss: 0.5194, Train: 94.17%, Valid: 83.75% Test: 92.16%\n",
      "Run: 02, Epoch: 75, Loss: 0.4556, Train: 92.50%, Valid: 85.00% Test: 90.20%\n",
      "Run: 02, Epoch: 76, Loss: 0.4625, Train: 88.33%, Valid: 81.25% Test: 88.24%\n",
      "Run: 02, Epoch: 77, Loss: 0.4876, Train: 89.17%, Valid: 78.75% Test: 90.20%\n",
      "Run: 02, Epoch: 78, Loss: 0.4397, Train: 91.67%, Valid: 81.25% Test: 92.16%\n",
      "Run: 02, Epoch: 79, Loss: 0.4515, Train: 93.33%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 80, Loss: 0.4455, Train: 90.83%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 81, Loss: 0.4384, Train: 90.00%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 82, Loss: 0.4823, Train: 90.00%, Valid: 81.25% Test: 92.16%\n",
      "Run: 02, Epoch: 83, Loss: 0.4498, Train: 86.67%, Valid: 77.50% Test: 90.20%\n",
      "Run: 02, Epoch: 84, Loss: 0.4157, Train: 87.50%, Valid: 78.75% Test: 90.20%\n",
      "Run: 02, Epoch: 85, Loss: 0.4946, Train: 90.00%, Valid: 77.50% Test: 90.20%\n",
      "Run: 02, Epoch: 86, Loss: 0.4358, Train: 92.50%, Valid: 82.50% Test: 88.24%\n",
      "Run: 02, Epoch: 87, Loss: 0.3823, Train: 94.17%, Valid: 81.25% Test: 88.24%\n",
      "Run: 02, Epoch: 88, Loss: 0.4361, Train: 95.83%, Valid: 80.00% Test: 88.24%\n",
      "Run: 02, Epoch: 89, Loss: 0.4490, Train: 95.00%, Valid: 81.25% Test: 88.24%\n",
      "Run: 02, Epoch: 90, Loss: 0.4443, Train: 94.17%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 91, Loss: 0.3964, Train: 91.67%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 92, Loss: 0.4386, Train: 90.83%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 93, Loss: 0.4227, Train: 88.33%, Valid: 75.00% Test: 90.20%\n",
      "Run: 02, Epoch: 94, Loss: 0.4012, Train: 85.83%, Valid: 72.50% Test: 90.20%\n",
      "Run: 02, Epoch: 95, Loss: 0.3689, Train: 84.17%, Valid: 72.50% Test: 90.20%\n",
      "Run: 02, Epoch: 96, Loss: 0.3800, Train: 85.83%, Valid: 73.75% Test: 90.20%\n",
      "Run: 02, Epoch: 97, Loss: 0.4635, Train: 90.83%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 98, Loss: 0.4339, Train: 96.67%, Valid: 81.25% Test: 92.16%\n",
      "Run: 02, Epoch: 99, Loss: 0.4059, Train: 90.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 02, Epoch: 100, Loss: 0.3554, Train: 80.00%, Valid: 67.50% Test: 60.78%\n",
      "Run: 02, Epoch: 101, Loss: 0.4086, Train: 79.17%, Valid: 63.75% Test: 58.82%\n",
      "Run: 02, Epoch: 102, Loss: 0.3838, Train: 85.83%, Valid: 70.00% Test: 70.59%\n",
      "Run: 02, Epoch: 103, Loss: 0.3677, Train: 92.50%, Valid: 77.50% Test: 80.39%\n",
      "Run: 02, Epoch: 104, Loss: 0.4398, Train: 93.33%, Valid: 81.25% Test: 88.24%\n",
      "Run: 02, Epoch: 105, Loss: 0.4039, Train: 91.67%, Valid: 78.75% Test: 92.16%\n",
      "Run: 02, Epoch: 106, Loss: 0.4299, Train: 87.50%, Valid: 75.00% Test: 90.20%\n",
      "Run: 02, Epoch: 107, Loss: 0.3504, Train: 86.67%, Valid: 75.00% Test: 90.20%\n",
      "Run: 02, Epoch: 108, Loss: 0.3821, Train: 85.00%, Valid: 75.00% Test: 88.24%\n",
      "Run: 02, Epoch: 109, Loss: 0.3436, Train: 85.00%, Valid: 73.75% Test: 88.24%\n",
      "Run: 02, Epoch: 110, Loss: 0.3153, Train: 87.50%, Valid: 75.00% Test: 90.20%\n",
      "Run: 02, Epoch: 111, Loss: 0.3686, Train: 89.17%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 112, Loss: 0.3340, Train: 90.00%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 113, Loss: 0.3909, Train: 90.00%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 114, Loss: 0.3396, Train: 90.83%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 115, Loss: 0.3759, Train: 91.67%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 116, Loss: 0.4059, Train: 94.17%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 117, Loss: 0.3532, Train: 95.83%, Valid: 80.00% Test: 88.24%\n",
      "Run: 02, Epoch: 118, Loss: 0.3677, Train: 96.67%, Valid: 78.75% Test: 86.27%\n",
      "Run: 02, Epoch: 119, Loss: 0.3415, Train: 95.83%, Valid: 82.50% Test: 82.35%\n",
      "Run: 02, Epoch: 120, Loss: 0.3240, Train: 97.50%, Valid: 82.50% Test: 82.35%\n",
      "Run: 02, Epoch: 121, Loss: 0.3256, Train: 96.67%, Valid: 81.25% Test: 80.39%\n",
      "Run: 02, Epoch: 122, Loss: 0.3368, Train: 95.83%, Valid: 82.50% Test: 82.35%\n",
      "Run: 02, Epoch: 123, Loss: 0.3144, Train: 96.67%, Valid: 78.75% Test: 90.20%\n",
      "Run: 02, Epoch: 124, Loss: 0.3720, Train: 95.83%, Valid: 73.75% Test: 90.20%\n",
      "Run: 02, Epoch: 125, Loss: 0.3311, Train: 92.50%, Valid: 75.00% Test: 90.20%\n",
      "Run: 02, Epoch: 126, Loss: 0.3181, Train: 89.17%, Valid: 75.00% Test: 90.20%\n",
      "Run: 02, Epoch: 127, Loss: 0.2970, Train: 91.67%, Valid: 76.25% Test: 92.16%\n",
      "Run: 02, Epoch: 128, Loss: 0.3391, Train: 92.50%, Valid: 82.50% Test: 94.12%\n",
      "Run: 02, Epoch: 129, Loss: 0.3098, Train: 96.67%, Valid: 83.75% Test: 94.12%\n",
      "Run: 02, Epoch: 130, Loss: 0.3099, Train: 94.17%, Valid: 83.75% Test: 94.12%\n",
      "Run: 02, Epoch: 131, Loss: 0.3421, Train: 94.17%, Valid: 83.75% Test: 92.16%\n",
      "Run: 02, Epoch: 132, Loss: 0.3841, Train: 94.17%, Valid: 82.50% Test: 92.16%\n",
      "Run: 02, Epoch: 133, Loss: 0.3290, Train: 93.33%, Valid: 82.50% Test: 90.20%\n",
      "Run: 02, Epoch: 134, Loss: 0.2803, Train: 91.67%, Valid: 81.25% Test: 90.20%\n",
      "Run: 02, Epoch: 135, Loss: 0.2901, Train: 91.67%, Valid: 81.25% Test: 90.20%\n",
      "Run: 02, Epoch: 136, Loss: 0.3150, Train: 90.83%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 137, Loss: 0.2709, Train: 95.00%, Valid: 81.25% Test: 90.20%\n",
      "Run: 02, Epoch: 138, Loss: 0.3115, Train: 95.00%, Valid: 81.25% Test: 88.24%\n",
      "Run: 02, Epoch: 139, Loss: 0.2962, Train: 95.83%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 140, Loss: 0.2684, Train: 95.83%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 141, Loss: 0.2907, Train: 95.83%, Valid: 80.00% Test: 86.27%\n",
      "Run: 02, Epoch: 142, Loss: 0.2903, Train: 95.00%, Valid: 81.25% Test: 90.20%\n",
      "Run: 02, Epoch: 143, Loss: 0.2546, Train: 93.33%, Valid: 83.75% Test: 90.20%\n",
      "Run: 02, Epoch: 144, Loss: 0.3074, Train: 92.50%, Valid: 83.75% Test: 92.16%\n",
      "Run: 02, Epoch: 145, Loss: 0.2367, Train: 91.67%, Valid: 81.25% Test: 92.16%\n",
      "Run: 02, Epoch: 146, Loss: 0.3189, Train: 91.67%, Valid: 81.25% Test: 92.16%\n",
      "Run: 02, Epoch: 147, Loss: 0.2998, Train: 89.17%, Valid: 78.75% Test: 92.16%\n",
      "Run: 02, Epoch: 148, Loss: 0.2719, Train: 87.50%, Valid: 77.50% Test: 90.20%\n",
      "Run: 02, Epoch: 149, Loss: 0.2699, Train: 90.00%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 150, Loss: 0.2830, Train: 90.83%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 151, Loss: 0.2637, Train: 94.17%, Valid: 83.75% Test: 92.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 152, Loss: 0.2726, Train: 95.83%, Valid: 81.25% Test: 92.16%\n",
      "Run: 02, Epoch: 153, Loss: 0.2603, Train: 96.67%, Valid: 82.50% Test: 94.12%\n",
      "Run: 02, Epoch: 154, Loss: 0.2886, Train: 97.50%, Valid: 78.75% Test: 90.20%\n",
      "Run: 02, Epoch: 155, Loss: 0.3146, Train: 95.00%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 156, Loss: 0.2727, Train: 94.17%, Valid: 71.25% Test: 78.43%\n",
      "Run: 02, Epoch: 157, Loss: 0.2825, Train: 95.00%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 158, Loss: 0.2979, Train: 96.67%, Valid: 73.75% Test: 80.39%\n",
      "Run: 02, Epoch: 159, Loss: 0.2363, Train: 97.50%, Valid: 77.50% Test: 86.27%\n",
      "Run: 02, Epoch: 160, Loss: 0.3054, Train: 98.33%, Valid: 85.00% Test: 88.24%\n",
      "Run: 02, Epoch: 161, Loss: 0.2572, Train: 97.50%, Valid: 83.75% Test: 94.12%\n",
      "Run: 02, Epoch: 162, Loss: 0.2965, Train: 96.67%, Valid: 82.50% Test: 92.16%\n",
      "Run: 02, Epoch: 163, Loss: 0.2734, Train: 95.00%, Valid: 81.25% Test: 90.20%\n",
      "Run: 02, Epoch: 164, Loss: 0.2520, Train: 91.67%, Valid: 78.75% Test: 90.20%\n",
      "Run: 02, Epoch: 165, Loss: 0.3125, Train: 93.33%, Valid: 80.00% Test: 90.20%\n",
      "Run: 02, Epoch: 166, Loss: 0.2864, Train: 96.67%, Valid: 78.75% Test: 92.16%\n",
      "Run: 02, Epoch: 167, Loss: 0.2864, Train: 97.50%, Valid: 78.75% Test: 86.27%\n",
      "Run: 02, Epoch: 168, Loss: 0.2359, Train: 99.17%, Valid: 82.50% Test: 84.31%\n",
      "Run: 02, Epoch: 169, Loss: 0.2622, Train: 98.33%, Valid: 83.75% Test: 84.31%\n",
      "Run: 02, Epoch: 170, Loss: 0.2990, Train: 96.67%, Valid: 77.50% Test: 82.35%\n",
      "Run: 02, Epoch: 171, Loss: 0.2295, Train: 96.67%, Valid: 77.50% Test: 80.39%\n",
      "Run: 02, Epoch: 172, Loss: 0.3027, Train: 96.67%, Valid: 80.00% Test: 82.35%\n",
      "Run: 02, Epoch: 173, Loss: 0.2265, Train: 96.67%, Valid: 83.75% Test: 90.20%\n",
      "Run: 02, Epoch: 174, Loss: 0.2915, Train: 95.83%, Valid: 87.50% Test: 92.16%\n",
      "Run: 02, Epoch: 175, Loss: 0.2372, Train: 96.67%, Valid: 85.00% Test: 92.16%\n",
      "Run: 02, Epoch: 176, Loss: 0.2921, Train: 96.67%, Valid: 85.00% Test: 92.16%\n",
      "Run: 02, Epoch: 177, Loss: 0.2337, Train: 97.50%, Valid: 82.50% Test: 92.16%\n",
      "Run: 02, Epoch: 178, Loss: 0.2546, Train: 95.83%, Valid: 82.50% Test: 90.20%\n",
      "Run: 02, Epoch: 179, Loss: 0.2934, Train: 93.33%, Valid: 81.25% Test: 90.20%\n",
      "Run: 02, Epoch: 180, Loss: 0.2764, Train: 93.33%, Valid: 80.00% Test: 92.16%\n",
      "Run: 02, Epoch: 181, Loss: 0.2835, Train: 93.33%, Valid: 78.75% Test: 92.16%\n",
      "Run: 02, Epoch: 182, Loss: 0.1966, Train: 93.33%, Valid: 78.75% Test: 92.16%\n",
      "Run: 02, Epoch: 183, Loss: 0.2994, Train: 95.00%, Valid: 81.25% Test: 92.16%\n",
      "Run: 02, Epoch: 184, Loss: 0.2963, Train: 97.50%, Valid: 81.25% Test: 92.16%\n",
      "Run: 02, Epoch: 185, Loss: 0.2385, Train: 99.17%, Valid: 82.50% Test: 92.16%\n",
      "Run: 02, Epoch: 186, Loss: 0.3022, Train: 98.33%, Valid: 82.50% Test: 86.27%\n",
      "Run: 02, Epoch: 187, Loss: 0.3071, Train: 98.33%, Valid: 83.75% Test: 84.31%\n",
      "Run: 02, Epoch: 188, Loss: 0.2286, Train: 98.33%, Valid: 81.25% Test: 84.31%\n",
      "Run: 02, Epoch: 189, Loss: 0.2304, Train: 98.33%, Valid: 78.75% Test: 84.31%\n",
      "Run: 02, Epoch: 190, Loss: 0.2378, Train: 97.50%, Valid: 78.75% Test: 86.27%\n",
      "Run: 02, Epoch: 191, Loss: 0.2428, Train: 95.83%, Valid: 81.25% Test: 86.27%\n",
      "Run: 02, Epoch: 192, Loss: 0.2830, Train: 96.67%, Valid: 80.00% Test: 86.27%\n",
      "Run: 02, Epoch: 193, Loss: 0.2958, Train: 94.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 02, Epoch: 194, Loss: 0.2152, Train: 94.17%, Valid: 75.00% Test: 82.35%\n",
      "Run: 02, Epoch: 195, Loss: 0.1974, Train: 92.50%, Valid: 72.50% Test: 80.39%\n",
      "Run: 02, Epoch: 196, Loss: 0.2132, Train: 89.17%, Valid: 72.50% Test: 80.39%\n",
      "Run: 02, Epoch: 197, Loss: 0.2517, Train: 87.50%, Valid: 75.00% Test: 80.39%\n",
      "Run: 02, Epoch: 198, Loss: 0.2366, Train: 87.50%, Valid: 76.25% Test: 84.31%\n",
      "Run: 02, Epoch: 199, Loss: 0.2900, Train: 93.33%, Valid: 76.25% Test: 86.27%\n",
      "Run: 02, Epoch: 200, Loss: 0.2169, Train: 95.83%, Valid: 73.75% Test: 88.24%\n",
      "Run 02:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 87.50\n",
      "  Final Train: 95.83\n",
      "   Final Test: 92.16\n",
      "Run: 03, Epoch: 01, Loss: 2.0296, Train: 9.17%, Valid: 12.50% Test: 9.80%\n",
      "Run: 03, Epoch: 02, Loss: 1.9527, Train: 8.33%, Valid: 8.75% Test: 7.84%\n",
      "Run: 03, Epoch: 03, Loss: 1.8730, Train: 8.33%, Valid: 8.75% Test: 7.84%\n",
      "Run: 03, Epoch: 04, Loss: 1.8148, Train: 8.33%, Valid: 8.75% Test: 7.84%\n",
      "Run: 03, Epoch: 05, Loss: 1.7456, Train: 8.33%, Valid: 8.75% Test: 7.84%\n",
      "Run: 03, Epoch: 06, Loss: 1.6770, Train: 8.33%, Valid: 8.75% Test: 7.84%\n",
      "Run: 03, Epoch: 07, Loss: 1.6081, Train: 8.33%, Valid: 11.25% Test: 7.84%\n",
      "Run: 03, Epoch: 08, Loss: 1.5391, Train: 9.17%, Valid: 12.50% Test: 9.80%\n",
      "Run: 03, Epoch: 09, Loss: 1.5023, Train: 15.83%, Valid: 18.75% Test: 25.49%\n",
      "Run: 03, Epoch: 10, Loss: 1.4135, Train: 35.00%, Valid: 31.25% Test: 35.29%\n",
      "Run: 03, Epoch: 11, Loss: 1.3652, Train: 30.83%, Valid: 28.75% Test: 39.22%\n",
      "Run: 03, Epoch: 12, Loss: 1.2994, Train: 29.17%, Valid: 26.25% Test: 31.37%\n",
      "Run: 03, Epoch: 13, Loss: 1.2377, Train: 28.33%, Valid: 26.25% Test: 31.37%\n",
      "Run: 03, Epoch: 14, Loss: 1.1944, Train: 29.17%, Valid: 26.25% Test: 31.37%\n",
      "Run: 03, Epoch: 15, Loss: 1.1671, Train: 30.83%, Valid: 27.50% Test: 31.37%\n",
      "Run: 03, Epoch: 16, Loss: 1.1129, Train: 50.83%, Valid: 51.25% Test: 50.98%\n",
      "Run: 03, Epoch: 17, Loss: 1.0687, Train: 63.33%, Valid: 65.00% Test: 62.75%\n",
      "Run: 03, Epoch: 18, Loss: 1.0605, Train: 74.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 03, Epoch: 19, Loss: 1.0156, Train: 75.00%, Valid: 70.00% Test: 76.47%\n",
      "Run: 03, Epoch: 20, Loss: 1.0077, Train: 70.83%, Valid: 73.75% Test: 74.51%\n",
      "Run: 03, Epoch: 21, Loss: 0.9760, Train: 72.50%, Valid: 73.75% Test: 74.51%\n",
      "Run: 03, Epoch: 22, Loss: 0.9421, Train: 73.33%, Valid: 73.75% Test: 74.51%\n",
      "Run: 03, Epoch: 23, Loss: 0.9178, Train: 71.67%, Valid: 73.75% Test: 74.51%\n",
      "Run: 03, Epoch: 24, Loss: 0.8982, Train: 71.67%, Valid: 73.75% Test: 72.55%\n",
      "Run: 03, Epoch: 25, Loss: 0.9069, Train: 70.83%, Valid: 73.75% Test: 74.51%\n",
      "Run: 03, Epoch: 26, Loss: 0.8922, Train: 72.50%, Valid: 72.50% Test: 76.47%\n",
      "Run: 03, Epoch: 27, Loss: 0.8382, Train: 72.50%, Valid: 71.25% Test: 76.47%\n",
      "Run: 03, Epoch: 28, Loss: 0.8540, Train: 71.67%, Valid: 70.00% Test: 76.47%\n",
      "Run: 03, Epoch: 29, Loss: 0.8244, Train: 69.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 03, Epoch: 30, Loss: 0.8032, Train: 74.17%, Valid: 72.50% Test: 80.39%\n",
      "Run: 03, Epoch: 31, Loss: 0.8552, Train: 78.33%, Valid: 73.75% Test: 80.39%\n",
      "Run: 03, Epoch: 32, Loss: 0.8165, Train: 80.00%, Valid: 78.75% Test: 80.39%\n",
      "Run: 03, Epoch: 33, Loss: 0.7929, Train: 81.67%, Valid: 77.50% Test: 80.39%\n",
      "Run: 03, Epoch: 34, Loss: 0.7677, Train: 78.33%, Valid: 75.00% Test: 78.43%\n",
      "Run: 03, Epoch: 35, Loss: 0.7879, Train: 77.50%, Valid: 75.00% Test: 76.47%\n",
      "Run: 03, Epoch: 36, Loss: 0.7975, Train: 75.83%, Valid: 75.00% Test: 76.47%\n",
      "Run: 03, Epoch: 37, Loss: 0.7499, Train: 75.83%, Valid: 73.75% Test: 76.47%\n",
      "Run: 03, Epoch: 38, Loss: 0.7440, Train: 76.67%, Valid: 71.25% Test: 74.51%\n",
      "Run: 03, Epoch: 39, Loss: 0.7511, Train: 79.17%, Valid: 75.00% Test: 74.51%\n",
      "Run: 03, Epoch: 40, Loss: 0.7541, Train: 80.83%, Valid: 76.25% Test: 74.51%\n",
      "Run: 03, Epoch: 41, Loss: 0.7564, Train: 82.50%, Valid: 73.75% Test: 74.51%\n",
      "Run: 03, Epoch: 42, Loss: 0.7183, Train: 82.50%, Valid: 73.75% Test: 76.47%\n",
      "Run: 03, Epoch: 43, Loss: 0.7338, Train: 82.50%, Valid: 77.50% Test: 76.47%\n",
      "Run: 03, Epoch: 44, Loss: 0.7492, Train: 82.50%, Valid: 80.00% Test: 78.43%\n",
      "Run: 03, Epoch: 45, Loss: 0.7082, Train: 81.67%, Valid: 80.00% Test: 78.43%\n",
      "Run: 03, Epoch: 46, Loss: 0.7003, Train: 80.00%, Valid: 78.75% Test: 78.43%\n",
      "Run: 03, Epoch: 47, Loss: 0.6923, Train: 80.00%, Valid: 76.25% Test: 76.47%\n",
      "Run: 03, Epoch: 48, Loss: 0.6722, Train: 80.00%, Valid: 76.25% Test: 76.47%\n",
      "Run: 03, Epoch: 49, Loss: 0.6959, Train: 79.17%, Valid: 76.25% Test: 76.47%\n",
      "Run: 03, Epoch: 50, Loss: 0.7043, Train: 80.00%, Valid: 76.25% Test: 76.47%\n",
      "Run: 03, Epoch: 51, Loss: 0.6451, Train: 78.33%, Valid: 78.75% Test: 76.47%\n",
      "Run: 03, Epoch: 52, Loss: 0.6929, Train: 80.83%, Valid: 80.00% Test: 76.47%\n",
      "Run: 03, Epoch: 53, Loss: 0.6716, Train: 82.50%, Valid: 80.00% Test: 78.43%\n",
      "Run: 03, Epoch: 54, Loss: 0.6814, Train: 84.17%, Valid: 80.00% Test: 78.43%\n",
      "Run: 03, Epoch: 55, Loss: 0.6761, Train: 86.67%, Valid: 81.25% Test: 84.31%\n",
      "Run: 03, Epoch: 56, Loss: 0.6492, Train: 88.33%, Valid: 83.75% Test: 84.31%\n",
      "Run: 03, Epoch: 57, Loss: 0.6602, Train: 89.17%, Valid: 85.00% Test: 84.31%\n",
      "Run: 03, Epoch: 58, Loss: 0.6596, Train: 90.83%, Valid: 83.75% Test: 84.31%\n",
      "Run: 03, Epoch: 59, Loss: 0.6544, Train: 89.17%, Valid: 82.50% Test: 84.31%\n",
      "Run: 03, Epoch: 60, Loss: 0.6423, Train: 89.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 03, Epoch: 61, Loss: 0.6262, Train: 86.67%, Valid: 83.75% Test: 84.31%\n",
      "Run: 03, Epoch: 62, Loss: 0.5951, Train: 84.17%, Valid: 81.25% Test: 82.35%\n",
      "Run: 03, Epoch: 63, Loss: 0.6519, Train: 85.83%, Valid: 83.75% Test: 84.31%\n",
      "Run: 03, Epoch: 64, Loss: 0.6399, Train: 85.00%, Valid: 85.00% Test: 84.31%\n",
      "Run: 03, Epoch: 65, Loss: 0.6027, Train: 84.17%, Valid: 80.00% Test: 84.31%\n",
      "Run: 03, Epoch: 66, Loss: 0.6002, Train: 84.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 03, Epoch: 67, Loss: 0.6287, Train: 85.83%, Valid: 81.25% Test: 86.27%\n",
      "Run: 03, Epoch: 68, Loss: 0.6182, Train: 87.50%, Valid: 81.25% Test: 86.27%\n",
      "Run: 03, Epoch: 69, Loss: 0.6055, Train: 87.50%, Valid: 81.25% Test: 84.31%\n",
      "Run: 03, Epoch: 70, Loss: 0.6337, Train: 85.00%, Valid: 81.25% Test: 84.31%\n",
      "Run: 03, Epoch: 71, Loss: 0.5947, Train: 83.33%, Valid: 80.00% Test: 82.35%\n",
      "Run: 03, Epoch: 72, Loss: 0.5830, Train: 80.83%, Valid: 78.75% Test: 78.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 73, Loss: 0.6211, Train: 80.83%, Valid: 80.00% Test: 78.43%\n",
      "Run: 03, Epoch: 74, Loss: 0.5927, Train: 84.17%, Valid: 83.75% Test: 82.35%\n",
      "Run: 03, Epoch: 75, Loss: 0.5661, Train: 85.83%, Valid: 86.25% Test: 82.35%\n",
      "Run: 03, Epoch: 76, Loss: 0.5958, Train: 88.33%, Valid: 87.50% Test: 82.35%\n",
      "Run: 03, Epoch: 77, Loss: 0.5713, Train: 92.50%, Valid: 87.50% Test: 84.31%\n",
      "Run: 03, Epoch: 78, Loss: 0.5758, Train: 94.17%, Valid: 87.50% Test: 84.31%\n",
      "Run: 03, Epoch: 79, Loss: 0.5738, Train: 97.50%, Valid: 86.25% Test: 86.27%\n",
      "Run: 03, Epoch: 80, Loss: 0.5990, Train: 96.67%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 81, Loss: 0.5787, Train: 92.50%, Valid: 86.25% Test: 86.27%\n",
      "Run: 03, Epoch: 82, Loss: 0.5899, Train: 90.00%, Valid: 83.75% Test: 84.31%\n",
      "Run: 03, Epoch: 83, Loss: 0.5468, Train: 88.33%, Valid: 83.75% Test: 86.27%\n",
      "Run: 03, Epoch: 84, Loss: 0.5438, Train: 87.50%, Valid: 85.00% Test: 86.27%\n",
      "Run: 03, Epoch: 85, Loss: 0.5750, Train: 84.17%, Valid: 83.75% Test: 84.31%\n",
      "Run: 03, Epoch: 86, Loss: 0.5517, Train: 83.33%, Valid: 83.75% Test: 84.31%\n",
      "Run: 03, Epoch: 87, Loss: 0.5497, Train: 85.83%, Valid: 83.75% Test: 84.31%\n",
      "Run: 03, Epoch: 88, Loss: 0.5614, Train: 88.33%, Valid: 86.25% Test: 84.31%\n",
      "Run: 03, Epoch: 89, Loss: 0.5159, Train: 94.17%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 90, Loss: 0.4947, Train: 95.83%, Valid: 86.25% Test: 82.35%\n",
      "Run: 03, Epoch: 91, Loss: 0.5542, Train: 96.67%, Valid: 86.25% Test: 82.35%\n",
      "Run: 03, Epoch: 92, Loss: 0.5449, Train: 95.00%, Valid: 86.25% Test: 82.35%\n",
      "Run: 03, Epoch: 93, Loss: 0.5223, Train: 92.50%, Valid: 86.25% Test: 86.27%\n",
      "Run: 03, Epoch: 94, Loss: 0.5177, Train: 92.50%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 95, Loss: 0.5183, Train: 90.00%, Valid: 86.25% Test: 84.31%\n",
      "Run: 03, Epoch: 96, Loss: 0.4921, Train: 90.83%, Valid: 86.25% Test: 84.31%\n",
      "Run: 03, Epoch: 97, Loss: 0.5161, Train: 90.83%, Valid: 86.25% Test: 86.27%\n",
      "Run: 03, Epoch: 98, Loss: 0.5300, Train: 89.17%, Valid: 87.50% Test: 82.35%\n",
      "Run: 03, Epoch: 99, Loss: 0.5244, Train: 90.83%, Valid: 88.75% Test: 84.31%\n",
      "Run: 03, Epoch: 100, Loss: 0.4668, Train: 94.17%, Valid: 88.75% Test: 84.31%\n",
      "Run: 03, Epoch: 101, Loss: 0.4704, Train: 94.17%, Valid: 88.75% Test: 84.31%\n",
      "Run: 03, Epoch: 102, Loss: 0.5213, Train: 92.50%, Valid: 86.25% Test: 84.31%\n",
      "Run: 03, Epoch: 103, Loss: 0.4818, Train: 91.67%, Valid: 87.50% Test: 84.31%\n",
      "Run: 03, Epoch: 104, Loss: 0.5046, Train: 90.83%, Valid: 88.75% Test: 84.31%\n",
      "Run: 03, Epoch: 105, Loss: 0.5115, Train: 91.67%, Valid: 88.75% Test: 86.27%\n",
      "Run: 03, Epoch: 106, Loss: 0.5336, Train: 91.67%, Valid: 88.75% Test: 86.27%\n",
      "Run: 03, Epoch: 107, Loss: 0.4812, Train: 91.67%, Valid: 88.75% Test: 86.27%\n",
      "Run: 03, Epoch: 108, Loss: 0.4824, Train: 92.50%, Valid: 88.75% Test: 86.27%\n",
      "Run: 03, Epoch: 109, Loss: 0.4818, Train: 92.50%, Valid: 88.75% Test: 84.31%\n",
      "Run: 03, Epoch: 110, Loss: 0.4695, Train: 93.33%, Valid: 88.75% Test: 84.31%\n",
      "Run: 03, Epoch: 111, Loss: 0.4808, Train: 92.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 03, Epoch: 112, Loss: 0.4938, Train: 92.50%, Valid: 88.75% Test: 86.27%\n",
      "Run: 03, Epoch: 113, Loss: 0.4469, Train: 91.67%, Valid: 88.75% Test: 88.24%\n",
      "Run: 03, Epoch: 114, Loss: 0.4236, Train: 91.67%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 115, Loss: 0.4423, Train: 91.67%, Valid: 87.50% Test: 88.24%\n",
      "Run: 03, Epoch: 116, Loss: 0.4193, Train: 94.17%, Valid: 87.50% Test: 90.20%\n",
      "Run: 03, Epoch: 117, Loss: 0.4692, Train: 95.00%, Valid: 90.00% Test: 86.27%\n",
      "Run: 03, Epoch: 118, Loss: 0.4680, Train: 95.00%, Valid: 90.00% Test: 82.35%\n",
      "Run: 03, Epoch: 119, Loss: 0.4503, Train: 91.67%, Valid: 90.00% Test: 84.31%\n",
      "Run: 03, Epoch: 120, Loss: 0.4499, Train: 90.83%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 121, Loss: 0.4539, Train: 90.00%, Valid: 86.25% Test: 86.27%\n",
      "Run: 03, Epoch: 122, Loss: 0.4820, Train: 90.83%, Valid: 88.75% Test: 86.27%\n",
      "Run: 03, Epoch: 123, Loss: 0.4504, Train: 89.17%, Valid: 91.25% Test: 86.27%\n",
      "Run: 03, Epoch: 124, Loss: 0.4539, Train: 92.50%, Valid: 90.00% Test: 88.24%\n",
      "Run: 03, Epoch: 125, Loss: 0.4707, Train: 95.00%, Valid: 91.25% Test: 88.24%\n",
      "Run: 03, Epoch: 126, Loss: 0.4372, Train: 94.17%, Valid: 90.00% Test: 86.27%\n",
      "Run: 03, Epoch: 127, Loss: 0.4336, Train: 94.17%, Valid: 86.25% Test: 86.27%\n",
      "Run: 03, Epoch: 128, Loss: 0.4274, Train: 95.00%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 129, Loss: 0.4504, Train: 95.00%, Valid: 86.25% Test: 90.20%\n",
      "Run: 03, Epoch: 130, Loss: 0.4721, Train: 98.33%, Valid: 88.75% Test: 90.20%\n",
      "Run: 03, Epoch: 131, Loss: 0.4314, Train: 98.33%, Valid: 88.75% Test: 90.20%\n",
      "Run: 03, Epoch: 132, Loss: 0.4262, Train: 98.33%, Valid: 88.75% Test: 88.24%\n",
      "Run: 03, Epoch: 133, Loss: 0.4276, Train: 93.33%, Valid: 88.75% Test: 88.24%\n",
      "Run: 03, Epoch: 134, Loss: 0.4196, Train: 90.00%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 135, Loss: 0.4243, Train: 90.00%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 136, Loss: 0.4332, Train: 93.33%, Valid: 88.75% Test: 88.24%\n",
      "Run: 03, Epoch: 137, Loss: 0.4485, Train: 95.83%, Valid: 90.00% Test: 88.24%\n",
      "Run: 03, Epoch: 138, Loss: 0.3635, Train: 98.33%, Valid: 86.25% Test: 90.20%\n",
      "Run: 03, Epoch: 139, Loss: 0.3746, Train: 98.33%, Valid: 87.50% Test: 90.20%\n",
      "Run: 03, Epoch: 140, Loss: 0.4113, Train: 98.33%, Valid: 87.50% Test: 90.20%\n",
      "Run: 03, Epoch: 141, Loss: 0.3920, Train: 95.83%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 142, Loss: 0.3872, Train: 96.67%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 143, Loss: 0.3792, Train: 97.50%, Valid: 90.00% Test: 88.24%\n",
      "Run: 03, Epoch: 144, Loss: 0.4116, Train: 94.17%, Valid: 91.25% Test: 88.24%\n",
      "Run: 03, Epoch: 145, Loss: 0.4089, Train: 90.00%, Valid: 88.75% Test: 86.27%\n",
      "Run: 03, Epoch: 146, Loss: 0.4311, Train: 90.00%, Valid: 87.50% Test: 88.24%\n",
      "Run: 03, Epoch: 147, Loss: 0.3940, Train: 91.67%, Valid: 88.75% Test: 88.24%\n",
      "Run: 03, Epoch: 148, Loss: 0.3738, Train: 95.00%, Valid: 90.00% Test: 88.24%\n",
      "Run: 03, Epoch: 149, Loss: 0.3373, Train: 96.67%, Valid: 88.75% Test: 90.20%\n",
      "Run: 03, Epoch: 150, Loss: 0.4094, Train: 97.50%, Valid: 88.75% Test: 94.12%\n",
      "Run: 03, Epoch: 151, Loss: 0.4277, Train: 95.83%, Valid: 88.75% Test: 92.16%\n",
      "Run: 03, Epoch: 152, Loss: 0.3918, Train: 94.17%, Valid: 87.50% Test: 88.24%\n",
      "Run: 03, Epoch: 153, Loss: 0.4132, Train: 94.17%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 154, Loss: 0.3746, Train: 94.17%, Valid: 86.25% Test: 86.27%\n",
      "Run: 03, Epoch: 155, Loss: 0.3800, Train: 94.17%, Valid: 85.00% Test: 86.27%\n",
      "Run: 03, Epoch: 156, Loss: 0.3395, Train: 94.17%, Valid: 85.00% Test: 86.27%\n",
      "Run: 03, Epoch: 157, Loss: 0.3732, Train: 94.17%, Valid: 87.50% Test: 88.24%\n",
      "Run: 03, Epoch: 158, Loss: 0.3835, Train: 96.67%, Valid: 88.75% Test: 92.16%\n",
      "Run: 03, Epoch: 159, Loss: 0.3979, Train: 97.50%, Valid: 92.50% Test: 92.16%\n",
      "Run: 03, Epoch: 160, Loss: 0.4255, Train: 97.50%, Valid: 92.50% Test: 86.27%\n",
      "Run: 03, Epoch: 161, Loss: 0.3789, Train: 97.50%, Valid: 90.00% Test: 88.24%\n",
      "Run: 03, Epoch: 162, Loss: 0.3336, Train: 97.50%, Valid: 87.50% Test: 90.20%\n",
      "Run: 03, Epoch: 163, Loss: 0.4379, Train: 97.50%, Valid: 87.50% Test: 88.24%\n",
      "Run: 03, Epoch: 164, Loss: 0.4339, Train: 97.50%, Valid: 87.50% Test: 88.24%\n",
      "Run: 03, Epoch: 165, Loss: 0.4092, Train: 96.67%, Valid: 86.25% Test: 86.27%\n",
      "Run: 03, Epoch: 166, Loss: 0.3879, Train: 95.83%, Valid: 87.50% Test: 84.31%\n",
      "Run: 03, Epoch: 167, Loss: 0.3413, Train: 94.17%, Valid: 90.00% Test: 88.24%\n",
      "Run: 03, Epoch: 168, Loss: 0.3730, Train: 96.67%, Valid: 90.00% Test: 84.31%\n",
      "Run: 03, Epoch: 169, Loss: 0.3854, Train: 95.83%, Valid: 90.00% Test: 84.31%\n",
      "Run: 03, Epoch: 170, Loss: 0.3426, Train: 97.50%, Valid: 90.00% Test: 94.12%\n",
      "Run: 03, Epoch: 171, Loss: 0.3618, Train: 97.50%, Valid: 90.00% Test: 92.16%\n",
      "Run: 03, Epoch: 172, Loss: 0.2961, Train: 97.50%, Valid: 92.50% Test: 92.16%\n",
      "Run: 03, Epoch: 173, Loss: 0.4234, Train: 97.50%, Valid: 92.50% Test: 92.16%\n",
      "Run: 03, Epoch: 174, Loss: 0.3213, Train: 96.67%, Valid: 91.25% Test: 90.20%\n",
      "Run: 03, Epoch: 175, Loss: 0.3589, Train: 96.67%, Valid: 91.25% Test: 88.24%\n",
      "Run: 03, Epoch: 176, Loss: 0.3345, Train: 97.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 03, Epoch: 177, Loss: 0.3695, Train: 96.67%, Valid: 87.50% Test: 90.20%\n",
      "Run: 03, Epoch: 178, Loss: 0.3445, Train: 95.83%, Valid: 88.75% Test: 88.24%\n",
      "Run: 03, Epoch: 179, Loss: 0.3482, Train: 95.00%, Valid: 88.75% Test: 90.20%\n",
      "Run: 03, Epoch: 180, Loss: 0.3766, Train: 95.00%, Valid: 88.75% Test: 90.20%\n",
      "Run: 03, Epoch: 181, Loss: 0.3348, Train: 92.50%, Valid: 85.00% Test: 88.24%\n",
      "Run: 03, Epoch: 182, Loss: 0.3146, Train: 88.33%, Valid: 81.25% Test: 88.24%\n",
      "Run: 03, Epoch: 183, Loss: 0.3466, Train: 79.17%, Valid: 78.75% Test: 84.31%\n",
      "Run: 03, Epoch: 184, Loss: 0.3175, Train: 80.00%, Valid: 76.25% Test: 84.31%\n",
      "Run: 03, Epoch: 185, Loss: 0.3241, Train: 87.50%, Valid: 81.25% Test: 86.27%\n",
      "Run: 03, Epoch: 186, Loss: 0.3925, Train: 93.33%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 187, Loss: 0.3140, Train: 96.67%, Valid: 86.25% Test: 88.24%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 188, Loss: 0.3410, Train: 97.50%, Valid: 87.50% Test: 90.20%\n",
      "Run: 03, Epoch: 189, Loss: 0.3421, Train: 97.50%, Valid: 90.00% Test: 92.16%\n",
      "Run: 03, Epoch: 190, Loss: 0.3479, Train: 97.50%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 191, Loss: 0.3248, Train: 98.33%, Valid: 86.25% Test: 90.20%\n",
      "Run: 03, Epoch: 192, Loss: 0.3602, Train: 99.17%, Valid: 85.00% Test: 90.20%\n",
      "Run: 03, Epoch: 193, Loss: 0.3185, Train: 99.17%, Valid: 85.00% Test: 88.24%\n",
      "Run: 03, Epoch: 194, Loss: 0.3953, Train: 98.33%, Valid: 85.00% Test: 88.24%\n",
      "Run: 03, Epoch: 195, Loss: 0.3433, Train: 97.50%, Valid: 86.25% Test: 88.24%\n",
      "Run: 03, Epoch: 196, Loss: 0.3434, Train: 95.00%, Valid: 85.00% Test: 86.27%\n",
      "Run: 03, Epoch: 197, Loss: 0.3511, Train: 93.33%, Valid: 87.50% Test: 86.27%\n",
      "Run: 03, Epoch: 198, Loss: 0.3300, Train: 92.50%, Valid: 88.75% Test: 84.31%\n",
      "Run: 03, Epoch: 199, Loss: 0.3325, Train: 92.50%, Valid: 90.00% Test: 86.27%\n",
      "Run: 03, Epoch: 200, Loss: 0.3245, Train: 93.33%, Valid: 87.50% Test: 84.31%\n",
      "Run 03:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 92.50\n",
      "  Final Train: 97.50\n",
      "   Final Test: 92.16\n",
      "Run: 04, Epoch: 01, Loss: 1.6392, Train: 18.33%, Valid: 6.25% Test: 9.80%\n",
      "Run: 04, Epoch: 02, Loss: 1.5752, Train: 18.33%, Valid: 6.25% Test: 9.80%\n",
      "Run: 04, Epoch: 03, Loss: 1.5228, Train: 18.33%, Valid: 6.25% Test: 9.80%\n",
      "Run: 04, Epoch: 04, Loss: 1.4932, Train: 55.83%, Valid: 56.25% Test: 50.98%\n",
      "Run: 04, Epoch: 05, Loss: 1.4276, Train: 54.17%, Valid: 58.75% Test: 52.94%\n",
      "Run: 04, Epoch: 06, Loss: 1.3789, Train: 53.33%, Valid: 56.25% Test: 50.98%\n",
      "Run: 04, Epoch: 07, Loss: 1.3264, Train: 54.17%, Valid: 56.25% Test: 50.98%\n",
      "Run: 04, Epoch: 08, Loss: 1.2826, Train: 55.00%, Valid: 57.50% Test: 49.02%\n",
      "Run: 04, Epoch: 09, Loss: 1.2461, Train: 53.33%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 10, Loss: 1.1997, Train: 52.50%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 11, Loss: 1.1715, Train: 52.50%, Valid: 51.25% Test: 47.06%\n",
      "Run: 04, Epoch: 12, Loss: 1.1561, Train: 52.50%, Valid: 51.25% Test: 47.06%\n",
      "Run: 04, Epoch: 13, Loss: 1.1038, Train: 50.83%, Valid: 51.25% Test: 47.06%\n",
      "Run: 04, Epoch: 14, Loss: 1.1033, Train: 50.83%, Valid: 51.25% Test: 47.06%\n",
      "Run: 04, Epoch: 15, Loss: 1.0455, Train: 51.67%, Valid: 51.25% Test: 47.06%\n",
      "Run: 04, Epoch: 16, Loss: 1.0071, Train: 51.67%, Valid: 53.75% Test: 49.02%\n",
      "Run: 04, Epoch: 17, Loss: 0.9951, Train: 51.67%, Valid: 53.75% Test: 49.02%\n",
      "Run: 04, Epoch: 18, Loss: 1.0140, Train: 52.50%, Valid: 53.75% Test: 49.02%\n",
      "Run: 04, Epoch: 19, Loss: 0.9694, Train: 52.50%, Valid: 55.00% Test: 49.02%\n",
      "Run: 04, Epoch: 20, Loss: 0.9611, Train: 54.17%, Valid: 57.50% Test: 49.02%\n",
      "Run: 04, Epoch: 21, Loss: 0.9665, Train: 55.00%, Valid: 61.25% Test: 52.94%\n",
      "Run: 04, Epoch: 22, Loss: 0.8948, Train: 58.33%, Valid: 65.00% Test: 54.90%\n",
      "Run: 04, Epoch: 23, Loss: 0.9081, Train: 60.00%, Valid: 67.50% Test: 58.82%\n",
      "Run: 04, Epoch: 24, Loss: 0.8840, Train: 61.67%, Valid: 70.00% Test: 60.78%\n",
      "Run: 04, Epoch: 25, Loss: 0.8777, Train: 63.33%, Valid: 72.50% Test: 60.78%\n",
      "Run: 04, Epoch: 26, Loss: 0.8488, Train: 65.00%, Valid: 73.75% Test: 60.78%\n",
      "Run: 04, Epoch: 27, Loss: 0.8722, Train: 67.50%, Valid: 72.50% Test: 60.78%\n",
      "Run: 04, Epoch: 28, Loss: 0.8923, Train: 67.50%, Valid: 73.75% Test: 60.78%\n",
      "Run: 04, Epoch: 29, Loss: 0.8571, Train: 68.33%, Valid: 73.75% Test: 60.78%\n",
      "Run: 04, Epoch: 30, Loss: 0.8502, Train: 67.50%, Valid: 73.75% Test: 60.78%\n",
      "Run: 04, Epoch: 31, Loss: 0.8321, Train: 67.50%, Valid: 73.75% Test: 58.82%\n",
      "Run: 04, Epoch: 32, Loss: 0.8090, Train: 66.67%, Valid: 71.25% Test: 58.82%\n",
      "Run: 04, Epoch: 33, Loss: 0.7846, Train: 65.00%, Valid: 70.00% Test: 56.86%\n",
      "Run: 04, Epoch: 34, Loss: 0.8154, Train: 66.67%, Valid: 71.25% Test: 58.82%\n",
      "Run: 04, Epoch: 35, Loss: 0.7786, Train: 71.67%, Valid: 73.75% Test: 62.75%\n",
      "Run: 04, Epoch: 36, Loss: 0.7780, Train: 76.67%, Valid: 76.25% Test: 62.75%\n",
      "Run: 04, Epoch: 37, Loss: 0.7781, Train: 80.00%, Valid: 77.50% Test: 70.59%\n",
      "Run: 04, Epoch: 38, Loss: 0.7576, Train: 79.17%, Valid: 78.75% Test: 74.51%\n",
      "Run: 04, Epoch: 39, Loss: 0.7614, Train: 80.83%, Valid: 81.25% Test: 76.47%\n",
      "Run: 04, Epoch: 40, Loss: 0.7580, Train: 82.50%, Valid: 81.25% Test: 78.43%\n",
      "Run: 04, Epoch: 41, Loss: 0.7080, Train: 82.50%, Valid: 77.50% Test: 82.35%\n",
      "Run: 04, Epoch: 42, Loss: 0.7237, Train: 83.33%, Valid: 77.50% Test: 84.31%\n",
      "Run: 04, Epoch: 43, Loss: 0.7599, Train: 84.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 04, Epoch: 44, Loss: 0.7073, Train: 82.50%, Valid: 81.25% Test: 84.31%\n",
      "Run: 04, Epoch: 45, Loss: 0.7064, Train: 85.83%, Valid: 82.50% Test: 80.39%\n",
      "Run: 04, Epoch: 46, Loss: 0.6774, Train: 85.83%, Valid: 80.00% Test: 78.43%\n",
      "Run: 04, Epoch: 47, Loss: 0.7070, Train: 83.33%, Valid: 77.50% Test: 78.43%\n",
      "Run: 04, Epoch: 48, Loss: 0.7278, Train: 82.50%, Valid: 77.50% Test: 78.43%\n",
      "Run: 04, Epoch: 49, Loss: 0.6770, Train: 80.00%, Valid: 77.50% Test: 74.51%\n",
      "Run: 04, Epoch: 50, Loss: 0.7094, Train: 80.00%, Valid: 77.50% Test: 72.55%\n",
      "Run: 04, Epoch: 51, Loss: 0.7185, Train: 81.67%, Valid: 77.50% Test: 74.51%\n",
      "Run: 04, Epoch: 52, Loss: 0.6669, Train: 83.33%, Valid: 78.75% Test: 76.47%\n",
      "Run: 04, Epoch: 53, Loss: 0.6575, Train: 83.33%, Valid: 80.00% Test: 76.47%\n",
      "Run: 04, Epoch: 54, Loss: 0.6528, Train: 84.17%, Valid: 81.25% Test: 76.47%\n",
      "Run: 04, Epoch: 55, Loss: 0.6162, Train: 85.00%, Valid: 81.25% Test: 76.47%\n",
      "Run: 04, Epoch: 56, Loss: 0.6673, Train: 84.17%, Valid: 81.25% Test: 76.47%\n",
      "Run: 04, Epoch: 57, Loss: 0.5922, Train: 83.33%, Valid: 80.00% Test: 76.47%\n",
      "Run: 04, Epoch: 58, Loss: 0.6368, Train: 83.33%, Valid: 81.25% Test: 76.47%\n",
      "Run: 04, Epoch: 59, Loss: 0.6538, Train: 84.17%, Valid: 81.25% Test: 80.39%\n",
      "Run: 04, Epoch: 60, Loss: 0.6088, Train: 85.00%, Valid: 81.25% Test: 80.39%\n",
      "Run: 04, Epoch: 61, Loss: 0.6588, Train: 84.17%, Valid: 82.50% Test: 84.31%\n",
      "Run: 04, Epoch: 62, Loss: 0.6350, Train: 83.33%, Valid: 78.75% Test: 82.35%\n",
      "Run: 04, Epoch: 63, Loss: 0.6305, Train: 82.50%, Valid: 75.00% Test: 84.31%\n",
      "Run: 04, Epoch: 64, Loss: 0.6170, Train: 83.33%, Valid: 77.50% Test: 84.31%\n",
      "Run: 04, Epoch: 65, Loss: 0.6144, Train: 85.00%, Valid: 82.50% Test: 84.31%\n",
      "Run: 04, Epoch: 66, Loss: 0.6190, Train: 85.83%, Valid: 82.50% Test: 80.39%\n",
      "Run: 04, Epoch: 67, Loss: 0.5825, Train: 85.83%, Valid: 82.50% Test: 82.35%\n",
      "Run: 04, Epoch: 68, Loss: 0.6095, Train: 87.50%, Valid: 82.50% Test: 82.35%\n",
      "Run: 04, Epoch: 69, Loss: 0.5746, Train: 85.00%, Valid: 80.00% Test: 80.39%\n",
      "Run: 04, Epoch: 70, Loss: 0.5617, Train: 85.83%, Valid: 80.00% Test: 82.35%\n",
      "Run: 04, Epoch: 71, Loss: 0.6134, Train: 85.00%, Valid: 83.75% Test: 80.39%\n",
      "Run: 04, Epoch: 72, Loss: 0.5926, Train: 87.50%, Valid: 82.50% Test: 84.31%\n",
      "Run: 04, Epoch: 73, Loss: 0.6055, Train: 88.33%, Valid: 83.75% Test: 84.31%\n",
      "Run: 04, Epoch: 74, Loss: 0.6409, Train: 85.83%, Valid: 82.50% Test: 86.27%\n",
      "Run: 04, Epoch: 75, Loss: 0.6146, Train: 84.17%, Valid: 78.75% Test: 84.31%\n",
      "Run: 04, Epoch: 76, Loss: 0.5928, Train: 84.17%, Valid: 80.00% Test: 84.31%\n",
      "Run: 04, Epoch: 77, Loss: 0.6130, Train: 87.50%, Valid: 82.50% Test: 86.27%\n",
      "Run: 04, Epoch: 78, Loss: 0.5919, Train: 88.33%, Valid: 82.50% Test: 78.43%\n",
      "Run: 04, Epoch: 79, Loss: 0.5628, Train: 88.33%, Valid: 83.75% Test: 80.39%\n",
      "Run: 04, Epoch: 80, Loss: 0.6218, Train: 87.50%, Valid: 83.75% Test: 80.39%\n",
      "Run: 04, Epoch: 81, Loss: 0.5387, Train: 89.17%, Valid: 83.75% Test: 80.39%\n",
      "Run: 04, Epoch: 82, Loss: 0.5717, Train: 89.17%, Valid: 85.00% Test: 82.35%\n",
      "Run: 04, Epoch: 83, Loss: 0.5620, Train: 88.33%, Valid: 83.75% Test: 82.35%\n",
      "Run: 04, Epoch: 84, Loss: 0.5459, Train: 87.50%, Valid: 83.75% Test: 84.31%\n",
      "Run: 04, Epoch: 85, Loss: 0.5541, Train: 87.50%, Valid: 81.25% Test: 82.35%\n",
      "Run: 04, Epoch: 86, Loss: 0.5727, Train: 85.83%, Valid: 82.50% Test: 82.35%\n",
      "Run: 04, Epoch: 87, Loss: 0.5187, Train: 85.83%, Valid: 81.25% Test: 82.35%\n",
      "Run: 04, Epoch: 88, Loss: 0.5001, Train: 85.00%, Valid: 81.25% Test: 84.31%\n",
      "Run: 04, Epoch: 89, Loss: 0.5262, Train: 84.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 04, Epoch: 90, Loss: 0.5728, Train: 84.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 04, Epoch: 91, Loss: 0.5179, Train: 84.17%, Valid: 81.25% Test: 86.27%\n",
      "Run: 04, Epoch: 92, Loss: 0.5489, Train: 86.67%, Valid: 81.25% Test: 84.31%\n",
      "Run: 04, Epoch: 93, Loss: 0.5503, Train: 86.67%, Valid: 81.25% Test: 82.35%\n",
      "Run: 04, Epoch: 94, Loss: 0.5445, Train: 87.50%, Valid: 85.00% Test: 82.35%\n",
      "Run: 04, Epoch: 95, Loss: 0.4878, Train: 88.33%, Valid: 83.75% Test: 78.43%\n",
      "Run: 04, Epoch: 96, Loss: 0.4990, Train: 89.17%, Valid: 83.75% Test: 78.43%\n",
      "Run: 04, Epoch: 97, Loss: 0.5636, Train: 89.17%, Valid: 83.75% Test: 78.43%\n",
      "Run: 04, Epoch: 98, Loss: 0.5001, Train: 89.17%, Valid: 80.00% Test: 78.43%\n",
      "Run: 04, Epoch: 99, Loss: 0.5480, Train: 88.33%, Valid: 80.00% Test: 78.43%\n",
      "Run: 04, Epoch: 100, Loss: 0.5165, Train: 88.33%, Valid: 78.75% Test: 78.43%\n",
      "Run: 04, Epoch: 101, Loss: 0.5002, Train: 88.33%, Valid: 80.00% Test: 78.43%\n",
      "Run: 04, Epoch: 102, Loss: 0.4987, Train: 87.50%, Valid: 81.25% Test: 80.39%\n",
      "Run: 04, Epoch: 103, Loss: 0.4897, Train: 87.50%, Valid: 82.50% Test: 80.39%\n",
      "Run: 04, Epoch: 104, Loss: 0.4253, Train: 88.33%, Valid: 81.25% Test: 84.31%\n",
      "Run: 04, Epoch: 105, Loss: 0.4823, Train: 88.33%, Valid: 83.75% Test: 82.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 106, Loss: 0.4978, Train: 88.33%, Valid: 85.00% Test: 84.31%\n",
      "Run: 04, Epoch: 107, Loss: 0.5216, Train: 89.17%, Valid: 81.25% Test: 80.39%\n",
      "Run: 04, Epoch: 108, Loss: 0.4944, Train: 89.17%, Valid: 78.75% Test: 74.51%\n",
      "Run: 04, Epoch: 109, Loss: 0.4858, Train: 87.50%, Valid: 78.75% Test: 74.51%\n",
      "Run: 04, Epoch: 110, Loss: 0.5339, Train: 88.33%, Valid: 83.75% Test: 76.47%\n",
      "Run: 04, Epoch: 111, Loss: 0.4599, Train: 89.17%, Valid: 86.25% Test: 76.47%\n",
      "Run: 04, Epoch: 112, Loss: 0.4961, Train: 90.00%, Valid: 87.50% Test: 80.39%\n",
      "Run: 04, Epoch: 113, Loss: 0.4662, Train: 89.17%, Valid: 90.00% Test: 82.35%\n",
      "Run: 04, Epoch: 114, Loss: 0.4818, Train: 90.83%, Valid: 92.50% Test: 86.27%\n",
      "Run: 04, Epoch: 115, Loss: 0.4687, Train: 90.83%, Valid: 90.00% Test: 82.35%\n",
      "Run: 04, Epoch: 116, Loss: 0.4474, Train: 90.83%, Valid: 88.75% Test: 86.27%\n",
      "Run: 04, Epoch: 117, Loss: 0.4600, Train: 91.67%, Valid: 88.75% Test: 88.24%\n",
      "Run: 04, Epoch: 118, Loss: 0.4948, Train: 91.67%, Valid: 88.75% Test: 88.24%\n",
      "Run: 04, Epoch: 119, Loss: 0.5249, Train: 91.67%, Valid: 88.75% Test: 88.24%\n",
      "Run: 04, Epoch: 120, Loss: 0.4053, Train: 91.67%, Valid: 88.75% Test: 88.24%\n",
      "Run: 04, Epoch: 121, Loss: 0.5052, Train: 90.83%, Valid: 86.25% Test: 86.27%\n",
      "Run: 04, Epoch: 122, Loss: 0.4354, Train: 90.83%, Valid: 85.00% Test: 86.27%\n",
      "Run: 04, Epoch: 123, Loss: 0.4855, Train: 90.00%, Valid: 85.00% Test: 86.27%\n",
      "Run: 04, Epoch: 124, Loss: 0.4450, Train: 87.50%, Valid: 83.75% Test: 84.31%\n",
      "Run: 04, Epoch: 125, Loss: 0.4579, Train: 89.17%, Valid: 82.50% Test: 80.39%\n",
      "Run: 04, Epoch: 126, Loss: 0.4466, Train: 89.17%, Valid: 81.25% Test: 78.43%\n",
      "Run: 04, Epoch: 127, Loss: 0.4522, Train: 90.00%, Valid: 80.00% Test: 78.43%\n",
      "Run: 04, Epoch: 128, Loss: 0.4093, Train: 89.17%, Valid: 81.25% Test: 78.43%\n",
      "Run: 04, Epoch: 129, Loss: 0.3933, Train: 88.33%, Valid: 77.50% Test: 74.51%\n",
      "Run: 04, Epoch: 130, Loss: 0.3862, Train: 87.50%, Valid: 76.25% Test: 74.51%\n",
      "Run: 04, Epoch: 131, Loss: 0.4886, Train: 90.00%, Valid: 81.25% Test: 78.43%\n",
      "Run: 04, Epoch: 132, Loss: 0.4095, Train: 91.67%, Valid: 86.25% Test: 86.27%\n",
      "Run: 04, Epoch: 133, Loss: 0.4412, Train: 93.33%, Valid: 88.75% Test: 84.31%\n",
      "Run: 04, Epoch: 134, Loss: 0.4391, Train: 94.17%, Valid: 90.00% Test: 88.24%\n",
      "Run: 04, Epoch: 135, Loss: 0.4039, Train: 93.33%, Valid: 88.75% Test: 84.31%\n",
      "Run: 04, Epoch: 136, Loss: 0.4583, Train: 92.50%, Valid: 87.50% Test: 86.27%\n",
      "Run: 04, Epoch: 137, Loss: 0.4301, Train: 91.67%, Valid: 88.75% Test: 86.27%\n",
      "Run: 04, Epoch: 138, Loss: 0.3844, Train: 91.67%, Valid: 86.25% Test: 86.27%\n",
      "Run: 04, Epoch: 139, Loss: 0.4410, Train: 90.83%, Valid: 87.50% Test: 88.24%\n",
      "Run: 04, Epoch: 140, Loss: 0.4126, Train: 91.67%, Valid: 88.75% Test: 84.31%\n",
      "Run: 04, Epoch: 141, Loss: 0.3975, Train: 92.50%, Valid: 90.00% Test: 86.27%\n",
      "Run: 04, Epoch: 142, Loss: 0.4322, Train: 92.50%, Valid: 90.00% Test: 86.27%\n",
      "Run: 04, Epoch: 143, Loss: 0.4602, Train: 90.83%, Valid: 88.75% Test: 84.31%\n",
      "Run: 04, Epoch: 144, Loss: 0.4277, Train: 84.17%, Valid: 83.75% Test: 78.43%\n",
      "Run: 04, Epoch: 145, Loss: 0.3971, Train: 85.00%, Valid: 83.75% Test: 78.43%\n",
      "Run: 04, Epoch: 146, Loss: 0.3997, Train: 90.00%, Valid: 87.50% Test: 82.35%\n",
      "Run: 04, Epoch: 147, Loss: 0.4249, Train: 94.17%, Valid: 86.25% Test: 78.43%\n",
      "Run: 04, Epoch: 148, Loss: 0.4261, Train: 91.67%, Valid: 87.50% Test: 80.39%\n",
      "Run: 04, Epoch: 149, Loss: 0.4479, Train: 91.67%, Valid: 83.75% Test: 80.39%\n",
      "Run: 04, Epoch: 150, Loss: 0.3724, Train: 90.00%, Valid: 82.50% Test: 82.35%\n",
      "Run: 04, Epoch: 151, Loss: 0.4172, Train: 89.17%, Valid: 85.00% Test: 82.35%\n",
      "Run: 04, Epoch: 152, Loss: 0.4046, Train: 90.83%, Valid: 86.25% Test: 82.35%\n",
      "Run: 04, Epoch: 153, Loss: 0.3976, Train: 91.67%, Valid: 90.00% Test: 86.27%\n",
      "Run: 04, Epoch: 154, Loss: 0.3635, Train: 94.17%, Valid: 90.00% Test: 90.20%\n",
      "Run: 04, Epoch: 155, Loss: 0.4025, Train: 94.17%, Valid: 91.25% Test: 90.20%\n",
      "Run: 04, Epoch: 156, Loss: 0.3631, Train: 94.17%, Valid: 90.00% Test: 86.27%\n",
      "Run: 04, Epoch: 157, Loss: 0.4026, Train: 93.33%, Valid: 91.25% Test: 88.24%\n",
      "Run: 04, Epoch: 158, Loss: 0.3980, Train: 93.33%, Valid: 91.25% Test: 88.24%\n",
      "Run: 04, Epoch: 159, Loss: 0.3796, Train: 93.33%, Valid: 91.25% Test: 86.27%\n",
      "Run: 04, Epoch: 160, Loss: 0.3625, Train: 93.33%, Valid: 90.00% Test: 90.20%\n",
      "Run: 04, Epoch: 161, Loss: 0.3767, Train: 92.50%, Valid: 88.75% Test: 86.27%\n",
      "Run: 04, Epoch: 162, Loss: 0.3375, Train: 92.50%, Valid: 87.50% Test: 86.27%\n",
      "Run: 04, Epoch: 163, Loss: 0.3530, Train: 92.50%, Valid: 90.00% Test: 84.31%\n",
      "Run: 04, Epoch: 164, Loss: 0.3470, Train: 92.50%, Valid: 90.00% Test: 86.27%\n",
      "Run: 04, Epoch: 165, Loss: 0.3501, Train: 95.00%, Valid: 91.25% Test: 86.27%\n",
      "Run: 04, Epoch: 166, Loss: 0.4063, Train: 92.50%, Valid: 88.75% Test: 86.27%\n",
      "Run: 04, Epoch: 167, Loss: 0.3374, Train: 89.17%, Valid: 86.25% Test: 80.39%\n",
      "Run: 04, Epoch: 168, Loss: 0.3824, Train: 90.83%, Valid: 87.50% Test: 82.35%\n",
      "Run: 04, Epoch: 169, Loss: 0.3421, Train: 95.83%, Valid: 86.25% Test: 88.24%\n",
      "Run: 04, Epoch: 170, Loss: 0.3718, Train: 93.33%, Valid: 86.25% Test: 86.27%\n",
      "Run: 04, Epoch: 171, Loss: 0.3954, Train: 93.33%, Valid: 85.00% Test: 86.27%\n",
      "Run: 04, Epoch: 172, Loss: 0.4187, Train: 93.33%, Valid: 85.00% Test: 86.27%\n",
      "Run: 04, Epoch: 173, Loss: 0.3626, Train: 93.33%, Valid: 88.75% Test: 88.24%\n",
      "Run: 04, Epoch: 174, Loss: 0.3820, Train: 93.33%, Valid: 90.00% Test: 86.27%\n",
      "Run: 04, Epoch: 175, Loss: 0.2983, Train: 91.67%, Valid: 90.00% Test: 86.27%\n",
      "Run: 04, Epoch: 176, Loss: 0.3545, Train: 94.17%, Valid: 90.00% Test: 86.27%\n",
      "Run: 04, Epoch: 177, Loss: 0.3155, Train: 92.50%, Valid: 91.25% Test: 86.27%\n",
      "Run: 04, Epoch: 178, Loss: 0.3810, Train: 93.33%, Valid: 91.25% Test: 86.27%\n",
      "Run: 04, Epoch: 179, Loss: 0.3334, Train: 93.33%, Valid: 88.75% Test: 80.39%\n",
      "Run: 04, Epoch: 180, Loss: 0.3733, Train: 94.17%, Valid: 88.75% Test: 80.39%\n",
      "Run: 04, Epoch: 181, Loss: 0.3701, Train: 94.17%, Valid: 88.75% Test: 86.27%\n",
      "Run: 04, Epoch: 182, Loss: 0.3605, Train: 93.33%, Valid: 88.75% Test: 84.31%\n",
      "Run: 04, Epoch: 183, Loss: 0.3244, Train: 94.17%, Valid: 88.75% Test: 86.27%\n",
      "Run: 04, Epoch: 184, Loss: 0.3484, Train: 93.33%, Valid: 90.00% Test: 80.39%\n",
      "Run: 04, Epoch: 185, Loss: 0.3205, Train: 92.50%, Valid: 91.25% Test: 78.43%\n",
      "Run: 04, Epoch: 186, Loss: 0.4207, Train: 92.50%, Valid: 90.00% Test: 80.39%\n",
      "Run: 04, Epoch: 187, Loss: 0.3573, Train: 92.50%, Valid: 90.00% Test: 84.31%\n",
      "Run: 04, Epoch: 188, Loss: 0.3721, Train: 93.33%, Valid: 90.00% Test: 88.24%\n",
      "Run: 04, Epoch: 189, Loss: 0.3719, Train: 93.33%, Valid: 88.75% Test: 86.27%\n",
      "Run: 04, Epoch: 190, Loss: 0.3053, Train: 94.17%, Valid: 87.50% Test: 86.27%\n",
      "Run: 04, Epoch: 191, Loss: 0.3383, Train: 91.67%, Valid: 86.25% Test: 86.27%\n",
      "Run: 04, Epoch: 192, Loss: 0.3110, Train: 92.50%, Valid: 86.25% Test: 86.27%\n",
      "Run: 04, Epoch: 193, Loss: 0.3155, Train: 93.33%, Valid: 86.25% Test: 88.24%\n",
      "Run: 04, Epoch: 194, Loss: 0.3142, Train: 92.50%, Valid: 87.50% Test: 88.24%\n",
      "Run: 04, Epoch: 195, Loss: 0.3306, Train: 92.50%, Valid: 87.50% Test: 84.31%\n",
      "Run: 04, Epoch: 196, Loss: 0.3254, Train: 92.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 04, Epoch: 197, Loss: 0.3618, Train: 91.67%, Valid: 91.25% Test: 88.24%\n",
      "Run: 04, Epoch: 198, Loss: 0.3266, Train: 93.33%, Valid: 93.75% Test: 94.12%\n",
      "Run: 04, Epoch: 199, Loss: 0.3906, Train: 94.17%, Valid: 93.75% Test: 92.16%\n",
      "Run: 04, Epoch: 200, Loss: 0.3418, Train: 95.00%, Valid: 93.75% Test: 90.20%\n",
      "Run 04:\n",
      "Highest Train: 95.83\n",
      "Highest Valid: 93.75\n",
      "  Final Train: 93.33\n",
      "   Final Test: 94.12\n",
      "Run: 05, Epoch: 01, Loss: 1.5482, Train: 14.17%, Valid: 12.50% Test: 9.80%\n",
      "Run: 05, Epoch: 02, Loss: 1.5037, Train: 14.17%, Valid: 12.50% Test: 9.80%\n",
      "Run: 05, Epoch: 03, Loss: 1.4379, Train: 50.83%, Valid: 42.50% Test: 31.37%\n",
      "Run: 05, Epoch: 04, Loss: 1.3788, Train: 48.33%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 05, Loss: 1.3287, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 06, Loss: 1.2982, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 07, Loss: 1.2594, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 08, Loss: 1.1977, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 09, Loss: 1.1674, Train: 47.50%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 10, Loss: 1.1092, Train: 48.33%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 11, Loss: 1.0692, Train: 49.17%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 12, Loss: 1.0509, Train: 50.00%, Valid: 51.25% Test: 39.22%\n",
      "Run: 05, Epoch: 13, Loss: 1.0163, Train: 50.83%, Valid: 53.75% Test: 43.14%\n",
      "Run: 05, Epoch: 14, Loss: 1.0420, Train: 50.83%, Valid: 53.75% Test: 43.14%\n",
      "Run: 05, Epoch: 15, Loss: 0.9923, Train: 54.17%, Valid: 57.50% Test: 45.10%\n",
      "Run: 05, Epoch: 16, Loss: 0.9725, Train: 55.83%, Valid: 57.50% Test: 45.10%\n",
      "Run: 05, Epoch: 17, Loss: 0.9459, Train: 58.33%, Valid: 60.00% Test: 49.02%\n",
      "Run: 05, Epoch: 18, Loss: 0.9753, Train: 59.17%, Valid: 58.75% Test: 49.02%\n",
      "Run: 05, Epoch: 19, Loss: 0.9242, Train: 60.00%, Valid: 61.25% Test: 49.02%\n",
      "Run: 05, Epoch: 20, Loss: 0.9151, Train: 60.83%, Valid: 61.25% Test: 49.02%\n",
      "Run: 05, Epoch: 21, Loss: 0.8955, Train: 62.50%, Valid: 61.25% Test: 47.06%\n",
      "Run: 05, Epoch: 22, Loss: 0.9057, Train: 61.67%, Valid: 61.25% Test: 52.94%\n",
      "Run: 05, Epoch: 23, Loss: 0.8488, Train: 63.33%, Valid: 63.75% Test: 54.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 24, Loss: 0.8917, Train: 65.83%, Valid: 68.75% Test: 54.90%\n",
      "Run: 05, Epoch: 25, Loss: 0.8576, Train: 68.33%, Valid: 70.00% Test: 60.78%\n",
      "Run: 05, Epoch: 26, Loss: 0.8747, Train: 70.83%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 27, Loss: 0.8466, Train: 71.67%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 28, Loss: 0.8235, Train: 71.67%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 29, Loss: 0.8466, Train: 70.83%, Valid: 72.50% Test: 66.67%\n",
      "Run: 05, Epoch: 30, Loss: 0.8261, Train: 70.83%, Valid: 70.00% Test: 56.86%\n",
      "Run: 05, Epoch: 31, Loss: 0.7760, Train: 67.50%, Valid: 71.25% Test: 54.90%\n",
      "Run: 05, Epoch: 32, Loss: 0.7885, Train: 64.17%, Valid: 68.75% Test: 54.90%\n",
      "Run: 05, Epoch: 33, Loss: 0.7568, Train: 63.33%, Valid: 67.50% Test: 54.90%\n",
      "Run: 05, Epoch: 34, Loss: 0.7535, Train: 63.33%, Valid: 65.00% Test: 54.90%\n",
      "Run: 05, Epoch: 35, Loss: 0.7600, Train: 65.00%, Valid: 65.00% Test: 54.90%\n",
      "Run: 05, Epoch: 36, Loss: 0.7826, Train: 72.50%, Valid: 68.75% Test: 62.75%\n",
      "Run: 05, Epoch: 37, Loss: 0.7517, Train: 78.33%, Valid: 73.75% Test: 70.59%\n",
      "Run: 05, Epoch: 38, Loss: 0.7593, Train: 79.17%, Valid: 73.75% Test: 72.55%\n",
      "Run: 05, Epoch: 39, Loss: 0.7211, Train: 80.83%, Valid: 72.50% Test: 76.47%\n",
      "Run: 05, Epoch: 40, Loss: 0.7304, Train: 79.17%, Valid: 72.50% Test: 76.47%\n",
      "Run: 05, Epoch: 41, Loss: 0.7519, Train: 79.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 05, Epoch: 42, Loss: 0.6928, Train: 76.67%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 43, Loss: 0.7250, Train: 78.33%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 44, Loss: 0.7290, Train: 79.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 45, Loss: 0.6788, Train: 79.17%, Valid: 67.50% Test: 76.47%\n",
      "Run: 05, Epoch: 46, Loss: 0.6987, Train: 79.17%, Valid: 71.25% Test: 78.43%\n",
      "Run: 05, Epoch: 47, Loss: 0.6906, Train: 82.50%, Valid: 75.00% Test: 76.47%\n",
      "Run: 05, Epoch: 48, Loss: 0.6818, Train: 86.67%, Valid: 75.00% Test: 80.39%\n",
      "Run: 05, Epoch: 49, Loss: 0.7138, Train: 84.17%, Valid: 75.00% Test: 74.51%\n",
      "Run: 05, Epoch: 50, Loss: 0.6717, Train: 85.00%, Valid: 75.00% Test: 74.51%\n",
      "Run: 05, Epoch: 51, Loss: 0.6576, Train: 83.33%, Valid: 76.25% Test: 74.51%\n",
      "Run: 05, Epoch: 52, Loss: 0.6369, Train: 80.83%, Valid: 76.25% Test: 70.59%\n",
      "Run: 05, Epoch: 53, Loss: 0.6517, Train: 79.17%, Valid: 76.25% Test: 70.59%\n",
      "Run: 05, Epoch: 54, Loss: 0.6703, Train: 80.00%, Valid: 77.50% Test: 68.63%\n",
      "Run: 05, Epoch: 55, Loss: 0.6030, Train: 79.17%, Valid: 78.75% Test: 72.55%\n",
      "Run: 05, Epoch: 56, Loss: 0.6038, Train: 83.33%, Valid: 77.50% Test: 78.43%\n",
      "Run: 05, Epoch: 57, Loss: 0.6175, Train: 84.17%, Valid: 76.25% Test: 76.47%\n",
      "Run: 05, Epoch: 58, Loss: 0.6072, Train: 84.17%, Valid: 75.00% Test: 76.47%\n",
      "Run: 05, Epoch: 59, Loss: 0.6186, Train: 84.17%, Valid: 75.00% Test: 78.43%\n",
      "Run: 05, Epoch: 60, Loss: 0.6152, Train: 85.83%, Valid: 73.75% Test: 78.43%\n",
      "Run: 05, Epoch: 61, Loss: 0.6306, Train: 85.83%, Valid: 75.00% Test: 78.43%\n",
      "Run: 05, Epoch: 62, Loss: 0.5870, Train: 85.83%, Valid: 77.50% Test: 72.55%\n",
      "Run: 05, Epoch: 63, Loss: 0.5744, Train: 85.83%, Valid: 77.50% Test: 74.51%\n",
      "Run: 05, Epoch: 64, Loss: 0.5723, Train: 85.83%, Valid: 78.75% Test: 76.47%\n",
      "Run: 05, Epoch: 65, Loss: 0.5704, Train: 86.67%, Valid: 78.75% Test: 76.47%\n",
      "Run: 05, Epoch: 66, Loss: 0.5809, Train: 86.67%, Valid: 77.50% Test: 76.47%\n",
      "Run: 05, Epoch: 67, Loss: 0.5757, Train: 87.50%, Valid: 76.25% Test: 78.43%\n",
      "Run: 05, Epoch: 68, Loss: 0.5893, Train: 87.50%, Valid: 76.25% Test: 78.43%\n",
      "Run: 05, Epoch: 69, Loss: 0.5953, Train: 87.50%, Valid: 77.50% Test: 84.31%\n",
      "Run: 05, Epoch: 70, Loss: 0.5751, Train: 88.33%, Valid: 78.75% Test: 80.39%\n",
      "Run: 05, Epoch: 71, Loss: 0.5379, Train: 88.33%, Valid: 78.75% Test: 82.35%\n",
      "Run: 05, Epoch: 72, Loss: 0.5568, Train: 88.33%, Valid: 78.75% Test: 84.31%\n",
      "Run: 05, Epoch: 73, Loss: 0.5542, Train: 87.50%, Valid: 77.50% Test: 84.31%\n",
      "Run: 05, Epoch: 74, Loss: 0.5561, Train: 86.67%, Valid: 77.50% Test: 84.31%\n",
      "Run: 05, Epoch: 75, Loss: 0.5313, Train: 87.50%, Valid: 77.50% Test: 84.31%\n",
      "Run: 05, Epoch: 76, Loss: 0.5319, Train: 87.50%, Valid: 76.25% Test: 86.27%\n",
      "Run: 05, Epoch: 77, Loss: 0.5927, Train: 89.17%, Valid: 76.25% Test: 82.35%\n",
      "Run: 05, Epoch: 78, Loss: 0.5421, Train: 91.67%, Valid: 76.25% Test: 84.31%\n",
      "Run: 05, Epoch: 79, Loss: 0.5685, Train: 91.67%, Valid: 76.25% Test: 86.27%\n",
      "Run: 05, Epoch: 80, Loss: 0.5417, Train: 91.67%, Valid: 76.25% Test: 86.27%\n",
      "Run: 05, Epoch: 81, Loss: 0.5396, Train: 90.83%, Valid: 80.00% Test: 84.31%\n",
      "Run: 05, Epoch: 82, Loss: 0.5062, Train: 91.67%, Valid: 81.25% Test: 84.31%\n",
      "Run: 05, Epoch: 83, Loss: 0.4991, Train: 90.83%, Valid: 81.25% Test: 82.35%\n",
      "Run: 05, Epoch: 84, Loss: 0.4605, Train: 87.50%, Valid: 81.25% Test: 78.43%\n",
      "Run: 05, Epoch: 85, Loss: 0.4906, Train: 89.17%, Valid: 76.25% Test: 80.39%\n",
      "Run: 05, Epoch: 86, Loss: 0.4952, Train: 88.33%, Valid: 76.25% Test: 82.35%\n",
      "Run: 05, Epoch: 87, Loss: 0.4855, Train: 89.17%, Valid: 76.25% Test: 82.35%\n",
      "Run: 05, Epoch: 88, Loss: 0.4993, Train: 90.00%, Valid: 77.50% Test: 82.35%\n",
      "Run: 05, Epoch: 89, Loss: 0.4760, Train: 88.33%, Valid: 76.25% Test: 84.31%\n",
      "Run: 05, Epoch: 90, Loss: 0.4940, Train: 90.00%, Valid: 76.25% Test: 80.39%\n",
      "Run: 05, Epoch: 91, Loss: 0.4657, Train: 87.50%, Valid: 76.25% Test: 80.39%\n",
      "Run: 05, Epoch: 92, Loss: 0.4678, Train: 87.50%, Valid: 76.25% Test: 82.35%\n",
      "Run: 05, Epoch: 93, Loss: 0.4738, Train: 89.17%, Valid: 78.75% Test: 80.39%\n",
      "Run: 05, Epoch: 94, Loss: 0.4674, Train: 90.00%, Valid: 78.75% Test: 82.35%\n",
      "Run: 05, Epoch: 95, Loss: 0.4340, Train: 91.67%, Valid: 78.75% Test: 84.31%\n",
      "Run: 05, Epoch: 96, Loss: 0.4792, Train: 90.83%, Valid: 80.00% Test: 82.35%\n",
      "Run: 05, Epoch: 97, Loss: 0.4697, Train: 90.83%, Valid: 78.75% Test: 88.24%\n",
      "Run: 05, Epoch: 98, Loss: 0.4523, Train: 90.83%, Valid: 78.75% Test: 84.31%\n",
      "Run: 05, Epoch: 99, Loss: 0.4271, Train: 90.83%, Valid: 78.75% Test: 84.31%\n",
      "Run: 05, Epoch: 100, Loss: 0.4493, Train: 90.83%, Valid: 76.25% Test: 84.31%\n",
      "Run: 05, Epoch: 101, Loss: 0.4722, Train: 91.67%, Valid: 78.75% Test: 82.35%\n",
      "Run: 05, Epoch: 102, Loss: 0.4027, Train: 91.67%, Valid: 78.75% Test: 86.27%\n",
      "Run: 05, Epoch: 103, Loss: 0.4412, Train: 91.67%, Valid: 78.75% Test: 86.27%\n",
      "Run: 05, Epoch: 104, Loss: 0.4379, Train: 91.67%, Valid: 80.00% Test: 90.20%\n",
      "Run: 05, Epoch: 105, Loss: 0.4293, Train: 92.50%, Valid: 78.75% Test: 86.27%\n",
      "Run: 05, Epoch: 106, Loss: 0.3998, Train: 91.67%, Valid: 76.25% Test: 86.27%\n",
      "Run: 05, Epoch: 107, Loss: 0.4716, Train: 90.83%, Valid: 77.50% Test: 86.27%\n",
      "Run: 05, Epoch: 108, Loss: 0.4016, Train: 90.00%, Valid: 76.25% Test: 84.31%\n",
      "Run: 05, Epoch: 109, Loss: 0.4327, Train: 87.50%, Valid: 77.50% Test: 82.35%\n",
      "Run: 05, Epoch: 110, Loss: 0.4339, Train: 87.50%, Valid: 78.75% Test: 84.31%\n",
      "Run: 05, Epoch: 111, Loss: 0.4066, Train: 89.17%, Valid: 78.75% Test: 86.27%\n",
      "Run: 05, Epoch: 112, Loss: 0.4419, Train: 90.00%, Valid: 78.75% Test: 90.20%\n",
      "Run: 05, Epoch: 113, Loss: 0.3989, Train: 89.17%, Valid: 77.50% Test: 88.24%\n",
      "Run: 05, Epoch: 114, Loss: 0.4442, Train: 89.17%, Valid: 77.50% Test: 82.35%\n",
      "Run: 05, Epoch: 115, Loss: 0.4107, Train: 90.00%, Valid: 78.75% Test: 82.35%\n",
      "Run: 05, Epoch: 116, Loss: 0.3634, Train: 89.17%, Valid: 80.00% Test: 84.31%\n",
      "Run: 05, Epoch: 117, Loss: 0.3821, Train: 89.17%, Valid: 78.75% Test: 82.35%\n",
      "Run: 05, Epoch: 118, Loss: 0.3908, Train: 89.17%, Valid: 78.75% Test: 82.35%\n",
      "Run: 05, Epoch: 119, Loss: 0.4132, Train: 90.00%, Valid: 78.75% Test: 86.27%\n",
      "Run: 05, Epoch: 120, Loss: 0.3790, Train: 90.00%, Valid: 80.00% Test: 84.31%\n",
      "Run: 05, Epoch: 121, Loss: 0.4032, Train: 91.67%, Valid: 80.00% Test: 84.31%\n",
      "Run: 05, Epoch: 122, Loss: 0.4156, Train: 93.33%, Valid: 80.00% Test: 84.31%\n",
      "Run: 05, Epoch: 123, Loss: 0.3584, Train: 95.00%, Valid: 80.00% Test: 84.31%\n",
      "Run: 05, Epoch: 124, Loss: 0.3517, Train: 95.83%, Valid: 81.25% Test: 84.31%\n",
      "Run: 05, Epoch: 125, Loss: 0.3953, Train: 95.83%, Valid: 82.50% Test: 88.24%\n",
      "Run: 05, Epoch: 126, Loss: 0.3669, Train: 97.50%, Valid: 83.75% Test: 92.16%\n",
      "Run: 05, Epoch: 127, Loss: 0.3497, Train: 96.67%, Valid: 85.00% Test: 94.12%\n",
      "Run: 05, Epoch: 128, Loss: 0.4003, Train: 97.50%, Valid: 85.00% Test: 90.20%\n",
      "Run: 05, Epoch: 129, Loss: 0.4064, Train: 97.50%, Valid: 82.50% Test: 94.12%\n",
      "Run: 05, Epoch: 130, Loss: 0.3897, Train: 97.50%, Valid: 81.25% Test: 94.12%\n",
      "Run: 05, Epoch: 131, Loss: 0.4038, Train: 95.00%, Valid: 80.00% Test: 96.08%\n",
      "Run: 05, Epoch: 132, Loss: 0.3636, Train: 94.17%, Valid: 80.00% Test: 88.24%\n",
      "Run: 05, Epoch: 133, Loss: 0.3407, Train: 95.00%, Valid: 80.00% Test: 88.24%\n",
      "Run: 05, Epoch: 134, Loss: 0.3130, Train: 95.00%, Valid: 80.00% Test: 88.24%\n",
      "Run: 05, Epoch: 135, Loss: 0.3446, Train: 95.83%, Valid: 80.00% Test: 88.24%\n",
      "Run: 05, Epoch: 136, Loss: 0.3581, Train: 95.83%, Valid: 82.50% Test: 88.24%\n",
      "Run: 05, Epoch: 137, Loss: 0.3534, Train: 95.83%, Valid: 83.75% Test: 84.31%\n",
      "Run: 05, Epoch: 138, Loss: 0.3704, Train: 96.67%, Valid: 83.75% Test: 84.31%\n",
      "Run: 05, Epoch: 139, Loss: 0.3395, Train: 95.00%, Valid: 83.75% Test: 84.31%\n",
      "Run: 05, Epoch: 140, Loss: 0.3576, Train: 96.67%, Valid: 82.50% Test: 84.31%\n",
      "Run: 05, Epoch: 141, Loss: 0.3232, Train: 95.00%, Valid: 81.25% Test: 84.31%\n",
      "Run: 05, Epoch: 142, Loss: 0.3349, Train: 96.67%, Valid: 80.00% Test: 90.20%\n",
      "Run: 05, Epoch: 143, Loss: 0.3693, Train: 95.00%, Valid: 78.75% Test: 88.24%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 144, Loss: 0.3358, Train: 94.17%, Valid: 78.75% Test: 92.16%\n",
      "Run: 05, Epoch: 145, Loss: 0.3524, Train: 94.17%, Valid: 78.75% Test: 94.12%\n",
      "Run: 05, Epoch: 146, Loss: 0.3082, Train: 94.17%, Valid: 80.00% Test: 94.12%\n",
      "Run: 05, Epoch: 147, Loss: 0.3460, Train: 95.83%, Valid: 81.25% Test: 92.16%\n",
      "Run: 05, Epoch: 148, Loss: 0.3309, Train: 97.50%, Valid: 82.50% Test: 86.27%\n",
      "Run: 05, Epoch: 149, Loss: 0.3538, Train: 96.67%, Valid: 83.75% Test: 86.27%\n",
      "Run: 05, Epoch: 150, Loss: 0.3396, Train: 96.67%, Valid: 81.25% Test: 86.27%\n",
      "Run: 05, Epoch: 151, Loss: 0.3880, Train: 96.67%, Valid: 80.00% Test: 90.20%\n",
      "Run: 05, Epoch: 152, Loss: 0.3257, Train: 95.83%, Valid: 81.25% Test: 88.24%\n",
      "Run: 05, Epoch: 153, Loss: 0.3201, Train: 94.17%, Valid: 77.50% Test: 90.20%\n",
      "Run: 05, Epoch: 154, Loss: 0.3325, Train: 93.33%, Valid: 73.75% Test: 90.20%\n",
      "Run: 05, Epoch: 155, Loss: 0.3065, Train: 94.17%, Valid: 73.75% Test: 86.27%\n",
      "Run: 05, Epoch: 156, Loss: 0.3329, Train: 95.00%, Valid: 75.00% Test: 86.27%\n",
      "Run: 05, Epoch: 157, Loss: 0.3351, Train: 96.67%, Valid: 81.25% Test: 90.20%\n",
      "Run: 05, Epoch: 158, Loss: 0.3174, Train: 98.33%, Valid: 81.25% Test: 90.20%\n",
      "Run: 05, Epoch: 159, Loss: 0.3374, Train: 96.67%, Valid: 81.25% Test: 90.20%\n",
      "Run: 05, Epoch: 160, Loss: 0.3160, Train: 96.67%, Valid: 80.00% Test: 90.20%\n",
      "Run: 05, Epoch: 161, Loss: 0.3284, Train: 96.67%, Valid: 77.50% Test: 90.20%\n",
      "Run: 05, Epoch: 162, Loss: 0.2866, Train: 97.50%, Valid: 80.00% Test: 90.20%\n",
      "Run: 05, Epoch: 163, Loss: 0.3064, Train: 98.33%, Valid: 81.25% Test: 88.24%\n",
      "Run: 05, Epoch: 164, Loss: 0.2963, Train: 97.50%, Valid: 82.50% Test: 90.20%\n",
      "Run: 05, Epoch: 165, Loss: 0.3295, Train: 97.50%, Valid: 82.50% Test: 92.16%\n",
      "Run: 05, Epoch: 166, Loss: 0.3234, Train: 96.67%, Valid: 83.75% Test: 92.16%\n",
      "Run: 05, Epoch: 167, Loss: 0.3163, Train: 95.83%, Valid: 83.75% Test: 90.20%\n",
      "Run: 05, Epoch: 168, Loss: 0.3226, Train: 98.33%, Valid: 83.75% Test: 90.20%\n",
      "Run: 05, Epoch: 169, Loss: 0.2987, Train: 97.50%, Valid: 82.50% Test: 94.12%\n",
      "Run: 05, Epoch: 170, Loss: 0.3306, Train: 98.33%, Valid: 86.25% Test: 96.08%\n",
      "Run: 05, Epoch: 171, Loss: 0.3488, Train: 98.33%, Valid: 85.00% Test: 94.12%\n",
      "Run: 05, Epoch: 172, Loss: 0.2693, Train: 98.33%, Valid: 82.50% Test: 94.12%\n",
      "Run: 05, Epoch: 173, Loss: 0.2860, Train: 98.33%, Valid: 82.50% Test: 96.08%\n",
      "Run: 05, Epoch: 174, Loss: 0.2904, Train: 97.50%, Valid: 83.75% Test: 90.20%\n",
      "Run: 05, Epoch: 175, Loss: 0.2900, Train: 97.50%, Valid: 85.00% Test: 90.20%\n",
      "Run: 05, Epoch: 176, Loss: 0.2738, Train: 96.67%, Valid: 85.00% Test: 86.27%\n",
      "Run: 05, Epoch: 177, Loss: 0.3035, Train: 95.83%, Valid: 85.00% Test: 86.27%\n",
      "Run: 05, Epoch: 178, Loss: 0.2828, Train: 95.83%, Valid: 83.75% Test: 88.24%\n",
      "Run: 05, Epoch: 179, Loss: 0.2727, Train: 95.83%, Valid: 82.50% Test: 92.16%\n",
      "Run: 05, Epoch: 180, Loss: 0.2771, Train: 96.67%, Valid: 82.50% Test: 94.12%\n",
      "Run: 05, Epoch: 181, Loss: 0.2929, Train: 97.50%, Valid: 81.25% Test: 94.12%\n",
      "Run: 05, Epoch: 182, Loss: 0.2956, Train: 95.00%, Valid: 78.75% Test: 92.16%\n",
      "Run: 05, Epoch: 183, Loss: 0.2999, Train: 95.00%, Valid: 78.75% Test: 92.16%\n",
      "Run: 05, Epoch: 184, Loss: 0.2440, Train: 96.67%, Valid: 78.75% Test: 96.08%\n",
      "Run: 05, Epoch: 185, Loss: 0.2873, Train: 97.50%, Valid: 80.00% Test: 96.08%\n",
      "Run: 05, Epoch: 186, Loss: 0.3031, Train: 99.17%, Valid: 82.50% Test: 96.08%\n",
      "Run: 05, Epoch: 187, Loss: 0.2948, Train: 97.50%, Valid: 86.25% Test: 92.16%\n",
      "Run: 05, Epoch: 188, Loss: 0.3250, Train: 97.50%, Valid: 85.00% Test: 90.20%\n",
      "Run: 05, Epoch: 189, Loss: 0.2981, Train: 96.67%, Valid: 86.25% Test: 82.35%\n",
      "Run: 05, Epoch: 190, Loss: 0.2429, Train: 95.83%, Valid: 83.75% Test: 76.47%\n",
      "Run: 05, Epoch: 191, Loss: 0.2724, Train: 95.83%, Valid: 83.75% Test: 80.39%\n",
      "Run: 05, Epoch: 192, Loss: 0.2620, Train: 97.50%, Valid: 85.00% Test: 88.24%\n",
      "Run: 05, Epoch: 193, Loss: 0.2932, Train: 97.50%, Valid: 83.75% Test: 88.24%\n",
      "Run: 05, Epoch: 194, Loss: 0.2362, Train: 98.33%, Valid: 81.25% Test: 88.24%\n",
      "Run: 05, Epoch: 195, Loss: 0.2055, Train: 98.33%, Valid: 81.25% Test: 88.24%\n",
      "Run: 05, Epoch: 196, Loss: 0.2378, Train: 97.50%, Valid: 80.00% Test: 96.08%\n",
      "Run: 05, Epoch: 197, Loss: 0.2561, Train: 96.67%, Valid: 81.25% Test: 94.12%\n",
      "Run: 05, Epoch: 198, Loss: 0.3055, Train: 95.83%, Valid: 81.25% Test: 94.12%\n",
      "Run: 05, Epoch: 199, Loss: 0.2725, Train: 95.83%, Valid: 80.00% Test: 84.31%\n",
      "Run: 05, Epoch: 200, Loss: 0.2826, Train: 97.50%, Valid: 78.75% Test: 86.27%\n",
      "Run 05:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 86.25\n",
      "  Final Train: 98.33\n",
      "   Final Test: 96.08\n",
      "Run: 06, Epoch: 01, Loss: 1.6062, Train: 25.83%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 02, Loss: 1.5340, Train: 25.83%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 03, Loss: 1.4950, Train: 25.83%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 04, Loss: 1.4299, Train: 25.83%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 05, Loss: 1.3787, Train: 30.83%, Valid: 33.75% Test: 39.22%\n",
      "Run: 06, Epoch: 06, Loss: 1.3487, Train: 47.50%, Valid: 43.75% Test: 52.94%\n",
      "Run: 06, Epoch: 07, Loss: 1.2847, Train: 58.33%, Valid: 52.50% Test: 58.82%\n",
      "Run: 06, Epoch: 08, Loss: 1.2595, Train: 54.17%, Valid: 57.50% Test: 54.90%\n",
      "Run: 06, Epoch: 09, Loss: 1.2310, Train: 52.50%, Valid: 55.00% Test: 54.90%\n",
      "Run: 06, Epoch: 10, Loss: 1.1922, Train: 53.33%, Valid: 56.25% Test: 54.90%\n",
      "Run: 06, Epoch: 11, Loss: 1.1417, Train: 53.33%, Valid: 55.00% Test: 54.90%\n",
      "Run: 06, Epoch: 12, Loss: 1.1375, Train: 54.17%, Valid: 57.50% Test: 54.90%\n",
      "Run: 06, Epoch: 13, Loss: 1.0871, Train: 54.17%, Valid: 57.50% Test: 54.90%\n",
      "Run: 06, Epoch: 14, Loss: 1.0914, Train: 54.17%, Valid: 57.50% Test: 56.86%\n",
      "Run: 06, Epoch: 15, Loss: 1.0404, Train: 54.17%, Valid: 57.50% Test: 56.86%\n",
      "Run: 06, Epoch: 16, Loss: 1.0407, Train: 55.00%, Valid: 56.25% Test: 56.86%\n",
      "Run: 06, Epoch: 17, Loss: 0.9949, Train: 53.33%, Valid: 55.00% Test: 58.82%\n",
      "Run: 06, Epoch: 18, Loss: 0.9872, Train: 55.00%, Valid: 53.75% Test: 58.82%\n",
      "Run: 06, Epoch: 19, Loss: 0.9842, Train: 58.33%, Valid: 53.75% Test: 58.82%\n",
      "Run: 06, Epoch: 20, Loss: 0.9347, Train: 60.00%, Valid: 56.25% Test: 60.78%\n",
      "Run: 06, Epoch: 21, Loss: 0.9217, Train: 65.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 06, Epoch: 22, Loss: 0.9342, Train: 65.83%, Valid: 66.25% Test: 64.71%\n",
      "Run: 06, Epoch: 23, Loss: 0.9183, Train: 67.50%, Valid: 66.25% Test: 62.75%\n",
      "Run: 06, Epoch: 24, Loss: 0.8788, Train: 67.50%, Valid: 66.25% Test: 62.75%\n",
      "Run: 06, Epoch: 25, Loss: 0.8882, Train: 66.67%, Valid: 66.25% Test: 64.71%\n",
      "Run: 06, Epoch: 26, Loss: 0.8704, Train: 66.67%, Valid: 63.75% Test: 64.71%\n",
      "Run: 06, Epoch: 27, Loss: 0.8497, Train: 66.67%, Valid: 63.75% Test: 64.71%\n",
      "Run: 06, Epoch: 28, Loss: 0.8577, Train: 65.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 06, Epoch: 29, Loss: 0.8650, Train: 69.17%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 30, Loss: 0.8703, Train: 71.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 31, Loss: 0.8449, Train: 72.50%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 32, Loss: 0.7954, Train: 72.50%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 33, Loss: 0.7902, Train: 73.33%, Valid: 66.25% Test: 64.71%\n",
      "Run: 06, Epoch: 34, Loss: 0.8142, Train: 75.83%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 35, Loss: 0.7943, Train: 78.33%, Valid: 73.75% Test: 66.67%\n",
      "Run: 06, Epoch: 36, Loss: 0.8312, Train: 78.33%, Valid: 77.50% Test: 66.67%\n",
      "Run: 06, Epoch: 37, Loss: 0.7796, Train: 80.00%, Valid: 80.00% Test: 72.55%\n",
      "Run: 06, Epoch: 38, Loss: 0.7948, Train: 78.33%, Valid: 78.75% Test: 78.43%\n",
      "Run: 06, Epoch: 39, Loss: 0.7852, Train: 76.67%, Valid: 80.00% Test: 82.35%\n",
      "Run: 06, Epoch: 40, Loss: 0.7827, Train: 75.83%, Valid: 80.00% Test: 80.39%\n",
      "Run: 06, Epoch: 41, Loss: 0.7893, Train: 75.83%, Valid: 81.25% Test: 82.35%\n",
      "Run: 06, Epoch: 42, Loss: 0.7441, Train: 77.50%, Valid: 78.75% Test: 74.51%\n",
      "Run: 06, Epoch: 43, Loss: 0.7343, Train: 75.00%, Valid: 75.00% Test: 72.55%\n",
      "Run: 06, Epoch: 44, Loss: 0.6984, Train: 74.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 45, Loss: 0.7270, Train: 75.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 06, Epoch: 46, Loss: 0.7280, Train: 80.00%, Valid: 77.50% Test: 72.55%\n",
      "Run: 06, Epoch: 47, Loss: 0.7352, Train: 81.67%, Valid: 78.75% Test: 68.63%\n",
      "Run: 06, Epoch: 48, Loss: 0.7254, Train: 85.00%, Valid: 76.25% Test: 68.63%\n",
      "Run: 06, Epoch: 49, Loss: 0.7183, Train: 88.33%, Valid: 81.25% Test: 76.47%\n",
      "Run: 06, Epoch: 50, Loss: 0.7088, Train: 87.50%, Valid: 86.25% Test: 76.47%\n",
      "Run: 06, Epoch: 51, Loss: 0.7075, Train: 85.83%, Valid: 86.25% Test: 78.43%\n",
      "Run: 06, Epoch: 52, Loss: 0.6682, Train: 82.50%, Valid: 83.75% Test: 76.47%\n",
      "Run: 06, Epoch: 53, Loss: 0.7289, Train: 80.00%, Valid: 82.50% Test: 74.51%\n",
      "Run: 06, Epoch: 54, Loss: 0.6713, Train: 82.50%, Valid: 86.25% Test: 76.47%\n",
      "Run: 06, Epoch: 55, Loss: 0.6684, Train: 84.17%, Valid: 85.00% Test: 78.43%\n",
      "Run: 06, Epoch: 56, Loss: 0.7025, Train: 85.00%, Valid: 82.50% Test: 76.47%\n",
      "Run: 06, Epoch: 57, Loss: 0.7202, Train: 85.00%, Valid: 83.75% Test: 72.55%\n",
      "Run: 06, Epoch: 58, Loss: 0.6359, Train: 83.33%, Valid: 78.75% Test: 66.67%\n",
      "Run: 06, Epoch: 59, Loss: 0.6600, Train: 80.83%, Valid: 77.50% Test: 64.71%\n",
      "Run: 06, Epoch: 60, Loss: 0.6572, Train: 80.00%, Valid: 75.00% Test: 64.71%\n",
      "Run: 06, Epoch: 61, Loss: 0.6278, Train: 81.67%, Valid: 78.75% Test: 62.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 62, Loss: 0.6340, Train: 84.17%, Valid: 81.25% Test: 62.75%\n",
      "Run: 06, Epoch: 63, Loss: 0.6376, Train: 85.83%, Valid: 80.00% Test: 62.75%\n",
      "Run: 06, Epoch: 64, Loss: 0.6018, Train: 87.50%, Valid: 81.25% Test: 66.67%\n",
      "Run: 06, Epoch: 65, Loss: 0.6001, Train: 89.17%, Valid: 85.00% Test: 70.59%\n",
      "Run: 06, Epoch: 66, Loss: 0.6090, Train: 89.17%, Valid: 86.25% Test: 78.43%\n",
      "Run: 06, Epoch: 67, Loss: 0.5962, Train: 89.17%, Valid: 86.25% Test: 80.39%\n",
      "Run: 06, Epoch: 68, Loss: 0.5904, Train: 90.00%, Valid: 87.50% Test: 78.43%\n",
      "Run: 06, Epoch: 69, Loss: 0.5691, Train: 86.67%, Valid: 88.75% Test: 78.43%\n",
      "Run: 06, Epoch: 70, Loss: 0.5574, Train: 85.00%, Valid: 88.75% Test: 78.43%\n",
      "Run: 06, Epoch: 71, Loss: 0.5571, Train: 86.67%, Valid: 88.75% Test: 76.47%\n",
      "Run: 06, Epoch: 72, Loss: 0.5569, Train: 87.50%, Valid: 86.25% Test: 78.43%\n",
      "Run: 06, Epoch: 73, Loss: 0.5674, Train: 86.67%, Valid: 85.00% Test: 76.47%\n",
      "Run: 06, Epoch: 74, Loss: 0.5595, Train: 87.50%, Valid: 81.25% Test: 74.51%\n",
      "Run: 06, Epoch: 75, Loss: 0.5312, Train: 87.50%, Valid: 81.25% Test: 74.51%\n",
      "Run: 06, Epoch: 76, Loss: 0.5060, Train: 87.50%, Valid: 80.00% Test: 70.59%\n",
      "Run: 06, Epoch: 77, Loss: 0.5715, Train: 85.83%, Valid: 81.25% Test: 70.59%\n",
      "Run: 06, Epoch: 78, Loss: 0.5775, Train: 89.17%, Valid: 82.50% Test: 66.67%\n",
      "Run: 06, Epoch: 79, Loss: 0.5313, Train: 90.00%, Valid: 83.75% Test: 70.59%\n",
      "Run: 06, Epoch: 80, Loss: 0.5092, Train: 90.00%, Valid: 86.25% Test: 72.55%\n",
      "Run: 06, Epoch: 81, Loss: 0.5182, Train: 90.00%, Valid: 81.25% Test: 68.63%\n",
      "Run: 06, Epoch: 82, Loss: 0.4746, Train: 88.33%, Valid: 81.25% Test: 70.59%\n",
      "Run: 06, Epoch: 83, Loss: 0.5050, Train: 86.67%, Valid: 83.75% Test: 70.59%\n",
      "Run: 06, Epoch: 84, Loss: 0.5051, Train: 84.17%, Valid: 85.00% Test: 70.59%\n",
      "Run: 06, Epoch: 85, Loss: 0.5134, Train: 85.00%, Valid: 82.50% Test: 70.59%\n",
      "Run: 06, Epoch: 86, Loss: 0.5583, Train: 90.00%, Valid: 87.50% Test: 72.55%\n",
      "Run: 06, Epoch: 87, Loss: 0.5241, Train: 91.67%, Valid: 88.75% Test: 72.55%\n",
      "Run: 06, Epoch: 88, Loss: 0.5321, Train: 92.50%, Valid: 83.75% Test: 72.55%\n",
      "Run: 06, Epoch: 89, Loss: 0.4553, Train: 91.67%, Valid: 78.75% Test: 70.59%\n",
      "Run: 06, Epoch: 90, Loss: 0.4776, Train: 92.50%, Valid: 78.75% Test: 68.63%\n",
      "Run: 06, Epoch: 91, Loss: 0.5074, Train: 91.67%, Valid: 82.50% Test: 70.59%\n",
      "Run: 06, Epoch: 92, Loss: 0.4683, Train: 92.50%, Valid: 85.00% Test: 68.63%\n",
      "Run: 06, Epoch: 93, Loss: 0.4946, Train: 90.83%, Valid: 85.00% Test: 76.47%\n",
      "Run: 06, Epoch: 94, Loss: 0.4917, Train: 90.83%, Valid: 86.25% Test: 74.51%\n",
      "Run: 06, Epoch: 95, Loss: 0.4953, Train: 90.83%, Valid: 88.75% Test: 76.47%\n",
      "Run: 06, Epoch: 96, Loss: 0.4493, Train: 90.83%, Valid: 88.75% Test: 76.47%\n",
      "Run: 06, Epoch: 97, Loss: 0.4152, Train: 90.00%, Valid: 88.75% Test: 72.55%\n",
      "Run: 06, Epoch: 98, Loss: 0.4593, Train: 91.67%, Valid: 88.75% Test: 74.51%\n",
      "Run: 06, Epoch: 99, Loss: 0.4449, Train: 91.67%, Valid: 87.50% Test: 74.51%\n",
      "Run: 06, Epoch: 100, Loss: 0.4372, Train: 91.67%, Valid: 87.50% Test: 74.51%\n",
      "Run: 06, Epoch: 101, Loss: 0.4336, Train: 93.33%, Valid: 86.25% Test: 70.59%\n",
      "Run: 06, Epoch: 102, Loss: 0.4513, Train: 90.83%, Valid: 83.75% Test: 70.59%\n",
      "Run: 06, Epoch: 103, Loss: 0.4438, Train: 89.17%, Valid: 83.75% Test: 68.63%\n",
      "Run: 06, Epoch: 104, Loss: 0.4755, Train: 90.83%, Valid: 86.25% Test: 70.59%\n",
      "Run: 06, Epoch: 105, Loss: 0.3708, Train: 90.83%, Valid: 88.75% Test: 74.51%\n",
      "Run: 06, Epoch: 106, Loss: 0.4103, Train: 90.83%, Valid: 88.75% Test: 78.43%\n",
      "Run: 06, Epoch: 107, Loss: 0.4415, Train: 89.17%, Valid: 90.00% Test: 78.43%\n",
      "Run: 06, Epoch: 108, Loss: 0.4714, Train: 89.17%, Valid: 90.00% Test: 78.43%\n",
      "Run: 06, Epoch: 109, Loss: 0.4233, Train: 90.83%, Valid: 90.00% Test: 78.43%\n",
      "Run: 06, Epoch: 110, Loss: 0.4499, Train: 92.50%, Valid: 91.25% Test: 82.35%\n",
      "Run: 06, Epoch: 111, Loss: 0.3943, Train: 93.33%, Valid: 90.00% Test: 80.39%\n",
      "Run: 06, Epoch: 112, Loss: 0.3743, Train: 92.50%, Valid: 90.00% Test: 84.31%\n",
      "Run: 06, Epoch: 113, Loss: 0.3748, Train: 94.17%, Valid: 87.50% Test: 82.35%\n",
      "Run: 06, Epoch: 114, Loss: 0.3439, Train: 93.33%, Valid: 85.00% Test: 76.47%\n",
      "Run: 06, Epoch: 115, Loss: 0.4076, Train: 91.67%, Valid: 85.00% Test: 70.59%\n",
      "Run: 06, Epoch: 116, Loss: 0.4126, Train: 89.17%, Valid: 82.50% Test: 62.75%\n",
      "Run: 06, Epoch: 117, Loss: 0.3715, Train: 88.33%, Valid: 82.50% Test: 60.78%\n",
      "Run: 06, Epoch: 118, Loss: 0.4273, Train: 90.00%, Valid: 83.75% Test: 64.71%\n",
      "Run: 06, Epoch: 119, Loss: 0.3472, Train: 90.83%, Valid: 82.50% Test: 70.59%\n",
      "Run: 06, Epoch: 120, Loss: 0.4038, Train: 92.50%, Valid: 83.75% Test: 74.51%\n",
      "Run: 06, Epoch: 121, Loss: 0.3972, Train: 93.33%, Valid: 86.25% Test: 76.47%\n",
      "Run: 06, Epoch: 122, Loss: 0.3516, Train: 93.33%, Valid: 86.25% Test: 80.39%\n",
      "Run: 06, Epoch: 123, Loss: 0.4146, Train: 95.00%, Valid: 86.25% Test: 80.39%\n",
      "Run: 06, Epoch: 124, Loss: 0.3824, Train: 95.83%, Valid: 85.00% Test: 78.43%\n",
      "Run: 06, Epoch: 125, Loss: 0.3501, Train: 96.67%, Valid: 87.50% Test: 80.39%\n",
      "Run: 06, Epoch: 126, Loss: 0.3527, Train: 97.50%, Valid: 83.75% Test: 76.47%\n",
      "Run: 06, Epoch: 127, Loss: 0.3717, Train: 95.83%, Valid: 80.00% Test: 72.55%\n",
      "Run: 06, Epoch: 128, Loss: 0.3766, Train: 94.17%, Valid: 76.25% Test: 66.67%\n",
      "Run: 06, Epoch: 129, Loss: 0.3702, Train: 94.17%, Valid: 77.50% Test: 60.78%\n",
      "Run: 06, Epoch: 130, Loss: 0.3528, Train: 90.83%, Valid: 80.00% Test: 60.78%\n",
      "Run: 06, Epoch: 131, Loss: 0.3819, Train: 93.33%, Valid: 82.50% Test: 70.59%\n",
      "Run: 06, Epoch: 132, Loss: 0.4087, Train: 95.83%, Valid: 85.00% Test: 72.55%\n",
      "Run: 06, Epoch: 133, Loss: 0.3816, Train: 96.67%, Valid: 87.50% Test: 76.47%\n",
      "Run: 06, Epoch: 134, Loss: 0.3712, Train: 95.00%, Valid: 88.75% Test: 80.39%\n",
      "Run: 06, Epoch: 135, Loss: 0.4047, Train: 94.17%, Valid: 87.50% Test: 80.39%\n",
      "Run: 06, Epoch: 136, Loss: 0.3752, Train: 93.33%, Valid: 87.50% Test: 78.43%\n",
      "Run: 06, Epoch: 137, Loss: 0.3892, Train: 95.00%, Valid: 87.50% Test: 76.47%\n",
      "Run: 06, Epoch: 138, Loss: 0.3449, Train: 95.83%, Valid: 86.25% Test: 78.43%\n",
      "Run: 06, Epoch: 139, Loss: 0.3155, Train: 96.67%, Valid: 86.25% Test: 78.43%\n",
      "Run: 06, Epoch: 140, Loss: 0.3469, Train: 93.33%, Valid: 87.50% Test: 78.43%\n",
      "Run: 06, Epoch: 141, Loss: 0.3309, Train: 93.33%, Valid: 87.50% Test: 78.43%\n",
      "Run: 06, Epoch: 142, Loss: 0.3033, Train: 90.00%, Valid: 85.00% Test: 70.59%\n",
      "Run: 06, Epoch: 143, Loss: 0.3245, Train: 91.67%, Valid: 83.75% Test: 66.67%\n",
      "Run: 06, Epoch: 144, Loss: 0.3502, Train: 91.67%, Valid: 87.50% Test: 74.51%\n",
      "Run: 06, Epoch: 145, Loss: 0.3645, Train: 92.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 06, Epoch: 146, Loss: 0.3160, Train: 90.83%, Valid: 90.00% Test: 86.27%\n",
      "Run: 06, Epoch: 147, Loss: 0.4006, Train: 91.67%, Valid: 92.50% Test: 86.27%\n",
      "Run: 06, Epoch: 148, Loss: 0.3767, Train: 91.67%, Valid: 92.50% Test: 84.31%\n",
      "Run: 06, Epoch: 149, Loss: 0.3094, Train: 92.50%, Valid: 91.25% Test: 84.31%\n",
      "Run: 06, Epoch: 150, Loss: 0.3172, Train: 93.33%, Valid: 91.25% Test: 88.24%\n",
      "Run: 06, Epoch: 151, Loss: 0.3268, Train: 97.50%, Valid: 88.75% Test: 76.47%\n",
      "Run: 06, Epoch: 152, Loss: 0.3200, Train: 94.17%, Valid: 77.50% Test: 58.82%\n",
      "Run: 06, Epoch: 153, Loss: 0.3006, Train: 84.17%, Valid: 65.00% Test: 47.06%\n",
      "Run: 06, Epoch: 154, Loss: 0.3311, Train: 84.17%, Valid: 63.75% Test: 49.02%\n",
      "Run: 06, Epoch: 155, Loss: 0.3888, Train: 91.67%, Valid: 73.75% Test: 54.90%\n",
      "Run: 06, Epoch: 156, Loss: 0.2896, Train: 95.83%, Valid: 83.75% Test: 70.59%\n",
      "Run: 06, Epoch: 157, Loss: 0.3318, Train: 99.17%, Valid: 87.50% Test: 82.35%\n",
      "Run: 06, Epoch: 158, Loss: 0.3251, Train: 95.83%, Valid: 88.75% Test: 80.39%\n",
      "Run: 06, Epoch: 159, Loss: 0.2816, Train: 93.33%, Valid: 86.25% Test: 80.39%\n",
      "Run: 06, Epoch: 160, Loss: 0.3095, Train: 92.50%, Valid: 87.50% Test: 80.39%\n",
      "Run: 06, Epoch: 161, Loss: 0.3492, Train: 91.67%, Valid: 86.25% Test: 76.47%\n",
      "Run: 06, Epoch: 162, Loss: 0.2992, Train: 91.67%, Valid: 80.00% Test: 70.59%\n",
      "Run: 06, Epoch: 163, Loss: 0.3491, Train: 90.83%, Valid: 78.75% Test: 68.63%\n",
      "Run: 06, Epoch: 164, Loss: 0.3302, Train: 90.00%, Valid: 78.75% Test: 70.59%\n",
      "Run: 06, Epoch: 165, Loss: 0.2846, Train: 94.17%, Valid: 82.50% Test: 68.63%\n",
      "Run: 06, Epoch: 166, Loss: 0.3189, Train: 96.67%, Valid: 83.75% Test: 74.51%\n",
      "Run: 06, Epoch: 167, Loss: 0.2889, Train: 96.67%, Valid: 87.50% Test: 76.47%\n",
      "Run: 06, Epoch: 168, Loss: 0.3766, Train: 96.67%, Valid: 91.25% Test: 76.47%\n",
      "Run: 06, Epoch: 169, Loss: 0.3645, Train: 97.50%, Valid: 90.00% Test: 76.47%\n",
      "Run: 06, Epoch: 170, Loss: 0.2737, Train: 97.50%, Valid: 90.00% Test: 84.31%\n",
      "Run: 06, Epoch: 171, Loss: 0.3482, Train: 97.50%, Valid: 88.75% Test: 84.31%\n",
      "Run: 06, Epoch: 172, Loss: 0.3070, Train: 95.83%, Valid: 90.00% Test: 86.27%\n",
      "Run: 06, Epoch: 173, Loss: 0.2873, Train: 95.00%, Valid: 88.75% Test: 80.39%\n",
      "Run: 06, Epoch: 174, Loss: 0.3015, Train: 95.00%, Valid: 88.75% Test: 80.39%\n",
      "Run: 06, Epoch: 175, Loss: 0.2461, Train: 95.83%, Valid: 90.00% Test: 80.39%\n",
      "Run: 06, Epoch: 176, Loss: 0.3296, Train: 95.83%, Valid: 91.25% Test: 78.43%\n",
      "Run: 06, Epoch: 177, Loss: 0.3264, Train: 96.67%, Valid: 91.25% Test: 78.43%\n",
      "Run: 06, Epoch: 178, Loss: 0.3027, Train: 95.00%, Valid: 92.50% Test: 78.43%\n",
      "Run: 06, Epoch: 179, Loss: 0.2407, Train: 95.83%, Valid: 92.50% Test: 82.35%\n",
      "Run: 06, Epoch: 180, Loss: 0.2267, Train: 96.67%, Valid: 92.50% Test: 82.35%\n",
      "Run: 06, Epoch: 181, Loss: 0.2449, Train: 96.67%, Valid: 92.50% Test: 84.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 182, Loss: 0.3033, Train: 96.67%, Valid: 92.50% Test: 84.31%\n",
      "Run: 06, Epoch: 183, Loss: 0.2936, Train: 96.67%, Valid: 90.00% Test: 84.31%\n",
      "Run: 06, Epoch: 184, Loss: 0.2210, Train: 95.00%, Valid: 86.25% Test: 80.39%\n",
      "Run: 06, Epoch: 185, Loss: 0.3179, Train: 94.17%, Valid: 86.25% Test: 82.35%\n",
      "Run: 06, Epoch: 186, Loss: 0.2826, Train: 94.17%, Valid: 88.75% Test: 82.35%\n",
      "Run: 06, Epoch: 187, Loss: 0.2764, Train: 95.83%, Valid: 86.25% Test: 78.43%\n",
      "Run: 06, Epoch: 188, Loss: 0.2075, Train: 96.67%, Valid: 88.75% Test: 78.43%\n",
      "Run: 06, Epoch: 189, Loss: 0.2788, Train: 96.67%, Valid: 88.75% Test: 78.43%\n",
      "Run: 06, Epoch: 190, Loss: 0.2932, Train: 96.67%, Valid: 90.00% Test: 84.31%\n",
      "Run: 06, Epoch: 191, Loss: 0.3191, Train: 97.50%, Valid: 91.25% Test: 80.39%\n",
      "Run: 06, Epoch: 192, Loss: 0.2651, Train: 95.83%, Valid: 91.25% Test: 80.39%\n",
      "Run: 06, Epoch: 193, Loss: 0.2586, Train: 95.83%, Valid: 91.25% Test: 82.35%\n",
      "Run: 06, Epoch: 194, Loss: 0.2634, Train: 95.83%, Valid: 90.00% Test: 78.43%\n",
      "Run: 06, Epoch: 195, Loss: 0.2472, Train: 96.67%, Valid: 87.50% Test: 76.47%\n",
      "Run: 06, Epoch: 196, Loss: 0.2865, Train: 95.83%, Valid: 85.00% Test: 74.51%\n",
      "Run: 06, Epoch: 197, Loss: 0.2808, Train: 95.00%, Valid: 83.75% Test: 72.55%\n",
      "Run: 06, Epoch: 198, Loss: 0.2556, Train: 90.83%, Valid: 80.00% Test: 68.63%\n",
      "Run: 06, Epoch: 199, Loss: 0.2365, Train: 90.83%, Valid: 81.25% Test: 64.71%\n",
      "Run: 06, Epoch: 200, Loss: 0.2355, Train: 90.83%, Valid: 82.50% Test: 62.75%\n",
      "Run 06:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 92.50\n",
      "  Final Train: 91.67\n",
      "   Final Test: 86.27\n",
      "Run: 07, Epoch: 01, Loss: 1.6954, Train: 7.50%, Valid: 11.25% Test: 5.88%\n",
      "Run: 07, Epoch: 02, Loss: 1.6149, Train: 7.50%, Valid: 11.25% Test: 5.88%\n",
      "Run: 07, Epoch: 03, Loss: 1.5633, Train: 7.50%, Valid: 11.25% Test: 5.88%\n",
      "Run: 07, Epoch: 04, Loss: 1.4883, Train: 7.50%, Valid: 11.25% Test: 5.88%\n",
      "Run: 07, Epoch: 05, Loss: 1.4595, Train: 44.17%, Valid: 51.25% Test: 49.02%\n",
      "Run: 07, Epoch: 06, Loss: 1.3859, Train: 45.83%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 07, Loss: 1.3465, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 08, Loss: 1.3044, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 09, Loss: 1.2396, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 10, Loss: 1.2204, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 11, Loss: 1.1785, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 12, Loss: 1.1601, Train: 45.83%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 13, Loss: 1.1459, Train: 46.67%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 14, Loss: 1.1246, Train: 49.17%, Valid: 52.50% Test: 50.98%\n",
      "Run: 07, Epoch: 15, Loss: 1.0906, Train: 54.17%, Valid: 53.75% Test: 52.94%\n",
      "Run: 07, Epoch: 16, Loss: 1.0563, Train: 57.50%, Valid: 58.75% Test: 62.75%\n",
      "Run: 07, Epoch: 17, Loss: 0.9929, Train: 60.00%, Valid: 58.75% Test: 62.75%\n",
      "Run: 07, Epoch: 18, Loss: 0.9896, Train: 60.83%, Valid: 60.00% Test: 62.75%\n",
      "Run: 07, Epoch: 19, Loss: 0.9649, Train: 64.17%, Valid: 62.50% Test: 66.67%\n",
      "Run: 07, Epoch: 20, Loss: 0.9083, Train: 68.33%, Valid: 63.75% Test: 66.67%\n",
      "Run: 07, Epoch: 21, Loss: 0.9115, Train: 68.33%, Valid: 63.75% Test: 68.63%\n",
      "Run: 07, Epoch: 22, Loss: 0.9418, Train: 69.17%, Valid: 62.50% Test: 66.67%\n",
      "Run: 07, Epoch: 23, Loss: 0.9010, Train: 65.00%, Valid: 62.50% Test: 66.67%\n",
      "Run: 07, Epoch: 24, Loss: 0.8949, Train: 63.33%, Valid: 61.25% Test: 66.67%\n",
      "Run: 07, Epoch: 25, Loss: 0.8904, Train: 65.00%, Valid: 65.00% Test: 66.67%\n",
      "Run: 07, Epoch: 26, Loss: 0.8772, Train: 67.50%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 27, Loss: 0.8912, Train: 71.67%, Valid: 70.00% Test: 70.59%\n",
      "Run: 07, Epoch: 28, Loss: 0.8207, Train: 74.17%, Valid: 67.50% Test: 76.47%\n",
      "Run: 07, Epoch: 29, Loss: 0.8618, Train: 74.17%, Valid: 66.25% Test: 72.55%\n",
      "Run: 07, Epoch: 30, Loss: 0.8280, Train: 72.50%, Valid: 62.50% Test: 68.63%\n",
      "Run: 07, Epoch: 31, Loss: 0.8409, Train: 67.50%, Valid: 58.75% Test: 64.71%\n",
      "Run: 07, Epoch: 32, Loss: 0.8420, Train: 65.83%, Valid: 55.00% Test: 64.71%\n",
      "Run: 07, Epoch: 33, Loss: 0.8120, Train: 70.00%, Valid: 60.00% Test: 64.71%\n",
      "Run: 07, Epoch: 34, Loss: 0.7910, Train: 74.17%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 35, Loss: 0.8050, Train: 75.83%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 36, Loss: 0.7892, Train: 75.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 07, Epoch: 37, Loss: 0.7877, Train: 71.67%, Valid: 70.00% Test: 70.59%\n",
      "Run: 07, Epoch: 38, Loss: 0.7763, Train: 70.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 39, Loss: 0.7759, Train: 72.50%, Valid: 66.25% Test: 72.55%\n",
      "Run: 07, Epoch: 40, Loss: 0.7636, Train: 77.50%, Valid: 68.75% Test: 74.51%\n",
      "Run: 07, Epoch: 41, Loss: 0.7832, Train: 77.50%, Valid: 68.75% Test: 74.51%\n",
      "Run: 07, Epoch: 42, Loss: 0.7271, Train: 77.50%, Valid: 67.50% Test: 72.55%\n",
      "Run: 07, Epoch: 43, Loss: 0.7285, Train: 78.33%, Valid: 66.25% Test: 70.59%\n",
      "Run: 07, Epoch: 44, Loss: 0.7292, Train: 79.17%, Valid: 63.75% Test: 70.59%\n",
      "Run: 07, Epoch: 45, Loss: 0.7423, Train: 79.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 46, Loss: 0.7098, Train: 79.17%, Valid: 66.25% Test: 74.51%\n",
      "Run: 07, Epoch: 47, Loss: 0.7491, Train: 78.33%, Valid: 68.75% Test: 76.47%\n",
      "Run: 07, Epoch: 48, Loss: 0.7154, Train: 76.67%, Valid: 67.50% Test: 76.47%\n",
      "Run: 07, Epoch: 49, Loss: 0.7098, Train: 76.67%, Valid: 68.75% Test: 76.47%\n",
      "Run: 07, Epoch: 50, Loss: 0.7235, Train: 75.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 07, Epoch: 51, Loss: 0.6920, Train: 73.33%, Valid: 71.25% Test: 72.55%\n",
      "Run: 07, Epoch: 52, Loss: 0.7012, Train: 75.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 07, Epoch: 53, Loss: 0.6492, Train: 75.83%, Valid: 72.50% Test: 72.55%\n",
      "Run: 07, Epoch: 54, Loss: 0.7140, Train: 75.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 07, Epoch: 55, Loss: 0.6980, Train: 79.17%, Valid: 72.50% Test: 72.55%\n",
      "Run: 07, Epoch: 56, Loss: 0.6479, Train: 80.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 07, Epoch: 57, Loss: 0.6807, Train: 78.33%, Valid: 71.25% Test: 72.55%\n",
      "Run: 07, Epoch: 58, Loss: 0.6483, Train: 79.17%, Valid: 72.50% Test: 72.55%\n",
      "Run: 07, Epoch: 59, Loss: 0.6918, Train: 79.17%, Valid: 73.75% Test: 76.47%\n",
      "Run: 07, Epoch: 60, Loss: 0.6574, Train: 80.83%, Valid: 73.75% Test: 78.43%\n",
      "Run: 07, Epoch: 61, Loss: 0.6329, Train: 84.17%, Valid: 73.75% Test: 80.39%\n",
      "Run: 07, Epoch: 62, Loss: 0.6437, Train: 85.00%, Valid: 73.75% Test: 80.39%\n",
      "Run: 07, Epoch: 63, Loss: 0.6179, Train: 83.33%, Valid: 76.25% Test: 78.43%\n",
      "Run: 07, Epoch: 64, Loss: 0.6790, Train: 85.83%, Valid: 78.75% Test: 80.39%\n",
      "Run: 07, Epoch: 65, Loss: 0.6142, Train: 88.33%, Valid: 80.00% Test: 84.31%\n",
      "Run: 07, Epoch: 66, Loss: 0.6197, Train: 89.17%, Valid: 78.75% Test: 86.27%\n",
      "Run: 07, Epoch: 67, Loss: 0.5804, Train: 90.83%, Valid: 80.00% Test: 86.27%\n",
      "Run: 07, Epoch: 68, Loss: 0.6016, Train: 90.00%, Valid: 81.25% Test: 84.31%\n",
      "Run: 07, Epoch: 69, Loss: 0.5893, Train: 88.33%, Valid: 77.50% Test: 80.39%\n",
      "Run: 07, Epoch: 70, Loss: 0.5866, Train: 85.00%, Valid: 73.75% Test: 76.47%\n",
      "Run: 07, Epoch: 71, Loss: 0.5760, Train: 87.50%, Valid: 73.75% Test: 80.39%\n",
      "Run: 07, Epoch: 72, Loss: 0.5757, Train: 85.00%, Valid: 72.50% Test: 78.43%\n",
      "Run: 07, Epoch: 73, Loss: 0.6050, Train: 85.83%, Valid: 72.50% Test: 78.43%\n",
      "Run: 07, Epoch: 74, Loss: 0.6362, Train: 86.67%, Valid: 75.00% Test: 80.39%\n",
      "Run: 07, Epoch: 75, Loss: 0.5454, Train: 87.50%, Valid: 76.25% Test: 82.35%\n",
      "Run: 07, Epoch: 76, Loss: 0.5888, Train: 85.83%, Valid: 75.00% Test: 80.39%\n",
      "Run: 07, Epoch: 77, Loss: 0.5452, Train: 85.83%, Valid: 75.00% Test: 80.39%\n",
      "Run: 07, Epoch: 78, Loss: 0.5621, Train: 87.50%, Valid: 72.50% Test: 76.47%\n",
      "Run: 07, Epoch: 79, Loss: 0.5745, Train: 85.83%, Valid: 71.25% Test: 76.47%\n",
      "Run: 07, Epoch: 80, Loss: 0.5147, Train: 85.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 07, Epoch: 81, Loss: 0.5489, Train: 85.83%, Valid: 73.75% Test: 74.51%\n",
      "Run: 07, Epoch: 82, Loss: 0.5736, Train: 85.00%, Valid: 76.25% Test: 76.47%\n",
      "Run: 07, Epoch: 83, Loss: 0.5310, Train: 85.00%, Valid: 76.25% Test: 76.47%\n",
      "Run: 07, Epoch: 84, Loss: 0.5333, Train: 85.00%, Valid: 78.75% Test: 78.43%\n",
      "Run: 07, Epoch: 85, Loss: 0.4986, Train: 85.83%, Valid: 78.75% Test: 78.43%\n",
      "Run: 07, Epoch: 86, Loss: 0.5304, Train: 84.17%, Valid: 76.25% Test: 78.43%\n",
      "Run: 07, Epoch: 87, Loss: 0.4798, Train: 84.17%, Valid: 75.00% Test: 78.43%\n",
      "Run: 07, Epoch: 88, Loss: 0.5096, Train: 83.33%, Valid: 76.25% Test: 80.39%\n",
      "Run: 07, Epoch: 89, Loss: 0.5479, Train: 85.83%, Valid: 75.00% Test: 82.35%\n",
      "Run: 07, Epoch: 90, Loss: 0.4959, Train: 86.67%, Valid: 76.25% Test: 80.39%\n",
      "Run: 07, Epoch: 91, Loss: 0.5641, Train: 87.50%, Valid: 76.25% Test: 78.43%\n",
      "Run: 07, Epoch: 92, Loss: 0.5253, Train: 88.33%, Valid: 75.00% Test: 78.43%\n",
      "Run: 07, Epoch: 93, Loss: 0.5251, Train: 91.67%, Valid: 80.00% Test: 78.43%\n",
      "Run: 07, Epoch: 94, Loss: 0.5138, Train: 91.67%, Valid: 83.75% Test: 86.27%\n",
      "Run: 07, Epoch: 95, Loss: 0.5008, Train: 93.33%, Valid: 83.75% Test: 84.31%\n",
      "Run: 07, Epoch: 96, Loss: 0.5126, Train: 93.33%, Valid: 85.00% Test: 86.27%\n",
      "Run: 07, Epoch: 97, Loss: 0.4889, Train: 93.33%, Valid: 85.00% Test: 86.27%\n",
      "Run: 07, Epoch: 98, Loss: 0.5066, Train: 91.67%, Valid: 82.50% Test: 86.27%\n",
      "Run: 07, Epoch: 99, Loss: 0.4905, Train: 90.83%, Valid: 81.25% Test: 86.27%\n",
      "Run: 07, Epoch: 100, Loss: 0.4667, Train: 90.00%, Valid: 81.25% Test: 86.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 101, Loss: 0.4893, Train: 90.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 07, Epoch: 102, Loss: 0.5308, Train: 91.67%, Valid: 83.75% Test: 88.24%\n",
      "Run: 07, Epoch: 103, Loss: 0.5148, Train: 93.33%, Valid: 82.50% Test: 88.24%\n",
      "Run: 07, Epoch: 104, Loss: 0.4771, Train: 94.17%, Valid: 85.00% Test: 88.24%\n",
      "Run: 07, Epoch: 105, Loss: 0.4846, Train: 95.00%, Valid: 83.75% Test: 88.24%\n",
      "Run: 07, Epoch: 106, Loss: 0.4493, Train: 95.83%, Valid: 86.25% Test: 88.24%\n",
      "Run: 07, Epoch: 107, Loss: 0.4825, Train: 95.00%, Valid: 87.50% Test: 88.24%\n",
      "Run: 07, Epoch: 108, Loss: 0.4422, Train: 95.00%, Valid: 88.75% Test: 92.16%\n",
      "Run: 07, Epoch: 109, Loss: 0.4227, Train: 93.33%, Valid: 83.75% Test: 92.16%\n",
      "Run: 07, Epoch: 110, Loss: 0.4286, Train: 89.17%, Valid: 83.75% Test: 86.27%\n",
      "Run: 07, Epoch: 111, Loss: 0.4698, Train: 90.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 07, Epoch: 112, Loss: 0.4647, Train: 90.00%, Valid: 78.75% Test: 84.31%\n",
      "Run: 07, Epoch: 113, Loss: 0.4607, Train: 90.83%, Valid: 78.75% Test: 82.35%\n",
      "Run: 07, Epoch: 114, Loss: 0.4543, Train: 91.67%, Valid: 78.75% Test: 84.31%\n",
      "Run: 07, Epoch: 115, Loss: 0.4512, Train: 92.50%, Valid: 80.00% Test: 82.35%\n",
      "Run: 07, Epoch: 116, Loss: 0.4367, Train: 94.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 07, Epoch: 117, Loss: 0.4597, Train: 97.50%, Valid: 83.75% Test: 86.27%\n",
      "Run: 07, Epoch: 118, Loss: 0.4356, Train: 96.67%, Valid: 87.50% Test: 88.24%\n",
      "Run: 07, Epoch: 119, Loss: 0.4186, Train: 95.83%, Valid: 87.50% Test: 90.20%\n",
      "Run: 07, Epoch: 120, Loss: 0.4387, Train: 95.83%, Valid: 86.25% Test: 90.20%\n",
      "Run: 07, Epoch: 121, Loss: 0.4469, Train: 95.83%, Valid: 86.25% Test: 94.12%\n",
      "Run: 07, Epoch: 122, Loss: 0.4497, Train: 94.17%, Valid: 86.25% Test: 96.08%\n",
      "Run: 07, Epoch: 123, Loss: 0.4128, Train: 94.17%, Valid: 87.50% Test: 94.12%\n",
      "Run: 07, Epoch: 124, Loss: 0.4124, Train: 93.33%, Valid: 86.25% Test: 90.20%\n",
      "Run: 07, Epoch: 125, Loss: 0.4095, Train: 92.50%, Valid: 83.75% Test: 90.20%\n",
      "Run: 07, Epoch: 126, Loss: 0.4206, Train: 92.50%, Valid: 83.75% Test: 88.24%\n",
      "Run: 07, Epoch: 127, Loss: 0.3479, Train: 92.50%, Valid: 85.00% Test: 86.27%\n",
      "Run: 07, Epoch: 128, Loss: 0.4451, Train: 94.17%, Valid: 85.00% Test: 86.27%\n",
      "Run: 07, Epoch: 129, Loss: 0.3999, Train: 91.67%, Valid: 86.25% Test: 88.24%\n",
      "Run: 07, Epoch: 130, Loss: 0.3813, Train: 90.00%, Valid: 83.75% Test: 82.35%\n",
      "Run: 07, Epoch: 131, Loss: 0.5074, Train: 90.00%, Valid: 85.00% Test: 82.35%\n",
      "Run: 07, Epoch: 132, Loss: 0.4081, Train: 91.67%, Valid: 85.00% Test: 86.27%\n",
      "Run: 07, Epoch: 133, Loss: 0.3958, Train: 94.17%, Valid: 85.00% Test: 90.20%\n",
      "Run: 07, Epoch: 134, Loss: 0.3500, Train: 95.00%, Valid: 86.25% Test: 90.20%\n",
      "Run: 07, Epoch: 135, Loss: 0.3595, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 07, Epoch: 136, Loss: 0.3790, Train: 94.17%, Valid: 80.00% Test: 84.31%\n",
      "Run: 07, Epoch: 137, Loss: 0.4006, Train: 94.17%, Valid: 80.00% Test: 82.35%\n",
      "Run: 07, Epoch: 138, Loss: 0.4120, Train: 93.33%, Valid: 77.50% Test: 84.31%\n",
      "Run: 07, Epoch: 139, Loss: 0.3630, Train: 95.83%, Valid: 82.50% Test: 84.31%\n",
      "Run: 07, Epoch: 140, Loss: 0.3914, Train: 97.50%, Valid: 85.00% Test: 88.24%\n",
      "Run: 07, Epoch: 141, Loss: 0.3838, Train: 97.50%, Valid: 87.50% Test: 92.16%\n",
      "Run: 07, Epoch: 142, Loss: 0.3656, Train: 98.33%, Valid: 87.50% Test: 90.20%\n",
      "Run: 07, Epoch: 143, Loss: 0.3600, Train: 98.33%, Valid: 87.50% Test: 90.20%\n",
      "Run: 07, Epoch: 144, Loss: 0.3357, Train: 97.50%, Valid: 87.50% Test: 92.16%\n",
      "Run: 07, Epoch: 145, Loss: 0.3662, Train: 97.50%, Valid: 87.50% Test: 90.20%\n",
      "Run: 07, Epoch: 146, Loss: 0.4273, Train: 95.00%, Valid: 88.75% Test: 92.16%\n",
      "Run: 07, Epoch: 147, Loss: 0.3850, Train: 94.17%, Valid: 88.75% Test: 92.16%\n",
      "Run: 07, Epoch: 148, Loss: 0.3322, Train: 94.17%, Valid: 85.00% Test: 92.16%\n",
      "Run: 07, Epoch: 149, Loss: 0.3283, Train: 95.83%, Valid: 85.00% Test: 92.16%\n",
      "Run: 07, Epoch: 150, Loss: 0.3979, Train: 96.67%, Valid: 86.25% Test: 92.16%\n",
      "Run: 07, Epoch: 151, Loss: 0.3384, Train: 97.50%, Valid: 87.50% Test: 88.24%\n",
      "Run: 07, Epoch: 152, Loss: 0.3489, Train: 97.50%, Valid: 87.50% Test: 88.24%\n",
      "Run: 07, Epoch: 153, Loss: 0.2993, Train: 98.33%, Valid: 86.25% Test: 88.24%\n",
      "Run: 07, Epoch: 154, Loss: 0.3405, Train: 98.33%, Valid: 86.25% Test: 90.20%\n",
      "Run: 07, Epoch: 155, Loss: 0.3563, Train: 96.67%, Valid: 86.25% Test: 88.24%\n",
      "Run: 07, Epoch: 156, Loss: 0.3268, Train: 97.50%, Valid: 85.00% Test: 90.20%\n",
      "Run: 07, Epoch: 157, Loss: 0.3625, Train: 95.83%, Valid: 86.25% Test: 92.16%\n",
      "Run: 07, Epoch: 158, Loss: 0.2867, Train: 94.17%, Valid: 86.25% Test: 90.20%\n",
      "Run: 07, Epoch: 159, Loss: 0.3592, Train: 93.33%, Valid: 85.00% Test: 90.20%\n",
      "Run: 07, Epoch: 160, Loss: 0.3732, Train: 94.17%, Valid: 85.00% Test: 92.16%\n",
      "Run: 07, Epoch: 161, Loss: 0.3581, Train: 98.33%, Valid: 87.50% Test: 90.20%\n",
      "Run: 07, Epoch: 162, Loss: 0.3539, Train: 99.17%, Valid: 87.50% Test: 94.12%\n",
      "Run: 07, Epoch: 163, Loss: 0.2922, Train: 97.50%, Valid: 86.25% Test: 88.24%\n",
      "Run: 07, Epoch: 164, Loss: 0.3873, Train: 96.67%, Valid: 86.25% Test: 88.24%\n",
      "Run: 07, Epoch: 165, Loss: 0.3295, Train: 97.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 07, Epoch: 166, Loss: 0.3280, Train: 96.67%, Valid: 88.75% Test: 86.27%\n",
      "Run: 07, Epoch: 167, Loss: 0.3336, Train: 95.83%, Valid: 87.50% Test: 86.27%\n",
      "Run: 07, Epoch: 168, Loss: 0.3615, Train: 96.67%, Valid: 83.75% Test: 88.24%\n",
      "Run: 07, Epoch: 169, Loss: 0.3433, Train: 95.83%, Valid: 83.75% Test: 86.27%\n",
      "Run: 07, Epoch: 170, Loss: 0.3083, Train: 95.00%, Valid: 85.00% Test: 88.24%\n",
      "Run: 07, Epoch: 171, Loss: 0.3327, Train: 95.83%, Valid: 82.50% Test: 90.20%\n",
      "Run: 07, Epoch: 172, Loss: 0.3347, Train: 95.83%, Valid: 82.50% Test: 90.20%\n",
      "Run: 07, Epoch: 173, Loss: 0.3325, Train: 95.83%, Valid: 83.75% Test: 92.16%\n",
      "Run: 07, Epoch: 174, Loss: 0.3704, Train: 95.83%, Valid: 83.75% Test: 90.20%\n",
      "Run: 07, Epoch: 175, Loss: 0.3498, Train: 97.50%, Valid: 82.50% Test: 90.20%\n",
      "Run: 07, Epoch: 176, Loss: 0.2776, Train: 98.33%, Valid: 82.50% Test: 88.24%\n",
      "Run: 07, Epoch: 177, Loss: 0.3442, Train: 97.50%, Valid: 83.75% Test: 86.27%\n",
      "Run: 07, Epoch: 178, Loss: 0.4555, Train: 98.33%, Valid: 86.25% Test: 88.24%\n",
      "Run: 07, Epoch: 179, Loss: 0.3280, Train: 97.50%, Valid: 87.50% Test: 88.24%\n",
      "Run: 07, Epoch: 180, Loss: 0.3078, Train: 95.00%, Valid: 82.50% Test: 90.20%\n",
      "Run: 07, Epoch: 181, Loss: 0.3200, Train: 92.50%, Valid: 78.75% Test: 84.31%\n",
      "Run: 07, Epoch: 182, Loss: 0.3488, Train: 93.33%, Valid: 82.50% Test: 88.24%\n",
      "Run: 07, Epoch: 183, Loss: 0.3423, Train: 95.83%, Valid: 83.75% Test: 90.20%\n",
      "Run: 07, Epoch: 184, Loss: 0.2898, Train: 97.50%, Valid: 83.75% Test: 92.16%\n",
      "Run: 07, Epoch: 185, Loss: 0.3056, Train: 97.50%, Valid: 86.25% Test: 92.16%\n",
      "Run: 07, Epoch: 186, Loss: 0.3559, Train: 99.17%, Valid: 87.50% Test: 92.16%\n",
      "Run: 07, Epoch: 187, Loss: 0.2819, Train: 99.17%, Valid: 87.50% Test: 92.16%\n",
      "Run: 07, Epoch: 188, Loss: 0.2604, Train: 99.17%, Valid: 87.50% Test: 92.16%\n",
      "Run: 07, Epoch: 189, Loss: 0.2742, Train: 99.17%, Valid: 87.50% Test: 92.16%\n",
      "Run: 07, Epoch: 190, Loss: 0.3207, Train: 99.17%, Valid: 90.00% Test: 96.08%\n",
      "Run: 07, Epoch: 191, Loss: 0.2845, Train: 98.33%, Valid: 88.75% Test: 94.12%\n",
      "Run: 07, Epoch: 192, Loss: 0.2794, Train: 97.50%, Valid: 87.50% Test: 94.12%\n",
      "Run: 07, Epoch: 193, Loss: 0.3164, Train: 96.67%, Valid: 87.50% Test: 94.12%\n",
      "Run: 07, Epoch: 194, Loss: 0.3254, Train: 96.67%, Valid: 87.50% Test: 92.16%\n",
      "Run: 07, Epoch: 195, Loss: 0.3027, Train: 97.50%, Valid: 87.50% Test: 92.16%\n",
      "Run: 07, Epoch: 196, Loss: 0.3066, Train: 98.33%, Valid: 87.50% Test: 92.16%\n",
      "Run: 07, Epoch: 197, Loss: 0.2800, Train: 97.50%, Valid: 87.50% Test: 90.20%\n",
      "Run: 07, Epoch: 198, Loss: 0.2975, Train: 96.67%, Valid: 87.50% Test: 92.16%\n",
      "Run: 07, Epoch: 199, Loss: 0.3191, Train: 96.67%, Valid: 88.75% Test: 90.20%\n",
      "Run: 07, Epoch: 200, Loss: 0.3144, Train: 98.33%, Valid: 90.00% Test: 88.24%\n",
      "Run 07:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 90.00\n",
      "  Final Train: 99.17\n",
      "   Final Test: 96.08\n",
      "Run: 08, Epoch: 01, Loss: 1.5486, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 02, Loss: 1.5114, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 03, Loss: 1.4443, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 04, Loss: 1.4177, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 05, Loss: 1.3615, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 06, Loss: 1.3244, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 07, Loss: 1.2969, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 08, Loss: 1.2340, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 09, Loss: 1.2117, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 10, Loss: 1.1707, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 11, Loss: 1.1755, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 12, Loss: 1.1232, Train: 45.00%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 13, Loss: 1.1220, Train: 45.00%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 14, Loss: 1.0667, Train: 46.67%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 15, Loss: 1.0439, Train: 47.50%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 16, Loss: 1.0119, Train: 49.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 17, Loss: 0.9953, Train: 52.50%, Valid: 51.25% Test: 50.98%\n",
      "Run: 08, Epoch: 18, Loss: 0.9604, Train: 54.17%, Valid: 51.25% Test: 52.94%\n",
      "Run: 08, Epoch: 19, Loss: 0.9855, Train: 55.83%, Valid: 52.50% Test: 54.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 20, Loss: 0.9866, Train: 57.50%, Valid: 53.75% Test: 54.90%\n",
      "Run: 08, Epoch: 21, Loss: 0.9001, Train: 58.33%, Valid: 56.25% Test: 54.90%\n",
      "Run: 08, Epoch: 22, Loss: 0.9297, Train: 58.33%, Valid: 57.50% Test: 54.90%\n",
      "Run: 08, Epoch: 23, Loss: 0.9390, Train: 59.17%, Valid: 60.00% Test: 54.90%\n",
      "Run: 08, Epoch: 24, Loss: 0.8843, Train: 60.00%, Valid: 61.25% Test: 56.86%\n",
      "Run: 08, Epoch: 25, Loss: 0.8999, Train: 65.83%, Valid: 62.50% Test: 58.82%\n",
      "Run: 08, Epoch: 26, Loss: 0.8837, Train: 67.50%, Valid: 66.25% Test: 62.75%\n",
      "Run: 08, Epoch: 27, Loss: 0.8688, Train: 67.50%, Valid: 67.50% Test: 64.71%\n",
      "Run: 08, Epoch: 28, Loss: 0.8630, Train: 67.50%, Valid: 67.50% Test: 64.71%\n",
      "Run: 08, Epoch: 29, Loss: 0.8611, Train: 69.17%, Valid: 66.25% Test: 66.67%\n",
      "Run: 08, Epoch: 30, Loss: 0.8127, Train: 69.17%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 31, Loss: 0.8402, Train: 69.17%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 32, Loss: 0.8052, Train: 70.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 33, Loss: 0.8281, Train: 70.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 08, Epoch: 34, Loss: 0.8030, Train: 69.17%, Valid: 67.50% Test: 66.67%\n",
      "Run: 08, Epoch: 35, Loss: 0.7754, Train: 70.83%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 36, Loss: 0.7869, Train: 72.50%, Valid: 70.00% Test: 66.67%\n",
      "Run: 08, Epoch: 37, Loss: 0.7787, Train: 72.50%, Valid: 72.50% Test: 68.63%\n",
      "Run: 08, Epoch: 38, Loss: 0.7202, Train: 73.33%, Valid: 72.50% Test: 70.59%\n",
      "Run: 08, Epoch: 39, Loss: 0.7753, Train: 74.17%, Valid: 72.50% Test: 72.55%\n",
      "Run: 08, Epoch: 40, Loss: 0.7844, Train: 75.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 08, Epoch: 41, Loss: 0.7274, Train: 75.83%, Valid: 72.50% Test: 70.59%\n",
      "Run: 08, Epoch: 42, Loss: 0.7389, Train: 75.83%, Valid: 71.25% Test: 70.59%\n",
      "Run: 08, Epoch: 43, Loss: 0.7634, Train: 76.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 08, Epoch: 44, Loss: 0.7115, Train: 75.83%, Valid: 71.25% Test: 70.59%\n",
      "Run: 08, Epoch: 45, Loss: 0.7242, Train: 78.33%, Valid: 75.00% Test: 70.59%\n",
      "Run: 08, Epoch: 46, Loss: 0.7065, Train: 80.83%, Valid: 78.75% Test: 70.59%\n",
      "Run: 08, Epoch: 47, Loss: 0.7261, Train: 80.83%, Valid: 83.75% Test: 70.59%\n",
      "Run: 08, Epoch: 48, Loss: 0.7327, Train: 80.83%, Valid: 85.00% Test: 76.47%\n",
      "Run: 08, Epoch: 49, Loss: 0.6839, Train: 82.50%, Valid: 85.00% Test: 76.47%\n",
      "Run: 08, Epoch: 50, Loss: 0.7049, Train: 85.00%, Valid: 85.00% Test: 76.47%\n",
      "Run: 08, Epoch: 51, Loss: 0.6745, Train: 85.83%, Valid: 85.00% Test: 76.47%\n",
      "Run: 08, Epoch: 52, Loss: 0.6881, Train: 85.00%, Valid: 85.00% Test: 76.47%\n",
      "Run: 08, Epoch: 53, Loss: 0.6559, Train: 84.17%, Valid: 85.00% Test: 76.47%\n",
      "Run: 08, Epoch: 54, Loss: 0.6777, Train: 84.17%, Valid: 85.00% Test: 78.43%\n",
      "Run: 08, Epoch: 55, Loss: 0.7407, Train: 85.83%, Valid: 86.25% Test: 80.39%\n",
      "Run: 08, Epoch: 56, Loss: 0.6786, Train: 86.67%, Valid: 86.25% Test: 82.35%\n",
      "Run: 08, Epoch: 57, Loss: 0.6712, Train: 85.83%, Valid: 86.25% Test: 82.35%\n",
      "Run: 08, Epoch: 58, Loss: 0.6491, Train: 85.00%, Valid: 86.25% Test: 80.39%\n",
      "Run: 08, Epoch: 59, Loss: 0.6960, Train: 84.17%, Valid: 82.50% Test: 78.43%\n",
      "Run: 08, Epoch: 60, Loss: 0.6705, Train: 83.33%, Valid: 80.00% Test: 76.47%\n",
      "Run: 08, Epoch: 61, Loss: 0.6449, Train: 83.33%, Valid: 80.00% Test: 70.59%\n",
      "Run: 08, Epoch: 62, Loss: 0.5984, Train: 83.33%, Valid: 80.00% Test: 74.51%\n",
      "Run: 08, Epoch: 63, Loss: 0.6320, Train: 85.00%, Valid: 83.75% Test: 74.51%\n",
      "Run: 08, Epoch: 64, Loss: 0.6118, Train: 88.33%, Valid: 86.25% Test: 78.43%\n",
      "Run: 08, Epoch: 65, Loss: 0.6281, Train: 89.17%, Valid: 87.50% Test: 78.43%\n",
      "Run: 08, Epoch: 66, Loss: 0.6093, Train: 89.17%, Valid: 83.75% Test: 78.43%\n",
      "Run: 08, Epoch: 67, Loss: 0.5656, Train: 86.67%, Valid: 83.75% Test: 74.51%\n",
      "Run: 08, Epoch: 68, Loss: 0.6023, Train: 84.17%, Valid: 83.75% Test: 72.55%\n",
      "Run: 08, Epoch: 69, Loss: 0.6459, Train: 83.33%, Valid: 83.75% Test: 72.55%\n",
      "Run: 08, Epoch: 70, Loss: 0.6106, Train: 83.33%, Valid: 85.00% Test: 72.55%\n",
      "Run: 08, Epoch: 71, Loss: 0.5860, Train: 83.33%, Valid: 85.00% Test: 74.51%\n",
      "Run: 08, Epoch: 72, Loss: 0.6084, Train: 86.67%, Valid: 87.50% Test: 76.47%\n",
      "Run: 08, Epoch: 73, Loss: 0.5844, Train: 89.17%, Valid: 87.50% Test: 82.35%\n",
      "Run: 08, Epoch: 74, Loss: 0.6272, Train: 90.00%, Valid: 90.00% Test: 82.35%\n",
      "Run: 08, Epoch: 75, Loss: 0.5606, Train: 90.83%, Valid: 91.25% Test: 80.39%\n",
      "Run: 08, Epoch: 76, Loss: 0.6022, Train: 88.33%, Valid: 92.50% Test: 76.47%\n",
      "Run: 08, Epoch: 77, Loss: 0.5787, Train: 88.33%, Valid: 92.50% Test: 76.47%\n",
      "Run: 08, Epoch: 78, Loss: 0.5702, Train: 88.33%, Valid: 91.25% Test: 76.47%\n",
      "Run: 08, Epoch: 79, Loss: 0.5917, Train: 90.00%, Valid: 91.25% Test: 76.47%\n",
      "Run: 08, Epoch: 80, Loss: 0.5578, Train: 92.50%, Valid: 91.25% Test: 80.39%\n",
      "Run: 08, Epoch: 81, Loss: 0.4878, Train: 90.83%, Valid: 87.50% Test: 82.35%\n",
      "Run: 08, Epoch: 82, Loss: 0.5285, Train: 88.33%, Valid: 88.75% Test: 78.43%\n",
      "Run: 08, Epoch: 83, Loss: 0.5456, Train: 85.00%, Valid: 88.75% Test: 76.47%\n",
      "Run: 08, Epoch: 84, Loss: 0.5123, Train: 84.17%, Valid: 87.50% Test: 76.47%\n",
      "Run: 08, Epoch: 85, Loss: 0.5183, Train: 84.17%, Valid: 88.75% Test: 74.51%\n",
      "Run: 08, Epoch: 86, Loss: 0.5399, Train: 83.33%, Valid: 88.75% Test: 76.47%\n",
      "Run: 08, Epoch: 87, Loss: 0.4967, Train: 89.17%, Valid: 88.75% Test: 78.43%\n",
      "Run: 08, Epoch: 88, Loss: 0.5474, Train: 93.33%, Valid: 88.75% Test: 78.43%\n",
      "Run: 08, Epoch: 89, Loss: 0.5278, Train: 94.17%, Valid: 90.00% Test: 80.39%\n",
      "Run: 08, Epoch: 90, Loss: 0.5260, Train: 94.17%, Valid: 88.75% Test: 78.43%\n",
      "Run: 08, Epoch: 91, Loss: 0.5437, Train: 95.83%, Valid: 86.25% Test: 78.43%\n",
      "Run: 08, Epoch: 92, Loss: 0.4965, Train: 93.33%, Valid: 85.00% Test: 84.31%\n",
      "Run: 08, Epoch: 93, Loss: 0.4739, Train: 89.17%, Valid: 86.25% Test: 84.31%\n",
      "Run: 08, Epoch: 94, Loss: 0.4528, Train: 88.33%, Valid: 86.25% Test: 84.31%\n",
      "Run: 08, Epoch: 95, Loss: 0.5241, Train: 90.00%, Valid: 86.25% Test: 82.35%\n",
      "Run: 08, Epoch: 96, Loss: 0.5014, Train: 90.00%, Valid: 87.50% Test: 82.35%\n",
      "Run: 08, Epoch: 97, Loss: 0.4964, Train: 89.17%, Valid: 90.00% Test: 84.31%\n",
      "Run: 08, Epoch: 98, Loss: 0.5389, Train: 90.83%, Valid: 91.25% Test: 84.31%\n",
      "Run: 08, Epoch: 99, Loss: 0.5167, Train: 90.83%, Valid: 90.00% Test: 84.31%\n",
      "Run: 08, Epoch: 100, Loss: 0.5088, Train: 92.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 08, Epoch: 101, Loss: 0.5430, Train: 90.00%, Valid: 88.75% Test: 80.39%\n",
      "Run: 08, Epoch: 102, Loss: 0.4775, Train: 90.00%, Valid: 88.75% Test: 76.47%\n",
      "Run: 08, Epoch: 103, Loss: 0.5290, Train: 90.00%, Valid: 85.00% Test: 76.47%\n",
      "Run: 08, Epoch: 104, Loss: 0.5034, Train: 90.83%, Valid: 87.50% Test: 76.47%\n",
      "Run: 08, Epoch: 105, Loss: 0.4863, Train: 92.50%, Valid: 87.50% Test: 78.43%\n",
      "Run: 08, Epoch: 106, Loss: 0.5199, Train: 92.50%, Valid: 88.75% Test: 84.31%\n",
      "Run: 08, Epoch: 107, Loss: 0.4559, Train: 88.33%, Valid: 88.75% Test: 82.35%\n",
      "Run: 08, Epoch: 108, Loss: 0.4512, Train: 85.83%, Valid: 88.75% Test: 82.35%\n",
      "Run: 08, Epoch: 109, Loss: 0.4506, Train: 88.33%, Valid: 90.00% Test: 84.31%\n",
      "Run: 08, Epoch: 110, Loss: 0.4608, Train: 93.33%, Valid: 90.00% Test: 84.31%\n",
      "Run: 08, Epoch: 111, Loss: 0.4553, Train: 95.00%, Valid: 91.25% Test: 84.31%\n",
      "Run: 08, Epoch: 112, Loss: 0.4605, Train: 94.17%, Valid: 92.50% Test: 82.35%\n",
      "Run: 08, Epoch: 113, Loss: 0.4636, Train: 93.33%, Valid: 91.25% Test: 78.43%\n",
      "Run: 08, Epoch: 114, Loss: 0.4579, Train: 93.33%, Valid: 90.00% Test: 78.43%\n",
      "Run: 08, Epoch: 115, Loss: 0.4634, Train: 92.50%, Valid: 90.00% Test: 78.43%\n",
      "Run: 08, Epoch: 116, Loss: 0.4834, Train: 93.33%, Valid: 90.00% Test: 80.39%\n",
      "Run: 08, Epoch: 117, Loss: 0.4014, Train: 93.33%, Valid: 90.00% Test: 82.35%\n",
      "Run: 08, Epoch: 118, Loss: 0.5295, Train: 91.67%, Valid: 90.00% Test: 84.31%\n",
      "Run: 08, Epoch: 119, Loss: 0.4309, Train: 90.83%, Valid: 90.00% Test: 82.35%\n",
      "Run: 08, Epoch: 120, Loss: 0.4235, Train: 90.83%, Valid: 90.00% Test: 84.31%\n",
      "Run: 08, Epoch: 121, Loss: 0.4857, Train: 93.33%, Valid: 91.25% Test: 86.27%\n",
      "Run: 08, Epoch: 122, Loss: 0.5141, Train: 93.33%, Valid: 91.25% Test: 84.31%\n",
      "Run: 08, Epoch: 123, Loss: 0.4612, Train: 95.00%, Valid: 93.75% Test: 84.31%\n",
      "Run: 08, Epoch: 124, Loss: 0.4411, Train: 94.17%, Valid: 93.75% Test: 82.35%\n",
      "Run: 08, Epoch: 125, Loss: 0.4647, Train: 95.00%, Valid: 92.50% Test: 84.31%\n",
      "Run: 08, Epoch: 126, Loss: 0.4267, Train: 94.17%, Valid: 91.25% Test: 84.31%\n",
      "Run: 08, Epoch: 127, Loss: 0.4143, Train: 93.33%, Valid: 88.75% Test: 80.39%\n",
      "Run: 08, Epoch: 128, Loss: 0.4032, Train: 93.33%, Valid: 86.25% Test: 80.39%\n",
      "Run: 08, Epoch: 129, Loss: 0.3383, Train: 94.17%, Valid: 85.00% Test: 78.43%\n",
      "Run: 08, Epoch: 130, Loss: 0.4390, Train: 94.17%, Valid: 82.50% Test: 78.43%\n",
      "Run: 08, Epoch: 131, Loss: 0.4387, Train: 91.67%, Valid: 83.75% Test: 80.39%\n",
      "Run: 08, Epoch: 132, Loss: 0.4500, Train: 91.67%, Valid: 85.00% Test: 82.35%\n",
      "Run: 08, Epoch: 133, Loss: 0.3740, Train: 90.83%, Valid: 86.25% Test: 82.35%\n",
      "Run: 08, Epoch: 134, Loss: 0.4048, Train: 92.50%, Valid: 88.75% Test: 82.35%\n",
      "Run: 08, Epoch: 135, Loss: 0.3750, Train: 94.17%, Valid: 90.00% Test: 84.31%\n",
      "Run: 08, Epoch: 136, Loss: 0.4064, Train: 95.83%, Valid: 92.50% Test: 86.27%\n",
      "Run: 08, Epoch: 137, Loss: 0.4381, Train: 94.17%, Valid: 91.25% Test: 80.39%\n",
      "Run: 08, Epoch: 138, Loss: 0.3887, Train: 94.17%, Valid: 87.50% Test: 78.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 139, Loss: 0.3683, Train: 92.50%, Valid: 88.75% Test: 76.47%\n",
      "Run: 08, Epoch: 140, Loss: 0.3688, Train: 93.33%, Valid: 92.50% Test: 78.43%\n",
      "Run: 08, Epoch: 141, Loss: 0.4011, Train: 95.83%, Valid: 92.50% Test: 82.35%\n",
      "Run: 08, Epoch: 142, Loss: 0.3853, Train: 94.17%, Valid: 91.25% Test: 82.35%\n",
      "Run: 08, Epoch: 143, Loss: 0.3767, Train: 94.17%, Valid: 88.75% Test: 80.39%\n",
      "Run: 08, Epoch: 144, Loss: 0.4249, Train: 93.33%, Valid: 87.50% Test: 82.35%\n",
      "Run: 08, Epoch: 145, Loss: 0.4544, Train: 91.67%, Valid: 87.50% Test: 82.35%\n",
      "Run: 08, Epoch: 146, Loss: 0.3798, Train: 93.33%, Valid: 87.50% Test: 82.35%\n",
      "Run: 08, Epoch: 147, Loss: 0.3872, Train: 94.17%, Valid: 90.00% Test: 82.35%\n",
      "Run: 08, Epoch: 148, Loss: 0.4128, Train: 95.83%, Valid: 92.50% Test: 82.35%\n",
      "Run: 08, Epoch: 149, Loss: 0.3281, Train: 93.33%, Valid: 91.25% Test: 78.43%\n",
      "Run: 08, Epoch: 150, Loss: 0.3532, Train: 92.50%, Valid: 90.00% Test: 74.51%\n",
      "Run: 08, Epoch: 151, Loss: 0.4023, Train: 94.17%, Valid: 90.00% Test: 76.47%\n",
      "Run: 08, Epoch: 152, Loss: 0.3276, Train: 93.33%, Valid: 91.25% Test: 76.47%\n",
      "Run: 08, Epoch: 153, Loss: 0.2965, Train: 93.33%, Valid: 88.75% Test: 78.43%\n",
      "Run: 08, Epoch: 154, Loss: 0.4174, Train: 93.33%, Valid: 87.50% Test: 76.47%\n",
      "Run: 08, Epoch: 155, Loss: 0.3267, Train: 90.00%, Valid: 88.75% Test: 76.47%\n",
      "Run: 08, Epoch: 156, Loss: 0.3538, Train: 90.00%, Valid: 90.00% Test: 80.39%\n",
      "Run: 08, Epoch: 157, Loss: 0.4082, Train: 95.00%, Valid: 91.25% Test: 80.39%\n",
      "Run: 08, Epoch: 158, Loss: 0.4218, Train: 96.67%, Valid: 91.25% Test: 84.31%\n",
      "Run: 08, Epoch: 159, Loss: 0.3432, Train: 95.83%, Valid: 91.25% Test: 84.31%\n",
      "Run: 08, Epoch: 160, Loss: 0.3889, Train: 95.00%, Valid: 91.25% Test: 80.39%\n",
      "Run: 08, Epoch: 161, Loss: 0.4209, Train: 95.83%, Valid: 92.50% Test: 80.39%\n",
      "Run: 08, Epoch: 162, Loss: 0.3778, Train: 95.00%, Valid: 92.50% Test: 82.35%\n",
      "Run: 08, Epoch: 163, Loss: 0.3075, Train: 95.83%, Valid: 93.75% Test: 82.35%\n",
      "Run: 08, Epoch: 164, Loss: 0.3762, Train: 95.83%, Valid: 92.50% Test: 82.35%\n",
      "Run: 08, Epoch: 165, Loss: 0.3504, Train: 95.00%, Valid: 92.50% Test: 82.35%\n",
      "Run: 08, Epoch: 166, Loss: 0.3580, Train: 95.83%, Valid: 92.50% Test: 82.35%\n",
      "Run: 08, Epoch: 167, Loss: 0.3138, Train: 96.67%, Valid: 92.50% Test: 84.31%\n",
      "Run: 08, Epoch: 168, Loss: 0.3184, Train: 96.67%, Valid: 92.50% Test: 88.24%\n",
      "Run: 08, Epoch: 169, Loss: 0.3212, Train: 95.83%, Valid: 88.75% Test: 86.27%\n",
      "Run: 08, Epoch: 170, Loss: 0.3872, Train: 95.00%, Valid: 90.00% Test: 86.27%\n",
      "Run: 08, Epoch: 171, Loss: 0.3767, Train: 91.67%, Valid: 90.00% Test: 82.35%\n",
      "Run: 08, Epoch: 172, Loss: 0.3800, Train: 92.50%, Valid: 88.75% Test: 82.35%\n",
      "Run: 08, Epoch: 173, Loss: 0.3894, Train: 95.00%, Valid: 86.25% Test: 80.39%\n",
      "Run: 08, Epoch: 174, Loss: 0.3705, Train: 95.00%, Valid: 86.25% Test: 78.43%\n",
      "Run: 08, Epoch: 175, Loss: 0.3087, Train: 95.83%, Valid: 87.50% Test: 80.39%\n",
      "Run: 08, Epoch: 176, Loss: 0.3461, Train: 95.83%, Valid: 91.25% Test: 84.31%\n",
      "Run: 08, Epoch: 177, Loss: 0.3300, Train: 95.83%, Valid: 91.25% Test: 78.43%\n",
      "Run: 08, Epoch: 178, Loss: 0.4003, Train: 95.00%, Valid: 91.25% Test: 80.39%\n",
      "Run: 08, Epoch: 179, Loss: 0.3760, Train: 95.00%, Valid: 90.00% Test: 86.27%\n",
      "Run: 08, Epoch: 180, Loss: 0.3400, Train: 94.17%, Valid: 88.75% Test: 82.35%\n",
      "Run: 08, Epoch: 181, Loss: 0.3398, Train: 94.17%, Valid: 90.00% Test: 82.35%\n",
      "Run: 08, Epoch: 182, Loss: 0.3723, Train: 95.83%, Valid: 91.25% Test: 82.35%\n",
      "Run: 08, Epoch: 183, Loss: 0.3594, Train: 95.83%, Valid: 91.25% Test: 82.35%\n",
      "Run: 08, Epoch: 184, Loss: 0.3414, Train: 95.83%, Valid: 91.25% Test: 86.27%\n",
      "Run: 08, Epoch: 185, Loss: 0.3417, Train: 94.17%, Valid: 90.00% Test: 80.39%\n",
      "Run: 08, Epoch: 186, Loss: 0.2873, Train: 89.17%, Valid: 90.00% Test: 70.59%\n",
      "Run: 08, Epoch: 187, Loss: 0.3139, Train: 84.17%, Valid: 82.50% Test: 64.71%\n",
      "Run: 08, Epoch: 188, Loss: 0.3418, Train: 74.17%, Valid: 76.25% Test: 62.75%\n",
      "Run: 08, Epoch: 189, Loss: 0.3141, Train: 73.33%, Valid: 75.00% Test: 62.75%\n",
      "Run: 08, Epoch: 190, Loss: 0.3135, Train: 76.67%, Valid: 80.00% Test: 64.71%\n",
      "Run: 08, Epoch: 191, Loss: 0.2838, Train: 81.67%, Valid: 83.75% Test: 70.59%\n",
      "Run: 08, Epoch: 192, Loss: 0.3745, Train: 81.67%, Valid: 82.50% Test: 70.59%\n",
      "Run: 08, Epoch: 193, Loss: 0.3193, Train: 80.00%, Valid: 82.50% Test: 68.63%\n",
      "Run: 08, Epoch: 194, Loss: 0.3135, Train: 78.33%, Valid: 76.25% Test: 62.75%\n",
      "Run: 08, Epoch: 195, Loss: 0.2771, Train: 75.00%, Valid: 72.50% Test: 58.82%\n",
      "Run: 08, Epoch: 196, Loss: 0.3149, Train: 75.83%, Valid: 76.25% Test: 62.75%\n",
      "Run: 08, Epoch: 197, Loss: 0.4044, Train: 86.67%, Valid: 88.75% Test: 72.55%\n",
      "Run: 08, Epoch: 198, Loss: 0.3319, Train: 92.50%, Valid: 88.75% Test: 76.47%\n",
      "Run: 08, Epoch: 199, Loss: 0.3263, Train: 94.17%, Valid: 90.00% Test: 80.39%\n",
      "Run: 08, Epoch: 200, Loss: 0.3411, Train: 96.67%, Valid: 91.25% Test: 82.35%\n",
      "Run 08:\n",
      "Highest Train: 96.67\n",
      "Highest Valid: 93.75\n",
      "  Final Train: 95.00\n",
      "   Final Test: 84.31\n",
      "Run: 09, Epoch: 01, Loss: 1.6956, Train: 9.17%, Valid: 7.50% Test: 7.84%\n",
      "Run: 09, Epoch: 02, Loss: 1.6201, Train: 9.17%, Valid: 7.50% Test: 7.84%\n",
      "Run: 09, Epoch: 03, Loss: 1.5481, Train: 9.17%, Valid: 7.50% Test: 7.84%\n",
      "Run: 09, Epoch: 04, Loss: 1.5040, Train: 47.50%, Valid: 40.00% Test: 45.10%\n",
      "Run: 09, Epoch: 05, Loss: 1.4191, Train: 55.00%, Valid: 40.00% Test: 47.06%\n",
      "Run: 09, Epoch: 06, Loss: 1.3896, Train: 55.00%, Valid: 38.75% Test: 47.06%\n",
      "Run: 09, Epoch: 07, Loss: 1.3440, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 08, Loss: 1.3044, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 09, Loss: 1.2716, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 10, Loss: 1.2000, Train: 53.33%, Valid: 38.75% Test: 45.10%\n",
      "Run: 09, Epoch: 11, Loss: 1.1509, Train: 53.33%, Valid: 41.25% Test: 45.10%\n",
      "Run: 09, Epoch: 12, Loss: 1.1124, Train: 53.33%, Valid: 41.25% Test: 45.10%\n",
      "Run: 09, Epoch: 13, Loss: 1.0755, Train: 54.17%, Valid: 41.25% Test: 45.10%\n",
      "Run: 09, Epoch: 14, Loss: 1.0821, Train: 54.17%, Valid: 41.25% Test: 45.10%\n",
      "Run: 09, Epoch: 15, Loss: 1.0604, Train: 54.17%, Valid: 41.25% Test: 47.06%\n",
      "Run: 09, Epoch: 16, Loss: 1.0165, Train: 55.83%, Valid: 42.50% Test: 47.06%\n",
      "Run: 09, Epoch: 17, Loss: 0.9614, Train: 55.00%, Valid: 42.50% Test: 45.10%\n",
      "Run: 09, Epoch: 18, Loss: 0.9736, Train: 55.00%, Valid: 42.50% Test: 45.10%\n",
      "Run: 09, Epoch: 19, Loss: 0.9519, Train: 56.67%, Valid: 42.50% Test: 47.06%\n",
      "Run: 09, Epoch: 20, Loss: 0.9188, Train: 57.50%, Valid: 46.25% Test: 49.02%\n",
      "Run: 09, Epoch: 21, Loss: 0.9135, Train: 59.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 09, Epoch: 22, Loss: 0.9221, Train: 62.50%, Valid: 48.75% Test: 54.90%\n",
      "Run: 09, Epoch: 23, Loss: 0.8725, Train: 62.50%, Valid: 52.50% Test: 58.82%\n",
      "Run: 09, Epoch: 24, Loss: 0.8703, Train: 65.83%, Valid: 58.75% Test: 64.71%\n",
      "Run: 09, Epoch: 25, Loss: 0.8826, Train: 68.33%, Valid: 60.00% Test: 64.71%\n",
      "Run: 09, Epoch: 26, Loss: 0.8250, Train: 69.17%, Valid: 61.25% Test: 64.71%\n",
      "Run: 09, Epoch: 27, Loss: 0.8412, Train: 70.83%, Valid: 61.25% Test: 68.63%\n",
      "Run: 09, Epoch: 28, Loss: 0.8252, Train: 70.00%, Valid: 60.00% Test: 68.63%\n",
      "Run: 09, Epoch: 29, Loss: 0.8088, Train: 70.00%, Valid: 61.25% Test: 66.67%\n",
      "Run: 09, Epoch: 30, Loss: 0.8138, Train: 69.17%, Valid: 61.25% Test: 66.67%\n",
      "Run: 09, Epoch: 31, Loss: 0.7896, Train: 69.17%, Valid: 61.25% Test: 64.71%\n",
      "Run: 09, Epoch: 32, Loss: 0.7773, Train: 70.83%, Valid: 62.50% Test: 66.67%\n",
      "Run: 09, Epoch: 33, Loss: 0.7582, Train: 72.50%, Valid: 62.50% Test: 70.59%\n",
      "Run: 09, Epoch: 34, Loss: 0.8023, Train: 74.17%, Valid: 72.50% Test: 72.55%\n",
      "Run: 09, Epoch: 35, Loss: 0.7740, Train: 71.67%, Valid: 70.00% Test: 72.55%\n",
      "Run: 09, Epoch: 36, Loss: 0.7585, Train: 71.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 09, Epoch: 37, Loss: 0.7830, Train: 71.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 09, Epoch: 38, Loss: 0.7308, Train: 71.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 09, Epoch: 39, Loss: 0.7732, Train: 72.50%, Valid: 68.75% Test: 72.55%\n",
      "Run: 09, Epoch: 40, Loss: 0.7340, Train: 73.33%, Valid: 68.75% Test: 72.55%\n",
      "Run: 09, Epoch: 41, Loss: 0.7456, Train: 73.33%, Valid: 68.75% Test: 74.51%\n",
      "Run: 09, Epoch: 42, Loss: 0.6935, Train: 71.67%, Valid: 67.50% Test: 74.51%\n",
      "Run: 09, Epoch: 43, Loss: 0.6891, Train: 71.67%, Valid: 65.00% Test: 72.55%\n",
      "Run: 09, Epoch: 44, Loss: 0.7081, Train: 75.83%, Valid: 67.50% Test: 74.51%\n",
      "Run: 09, Epoch: 45, Loss: 0.7064, Train: 76.67%, Valid: 73.75% Test: 74.51%\n",
      "Run: 09, Epoch: 46, Loss: 0.6865, Train: 77.50%, Valid: 72.50% Test: 74.51%\n",
      "Run: 09, Epoch: 47, Loss: 0.6521, Train: 78.33%, Valid: 78.75% Test: 74.51%\n",
      "Run: 09, Epoch: 48, Loss: 0.7126, Train: 80.00%, Valid: 80.00% Test: 76.47%\n",
      "Run: 09, Epoch: 49, Loss: 0.6663, Train: 80.83%, Valid: 83.75% Test: 78.43%\n",
      "Run: 09, Epoch: 50, Loss: 0.6565, Train: 82.50%, Valid: 83.75% Test: 78.43%\n",
      "Run: 09, Epoch: 51, Loss: 0.6512, Train: 81.67%, Valid: 82.50% Test: 80.39%\n",
      "Run: 09, Epoch: 52, Loss: 0.6458, Train: 80.00%, Valid: 81.25% Test: 78.43%\n",
      "Run: 09, Epoch: 53, Loss: 0.6059, Train: 78.33%, Valid: 77.50% Test: 76.47%\n",
      "Run: 09, Epoch: 54, Loss: 0.6175, Train: 77.50%, Valid: 72.50% Test: 76.47%\n",
      "Run: 09, Epoch: 55, Loss: 0.6287, Train: 76.67%, Valid: 71.25% Test: 76.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 56, Loss: 0.6106, Train: 78.33%, Valid: 73.75% Test: 74.51%\n",
      "Run: 09, Epoch: 57, Loss: 0.6399, Train: 78.33%, Valid: 75.00% Test: 74.51%\n",
      "Run: 09, Epoch: 58, Loss: 0.6077, Train: 81.67%, Valid: 76.25% Test: 76.47%\n",
      "Run: 09, Epoch: 59, Loss: 0.6053, Train: 84.17%, Valid: 80.00% Test: 80.39%\n",
      "Run: 09, Epoch: 60, Loss: 0.5949, Train: 86.67%, Valid: 82.50% Test: 80.39%\n",
      "Run: 09, Epoch: 61, Loss: 0.6117, Train: 87.50%, Valid: 85.00% Test: 84.31%\n",
      "Run: 09, Epoch: 62, Loss: 0.5551, Train: 86.67%, Valid: 85.00% Test: 86.27%\n",
      "Run: 09, Epoch: 63, Loss: 0.6242, Train: 85.83%, Valid: 82.50% Test: 86.27%\n",
      "Run: 09, Epoch: 64, Loss: 0.6029, Train: 85.83%, Valid: 80.00% Test: 82.35%\n",
      "Run: 09, Epoch: 65, Loss: 0.5907, Train: 85.83%, Valid: 78.75% Test: 82.35%\n",
      "Run: 09, Epoch: 66, Loss: 0.5995, Train: 83.33%, Valid: 77.50% Test: 82.35%\n",
      "Run: 09, Epoch: 67, Loss: 0.5700, Train: 83.33%, Valid: 77.50% Test: 80.39%\n",
      "Run: 09, Epoch: 68, Loss: 0.5870, Train: 84.17%, Valid: 80.00% Test: 80.39%\n",
      "Run: 09, Epoch: 69, Loss: 0.5683, Train: 85.00%, Valid: 81.25% Test: 80.39%\n",
      "Run: 09, Epoch: 70, Loss: 0.5263, Train: 85.83%, Valid: 82.50% Test: 82.35%\n",
      "Run: 09, Epoch: 71, Loss: 0.5870, Train: 84.17%, Valid: 81.25% Test: 80.39%\n",
      "Run: 09, Epoch: 72, Loss: 0.5719, Train: 83.33%, Valid: 76.25% Test: 76.47%\n",
      "Run: 09, Epoch: 73, Loss: 0.5721, Train: 82.50%, Valid: 77.50% Test: 76.47%\n",
      "Run: 09, Epoch: 74, Loss: 0.5499, Train: 82.50%, Valid: 75.00% Test: 76.47%\n",
      "Run: 09, Epoch: 75, Loss: 0.5307, Train: 80.83%, Valid: 75.00% Test: 76.47%\n",
      "Run: 09, Epoch: 76, Loss: 0.5294, Train: 85.00%, Valid: 78.75% Test: 76.47%\n",
      "Run: 09, Epoch: 77, Loss: 0.5524, Train: 88.33%, Valid: 80.00% Test: 78.43%\n",
      "Run: 09, Epoch: 78, Loss: 0.5483, Train: 88.33%, Valid: 80.00% Test: 78.43%\n",
      "Run: 09, Epoch: 79, Loss: 0.5545, Train: 89.17%, Valid: 80.00% Test: 82.35%\n",
      "Run: 09, Epoch: 80, Loss: 0.4884, Train: 90.00%, Valid: 80.00% Test: 88.24%\n",
      "Run: 09, Epoch: 81, Loss: 0.5520, Train: 88.33%, Valid: 82.50% Test: 90.20%\n",
      "Run: 09, Epoch: 82, Loss: 0.5184, Train: 85.83%, Valid: 81.25% Test: 86.27%\n",
      "Run: 09, Epoch: 83, Loss: 0.5386, Train: 86.67%, Valid: 83.75% Test: 88.24%\n",
      "Run: 09, Epoch: 84, Loss: 0.4888, Train: 88.33%, Valid: 83.75% Test: 88.24%\n",
      "Run: 09, Epoch: 85, Loss: 0.5377, Train: 88.33%, Valid: 85.00% Test: 88.24%\n",
      "Run: 09, Epoch: 86, Loss: 0.5264, Train: 89.17%, Valid: 86.25% Test: 90.20%\n",
      "Run: 09, Epoch: 87, Loss: 0.5360, Train: 90.83%, Valid: 85.00% Test: 90.20%\n",
      "Run: 09, Epoch: 88, Loss: 0.5548, Train: 90.83%, Valid: 83.75% Test: 86.27%\n",
      "Run: 09, Epoch: 89, Loss: 0.4791, Train: 90.00%, Valid: 82.50% Test: 86.27%\n",
      "Run: 09, Epoch: 90, Loss: 0.5273, Train: 90.00%, Valid: 83.75% Test: 84.31%\n",
      "Run: 09, Epoch: 91, Loss: 0.4825, Train: 89.17%, Valid: 82.50% Test: 84.31%\n",
      "Run: 09, Epoch: 92, Loss: 0.5656, Train: 88.33%, Valid: 82.50% Test: 84.31%\n",
      "Run: 09, Epoch: 93, Loss: 0.5014, Train: 90.00%, Valid: 83.75% Test: 84.31%\n",
      "Run: 09, Epoch: 94, Loss: 0.4885, Train: 91.67%, Valid: 83.75% Test: 82.35%\n",
      "Run: 09, Epoch: 95, Loss: 0.4683, Train: 92.50%, Valid: 83.75% Test: 82.35%\n",
      "Run: 09, Epoch: 96, Loss: 0.4677, Train: 92.50%, Valid: 83.75% Test: 82.35%\n",
      "Run: 09, Epoch: 97, Loss: 0.4466, Train: 91.67%, Valid: 83.75% Test: 82.35%\n",
      "Run: 09, Epoch: 98, Loss: 0.4747, Train: 91.67%, Valid: 86.25% Test: 82.35%\n",
      "Run: 09, Epoch: 99, Loss: 0.4559, Train: 89.17%, Valid: 86.25% Test: 82.35%\n",
      "Run: 09, Epoch: 100, Loss: 0.4601, Train: 90.00%, Valid: 86.25% Test: 84.31%\n",
      "Run: 09, Epoch: 101, Loss: 0.4365, Train: 90.00%, Valid: 85.00% Test: 84.31%\n",
      "Run: 09, Epoch: 102, Loss: 0.4078, Train: 87.50%, Valid: 85.00% Test: 84.31%\n",
      "Run: 09, Epoch: 103, Loss: 0.4771, Train: 88.33%, Valid: 86.25% Test: 84.31%\n",
      "Run: 09, Epoch: 104, Loss: 0.4738, Train: 86.67%, Valid: 78.75% Test: 84.31%\n",
      "Run: 09, Epoch: 105, Loss: 0.4414, Train: 85.83%, Valid: 76.25% Test: 82.35%\n",
      "Run: 09, Epoch: 106, Loss: 0.4235, Train: 87.50%, Valid: 76.25% Test: 80.39%\n",
      "Run: 09, Epoch: 107, Loss: 0.4183, Train: 88.33%, Valid: 81.25% Test: 80.39%\n",
      "Run: 09, Epoch: 108, Loss: 0.4548, Train: 94.17%, Valid: 83.75% Test: 82.35%\n",
      "Run: 09, Epoch: 109, Loss: 0.4624, Train: 94.17%, Valid: 85.00% Test: 84.31%\n",
      "Run: 09, Epoch: 110, Loss: 0.4027, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 09, Epoch: 111, Loss: 0.4417, Train: 95.00%, Valid: 86.25% Test: 88.24%\n",
      "Run: 09, Epoch: 112, Loss: 0.4235, Train: 95.00%, Valid: 85.00% Test: 86.27%\n",
      "Run: 09, Epoch: 113, Loss: 0.3940, Train: 95.00%, Valid: 85.00% Test: 86.27%\n",
      "Run: 09, Epoch: 114, Loss: 0.4348, Train: 95.00%, Valid: 85.00% Test: 86.27%\n",
      "Run: 09, Epoch: 115, Loss: 0.4091, Train: 95.00%, Valid: 85.00% Test: 88.24%\n",
      "Run: 09, Epoch: 116, Loss: 0.4314, Train: 95.00%, Valid: 85.00% Test: 88.24%\n",
      "Run: 09, Epoch: 117, Loss: 0.3806, Train: 94.17%, Valid: 83.75% Test: 86.27%\n",
      "Run: 09, Epoch: 118, Loss: 0.4060, Train: 90.83%, Valid: 80.00% Test: 82.35%\n",
      "Run: 09, Epoch: 119, Loss: 0.3738, Train: 88.33%, Valid: 77.50% Test: 82.35%\n",
      "Run: 09, Epoch: 120, Loss: 0.4036, Train: 90.00%, Valid: 78.75% Test: 82.35%\n",
      "Run: 09, Epoch: 121, Loss: 0.4020, Train: 91.67%, Valid: 83.75% Test: 84.31%\n",
      "Run: 09, Epoch: 122, Loss: 0.4455, Train: 90.83%, Valid: 83.75% Test: 86.27%\n",
      "Run: 09, Epoch: 123, Loss: 0.4368, Train: 91.67%, Valid: 87.50% Test: 90.20%\n",
      "Run: 09, Epoch: 124, Loss: 0.4100, Train: 95.00%, Valid: 87.50% Test: 90.20%\n",
      "Run: 09, Epoch: 125, Loss: 0.4107, Train: 95.00%, Valid: 87.50% Test: 90.20%\n",
      "Run: 09, Epoch: 126, Loss: 0.3795, Train: 94.17%, Valid: 82.50% Test: 86.27%\n",
      "Run: 09, Epoch: 127, Loss: 0.4388, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 09, Epoch: 128, Loss: 0.4246, Train: 95.83%, Valid: 85.00% Test: 90.20%\n",
      "Run: 09, Epoch: 129, Loss: 0.4175, Train: 95.00%, Valid: 81.25% Test: 88.24%\n",
      "Run: 09, Epoch: 130, Loss: 0.3848, Train: 93.33%, Valid: 77.50% Test: 82.35%\n",
      "Run: 09, Epoch: 131, Loss: 0.4278, Train: 91.67%, Valid: 78.75% Test: 80.39%\n",
      "Run: 09, Epoch: 132, Loss: 0.4089, Train: 95.00%, Valid: 80.00% Test: 80.39%\n",
      "Run: 09, Epoch: 133, Loss: 0.3746, Train: 95.00%, Valid: 77.50% Test: 82.35%\n",
      "Run: 09, Epoch: 134, Loss: 0.3785, Train: 94.17%, Valid: 81.25% Test: 88.24%\n",
      "Run: 09, Epoch: 135, Loss: 0.3684, Train: 95.83%, Valid: 82.50% Test: 88.24%\n",
      "Run: 09, Epoch: 136, Loss: 0.3491, Train: 96.67%, Valid: 83.75% Test: 90.20%\n",
      "Run: 09, Epoch: 137, Loss: 0.3372, Train: 97.50%, Valid: 83.75% Test: 90.20%\n",
      "Run: 09, Epoch: 138, Loss: 0.4100, Train: 98.33%, Valid: 86.25% Test: 90.20%\n",
      "Run: 09, Epoch: 139, Loss: 0.3923, Train: 95.00%, Valid: 87.50% Test: 88.24%\n",
      "Run: 09, Epoch: 140, Loss: 0.3610, Train: 94.17%, Valid: 87.50% Test: 88.24%\n",
      "Run: 09, Epoch: 141, Loss: 0.3973, Train: 93.33%, Valid: 85.00% Test: 88.24%\n",
      "Run: 09, Epoch: 142, Loss: 0.4106, Train: 92.50%, Valid: 82.50% Test: 88.24%\n",
      "Run: 09, Epoch: 143, Loss: 0.3415, Train: 93.33%, Valid: 83.75% Test: 88.24%\n",
      "Run: 09, Epoch: 144, Loss: 0.3695, Train: 95.00%, Valid: 82.50% Test: 88.24%\n",
      "Run: 09, Epoch: 145, Loss: 0.3885, Train: 92.50%, Valid: 81.25% Test: 86.27%\n",
      "Run: 09, Epoch: 146, Loss: 0.3821, Train: 91.67%, Valid: 83.75% Test: 84.31%\n",
      "Run: 09, Epoch: 147, Loss: 0.3470, Train: 94.17%, Valid: 82.50% Test: 86.27%\n",
      "Run: 09, Epoch: 148, Loss: 0.3324, Train: 94.17%, Valid: 82.50% Test: 86.27%\n",
      "Run: 09, Epoch: 149, Loss: 0.3385, Train: 94.17%, Valid: 86.25% Test: 86.27%\n",
      "Run: 09, Epoch: 150, Loss: 0.3685, Train: 96.67%, Valid: 85.00% Test: 90.20%\n",
      "Run: 09, Epoch: 151, Loss: 0.3593, Train: 99.17%, Valid: 87.50% Test: 90.20%\n",
      "Run: 09, Epoch: 152, Loss: 0.3139, Train: 99.17%, Valid: 88.75% Test: 92.16%\n",
      "Run: 09, Epoch: 153, Loss: 0.3569, Train: 99.17%, Valid: 90.00% Test: 92.16%\n",
      "Run: 09, Epoch: 154, Loss: 0.3073, Train: 96.67%, Valid: 90.00% Test: 92.16%\n",
      "Run: 09, Epoch: 155, Loss: 0.3511, Train: 97.50%, Valid: 90.00% Test: 90.20%\n",
      "Run: 09, Epoch: 156, Loss: 0.3253, Train: 95.83%, Valid: 90.00% Test: 88.24%\n",
      "Run: 09, Epoch: 157, Loss: 0.3127, Train: 95.00%, Valid: 83.75% Test: 88.24%\n",
      "Run: 09, Epoch: 158, Loss: 0.3861, Train: 93.33%, Valid: 82.50% Test: 86.27%\n",
      "Run: 09, Epoch: 159, Loss: 0.3554, Train: 91.67%, Valid: 77.50% Test: 86.27%\n",
      "Run: 09, Epoch: 160, Loss: 0.3747, Train: 92.50%, Valid: 81.25% Test: 88.24%\n",
      "Run: 09, Epoch: 161, Loss: 0.3137, Train: 95.00%, Valid: 85.00% Test: 92.16%\n",
      "Run: 09, Epoch: 162, Loss: 0.3159, Train: 96.67%, Valid: 85.00% Test: 90.20%\n",
      "Run: 09, Epoch: 163, Loss: 0.3258, Train: 96.67%, Valid: 82.50% Test: 88.24%\n",
      "Run: 09, Epoch: 164, Loss: 0.3574, Train: 95.83%, Valid: 81.25% Test: 86.27%\n",
      "Run: 09, Epoch: 165, Loss: 0.3718, Train: 92.50%, Valid: 82.50% Test: 82.35%\n",
      "Run: 09, Epoch: 166, Loss: 0.3373, Train: 92.50%, Valid: 81.25% Test: 84.31%\n",
      "Run: 09, Epoch: 167, Loss: 0.3174, Train: 94.17%, Valid: 80.00% Test: 86.27%\n",
      "Run: 09, Epoch: 168, Loss: 0.3045, Train: 94.17%, Valid: 81.25% Test: 86.27%\n",
      "Run: 09, Epoch: 169, Loss: 0.3397, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 09, Epoch: 170, Loss: 0.3611, Train: 95.83%, Valid: 83.75% Test: 86.27%\n",
      "Run: 09, Epoch: 171, Loss: 0.3515, Train: 97.50%, Valid: 85.00% Test: 88.24%\n",
      "Run: 09, Epoch: 172, Loss: 0.3803, Train: 99.17%, Valid: 87.50% Test: 88.24%\n",
      "Run: 09, Epoch: 173, Loss: 0.2995, Train: 99.17%, Valid: 87.50% Test: 90.20%\n",
      "Run: 09, Epoch: 174, Loss: 0.3031, Train: 97.50%, Valid: 87.50% Test: 90.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 175, Loss: 0.2952, Train: 97.50%, Valid: 88.75% Test: 90.20%\n",
      "Run: 09, Epoch: 176, Loss: 0.3113, Train: 97.50%, Valid: 87.50% Test: 88.24%\n",
      "Run: 09, Epoch: 177, Loss: 0.3130, Train: 95.83%, Valid: 87.50% Test: 88.24%\n",
      "Run: 09, Epoch: 178, Loss: 0.2794, Train: 95.00%, Valid: 88.75% Test: 88.24%\n",
      "Run: 09, Epoch: 179, Loss: 0.2902, Train: 96.67%, Valid: 90.00% Test: 90.20%\n",
      "Run: 09, Epoch: 180, Loss: 0.3380, Train: 97.50%, Valid: 88.75% Test: 92.16%\n",
      "Run: 09, Epoch: 181, Loss: 0.2690, Train: 96.67%, Valid: 88.75% Test: 90.20%\n",
      "Run: 09, Epoch: 182, Loss: 0.3327, Train: 97.50%, Valid: 90.00% Test: 90.20%\n",
      "Run: 09, Epoch: 183, Loss: 0.2911, Train: 95.83%, Valid: 88.75% Test: 90.20%\n",
      "Run: 09, Epoch: 184, Loss: 0.3421, Train: 95.83%, Valid: 87.50% Test: 88.24%\n",
      "Run: 09, Epoch: 185, Loss: 0.3090, Train: 95.83%, Valid: 86.25% Test: 88.24%\n",
      "Run: 09, Epoch: 186, Loss: 0.2569, Train: 96.67%, Valid: 87.50% Test: 88.24%\n",
      "Run: 09, Epoch: 187, Loss: 0.3099, Train: 98.33%, Valid: 88.75% Test: 92.16%\n",
      "Run: 09, Epoch: 188, Loss: 0.3215, Train: 99.17%, Valid: 88.75% Test: 92.16%\n",
      "Run: 09, Epoch: 189, Loss: 0.2932, Train: 100.00%, Valid: 87.50% Test: 90.20%\n",
      "Run: 09, Epoch: 190, Loss: 0.2960, Train: 99.17%, Valid: 87.50% Test: 90.20%\n",
      "Run: 09, Epoch: 191, Loss: 0.2400, Train: 97.50%, Valid: 87.50% Test: 90.20%\n",
      "Run: 09, Epoch: 192, Loss: 0.2588, Train: 95.00%, Valid: 86.25% Test: 90.20%\n",
      "Run: 09, Epoch: 193, Loss: 0.2712, Train: 95.83%, Valid: 83.75% Test: 84.31%\n",
      "Run: 09, Epoch: 194, Loss: 0.3126, Train: 96.67%, Valid: 85.00% Test: 86.27%\n",
      "Run: 09, Epoch: 195, Loss: 0.2842, Train: 96.67%, Valid: 80.00% Test: 86.27%\n",
      "Run: 09, Epoch: 196, Loss: 0.2830, Train: 96.67%, Valid: 81.25% Test: 86.27%\n",
      "Run: 09, Epoch: 197, Loss: 0.2514, Train: 95.83%, Valid: 81.25% Test: 84.31%\n",
      "Run: 09, Epoch: 198, Loss: 0.2420, Train: 94.17%, Valid: 81.25% Test: 84.31%\n",
      "Run: 09, Epoch: 199, Loss: 0.2975, Train: 96.67%, Valid: 77.50% Test: 86.27%\n",
      "Run: 09, Epoch: 200, Loss: 0.2814, Train: 98.33%, Valid: 82.50% Test: 88.24%\n",
      "Run 09:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 90.00\n",
      "  Final Train: 99.17\n",
      "   Final Test: 92.16\n",
      "Run: 10, Epoch: 01, Loss: 1.6812, Train: 42.50%, Valid: 45.00% Test: 37.25%\n",
      "Run: 10, Epoch: 02, Loss: 1.6168, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 03, Loss: 1.5417, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 04, Loss: 1.4792, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 05, Loss: 1.4145, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 06, Loss: 1.3678, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 07, Loss: 1.3094, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 08, Loss: 1.2733, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 09, Loss: 1.2157, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 10, Loss: 1.1809, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 11, Loss: 1.0976, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 12, Loss: 1.0914, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 13, Loss: 1.0366, Train: 50.00%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 14, Loss: 0.9903, Train: 51.67%, Valid: 46.25% Test: 47.06%\n",
      "Run: 10, Epoch: 15, Loss: 0.9965, Train: 63.33%, Valid: 60.00% Test: 52.94%\n",
      "Run: 10, Epoch: 16, Loss: 0.9545, Train: 70.00%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 17, Loss: 0.9460, Train: 72.50%, Valid: 62.50% Test: 66.67%\n",
      "Run: 10, Epoch: 18, Loss: 0.9205, Train: 71.67%, Valid: 63.75% Test: 66.67%\n",
      "Run: 10, Epoch: 19, Loss: 0.9194, Train: 66.67%, Valid: 61.25% Test: 66.67%\n",
      "Run: 10, Epoch: 20, Loss: 0.8968, Train: 63.33%, Valid: 60.00% Test: 58.82%\n",
      "Run: 10, Epoch: 21, Loss: 0.9022, Train: 61.67%, Valid: 58.75% Test: 58.82%\n",
      "Run: 10, Epoch: 22, Loss: 0.8627, Train: 61.67%, Valid: 58.75% Test: 62.75%\n",
      "Run: 10, Epoch: 23, Loss: 0.8791, Train: 64.17%, Valid: 60.00% Test: 62.75%\n",
      "Run: 10, Epoch: 24, Loss: 0.8491, Train: 67.50%, Valid: 63.75% Test: 66.67%\n",
      "Run: 10, Epoch: 25, Loss: 0.8203, Train: 74.17%, Valid: 65.00% Test: 70.59%\n",
      "Run: 10, Epoch: 26, Loss: 0.7953, Train: 77.50%, Valid: 66.25% Test: 70.59%\n",
      "Run: 10, Epoch: 27, Loss: 0.7886, Train: 77.50%, Valid: 65.00% Test: 72.55%\n",
      "Run: 10, Epoch: 28, Loss: 0.7737, Train: 77.50%, Valid: 66.25% Test: 72.55%\n",
      "Run: 10, Epoch: 29, Loss: 0.7708, Train: 77.50%, Valid: 67.50% Test: 70.59%\n",
      "Run: 10, Epoch: 30, Loss: 0.7545, Train: 75.83%, Valid: 67.50% Test: 70.59%\n",
      "Run: 10, Epoch: 31, Loss: 0.7683, Train: 75.83%, Valid: 66.25% Test: 70.59%\n",
      "Run: 10, Epoch: 32, Loss: 0.7774, Train: 75.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 10, Epoch: 33, Loss: 0.7545, Train: 77.50%, Valid: 68.75% Test: 72.55%\n",
      "Run: 10, Epoch: 34, Loss: 0.7626, Train: 78.33%, Valid: 68.75% Test: 74.51%\n",
      "Run: 10, Epoch: 35, Loss: 0.7185, Train: 80.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 10, Epoch: 36, Loss: 0.7290, Train: 80.00%, Valid: 71.25% Test: 74.51%\n",
      "Run: 10, Epoch: 37, Loss: 0.7178, Train: 80.83%, Valid: 72.50% Test: 76.47%\n",
      "Run: 10, Epoch: 38, Loss: 0.7074, Train: 80.83%, Valid: 73.75% Test: 76.47%\n",
      "Run: 10, Epoch: 39, Loss: 0.6837, Train: 80.83%, Valid: 72.50% Test: 74.51%\n",
      "Run: 10, Epoch: 40, Loss: 0.7204, Train: 80.00%, Valid: 70.00% Test: 76.47%\n",
      "Run: 10, Epoch: 41, Loss: 0.7209, Train: 80.00%, Valid: 70.00% Test: 76.47%\n",
      "Run: 10, Epoch: 42, Loss: 0.7105, Train: 79.17%, Valid: 68.75% Test: 76.47%\n",
      "Run: 10, Epoch: 43, Loss: 0.6591, Train: 78.33%, Valid: 70.00% Test: 74.51%\n",
      "Run: 10, Epoch: 44, Loss: 0.6813, Train: 80.00%, Valid: 70.00% Test: 74.51%\n",
      "Run: 10, Epoch: 45, Loss: 0.6663, Train: 80.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 10, Epoch: 46, Loss: 0.6823, Train: 82.50%, Valid: 76.25% Test: 74.51%\n",
      "Run: 10, Epoch: 47, Loss: 0.6890, Train: 82.50%, Valid: 76.25% Test: 74.51%\n",
      "Run: 10, Epoch: 48, Loss: 0.6482, Train: 81.67%, Valid: 75.00% Test: 74.51%\n",
      "Run: 10, Epoch: 49, Loss: 0.6250, Train: 80.83%, Valid: 75.00% Test: 74.51%\n",
      "Run: 10, Epoch: 50, Loss: 0.6335, Train: 77.50%, Valid: 71.25% Test: 72.55%\n",
      "Run: 10, Epoch: 51, Loss: 0.6351, Train: 76.67%, Valid: 67.50% Test: 72.55%\n",
      "Run: 10, Epoch: 52, Loss: 0.6017, Train: 76.67%, Valid: 68.75% Test: 72.55%\n",
      "Run: 10, Epoch: 53, Loss: 0.6405, Train: 77.50%, Valid: 70.00% Test: 74.51%\n",
      "Run: 10, Epoch: 54, Loss: 0.6413, Train: 80.00%, Valid: 70.00% Test: 74.51%\n",
      "Run: 10, Epoch: 55, Loss: 0.6160, Train: 80.83%, Valid: 71.25% Test: 74.51%\n",
      "Run: 10, Epoch: 56, Loss: 0.6673, Train: 82.50%, Valid: 73.75% Test: 74.51%\n",
      "Run: 10, Epoch: 57, Loss: 0.6013, Train: 84.17%, Valid: 75.00% Test: 76.47%\n",
      "Run: 10, Epoch: 58, Loss: 0.6205, Train: 85.00%, Valid: 75.00% Test: 76.47%\n",
      "Run: 10, Epoch: 59, Loss: 0.6245, Train: 86.67%, Valid: 76.25% Test: 78.43%\n",
      "Run: 10, Epoch: 60, Loss: 0.6359, Train: 85.83%, Valid: 76.25% Test: 78.43%\n",
      "Run: 10, Epoch: 61, Loss: 0.5727, Train: 84.17%, Valid: 75.00% Test: 76.47%\n",
      "Run: 10, Epoch: 62, Loss: 0.5770, Train: 81.67%, Valid: 75.00% Test: 76.47%\n",
      "Run: 10, Epoch: 63, Loss: 0.5871, Train: 83.33%, Valid: 76.25% Test: 76.47%\n",
      "Run: 10, Epoch: 64, Loss: 0.5880, Train: 83.33%, Valid: 76.25% Test: 76.47%\n",
      "Run: 10, Epoch: 65, Loss: 0.5833, Train: 83.33%, Valid: 77.50% Test: 76.47%\n",
      "Run: 10, Epoch: 66, Loss: 0.5860, Train: 84.17%, Valid: 77.50% Test: 76.47%\n",
      "Run: 10, Epoch: 67, Loss: 0.5695, Train: 85.00%, Valid: 75.00% Test: 76.47%\n",
      "Run: 10, Epoch: 68, Loss: 0.5557, Train: 85.00%, Valid: 76.25% Test: 74.51%\n",
      "Run: 10, Epoch: 69, Loss: 0.5736, Train: 85.83%, Valid: 77.50% Test: 78.43%\n",
      "Run: 10, Epoch: 70, Loss: 0.5211, Train: 85.83%, Valid: 78.75% Test: 78.43%\n",
      "Run: 10, Epoch: 71, Loss: 0.5630, Train: 85.83%, Valid: 78.75% Test: 80.39%\n",
      "Run: 10, Epoch: 72, Loss: 0.5732, Train: 86.67%, Valid: 78.75% Test: 80.39%\n",
      "Run: 10, Epoch: 73, Loss: 0.5665, Train: 87.50%, Valid: 80.00% Test: 82.35%\n",
      "Run: 10, Epoch: 74, Loss: 0.5501, Train: 87.50%, Valid: 82.50% Test: 80.39%\n",
      "Run: 10, Epoch: 75, Loss: 0.5444, Train: 87.50%, Valid: 81.25% Test: 78.43%\n",
      "Run: 10, Epoch: 76, Loss: 0.5522, Train: 87.50%, Valid: 81.25% Test: 80.39%\n",
      "Run: 10, Epoch: 77, Loss: 0.4964, Train: 85.83%, Valid: 78.75% Test: 78.43%\n",
      "Run: 10, Epoch: 78, Loss: 0.5558, Train: 86.67%, Valid: 80.00% Test: 80.39%\n",
      "Run: 10, Epoch: 79, Loss: 0.5372, Train: 88.33%, Valid: 81.25% Test: 80.39%\n",
      "Run: 10, Epoch: 80, Loss: 0.5345, Train: 89.17%, Valid: 81.25% Test: 80.39%\n",
      "Run: 10, Epoch: 81, Loss: 0.5345, Train: 89.17%, Valid: 82.50% Test: 82.35%\n",
      "Run: 10, Epoch: 82, Loss: 0.4680, Train: 91.67%, Valid: 82.50% Test: 82.35%\n",
      "Run: 10, Epoch: 83, Loss: 0.5687, Train: 92.50%, Valid: 83.75% Test: 82.35%\n",
      "Run: 10, Epoch: 84, Loss: 0.4973, Train: 92.50%, Valid: 83.75% Test: 84.31%\n",
      "Run: 10, Epoch: 85, Loss: 0.4895, Train: 92.50%, Valid: 82.50% Test: 84.31%\n",
      "Run: 10, Epoch: 86, Loss: 0.4955, Train: 91.67%, Valid: 83.75% Test: 82.35%\n",
      "Run: 10, Epoch: 87, Loss: 0.5098, Train: 91.67%, Valid: 82.50% Test: 82.35%\n",
      "Run: 10, Epoch: 88, Loss: 0.5509, Train: 91.67%, Valid: 81.25% Test: 80.39%\n",
      "Run: 10, Epoch: 89, Loss: 0.4782, Train: 90.00%, Valid: 82.50% Test: 78.43%\n",
      "Run: 10, Epoch: 90, Loss: 0.4969, Train: 88.33%, Valid: 78.75% Test: 76.47%\n",
      "Run: 10, Epoch: 91, Loss: 0.4353, Train: 88.33%, Valid: 80.00% Test: 80.39%\n",
      "Run: 10, Epoch: 92, Loss: 0.4614, Train: 88.33%, Valid: 80.00% Test: 78.43%\n",
      "Run: 10, Epoch: 93, Loss: 0.4634, Train: 88.33%, Valid: 78.75% Test: 80.39%\n",
      "Run: 10, Epoch: 94, Loss: 0.4860, Train: 88.33%, Valid: 78.75% Test: 84.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 95, Loss: 0.4697, Train: 90.00%, Valid: 78.75% Test: 80.39%\n",
      "Run: 10, Epoch: 96, Loss: 0.4381, Train: 89.17%, Valid: 80.00% Test: 80.39%\n",
      "Run: 10, Epoch: 97, Loss: 0.4799, Train: 87.50%, Valid: 82.50% Test: 80.39%\n",
      "Run: 10, Epoch: 98, Loss: 0.4644, Train: 87.50%, Valid: 82.50% Test: 80.39%\n",
      "Run: 10, Epoch: 99, Loss: 0.4339, Train: 89.17%, Valid: 82.50% Test: 80.39%\n",
      "Run: 10, Epoch: 100, Loss: 0.4201, Train: 90.00%, Valid: 82.50% Test: 84.31%\n",
      "Run: 10, Epoch: 101, Loss: 0.5098, Train: 91.67%, Valid: 81.25% Test: 84.31%\n",
      "Run: 10, Epoch: 102, Loss: 0.4313, Train: 91.67%, Valid: 83.75% Test: 84.31%\n",
      "Run: 10, Epoch: 103, Loss: 0.4588, Train: 90.83%, Valid: 83.75% Test: 84.31%\n",
      "Run: 10, Epoch: 104, Loss: 0.4757, Train: 91.67%, Valid: 81.25% Test: 82.35%\n",
      "Run: 10, Epoch: 105, Loss: 0.4233, Train: 90.83%, Valid: 82.50% Test: 82.35%\n",
      "Run: 10, Epoch: 106, Loss: 0.4494, Train: 90.00%, Valid: 82.50% Test: 80.39%\n",
      "Run: 10, Epoch: 107, Loss: 0.4492, Train: 91.67%, Valid: 82.50% Test: 80.39%\n",
      "Run: 10, Epoch: 108, Loss: 0.4241, Train: 91.67%, Valid: 82.50% Test: 82.35%\n",
      "Run: 10, Epoch: 109, Loss: 0.3968, Train: 91.67%, Valid: 86.25% Test: 84.31%\n",
      "Run: 10, Epoch: 110, Loss: 0.4421, Train: 94.17%, Valid: 85.00% Test: 86.27%\n",
      "Run: 10, Epoch: 111, Loss: 0.4148, Train: 94.17%, Valid: 85.00% Test: 86.27%\n",
      "Run: 10, Epoch: 112, Loss: 0.4066, Train: 92.50%, Valid: 80.00% Test: 82.35%\n",
      "Run: 10, Epoch: 113, Loss: 0.4310, Train: 95.00%, Valid: 87.50% Test: 86.27%\n",
      "Run: 10, Epoch: 114, Loss: 0.4277, Train: 95.00%, Valid: 87.50% Test: 84.31%\n",
      "Run: 10, Epoch: 115, Loss: 0.4187, Train: 94.17%, Valid: 85.00% Test: 84.31%\n",
      "Run: 10, Epoch: 116, Loss: 0.4275, Train: 95.00%, Valid: 83.75% Test: 82.35%\n",
      "Run: 10, Epoch: 117, Loss: 0.4678, Train: 95.83%, Valid: 86.25% Test: 86.27%\n",
      "Run: 10, Epoch: 118, Loss: 0.4114, Train: 96.67%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 119, Loss: 0.4427, Train: 95.83%, Valid: 82.50% Test: 86.27%\n",
      "Run: 10, Epoch: 120, Loss: 0.4291, Train: 93.33%, Valid: 83.75% Test: 84.31%\n",
      "Run: 10, Epoch: 121, Loss: 0.4297, Train: 92.50%, Valid: 83.75% Test: 86.27%\n",
      "Run: 10, Epoch: 122, Loss: 0.4653, Train: 90.83%, Valid: 81.25% Test: 86.27%\n",
      "Run: 10, Epoch: 123, Loss: 0.4102, Train: 90.83%, Valid: 83.75% Test: 84.31%\n",
      "Run: 10, Epoch: 124, Loss: 0.3816, Train: 89.17%, Valid: 82.50% Test: 82.35%\n",
      "Run: 10, Epoch: 125, Loss: 0.4073, Train: 90.83%, Valid: 83.75% Test: 84.31%\n",
      "Run: 10, Epoch: 126, Loss: 0.3684, Train: 90.83%, Valid: 83.75% Test: 84.31%\n",
      "Run: 10, Epoch: 127, Loss: 0.3433, Train: 93.33%, Valid: 85.00% Test: 84.31%\n",
      "Run: 10, Epoch: 128, Loss: 0.3768, Train: 95.00%, Valid: 86.25% Test: 84.31%\n",
      "Run: 10, Epoch: 129, Loss: 0.4140, Train: 95.00%, Valid: 86.25% Test: 88.24%\n",
      "Run: 10, Epoch: 130, Loss: 0.4012, Train: 95.83%, Valid: 87.50% Test: 86.27%\n",
      "Run: 10, Epoch: 131, Loss: 0.4328, Train: 94.17%, Valid: 85.00% Test: 84.31%\n",
      "Run: 10, Epoch: 132, Loss: 0.4060, Train: 95.00%, Valid: 83.75% Test: 84.31%\n",
      "Run: 10, Epoch: 133, Loss: 0.3539, Train: 92.50%, Valid: 85.00% Test: 86.27%\n",
      "Run: 10, Epoch: 134, Loss: 0.3674, Train: 90.00%, Valid: 82.50% Test: 86.27%\n",
      "Run: 10, Epoch: 135, Loss: 0.4184, Train: 90.83%, Valid: 81.25% Test: 84.31%\n",
      "Run: 10, Epoch: 136, Loss: 0.4229, Train: 93.33%, Valid: 82.50% Test: 84.31%\n",
      "Run: 10, Epoch: 137, Loss: 0.3681, Train: 93.33%, Valid: 82.50% Test: 86.27%\n",
      "Run: 10, Epoch: 138, Loss: 0.3702, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 10, Epoch: 139, Loss: 0.4160, Train: 95.00%, Valid: 85.00% Test: 86.27%\n",
      "Run: 10, Epoch: 140, Loss: 0.3439, Train: 95.00%, Valid: 85.00% Test: 86.27%\n",
      "Run: 10, Epoch: 141, Loss: 0.4060, Train: 95.00%, Valid: 87.50% Test: 84.31%\n",
      "Run: 10, Epoch: 142, Loss: 0.3303, Train: 96.67%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 143, Loss: 0.4081, Train: 96.67%, Valid: 83.75% Test: 90.20%\n",
      "Run: 10, Epoch: 144, Loss: 0.4231, Train: 98.33%, Valid: 86.25% Test: 90.20%\n",
      "Run: 10, Epoch: 145, Loss: 0.4031, Train: 96.67%, Valid: 85.00% Test: 84.31%\n",
      "Run: 10, Epoch: 146, Loss: 0.3670, Train: 97.50%, Valid: 82.50% Test: 86.27%\n",
      "Run: 10, Epoch: 147, Loss: 0.3548, Train: 95.83%, Valid: 80.00% Test: 88.24%\n",
      "Run: 10, Epoch: 148, Loss: 0.3416, Train: 95.00%, Valid: 81.25% Test: 84.31%\n",
      "Run: 10, Epoch: 149, Loss: 0.3292, Train: 93.33%, Valid: 81.25% Test: 82.35%\n",
      "Run: 10, Epoch: 150, Loss: 0.3784, Train: 92.50%, Valid: 82.50% Test: 82.35%\n",
      "Run: 10, Epoch: 151, Loss: 0.3509, Train: 93.33%, Valid: 82.50% Test: 82.35%\n",
      "Run: 10, Epoch: 152, Loss: 0.3477, Train: 94.17%, Valid: 85.00% Test: 86.27%\n",
      "Run: 10, Epoch: 153, Loss: 0.3019, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 10, Epoch: 154, Loss: 0.4244, Train: 95.00%, Valid: 83.75% Test: 86.27%\n",
      "Run: 10, Epoch: 155, Loss: 0.3371, Train: 95.83%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 156, Loss: 0.3458, Train: 95.83%, Valid: 88.75% Test: 88.24%\n",
      "Run: 10, Epoch: 157, Loss: 0.3132, Train: 96.67%, Valid: 86.25% Test: 86.27%\n",
      "Run: 10, Epoch: 158, Loss: 0.3325, Train: 94.17%, Valid: 86.25% Test: 84.31%\n",
      "Run: 10, Epoch: 159, Loss: 0.3194, Train: 95.00%, Valid: 86.25% Test: 84.31%\n",
      "Run: 10, Epoch: 160, Loss: 0.3096, Train: 95.83%, Valid: 88.75% Test: 86.27%\n",
      "Run: 10, Epoch: 161, Loss: 0.3610, Train: 95.83%, Valid: 88.75% Test: 86.27%\n",
      "Run: 10, Epoch: 162, Loss: 0.3839, Train: 95.83%, Valid: 86.25% Test: 86.27%\n",
      "Run: 10, Epoch: 163, Loss: 0.3035, Train: 96.67%, Valid: 87.50% Test: 86.27%\n",
      "Run: 10, Epoch: 164, Loss: 0.2932, Train: 95.83%, Valid: 86.25% Test: 86.27%\n",
      "Run: 10, Epoch: 165, Loss: 0.2767, Train: 97.50%, Valid: 86.25% Test: 86.27%\n",
      "Run: 10, Epoch: 166, Loss: 0.3291, Train: 96.67%, Valid: 86.25% Test: 86.27%\n",
      "Run: 10, Epoch: 167, Loss: 0.3101, Train: 96.67%, Valid: 81.25% Test: 84.31%\n",
      "Run: 10, Epoch: 168, Loss: 0.3315, Train: 96.67%, Valid: 81.25% Test: 86.27%\n",
      "Run: 10, Epoch: 169, Loss: 0.3462, Train: 97.50%, Valid: 83.75% Test: 88.24%\n",
      "Run: 10, Epoch: 170, Loss: 0.3162, Train: 98.33%, Valid: 87.50% Test: 88.24%\n",
      "Run: 10, Epoch: 171, Loss: 0.2780, Train: 99.17%, Valid: 87.50% Test: 90.20%\n",
      "Run: 10, Epoch: 172, Loss: 0.3230, Train: 100.00%, Valid: 87.50% Test: 90.20%\n",
      "Run: 10, Epoch: 173, Loss: 0.3351, Train: 100.00%, Valid: 87.50% Test: 90.20%\n",
      "Run: 10, Epoch: 174, Loss: 0.2420, Train: 99.17%, Valid: 90.00% Test: 90.20%\n",
      "Run: 10, Epoch: 175, Loss: 0.3393, Train: 98.33%, Valid: 87.50% Test: 88.24%\n",
      "Run: 10, Epoch: 176, Loss: 0.3185, Train: 97.50%, Valid: 87.50% Test: 88.24%\n",
      "Run: 10, Epoch: 177, Loss: 0.3324, Train: 96.67%, Valid: 86.25% Test: 88.24%\n",
      "Run: 10, Epoch: 178, Loss: 0.3101, Train: 95.83%, Valid: 83.75% Test: 88.24%\n",
      "Run: 10, Epoch: 179, Loss: 0.2750, Train: 96.67%, Valid: 81.25% Test: 84.31%\n",
      "Run: 10, Epoch: 180, Loss: 0.2833, Train: 96.67%, Valid: 83.75% Test: 84.31%\n",
      "Run: 10, Epoch: 181, Loss: 0.3271, Train: 95.83%, Valid: 85.00% Test: 84.31%\n",
      "Run: 10, Epoch: 182, Loss: 0.3141, Train: 96.67%, Valid: 85.00% Test: 86.27%\n",
      "Run: 10, Epoch: 183, Loss: 0.3315, Train: 95.83%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 184, Loss: 0.3102, Train: 95.83%, Valid: 87.50% Test: 88.24%\n",
      "Run: 10, Epoch: 185, Loss: 0.2898, Train: 95.83%, Valid: 87.50% Test: 88.24%\n",
      "Run: 10, Epoch: 186, Loss: 0.3018, Train: 95.00%, Valid: 88.75% Test: 88.24%\n",
      "Run: 10, Epoch: 187, Loss: 0.2966, Train: 95.00%, Valid: 87.50% Test: 88.24%\n",
      "Run: 10, Epoch: 188, Loss: 0.3246, Train: 95.83%, Valid: 86.25% Test: 88.24%\n",
      "Run: 10, Epoch: 189, Loss: 0.3118, Train: 95.83%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 190, Loss: 0.3465, Train: 96.67%, Valid: 86.25% Test: 86.27%\n",
      "Run: 10, Epoch: 191, Loss: 0.3225, Train: 96.67%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 192, Loss: 0.2688, Train: 95.83%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 193, Loss: 0.2674, Train: 95.83%, Valid: 85.00% Test: 88.24%\n",
      "Run: 10, Epoch: 194, Loss: 0.2814, Train: 96.67%, Valid: 88.75% Test: 88.24%\n",
      "Run: 10, Epoch: 195, Loss: 0.2885, Train: 97.50%, Valid: 88.75% Test: 88.24%\n",
      "Run: 10, Epoch: 196, Loss: 0.2434, Train: 98.33%, Valid: 88.75% Test: 90.20%\n",
      "Run: 10, Epoch: 197, Loss: 0.2519, Train: 98.33%, Valid: 88.75% Test: 90.20%\n",
      "Run: 10, Epoch: 198, Loss: 0.2562, Train: 98.33%, Valid: 88.75% Test: 90.20%\n",
      "Run: 10, Epoch: 199, Loss: 0.2600, Train: 99.17%, Valid: 87.50% Test: 90.20%\n",
      "Run: 10, Epoch: 200, Loss: 0.2884, Train: 98.33%, Valid: 86.25% Test: 88.24%\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 90.00\n",
      "  Final Train: 99.17\n",
      "   Final Test: 90.20\n",
      "All runs:\n",
      "Highest Train: 98.75 ± 1.37\n",
      "Highest Valid: 90.75 ± 2.51\n",
      "  Final Train: 96.50 ± 2.63\n",
      "   Final Test: 90.98 ± 4.15\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.5,'num_layers_mlp': 3}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 5,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(15, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        \n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.001)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccbc05",
   "metadata": {},
   "source": [
    "# TOPO-GSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceda79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[251, 1703], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10], adj_t=[251, 251, nnz=515], topo=[251, 24])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "topo_fe=torch.cat((topo_betti0,topo_betti1),1)\n",
    "data.topo=topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "880f9749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x16a8ca9e0>\n",
      "Run: 01, Epoch: 01, Loss: 1.8350, Train: 3.33%, Valid: 6.25% Test: 1.96%\n",
      "Run: 01, Epoch: 02, Loss: 1.6979, Train: 3.33%, Valid: 6.25% Test: 1.96%\n",
      "Run: 01, Epoch: 03, Loss: 1.6062, Train: 3.33%, Valid: 6.25% Test: 1.96%\n",
      "Run: 01, Epoch: 04, Loss: 1.5003, Train: 3.33%, Valid: 6.25% Test: 1.96%\n",
      "Run: 01, Epoch: 05, Loss: 1.4125, Train: 3.33%, Valid: 6.25% Test: 1.96%\n",
      "Run: 01, Epoch: 06, Loss: 1.3367, Train: 22.50%, Valid: 21.25% Test: 7.84%\n",
      "Run: 01, Epoch: 07, Loss: 1.2532, Train: 41.67%, Valid: 52.50% Test: 49.02%\n",
      "Run: 01, Epoch: 08, Loss: 1.1519, Train: 45.00%, Valid: 52.50% Test: 52.94%\n",
      "Run: 01, Epoch: 09, Loss: 1.1172, Train: 51.67%, Valid: 52.50% Test: 52.94%\n",
      "Run: 01, Epoch: 10, Loss: 1.0528, Train: 60.00%, Valid: 53.75% Test: 52.94%\n",
      "Run: 01, Epoch: 11, Loss: 1.0066, Train: 64.17%, Valid: 55.00% Test: 54.90%\n",
      "Run: 01, Epoch: 12, Loss: 0.9572, Train: 65.83%, Valid: 58.75% Test: 54.90%\n",
      "Run: 01, Epoch: 13, Loss: 0.9347, Train: 67.50%, Valid: 61.25% Test: 56.86%\n",
      "Run: 01, Epoch: 14, Loss: 0.8765, Train: 69.17%, Valid: 62.50% Test: 56.86%\n",
      "Run: 01, Epoch: 15, Loss: 0.8616, Train: 69.17%, Valid: 63.75% Test: 56.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshem/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 16, Loss: 0.8280, Train: 70.00%, Valid: 66.25% Test: 60.78%\n",
      "Run: 01, Epoch: 17, Loss: 0.7981, Train: 74.17%, Valid: 66.25% Test: 62.75%\n",
      "Run: 01, Epoch: 18, Loss: 0.7872, Train: 75.83%, Valid: 67.50% Test: 62.75%\n",
      "Run: 01, Epoch: 19, Loss: 0.7605, Train: 76.67%, Valid: 67.50% Test: 62.75%\n",
      "Run: 01, Epoch: 20, Loss: 0.7559, Train: 79.17%, Valid: 68.75% Test: 62.75%\n",
      "Run: 01, Epoch: 21, Loss: 0.7140, Train: 80.83%, Valid: 68.75% Test: 66.67%\n",
      "Run: 01, Epoch: 22, Loss: 0.7089, Train: 82.50%, Valid: 68.75% Test: 66.67%\n",
      "Run: 01, Epoch: 23, Loss: 0.7126, Train: 86.67%, Valid: 70.00% Test: 66.67%\n",
      "Run: 01, Epoch: 24, Loss: 0.6754, Train: 86.67%, Valid: 70.00% Test: 66.67%\n",
      "Run: 01, Epoch: 25, Loss: 0.6542, Train: 86.67%, Valid: 70.00% Test: 66.67%\n",
      "Run: 01, Epoch: 26, Loss: 0.6593, Train: 87.50%, Valid: 71.25% Test: 66.67%\n",
      "Run: 01, Epoch: 27, Loss: 0.6295, Train: 87.50%, Valid: 71.25% Test: 66.67%\n",
      "Run: 01, Epoch: 28, Loss: 0.6508, Train: 87.50%, Valid: 71.25% Test: 66.67%\n",
      "Run: 01, Epoch: 29, Loss: 0.6211, Train: 87.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 01, Epoch: 30, Loss: 0.6071, Train: 89.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 31, Loss: 0.6358, Train: 90.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 01, Epoch: 32, Loss: 0.5956, Train: 90.83%, Valid: 71.25% Test: 70.59%\n",
      "Run: 01, Epoch: 33, Loss: 0.6220, Train: 90.83%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 34, Loss: 0.5738, Train: 90.83%, Valid: 71.25% Test: 70.59%\n",
      "Run: 01, Epoch: 35, Loss: 0.5716, Train: 91.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 01, Epoch: 36, Loss: 0.5977, Train: 93.33%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 37, Loss: 0.5600, Train: 95.83%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 38, Loss: 0.5723, Train: 95.83%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 39, Loss: 0.5510, Train: 95.83%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 40, Loss: 0.5351, Train: 95.83%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 41, Loss: 0.5176, Train: 95.83%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 42, Loss: 0.5076, Train: 96.67%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 43, Loss: 0.5294, Train: 96.67%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 44, Loss: 0.4987, Train: 96.67%, Valid: 72.50% Test: 70.59%\n",
      "Run: 01, Epoch: 45, Loss: 0.5244, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 46, Loss: 0.5253, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 47, Loss: 0.5100, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 48, Loss: 0.4850, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 49, Loss: 0.4834, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 50, Loss: 0.4789, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 51, Loss: 0.4692, Train: 96.67%, Valid: 75.00% Test: 68.63%\n",
      "Run: 01, Epoch: 52, Loss: 0.4636, Train: 96.67%, Valid: 77.50% Test: 70.59%\n",
      "Run: 01, Epoch: 53, Loss: 0.4871, Train: 96.67%, Valid: 77.50% Test: 70.59%\n",
      "Run: 01, Epoch: 54, Loss: 0.4551, Train: 96.67%, Valid: 77.50% Test: 72.55%\n",
      "Run: 01, Epoch: 55, Loss: 0.4567, Train: 96.67%, Valid: 77.50% Test: 74.51%\n",
      "Run: 01, Epoch: 56, Loss: 0.4500, Train: 96.67%, Valid: 77.50% Test: 74.51%\n",
      "Run: 01, Epoch: 57, Loss: 0.4555, Train: 96.67%, Valid: 77.50% Test: 74.51%\n",
      "Run: 01, Epoch: 58, Loss: 0.4378, Train: 96.67%, Valid: 77.50% Test: 72.55%\n",
      "Run: 01, Epoch: 59, Loss: 0.4383, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 60, Loss: 0.4289, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 61, Loss: 0.4168, Train: 96.67%, Valid: 77.50% Test: 72.55%\n",
      "Run: 01, Epoch: 62, Loss: 0.4071, Train: 96.67%, Valid: 77.50% Test: 72.55%\n",
      "Run: 01, Epoch: 63, Loss: 0.4045, Train: 96.67%, Valid: 77.50% Test: 72.55%\n",
      "Run: 01, Epoch: 64, Loss: 0.4275, Train: 96.67%, Valid: 77.50% Test: 72.55%\n",
      "Run: 01, Epoch: 65, Loss: 0.4240, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 66, Loss: 0.4237, Train: 96.67%, Valid: 76.25% Test: 70.59%\n",
      "Run: 01, Epoch: 67, Loss: 0.3937, Train: 96.67%, Valid: 75.00% Test: 68.63%\n",
      "Run: 01, Epoch: 68, Loss: 0.3816, Train: 96.67%, Valid: 75.00% Test: 68.63%\n",
      "Run: 01, Epoch: 69, Loss: 0.3680, Train: 96.67%, Valid: 75.00% Test: 68.63%\n",
      "Run: 01, Epoch: 70, Loss: 0.4364, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 71, Loss: 0.3961, Train: 96.67%, Valid: 72.50% Test: 68.63%\n",
      "Run: 01, Epoch: 72, Loss: 0.3920, Train: 96.67%, Valid: 72.50% Test: 68.63%\n",
      "Run: 01, Epoch: 73, Loss: 0.4004, Train: 96.67%, Valid: 72.50% Test: 68.63%\n",
      "Run: 01, Epoch: 74, Loss: 0.4010, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 75, Loss: 0.3783, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 76, Loss: 0.3884, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 01, Epoch: 77, Loss: 0.3869, Train: 96.67%, Valid: 72.50% Test: 68.63%\n",
      "Run: 01, Epoch: 78, Loss: 0.3986, Train: 96.67%, Valid: 71.25% Test: 66.67%\n",
      "Run: 01, Epoch: 79, Loss: 0.3621, Train: 96.67%, Valid: 73.75% Test: 66.67%\n",
      "Run: 01, Epoch: 80, Loss: 0.4012, Train: 96.67%, Valid: 73.75% Test: 64.71%\n",
      "Run: 01, Epoch: 81, Loss: 0.3416, Train: 96.67%, Valid: 73.75% Test: 64.71%\n",
      "Run: 01, Epoch: 82, Loss: 0.3726, Train: 96.67%, Valid: 75.00% Test: 64.71%\n",
      "Run: 01, Epoch: 83, Loss: 0.3579, Train: 96.67%, Valid: 75.00% Test: 68.63%\n",
      "Run: 01, Epoch: 84, Loss: 0.3766, Train: 96.67%, Valid: 75.00% Test: 68.63%\n",
      "Run: 01, Epoch: 85, Loss: 0.3232, Train: 96.67%, Valid: 75.00% Test: 68.63%\n",
      "Run: 01, Epoch: 86, Loss: 0.3621, Train: 96.67%, Valid: 75.00% Test: 68.63%\n",
      "Run: 01, Epoch: 87, Loss: 0.3282, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 88, Loss: 0.3444, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 89, Loss: 0.3166, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 90, Loss: 0.3231, Train: 96.67%, Valid: 73.75% Test: 72.55%\n",
      "Run: 01, Epoch: 91, Loss: 0.3448, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 92, Loss: 0.3396, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 93, Loss: 0.3370, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 94, Loss: 0.2885, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 95, Loss: 0.3567, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 96, Loss: 0.3020, Train: 96.67%, Valid: 76.25% Test: 70.59%\n",
      "Run: 01, Epoch: 97, Loss: 0.3075, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 98, Loss: 0.3468, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 99, Loss: 0.3409, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 100, Loss: 0.3221, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 101, Loss: 0.2912, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 102, Loss: 0.2872, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 103, Loss: 0.3063, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 104, Loss: 0.3024, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 105, Loss: 0.2946, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 106, Loss: 0.3059, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 107, Loss: 0.3002, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 108, Loss: 0.2997, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 109, Loss: 0.2978, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 110, Loss: 0.2756, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 111, Loss: 0.3093, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 112, Loss: 0.2823, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 113, Loss: 0.2785, Train: 96.67%, Valid: 73.75% Test: 74.51%\n",
      "Run: 01, Epoch: 114, Loss: 0.2879, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 01, Epoch: 115, Loss: 0.2521, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 01, Epoch: 116, Loss: 0.2730, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 117, Loss: 0.2525, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 118, Loss: 0.2629, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 119, Loss: 0.2954, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 120, Loss: 0.2794, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 121, Loss: 0.2593, Train: 96.67%, Valid: 76.25% Test: 70.59%\n",
      "Run: 01, Epoch: 122, Loss: 0.2419, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 123, Loss: 0.2734, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 124, Loss: 0.2703, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 125, Loss: 0.2554, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 126, Loss: 0.2438, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 127, Loss: 0.3106, Train: 96.67%, Valid: 76.25% Test: 74.51%\n",
      "Run: 01, Epoch: 128, Loss: 0.2616, Train: 96.67%, Valid: 77.50% Test: 72.55%\n",
      "Run: 01, Epoch: 129, Loss: 0.2725, Train: 96.67%, Valid: 77.50% Test: 72.55%\n",
      "Run: 01, Epoch: 130, Loss: 0.2374, Train: 96.67%, Valid: 77.50% Test: 72.55%\n",
      "Run: 01, Epoch: 131, Loss: 0.2563, Train: 96.67%, Valid: 77.50% Test: 72.55%\n",
      "Run: 01, Epoch: 132, Loss: 0.2825, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 133, Loss: 0.3015, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 134, Loss: 0.2644, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 135, Loss: 0.2463, Train: 96.67%, Valid: 76.25% Test: 70.59%\n",
      "Run: 01, Epoch: 136, Loss: 0.2271, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 137, Loss: 0.2238, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 138, Loss: 0.2109, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 139, Loss: 0.2495, Train: 96.67%, Valid: 76.25% Test: 74.51%\n",
      "Run: 01, Epoch: 140, Loss: 0.2578, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 141, Loss: 0.2591, Train: 96.67%, Valid: 76.25% Test: 74.51%\n",
      "Run: 01, Epoch: 142, Loss: 0.2229, Train: 96.67%, Valid: 76.25% Test: 74.51%\n",
      "Run: 01, Epoch: 143, Loss: 0.1996, Train: 96.67%, Valid: 76.25% Test: 74.51%\n",
      "Run: 01, Epoch: 144, Loss: 0.2250, Train: 96.67%, Valid: 76.25% Test: 74.51%\n",
      "Run: 01, Epoch: 145, Loss: 0.2344, Train: 96.67%, Valid: 76.25% Test: 74.51%\n",
      "Run: 01, Epoch: 146, Loss: 0.2232, Train: 96.67%, Valid: 76.25% Test: 74.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 147, Loss: 0.2318, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 148, Loss: 0.2701, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 149, Loss: 0.2366, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 150, Loss: 0.2201, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 151, Loss: 0.2295, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 152, Loss: 0.2245, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 153, Loss: 0.2096, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 154, Loss: 0.2402, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 155, Loss: 0.2192, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 156, Loss: 0.1980, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 157, Loss: 0.2076, Train: 96.67%, Valid: 76.25% Test: 70.59%\n",
      "Run: 01, Epoch: 158, Loss: 0.2155, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 159, Loss: 0.2165, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 160, Loss: 0.2187, Train: 96.67%, Valid: 76.25% Test: 70.59%\n",
      "Run: 01, Epoch: 161, Loss: 0.2066, Train: 96.67%, Valid: 76.25% Test: 70.59%\n",
      "Run: 01, Epoch: 162, Loss: 0.1907, Train: 96.67%, Valid: 76.25% Test: 70.59%\n",
      "Run: 01, Epoch: 163, Loss: 0.1848, Train: 96.67%, Valid: 76.25% Test: 70.59%\n",
      "Run: 01, Epoch: 164, Loss: 0.1929, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 165, Loss: 0.2103, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 166, Loss: 0.1937, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 01, Epoch: 167, Loss: 0.2125, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 168, Loss: 0.2201, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 169, Loss: 0.2084, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 170, Loss: 0.1957, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 171, Loss: 0.1834, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 172, Loss: 0.1645, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 173, Loss: 0.1815, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 174, Loss: 0.2157, Train: 96.67%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 175, Loss: 0.1974, Train: 96.67%, Valid: 73.75% Test: 72.55%\n",
      "Run: 01, Epoch: 176, Loss: 0.1807, Train: 98.33%, Valid: 73.75% Test: 72.55%\n",
      "Run: 01, Epoch: 177, Loss: 0.1783, Train: 98.33%, Valid: 73.75% Test: 72.55%\n",
      "Run: 01, Epoch: 178, Loss: 0.1936, Train: 98.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 179, Loss: 0.1474, Train: 98.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 180, Loss: 0.1619, Train: 99.17%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 181, Loss: 0.2014, Train: 99.17%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 182, Loss: 0.2329, Train: 99.17%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 183, Loss: 0.1610, Train: 99.17%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 184, Loss: 0.1773, Train: 99.17%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 185, Loss: 0.1775, Train: 99.17%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 186, Loss: 0.2090, Train: 99.17%, Valid: 75.00% Test: 74.51%\n",
      "Run: 01, Epoch: 187, Loss: 0.2606, Train: 99.17%, Valid: 75.00% Test: 74.51%\n",
      "Run: 01, Epoch: 188, Loss: 0.1691, Train: 99.17%, Valid: 75.00% Test: 74.51%\n",
      "Run: 01, Epoch: 189, Loss: 0.1658, Train: 99.17%, Valid: 76.25% Test: 74.51%\n",
      "Run: 01, Epoch: 190, Loss: 0.1745, Train: 99.17%, Valid: 76.25% Test: 74.51%\n",
      "Run: 01, Epoch: 191, Loss: 0.1700, Train: 99.17%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 192, Loss: 0.1969, Train: 100.00%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 193, Loss: 0.1710, Train: 100.00%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 194, Loss: 0.2030, Train: 100.00%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 195, Loss: 0.1947, Train: 100.00%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 196, Loss: 0.1627, Train: 100.00%, Valid: 76.25% Test: 72.55%\n",
      "Run: 01, Epoch: 197, Loss: 0.1846, Train: 100.00%, Valid: 75.00% Test: 72.55%\n",
      "Run: 01, Epoch: 198, Loss: 0.1716, Train: 100.00%, Valid: 75.00% Test: 74.51%\n",
      "Run: 01, Epoch: 199, Loss: 0.1445, Train: 100.00%, Valid: 75.00% Test: 74.51%\n",
      "Run: 01, Epoch: 200, Loss: 0.1405, Train: 100.00%, Valid: 73.75% Test: 74.51%\n",
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 77.50\n",
      "  Final Train: 96.67\n",
      "   Final Test: 70.59\n",
      "Run: 02, Epoch: 01, Loss: 1.6720, Train: 10.00%, Valid: 10.00% Test: 1.96%\n",
      "Run: 02, Epoch: 02, Loss: 1.5275, Train: 10.00%, Valid: 10.00% Test: 1.96%\n",
      "Run: 02, Epoch: 03, Loss: 1.4422, Train: 53.33%, Valid: 38.75% Test: 33.33%\n",
      "Run: 02, Epoch: 04, Loss: 1.3608, Train: 74.17%, Valid: 63.75% Test: 74.51%\n",
      "Run: 02, Epoch: 05, Loss: 1.2806, Train: 73.33%, Valid: 61.25% Test: 82.35%\n",
      "Run: 02, Epoch: 06, Loss: 1.2239, Train: 73.33%, Valid: 60.00% Test: 82.35%\n",
      "Run: 02, Epoch: 07, Loss: 1.1503, Train: 71.67%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 08, Loss: 1.0935, Train: 71.67%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 09, Loss: 1.0525, Train: 71.67%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 10, Loss: 0.9881, Train: 71.67%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 11, Loss: 0.9535, Train: 72.50%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 12, Loss: 0.9098, Train: 72.50%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 13, Loss: 0.8926, Train: 73.33%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 14, Loss: 0.8411, Train: 73.33%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 15, Loss: 0.8150, Train: 73.33%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 16, Loss: 0.8147, Train: 73.33%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 17, Loss: 0.7978, Train: 73.33%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 18, Loss: 0.7608, Train: 73.33%, Valid: 57.50% Test: 82.35%\n",
      "Run: 02, Epoch: 19, Loss: 0.7415, Train: 73.33%, Valid: 58.75% Test: 82.35%\n",
      "Run: 02, Epoch: 20, Loss: 0.7495, Train: 77.50%, Valid: 60.00% Test: 82.35%\n",
      "Run: 02, Epoch: 21, Loss: 0.6803, Train: 77.50%, Valid: 60.00% Test: 82.35%\n",
      "Run: 02, Epoch: 22, Loss: 0.6954, Train: 79.17%, Valid: 60.00% Test: 82.35%\n",
      "Run: 02, Epoch: 23, Loss: 0.6527, Train: 80.83%, Valid: 62.50% Test: 82.35%\n",
      "Run: 02, Epoch: 24, Loss: 0.6286, Train: 83.33%, Valid: 62.50% Test: 82.35%\n",
      "Run: 02, Epoch: 25, Loss: 0.6489, Train: 86.67%, Valid: 62.50% Test: 84.31%\n",
      "Run: 02, Epoch: 26, Loss: 0.6205, Train: 88.33%, Valid: 65.00% Test: 84.31%\n",
      "Run: 02, Epoch: 27, Loss: 0.6197, Train: 88.33%, Valid: 66.25% Test: 82.35%\n",
      "Run: 02, Epoch: 28, Loss: 0.5987, Train: 88.33%, Valid: 66.25% Test: 82.35%\n",
      "Run: 02, Epoch: 29, Loss: 0.6187, Train: 88.33%, Valid: 66.25% Test: 82.35%\n",
      "Run: 02, Epoch: 30, Loss: 0.5871, Train: 88.33%, Valid: 66.25% Test: 82.35%\n",
      "Run: 02, Epoch: 31, Loss: 0.5548, Train: 88.33%, Valid: 67.50% Test: 82.35%\n",
      "Run: 02, Epoch: 32, Loss: 0.5492, Train: 89.17%, Valid: 67.50% Test: 82.35%\n",
      "Run: 02, Epoch: 33, Loss: 0.5473, Train: 90.83%, Valid: 67.50% Test: 82.35%\n",
      "Run: 02, Epoch: 34, Loss: 0.5327, Train: 91.67%, Valid: 67.50% Test: 84.31%\n",
      "Run: 02, Epoch: 35, Loss: 0.5042, Train: 92.50%, Valid: 67.50% Test: 84.31%\n",
      "Run: 02, Epoch: 36, Loss: 0.5232, Train: 94.17%, Valid: 67.50% Test: 82.35%\n",
      "Run: 02, Epoch: 37, Loss: 0.5188, Train: 95.00%, Valid: 67.50% Test: 80.39%\n",
      "Run: 02, Epoch: 38, Loss: 0.5176, Train: 96.67%, Valid: 67.50% Test: 80.39%\n",
      "Run: 02, Epoch: 39, Loss: 0.4988, Train: 96.67%, Valid: 67.50% Test: 80.39%\n",
      "Run: 02, Epoch: 40, Loss: 0.5059, Train: 96.67%, Valid: 67.50% Test: 80.39%\n",
      "Run: 02, Epoch: 41, Loss: 0.4899, Train: 96.67%, Valid: 66.25% Test: 78.43%\n",
      "Run: 02, Epoch: 42, Loss: 0.4977, Train: 97.50%, Valid: 66.25% Test: 78.43%\n",
      "Run: 02, Epoch: 43, Loss: 0.4636, Train: 97.50%, Valid: 66.25% Test: 78.43%\n",
      "Run: 02, Epoch: 44, Loss: 0.4726, Train: 97.50%, Valid: 67.50% Test: 80.39%\n",
      "Run: 02, Epoch: 45, Loss: 0.4629, Train: 97.50%, Valid: 70.00% Test: 80.39%\n",
      "Run: 02, Epoch: 46, Loss: 0.4573, Train: 97.50%, Valid: 70.00% Test: 80.39%\n",
      "Run: 02, Epoch: 47, Loss: 0.4455, Train: 97.50%, Valid: 71.25% Test: 80.39%\n",
      "Run: 02, Epoch: 48, Loss: 0.4486, Train: 97.50%, Valid: 71.25% Test: 78.43%\n",
      "Run: 02, Epoch: 49, Loss: 0.4463, Train: 98.33%, Valid: 72.50% Test: 78.43%\n",
      "Run: 02, Epoch: 50, Loss: 0.4136, Train: 98.33%, Valid: 72.50% Test: 78.43%\n",
      "Run: 02, Epoch: 51, Loss: 0.4282, Train: 98.33%, Valid: 72.50% Test: 78.43%\n",
      "Run: 02, Epoch: 52, Loss: 0.3975, Train: 98.33%, Valid: 72.50% Test: 78.43%\n",
      "Run: 02, Epoch: 53, Loss: 0.3973, Train: 98.33%, Valid: 72.50% Test: 78.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 54, Loss: 0.3762, Train: 98.33%, Valid: 71.25% Test: 78.43%\n",
      "Run: 02, Epoch: 55, Loss: 0.3713, Train: 98.33%, Valid: 71.25% Test: 78.43%\n",
      "Run: 02, Epoch: 56, Loss: 0.3937, Train: 99.17%, Valid: 71.25% Test: 78.43%\n",
      "Run: 02, Epoch: 57, Loss: 0.4001, Train: 99.17%, Valid: 71.25% Test: 78.43%\n",
      "Run: 02, Epoch: 58, Loss: 0.3757, Train: 99.17%, Valid: 71.25% Test: 78.43%\n",
      "Run: 02, Epoch: 59, Loss: 0.3729, Train: 99.17%, Valid: 71.25% Test: 78.43%\n",
      "Run: 02, Epoch: 60, Loss: 0.3881, Train: 99.17%, Valid: 72.50% Test: 78.43%\n",
      "Run: 02, Epoch: 61, Loss: 0.3683, Train: 99.17%, Valid: 72.50% Test: 78.43%\n",
      "Run: 02, Epoch: 62, Loss: 0.3456, Train: 99.17%, Valid: 72.50% Test: 78.43%\n",
      "Run: 02, Epoch: 63, Loss: 0.3627, Train: 99.17%, Valid: 72.50% Test: 78.43%\n",
      "Run: 02, Epoch: 64, Loss: 0.3619, Train: 99.17%, Valid: 72.50% Test: 78.43%\n",
      "Run: 02, Epoch: 65, Loss: 0.3397, Train: 99.17%, Valid: 72.50% Test: 78.43%\n",
      "Run: 02, Epoch: 66, Loss: 0.3232, Train: 99.17%, Valid: 71.25% Test: 78.43%\n",
      "Run: 02, Epoch: 67, Loss: 0.3308, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 68, Loss: 0.3257, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 69, Loss: 0.3322, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 70, Loss: 0.3344, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 71, Loss: 0.3672, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 72, Loss: 0.3177, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 73, Loss: 0.3214, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 74, Loss: 0.3057, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 75, Loss: 0.3211, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 76, Loss: 0.2892, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 77, Loss: 0.2751, Train: 99.17%, Valid: 72.50% Test: 76.47%\n",
      "Run: 02, Epoch: 78, Loss: 0.2726, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 79, Loss: 0.2698, Train: 99.17%, Valid: 72.50% Test: 76.47%\n",
      "Run: 02, Epoch: 80, Loss: 0.3038, Train: 99.17%, Valid: 72.50% Test: 76.47%\n",
      "Run: 02, Epoch: 81, Loss: 0.2850, Train: 99.17%, Valid: 72.50% Test: 76.47%\n",
      "Run: 02, Epoch: 82, Loss: 0.3055, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 83, Loss: 0.2738, Train: 99.17%, Valid: 72.50% Test: 76.47%\n",
      "Run: 02, Epoch: 84, Loss: 0.2566, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 85, Loss: 0.2691, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 86, Loss: 0.2548, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 87, Loss: 0.2867, Train: 99.17%, Valid: 68.75% Test: 76.47%\n",
      "Run: 02, Epoch: 88, Loss: 0.2979, Train: 99.17%, Valid: 68.75% Test: 76.47%\n",
      "Run: 02, Epoch: 89, Loss: 0.2723, Train: 99.17%, Valid: 68.75% Test: 76.47%\n",
      "Run: 02, Epoch: 90, Loss: 0.2934, Train: 99.17%, Valid: 68.75% Test: 76.47%\n",
      "Run: 02, Epoch: 91, Loss: 0.2983, Train: 99.17%, Valid: 67.50% Test: 76.47%\n",
      "Run: 02, Epoch: 92, Loss: 0.2498, Train: 99.17%, Valid: 67.50% Test: 76.47%\n",
      "Run: 02, Epoch: 93, Loss: 0.3131, Train: 99.17%, Valid: 67.50% Test: 76.47%\n",
      "Run: 02, Epoch: 94, Loss: 0.2659, Train: 99.17%, Valid: 67.50% Test: 76.47%\n",
      "Run: 02, Epoch: 95, Loss: 0.2418, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 96, Loss: 0.2269, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 97, Loss: 0.2475, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 98, Loss: 0.2596, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 99, Loss: 0.2474, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 100, Loss: 0.2462, Train: 99.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 02, Epoch: 101, Loss: 0.2152, Train: 99.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 02, Epoch: 102, Loss: 0.2687, Train: 99.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 02, Epoch: 103, Loss: 0.2709, Train: 99.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 02, Epoch: 104, Loss: 0.2208, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 02, Epoch: 105, Loss: 0.2234, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 02, Epoch: 106, Loss: 0.2261, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 02, Epoch: 107, Loss: 0.2061, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 02, Epoch: 108, Loss: 0.2375, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 02, Epoch: 109, Loss: 0.2519, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 02, Epoch: 110, Loss: 0.2135, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 02, Epoch: 111, Loss: 0.2100, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 02, Epoch: 112, Loss: 0.2227, Train: 99.17%, Valid: 71.25% Test: 72.55%\n",
      "Run: 02, Epoch: 113, Loss: 0.2274, Train: 99.17%, Valid: 71.25% Test: 72.55%\n",
      "Run: 02, Epoch: 114, Loss: 0.2017, Train: 99.17%, Valid: 71.25% Test: 72.55%\n",
      "Run: 02, Epoch: 115, Loss: 0.1929, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 02, Epoch: 116, Loss: 0.1818, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 02, Epoch: 117, Loss: 0.2149, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 118, Loss: 0.2212, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 119, Loss: 0.2105, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 120, Loss: 0.2299, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 121, Loss: 0.1874, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 122, Loss: 0.2020, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 123, Loss: 0.2171, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 124, Loss: 0.2025, Train: 99.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 02, Epoch: 125, Loss: 0.1835, Train: 99.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 02, Epoch: 126, Loss: 0.2222, Train: 99.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 02, Epoch: 127, Loss: 0.2114, Train: 99.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 02, Epoch: 128, Loss: 0.1740, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 129, Loss: 0.1951, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 130, Loss: 0.2166, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 131, Loss: 0.2040, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 132, Loss: 0.1585, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 133, Loss: 0.1842, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 134, Loss: 0.1874, Train: 99.17%, Valid: 66.25% Test: 74.51%\n",
      "Run: 02, Epoch: 135, Loss: 0.1574, Train: 99.17%, Valid: 66.25% Test: 74.51%\n",
      "Run: 02, Epoch: 136, Loss: 0.1846, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 137, Loss: 0.1676, Train: 99.17%, Valid: 66.25% Test: 74.51%\n",
      "Run: 02, Epoch: 138, Loss: 0.1807, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 139, Loss: 0.1610, Train: 99.17%, Valid: 67.50% Test: 76.47%\n",
      "Run: 02, Epoch: 140, Loss: 0.1714, Train: 99.17%, Valid: 67.50% Test: 78.43%\n",
      "Run: 02, Epoch: 141, Loss: 0.2063, Train: 99.17%, Valid: 67.50% Test: 80.39%\n",
      "Run: 02, Epoch: 142, Loss: 0.1752, Train: 99.17%, Valid: 66.25% Test: 80.39%\n",
      "Run: 02, Epoch: 143, Loss: 0.2035, Train: 99.17%, Valid: 68.75% Test: 78.43%\n",
      "Run: 02, Epoch: 144, Loss: 0.1539, Train: 99.17%, Valid: 68.75% Test: 78.43%\n",
      "Run: 02, Epoch: 145, Loss: 0.1819, Train: 99.17%, Valid: 68.75% Test: 78.43%\n",
      "Run: 02, Epoch: 146, Loss: 0.1785, Train: 99.17%, Valid: 68.75% Test: 78.43%\n",
      "Run: 02, Epoch: 147, Loss: 0.1505, Train: 99.17%, Valid: 68.75% Test: 78.43%\n",
      "Run: 02, Epoch: 148, Loss: 0.1669, Train: 99.17%, Valid: 68.75% Test: 78.43%\n",
      "Run: 02, Epoch: 149, Loss: 0.1463, Train: 99.17%, Valid: 66.25% Test: 78.43%\n",
      "Run: 02, Epoch: 150, Loss: 0.2046, Train: 99.17%, Valid: 66.25% Test: 78.43%\n",
      "Run: 02, Epoch: 151, Loss: 0.1761, Train: 99.17%, Valid: 66.25% Test: 78.43%\n",
      "Run: 02, Epoch: 152, Loss: 0.1675, Train: 99.17%, Valid: 68.75% Test: 76.47%\n",
      "Run: 02, Epoch: 153, Loss: 0.1598, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 154, Loss: 0.1539, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 155, Loss: 0.1359, Train: 99.17%, Valid: 70.00% Test: 74.51%\n",
      "Run: 02, Epoch: 156, Loss: 0.1542, Train: 99.17%, Valid: 71.25% Test: 74.51%\n",
      "Run: 02, Epoch: 157, Loss: 0.1766, Train: 99.17%, Valid: 71.25% Test: 74.51%\n",
      "Run: 02, Epoch: 158, Loss: 0.1498, Train: 99.17%, Valid: 71.25% Test: 74.51%\n",
      "Run: 02, Epoch: 159, Loss: 0.1701, Train: 99.17%, Valid: 71.25% Test: 74.51%\n",
      "Run: 02, Epoch: 160, Loss: 0.1453, Train: 99.17%, Valid: 71.25% Test: 74.51%\n",
      "Run: 02, Epoch: 161, Loss: 0.1702, Train: 99.17%, Valid: 72.50% Test: 74.51%\n",
      "Run: 02, Epoch: 162, Loss: 0.1670, Train: 99.17%, Valid: 72.50% Test: 74.51%\n",
      "Run: 02, Epoch: 163, Loss: 0.1455, Train: 99.17%, Valid: 72.50% Test: 76.47%\n",
      "Run: 02, Epoch: 164, Loss: 0.1311, Train: 99.17%, Valid: 73.75% Test: 76.47%\n",
      "Run: 02, Epoch: 165, Loss: 0.1787, Train: 99.17%, Valid: 73.75% Test: 76.47%\n",
      "Run: 02, Epoch: 166, Loss: 0.1444, Train: 99.17%, Valid: 72.50% Test: 76.47%\n",
      "Run: 02, Epoch: 167, Loss: 0.1239, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 168, Loss: 0.1384, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 169, Loss: 0.1747, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 170, Loss: 0.1351, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 171, Loss: 0.1433, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 172, Loss: 0.1435, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 173, Loss: 0.1328, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 174, Loss: 0.1697, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 175, Loss: 0.1340, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 176, Loss: 0.1601, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 177, Loss: 0.1678, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 178, Loss: 0.1471, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 179, Loss: 0.1426, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 180, Loss: 0.1445, Train: 99.17%, Valid: 71.25% Test: 76.47%\n",
      "Run: 02, Epoch: 181, Loss: 0.1421, Train: 99.17%, Valid: 70.00% Test: 78.43%\n",
      "Run: 02, Epoch: 182, Loss: 0.1600, Train: 99.17%, Valid: 70.00% Test: 78.43%\n",
      "Run: 02, Epoch: 183, Loss: 0.1469, Train: 99.17%, Valid: 70.00% Test: 78.43%\n",
      "Run: 02, Epoch: 184, Loss: 0.1263, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 185, Loss: 0.1424, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 186, Loss: 0.1181, Train: 99.17%, Valid: 70.00% Test: 74.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 187, Loss: 0.1216, Train: 99.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 02, Epoch: 188, Loss: 0.1591, Train: 99.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 02, Epoch: 189, Loss: 0.1481, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 190, Loss: 0.1304, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 191, Loss: 0.1678, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 192, Loss: 0.1360, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 193, Loss: 0.1245, Train: 99.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 02, Epoch: 194, Loss: 0.1098, Train: 99.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 02, Epoch: 195, Loss: 0.1554, Train: 99.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 02, Epoch: 196, Loss: 0.1203, Train: 99.17%, Valid: 68.75% Test: 76.47%\n",
      "Run: 02, Epoch: 197, Loss: 0.1266, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 198, Loss: 0.1188, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 199, Loss: 0.1316, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run: 02, Epoch: 200, Loss: 0.1274, Train: 99.17%, Valid: 70.00% Test: 76.47%\n",
      "Run 02:\n",
      "Highest Train: 99.17\n",
      "Highest Valid: 73.75\n",
      "  Final Train: 99.17\n",
      "   Final Test: 76.47\n",
      "Run: 03, Epoch: 01, Loss: 1.6999, Train: 9.17%, Valid: 16.25% Test: 15.69%\n",
      "Run: 03, Epoch: 02, Loss: 1.5895, Train: 9.17%, Valid: 16.25% Test: 15.69%\n",
      "Run: 03, Epoch: 03, Loss: 1.5026, Train: 63.33%, Valid: 53.75% Test: 60.78%\n",
      "Run: 03, Epoch: 04, Loss: 1.4300, Train: 74.17%, Valid: 61.25% Test: 64.71%\n",
      "Run: 03, Epoch: 05, Loss: 1.3459, Train: 75.83%, Valid: 63.75% Test: 68.63%\n",
      "Run: 03, Epoch: 06, Loss: 1.2913, Train: 76.67%, Valid: 66.25% Test: 70.59%\n",
      "Run: 03, Epoch: 07, Loss: 1.2231, Train: 76.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 03, Epoch: 08, Loss: 1.1639, Train: 76.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 03, Epoch: 09, Loss: 1.0963, Train: 76.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 03, Epoch: 10, Loss: 1.0344, Train: 76.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 03, Epoch: 11, Loss: 0.9985, Train: 76.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 03, Epoch: 12, Loss: 0.9630, Train: 76.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 03, Epoch: 13, Loss: 0.9037, Train: 76.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 03, Epoch: 14, Loss: 0.8544, Train: 76.67%, Valid: 66.25% Test: 72.55%\n",
      "Run: 03, Epoch: 15, Loss: 0.8379, Train: 76.67%, Valid: 67.50% Test: 70.59%\n",
      "Run: 03, Epoch: 16, Loss: 0.8198, Train: 76.67%, Valid: 67.50% Test: 70.59%\n",
      "Run: 03, Epoch: 17, Loss: 0.7910, Train: 76.67%, Valid: 68.75% Test: 68.63%\n",
      "Run: 03, Epoch: 18, Loss: 0.7763, Train: 76.67%, Valid: 68.75% Test: 64.71%\n",
      "Run: 03, Epoch: 19, Loss: 0.7605, Train: 76.67%, Valid: 68.75% Test: 64.71%\n",
      "Run: 03, Epoch: 20, Loss: 0.7560, Train: 76.67%, Valid: 67.50% Test: 66.67%\n",
      "Run: 03, Epoch: 21, Loss: 0.7092, Train: 76.67%, Valid: 66.25% Test: 66.67%\n",
      "Run: 03, Epoch: 22, Loss: 0.7308, Train: 76.67%, Valid: 66.25% Test: 66.67%\n",
      "Run: 03, Epoch: 23, Loss: 0.6944, Train: 76.67%, Valid: 66.25% Test: 66.67%\n",
      "Run: 03, Epoch: 24, Loss: 0.7014, Train: 76.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 03, Epoch: 25, Loss: 0.6772, Train: 76.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 03, Epoch: 26, Loss: 0.6562, Train: 76.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 03, Epoch: 27, Loss: 0.6599, Train: 76.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 03, Epoch: 28, Loss: 0.6690, Train: 76.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 03, Epoch: 29, Loss: 0.6426, Train: 76.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 03, Epoch: 30, Loss: 0.6409, Train: 76.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 03, Epoch: 31, Loss: 0.6278, Train: 76.67%, Valid: 65.00% Test: 68.63%\n",
      "Run: 03, Epoch: 32, Loss: 0.6034, Train: 76.67%, Valid: 63.75% Test: 68.63%\n",
      "Run: 03, Epoch: 33, Loss: 0.5995, Train: 76.67%, Valid: 63.75% Test: 66.67%\n",
      "Run: 03, Epoch: 34, Loss: 0.6045, Train: 80.00%, Valid: 65.00% Test: 66.67%\n",
      "Run: 03, Epoch: 35, Loss: 0.5871, Train: 80.83%, Valid: 65.00% Test: 66.67%\n",
      "Run: 03, Epoch: 36, Loss: 0.5947, Train: 83.33%, Valid: 65.00% Test: 66.67%\n",
      "Run: 03, Epoch: 37, Loss: 0.5655, Train: 87.50%, Valid: 65.00% Test: 64.71%\n",
      "Run: 03, Epoch: 38, Loss: 0.5667, Train: 89.17%, Valid: 65.00% Test: 64.71%\n",
      "Run: 03, Epoch: 39, Loss: 0.5581, Train: 90.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 03, Epoch: 40, Loss: 0.5451, Train: 90.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 03, Epoch: 41, Loss: 0.5622, Train: 93.33%, Valid: 67.50% Test: 64.71%\n",
      "Run: 03, Epoch: 42, Loss: 0.5323, Train: 93.33%, Valid: 67.50% Test: 62.75%\n",
      "Run: 03, Epoch: 43, Loss: 0.5402, Train: 93.33%, Valid: 67.50% Test: 62.75%\n",
      "Run: 03, Epoch: 44, Loss: 0.5239, Train: 93.33%, Valid: 67.50% Test: 62.75%\n",
      "Run: 03, Epoch: 45, Loss: 0.5171, Train: 93.33%, Valid: 67.50% Test: 62.75%\n",
      "Run: 03, Epoch: 46, Loss: 0.5415, Train: 94.17%, Valid: 67.50% Test: 62.75%\n",
      "Run: 03, Epoch: 47, Loss: 0.5052, Train: 94.17%, Valid: 67.50% Test: 62.75%\n",
      "Run: 03, Epoch: 48, Loss: 0.5265, Train: 94.17%, Valid: 65.00% Test: 62.75%\n",
      "Run: 03, Epoch: 49, Loss: 0.5335, Train: 94.17%, Valid: 65.00% Test: 62.75%\n",
      "Run: 03, Epoch: 50, Loss: 0.4760, Train: 94.17%, Valid: 63.75% Test: 62.75%\n",
      "Run: 03, Epoch: 51, Loss: 0.5261, Train: 94.17%, Valid: 63.75% Test: 62.75%\n",
      "Run: 03, Epoch: 52, Loss: 0.4894, Train: 94.17%, Valid: 65.00% Test: 64.71%\n",
      "Run: 03, Epoch: 53, Loss: 0.4928, Train: 94.17%, Valid: 63.75% Test: 64.71%\n",
      "Run: 03, Epoch: 54, Loss: 0.4936, Train: 95.00%, Valid: 63.75% Test: 64.71%\n",
      "Run: 03, Epoch: 55, Loss: 0.4618, Train: 95.83%, Valid: 63.75% Test: 64.71%\n",
      "Run: 03, Epoch: 56, Loss: 0.4695, Train: 96.67%, Valid: 62.50% Test: 64.71%\n",
      "Run: 03, Epoch: 57, Loss: 0.4839, Train: 96.67%, Valid: 62.50% Test: 64.71%\n",
      "Run: 03, Epoch: 58, Loss: 0.4533, Train: 96.67%, Valid: 62.50% Test: 62.75%\n",
      "Run: 03, Epoch: 59, Loss: 0.4463, Train: 96.67%, Valid: 62.50% Test: 62.75%\n",
      "Run: 03, Epoch: 60, Loss: 0.4701, Train: 97.50%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 61, Loss: 0.4477, Train: 97.50%, Valid: 62.50% Test: 60.78%\n",
      "Run: 03, Epoch: 62, Loss: 0.4431, Train: 97.50%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 63, Loss: 0.4333, Train: 97.50%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 64, Loss: 0.4371, Train: 97.50%, Valid: 62.50% Test: 60.78%\n",
      "Run: 03, Epoch: 65, Loss: 0.4328, Train: 97.50%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 66, Loss: 0.4474, Train: 98.33%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 67, Loss: 0.4354, Train: 99.17%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 68, Loss: 0.4112, Train: 99.17%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 69, Loss: 0.4309, Train: 99.17%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 70, Loss: 0.4036, Train: 99.17%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 71, Loss: 0.4067, Train: 99.17%, Valid: 63.75% Test: 62.75%\n",
      "Run: 03, Epoch: 72, Loss: 0.3788, Train: 99.17%, Valid: 63.75% Test: 62.75%\n",
      "Run: 03, Epoch: 73, Loss: 0.3876, Train: 100.00%, Valid: 63.75% Test: 62.75%\n",
      "Run: 03, Epoch: 74, Loss: 0.4112, Train: 100.00%, Valid: 63.75% Test: 62.75%\n",
      "Run: 03, Epoch: 75, Loss: 0.3762, Train: 100.00%, Valid: 62.50% Test: 62.75%\n",
      "Run: 03, Epoch: 76, Loss: 0.3655, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 77, Loss: 0.3638, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 78, Loss: 0.3731, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 79, Loss: 0.3824, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 80, Loss: 0.3576, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 81, Loss: 0.3540, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 82, Loss: 0.3780, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 83, Loss: 0.3525, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 84, Loss: 0.3470, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 85, Loss: 0.3199, Train: 100.00%, Valid: 58.75% Test: 62.75%\n",
      "Run: 03, Epoch: 86, Loss: 0.3674, Train: 100.00%, Valid: 58.75% Test: 62.75%\n",
      "Run: 03, Epoch: 87, Loss: 0.3194, Train: 100.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 03, Epoch: 88, Loss: 0.3547, Train: 100.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 03, Epoch: 89, Loss: 0.3009, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 90, Loss: 0.3209, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 91, Loss: 0.3239, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 92, Loss: 0.3553, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 93, Loss: 0.3017, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 94, Loss: 0.3490, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 95, Loss: 0.3547, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 96, Loss: 0.3020, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 97, Loss: 0.3214, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 98, Loss: 0.3820, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 99, Loss: 0.3314, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 100, Loss: 0.3002, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 101, Loss: 0.3160, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 102, Loss: 0.2894, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 103, Loss: 0.2941, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 104, Loss: 0.3068, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 105, Loss: 0.2692, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 106, Loss: 0.2999, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 107, Loss: 0.2701, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 108, Loss: 0.2505, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 109, Loss: 0.2797, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 110, Loss: 0.3056, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 111, Loss: 0.2940, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 112, Loss: 0.2778, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 113, Loss: 0.2507, Train: 100.00%, Valid: 61.25% Test: 62.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 114, Loss: 0.2855, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 115, Loss: 0.2813, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 116, Loss: 0.2488, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 117, Loss: 0.2518, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 118, Loss: 0.2252, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 119, Loss: 0.2635, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 120, Loss: 0.2830, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 121, Loss: 0.2703, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 122, Loss: 0.2601, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 123, Loss: 0.2336, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 124, Loss: 0.2520, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 125, Loss: 0.2785, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 126, Loss: 0.2059, Train: 100.00%, Valid: 60.00% Test: 62.75%\n",
      "Run: 03, Epoch: 127, Loss: 0.2673, Train: 100.00%, Valid: 61.25% Test: 62.75%\n",
      "Run: 03, Epoch: 128, Loss: 0.2137, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 129, Loss: 0.2812, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 130, Loss: 0.2094, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 131, Loss: 0.2240, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 132, Loss: 0.2153, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 133, Loss: 0.2274, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 134, Loss: 0.2612, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 135, Loss: 0.2292, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 136, Loss: 0.2226, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 137, Loss: 0.2337, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 138, Loss: 0.2139, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 139, Loss: 0.2507, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 140, Loss: 0.2330, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 141, Loss: 0.2019, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 142, Loss: 0.1957, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 143, Loss: 0.2415, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 144, Loss: 0.1964, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 145, Loss: 0.2370, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 146, Loss: 0.1922, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 147, Loss: 0.1878, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 148, Loss: 0.2205, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 149, Loss: 0.2053, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 150, Loss: 0.2128, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 151, Loss: 0.1679, Train: 100.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 03, Epoch: 152, Loss: 0.2342, Train: 100.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 03, Epoch: 153, Loss: 0.1745, Train: 100.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 03, Epoch: 154, Loss: 0.2087, Train: 100.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 03, Epoch: 155, Loss: 0.2217, Train: 100.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 03, Epoch: 156, Loss: 0.1721, Train: 100.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 03, Epoch: 157, Loss: 0.1782, Train: 100.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 03, Epoch: 158, Loss: 0.1569, Train: 100.00%, Valid: 58.75% Test: 62.75%\n",
      "Run: 03, Epoch: 159, Loss: 0.2179, Train: 100.00%, Valid: 57.50% Test: 62.75%\n",
      "Run: 03, Epoch: 160, Loss: 0.1900, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 161, Loss: 0.2031, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 162, Loss: 0.2038, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 163, Loss: 0.2052, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 164, Loss: 0.2114, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 165, Loss: 0.1509, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 166, Loss: 0.2131, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 167, Loss: 0.2072, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 168, Loss: 0.1643, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 169, Loss: 0.1571, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 170, Loss: 0.1611, Train: 100.00%, Valid: 57.50% Test: 60.78%\n",
      "Run: 03, Epoch: 171, Loss: 0.2038, Train: 100.00%, Valid: 57.50% Test: 58.82%\n",
      "Run: 03, Epoch: 172, Loss: 0.1708, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 173, Loss: 0.1699, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 174, Loss: 0.1620, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 175, Loss: 0.1614, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 176, Loss: 0.1716, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 177, Loss: 0.1983, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 178, Loss: 0.2014, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 179, Loss: 0.1719, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 180, Loss: 0.1705, Train: 100.00%, Valid: 58.75% Test: 60.78%\n",
      "Run: 03, Epoch: 181, Loss: 0.1727, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 182, Loss: 0.1775, Train: 100.00%, Valid: 61.25% Test: 60.78%\n",
      "Run: 03, Epoch: 183, Loss: 0.1511, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 184, Loss: 0.1480, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 185, Loss: 0.1223, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 186, Loss: 0.1468, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 187, Loss: 0.1699, Train: 100.00%, Valid: 60.00% Test: 60.78%\n",
      "Run: 03, Epoch: 188, Loss: 0.1453, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 189, Loss: 0.1335, Train: 100.00%, Valid: 60.00% Test: 58.82%\n",
      "Run: 03, Epoch: 190, Loss: 0.1285, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 191, Loss: 0.1242, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 192, Loss: 0.1520, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 193, Loss: 0.1715, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 194, Loss: 0.1926, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 195, Loss: 0.1130, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 196, Loss: 0.2086, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 197, Loss: 0.2043, Train: 100.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 03, Epoch: 198, Loss: 0.1526, Train: 100.00%, Valid: 57.50% Test: 58.82%\n",
      "Run: 03, Epoch: 199, Loss: 0.0971, Train: 100.00%, Valid: 57.50% Test: 58.82%\n",
      "Run: 03, Epoch: 200, Loss: 0.1267, Train: 100.00%, Valid: 57.50% Test: 58.82%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 68.75\n",
      "  Final Train: 76.67\n",
      "   Final Test: 68.63\n",
      "Run: 04, Epoch: 01, Loss: 1.9328, Train: 6.67%, Valid: 11.25% Test: 7.84%\n",
      "Run: 04, Epoch: 02, Loss: 1.8107, Train: 6.67%, Valid: 11.25% Test: 7.84%\n",
      "Run: 04, Epoch: 03, Loss: 1.7258, Train: 6.67%, Valid: 11.25% Test: 7.84%\n",
      "Run: 04, Epoch: 04, Loss: 1.6135, Train: 23.33%, Valid: 30.00% Test: 27.45%\n",
      "Run: 04, Epoch: 05, Loss: 1.5366, Train: 28.33%, Valid: 35.00% Test: 35.29%\n",
      "Run: 04, Epoch: 06, Loss: 1.4583, Train: 23.33%, Valid: 30.00% Test: 37.25%\n",
      "Run: 04, Epoch: 07, Loss: 1.3991, Train: 23.33%, Valid: 30.00% Test: 37.25%\n",
      "Run: 04, Epoch: 08, Loss: 1.3240, Train: 23.33%, Valid: 30.00% Test: 35.29%\n",
      "Run: 04, Epoch: 09, Loss: 1.2399, Train: 23.33%, Valid: 30.00% Test: 35.29%\n",
      "Run: 04, Epoch: 10, Loss: 1.1905, Train: 27.50%, Valid: 30.00% Test: 35.29%\n",
      "Run: 04, Epoch: 11, Loss: 1.1391, Train: 50.83%, Valid: 42.50% Test: 50.98%\n",
      "Run: 04, Epoch: 12, Loss: 1.0734, Train: 64.17%, Valid: 50.00% Test: 54.90%\n",
      "Run: 04, Epoch: 13, Loss: 1.0198, Train: 71.67%, Valid: 56.25% Test: 62.75%\n",
      "Run: 04, Epoch: 14, Loss: 1.0093, Train: 78.33%, Valid: 60.00% Test: 66.67%\n",
      "Run: 04, Epoch: 15, Loss: 0.9392, Train: 82.50%, Valid: 65.00% Test: 64.71%\n",
      "Run: 04, Epoch: 16, Loss: 0.9000, Train: 85.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 04, Epoch: 17, Loss: 0.8730, Train: 85.83%, Valid: 72.50% Test: 68.63%\n",
      "Run: 04, Epoch: 18, Loss: 0.8638, Train: 85.83%, Valid: 73.75% Test: 70.59%\n",
      "Run: 04, Epoch: 19, Loss: 0.8143, Train: 85.83%, Valid: 73.75% Test: 70.59%\n",
      "Run: 04, Epoch: 20, Loss: 0.7806, Train: 86.67%, Valid: 73.75% Test: 72.55%\n",
      "Run: 04, Epoch: 21, Loss: 0.7642, Train: 86.67%, Valid: 73.75% Test: 74.51%\n",
      "Run: 04, Epoch: 22, Loss: 0.7522, Train: 87.50%, Valid: 75.00% Test: 74.51%\n",
      "Run: 04, Epoch: 23, Loss: 0.7498, Train: 87.50%, Valid: 75.00% Test: 74.51%\n",
      "Run: 04, Epoch: 24, Loss: 0.7107, Train: 88.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 04, Epoch: 25, Loss: 0.7095, Train: 88.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 04, Epoch: 26, Loss: 0.6940, Train: 88.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 04, Epoch: 27, Loss: 0.6910, Train: 88.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 04, Epoch: 28, Loss: 0.6603, Train: 88.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 04, Epoch: 29, Loss: 0.6533, Train: 88.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 04, Epoch: 30, Loss: 0.6306, Train: 88.33%, Valid: 73.75% Test: 72.55%\n",
      "Run: 04, Epoch: 31, Loss: 0.6261, Train: 88.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 04, Epoch: 32, Loss: 0.6430, Train: 88.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 04, Epoch: 33, Loss: 0.6278, Train: 88.33%, Valid: 75.00% Test: 70.59%\n",
      "Run: 04, Epoch: 34, Loss: 0.5912, Train: 88.33%, Valid: 75.00% Test: 70.59%\n",
      "Run: 04, Epoch: 35, Loss: 0.5775, Train: 88.33%, Valid: 75.00% Test: 70.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 36, Loss: 0.5867, Train: 88.33%, Valid: 75.00% Test: 70.59%\n",
      "Run: 04, Epoch: 37, Loss: 0.5975, Train: 88.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 04, Epoch: 38, Loss: 0.5721, Train: 88.33%, Valid: 75.00% Test: 72.55%\n",
      "Run: 04, Epoch: 39, Loss: 0.5833, Train: 88.33%, Valid: 73.75% Test: 72.55%\n",
      "Run: 04, Epoch: 40, Loss: 0.5604, Train: 88.33%, Valid: 73.75% Test: 72.55%\n",
      "Run: 04, Epoch: 41, Loss: 0.5745, Train: 88.33%, Valid: 73.75% Test: 72.55%\n",
      "Run: 04, Epoch: 42, Loss: 0.5381, Train: 88.33%, Valid: 73.75% Test: 72.55%\n",
      "Run: 04, Epoch: 43, Loss: 0.5237, Train: 89.17%, Valid: 73.75% Test: 72.55%\n",
      "Run: 04, Epoch: 44, Loss: 0.5451, Train: 89.17%, Valid: 73.75% Test: 72.55%\n",
      "Run: 04, Epoch: 45, Loss: 0.5038, Train: 89.17%, Valid: 73.75% Test: 72.55%\n",
      "Run: 04, Epoch: 46, Loss: 0.5127, Train: 90.00%, Valid: 73.75% Test: 70.59%\n",
      "Run: 04, Epoch: 47, Loss: 0.5149, Train: 90.00%, Valid: 73.75% Test: 70.59%\n",
      "Run: 04, Epoch: 48, Loss: 0.5034, Train: 90.00%, Valid: 75.00% Test: 70.59%\n",
      "Run: 04, Epoch: 49, Loss: 0.4644, Train: 89.17%, Valid: 75.00% Test: 70.59%\n",
      "Run: 04, Epoch: 50, Loss: 0.4813, Train: 89.17%, Valid: 75.00% Test: 68.63%\n",
      "Run: 04, Epoch: 51, Loss: 0.4978, Train: 89.17%, Valid: 75.00% Test: 68.63%\n",
      "Run: 04, Epoch: 52, Loss: 0.4884, Train: 89.17%, Valid: 75.00% Test: 68.63%\n",
      "Run: 04, Epoch: 53, Loss: 0.4885, Train: 89.17%, Valid: 75.00% Test: 68.63%\n",
      "Run: 04, Epoch: 54, Loss: 0.4753, Train: 90.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 04, Epoch: 55, Loss: 0.4801, Train: 90.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 04, Epoch: 56, Loss: 0.4620, Train: 90.83%, Valid: 73.75% Test: 68.63%\n",
      "Run: 04, Epoch: 57, Loss: 0.4480, Train: 90.83%, Valid: 73.75% Test: 68.63%\n",
      "Run: 04, Epoch: 58, Loss: 0.4640, Train: 90.83%, Valid: 73.75% Test: 68.63%\n",
      "Run: 04, Epoch: 59, Loss: 0.4495, Train: 90.83%, Valid: 72.50% Test: 68.63%\n",
      "Run: 04, Epoch: 60, Loss: 0.4613, Train: 91.67%, Valid: 72.50% Test: 68.63%\n",
      "Run: 04, Epoch: 61, Loss: 0.4255, Train: 92.50%, Valid: 72.50% Test: 68.63%\n",
      "Run: 04, Epoch: 62, Loss: 0.4471, Train: 92.50%, Valid: 72.50% Test: 68.63%\n",
      "Run: 04, Epoch: 63, Loss: 0.4062, Train: 92.50%, Valid: 72.50% Test: 68.63%\n",
      "Run: 04, Epoch: 64, Loss: 0.4619, Train: 94.17%, Valid: 72.50% Test: 70.59%\n",
      "Run: 04, Epoch: 65, Loss: 0.3986, Train: 94.17%, Valid: 72.50% Test: 70.59%\n",
      "Run: 04, Epoch: 66, Loss: 0.4133, Train: 94.17%, Valid: 71.25% Test: 70.59%\n",
      "Run: 04, Epoch: 67, Loss: 0.4160, Train: 94.17%, Valid: 70.00% Test: 70.59%\n",
      "Run: 04, Epoch: 68, Loss: 0.4450, Train: 94.17%, Valid: 70.00% Test: 70.59%\n",
      "Run: 04, Epoch: 69, Loss: 0.4148, Train: 94.17%, Valid: 70.00% Test: 70.59%\n",
      "Run: 04, Epoch: 70, Loss: 0.4094, Train: 95.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 04, Epoch: 71, Loss: 0.3958, Train: 95.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 04, Epoch: 72, Loss: 0.3956, Train: 95.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 04, Epoch: 73, Loss: 0.3956, Train: 95.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 04, Epoch: 74, Loss: 0.3635, Train: 95.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 04, Epoch: 75, Loss: 0.4039, Train: 95.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 76, Loss: 0.4170, Train: 95.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 77, Loss: 0.3597, Train: 95.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 04, Epoch: 78, Loss: 0.3894, Train: 95.83%, Valid: 71.25% Test: 68.63%\n",
      "Run: 04, Epoch: 79, Loss: 0.3392, Train: 95.83%, Valid: 71.25% Test: 68.63%\n",
      "Run: 04, Epoch: 80, Loss: 0.3790, Train: 95.83%, Valid: 71.25% Test: 68.63%\n",
      "Run: 04, Epoch: 81, Loss: 0.3710, Train: 97.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 82, Loss: 0.3620, Train: 97.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 83, Loss: 0.3504, Train: 97.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 84, Loss: 0.3569, Train: 97.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 85, Loss: 0.3220, Train: 97.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 86, Loss: 0.3594, Train: 97.50%, Valid: 71.25% Test: 68.63%\n",
      "Run: 04, Epoch: 87, Loss: 0.3674, Train: 97.50%, Valid: 71.25% Test: 68.63%\n",
      "Run: 04, Epoch: 88, Loss: 0.3126, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 04, Epoch: 89, Loss: 0.3448, Train: 96.67%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 90, Loss: 0.3297, Train: 96.67%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 91, Loss: 0.3374, Train: 96.67%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 92, Loss: 0.3163, Train: 97.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 93, Loss: 0.3191, Train: 97.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 04, Epoch: 94, Loss: 0.3664, Train: 97.50%, Valid: 70.00% Test: 66.67%\n",
      "Run: 04, Epoch: 95, Loss: 0.3059, Train: 97.50%, Valid: 70.00% Test: 66.67%\n",
      "Run: 04, Epoch: 96, Loss: 0.2856, Train: 98.33%, Valid: 70.00% Test: 64.71%\n",
      "Run: 04, Epoch: 97, Loss: 0.3108, Train: 98.33%, Valid: 70.00% Test: 64.71%\n",
      "Run: 04, Epoch: 98, Loss: 0.3145, Train: 98.33%, Valid: 70.00% Test: 64.71%\n",
      "Run: 04, Epoch: 99, Loss: 0.3293, Train: 98.33%, Valid: 71.25% Test: 64.71%\n",
      "Run: 04, Epoch: 100, Loss: 0.3473, Train: 98.33%, Valid: 72.50% Test: 64.71%\n",
      "Run: 04, Epoch: 101, Loss: 0.3062, Train: 98.33%, Valid: 72.50% Test: 64.71%\n",
      "Run: 04, Epoch: 102, Loss: 0.3385, Train: 97.50%, Valid: 72.50% Test: 64.71%\n",
      "Run: 04, Epoch: 103, Loss: 0.3188, Train: 97.50%, Valid: 73.75% Test: 64.71%\n",
      "Run: 04, Epoch: 104, Loss: 0.3043, Train: 97.50%, Valid: 73.75% Test: 64.71%\n",
      "Run: 04, Epoch: 105, Loss: 0.2669, Train: 98.33%, Valid: 75.00% Test: 64.71%\n",
      "Run: 04, Epoch: 106, Loss: 0.2632, Train: 98.33%, Valid: 75.00% Test: 64.71%\n",
      "Run: 04, Epoch: 107, Loss: 0.3270, Train: 98.33%, Valid: 73.75% Test: 64.71%\n",
      "Run: 04, Epoch: 108, Loss: 0.2968, Train: 98.33%, Valid: 73.75% Test: 66.67%\n",
      "Run: 04, Epoch: 109, Loss: 0.2981, Train: 98.33%, Valid: 73.75% Test: 66.67%\n",
      "Run: 04, Epoch: 110, Loss: 0.2971, Train: 98.33%, Valid: 73.75% Test: 66.67%\n",
      "Run: 04, Epoch: 111, Loss: 0.2743, Train: 98.33%, Valid: 76.25% Test: 66.67%\n",
      "Run: 04, Epoch: 112, Loss: 0.2943, Train: 98.33%, Valid: 76.25% Test: 66.67%\n",
      "Run: 04, Epoch: 113, Loss: 0.2814, Train: 99.17%, Valid: 76.25% Test: 66.67%\n",
      "Run: 04, Epoch: 114, Loss: 0.2888, Train: 99.17%, Valid: 76.25% Test: 66.67%\n",
      "Run: 04, Epoch: 115, Loss: 0.2763, Train: 100.00%, Valid: 75.00% Test: 66.67%\n",
      "Run: 04, Epoch: 116, Loss: 0.2852, Train: 100.00%, Valid: 76.25% Test: 66.67%\n",
      "Run: 04, Epoch: 117, Loss: 0.2688, Train: 100.00%, Valid: 76.25% Test: 66.67%\n",
      "Run: 04, Epoch: 118, Loss: 0.2796, Train: 99.17%, Valid: 72.50% Test: 66.67%\n",
      "Run: 04, Epoch: 119, Loss: 0.2434, Train: 99.17%, Valid: 71.25% Test: 66.67%\n",
      "Run: 04, Epoch: 120, Loss: 0.2739, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 04, Epoch: 121, Loss: 0.2505, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 04, Epoch: 122, Loss: 0.2654, Train: 98.33%, Valid: 71.25% Test: 64.71%\n",
      "Run: 04, Epoch: 123, Loss: 0.2435, Train: 98.33%, Valid: 71.25% Test: 64.71%\n",
      "Run: 04, Epoch: 124, Loss: 0.2366, Train: 98.33%, Valid: 72.50% Test: 64.71%\n",
      "Run: 04, Epoch: 125, Loss: 0.2368, Train: 99.17%, Valid: 75.00% Test: 64.71%\n",
      "Run: 04, Epoch: 126, Loss: 0.2648, Train: 99.17%, Valid: 75.00% Test: 64.71%\n",
      "Run: 04, Epoch: 127, Loss: 0.2387, Train: 98.33%, Valid: 75.00% Test: 64.71%\n",
      "Run: 04, Epoch: 128, Loss: 0.2342, Train: 98.33%, Valid: 73.75% Test: 64.71%\n",
      "Run: 04, Epoch: 129, Loss: 0.2274, Train: 98.33%, Valid: 73.75% Test: 64.71%\n",
      "Run: 04, Epoch: 130, Loss: 0.2418, Train: 98.33%, Valid: 73.75% Test: 64.71%\n",
      "Run: 04, Epoch: 131, Loss: 0.2618, Train: 99.17%, Valid: 75.00% Test: 62.75%\n",
      "Run: 04, Epoch: 132, Loss: 0.2068, Train: 99.17%, Valid: 75.00% Test: 60.78%\n",
      "Run: 04, Epoch: 133, Loss: 0.2673, Train: 99.17%, Valid: 75.00% Test: 60.78%\n",
      "Run: 04, Epoch: 134, Loss: 0.2603, Train: 99.17%, Valid: 75.00% Test: 60.78%\n",
      "Run: 04, Epoch: 135, Loss: 0.2401, Train: 99.17%, Valid: 75.00% Test: 58.82%\n",
      "Run: 04, Epoch: 136, Loss: 0.2263, Train: 100.00%, Valid: 75.00% Test: 60.78%\n",
      "Run: 04, Epoch: 137, Loss: 0.2175, Train: 100.00%, Valid: 73.75% Test: 60.78%\n",
      "Run: 04, Epoch: 138, Loss: 0.2108, Train: 100.00%, Valid: 73.75% Test: 60.78%\n",
      "Run: 04, Epoch: 139, Loss: 0.2191, Train: 100.00%, Valid: 75.00% Test: 60.78%\n",
      "Run: 04, Epoch: 140, Loss: 0.2205, Train: 100.00%, Valid: 73.75% Test: 60.78%\n",
      "Run: 04, Epoch: 141, Loss: 0.2260, Train: 100.00%, Valid: 73.75% Test: 60.78%\n",
      "Run: 04, Epoch: 142, Loss: 0.2411, Train: 100.00%, Valid: 75.00% Test: 60.78%\n",
      "Run: 04, Epoch: 143, Loss: 0.2589, Train: 100.00%, Valid: 73.75% Test: 60.78%\n",
      "Run: 04, Epoch: 144, Loss: 0.2267, Train: 100.00%, Valid: 72.50% Test: 60.78%\n",
      "Run: 04, Epoch: 145, Loss: 0.2408, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 04, Epoch: 146, Loss: 0.2495, Train: 99.17%, Valid: 71.25% Test: 62.75%\n",
      "Run: 04, Epoch: 147, Loss: 0.2196, Train: 99.17%, Valid: 71.25% Test: 60.78%\n",
      "Run: 04, Epoch: 148, Loss: 0.2100, Train: 99.17%, Valid: 71.25% Test: 62.75%\n",
      "Run: 04, Epoch: 149, Loss: 0.2618, Train: 99.17%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 150, Loss: 0.2118, Train: 99.17%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 151, Loss: 0.2040, Train: 99.17%, Valid: 71.25% Test: 62.75%\n",
      "Run: 04, Epoch: 152, Loss: 0.1877, Train: 99.17%, Valid: 71.25% Test: 62.75%\n",
      "Run: 04, Epoch: 153, Loss: 0.2450, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 154, Loss: 0.1735, Train: 100.00%, Valid: 70.00% Test: 62.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 155, Loss: 0.1726, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 156, Loss: 0.1958, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 157, Loss: 0.2052, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 158, Loss: 0.2208, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 04, Epoch: 159, Loss: 0.2242, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 04, Epoch: 160, Loss: 0.1916, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 161, Loss: 0.1819, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 162, Loss: 0.1709, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 04, Epoch: 163, Loss: 0.1888, Train: 100.00%, Valid: 67.50% Test: 60.78%\n",
      "Run: 04, Epoch: 164, Loss: 0.2108, Train: 99.17%, Valid: 67.50% Test: 60.78%\n",
      "Run: 04, Epoch: 165, Loss: 0.1916, Train: 99.17%, Valid: 67.50% Test: 60.78%\n",
      "Run: 04, Epoch: 166, Loss: 0.1811, Train: 99.17%, Valid: 67.50% Test: 62.75%\n",
      "Run: 04, Epoch: 167, Loss: 0.1962, Train: 99.17%, Valid: 67.50% Test: 60.78%\n",
      "Run: 04, Epoch: 168, Loss: 0.1913, Train: 100.00%, Valid: 67.50% Test: 60.78%\n",
      "Run: 04, Epoch: 169, Loss: 0.1719, Train: 100.00%, Valid: 66.25% Test: 60.78%\n",
      "Run: 04, Epoch: 170, Loss: 0.2352, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 04, Epoch: 171, Loss: 0.1886, Train: 100.00%, Valid: 66.25% Test: 62.75%\n",
      "Run: 04, Epoch: 172, Loss: 0.1917, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 04, Epoch: 173, Loss: 0.1796, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 174, Loss: 0.1913, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 175, Loss: 0.1728, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 04, Epoch: 176, Loss: 0.1927, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 04, Epoch: 177, Loss: 0.1713, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 04, Epoch: 178, Loss: 0.1732, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 04, Epoch: 179, Loss: 0.1816, Train: 100.00%, Valid: 68.75% Test: 60.78%\n",
      "Run: 04, Epoch: 180, Loss: 0.1833, Train: 100.00%, Valid: 68.75% Test: 60.78%\n",
      "Run: 04, Epoch: 181, Loss: 0.2126, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 04, Epoch: 182, Loss: 0.1763, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 04, Epoch: 183, Loss: 0.1589, Train: 99.17%, Valid: 68.75% Test: 62.75%\n",
      "Run: 04, Epoch: 184, Loss: 0.1851, Train: 99.17%, Valid: 68.75% Test: 62.75%\n",
      "Run: 04, Epoch: 185, Loss: 0.1608, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 04, Epoch: 186, Loss: 0.1647, Train: 99.17%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 187, Loss: 0.2294, Train: 99.17%, Valid: 71.25% Test: 62.75%\n",
      "Run: 04, Epoch: 188, Loss: 0.1799, Train: 99.17%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 189, Loss: 0.1826, Train: 99.17%, Valid: 68.75% Test: 62.75%\n",
      "Run: 04, Epoch: 190, Loss: 0.1925, Train: 99.17%, Valid: 68.75% Test: 64.71%\n",
      "Run: 04, Epoch: 191, Loss: 0.1694, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 04, Epoch: 192, Loss: 0.1767, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 04, Epoch: 193, Loss: 0.1435, Train: 99.17%, Valid: 68.75% Test: 64.71%\n",
      "Run: 04, Epoch: 194, Loss: 0.1571, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 04, Epoch: 195, Loss: 0.1707, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 04, Epoch: 196, Loss: 0.1833, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 04, Epoch: 197, Loss: 0.1728, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 198, Loss: 0.1900, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 04, Epoch: 199, Loss: 0.1628, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 04, Epoch: 200, Loss: 0.1586, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run 04:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 76.25\n",
      "  Final Train: 98.33\n",
      "   Final Test: 66.67\n",
      "Run: 05, Epoch: 01, Loss: 1.8640, Train: 14.17%, Valid: 12.50% Test: 9.80%\n",
      "Run: 05, Epoch: 02, Loss: 1.7503, Train: 27.50%, Valid: 22.50% Test: 37.25%\n",
      "Run: 05, Epoch: 03, Loss: 1.6600, Train: 27.50%, Valid: 22.50% Test: 37.25%\n",
      "Run: 05, Epoch: 04, Loss: 1.5679, Train: 27.50%, Valid: 22.50% Test: 37.25%\n",
      "Run: 05, Epoch: 05, Loss: 1.4981, Train: 27.50%, Valid: 22.50% Test: 37.25%\n",
      "Run: 05, Epoch: 06, Loss: 1.4244, Train: 27.50%, Valid: 22.50% Test: 37.25%\n",
      "Run: 05, Epoch: 07, Loss: 1.3565, Train: 27.50%, Valid: 22.50% Test: 37.25%\n",
      "Run: 05, Epoch: 08, Loss: 1.2815, Train: 27.50%, Valid: 22.50% Test: 37.25%\n",
      "Run: 05, Epoch: 09, Loss: 1.2054, Train: 27.50%, Valid: 22.50% Test: 37.25%\n",
      "Run: 05, Epoch: 10, Loss: 1.1512, Train: 30.83%, Valid: 22.50% Test: 39.22%\n",
      "Run: 05, Epoch: 11, Loss: 1.1114, Train: 35.00%, Valid: 23.75% Test: 43.14%\n",
      "Run: 05, Epoch: 12, Loss: 1.0584, Train: 59.17%, Valid: 50.00% Test: 52.94%\n",
      "Run: 05, Epoch: 13, Loss: 0.9902, Train: 71.67%, Valid: 58.75% Test: 64.71%\n",
      "Run: 05, Epoch: 14, Loss: 0.9567, Train: 75.00%, Valid: 65.00% Test: 72.55%\n",
      "Run: 05, Epoch: 15, Loss: 0.9215, Train: 75.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 05, Epoch: 16, Loss: 0.8907, Train: 75.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 05, Epoch: 17, Loss: 0.8666, Train: 75.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 05, Epoch: 18, Loss: 0.8208, Train: 74.17%, Valid: 66.25% Test: 66.67%\n",
      "Run: 05, Epoch: 19, Loss: 0.8092, Train: 75.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 05, Epoch: 20, Loss: 0.7795, Train: 75.83%, Valid: 66.25% Test: 66.67%\n",
      "Run: 05, Epoch: 21, Loss: 0.7825, Train: 75.83%, Valid: 66.25% Test: 66.67%\n",
      "Run: 05, Epoch: 22, Loss: 0.7368, Train: 79.17%, Valid: 66.25% Test: 66.67%\n",
      "Run: 05, Epoch: 23, Loss: 0.7234, Train: 80.83%, Valid: 66.25% Test: 66.67%\n",
      "Run: 05, Epoch: 24, Loss: 0.7066, Train: 80.83%, Valid: 67.50% Test: 68.63%\n",
      "Run: 05, Epoch: 25, Loss: 0.7090, Train: 80.83%, Valid: 67.50% Test: 68.63%\n",
      "Run: 05, Epoch: 26, Loss: 0.6669, Train: 82.50%, Valid: 68.75% Test: 68.63%\n",
      "Run: 05, Epoch: 27, Loss: 0.6740, Train: 84.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 05, Epoch: 28, Loss: 0.6553, Train: 85.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 29, Loss: 0.6456, Train: 85.83%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 30, Loss: 0.6276, Train: 87.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 31, Loss: 0.6180, Train: 87.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 32, Loss: 0.6200, Train: 87.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 33, Loss: 0.6100, Train: 88.33%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 34, Loss: 0.5915, Train: 89.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 35, Loss: 0.5956, Train: 89.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 36, Loss: 0.5817, Train: 89.17%, Valid: 70.00% Test: 68.63%\n",
      "Run: 05, Epoch: 37, Loss: 0.6024, Train: 89.17%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 38, Loss: 0.5479, Train: 89.17%, Valid: 70.00% Test: 70.59%\n",
      "Run: 05, Epoch: 39, Loss: 0.5641, Train: 89.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 40, Loss: 0.5765, Train: 89.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 41, Loss: 0.5414, Train: 89.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 42, Loss: 0.5573, Train: 89.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 43, Loss: 0.5386, Train: 89.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 44, Loss: 0.5449, Train: 89.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 45, Loss: 0.4928, Train: 89.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 46, Loss: 0.5209, Train: 90.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 47, Loss: 0.5181, Train: 90.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 48, Loss: 0.5073, Train: 92.50%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 49, Loss: 0.4948, Train: 93.33%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 50, Loss: 0.4894, Train: 94.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 05, Epoch: 51, Loss: 0.4955, Train: 94.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 52, Loss: 0.4801, Train: 94.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 05, Epoch: 53, Loss: 0.4990, Train: 94.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 05, Epoch: 54, Loss: 0.4699, Train: 94.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 55, Loss: 0.4730, Train: 94.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 56, Loss: 0.4695, Train: 94.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 57, Loss: 0.4673, Train: 94.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 58, Loss: 0.4888, Train: 94.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 59, Loss: 0.4409, Train: 95.00%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 60, Loss: 0.4311, Train: 95.00%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 61, Loss: 0.4507, Train: 95.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 05, Epoch: 62, Loss: 0.4219, Train: 95.83%, Valid: 67.50% Test: 70.59%\n",
      "Run: 05, Epoch: 63, Loss: 0.4097, Train: 95.83%, Valid: 67.50% Test: 70.59%\n",
      "Run: 05, Epoch: 64, Loss: 0.4236, Train: 95.83%, Valid: 67.50% Test: 70.59%\n",
      "Run: 05, Epoch: 65, Loss: 0.4135, Train: 95.83%, Valid: 67.50% Test: 70.59%\n",
      "Run: 05, Epoch: 66, Loss: 0.4506, Train: 95.83%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 67, Loss: 0.4053, Train: 95.83%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 68, Loss: 0.4069, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 69, Loss: 0.3958, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 70, Loss: 0.4186, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 71, Loss: 0.4153, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 72, Loss: 0.4007, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 73, Loss: 0.4035, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 74, Loss: 0.4389, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 75, Loss: 0.3777, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 76, Loss: 0.3719, Train: 96.67%, Valid: 70.00% Test: 72.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 77, Loss: 0.3905, Train: 97.50%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 78, Loss: 0.3674, Train: 97.50%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 79, Loss: 0.3881, Train: 97.50%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 80, Loss: 0.3478, Train: 97.50%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 81, Loss: 0.3740, Train: 97.50%, Valid: 70.00% Test: 72.55%\n",
      "Run: 05, Epoch: 82, Loss: 0.3892, Train: 97.50%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 83, Loss: 0.3391, Train: 97.50%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 84, Loss: 0.3495, Train: 97.50%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 85, Loss: 0.3572, Train: 97.50%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 86, Loss: 0.3319, Train: 97.50%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 87, Loss: 0.3174, Train: 97.50%, Valid: 67.50% Test: 72.55%\n",
      "Run: 05, Epoch: 88, Loss: 0.3402, Train: 97.50%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 89, Loss: 0.3549, Train: 97.50%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 90, Loss: 0.3563, Train: 98.33%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 91, Loss: 0.3811, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 05, Epoch: 92, Loss: 0.3528, Train: 99.17%, Valid: 72.50% Test: 72.55%\n",
      "Run: 05, Epoch: 93, Loss: 0.3301, Train: 99.17%, Valid: 71.25% Test: 72.55%\n",
      "Run: 05, Epoch: 94, Loss: 0.3349, Train: 99.17%, Valid: 71.25% Test: 72.55%\n",
      "Run: 05, Epoch: 95, Loss: 0.3044, Train: 99.17%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 96, Loss: 0.3183, Train: 99.17%, Valid: 71.25% Test: 70.59%\n",
      "Run: 05, Epoch: 97, Loss: 0.3254, Train: 99.17%, Valid: 72.50% Test: 70.59%\n",
      "Run: 05, Epoch: 98, Loss: 0.3131, Train: 99.17%, Valid: 72.50% Test: 70.59%\n",
      "Run: 05, Epoch: 99, Loss: 0.3254, Train: 99.17%, Valid: 72.50% Test: 70.59%\n",
      "Run: 05, Epoch: 100, Loss: 0.2903, Train: 99.17%, Valid: 72.50% Test: 70.59%\n",
      "Run: 05, Epoch: 101, Loss: 0.3223, Train: 99.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 102, Loss: 0.2898, Train: 99.17%, Valid: 72.50% Test: 68.63%\n",
      "Run: 05, Epoch: 103, Loss: 0.2983, Train: 99.17%, Valid: 72.50% Test: 68.63%\n",
      "Run: 05, Epoch: 104, Loss: 0.2856, Train: 99.17%, Valid: 72.50% Test: 68.63%\n",
      "Run: 05, Epoch: 105, Loss: 0.3098, Train: 99.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 106, Loss: 0.3087, Train: 99.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 107, Loss: 0.2881, Train: 99.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 108, Loss: 0.2791, Train: 99.17%, Valid: 71.25% Test: 68.63%\n",
      "Run: 05, Epoch: 109, Loss: 0.3198, Train: 99.17%, Valid: 70.00% Test: 66.67%\n",
      "Run: 05, Epoch: 110, Loss: 0.3037, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 111, Loss: 0.3077, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 112, Loss: 0.2835, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 113, Loss: 0.3203, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 114, Loss: 0.2643, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 115, Loss: 0.2508, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 116, Loss: 0.2577, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 117, Loss: 0.2465, Train: 99.17%, Valid: 72.50% Test: 64.71%\n",
      "Run: 05, Epoch: 118, Loss: 0.2495, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 119, Loss: 0.3011, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 120, Loss: 0.2478, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 121, Loss: 0.2692, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 122, Loss: 0.2677, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 123, Loss: 0.2699, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 124, Loss: 0.2437, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 125, Loss: 0.2577, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 126, Loss: 0.2434, Train: 99.17%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 127, Loss: 0.2603, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 128, Loss: 0.2297, Train: 99.17%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 129, Loss: 0.2271, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 05, Epoch: 130, Loss: 0.2504, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 131, Loss: 0.2220, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 132, Loss: 0.2419, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 133, Loss: 0.2378, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 134, Loss: 0.2244, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 135, Loss: 0.2228, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 136, Loss: 0.2244, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 05, Epoch: 137, Loss: 0.2321, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 05, Epoch: 138, Loss: 0.2499, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 05, Epoch: 139, Loss: 0.2338, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 05, Epoch: 140, Loss: 0.2048, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 05, Epoch: 141, Loss: 0.1987, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 142, Loss: 0.2115, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 143, Loss: 0.2205, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 144, Loss: 0.2239, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run: 05, Epoch: 145, Loss: 0.1932, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run: 05, Epoch: 146, Loss: 0.2770, Train: 100.00%, Valid: 73.75% Test: 64.71%\n",
      "Run: 05, Epoch: 147, Loss: 0.1887, Train: 100.00%, Valid: 73.75% Test: 64.71%\n",
      "Run: 05, Epoch: 148, Loss: 0.1961, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run: 05, Epoch: 149, Loss: 0.2057, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run: 05, Epoch: 150, Loss: 0.2059, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run: 05, Epoch: 151, Loss: 0.1800, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run: 05, Epoch: 152, Loss: 0.2234, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 153, Loss: 0.2162, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 154, Loss: 0.2126, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 155, Loss: 0.1971, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 156, Loss: 0.1756, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 157, Loss: 0.2055, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 158, Loss: 0.1806, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 159, Loss: 0.1972, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 160, Loss: 0.2210, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 161, Loss: 0.1803, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 162, Loss: 0.1885, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 163, Loss: 0.1756, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 164, Loss: 0.1980, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 165, Loss: 0.2001, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 166, Loss: 0.1740, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 167, Loss: 0.1881, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 168, Loss: 0.1619, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 169, Loss: 0.1876, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 170, Loss: 0.1827, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 171, Loss: 0.1872, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 05, Epoch: 172, Loss: 0.1656, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 05, Epoch: 173, Loss: 0.1926, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 05, Epoch: 174, Loss: 0.1602, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 05, Epoch: 175, Loss: 0.1714, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 05, Epoch: 176, Loss: 0.1847, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 05, Epoch: 177, Loss: 0.1766, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 05, Epoch: 178, Loss: 0.1648, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 05, Epoch: 179, Loss: 0.1936, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 05, Epoch: 180, Loss: 0.1865, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 181, Loss: 0.1713, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 182, Loss: 0.1891, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 183, Loss: 0.1508, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 184, Loss: 0.1876, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 185, Loss: 0.1583, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 186, Loss: 0.1473, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 187, Loss: 0.1471, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 188, Loss: 0.1405, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 189, Loss: 0.1844, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 190, Loss: 0.1473, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 191, Loss: 0.1962, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 05, Epoch: 192, Loss: 0.1640, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 193, Loss: 0.1633, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 194, Loss: 0.1471, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 195, Loss: 0.1375, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 196, Loss: 0.1722, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 05, Epoch: 197, Loss: 0.1686, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 198, Loss: 0.1545, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 199, Loss: 0.1846, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 05, Epoch: 200, Loss: 0.1703, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run 05:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.75\n",
      "  Final Train: 100.00\n",
      "   Final Test: 64.71\n",
      "Run: 06, Epoch: 01, Loss: 1.6206, Train: 25.83%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 02, Loss: 1.4951, Train: 25.83%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 03, Loss: 1.4347, Train: 25.83%, Valid: 28.75% Test: 31.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 04, Loss: 1.3706, Train: 25.83%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 05, Loss: 1.3006, Train: 25.83%, Valid: 28.75% Test: 31.37%\n",
      "Run: 06, Epoch: 06, Loss: 1.2390, Train: 53.33%, Valid: 51.25% Test: 45.10%\n",
      "Run: 06, Epoch: 07, Loss: 1.1708, Train: 67.50%, Valid: 67.50% Test: 74.51%\n",
      "Run: 06, Epoch: 08, Loss: 1.1097, Train: 67.50%, Valid: 65.00% Test: 68.63%\n",
      "Run: 06, Epoch: 09, Loss: 1.0778, Train: 67.50%, Valid: 60.00% Test: 64.71%\n",
      "Run: 06, Epoch: 10, Loss: 1.0189, Train: 70.00%, Valid: 60.00% Test: 64.71%\n",
      "Run: 06, Epoch: 11, Loss: 0.9750, Train: 73.33%, Valid: 60.00% Test: 64.71%\n",
      "Run: 06, Epoch: 12, Loss: 0.9035, Train: 75.00%, Valid: 60.00% Test: 66.67%\n",
      "Run: 06, Epoch: 13, Loss: 0.8993, Train: 76.67%, Valid: 61.25% Test: 66.67%\n",
      "Run: 06, Epoch: 14, Loss: 0.8594, Train: 81.67%, Valid: 61.25% Test: 66.67%\n",
      "Run: 06, Epoch: 15, Loss: 0.8352, Train: 82.50%, Valid: 61.25% Test: 66.67%\n",
      "Run: 06, Epoch: 16, Loss: 0.7973, Train: 82.50%, Valid: 61.25% Test: 66.67%\n",
      "Run: 06, Epoch: 17, Loss: 0.7773, Train: 83.33%, Valid: 61.25% Test: 66.67%\n",
      "Run: 06, Epoch: 18, Loss: 0.7640, Train: 84.17%, Valid: 60.00% Test: 68.63%\n",
      "Run: 06, Epoch: 19, Loss: 0.7319, Train: 85.00%, Valid: 61.25% Test: 68.63%\n",
      "Run: 06, Epoch: 20, Loss: 0.7306, Train: 85.83%, Valid: 63.75% Test: 68.63%\n",
      "Run: 06, Epoch: 21, Loss: 0.7040, Train: 85.83%, Valid: 65.00% Test: 70.59%\n",
      "Run: 06, Epoch: 22, Loss: 0.7003, Train: 86.67%, Valid: 66.25% Test: 70.59%\n",
      "Run: 06, Epoch: 23, Loss: 0.7089, Train: 86.67%, Valid: 65.00% Test: 70.59%\n",
      "Run: 06, Epoch: 24, Loss: 0.6809, Train: 87.50%, Valid: 67.50% Test: 70.59%\n",
      "Run: 06, Epoch: 25, Loss: 0.6458, Train: 87.50%, Valid: 67.50% Test: 72.55%\n",
      "Run: 06, Epoch: 26, Loss: 0.6602, Train: 88.33%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 27, Loss: 0.6314, Train: 88.33%, Valid: 68.75% Test: 72.55%\n",
      "Run: 06, Epoch: 28, Loss: 0.6529, Train: 88.33%, Valid: 70.00% Test: 72.55%\n",
      "Run: 06, Epoch: 29, Loss: 0.6217, Train: 89.17%, Valid: 68.75% Test: 74.51%\n",
      "Run: 06, Epoch: 30, Loss: 0.6058, Train: 91.67%, Valid: 68.75% Test: 76.47%\n",
      "Run: 06, Epoch: 31, Loss: 0.6222, Train: 91.67%, Valid: 68.75% Test: 76.47%\n",
      "Run: 06, Epoch: 32, Loss: 0.5776, Train: 92.50%, Valid: 70.00% Test: 74.51%\n",
      "Run: 06, Epoch: 33, Loss: 0.6109, Train: 93.33%, Valid: 71.25% Test: 74.51%\n",
      "Run: 06, Epoch: 34, Loss: 0.5741, Train: 93.33%, Valid: 73.75% Test: 74.51%\n",
      "Run: 06, Epoch: 35, Loss: 0.5576, Train: 94.17%, Valid: 73.75% Test: 74.51%\n",
      "Run: 06, Epoch: 36, Loss: 0.5647, Train: 94.17%, Valid: 75.00% Test: 74.51%\n",
      "Run: 06, Epoch: 37, Loss: 0.5668, Train: 95.00%, Valid: 75.00% Test: 74.51%\n",
      "Run: 06, Epoch: 38, Loss: 0.5244, Train: 95.00%, Valid: 75.00% Test: 74.51%\n",
      "Run: 06, Epoch: 39, Loss: 0.5442, Train: 95.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 06, Epoch: 40, Loss: 0.5284, Train: 95.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 06, Epoch: 41, Loss: 0.5012, Train: 95.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 06, Epoch: 42, Loss: 0.4984, Train: 95.00%, Valid: 75.00% Test: 72.55%\n",
      "Run: 06, Epoch: 43, Loss: 0.5168, Train: 95.00%, Valid: 73.75% Test: 74.51%\n",
      "Run: 06, Epoch: 44, Loss: 0.4860, Train: 95.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 06, Epoch: 45, Loss: 0.4899, Train: 95.83%, Valid: 73.75% Test: 72.55%\n",
      "Run: 06, Epoch: 46, Loss: 0.4751, Train: 95.83%, Valid: 73.75% Test: 72.55%\n",
      "Run: 06, Epoch: 47, Loss: 0.4628, Train: 96.67%, Valid: 75.00% Test: 72.55%\n",
      "Run: 06, Epoch: 48, Loss: 0.4722, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 06, Epoch: 49, Loss: 0.4754, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 06, Epoch: 50, Loss: 0.4744, Train: 96.67%, Valid: 75.00% Test: 70.59%\n",
      "Run: 06, Epoch: 51, Loss: 0.4647, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 06, Epoch: 52, Loss: 0.4324, Train: 96.67%, Valid: 73.75% Test: 70.59%\n",
      "Run: 06, Epoch: 53, Loss: 0.4601, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 06, Epoch: 54, Loss: 0.4308, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 06, Epoch: 55, Loss: 0.4463, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 06, Epoch: 56, Loss: 0.4629, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 06, Epoch: 57, Loss: 0.4488, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 06, Epoch: 58, Loss: 0.4332, Train: 96.67%, Valid: 73.75% Test: 68.63%\n",
      "Run: 06, Epoch: 59, Loss: 0.4091, Train: 96.67%, Valid: 72.50% Test: 70.59%\n",
      "Run: 06, Epoch: 60, Loss: 0.4061, Train: 96.67%, Valid: 72.50% Test: 70.59%\n",
      "Run: 06, Epoch: 61, Loss: 0.3963, Train: 96.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 62, Loss: 0.3870, Train: 96.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 63, Loss: 0.3845, Train: 96.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 64, Loss: 0.4023, Train: 96.67%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 65, Loss: 0.4109, Train: 96.67%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 66, Loss: 0.4020, Train: 96.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 67, Loss: 0.3833, Train: 96.67%, Valid: 71.25% Test: 72.55%\n",
      "Run: 06, Epoch: 68, Loss: 0.3842, Train: 96.67%, Valid: 71.25% Test: 72.55%\n",
      "Run: 06, Epoch: 69, Loss: 0.3622, Train: 96.67%, Valid: 71.25% Test: 72.55%\n",
      "Run: 06, Epoch: 70, Loss: 0.3765, Train: 96.67%, Valid: 71.25% Test: 72.55%\n",
      "Run: 06, Epoch: 71, Loss: 0.3314, Train: 96.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 72, Loss: 0.3574, Train: 96.67%, Valid: 70.00% Test: 68.63%\n",
      "Run: 06, Epoch: 73, Loss: 0.3372, Train: 96.67%, Valid: 68.75% Test: 68.63%\n",
      "Run: 06, Epoch: 74, Loss: 0.3442, Train: 96.67%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 75, Loss: 0.3511, Train: 96.67%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 76, Loss: 0.3594, Train: 96.67%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 77, Loss: 0.3568, Train: 96.67%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 78, Loss: 0.3383, Train: 96.67%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 79, Loss: 0.3041, Train: 96.67%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 80, Loss: 0.3646, Train: 96.67%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 81, Loss: 0.3422, Train: 96.67%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 82, Loss: 0.3346, Train: 96.67%, Valid: 70.00% Test: 68.63%\n",
      "Run: 06, Epoch: 83, Loss: 0.3287, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 84, Loss: 0.3181, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 85, Loss: 0.3174, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 86, Loss: 0.3142, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 87, Loss: 0.3104, Train: 96.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 88, Loss: 0.3195, Train: 96.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 89, Loss: 0.3014, Train: 96.67%, Valid: 71.25% Test: 70.59%\n",
      "Run: 06, Epoch: 90, Loss: 0.2989, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 91, Loss: 0.3350, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 92, Loss: 0.2687, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 93, Loss: 0.2779, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 94, Loss: 0.2785, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 95, Loss: 0.3032, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 96, Loss: 0.2781, Train: 96.67%, Valid: 71.25% Test: 68.63%\n",
      "Run: 06, Epoch: 97, Loss: 0.2589, Train: 96.67%, Valid: 71.25% Test: 66.67%\n",
      "Run: 06, Epoch: 98, Loss: 0.2810, Train: 96.67%, Valid: 71.25% Test: 64.71%\n",
      "Run: 06, Epoch: 99, Loss: 0.2457, Train: 96.67%, Valid: 71.25% Test: 64.71%\n",
      "Run: 06, Epoch: 100, Loss: 0.2799, Train: 96.67%, Valid: 71.25% Test: 64.71%\n",
      "Run: 06, Epoch: 101, Loss: 0.2369, Train: 96.67%, Valid: 71.25% Test: 66.67%\n",
      "Run: 06, Epoch: 102, Loss: 0.2694, Train: 96.67%, Valid: 71.25% Test: 66.67%\n",
      "Run: 06, Epoch: 103, Loss: 0.2722, Train: 96.67%, Valid: 71.25% Test: 64.71%\n",
      "Run: 06, Epoch: 104, Loss: 0.2646, Train: 96.67%, Valid: 71.25% Test: 66.67%\n",
      "Run: 06, Epoch: 105, Loss: 0.2927, Train: 97.50%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 106, Loss: 0.2528, Train: 97.50%, Valid: 70.00% Test: 64.71%\n",
      "Run: 06, Epoch: 107, Loss: 0.2477, Train: 97.50%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 108, Loss: 0.2796, Train: 98.33%, Valid: 70.00% Test: 64.71%\n",
      "Run: 06, Epoch: 109, Loss: 0.2442, Train: 98.33%, Valid: 70.00% Test: 64.71%\n",
      "Run: 06, Epoch: 110, Loss: 0.2542, Train: 98.33%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 111, Loss: 0.2534, Train: 99.17%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 112, Loss: 0.2482, Train: 99.17%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 113, Loss: 0.2058, Train: 99.17%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 114, Loss: 0.2641, Train: 99.17%, Valid: 67.50% Test: 64.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 115, Loss: 0.2350, Train: 99.17%, Valid: 67.50% Test: 62.75%\n",
      "Run: 06, Epoch: 116, Loss: 0.2493, Train: 99.17%, Valid: 67.50% Test: 62.75%\n",
      "Run: 06, Epoch: 117, Loss: 0.2444, Train: 99.17%, Valid: 67.50% Test: 62.75%\n",
      "Run: 06, Epoch: 118, Loss: 0.2109, Train: 99.17%, Valid: 67.50% Test: 62.75%\n",
      "Run: 06, Epoch: 119, Loss: 0.2156, Train: 99.17%, Valid: 67.50% Test: 62.75%\n",
      "Run: 06, Epoch: 120, Loss: 0.2010, Train: 99.17%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 121, Loss: 0.2331, Train: 99.17%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 122, Loss: 0.2329, Train: 99.17%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 123, Loss: 0.2139, Train: 99.17%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 124, Loss: 0.2126, Train: 99.17%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 125, Loss: 0.2356, Train: 99.17%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 126, Loss: 0.2046, Train: 99.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 06, Epoch: 127, Loss: 0.2085, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 06, Epoch: 128, Loss: 0.2394, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 06, Epoch: 129, Loss: 0.2328, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 06, Epoch: 130, Loss: 0.2086, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 06, Epoch: 131, Loss: 0.1970, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 132, Loss: 0.2006, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 133, Loss: 0.1767, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 134, Loss: 0.1883, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 135, Loss: 0.2008, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 136, Loss: 0.2117, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 137, Loss: 0.1837, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 138, Loss: 0.2294, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 139, Loss: 0.1727, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 06, Epoch: 140, Loss: 0.1950, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 06, Epoch: 141, Loss: 0.1754, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 06, Epoch: 142, Loss: 0.2066, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 06, Epoch: 143, Loss: 0.1832, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 06, Epoch: 144, Loss: 0.1660, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 145, Loss: 0.2121, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 146, Loss: 0.1602, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 147, Loss: 0.1686, Train: 100.00%, Valid: 68.75% Test: 60.78%\n",
      "Run: 06, Epoch: 148, Loss: 0.1421, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 149, Loss: 0.1671, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 150, Loss: 0.2099, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 06, Epoch: 151, Loss: 0.1971, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 152, Loss: 0.1413, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 06, Epoch: 153, Loss: 0.1466, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 154, Loss: 0.1677, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 155, Loss: 0.1758, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 156, Loss: 0.1615, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 157, Loss: 0.1519, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 06, Epoch: 158, Loss: 0.1674, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 159, Loss: 0.2024, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 160, Loss: 0.1525, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 06, Epoch: 161, Loss: 0.1580, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 162, Loss: 0.1679, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 163, Loss: 0.1623, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 06, Epoch: 164, Loss: 0.1538, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 06, Epoch: 165, Loss: 0.1453, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 06, Epoch: 166, Loss: 0.1480, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 06, Epoch: 167, Loss: 0.1368, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 06, Epoch: 168, Loss: 0.1593, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 169, Loss: 0.1383, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 170, Loss: 0.1300, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 171, Loss: 0.1230, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 172, Loss: 0.1311, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 06, Epoch: 173, Loss: 0.1441, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 06, Epoch: 174, Loss: 0.1346, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 06, Epoch: 175, Loss: 0.1591, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 06, Epoch: 176, Loss: 0.1426, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 177, Loss: 0.1295, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 06, Epoch: 178, Loss: 0.1036, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 06, Epoch: 179, Loss: 0.1302, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 06, Epoch: 180, Loss: 0.1252, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 06, Epoch: 181, Loss: 0.1829, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 06, Epoch: 182, Loss: 0.1283, Train: 100.00%, Valid: 65.00% Test: 68.63%\n",
      "Run: 06, Epoch: 183, Loss: 0.1408, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 06, Epoch: 184, Loss: 0.1292, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 06, Epoch: 185, Loss: 0.1128, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 06, Epoch: 186, Loss: 0.1314, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 06, Epoch: 187, Loss: 0.1439, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 06, Epoch: 188, Loss: 0.1181, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 06, Epoch: 189, Loss: 0.1238, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 06, Epoch: 190, Loss: 0.1311, Train: 100.00%, Valid: 66.25% Test: 70.59%\n",
      "Run: 06, Epoch: 191, Loss: 0.1109, Train: 100.00%, Valid: 66.25% Test: 70.59%\n",
      "Run: 06, Epoch: 192, Loss: 0.1222, Train: 100.00%, Valid: 66.25% Test: 70.59%\n",
      "Run: 06, Epoch: 193, Loss: 0.1343, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 06, Epoch: 194, Loss: 0.1596, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 06, Epoch: 195, Loss: 0.1220, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 196, Loss: 0.1066, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 197, Loss: 0.1220, Train: 100.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 06, Epoch: 198, Loss: 0.1311, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 199, Loss: 0.1377, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 06, Epoch: 200, Loss: 0.1372, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run 06:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 75.00\n",
      "  Final Train: 94.17\n",
      "   Final Test: 74.51\n",
      "Run: 07, Epoch: 01, Loss: 1.5967, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 02, Loss: 1.4806, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 03, Loss: 1.4060, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 04, Loss: 1.3424, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 05, Loss: 1.2695, Train: 45.00%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 06, Loss: 1.1972, Train: 45.83%, Valid: 50.00% Test: 47.06%\n",
      "Run: 07, Epoch: 07, Loss: 1.1235, Train: 47.50%, Valid: 50.00% Test: 50.98%\n",
      "Run: 07, Epoch: 08, Loss: 1.0705, Train: 55.83%, Valid: 52.50% Test: 54.90%\n",
      "Run: 07, Epoch: 09, Loss: 1.0313, Train: 64.17%, Valid: 56.25% Test: 62.75%\n",
      "Run: 07, Epoch: 10, Loss: 0.9891, Train: 68.33%, Valid: 58.75% Test: 64.71%\n",
      "Run: 07, Epoch: 11, Loss: 0.9506, Train: 68.33%, Valid: 61.25% Test: 66.67%\n",
      "Run: 07, Epoch: 12, Loss: 0.8943, Train: 70.83%, Valid: 63.75% Test: 66.67%\n",
      "Run: 07, Epoch: 13, Loss: 0.8893, Train: 72.50%, Valid: 65.00% Test: 64.71%\n",
      "Run: 07, Epoch: 14, Loss: 0.8609, Train: 73.33%, Valid: 66.25% Test: 66.67%\n",
      "Run: 07, Epoch: 15, Loss: 0.8274, Train: 74.17%, Valid: 67.50% Test: 66.67%\n",
      "Run: 07, Epoch: 16, Loss: 0.7916, Train: 74.17%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 17, Loss: 0.7799, Train: 75.83%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 18, Loss: 0.7538, Train: 75.83%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 19, Loss: 0.7535, Train: 75.83%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 20, Loss: 0.7210, Train: 75.83%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 21, Loss: 0.7195, Train: 75.83%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 22, Loss: 0.7094, Train: 75.83%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 23, Loss: 0.6945, Train: 75.83%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 24, Loss: 0.7030, Train: 77.50%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 25, Loss: 0.6809, Train: 79.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 26, Loss: 0.6845, Train: 80.83%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 27, Loss: 0.6457, Train: 84.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 28, Loss: 0.6889, Train: 84.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 29, Loss: 0.6611, Train: 85.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 30, Loss: 0.6259, Train: 86.67%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 31, Loss: 0.6263, Train: 86.67%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 32, Loss: 0.6097, Train: 87.50%, Valid: 67.50% Test: 70.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 33, Loss: 0.6156, Train: 87.50%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 34, Loss: 0.6217, Train: 87.50%, Valid: 66.25% Test: 76.47%\n",
      "Run: 07, Epoch: 35, Loss: 0.5915, Train: 87.50%, Valid: 66.25% Test: 76.47%\n",
      "Run: 07, Epoch: 36, Loss: 0.6012, Train: 87.50%, Valid: 66.25% Test: 74.51%\n",
      "Run: 07, Epoch: 37, Loss: 0.5930, Train: 88.33%, Valid: 66.25% Test: 74.51%\n",
      "Run: 07, Epoch: 38, Loss: 0.5857, Train: 88.33%, Valid: 66.25% Test: 74.51%\n",
      "Run: 07, Epoch: 39, Loss: 0.5928, Train: 88.33%, Valid: 66.25% Test: 74.51%\n",
      "Run: 07, Epoch: 40, Loss: 0.5699, Train: 88.33%, Valid: 66.25% Test: 74.51%\n",
      "Run: 07, Epoch: 41, Loss: 0.5544, Train: 88.33%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 42, Loss: 0.5495, Train: 88.33%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 43, Loss: 0.5569, Train: 90.00%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 44, Loss: 0.5380, Train: 91.67%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 45, Loss: 0.5258, Train: 92.50%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 46, Loss: 0.5407, Train: 93.33%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 47, Loss: 0.5362, Train: 94.17%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 48, Loss: 0.5202, Train: 95.00%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 49, Loss: 0.5095, Train: 95.00%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 50, Loss: 0.5094, Train: 95.83%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 51, Loss: 0.4884, Train: 95.83%, Valid: 67.50% Test: 74.51%\n",
      "Run: 07, Epoch: 52, Loss: 0.5104, Train: 95.83%, Valid: 68.75% Test: 76.47%\n",
      "Run: 07, Epoch: 53, Loss: 0.5206, Train: 95.83%, Valid: 68.75% Test: 76.47%\n",
      "Run: 07, Epoch: 54, Loss: 0.4480, Train: 95.83%, Valid: 68.75% Test: 76.47%\n",
      "Run: 07, Epoch: 55, Loss: 0.4747, Train: 95.83%, Valid: 68.75% Test: 76.47%\n",
      "Run: 07, Epoch: 56, Loss: 0.4699, Train: 95.83%, Valid: 68.75% Test: 76.47%\n",
      "Run: 07, Epoch: 57, Loss: 0.4478, Train: 95.83%, Valid: 68.75% Test: 74.51%\n",
      "Run: 07, Epoch: 58, Loss: 0.4514, Train: 95.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 07, Epoch: 59, Loss: 0.4240, Train: 95.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 07, Epoch: 60, Loss: 0.4506, Train: 95.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 07, Epoch: 61, Loss: 0.4485, Train: 95.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 07, Epoch: 62, Loss: 0.4668, Train: 95.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 07, Epoch: 63, Loss: 0.4584, Train: 95.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 07, Epoch: 64, Loss: 0.4287, Train: 95.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 07, Epoch: 65, Loss: 0.4183, Train: 95.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 07, Epoch: 66, Loss: 0.4346, Train: 95.83%, Valid: 70.00% Test: 74.51%\n",
      "Run: 07, Epoch: 67, Loss: 0.4067, Train: 95.83%, Valid: 68.75% Test: 74.51%\n",
      "Run: 07, Epoch: 68, Loss: 0.4109, Train: 95.83%, Valid: 68.75% Test: 74.51%\n",
      "Run: 07, Epoch: 69, Loss: 0.3834, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 70, Loss: 0.3912, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 71, Loss: 0.4132, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 72, Loss: 0.3946, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 73, Loss: 0.3888, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 74, Loss: 0.3935, Train: 95.83%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 75, Loss: 0.3820, Train: 95.83%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 76, Loss: 0.3485, Train: 95.83%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 77, Loss: 0.3502, Train: 95.83%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 78, Loss: 0.3761, Train: 95.83%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 79, Loss: 0.3940, Train: 95.83%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 80, Loss: 0.3642, Train: 95.83%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 81, Loss: 0.3391, Train: 95.83%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 82, Loss: 0.3337, Train: 95.83%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 83, Loss: 0.3918, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 84, Loss: 0.3731, Train: 95.83%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 85, Loss: 0.3146, Train: 95.83%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 86, Loss: 0.3342, Train: 95.83%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 87, Loss: 0.3299, Train: 96.67%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 88, Loss: 0.3326, Train: 96.67%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 89, Loss: 0.3421, Train: 96.67%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 90, Loss: 0.3449, Train: 96.67%, Valid: 68.75% Test: 68.63%\n",
      "Run: 07, Epoch: 91, Loss: 0.3350, Train: 96.67%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 92, Loss: 0.2939, Train: 97.50%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 93, Loss: 0.2891, Train: 97.50%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 94, Loss: 0.3459, Train: 97.50%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 95, Loss: 0.3045, Train: 97.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 07, Epoch: 96, Loss: 0.3437, Train: 97.50%, Valid: 70.00% Test: 68.63%\n",
      "Run: 07, Epoch: 97, Loss: 0.2742, Train: 97.50%, Valid: 68.75% Test: 68.63%\n",
      "Run: 07, Epoch: 98, Loss: 0.3168, Train: 97.50%, Valid: 68.75% Test: 68.63%\n",
      "Run: 07, Epoch: 99, Loss: 0.2965, Train: 97.50%, Valid: 68.75% Test: 68.63%\n",
      "Run: 07, Epoch: 100, Loss: 0.2918, Train: 97.50%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 101, Loss: 0.3110, Train: 97.50%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 102, Loss: 0.2793, Train: 97.50%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 103, Loss: 0.2866, Train: 97.50%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 104, Loss: 0.2910, Train: 97.50%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 105, Loss: 0.3061, Train: 97.50%, Valid: 66.25% Test: 70.59%\n",
      "Run: 07, Epoch: 106, Loss: 0.2882, Train: 98.33%, Valid: 66.25% Test: 70.59%\n",
      "Run: 07, Epoch: 107, Loss: 0.2704, Train: 98.33%, Valid: 66.25% Test: 70.59%\n",
      "Run: 07, Epoch: 108, Loss: 0.2656, Train: 98.33%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 109, Loss: 0.2680, Train: 98.33%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 110, Loss: 0.2722, Train: 98.33%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 111, Loss: 0.2334, Train: 98.33%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 112, Loss: 0.2503, Train: 98.33%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 113, Loss: 0.2580, Train: 98.33%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 114, Loss: 0.2642, Train: 98.33%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 115, Loss: 0.2674, Train: 98.33%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 116, Loss: 0.2645, Train: 99.17%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 117, Loss: 0.2431, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 118, Loss: 0.3292, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 119, Loss: 0.2363, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 120, Loss: 0.2352, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 121, Loss: 0.2186, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 122, Loss: 0.2340, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 123, Loss: 0.2507, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 124, Loss: 0.2463, Train: 99.17%, Valid: 71.25% Test: 72.55%\n",
      "Run: 07, Epoch: 125, Loss: 0.2429, Train: 99.17%, Valid: 71.25% Test: 72.55%\n",
      "Run: 07, Epoch: 126, Loss: 0.2380, Train: 99.17%, Valid: 71.25% Test: 72.55%\n",
      "Run: 07, Epoch: 127, Loss: 0.2303, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 128, Loss: 0.2407, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 129, Loss: 0.2747, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 130, Loss: 0.2263, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 131, Loss: 0.2237, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 132, Loss: 0.2571, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 133, Loss: 0.1898, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 134, Loss: 0.2303, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 135, Loss: 0.2219, Train: 99.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 07, Epoch: 136, Loss: 0.2080, Train: 99.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 07, Epoch: 137, Loss: 0.1984, Train: 99.17%, Valid: 67.50% Test: 72.55%\n",
      "Run: 07, Epoch: 138, Loss: 0.2429, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 139, Loss: 0.2067, Train: 99.17%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 140, Loss: 0.1751, Train: 99.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 07, Epoch: 141, Loss: 0.2742, Train: 99.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 07, Epoch: 142, Loss: 0.2072, Train: 99.17%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 143, Loss: 0.2425, Train: 99.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 144, Loss: 0.2249, Train: 99.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 145, Loss: 0.2486, Train: 99.17%, Valid: 67.50% Test: 68.63%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 146, Loss: 0.2415, Train: 99.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 07, Epoch: 147, Loss: 0.2454, Train: 99.17%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 148, Loss: 0.1856, Train: 99.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 149, Loss: 0.2175, Train: 99.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 150, Loss: 0.2181, Train: 99.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 151, Loss: 0.1812, Train: 99.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 152, Loss: 0.2415, Train: 99.17%, Valid: 68.75% Test: 70.59%\n",
      "Run: 07, Epoch: 153, Loss: 0.2088, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 154, Loss: 0.1726, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 155, Loss: 0.1920, Train: 99.17%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 156, Loss: 0.1938, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 157, Loss: 0.1999, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 07, Epoch: 158, Loss: 0.2005, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 159, Loss: 0.1808, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 160, Loss: 0.2364, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 161, Loss: 0.2676, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 162, Loss: 0.2256, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 163, Loss: 0.1924, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 164, Loss: 0.1867, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 165, Loss: 0.2120, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 166, Loss: 0.1824, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 167, Loss: 0.1903, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 168, Loss: 0.1617, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 169, Loss: 0.1528, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 170, Loss: 0.1657, Train: 100.00%, Valid: 68.75% Test: 72.55%\n",
      "Run: 07, Epoch: 171, Loss: 0.1827, Train: 100.00%, Valid: 67.50% Test: 72.55%\n",
      "Run: 07, Epoch: 172, Loss: 0.1469, Train: 100.00%, Valid: 67.50% Test: 72.55%\n",
      "Run: 07, Epoch: 173, Loss: 0.1698, Train: 100.00%, Valid: 67.50% Test: 72.55%\n",
      "Run: 07, Epoch: 174, Loss: 0.2177, Train: 100.00%, Valid: 67.50% Test: 72.55%\n",
      "Run: 07, Epoch: 175, Loss: 0.1620, Train: 100.00%, Valid: 67.50% Test: 72.55%\n",
      "Run: 07, Epoch: 176, Loss: 0.2304, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 177, Loss: 0.2077, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 178, Loss: 0.1570, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 179, Loss: 0.1544, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 180, Loss: 0.1854, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 181, Loss: 0.1642, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 182, Loss: 0.1765, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 183, Loss: 0.1718, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 07, Epoch: 184, Loss: 0.1612, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 07, Epoch: 185, Loss: 0.1605, Train: 100.00%, Valid: 66.25% Test: 68.63%\n",
      "Run: 07, Epoch: 186, Loss: 0.1525, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 07, Epoch: 187, Loss: 0.1703, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 07, Epoch: 188, Loss: 0.1178, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 07, Epoch: 189, Loss: 0.1265, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 07, Epoch: 190, Loss: 0.1616, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 07, Epoch: 191, Loss: 0.2016, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 07, Epoch: 192, Loss: 0.1948, Train: 100.00%, Valid: 65.00% Test: 68.63%\n",
      "Run: 07, Epoch: 193, Loss: 0.1662, Train: 100.00%, Valid: 65.00% Test: 68.63%\n",
      "Run: 07, Epoch: 194, Loss: 0.1550, Train: 100.00%, Valid: 65.00% Test: 68.63%\n",
      "Run: 07, Epoch: 195, Loss: 0.1395, Train: 100.00%, Valid: 63.75% Test: 68.63%\n",
      "Run: 07, Epoch: 196, Loss: 0.1132, Train: 100.00%, Valid: 65.00% Test: 68.63%\n",
      "Run: 07, Epoch: 197, Loss: 0.1331, Train: 100.00%, Valid: 63.75% Test: 68.63%\n",
      "Run: 07, Epoch: 198, Loss: 0.1827, Train: 100.00%, Valid: 62.50% Test: 68.63%\n",
      "Run: 07, Epoch: 199, Loss: 0.1449, Train: 100.00%, Valid: 63.75% Test: 68.63%\n",
      "Run: 07, Epoch: 200, Loss: 0.1517, Train: 100.00%, Valid: 62.50% Test: 68.63%\n",
      "Run 07:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 71.25\n",
      "  Final Train: 99.17\n",
      "   Final Test: 72.55\n",
      "Run: 08, Epoch: 01, Loss: 1.5596, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 02, Loss: 1.4332, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 03, Loss: 1.3586, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 04, Loss: 1.3008, Train: 44.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 05, Loss: 1.2350, Train: 45.83%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 06, Loss: 1.1691, Train: 49.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 07, Loss: 1.1484, Train: 54.17%, Valid: 48.75% Test: 50.98%\n",
      "Run: 08, Epoch: 08, Loss: 1.0804, Train: 59.17%, Valid: 51.25% Test: 52.94%\n",
      "Run: 08, Epoch: 09, Loss: 1.0386, Train: 61.67%, Valid: 51.25% Test: 54.90%\n",
      "Run: 08, Epoch: 10, Loss: 0.9930, Train: 63.33%, Valid: 53.75% Test: 56.86%\n",
      "Run: 08, Epoch: 11, Loss: 0.9606, Train: 65.83%, Valid: 55.00% Test: 56.86%\n",
      "Run: 08, Epoch: 12, Loss: 0.9317, Train: 65.83%, Valid: 56.25% Test: 56.86%\n",
      "Run: 08, Epoch: 13, Loss: 0.9109, Train: 67.50%, Valid: 58.75% Test: 56.86%\n",
      "Run: 08, Epoch: 14, Loss: 0.8818, Train: 68.33%, Valid: 60.00% Test: 58.82%\n",
      "Run: 08, Epoch: 15, Loss: 0.8631, Train: 68.33%, Valid: 61.25% Test: 60.78%\n",
      "Run: 08, Epoch: 16, Loss: 0.8454, Train: 69.17%, Valid: 61.25% Test: 62.75%\n",
      "Run: 08, Epoch: 17, Loss: 0.8113, Train: 70.83%, Valid: 62.50% Test: 62.75%\n",
      "Run: 08, Epoch: 18, Loss: 0.8093, Train: 71.67%, Valid: 63.75% Test: 64.71%\n",
      "Run: 08, Epoch: 19, Loss: 0.7856, Train: 71.67%, Valid: 63.75% Test: 66.67%\n",
      "Run: 08, Epoch: 20, Loss: 0.7874, Train: 71.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 08, Epoch: 21, Loss: 0.7785, Train: 71.67%, Valid: 66.25% Test: 66.67%\n",
      "Run: 08, Epoch: 22, Loss: 0.7283, Train: 71.67%, Valid: 66.25% Test: 66.67%\n",
      "Run: 08, Epoch: 23, Loss: 0.7072, Train: 71.67%, Valid: 66.25% Test: 66.67%\n",
      "Run: 08, Epoch: 24, Loss: 0.7224, Train: 71.67%, Valid: 66.25% Test: 66.67%\n",
      "Run: 08, Epoch: 25, Loss: 0.7212, Train: 71.67%, Valid: 66.25% Test: 66.67%\n",
      "Run: 08, Epoch: 26, Loss: 0.6998, Train: 75.00%, Valid: 67.50% Test: 66.67%\n",
      "Run: 08, Epoch: 27, Loss: 0.6667, Train: 77.50%, Valid: 67.50% Test: 66.67%\n",
      "Run: 08, Epoch: 28, Loss: 0.6773, Train: 79.17%, Valid: 67.50% Test: 66.67%\n",
      "Run: 08, Epoch: 29, Loss: 0.6730, Train: 82.50%, Valid: 67.50% Test: 66.67%\n",
      "Run: 08, Epoch: 30, Loss: 0.6508, Train: 83.33%, Valid: 67.50% Test: 66.67%\n",
      "Run: 08, Epoch: 31, Loss: 0.6679, Train: 85.83%, Valid: 67.50% Test: 68.63%\n",
      "Run: 08, Epoch: 32, Loss: 0.6542, Train: 87.50%, Valid: 67.50% Test: 68.63%\n",
      "Run: 08, Epoch: 33, Loss: 0.6381, Train: 88.33%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 34, Loss: 0.6198, Train: 89.17%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 35, Loss: 0.6037, Train: 90.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 36, Loss: 0.6155, Train: 90.83%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 37, Loss: 0.6134, Train: 91.67%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 38, Loss: 0.6134, Train: 91.67%, Valid: 67.50% Test: 68.63%\n",
      "Run: 08, Epoch: 39, Loss: 0.5911, Train: 91.67%, Valid: 67.50% Test: 68.63%\n",
      "Run: 08, Epoch: 40, Loss: 0.5880, Train: 93.33%, Valid: 67.50% Test: 68.63%\n",
      "Run: 08, Epoch: 41, Loss: 0.6011, Train: 93.33%, Valid: 70.00% Test: 72.55%\n",
      "Run: 08, Epoch: 42, Loss: 0.5687, Train: 93.33%, Valid: 71.25% Test: 72.55%\n",
      "Run: 08, Epoch: 43, Loss: 0.5628, Train: 93.33%, Valid: 72.50% Test: 74.51%\n",
      "Run: 08, Epoch: 44, Loss: 0.5525, Train: 93.33%, Valid: 72.50% Test: 76.47%\n",
      "Run: 08, Epoch: 45, Loss: 0.5678, Train: 93.33%, Valid: 73.75% Test: 76.47%\n",
      "Run: 08, Epoch: 46, Loss: 0.5492, Train: 93.33%, Valid: 73.75% Test: 76.47%\n",
      "Run: 08, Epoch: 47, Loss: 0.5483, Train: 93.33%, Valid: 73.75% Test: 76.47%\n",
      "Run: 08, Epoch: 48, Loss: 0.5175, Train: 94.17%, Valid: 75.00% Test: 74.51%\n",
      "Run: 08, Epoch: 49, Loss: 0.5149, Train: 94.17%, Valid: 76.25% Test: 74.51%\n",
      "Run: 08, Epoch: 50, Loss: 0.5190, Train: 94.17%, Valid: 77.50% Test: 74.51%\n",
      "Run: 08, Epoch: 51, Loss: 0.5161, Train: 95.00%, Valid: 77.50% Test: 74.51%\n",
      "Run: 08, Epoch: 52, Loss: 0.5044, Train: 95.00%, Valid: 75.00% Test: 74.51%\n",
      "Run: 08, Epoch: 53, Loss: 0.4999, Train: 95.00%, Valid: 76.25% Test: 74.51%\n",
      "Run: 08, Epoch: 54, Loss: 0.4796, Train: 95.00%, Valid: 73.75% Test: 74.51%\n",
      "Run: 08, Epoch: 55, Loss: 0.4867, Train: 95.00%, Valid: 73.75% Test: 72.55%\n",
      "Run: 08, Epoch: 56, Loss: 0.4811, Train: 95.00%, Valid: 73.75% Test: 70.59%\n",
      "Run: 08, Epoch: 57, Loss: 0.4621, Train: 95.00%, Valid: 75.00% Test: 70.59%\n",
      "Run: 08, Epoch: 58, Loss: 0.4740, Train: 95.00%, Valid: 75.00% Test: 68.63%\n",
      "Run: 08, Epoch: 59, Loss: 0.4717, Train: 95.00%, Valid: 75.00% Test: 68.63%\n",
      "Run: 08, Epoch: 60, Loss: 0.4546, Train: 94.17%, Valid: 75.00% Test: 68.63%\n",
      "Run: 08, Epoch: 61, Loss: 0.4547, Train: 94.17%, Valid: 75.00% Test: 66.67%\n",
      "Run: 08, Epoch: 62, Loss: 0.4762, Train: 94.17%, Valid: 75.00% Test: 66.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 63, Loss: 0.4902, Train: 94.17%, Valid: 73.75% Test: 66.67%\n",
      "Run: 08, Epoch: 64, Loss: 0.4874, Train: 95.00%, Valid: 73.75% Test: 66.67%\n",
      "Run: 08, Epoch: 65, Loss: 0.4356, Train: 95.00%, Valid: 73.75% Test: 66.67%\n",
      "Run: 08, Epoch: 66, Loss: 0.4544, Train: 95.83%, Valid: 72.50% Test: 64.71%\n",
      "Run: 08, Epoch: 67, Loss: 0.4265, Train: 95.83%, Valid: 72.50% Test: 68.63%\n",
      "Run: 08, Epoch: 68, Loss: 0.4046, Train: 96.67%, Valid: 72.50% Test: 70.59%\n",
      "Run: 08, Epoch: 69, Loss: 0.3926, Train: 97.50%, Valid: 72.50% Test: 70.59%\n",
      "Run: 08, Epoch: 70, Loss: 0.4075, Train: 97.50%, Valid: 72.50% Test: 68.63%\n",
      "Run: 08, Epoch: 71, Loss: 0.3768, Train: 97.50%, Valid: 73.75% Test: 68.63%\n",
      "Run: 08, Epoch: 72, Loss: 0.4059, Train: 97.50%, Valid: 73.75% Test: 68.63%\n",
      "Run: 08, Epoch: 73, Loss: 0.4296, Train: 97.50%, Valid: 75.00% Test: 66.67%\n",
      "Run: 08, Epoch: 74, Loss: 0.4199, Train: 97.50%, Valid: 75.00% Test: 68.63%\n",
      "Run: 08, Epoch: 75, Loss: 0.3794, Train: 97.50%, Valid: 75.00% Test: 68.63%\n",
      "Run: 08, Epoch: 76, Loss: 0.4050, Train: 98.33%, Valid: 76.25% Test: 68.63%\n",
      "Run: 08, Epoch: 77, Loss: 0.3866, Train: 98.33%, Valid: 76.25% Test: 68.63%\n",
      "Run: 08, Epoch: 78, Loss: 0.3702, Train: 99.17%, Valid: 76.25% Test: 70.59%\n",
      "Run: 08, Epoch: 79, Loss: 0.3797, Train: 99.17%, Valid: 76.25% Test: 70.59%\n",
      "Run: 08, Epoch: 80, Loss: 0.3725, Train: 99.17%, Valid: 76.25% Test: 70.59%\n",
      "Run: 08, Epoch: 81, Loss: 0.3547, Train: 99.17%, Valid: 76.25% Test: 70.59%\n",
      "Run: 08, Epoch: 82, Loss: 0.3941, Train: 99.17%, Valid: 76.25% Test: 70.59%\n",
      "Run: 08, Epoch: 83, Loss: 0.3574, Train: 99.17%, Valid: 75.00% Test: 68.63%\n",
      "Run: 08, Epoch: 84, Loss: 0.3411, Train: 99.17%, Valid: 75.00% Test: 66.67%\n",
      "Run: 08, Epoch: 85, Loss: 0.3485, Train: 99.17%, Valid: 75.00% Test: 66.67%\n",
      "Run: 08, Epoch: 86, Loss: 0.3259, Train: 99.17%, Valid: 75.00% Test: 66.67%\n",
      "Run: 08, Epoch: 87, Loss: 0.3881, Train: 99.17%, Valid: 76.25% Test: 66.67%\n",
      "Run: 08, Epoch: 88, Loss: 0.3441, Train: 99.17%, Valid: 76.25% Test: 66.67%\n",
      "Run: 08, Epoch: 89, Loss: 0.3346, Train: 99.17%, Valid: 76.25% Test: 66.67%\n",
      "Run: 08, Epoch: 90, Loss: 0.3211, Train: 99.17%, Valid: 75.00% Test: 64.71%\n",
      "Run: 08, Epoch: 91, Loss: 0.2968, Train: 100.00%, Valid: 75.00% Test: 64.71%\n",
      "Run: 08, Epoch: 92, Loss: 0.3449, Train: 100.00%, Valid: 75.00% Test: 64.71%\n",
      "Run: 08, Epoch: 93, Loss: 0.3342, Train: 100.00%, Valid: 75.00% Test: 64.71%\n",
      "Run: 08, Epoch: 94, Loss: 0.3048, Train: 100.00%, Valid: 75.00% Test: 66.67%\n",
      "Run: 08, Epoch: 95, Loss: 0.3259, Train: 100.00%, Valid: 75.00% Test: 66.67%\n",
      "Run: 08, Epoch: 96, Loss: 0.3218, Train: 100.00%, Valid: 75.00% Test: 72.55%\n",
      "Run: 08, Epoch: 97, Loss: 0.3357, Train: 100.00%, Valid: 77.50% Test: 72.55%\n",
      "Run: 08, Epoch: 98, Loss: 0.3118, Train: 100.00%, Valid: 77.50% Test: 72.55%\n",
      "Run: 08, Epoch: 99, Loss: 0.2943, Train: 100.00%, Valid: 77.50% Test: 70.59%\n",
      "Run: 08, Epoch: 100, Loss: 0.2963, Train: 100.00%, Valid: 75.00% Test: 72.55%\n",
      "Run: 08, Epoch: 101, Loss: 0.2990, Train: 100.00%, Valid: 75.00% Test: 72.55%\n",
      "Run: 08, Epoch: 102, Loss: 0.2735, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 08, Epoch: 103, Loss: 0.3115, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 08, Epoch: 104, Loss: 0.2961, Train: 100.00%, Valid: 72.50% Test: 72.55%\n",
      "Run: 08, Epoch: 105, Loss: 0.3062, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 08, Epoch: 106, Loss: 0.3117, Train: 100.00%, Valid: 71.25% Test: 72.55%\n",
      "Run: 08, Epoch: 107, Loss: 0.3285, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 08, Epoch: 108, Loss: 0.2665, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 08, Epoch: 109, Loss: 0.3078, Train: 100.00%, Valid: 70.00% Test: 72.55%\n",
      "Run: 08, Epoch: 110, Loss: 0.2966, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 08, Epoch: 111, Loss: 0.2746, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 08, Epoch: 112, Loss: 0.2662, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 113, Loss: 0.2950, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 114, Loss: 0.2743, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 08, Epoch: 115, Loss: 0.2791, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 08, Epoch: 116, Loss: 0.2690, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 08, Epoch: 117, Loss: 0.3053, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 118, Loss: 0.2489, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 08, Epoch: 119, Loss: 0.2326, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 08, Epoch: 120, Loss: 0.2383, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 121, Loss: 0.2476, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 08, Epoch: 122, Loss: 0.2193, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 123, Loss: 0.2400, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 08, Epoch: 124, Loss: 0.2476, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 08, Epoch: 125, Loss: 0.2432, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 08, Epoch: 126, Loss: 0.2422, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 08, Epoch: 127, Loss: 0.2370, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 128, Loss: 0.2185, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 129, Loss: 0.2354, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 130, Loss: 0.1836, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 08, Epoch: 131, Loss: 0.2284, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 132, Loss: 0.2335, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 133, Loss: 0.2431, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 134, Loss: 0.2555, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 135, Loss: 0.2611, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 136, Loss: 0.1863, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 08, Epoch: 137, Loss: 0.2000, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 138, Loss: 0.2298, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 08, Epoch: 139, Loss: 0.2528, Train: 100.00%, Valid: 66.25% Test: 70.59%\n",
      "Run: 08, Epoch: 140, Loss: 0.2360, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 141, Loss: 0.2736, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 142, Loss: 0.2206, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 08, Epoch: 143, Loss: 0.2269, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 144, Loss: 0.2065, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 08, Epoch: 145, Loss: 0.2154, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 08, Epoch: 146, Loss: 0.2347, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 147, Loss: 0.1715, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 148, Loss: 0.1957, Train: 100.00%, Valid: 68.75% Test: 68.63%\n",
      "Run: 08, Epoch: 149, Loss: 0.2204, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 08, Epoch: 150, Loss: 0.1683, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 08, Epoch: 151, Loss: 0.2030, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 08, Epoch: 152, Loss: 0.1915, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 08, Epoch: 153, Loss: 0.2257, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 154, Loss: 0.2326, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 155, Loss: 0.1780, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 08, Epoch: 156, Loss: 0.1576, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 08, Epoch: 157, Loss: 0.1935, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 08, Epoch: 158, Loss: 0.1893, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 08, Epoch: 159, Loss: 0.2270, Train: 100.00%, Valid: 65.00% Test: 64.71%\n",
      "Run: 08, Epoch: 160, Loss: 0.1658, Train: 100.00%, Valid: 65.00% Test: 64.71%\n",
      "Run: 08, Epoch: 161, Loss: 0.1892, Train: 100.00%, Valid: 65.00% Test: 64.71%\n",
      "Run: 08, Epoch: 162, Loss: 0.2056, Train: 100.00%, Valid: 65.00% Test: 64.71%\n",
      "Run: 08, Epoch: 163, Loss: 0.1391, Train: 100.00%, Valid: 65.00% Test: 64.71%\n",
      "Run: 08, Epoch: 164, Loss: 0.2251, Train: 100.00%, Valid: 65.00% Test: 64.71%\n",
      "Run: 08, Epoch: 165, Loss: 0.1887, Train: 100.00%, Valid: 65.00% Test: 66.67%\n",
      "Run: 08, Epoch: 166, Loss: 0.1380, Train: 100.00%, Valid: 65.00% Test: 68.63%\n",
      "Run: 08, Epoch: 167, Loss: 0.1856, Train: 100.00%, Valid: 66.25% Test: 66.67%\n",
      "Run: 08, Epoch: 168, Loss: 0.1473, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 169, Loss: 0.1645, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 170, Loss: 0.1705, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 171, Loss: 0.1818, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 172, Loss: 0.1865, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 173, Loss: 0.1411, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 174, Loss: 0.1417, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 175, Loss: 0.1595, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 08, Epoch: 176, Loss: 0.1350, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 177, Loss: 0.1829, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 178, Loss: 0.1376, Train: 100.00%, Valid: 68.75% Test: 70.59%\n",
      "Run: 08, Epoch: 179, Loss: 0.1526, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 180, Loss: 0.1811, Train: 100.00%, Valid: 67.50% Test: 70.59%\n",
      "Run: 08, Epoch: 181, Loss: 0.1931, Train: 100.00%, Valid: 67.50% Test: 68.63%\n",
      "Run: 08, Epoch: 182, Loss: 0.1425, Train: 100.00%, Valid: 66.25% Test: 66.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 183, Loss: 0.1704, Train: 100.00%, Valid: 65.00% Test: 66.67%\n",
      "Run: 08, Epoch: 184, Loss: 0.1591, Train: 100.00%, Valid: 63.75% Test: 66.67%\n",
      "Run: 08, Epoch: 185, Loss: 0.1609, Train: 100.00%, Valid: 65.00% Test: 66.67%\n",
      "Run: 08, Epoch: 186, Loss: 0.2424, Train: 100.00%, Valid: 63.75% Test: 66.67%\n",
      "Run: 08, Epoch: 187, Loss: 0.1555, Train: 100.00%, Valid: 62.50% Test: 66.67%\n",
      "Run: 08, Epoch: 188, Loss: 0.1114, Train: 100.00%, Valid: 62.50% Test: 64.71%\n",
      "Run: 08, Epoch: 189, Loss: 0.1879, Train: 100.00%, Valid: 61.25% Test: 64.71%\n",
      "Run: 08, Epoch: 190, Loss: 0.1318, Train: 100.00%, Valid: 60.00% Test: 64.71%\n",
      "Run: 08, Epoch: 191, Loss: 0.1609, Train: 100.00%, Valid: 60.00% Test: 64.71%\n",
      "Run: 08, Epoch: 192, Loss: 0.1459, Train: 100.00%, Valid: 60.00% Test: 64.71%\n",
      "Run: 08, Epoch: 193, Loss: 0.1982, Train: 100.00%, Valid: 61.25% Test: 64.71%\n",
      "Run: 08, Epoch: 194, Loss: 0.1777, Train: 100.00%, Valid: 61.25% Test: 64.71%\n",
      "Run: 08, Epoch: 195, Loss: 0.1647, Train: 100.00%, Valid: 62.50% Test: 64.71%\n",
      "Run: 08, Epoch: 196, Loss: 0.1488, Train: 100.00%, Valid: 62.50% Test: 64.71%\n",
      "Run: 08, Epoch: 197, Loss: 0.1448, Train: 100.00%, Valid: 63.75% Test: 66.67%\n",
      "Run: 08, Epoch: 198, Loss: 0.1527, Train: 100.00%, Valid: 63.75% Test: 66.67%\n",
      "Run: 08, Epoch: 199, Loss: 0.1395, Train: 100.00%, Valid: 63.75% Test: 66.67%\n",
      "Run: 08, Epoch: 200, Loss: 0.1261, Train: 100.00%, Valid: 63.75% Test: 66.67%\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 77.50\n",
      "  Final Train: 94.17\n",
      "   Final Test: 74.51\n",
      "Run: 09, Epoch: 01, Loss: 1.6833, Train: 8.33%, Valid: 6.25% Test: 1.96%\n",
      "Run: 09, Epoch: 02, Loss: 1.5579, Train: 23.33%, Valid: 33.75% Test: 29.41%\n",
      "Run: 09, Epoch: 03, Loss: 1.4828, Train: 23.33%, Valid: 33.75% Test: 29.41%\n",
      "Run: 09, Epoch: 04, Loss: 1.3967, Train: 24.17%, Valid: 35.00% Test: 29.41%\n",
      "Run: 09, Epoch: 05, Loss: 1.3370, Train: 46.67%, Valid: 45.00% Test: 49.02%\n",
      "Run: 09, Epoch: 06, Loss: 1.2508, Train: 66.67%, Valid: 56.25% Test: 64.71%\n",
      "Run: 09, Epoch: 07, Loss: 1.1937, Train: 72.50%, Valid: 61.25% Test: 60.78%\n",
      "Run: 09, Epoch: 08, Loss: 1.1268, Train: 75.00%, Valid: 56.25% Test: 60.78%\n",
      "Run: 09, Epoch: 09, Loss: 1.0976, Train: 75.83%, Valid: 53.75% Test: 60.78%\n",
      "Run: 09, Epoch: 10, Loss: 1.0349, Train: 76.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 09, Epoch: 11, Loss: 0.9804, Train: 76.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 09, Epoch: 12, Loss: 0.9302, Train: 76.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 09, Epoch: 13, Loss: 0.9001, Train: 76.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 09, Epoch: 14, Loss: 0.8694, Train: 76.67%, Valid: 55.00% Test: 58.82%\n",
      "Run: 09, Epoch: 15, Loss: 0.8245, Train: 76.67%, Valid: 56.25% Test: 58.82%\n",
      "Run: 09, Epoch: 16, Loss: 0.7757, Train: 76.67%, Valid: 56.25% Test: 58.82%\n",
      "Run: 09, Epoch: 17, Loss: 0.7635, Train: 76.67%, Valid: 56.25% Test: 60.78%\n",
      "Run: 09, Epoch: 18, Loss: 0.7384, Train: 76.67%, Valid: 57.50% Test: 60.78%\n",
      "Run: 09, Epoch: 19, Loss: 0.7321, Train: 76.67%, Valid: 58.75% Test: 60.78%\n",
      "Run: 09, Epoch: 20, Loss: 0.6994, Train: 76.67%, Valid: 58.75% Test: 60.78%\n",
      "Run: 09, Epoch: 21, Loss: 0.6891, Train: 76.67%, Valid: 58.75% Test: 60.78%\n",
      "Run: 09, Epoch: 22, Loss: 0.6729, Train: 76.67%, Valid: 58.75% Test: 60.78%\n",
      "Run: 09, Epoch: 23, Loss: 0.6557, Train: 76.67%, Valid: 60.00% Test: 60.78%\n",
      "Run: 09, Epoch: 24, Loss: 0.6623, Train: 76.67%, Valid: 61.25% Test: 60.78%\n",
      "Run: 09, Epoch: 25, Loss: 0.6427, Train: 76.67%, Valid: 61.25% Test: 60.78%\n",
      "Run: 09, Epoch: 26, Loss: 0.6175, Train: 76.67%, Valid: 60.00% Test: 62.75%\n",
      "Run: 09, Epoch: 27, Loss: 0.6547, Train: 77.50%, Valid: 61.25% Test: 62.75%\n",
      "Run: 09, Epoch: 28, Loss: 0.6053, Train: 78.33%, Valid: 62.50% Test: 62.75%\n",
      "Run: 09, Epoch: 29, Loss: 0.6051, Train: 80.83%, Valid: 62.50% Test: 62.75%\n",
      "Run: 09, Epoch: 30, Loss: 0.5855, Train: 82.50%, Valid: 63.75% Test: 62.75%\n",
      "Run: 09, Epoch: 31, Loss: 0.5815, Train: 82.50%, Valid: 63.75% Test: 62.75%\n",
      "Run: 09, Epoch: 32, Loss: 0.6085, Train: 84.17%, Valid: 63.75% Test: 64.71%\n",
      "Run: 09, Epoch: 33, Loss: 0.5583, Train: 85.00%, Valid: 62.50% Test: 64.71%\n",
      "Run: 09, Epoch: 34, Loss: 0.5614, Train: 89.17%, Valid: 62.50% Test: 64.71%\n",
      "Run: 09, Epoch: 35, Loss: 0.5720, Train: 89.17%, Valid: 65.00% Test: 64.71%\n",
      "Run: 09, Epoch: 36, Loss: 0.5400, Train: 90.00%, Valid: 65.00% Test: 64.71%\n",
      "Run: 09, Epoch: 37, Loss: 0.5240, Train: 90.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 38, Loss: 0.5230, Train: 93.33%, Valid: 66.25% Test: 62.75%\n",
      "Run: 09, Epoch: 39, Loss: 0.5530, Train: 94.17%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 40, Loss: 0.5283, Train: 94.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 41, Loss: 0.4960, Train: 95.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 42, Loss: 0.4802, Train: 95.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 43, Loss: 0.4918, Train: 95.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 44, Loss: 0.4965, Train: 95.83%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 45, Loss: 0.4864, Train: 95.83%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 46, Loss: 0.4741, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 47, Loss: 0.4745, Train: 95.83%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 48, Loss: 0.4531, Train: 95.83%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 49, Loss: 0.4661, Train: 95.83%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 50, Loss: 0.4768, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 51, Loss: 0.4596, Train: 95.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 09, Epoch: 52, Loss: 0.4613, Train: 95.83%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 53, Loss: 0.4272, Train: 95.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 09, Epoch: 54, Loss: 0.3926, Train: 95.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 09, Epoch: 55, Loss: 0.4253, Train: 95.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 09, Epoch: 56, Loss: 0.4144, Train: 95.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 09, Epoch: 57, Loss: 0.3970, Train: 95.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 09, Epoch: 58, Loss: 0.4015, Train: 95.83%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 59, Loss: 0.4084, Train: 95.83%, Valid: 66.25% Test: 62.75%\n",
      "Run: 09, Epoch: 60, Loss: 0.4116, Train: 95.83%, Valid: 66.25% Test: 62.75%\n",
      "Run: 09, Epoch: 61, Loss: 0.4116, Train: 95.83%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 62, Loss: 0.3833, Train: 95.83%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 63, Loss: 0.4026, Train: 95.83%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 64, Loss: 0.3828, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 65, Loss: 0.4055, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 66, Loss: 0.3713, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 67, Loss: 0.3710, Train: 95.83%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 68, Loss: 0.3626, Train: 95.83%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 69, Loss: 0.3825, Train: 95.83%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 70, Loss: 0.3253, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 71, Loss: 0.3554, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 72, Loss: 0.3597, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 73, Loss: 0.3896, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 74, Loss: 0.3418, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 75, Loss: 0.3397, Train: 95.83%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 76, Loss: 0.3467, Train: 95.83%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 77, Loss: 0.3422, Train: 95.83%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 78, Loss: 0.3694, Train: 95.83%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 79, Loss: 0.3409, Train: 95.83%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 80, Loss: 0.3320, Train: 95.83%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 81, Loss: 0.3504, Train: 95.83%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 82, Loss: 0.3075, Train: 95.83%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 83, Loss: 0.3113, Train: 95.83%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 84, Loss: 0.3064, Train: 96.67%, Valid: 72.50% Test: 64.71%\n",
      "Run: 09, Epoch: 85, Loss: 0.3179, Train: 97.50%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 86, Loss: 0.3017, Train: 97.50%, Valid: 70.00% Test: 66.67%\n",
      "Run: 09, Epoch: 87, Loss: 0.3058, Train: 97.50%, Valid: 70.00% Test: 66.67%\n",
      "Run: 09, Epoch: 88, Loss: 0.2843, Train: 98.33%, Valid: 70.00% Test: 66.67%\n",
      "Run: 09, Epoch: 89, Loss: 0.3260, Train: 98.33%, Valid: 70.00% Test: 66.67%\n",
      "Run: 09, Epoch: 90, Loss: 0.3116, Train: 98.33%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 91, Loss: 0.2730, Train: 98.33%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 92, Loss: 0.3198, Train: 98.33%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 93, Loss: 0.3236, Train: 98.33%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 94, Loss: 0.3103, Train: 97.50%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 95, Loss: 0.2703, Train: 97.50%, Valid: 71.25% Test: 66.67%\n",
      "Run: 09, Epoch: 96, Loss: 0.2785, Train: 97.50%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 97, Loss: 0.2960, Train: 98.33%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 98, Loss: 0.2875, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 99, Loss: 0.2580, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 100, Loss: 0.2652, Train: 99.17%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 101, Loss: 0.2846, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 102, Loss: 0.2865, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 103, Loss: 0.2967, Train: 100.00%, Valid: 68.75% Test: 64.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 104, Loss: 0.2496, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 105, Loss: 0.2605, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 106, Loss: 0.2746, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 107, Loss: 0.2663, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 108, Loss: 0.2118, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 109, Loss: 0.2665, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 110, Loss: 0.2469, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 09, Epoch: 111, Loss: 0.2320, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 09, Epoch: 112, Loss: 0.2110, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 09, Epoch: 113, Loss: 0.2589, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 09, Epoch: 114, Loss: 0.2385, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 09, Epoch: 115, Loss: 0.2204, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 09, Epoch: 116, Loss: 0.2157, Train: 100.00%, Valid: 67.50% Test: 62.75%\n",
      "Run: 09, Epoch: 117, Loss: 0.2215, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 118, Loss: 0.1920, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 119, Loss: 0.2467, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 120, Loss: 0.2190, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 121, Loss: 0.2443, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 122, Loss: 0.2055, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 123, Loss: 0.2140, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 124, Loss: 0.2036, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 125, Loss: 0.2032, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 126, Loss: 0.2176, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 127, Loss: 0.2376, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 128, Loss: 0.2175, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 129, Loss: 0.2074, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 130, Loss: 0.1952, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 131, Loss: 0.2229, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 132, Loss: 0.1896, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 133, Loss: 0.1796, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 134, Loss: 0.2056, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 135, Loss: 0.2233, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 136, Loss: 0.2340, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 137, Loss: 0.2052, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 138, Loss: 0.1713, Train: 100.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 09, Epoch: 139, Loss: 0.1963, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 140, Loss: 0.2168, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 141, Loss: 0.2143, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 142, Loss: 0.2072, Train: 100.00%, Valid: 67.50% Test: 64.71%\n",
      "Run: 09, Epoch: 143, Loss: 0.1902, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 144, Loss: 0.2061, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 145, Loss: 0.1829, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 146, Loss: 0.1859, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 147, Loss: 0.1868, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 148, Loss: 0.1683, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 149, Loss: 0.1740, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 150, Loss: 0.1636, Train: 100.00%, Valid: 71.25% Test: 60.78%\n",
      "Run: 09, Epoch: 151, Loss: 0.1757, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 09, Epoch: 152, Loss: 0.2263, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 09, Epoch: 153, Loss: 0.1956, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 09, Epoch: 154, Loss: 0.2102, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 09, Epoch: 155, Loss: 0.1534, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 156, Loss: 0.1789, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 157, Loss: 0.1915, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 09, Epoch: 158, Loss: 0.1495, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 09, Epoch: 159, Loss: 0.1507, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 160, Loss: 0.1625, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 161, Loss: 0.1506, Train: 100.00%, Valid: 68.75% Test: 64.71%\n",
      "Run: 09, Epoch: 162, Loss: 0.1338, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 163, Loss: 0.1640, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 164, Loss: 0.1464, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 165, Loss: 0.1947, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 166, Loss: 0.1571, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 167, Loss: 0.1684, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 168, Loss: 0.1612, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 169, Loss: 0.1420, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 170, Loss: 0.1671, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 171, Loss: 0.1393, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 09, Epoch: 172, Loss: 0.1501, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 09, Epoch: 173, Loss: 0.1455, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 174, Loss: 0.1515, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 175, Loss: 0.1450, Train: 100.00%, Valid: 70.00% Test: 62.75%\n",
      "Run: 09, Epoch: 176, Loss: 0.1597, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 177, Loss: 0.1609, Train: 100.00%, Valid: 70.00% Test: 64.71%\n",
      "Run: 09, Epoch: 178, Loss: 0.1276, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 179, Loss: 0.1469, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 180, Loss: 0.1346, Train: 100.00%, Valid: 68.75% Test: 62.75%\n",
      "Run: 09, Epoch: 181, Loss: 0.1308, Train: 100.00%, Valid: 68.75% Test: 60.78%\n",
      "Run: 09, Epoch: 182, Loss: 0.1808, Train: 100.00%, Valid: 68.75% Test: 60.78%\n",
      "Run: 09, Epoch: 183, Loss: 0.1324, Train: 100.00%, Valid: 68.75% Test: 60.78%\n",
      "Run: 09, Epoch: 184, Loss: 0.1451, Train: 100.00%, Valid: 68.75% Test: 60.78%\n",
      "Run: 09, Epoch: 185, Loss: 0.1711, Train: 100.00%, Valid: 68.75% Test: 60.78%\n",
      "Run: 09, Epoch: 186, Loss: 0.1283, Train: 100.00%, Valid: 68.75% Test: 60.78%\n",
      "Run: 09, Epoch: 187, Loss: 0.1318, Train: 100.00%, Valid: 72.50% Test: 60.78%\n",
      "Run: 09, Epoch: 188, Loss: 0.1371, Train: 100.00%, Valid: 71.25% Test: 60.78%\n",
      "Run: 09, Epoch: 189, Loss: 0.1227, Train: 100.00%, Valid: 71.25% Test: 60.78%\n",
      "Run: 09, Epoch: 190, Loss: 0.1628, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 09, Epoch: 191, Loss: 0.1285, Train: 100.00%, Valid: 68.75% Test: 60.78%\n",
      "Run: 09, Epoch: 192, Loss: 0.1368, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 09, Epoch: 193, Loss: 0.1247, Train: 100.00%, Valid: 70.00% Test: 60.78%\n",
      "Run: 09, Epoch: 194, Loss: 0.1226, Train: 100.00%, Valid: 70.00% Test: 58.82%\n",
      "Run: 09, Epoch: 195, Loss: 0.1477, Train: 100.00%, Valid: 70.00% Test: 58.82%\n",
      "Run: 09, Epoch: 196, Loss: 0.1358, Train: 100.00%, Valid: 68.75% Test: 58.82%\n",
      "Run: 09, Epoch: 197, Loss: 0.1319, Train: 100.00%, Valid: 68.75% Test: 58.82%\n",
      "Run: 09, Epoch: 198, Loss: 0.1545, Train: 100.00%, Valid: 67.50% Test: 58.82%\n",
      "Run: 09, Epoch: 199, Loss: 0.1208, Train: 100.00%, Valid: 68.75% Test: 58.82%\n",
      "Run: 09, Epoch: 200, Loss: 0.1403, Train: 100.00%, Valid: 68.75% Test: 58.82%\n",
      "Run 09:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 72.50\n",
      "  Final Train: 96.67\n",
      "   Final Test: 64.71\n",
      "Run: 10, Epoch: 01, Loss: 1.7527, Train: 5.00%, Valid: 3.75% Test: 1.96%\n",
      "Run: 10, Epoch: 02, Loss: 1.6393, Train: 5.00%, Valid: 3.75% Test: 1.96%\n",
      "Run: 10, Epoch: 03, Loss: 1.5542, Train: 7.50%, Valid: 3.75% Test: 3.92%\n",
      "Run: 10, Epoch: 04, Loss: 1.4646, Train: 48.33%, Valid: 45.00% Test: 45.10%\n",
      "Run: 10, Epoch: 05, Loss: 1.3932, Train: 48.33%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 06, Loss: 1.3126, Train: 49.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 07, Loss: 1.2299, Train: 54.17%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 08, Loss: 1.1609, Train: 55.00%, Valid: 46.25% Test: 45.10%\n",
      "Run: 10, Epoch: 09, Loss: 1.0844, Train: 60.00%, Valid: 47.50% Test: 47.06%\n",
      "Run: 10, Epoch: 10, Loss: 1.0272, Train: 61.67%, Valid: 48.75% Test: 47.06%\n",
      "Run: 10, Epoch: 11, Loss: 0.9907, Train: 63.33%, Valid: 51.25% Test: 49.02%\n",
      "Run: 10, Epoch: 12, Loss: 0.9512, Train: 67.50%, Valid: 52.50% Test: 50.98%\n",
      "Run: 10, Epoch: 13, Loss: 0.9036, Train: 71.67%, Valid: 55.00% Test: 56.86%\n",
      "Run: 10, Epoch: 14, Loss: 0.8646, Train: 72.50%, Valid: 57.50% Test: 58.82%\n",
      "Run: 10, Epoch: 15, Loss: 0.8390, Train: 75.00%, Valid: 58.75% Test: 58.82%\n",
      "Run: 10, Epoch: 16, Loss: 0.7881, Train: 75.83%, Valid: 62.50% Test: 58.82%\n",
      "Run: 10, Epoch: 17, Loss: 0.7926, Train: 76.67%, Valid: 62.50% Test: 58.82%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 18, Loss: 0.7391, Train: 76.67%, Valid: 62.50% Test: 58.82%\n",
      "Run: 10, Epoch: 19, Loss: 0.7578, Train: 77.50%, Valid: 62.50% Test: 62.75%\n",
      "Run: 10, Epoch: 20, Loss: 0.7111, Train: 77.50%, Valid: 62.50% Test: 64.71%\n",
      "Run: 10, Epoch: 21, Loss: 0.7314, Train: 77.50%, Valid: 62.50% Test: 66.67%\n",
      "Run: 10, Epoch: 22, Loss: 0.6836, Train: 77.50%, Valid: 62.50% Test: 66.67%\n",
      "Run: 10, Epoch: 23, Loss: 0.6792, Train: 77.50%, Valid: 62.50% Test: 66.67%\n",
      "Run: 10, Epoch: 24, Loss: 0.6843, Train: 77.50%, Valid: 62.50% Test: 66.67%\n",
      "Run: 10, Epoch: 25, Loss: 0.6687, Train: 78.33%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 26, Loss: 0.6653, Train: 79.17%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 27, Loss: 0.6401, Train: 81.67%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 28, Loss: 0.6287, Train: 83.33%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 29, Loss: 0.6150, Train: 84.17%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 30, Loss: 0.5975, Train: 85.00%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 31, Loss: 0.6318, Train: 85.83%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 32, Loss: 0.6159, Train: 85.83%, Valid: 63.75% Test: 64.71%\n",
      "Run: 10, Epoch: 33, Loss: 0.6004, Train: 85.83%, Valid: 65.00% Test: 64.71%\n",
      "Run: 10, Epoch: 34, Loss: 0.6038, Train: 86.67%, Valid: 65.00% Test: 66.67%\n",
      "Run: 10, Epoch: 35, Loss: 0.5673, Train: 87.50%, Valid: 65.00% Test: 66.67%\n",
      "Run: 10, Epoch: 36, Loss: 0.5569, Train: 87.50%, Valid: 65.00% Test: 66.67%\n",
      "Run: 10, Epoch: 37, Loss: 0.5404, Train: 87.50%, Valid: 65.00% Test: 66.67%\n",
      "Run: 10, Epoch: 38, Loss: 0.5764, Train: 88.33%, Valid: 65.00% Test: 66.67%\n",
      "Run: 10, Epoch: 39, Loss: 0.5469, Train: 89.17%, Valid: 65.00% Test: 64.71%\n",
      "Run: 10, Epoch: 40, Loss: 0.5469, Train: 89.17%, Valid: 65.00% Test: 62.75%\n",
      "Run: 10, Epoch: 41, Loss: 0.5437, Train: 89.17%, Valid: 65.00% Test: 62.75%\n",
      "Run: 10, Epoch: 42, Loss: 0.5288, Train: 89.17%, Valid: 65.00% Test: 64.71%\n",
      "Run: 10, Epoch: 43, Loss: 0.5350, Train: 89.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 44, Loss: 0.5495, Train: 89.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 45, Loss: 0.5056, Train: 89.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 46, Loss: 0.5185, Train: 89.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 47, Loss: 0.5168, Train: 89.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 48, Loss: 0.4743, Train: 89.17%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 49, Loss: 0.5075, Train: 90.00%, Valid: 66.25% Test: 64.71%\n",
      "Run: 10, Epoch: 50, Loss: 0.4743, Train: 91.67%, Valid: 66.25% Test: 64.71%\n",
      "Run: 10, Epoch: 51, Loss: 0.4838, Train: 91.67%, Valid: 66.25% Test: 64.71%\n",
      "Run: 10, Epoch: 52, Loss: 0.5144, Train: 91.67%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 53, Loss: 0.4625, Train: 91.67%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 54, Loss: 0.4739, Train: 91.67%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 55, Loss: 0.4993, Train: 91.67%, Valid: 67.50% Test: 64.71%\n",
      "Run: 10, Epoch: 56, Loss: 0.4617, Train: 91.67%, Valid: 66.25% Test: 64.71%\n",
      "Run: 10, Epoch: 57, Loss: 0.4788, Train: 91.67%, Valid: 66.25% Test: 64.71%\n",
      "Run: 10, Epoch: 58, Loss: 0.4752, Train: 92.50%, Valid: 66.25% Test: 68.63%\n",
      "Run: 10, Epoch: 59, Loss: 0.4545, Train: 92.50%, Valid: 66.25% Test: 68.63%\n",
      "Run: 10, Epoch: 60, Loss: 0.4506, Train: 92.50%, Valid: 66.25% Test: 70.59%\n",
      "Run: 10, Epoch: 61, Loss: 0.4480, Train: 92.50%, Valid: 66.25% Test: 70.59%\n",
      "Run: 10, Epoch: 62, Loss: 0.4404, Train: 92.50%, Valid: 66.25% Test: 70.59%\n",
      "Run: 10, Epoch: 63, Loss: 0.4450, Train: 93.33%, Valid: 65.00% Test: 70.59%\n",
      "Run: 10, Epoch: 64, Loss: 0.4116, Train: 93.33%, Valid: 65.00% Test: 68.63%\n",
      "Run: 10, Epoch: 65, Loss: 0.4213, Train: 94.17%, Valid: 65.00% Test: 68.63%\n",
      "Run: 10, Epoch: 66, Loss: 0.4111, Train: 94.17%, Valid: 65.00% Test: 68.63%\n",
      "Run: 10, Epoch: 67, Loss: 0.4457, Train: 94.17%, Valid: 65.00% Test: 66.67%\n",
      "Run: 10, Epoch: 68, Loss: 0.3919, Train: 94.17%, Valid: 65.00% Test: 66.67%\n",
      "Run: 10, Epoch: 69, Loss: 0.4130, Train: 94.17%, Valid: 65.00% Test: 66.67%\n",
      "Run: 10, Epoch: 70, Loss: 0.3879, Train: 94.17%, Valid: 65.00% Test: 68.63%\n",
      "Run: 10, Epoch: 71, Loss: 0.3871, Train: 94.17%, Valid: 65.00% Test: 68.63%\n",
      "Run: 10, Epoch: 72, Loss: 0.3885, Train: 94.17%, Valid: 65.00% Test: 68.63%\n",
      "Run: 10, Epoch: 73, Loss: 0.4006, Train: 94.17%, Valid: 65.00% Test: 68.63%\n",
      "Run: 10, Epoch: 74, Loss: 0.4294, Train: 94.17%, Valid: 65.00% Test: 68.63%\n",
      "Run: 10, Epoch: 75, Loss: 0.3941, Train: 94.17%, Valid: 66.25% Test: 68.63%\n",
      "Run: 10, Epoch: 76, Loss: 0.3811, Train: 94.17%, Valid: 66.25% Test: 68.63%\n",
      "Run: 10, Epoch: 77, Loss: 0.3944, Train: 94.17%, Valid: 66.25% Test: 68.63%\n",
      "Run: 10, Epoch: 78, Loss: 0.4104, Train: 94.17%, Valid: 66.25% Test: 68.63%\n",
      "Run: 10, Epoch: 79, Loss: 0.3706, Train: 94.17%, Valid: 66.25% Test: 68.63%\n",
      "Run: 10, Epoch: 80, Loss: 0.3614, Train: 94.17%, Valid: 67.50% Test: 68.63%\n",
      "Run: 10, Epoch: 81, Loss: 0.3854, Train: 94.17%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 82, Loss: 0.3593, Train: 94.17%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 83, Loss: 0.3683, Train: 94.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 10, Epoch: 84, Loss: 0.3998, Train: 94.17%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 85, Loss: 0.3544, Train: 94.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 10, Epoch: 86, Loss: 0.3547, Train: 94.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 10, Epoch: 87, Loss: 0.3340, Train: 94.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 10, Epoch: 88, Loss: 0.3470, Train: 94.17%, Valid: 68.75% Test: 68.63%\n",
      "Run: 10, Epoch: 89, Loss: 0.3768, Train: 95.83%, Valid: 68.75% Test: 68.63%\n",
      "Run: 10, Epoch: 90, Loss: 0.3745, Train: 95.83%, Valid: 68.75% Test: 68.63%\n",
      "Run: 10, Epoch: 91, Loss: 0.3433, Train: 95.83%, Valid: 68.75% Test: 68.63%\n",
      "Run: 10, Epoch: 92, Loss: 0.3356, Train: 96.67%, Valid: 67.50% Test: 66.67%\n",
      "Run: 10, Epoch: 93, Loss: 0.3281, Train: 96.67%, Valid: 67.50% Test: 66.67%\n",
      "Run: 10, Epoch: 94, Loss: 0.3299, Train: 97.50%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 95, Loss: 0.3619, Train: 97.50%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 96, Loss: 0.3775, Train: 98.33%, Valid: 67.50% Test: 66.67%\n",
      "Run: 10, Epoch: 97, Loss: 0.3403, Train: 98.33%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 98, Loss: 0.3002, Train: 99.17%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 99, Loss: 0.3259, Train: 99.17%, Valid: 70.00% Test: 66.67%\n",
      "Run: 10, Epoch: 100, Loss: 0.3278, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 10, Epoch: 101, Loss: 0.3007, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 102, Loss: 0.3262, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 103, Loss: 0.2837, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 10, Epoch: 104, Loss: 0.3091, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 10, Epoch: 105, Loss: 0.3198, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 10, Epoch: 106, Loss: 0.3067, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 10, Epoch: 107, Loss: 0.3011, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 10, Epoch: 108, Loss: 0.3321, Train: 100.00%, Valid: 71.25% Test: 60.78%\n",
      "Run: 10, Epoch: 109, Loss: 0.2930, Train: 100.00%, Valid: 71.25% Test: 60.78%\n",
      "Run: 10, Epoch: 110, Loss: 0.3014, Train: 100.00%, Valid: 72.50% Test: 60.78%\n",
      "Run: 10, Epoch: 111, Loss: 0.3206, Train: 100.00%, Valid: 71.25% Test: 60.78%\n",
      "Run: 10, Epoch: 112, Loss: 0.2994, Train: 100.00%, Valid: 72.50% Test: 60.78%\n",
      "Run: 10, Epoch: 113, Loss: 0.2696, Train: 100.00%, Valid: 72.50% Test: 60.78%\n",
      "Run: 10, Epoch: 114, Loss: 0.2857, Train: 100.00%, Valid: 72.50% Test: 60.78%\n",
      "Run: 10, Epoch: 115, Loss: 0.2992, Train: 100.00%, Valid: 72.50% Test: 62.75%\n",
      "Run: 10, Epoch: 116, Loss: 0.3220, Train: 100.00%, Valid: 72.50% Test: 62.75%\n",
      "Run: 10, Epoch: 117, Loss: 0.2526, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 10, Epoch: 118, Loss: 0.2826, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 10, Epoch: 119, Loss: 0.2733, Train: 100.00%, Valid: 71.25% Test: 62.75%\n",
      "Run: 10, Epoch: 120, Loss: 0.2670, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 10, Epoch: 121, Loss: 0.2730, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 10, Epoch: 122, Loss: 0.2652, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 10, Epoch: 123, Loss: 0.3107, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 124, Loss: 0.2473, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 10, Epoch: 125, Loss: 0.2466, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 126, Loss: 0.2606, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 127, Loss: 0.2538, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 128, Loss: 0.2367, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 129, Loss: 0.2806, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 130, Loss: 0.2989, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 131, Loss: 0.2396, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 132, Loss: 0.2897, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 133, Loss: 0.2759, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 134, Loss: 0.2501, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 135, Loss: 0.2627, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 136, Loss: 0.2319, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 137, Loss: 0.2368, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 138, Loss: 0.2759, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 139, Loss: 0.2419, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 140, Loss: 0.2330, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 141, Loss: 0.2288, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 10, Epoch: 142, Loss: 0.2248, Train: 100.00%, Valid: 71.25% Test: 64.71%\n",
      "Run: 10, Epoch: 143, Loss: 0.2508, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 144, Loss: 0.2055, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 145, Loss: 0.2420, Train: 100.00%, Valid: 71.25% Test: 66.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 146, Loss: 0.2171, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 147, Loss: 0.2340, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 148, Loss: 0.2463, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 149, Loss: 0.2502, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 150, Loss: 0.1794, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 151, Loss: 0.2055, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 152, Loss: 0.2264, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 153, Loss: 0.1889, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 154, Loss: 0.2097, Train: 100.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 10, Epoch: 155, Loss: 0.2120, Train: 100.00%, Valid: 73.75% Test: 68.63%\n",
      "Run: 10, Epoch: 156, Loss: 0.1844, Train: 100.00%, Valid: 73.75% Test: 66.67%\n",
      "Run: 10, Epoch: 157, Loss: 0.2111, Train: 100.00%, Valid: 73.75% Test: 66.67%\n",
      "Run: 10, Epoch: 158, Loss: 0.2095, Train: 100.00%, Valid: 72.50% Test: 66.67%\n",
      "Run: 10, Epoch: 159, Loss: 0.1877, Train: 100.00%, Valid: 72.50% Test: 66.67%\n",
      "Run: 10, Epoch: 160, Loss: 0.1545, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run: 10, Epoch: 161, Loss: 0.2497, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run: 10, Epoch: 162, Loss: 0.2341, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run: 10, Epoch: 163, Loss: 0.2020, Train: 100.00%, Valid: 73.75% Test: 64.71%\n",
      "Run: 10, Epoch: 164, Loss: 0.1974, Train: 100.00%, Valid: 72.50% Test: 62.75%\n",
      "Run: 10, Epoch: 165, Loss: 0.1808, Train: 100.00%, Valid: 72.50% Test: 62.75%\n",
      "Run: 10, Epoch: 166, Loss: 0.2153, Train: 100.00%, Valid: 72.50% Test: 64.71%\n",
      "Run: 10, Epoch: 167, Loss: 0.2435, Train: 100.00%, Valid: 72.50% Test: 66.67%\n",
      "Run: 10, Epoch: 168, Loss: 0.1952, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 169, Loss: 0.1956, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 10, Epoch: 170, Loss: 0.2288, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 10, Epoch: 171, Loss: 0.1838, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 10, Epoch: 172, Loss: 0.2169, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 10, Epoch: 173, Loss: 0.1981, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 10, Epoch: 174, Loss: 0.2010, Train: 100.00%, Valid: 70.00% Test: 70.59%\n",
      "Run: 10, Epoch: 175, Loss: 0.1998, Train: 100.00%, Valid: 71.25% Test: 70.59%\n",
      "Run: 10, Epoch: 176, Loss: 0.2105, Train: 100.00%, Valid: 72.50% Test: 70.59%\n",
      "Run: 10, Epoch: 177, Loss: 0.1680, Train: 100.00%, Valid: 72.50% Test: 68.63%\n",
      "Run: 10, Epoch: 178, Loss: 0.1654, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 179, Loss: 0.2109, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 180, Loss: 0.2030, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 181, Loss: 0.2062, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 182, Loss: 0.1862, Train: 100.00%, Valid: 68.75% Test: 66.67%\n",
      "Run: 10, Epoch: 183, Loss: 0.1742, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 10, Epoch: 184, Loss: 0.1709, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 10, Epoch: 185, Loss: 0.1577, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run: 10, Epoch: 186, Loss: 0.1702, Train: 100.00%, Valid: 70.00% Test: 66.67%\n",
      "Run: 10, Epoch: 187, Loss: 0.1832, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 188, Loss: 0.1787, Train: 100.00%, Valid: 72.50% Test: 66.67%\n",
      "Run: 10, Epoch: 189, Loss: 0.2254, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 190, Loss: 0.1834, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 191, Loss: 0.1637, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 192, Loss: 0.1768, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 193, Loss: 0.1321, Train: 100.00%, Valid: 71.25% Test: 66.67%\n",
      "Run: 10, Epoch: 194, Loss: 0.1778, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 195, Loss: 0.1687, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 196, Loss: 0.1805, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 197, Loss: 0.1801, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 198, Loss: 0.1366, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 199, Loss: 0.1625, Train: 100.00%, Valid: 71.25% Test: 68.63%\n",
      "Run: 10, Epoch: 200, Loss: 0.1529, Train: 100.00%, Valid: 70.00% Test: 68.63%\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 73.75\n",
      "  Final Train: 100.00\n",
      "   Final Test: 68.63\n",
      "All runs:\n",
      "Highest Train: 99.92 ± 0.26\n",
      "Highest Valid: 74.00 ± 2.75\n",
      "  Final Train: 95.50 ± 6.96\n",
      "   Final Test: 70.20 ± 4.22\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.5,'num_layers_mlp': 3}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 5,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(15, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        \n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.001)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966797f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
