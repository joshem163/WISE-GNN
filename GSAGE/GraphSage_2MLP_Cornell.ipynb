{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af88d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx import ego_graph\n",
    "\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "\n",
    "#from logger import Logger\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import WebKB\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7babc9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=298])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Cornell', name='Cornell',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "#data.adj_t = data.adj_t.to_symmetric()\n",
    "print(data)\n",
    "#split_idx = dataset.get_idx_split()\n",
    "#train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91fdcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = np.where(data.train_mask)[0]\n",
    "print(len(train_index))\n",
    "valid_index = np.where(data.val_mask)[0]\n",
    "print(len(valid_index))\n",
    "test_index = np.where(data.test_mask)[0]\n",
    "print(len(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0b82f",
   "metadata": {},
   "source": [
    "# GSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9ef33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, runs, info=None):\n",
    "        self.info = info\n",
    "        self.results = [[] for _ in range(runs)]\n",
    "\n",
    "    def add_result(self, run, result):\n",
    "        assert len(result) == 3\n",
    "        assert run >= 0 and run < len(self.results)\n",
    "        self.results[run].append(result)\n",
    "\n",
    "    def print_statistics(self, run=None):\n",
    "        if run is not None:\n",
    "            result = 100 * torch.tensor(self.results[run])\n",
    "            argmax = result[:, 1].argmax().item()\n",
    "            print(f'Run {run + 1:02d}:')\n",
    "            print(f'Highest Train: {result[:, 0].max():.2f}')\n",
    "            print(f'Highest Valid: {result[:, 1].max():.2f}')\n",
    "            print(f'  Final Train: {result[argmax, 0]:.2f}')\n",
    "            print(f'   Final Test: {result[argmax, 2]:.2f}')\n",
    "        else:\n",
    "            result = 100 * torch.tensor(self.results)\n",
    "\n",
    "            best_results = []\n",
    "            for r in result:\n",
    "                train1 = r[:, 0].max().item()\n",
    "                valid = r[:, 1].max().item()\n",
    "                train2 = r[r[:, 1].argmax(), 0].item()\n",
    "                test = r[r[:, 1].argmax(), 2].item()\n",
    "                best_results.append((train1, valid, train2, test))\n",
    "\n",
    "            best_result = torch.tensor(best_results)\n",
    "\n",
    "            print(f'All runs:')\n",
    "            r = best_result[:, 0]\n",
    "            print(f'Highest Train: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 1]\n",
    "            print(f'Highest Valid: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 2]\n",
    "            print(f'  Final Train: {r.mean():.2f} ± {r.std():.2f}')\n",
    "            r = best_result[:, 3]\n",
    "            print(f'   Final Test: {r.mean():.2f} ± {r.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47468ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "def train(model, data, train_idx, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(len(out))\n",
    "    #print(data.y.squeeze(1)[train_idx])\n",
    "    loss = F.nll_loss(out, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.adj_t)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=[data.train_mask[i][0] for i in range(183)]\n",
    "train_index = np.where(idx)[0]\n",
    "print(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23796d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x161d8ac50>\n",
      "Run: 01, Epoch: 01, Loss: 1.7830, Train: 77.01%, Valid: 54.24% Test: 51.35%\n",
      "Run: 01, Epoch: 02, Loss: 0.9958, Train: 78.16%, Valid: 57.63% Test: 59.46%\n",
      "Run: 01, Epoch: 03, Loss: 0.7884, Train: 80.46%, Valid: 55.93% Test: 59.46%\n",
      "Run: 01, Epoch: 04, Loss: 0.7604, Train: 88.51%, Valid: 59.32% Test: 62.16%\n",
      "Run: 01, Epoch: 05, Loss: 0.6071, Train: 87.36%, Valid: 59.32% Test: 64.86%\n",
      "Run: 01, Epoch: 06, Loss: 0.5397, Train: 93.10%, Valid: 61.02% Test: 64.86%\n",
      "Run: 01, Epoch: 07, Loss: 0.4847, Train: 94.25%, Valid: 61.02% Test: 67.57%\n",
      "Run: 01, Epoch: 08, Loss: 0.5274, Train: 94.25%, Valid: 62.71% Test: 70.27%\n",
      "Run: 01, Epoch: 09, Loss: 0.4682, Train: 94.25%, Valid: 64.41% Test: 62.16%\n",
      "Run: 01, Epoch: 10, Loss: 0.3679, Train: 94.25%, Valid: 64.41% Test: 62.16%\n",
      "Run: 01, Epoch: 11, Loss: 0.4389, Train: 95.40%, Valid: 61.02% Test: 59.46%\n",
      "Run: 01, Epoch: 12, Loss: 0.3415, Train: 96.55%, Valid: 62.71% Test: 59.46%\n",
      "Run: 01, Epoch: 13, Loss: 0.3268, Train: 97.70%, Valid: 62.71% Test: 56.76%\n",
      "Run: 01, Epoch: 14, Loss: 0.2680, Train: 96.55%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 15, Loss: 0.2496, Train: 97.70%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 16, Loss: 0.2347, Train: 97.70%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 17, Loss: 0.2596, Train: 97.70%, Valid: 61.02% Test: 59.46%\n",
      "Run: 01, Epoch: 18, Loss: 0.2184, Train: 97.70%, Valid: 61.02% Test: 62.16%\n",
      "Run: 01, Epoch: 19, Loss: 0.2745, Train: 97.70%, Valid: 61.02% Test: 62.16%\n",
      "Run: 01, Epoch: 20, Loss: 0.2519, Train: 98.85%, Valid: 61.02% Test: 62.16%\n",
      "Run: 01, Epoch: 21, Loss: 0.2043, Train: 98.85%, Valid: 62.71% Test: 62.16%\n",
      "Run: 01, Epoch: 22, Loss: 0.1446, Train: 98.85%, Valid: 61.02% Test: 62.16%\n",
      "Run: 01, Epoch: 23, Loss: 0.1244, Train: 98.85%, Valid: 61.02% Test: 62.16%\n",
      "Run: 01, Epoch: 24, Loss: 0.1713, Train: 98.85%, Valid: 59.32% Test: 62.16%\n",
      "Run: 01, Epoch: 25, Loss: 0.1592, Train: 100.00%, Valid: 59.32% Test: 62.16%\n",
      "Run: 01, Epoch: 26, Loss: 0.1599, Train: 100.00%, Valid: 59.32% Test: 64.86%\n",
      "Run: 01, Epoch: 27, Loss: 0.1320, Train: 100.00%, Valid: 59.32% Test: 62.16%\n",
      "Run: 01, Epoch: 28, Loss: 0.1015, Train: 100.00%, Valid: 59.32% Test: 62.16%\n",
      "Run: 01, Epoch: 29, Loss: 0.1098, Train: 100.00%, Valid: 59.32% Test: 62.16%\n",
      "Run: 01, Epoch: 30, Loss: 0.1197, Train: 100.00%, Valid: 57.63% Test: 62.16%\n",
      "Run: 01, Epoch: 31, Loss: 0.0726, Train: 100.00%, Valid: 57.63% Test: 62.16%\n",
      "Run: 01, Epoch: 32, Loss: 0.1155, Train: 100.00%, Valid: 55.93% Test: 62.16%\n",
      "Run: 01, Epoch: 33, Loss: 0.1033, Train: 100.00%, Valid: 55.93% Test: 62.16%\n",
      "Run: 01, Epoch: 34, Loss: 0.1219, Train: 100.00%, Valid: 62.71% Test: 62.16%\n",
      "Run: 01, Epoch: 35, Loss: 0.1302, Train: 100.00%, Valid: 62.71% Test: 62.16%\n",
      "Run: 01, Epoch: 36, Loss: 0.1088, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 01, Epoch: 37, Loss: 0.0633, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 01, Epoch: 38, Loss: 0.0818, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 01, Epoch: 39, Loss: 0.0838, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 01, Epoch: 40, Loss: 0.0632, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 01, Epoch: 41, Loss: 0.0343, Train: 100.00%, Valid: 61.02% Test: 59.46%\n",
      "Run: 01, Epoch: 42, Loss: 0.0519, Train: 100.00%, Valid: 61.02% Test: 59.46%\n",
      "Run: 01, Epoch: 43, Loss: 0.0523, Train: 100.00%, Valid: 61.02% Test: 59.46%\n",
      "Run: 01, Epoch: 44, Loss: 0.0648, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 01, Epoch: 45, Loss: 0.0697, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 01, Epoch: 46, Loss: 0.0419, Train: 100.00%, Valid: 62.71% Test: 62.16%\n",
      "Run: 01, Epoch: 47, Loss: 0.0581, Train: 100.00%, Valid: 62.71% Test: 62.16%\n",
      "Run: 01, Epoch: 48, Loss: 0.0900, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 01, Epoch: 49, Loss: 0.0454, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 50, Loss: 0.0447, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 51, Loss: 0.0712, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 52, Loss: 0.0332, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 53, Loss: 0.0729, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 54, Loss: 0.0415, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 55, Loss: 0.0570, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 56, Loss: 0.0197, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 57, Loss: 0.0308, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 58, Loss: 0.0351, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 59, Loss: 0.0245, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 60, Loss: 0.0259, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 61, Loss: 0.0372, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 62, Loss: 0.0849, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 01, Epoch: 63, Loss: 0.0538, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 01, Epoch: 64, Loss: 0.0386, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 01, Epoch: 65, Loss: 0.0251, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 01, Epoch: 66, Loss: 0.0465, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 01, Epoch: 67, Loss: 0.0129, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 01, Epoch: 68, Loss: 0.0187, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 01, Epoch: 69, Loss: 0.0301, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 70, Loss: 0.0269, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 71, Loss: 0.0320, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 72, Loss: 0.0141, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 73, Loss: 0.0631, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 74, Loss: 0.0268, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 75, Loss: 0.0248, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 76, Loss: 0.0210, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 77, Loss: 0.0331, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 78, Loss: 0.0338, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 79, Loss: 0.0333, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 80, Loss: 0.0260, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 81, Loss: 0.0288, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 82, Loss: 0.0132, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 83, Loss: 0.0163, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 84, Loss: 0.0379, Train: 100.00%, Valid: 64.41% Test: 56.76%\n",
      "Run: 01, Epoch: 85, Loss: 0.0364, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 01, Epoch: 86, Loss: 0.0077, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 01, Epoch: 87, Loss: 0.0126, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 01, Epoch: 88, Loss: 0.0183, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 01, Epoch: 89, Loss: 0.0097, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 01, Epoch: 90, Loss: 0.0328, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 01, Epoch: 91, Loss: 0.0304, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 01, Epoch: 92, Loss: 0.0085, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 01, Epoch: 93, Loss: 0.0392, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 01, Epoch: 94, Loss: 0.0113, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 01, Epoch: 95, Loss: 0.0237, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 01, Epoch: 96, Loss: 0.0512, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 01, Epoch: 97, Loss: 0.0109, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 01, Epoch: 98, Loss: 0.0232, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 01, Epoch: 99, Loss: 0.0073, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 01, Epoch: 100, Loss: 0.0139, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 67.80\n",
      "  Final Train: 100.00\n",
      "   Final Test: 59.46\n",
      "Run: 02, Epoch: 01, Loss: 1.8386, Train: 82.76%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 02, Loss: 1.0412, Train: 85.06%, Valid: 64.41% Test: 54.05%\n",
      "Run: 02, Epoch: 03, Loss: 0.8204, Train: 87.36%, Valid: 64.41% Test: 59.46%\n",
      "Run: 02, Epoch: 04, Loss: 0.6888, Train: 86.21%, Valid: 64.41% Test: 64.86%\n",
      "Run: 02, Epoch: 05, Loss: 0.6030, Train: 87.36%, Valid: 61.02% Test: 64.86%\n",
      "Run: 02, Epoch: 06, Loss: 0.6005, Train: 87.36%, Valid: 62.71% Test: 64.86%\n",
      "Run: 02, Epoch: 07, Loss: 0.5271, Train: 87.36%, Valid: 62.71% Test: 70.27%\n",
      "Run: 02, Epoch: 08, Loss: 0.5071, Train: 88.51%, Valid: 62.71% Test: 72.97%\n",
      "Run: 02, Epoch: 09, Loss: 0.4039, Train: 90.80%, Valid: 61.02% Test: 70.27%\n",
      "Run: 02, Epoch: 10, Loss: 0.4064, Train: 90.80%, Valid: 61.02% Test: 70.27%\n",
      "Run: 02, Epoch: 11, Loss: 0.3551, Train: 90.80%, Valid: 61.02% Test: 67.57%\n",
      "Run: 02, Epoch: 12, Loss: 0.3691, Train: 93.10%, Valid: 59.32% Test: 70.27%\n",
      "Run: 02, Epoch: 13, Loss: 0.2892, Train: 94.25%, Valid: 59.32% Test: 67.57%\n",
      "Run: 02, Epoch: 14, Loss: 0.2843, Train: 94.25%, Valid: 57.63% Test: 67.57%\n",
      "Run: 02, Epoch: 15, Loss: 0.2867, Train: 96.55%, Valid: 59.32% Test: 67.57%\n",
      "Run: 02, Epoch: 16, Loss: 0.2296, Train: 96.55%, Valid: 59.32% Test: 67.57%\n",
      "Run: 02, Epoch: 17, Loss: 0.2589, Train: 96.55%, Valid: 61.02% Test: 67.57%\n",
      "Run: 02, Epoch: 18, Loss: 0.2285, Train: 96.55%, Valid: 61.02% Test: 64.86%\n",
      "Run: 02, Epoch: 19, Loss: 0.2329, Train: 97.70%, Valid: 61.02% Test: 62.16%\n",
      "Run: 02, Epoch: 20, Loss: 0.2436, Train: 97.70%, Valid: 62.71% Test: 62.16%\n",
      "Run: 02, Epoch: 21, Loss: 0.1636, Train: 97.70%, Valid: 62.71% Test: 62.16%\n",
      "Run: 02, Epoch: 22, Loss: 0.1854, Train: 97.70%, Valid: 62.71% Test: 62.16%\n",
      "Run: 02, Epoch: 23, Loss: 0.1873, Train: 97.70%, Valid: 62.71% Test: 62.16%\n",
      "Run: 02, Epoch: 24, Loss: 0.1087, Train: 97.70%, Valid: 62.71% Test: 59.46%\n",
      "Run: 02, Epoch: 25, Loss: 0.1536, Train: 97.70%, Valid: 62.71% Test: 59.46%\n",
      "Run: 02, Epoch: 26, Loss: 0.0924, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 02, Epoch: 27, Loss: 0.1130, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 02, Epoch: 28, Loss: 0.1103, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 02, Epoch: 29, Loss: 0.1193, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 30, Loss: 0.1509, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 31, Loss: 0.1446, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 32, Loss: 0.0574, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 33, Loss: 0.0980, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 34, Loss: 0.0847, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 35, Loss: 0.0903, Train: 100.00%, Valid: 62.71% Test: 56.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 36, Loss: 0.1134, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 02, Epoch: 37, Loss: 0.0755, Train: 100.00%, Valid: 62.71% Test: 59.46%\n",
      "Run: 02, Epoch: 38, Loss: 0.0879, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 39, Loss: 0.0399, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 40, Loss: 0.0492, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 41, Loss: 0.0539, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 42, Loss: 0.0564, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 43, Loss: 0.0694, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 44, Loss: 0.0540, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 45, Loss: 0.0610, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 46, Loss: 0.0440, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 47, Loss: 0.0604, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 48, Loss: 0.0818, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 49, Loss: 0.0612, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 50, Loss: 0.0527, Train: 100.00%, Valid: 62.71% Test: 54.05%\n",
      "Run: 02, Epoch: 51, Loss: 0.0389, Train: 100.00%, Valid: 62.71% Test: 54.05%\n",
      "Run: 02, Epoch: 52, Loss: 0.0375, Train: 100.00%, Valid: 62.71% Test: 54.05%\n",
      "Run: 02, Epoch: 53, Loss: 0.0499, Train: 100.00%, Valid: 62.71% Test: 54.05%\n",
      "Run: 02, Epoch: 54, Loss: 0.0354, Train: 100.00%, Valid: 62.71% Test: 54.05%\n",
      "Run: 02, Epoch: 55, Loss: 0.0560, Train: 100.00%, Valid: 62.71% Test: 54.05%\n",
      "Run: 02, Epoch: 56, Loss: 0.0228, Train: 100.00%, Valid: 62.71% Test: 54.05%\n",
      "Run: 02, Epoch: 57, Loss: 0.0419, Train: 100.00%, Valid: 62.71% Test: 54.05%\n",
      "Run: 02, Epoch: 58, Loss: 0.0436, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 59, Loss: 0.0478, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 60, Loss: 0.0476, Train: 100.00%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 61, Loss: 0.0356, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 62, Loss: 0.0129, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 63, Loss: 0.0184, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 64, Loss: 0.0316, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 65, Loss: 0.0382, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 66, Loss: 0.0395, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 67, Loss: 0.0295, Train: 100.00%, Valid: 61.02% Test: 54.05%\n",
      "Run: 02, Epoch: 68, Loss: 0.0311, Train: 100.00%, Valid: 61.02% Test: 54.05%\n",
      "Run: 02, Epoch: 69, Loss: 0.0350, Train: 100.00%, Valid: 61.02% Test: 54.05%\n",
      "Run: 02, Epoch: 70, Loss: 0.0333, Train: 100.00%, Valid: 61.02% Test: 54.05%\n",
      "Run: 02, Epoch: 71, Loss: 0.0414, Train: 100.00%, Valid: 61.02% Test: 54.05%\n",
      "Run: 02, Epoch: 72, Loss: 0.0188, Train: 100.00%, Valid: 61.02% Test: 54.05%\n",
      "Run: 02, Epoch: 73, Loss: 0.0319, Train: 100.00%, Valid: 61.02% Test: 54.05%\n",
      "Run: 02, Epoch: 74, Loss: 0.0188, Train: 100.00%, Valid: 61.02% Test: 54.05%\n",
      "Run: 02, Epoch: 75, Loss: 0.0630, Train: 100.00%, Valid: 61.02% Test: 54.05%\n",
      "Run: 02, Epoch: 76, Loss: 0.0518, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 77, Loss: 0.0426, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 78, Loss: 0.0174, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 79, Loss: 0.0243, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 80, Loss: 0.0162, Train: 100.00%, Valid: 61.02% Test: 56.76%\n",
      "Run: 02, Epoch: 81, Loss: 0.0427, Train: 100.00%, Valid: 61.02% Test: 59.46%\n",
      "Run: 02, Epoch: 82, Loss: 0.0353, Train: 100.00%, Valid: 61.02% Test: 59.46%\n",
      "Run: 02, Epoch: 83, Loss: 0.0522, Train: 100.00%, Valid: 59.32% Test: 59.46%\n",
      "Run: 02, Epoch: 84, Loss: 0.0239, Train: 100.00%, Valid: 59.32% Test: 59.46%\n",
      "Run: 02, Epoch: 85, Loss: 0.0304, Train: 100.00%, Valid: 59.32% Test: 59.46%\n",
      "Run: 02, Epoch: 86, Loss: 0.0092, Train: 100.00%, Valid: 59.32% Test: 59.46%\n",
      "Run: 02, Epoch: 87, Loss: 0.0331, Train: 100.00%, Valid: 59.32% Test: 59.46%\n",
      "Run: 02, Epoch: 88, Loss: 0.0147, Train: 100.00%, Valid: 59.32% Test: 59.46%\n",
      "Run: 02, Epoch: 89, Loss: 0.0088, Train: 100.00%, Valid: 59.32% Test: 59.46%\n",
      "Run: 02, Epoch: 90, Loss: 0.0596, Train: 100.00%, Valid: 57.63% Test: 59.46%\n",
      "Run: 02, Epoch: 91, Loss: 0.0358, Train: 100.00%, Valid: 57.63% Test: 59.46%\n",
      "Run: 02, Epoch: 92, Loss: 0.0382, Train: 100.00%, Valid: 57.63% Test: 62.16%\n",
      "Run: 02, Epoch: 93, Loss: 0.0285, Train: 100.00%, Valid: 57.63% Test: 62.16%\n",
      "Run: 02, Epoch: 94, Loss: 0.0146, Train: 100.00%, Valid: 57.63% Test: 62.16%\n",
      "Run: 02, Epoch: 95, Loss: 0.0160, Train: 100.00%, Valid: 57.63% Test: 62.16%\n",
      "Run: 02, Epoch: 96, Loss: 0.0092, Train: 100.00%, Valid: 57.63% Test: 62.16%\n",
      "Run: 02, Epoch: 97, Loss: 0.0418, Train: 100.00%, Valid: 57.63% Test: 62.16%\n",
      "Run: 02, Epoch: 98, Loss: 0.0053, Train: 100.00%, Valid: 57.63% Test: 62.16%\n",
      "Run: 02, Epoch: 99, Loss: 0.0288, Train: 100.00%, Valid: 57.63% Test: 62.16%\n",
      "Run: 02, Epoch: 100, Loss: 0.0215, Train: 100.00%, Valid: 57.63% Test: 59.46%\n",
      "Run 02:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 64.41\n",
      "  Final Train: 85.06\n",
      "   Final Test: 54.05\n",
      "Run: 03, Epoch: 01, Loss: 1.6512, Train: 79.31%, Valid: 54.24% Test: 56.76%\n",
      "Run: 03, Epoch: 02, Loss: 0.9760, Train: 85.06%, Valid: 59.32% Test: 56.76%\n",
      "Run: 03, Epoch: 03, Loss: 0.8241, Train: 83.91%, Valid: 54.24% Test: 62.16%\n",
      "Run: 03, Epoch: 04, Loss: 0.6252, Train: 83.91%, Valid: 57.63% Test: 67.57%\n",
      "Run: 03, Epoch: 05, Loss: 0.6560, Train: 83.91%, Valid: 59.32% Test: 70.27%\n",
      "Run: 03, Epoch: 06, Loss: 0.5317, Train: 85.06%, Valid: 57.63% Test: 70.27%\n",
      "Run: 03, Epoch: 07, Loss: 0.5728, Train: 86.21%, Valid: 57.63% Test: 70.27%\n",
      "Run: 03, Epoch: 08, Loss: 0.4963, Train: 87.36%, Valid: 55.93% Test: 72.97%\n",
      "Run: 03, Epoch: 09, Loss: 0.4504, Train: 91.95%, Valid: 57.63% Test: 70.27%\n",
      "Run: 03, Epoch: 10, Loss: 0.4060, Train: 91.95%, Valid: 59.32% Test: 70.27%\n",
      "Run: 03, Epoch: 11, Loss: 0.3676, Train: 95.40%, Valid: 61.02% Test: 70.27%\n",
      "Run: 03, Epoch: 12, Loss: 0.3636, Train: 96.55%, Valid: 61.02% Test: 70.27%\n",
      "Run: 03, Epoch: 13, Loss: 0.3326, Train: 97.70%, Valid: 59.32% Test: 70.27%\n",
      "Run: 03, Epoch: 14, Loss: 0.2627, Train: 97.70%, Valid: 59.32% Test: 70.27%\n",
      "Run: 03, Epoch: 15, Loss: 0.2468, Train: 97.70%, Valid: 61.02% Test: 70.27%\n",
      "Run: 03, Epoch: 16, Loss: 0.2051, Train: 97.70%, Valid: 61.02% Test: 70.27%\n",
      "Run: 03, Epoch: 17, Loss: 0.2032, Train: 97.70%, Valid: 61.02% Test: 70.27%\n",
      "Run: 03, Epoch: 18, Loss: 0.2063, Train: 98.85%, Valid: 62.71% Test: 70.27%\n",
      "Run: 03, Epoch: 19, Loss: 0.2072, Train: 98.85%, Valid: 64.41% Test: 70.27%\n",
      "Run: 03, Epoch: 20, Loss: 0.1790, Train: 98.85%, Valid: 66.10% Test: 70.27%\n",
      "Run: 03, Epoch: 21, Loss: 0.2018, Train: 100.00%, Valid: 64.41% Test: 70.27%\n",
      "Run: 03, Epoch: 22, Loss: 0.1397, Train: 100.00%, Valid: 66.10% Test: 70.27%\n",
      "Run: 03, Epoch: 23, Loss: 0.1829, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 24, Loss: 0.1287, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 03, Epoch: 25, Loss: 0.1055, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 03, Epoch: 26, Loss: 0.0875, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 03, Epoch: 27, Loss: 0.1102, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 28, Loss: 0.1385, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 29, Loss: 0.1448, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 30, Loss: 0.0989, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 31, Loss: 0.0885, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 32, Loss: 0.1271, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 03, Epoch: 33, Loss: 0.0800, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 34, Loss: 0.1325, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 35, Loss: 0.0803, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 03, Epoch: 36, Loss: 0.0842, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 03, Epoch: 37, Loss: 0.0716, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 03, Epoch: 38, Loss: 0.0791, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 03, Epoch: 39, Loss: 0.0528, Train: 100.00%, Valid: 66.10% Test: 67.57%\n",
      "Run: 03, Epoch: 40, Loss: 0.0545, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 41, Loss: 0.0321, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 03, Epoch: 42, Loss: 0.0274, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 03, Epoch: 43, Loss: 0.0400, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 03, Epoch: 44, Loss: 0.0395, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 03, Epoch: 45, Loss: 0.0693, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 03, Epoch: 46, Loss: 0.0742, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 03, Epoch: 47, Loss: 0.0295, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 03, Epoch: 48, Loss: 0.0583, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 03, Epoch: 49, Loss: 0.0405, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 03, Epoch: 50, Loss: 0.0363, Train: 100.00%, Valid: 72.88% Test: 64.86%\n",
      "Run: 03, Epoch: 51, Loss: 0.0452, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 03, Epoch: 52, Loss: 0.0284, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 53, Loss: 0.0367, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 54, Loss: 0.0172, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 55, Loss: 0.0386, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 56, Loss: 0.0478, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 57, Loss: 0.0645, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 58, Loss: 0.0547, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 59, Loss: 0.0476, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 60, Loss: 0.0398, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 61, Loss: 0.0180, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 62, Loss: 0.0133, Train: 100.00%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 63, Loss: 0.0364, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 64, Loss: 0.0262, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 65, Loss: 0.0231, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 66, Loss: 0.0151, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 67, Loss: 0.0474, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 68, Loss: 0.0206, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 69, Loss: 0.0322, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 70, Loss: 0.0607, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 71, Loss: 0.0403, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 72, Loss: 0.0386, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 73, Loss: 0.0199, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 74, Loss: 0.0270, Train: 100.00%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 75, Loss: 0.0130, Train: 100.00%, Valid: 71.19% Test: 67.57%\n",
      "Run: 03, Epoch: 76, Loss: 0.0270, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 77, Loss: 0.0087, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 78, Loss: 0.0332, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 79, Loss: 0.0299, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 80, Loss: 0.0259, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 81, Loss: 0.0398, Train: 100.00%, Valid: 67.80% Test: 67.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 82, Loss: 0.0498, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 83, Loss: 0.0505, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 03, Epoch: 84, Loss: 0.0281, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 03, Epoch: 85, Loss: 0.0318, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 03, Epoch: 86, Loss: 0.0127, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 03, Epoch: 87, Loss: 0.0246, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 03, Epoch: 88, Loss: 0.0141, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 03, Epoch: 89, Loss: 0.0274, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 03, Epoch: 90, Loss: 0.0159, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 03, Epoch: 91, Loss: 0.0087, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 03, Epoch: 92, Loss: 0.0368, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 03, Epoch: 93, Loss: 0.0031, Train: 100.00%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 94, Loss: 0.0553, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 03, Epoch: 95, Loss: 0.0263, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 03, Epoch: 96, Loss: 0.0046, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 03, Epoch: 97, Loss: 0.0131, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 03, Epoch: 98, Loss: 0.0498, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 03, Epoch: 99, Loss: 0.0052, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run: 03, Epoch: 100, Loss: 0.0121, Train: 100.00%, Valid: 69.49% Test: 67.57%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 74.58\n",
      "  Final Train: 100.00\n",
      "   Final Test: 67.57\n",
      "Run: 04, Epoch: 01, Loss: 1.8085, Train: 58.62%, Valid: 38.98% Test: 45.95%\n",
      "Run: 04, Epoch: 02, Loss: 0.9197, Train: 87.36%, Valid: 52.54% Test: 64.86%\n",
      "Run: 04, Epoch: 03, Loss: 0.8146, Train: 89.66%, Valid: 57.63% Test: 64.86%\n",
      "Run: 04, Epoch: 04, Loss: 0.7087, Train: 89.66%, Valid: 52.54% Test: 64.86%\n",
      "Run: 04, Epoch: 05, Loss: 0.6264, Train: 87.36%, Valid: 50.85% Test: 64.86%\n",
      "Run: 04, Epoch: 06, Loss: 0.5645, Train: 87.36%, Valid: 50.85% Test: 64.86%\n",
      "Run: 04, Epoch: 07, Loss: 0.4871, Train: 89.66%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 08, Loss: 0.4504, Train: 90.80%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 09, Loss: 0.4421, Train: 91.95%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 10, Loss: 0.3731, Train: 91.95%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 11, Loss: 0.4097, Train: 95.40%, Valid: 54.24% Test: 62.16%\n",
      "Run: 04, Epoch: 12, Loss: 0.3407, Train: 95.40%, Valid: 54.24% Test: 62.16%\n",
      "Run: 04, Epoch: 13, Loss: 0.3089, Train: 95.40%, Valid: 52.54% Test: 64.86%\n",
      "Run: 04, Epoch: 14, Loss: 0.2512, Train: 95.40%, Valid: 52.54% Test: 64.86%\n",
      "Run: 04, Epoch: 15, Loss: 0.2834, Train: 95.40%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 16, Loss: 0.2506, Train: 96.55%, Valid: 54.24% Test: 62.16%\n",
      "Run: 04, Epoch: 17, Loss: 0.2612, Train: 96.55%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 18, Loss: 0.1909, Train: 98.85%, Valid: 50.85% Test: 62.16%\n",
      "Run: 04, Epoch: 19, Loss: 0.1424, Train: 100.00%, Valid: 50.85% Test: 62.16%\n",
      "Run: 04, Epoch: 20, Loss: 0.1486, Train: 100.00%, Valid: 55.93% Test: 62.16%\n",
      "Run: 04, Epoch: 21, Loss: 0.1537, Train: 100.00%, Valid: 55.93% Test: 62.16%\n",
      "Run: 04, Epoch: 22, Loss: 0.1490, Train: 100.00%, Valid: 55.93% Test: 62.16%\n",
      "Run: 04, Epoch: 23, Loss: 0.1573, Train: 100.00%, Valid: 55.93% Test: 62.16%\n",
      "Run: 04, Epoch: 24, Loss: 0.1118, Train: 100.00%, Valid: 55.93% Test: 62.16%\n",
      "Run: 04, Epoch: 25, Loss: 0.1535, Train: 100.00%, Valid: 54.24% Test: 62.16%\n",
      "Run: 04, Epoch: 26, Loss: 0.1277, Train: 100.00%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 27, Loss: 0.1070, Train: 100.00%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 28, Loss: 0.0969, Train: 100.00%, Valid: 52.54% Test: 62.16%\n",
      "Run: 04, Epoch: 29, Loss: 0.0991, Train: 100.00%, Valid: 50.85% Test: 62.16%\n",
      "Run: 04, Epoch: 30, Loss: 0.0957, Train: 100.00%, Valid: 50.85% Test: 62.16%\n",
      "Run: 04, Epoch: 31, Loss: 0.0549, Train: 100.00%, Valid: 49.15% Test: 62.16%\n",
      "Run: 04, Epoch: 32, Loss: 0.0621, Train: 100.00%, Valid: 49.15% Test: 62.16%\n",
      "Run: 04, Epoch: 33, Loss: 0.0940, Train: 100.00%, Valid: 47.46% Test: 64.86%\n",
      "Run: 04, Epoch: 34, Loss: 0.0575, Train: 100.00%, Valid: 47.46% Test: 67.57%\n",
      "Run: 04, Epoch: 35, Loss: 0.1071, Train: 100.00%, Valid: 47.46% Test: 67.57%\n",
      "Run: 04, Epoch: 36, Loss: 0.0627, Train: 100.00%, Valid: 49.15% Test: 67.57%\n",
      "Run: 04, Epoch: 37, Loss: 0.0402, Train: 100.00%, Valid: 49.15% Test: 67.57%\n",
      "Run: 04, Epoch: 38, Loss: 0.0407, Train: 100.00%, Valid: 49.15% Test: 67.57%\n",
      "Run: 04, Epoch: 39, Loss: 0.0834, Train: 100.00%, Valid: 49.15% Test: 67.57%\n",
      "Run: 04, Epoch: 40, Loss: 0.0486, Train: 100.00%, Valid: 49.15% Test: 70.27%\n",
      "Run: 04, Epoch: 41, Loss: 0.0883, Train: 100.00%, Valid: 49.15% Test: 70.27%\n",
      "Run: 04, Epoch: 42, Loss: 0.0472, Train: 100.00%, Valid: 50.85% Test: 70.27%\n",
      "Run: 04, Epoch: 43, Loss: 0.0348, Train: 100.00%, Valid: 50.85% Test: 70.27%\n",
      "Run: 04, Epoch: 44, Loss: 0.0553, Train: 100.00%, Valid: 50.85% Test: 70.27%\n",
      "Run: 04, Epoch: 45, Loss: 0.0605, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 04, Epoch: 46, Loss: 0.0483, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 04, Epoch: 47, Loss: 0.0202, Train: 100.00%, Valid: 54.24% Test: 70.27%\n",
      "Run: 04, Epoch: 48, Loss: 0.0443, Train: 100.00%, Valid: 54.24% Test: 70.27%\n",
      "Run: 04, Epoch: 49, Loss: 0.0767, Train: 100.00%, Valid: 54.24% Test: 70.27%\n",
      "Run: 04, Epoch: 50, Loss: 0.0299, Train: 100.00%, Valid: 54.24% Test: 70.27%\n",
      "Run: 04, Epoch: 51, Loss: 0.0493, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 52, Loss: 0.0224, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 53, Loss: 0.0374, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 54, Loss: 0.0286, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 55, Loss: 0.0497, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 56, Loss: 0.0146, Train: 100.00%, Valid: 52.54% Test: 67.57%\n",
      "Run: 04, Epoch: 57, Loss: 0.0255, Train: 100.00%, Valid: 52.54% Test: 67.57%\n",
      "Run: 04, Epoch: 58, Loss: 0.0377, Train: 100.00%, Valid: 52.54% Test: 67.57%\n",
      "Run: 04, Epoch: 59, Loss: 0.0351, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 60, Loss: 0.0210, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 61, Loss: 0.0294, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 62, Loss: 0.0359, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 63, Loss: 0.0116, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 64, Loss: 0.0139, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 65, Loss: 0.0160, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 66, Loss: 0.0100, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 67, Loss: 0.0429, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 68, Loss: 0.0209, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 69, Loss: 0.0212, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 70, Loss: 0.0275, Train: 100.00%, Valid: 55.93% Test: 64.86%\n",
      "Run: 04, Epoch: 71, Loss: 0.0252, Train: 100.00%, Valid: 55.93% Test: 64.86%\n",
      "Run: 04, Epoch: 72, Loss: 0.0143, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 73, Loss: 0.0352, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 74, Loss: 0.0195, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 75, Loss: 0.0323, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 76, Loss: 0.0296, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 77, Loss: 0.0370, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 78, Loss: 0.0436, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 79, Loss: 0.0190, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 04, Epoch: 80, Loss: 0.0436, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 81, Loss: 0.0050, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 82, Loss: 0.0247, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 04, Epoch: 83, Loss: 0.0169, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 04, Epoch: 84, Loss: 0.0251, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 04, Epoch: 85, Loss: 0.0071, Train: 100.00%, Valid: 55.93% Test: 70.27%\n",
      "Run: 04, Epoch: 86, Loss: 0.0100, Train: 100.00%, Valid: 54.24% Test: 70.27%\n",
      "Run: 04, Epoch: 87, Loss: 0.0416, Train: 100.00%, Valid: 54.24% Test: 70.27%\n",
      "Run: 04, Epoch: 88, Loss: 0.0301, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 89, Loss: 0.0111, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 90, Loss: 0.0311, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 91, Loss: 0.0124, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 92, Loss: 0.0316, Train: 100.00%, Valid: 57.63% Test: 67.57%\n",
      "Run: 04, Epoch: 93, Loss: 0.0126, Train: 100.00%, Valid: 57.63% Test: 67.57%\n",
      "Run: 04, Epoch: 94, Loss: 0.0496, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 04, Epoch: 95, Loss: 0.0038, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 04, Epoch: 96, Loss: 0.0170, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 04, Epoch: 97, Loss: 0.0051, Train: 100.00%, Valid: 55.93% Test: 67.57%\n",
      "Run: 04, Epoch: 98, Loss: 0.0129, Train: 100.00%, Valid: 57.63% Test: 67.57%\n",
      "Run: 04, Epoch: 99, Loss: 0.0387, Train: 100.00%, Valid: 57.63% Test: 67.57%\n",
      "Run: 04, Epoch: 100, Loss: 0.0236, Train: 100.00%, Valid: 57.63% Test: 67.57%\n",
      "Run 04:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 57.63\n",
      "  Final Train: 89.66\n",
      "   Final Test: 64.86\n",
      "Run: 05, Epoch: 01, Loss: 1.5683, Train: 73.56%, Valid: 47.46% Test: 59.46%\n",
      "Run: 05, Epoch: 02, Loss: 0.8910, Train: 83.91%, Valid: 47.46% Test: 59.46%\n",
      "Run: 05, Epoch: 03, Loss: 0.7063, Train: 83.91%, Valid: 50.85% Test: 56.76%\n",
      "Run: 05, Epoch: 04, Loss: 0.6297, Train: 88.51%, Valid: 54.24% Test: 56.76%\n",
      "Run: 05, Epoch: 05, Loss: 0.6535, Train: 91.95%, Valid: 55.93% Test: 62.16%\n",
      "Run: 05, Epoch: 06, Loss: 0.5421, Train: 91.95%, Valid: 59.32% Test: 64.86%\n",
      "Run: 05, Epoch: 07, Loss: 0.4501, Train: 94.25%, Valid: 61.02% Test: 70.27%\n",
      "Run: 05, Epoch: 08, Loss: 0.4552, Train: 94.25%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 09, Loss: 0.4213, Train: 95.40%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 10, Loss: 0.3240, Train: 97.70%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 11, Loss: 0.2937, Train: 98.85%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 12, Loss: 0.3159, Train: 98.85%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 13, Loss: 0.2207, Train: 98.85%, Valid: 61.02% Test: 67.57%\n",
      "Run: 05, Epoch: 14, Loss: 0.2218, Train: 98.85%, Valid: 61.02% Test: 67.57%\n",
      "Run: 05, Epoch: 15, Loss: 0.2280, Train: 98.85%, Valid: 61.02% Test: 67.57%\n",
      "Run: 05, Epoch: 16, Loss: 0.1997, Train: 98.85%, Valid: 59.32% Test: 70.27%\n",
      "Run: 05, Epoch: 17, Loss: 0.2477, Train: 98.85%, Valid: 57.63% Test: 70.27%\n",
      "Run: 05, Epoch: 18, Loss: 0.1878, Train: 98.85%, Valid: 57.63% Test: 67.57%\n",
      "Run: 05, Epoch: 19, Loss: 0.1564, Train: 98.85%, Valid: 57.63% Test: 67.57%\n",
      "Run: 05, Epoch: 20, Loss: 0.1893, Train: 98.85%, Valid: 57.63% Test: 67.57%\n",
      "Run: 05, Epoch: 21, Loss: 0.2224, Train: 98.85%, Valid: 55.93% Test: 67.57%\n",
      "Run: 05, Epoch: 22, Loss: 0.1282, Train: 98.85%, Valid: 55.93% Test: 64.86%\n",
      "Run: 05, Epoch: 23, Loss: 0.1119, Train: 98.85%, Valid: 54.24% Test: 64.86%\n",
      "Run: 05, Epoch: 24, Loss: 0.1315, Train: 98.85%, Valid: 54.24% Test: 64.86%\n",
      "Run: 05, Epoch: 25, Loss: 0.1041, Train: 98.85%, Valid: 52.54% Test: 64.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 26, Loss: 0.1187, Train: 100.00%, Valid: 54.24% Test: 62.16%\n",
      "Run: 05, Epoch: 27, Loss: 0.0851, Train: 100.00%, Valid: 54.24% Test: 67.57%\n",
      "Run: 05, Epoch: 28, Loss: 0.0717, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 05, Epoch: 29, Loss: 0.0943, Train: 100.00%, Valid: 50.85% Test: 64.86%\n",
      "Run: 05, Epoch: 30, Loss: 0.1080, Train: 100.00%, Valid: 52.54% Test: 64.86%\n",
      "Run: 05, Epoch: 31, Loss: 0.0684, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 05, Epoch: 32, Loss: 0.0631, Train: 100.00%, Valid: 54.24% Test: 64.86%\n",
      "Run: 05, Epoch: 33, Loss: 0.0658, Train: 100.00%, Valid: 54.24% Test: 62.16%\n",
      "Run: 05, Epoch: 34, Loss: 0.0624, Train: 100.00%, Valid: 54.24% Test: 62.16%\n",
      "Run: 05, Epoch: 35, Loss: 0.0995, Train: 100.00%, Valid: 54.24% Test: 62.16%\n",
      "Run: 05, Epoch: 36, Loss: 0.0484, Train: 100.00%, Valid: 54.24% Test: 62.16%\n",
      "Run: 05, Epoch: 37, Loss: 0.0685, Train: 100.00%, Valid: 52.54% Test: 62.16%\n",
      "Run: 05, Epoch: 38, Loss: 0.0495, Train: 100.00%, Valid: 50.85% Test: 62.16%\n",
      "Run: 05, Epoch: 39, Loss: 0.0788, Train: 100.00%, Valid: 49.15% Test: 59.46%\n",
      "Run: 05, Epoch: 40, Loss: 0.0448, Train: 100.00%, Valid: 49.15% Test: 59.46%\n",
      "Run: 05, Epoch: 41, Loss: 0.0475, Train: 100.00%, Valid: 49.15% Test: 59.46%\n",
      "Run: 05, Epoch: 42, Loss: 0.0562, Train: 100.00%, Valid: 49.15% Test: 56.76%\n",
      "Run: 05, Epoch: 43, Loss: 0.0500, Train: 100.00%, Valid: 47.46% Test: 54.05%\n",
      "Run: 05, Epoch: 44, Loss: 0.0475, Train: 100.00%, Valid: 47.46% Test: 51.35%\n",
      "Run: 05, Epoch: 45, Loss: 0.0266, Train: 100.00%, Valid: 45.76% Test: 51.35%\n",
      "Run: 05, Epoch: 46, Loss: 0.0613, Train: 100.00%, Valid: 47.46% Test: 51.35%\n",
      "Run: 05, Epoch: 47, Loss: 0.0305, Train: 100.00%, Valid: 47.46% Test: 51.35%\n",
      "Run: 05, Epoch: 48, Loss: 0.0482, Train: 100.00%, Valid: 47.46% Test: 54.05%\n",
      "Run: 05, Epoch: 49, Loss: 0.0489, Train: 100.00%, Valid: 45.76% Test: 54.05%\n",
      "Run: 05, Epoch: 50, Loss: 0.0963, Train: 100.00%, Valid: 45.76% Test: 54.05%\n",
      "Run: 05, Epoch: 51, Loss: 0.0355, Train: 100.00%, Valid: 45.76% Test: 54.05%\n",
      "Run: 05, Epoch: 52, Loss: 0.0283, Train: 100.00%, Valid: 45.76% Test: 54.05%\n",
      "Run: 05, Epoch: 53, Loss: 0.0411, Train: 100.00%, Valid: 45.76% Test: 54.05%\n",
      "Run: 05, Epoch: 54, Loss: 0.0278, Train: 100.00%, Valid: 47.46% Test: 56.76%\n",
      "Run: 05, Epoch: 55, Loss: 0.0398, Train: 100.00%, Valid: 47.46% Test: 56.76%\n",
      "Run: 05, Epoch: 56, Loss: 0.0552, Train: 100.00%, Valid: 45.76% Test: 56.76%\n",
      "Run: 05, Epoch: 57, Loss: 0.0698, Train: 100.00%, Valid: 45.76% Test: 54.05%\n",
      "Run: 05, Epoch: 58, Loss: 0.0351, Train: 100.00%, Valid: 44.07% Test: 54.05%\n",
      "Run: 05, Epoch: 59, Loss: 0.0260, Train: 100.00%, Valid: 45.76% Test: 54.05%\n",
      "Run: 05, Epoch: 60, Loss: 0.0363, Train: 100.00%, Valid: 47.46% Test: 56.76%\n",
      "Run: 05, Epoch: 61, Loss: 0.0366, Train: 100.00%, Valid: 47.46% Test: 59.46%\n",
      "Run: 05, Epoch: 62, Loss: 0.0193, Train: 100.00%, Valid: 47.46% Test: 56.76%\n",
      "Run: 05, Epoch: 63, Loss: 0.0245, Train: 100.00%, Valid: 49.15% Test: 62.16%\n",
      "Run: 05, Epoch: 64, Loss: 0.0254, Train: 100.00%, Valid: 49.15% Test: 56.76%\n",
      "Run: 05, Epoch: 65, Loss: 0.0340, Train: 100.00%, Valid: 49.15% Test: 56.76%\n",
      "Run: 05, Epoch: 66, Loss: 0.0330, Train: 100.00%, Valid: 47.46% Test: 54.05%\n",
      "Run: 05, Epoch: 67, Loss: 0.0163, Train: 100.00%, Valid: 47.46% Test: 54.05%\n",
      "Run: 05, Epoch: 68, Loss: 0.0114, Train: 100.00%, Valid: 49.15% Test: 56.76%\n",
      "Run: 05, Epoch: 69, Loss: 0.0082, Train: 100.00%, Valid: 49.15% Test: 56.76%\n",
      "Run: 05, Epoch: 70, Loss: 0.0200, Train: 100.00%, Valid: 49.15% Test: 59.46%\n",
      "Run: 05, Epoch: 71, Loss: 0.0148, Train: 100.00%, Valid: 50.85% Test: 59.46%\n",
      "Run: 05, Epoch: 72, Loss: 0.0233, Train: 100.00%, Valid: 50.85% Test: 59.46%\n",
      "Run: 05, Epoch: 73, Loss: 0.0346, Train: 100.00%, Valid: 50.85% Test: 59.46%\n",
      "Run: 05, Epoch: 74, Loss: 0.0171, Train: 100.00%, Valid: 52.54% Test: 59.46%\n",
      "Run: 05, Epoch: 75, Loss: 0.0379, Train: 100.00%, Valid: 52.54% Test: 62.16%\n",
      "Run: 05, Epoch: 76, Loss: 0.0322, Train: 100.00%, Valid: 50.85% Test: 62.16%\n",
      "Run: 05, Epoch: 77, Loss: 0.0068, Train: 100.00%, Valid: 50.85% Test: 62.16%\n",
      "Run: 05, Epoch: 78, Loss: 0.0388, Train: 100.00%, Valid: 50.85% Test: 62.16%\n",
      "Run: 05, Epoch: 79, Loss: 0.0111, Train: 100.00%, Valid: 50.85% Test: 59.46%\n",
      "Run: 05, Epoch: 80, Loss: 0.0205, Train: 100.00%, Valid: 47.46% Test: 59.46%\n",
      "Run: 05, Epoch: 81, Loss: 0.0104, Train: 100.00%, Valid: 47.46% Test: 59.46%\n",
      "Run: 05, Epoch: 82, Loss: 0.0138, Train: 100.00%, Valid: 50.85% Test: 59.46%\n",
      "Run: 05, Epoch: 83, Loss: 0.0478, Train: 100.00%, Valid: 52.54% Test: 62.16%\n",
      "Run: 05, Epoch: 84, Loss: 0.0287, Train: 100.00%, Valid: 52.54% Test: 64.86%\n",
      "Run: 05, Epoch: 85, Loss: 0.0115, Train: 100.00%, Valid: 52.54% Test: 64.86%\n",
      "Run: 05, Epoch: 86, Loss: 0.0248, Train: 100.00%, Valid: 52.54% Test: 64.86%\n",
      "Run: 05, Epoch: 87, Loss: 0.0089, Train: 100.00%, Valid: 52.54% Test: 64.86%\n",
      "Run: 05, Epoch: 88, Loss: 0.0152, Train: 100.00%, Valid: 52.54% Test: 67.57%\n",
      "Run: 05, Epoch: 89, Loss: 0.0183, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 90, Loss: 0.0182, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 91, Loss: 0.0168, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 92, Loss: 0.0306, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 93, Loss: 0.0312, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 94, Loss: 0.0419, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 95, Loss: 0.0163, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 96, Loss: 0.0240, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 97, Loss: 0.0025, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 98, Loss: 0.0104, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 99, Loss: 0.0293, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 100, Loss: 0.0407, Train: 100.00%, Valid: 52.54% Test: 70.27%\n",
      "Run 05:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 62.71\n",
      "  Final Train: 94.25\n",
      "   Final Test: 67.57\n",
      "Run: 06, Epoch: 01, Loss: 1.7733, Train: 74.71%, Valid: 62.71% Test: 40.54%\n",
      "Run: 06, Epoch: 02, Loss: 0.9287, Train: 80.46%, Valid: 72.88% Test: 54.05%\n",
      "Run: 06, Epoch: 03, Loss: 0.7980, Train: 85.06%, Valid: 66.10% Test: 56.76%\n",
      "Run: 06, Epoch: 04, Loss: 0.6506, Train: 93.10%, Valid: 69.49% Test: 59.46%\n",
      "Run: 06, Epoch: 05, Loss: 0.6133, Train: 93.10%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 06, Loss: 0.5580, Train: 93.10%, Valid: 69.49% Test: 62.16%\n",
      "Run: 06, Epoch: 07, Loss: 0.5341, Train: 95.40%, Valid: 69.49% Test: 59.46%\n",
      "Run: 06, Epoch: 08, Loss: 0.5370, Train: 96.55%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 09, Loss: 0.3829, Train: 96.55%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 10, Loss: 0.3600, Train: 96.55%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 11, Loss: 0.3619, Train: 96.55%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 12, Loss: 0.3192, Train: 97.70%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 13, Loss: 0.3258, Train: 97.70%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 14, Loss: 0.2613, Train: 97.70%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 15, Loss: 0.2876, Train: 97.70%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 16, Loss: 0.2111, Train: 97.70%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 17, Loss: 0.2189, Train: 97.70%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 18, Loss: 0.2390, Train: 97.70%, Valid: 66.10% Test: 56.76%\n",
      "Run: 06, Epoch: 19, Loss: 0.1632, Train: 98.85%, Valid: 66.10% Test: 56.76%\n",
      "Run: 06, Epoch: 20, Loss: 0.1627, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 06, Epoch: 21, Loss: 0.1485, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 06, Epoch: 22, Loss: 0.1042, Train: 100.00%, Valid: 66.10% Test: 56.76%\n",
      "Run: 06, Epoch: 23, Loss: 0.1103, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 24, Loss: 0.1334, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 25, Loss: 0.1080, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 26, Loss: 0.1331, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 27, Loss: 0.1085, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 28, Loss: 0.0923, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 29, Loss: 0.1187, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 30, Loss: 0.1242, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 31, Loss: 0.0916, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 32, Loss: 0.0604, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 33, Loss: 0.0671, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 34, Loss: 0.1004, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 35, Loss: 0.0482, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 06, Epoch: 36, Loss: 0.1024, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 06, Epoch: 37, Loss: 0.0449, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 06, Epoch: 38, Loss: 0.0682, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 06, Epoch: 39, Loss: 0.0587, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 40, Loss: 0.0517, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 41, Loss: 0.0552, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 42, Loss: 0.0293, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 43, Loss: 0.0775, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 44, Loss: 0.0447, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 45, Loss: 0.0336, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 46, Loss: 0.0498, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 47, Loss: 0.0479, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 48, Loss: 0.0329, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 49, Loss: 0.0541, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 50, Loss: 0.0800, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 51, Loss: 0.0279, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 52, Loss: 0.0683, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 53, Loss: 0.0386, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 54, Loss: 0.0381, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 55, Loss: 0.0153, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 06, Epoch: 56, Loss: 0.0213, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 06, Epoch: 57, Loss: 0.0475, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 06, Epoch: 58, Loss: 0.0150, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 06, Epoch: 59, Loss: 0.0328, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 06, Epoch: 60, Loss: 0.0191, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 61, Loss: 0.0394, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 62, Loss: 0.0485, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 63, Loss: 0.0307, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 64, Loss: 0.0128, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 65, Loss: 0.0180, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 66, Loss: 0.0614, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 67, Loss: 0.0290, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 68, Loss: 0.0230, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 69, Loss: 0.0175, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 70, Loss: 0.0239, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 71, Loss: 0.0288, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 72, Loss: 0.0201, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 73, Loss: 0.0304, Train: 100.00%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 74, Loss: 0.0253, Train: 100.00%, Valid: 66.10% Test: 59.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 75, Loss: 0.0233, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 76, Loss: 0.0082, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 77, Loss: 0.0312, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 78, Loss: 0.0363, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 79, Loss: 0.0441, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 80, Loss: 0.0466, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 81, Loss: 0.0236, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 82, Loss: 0.0275, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 83, Loss: 0.0275, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 84, Loss: 0.0183, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 85, Loss: 0.0340, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 86, Loss: 0.0184, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 87, Loss: 0.0209, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 88, Loss: 0.0308, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 89, Loss: 0.0230, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 90, Loss: 0.0445, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 91, Loss: 0.0114, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 92, Loss: 0.0111, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 93, Loss: 0.0096, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 94, Loss: 0.0124, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 95, Loss: 0.0212, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 96, Loss: 0.0144, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 97, Loss: 0.0146, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 98, Loss: 0.0198, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 06, Epoch: 99, Loss: 0.0084, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 06, Epoch: 100, Loss: 0.0087, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run 06:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 72.88\n",
      "  Final Train: 80.46\n",
      "   Final Test: 54.05\n",
      "Run: 07, Epoch: 01, Loss: 1.7370, Train: 70.11%, Valid: 50.85% Test: 56.76%\n",
      "Run: 07, Epoch: 02, Loss: 0.9527, Train: 77.01%, Valid: 55.93% Test: 59.46%\n",
      "Run: 07, Epoch: 03, Loss: 0.8087, Train: 85.06%, Valid: 57.63% Test: 59.46%\n",
      "Run: 07, Epoch: 04, Loss: 0.7611, Train: 89.66%, Valid: 54.24% Test: 54.05%\n",
      "Run: 07, Epoch: 05, Loss: 0.7686, Train: 91.95%, Valid: 55.93% Test: 56.76%\n",
      "Run: 07, Epoch: 06, Loss: 0.6018, Train: 90.80%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 07, Loss: 0.5439, Train: 93.10%, Valid: 59.32% Test: 67.57%\n",
      "Run: 07, Epoch: 08, Loss: 0.4630, Train: 95.40%, Valid: 59.32% Test: 64.86%\n",
      "Run: 07, Epoch: 09, Loss: 0.4197, Train: 96.55%, Valid: 59.32% Test: 64.86%\n",
      "Run: 07, Epoch: 10, Loss: 0.3972, Train: 97.70%, Valid: 57.63% Test: 64.86%\n",
      "Run: 07, Epoch: 11, Loss: 0.3990, Train: 97.70%, Valid: 55.93% Test: 72.97%\n",
      "Run: 07, Epoch: 12, Loss: 0.3335, Train: 97.70%, Valid: 55.93% Test: 70.27%\n",
      "Run: 07, Epoch: 13, Loss: 0.3661, Train: 97.70%, Valid: 57.63% Test: 72.97%\n",
      "Run: 07, Epoch: 14, Loss: 0.3065, Train: 97.70%, Valid: 57.63% Test: 72.97%\n",
      "Run: 07, Epoch: 15, Loss: 0.2746, Train: 97.70%, Valid: 57.63% Test: 72.97%\n",
      "Run: 07, Epoch: 16, Loss: 0.2255, Train: 98.85%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 17, Loss: 0.2067, Train: 98.85%, Valid: 55.93% Test: 70.27%\n",
      "Run: 07, Epoch: 18, Loss: 0.1851, Train: 98.85%, Valid: 55.93% Test: 67.57%\n",
      "Run: 07, Epoch: 19, Loss: 0.1992, Train: 98.85%, Valid: 55.93% Test: 67.57%\n",
      "Run: 07, Epoch: 20, Loss: 0.1973, Train: 98.85%, Valid: 55.93% Test: 67.57%\n",
      "Run: 07, Epoch: 21, Loss: 0.2126, Train: 98.85%, Valid: 55.93% Test: 67.57%\n",
      "Run: 07, Epoch: 22, Loss: 0.1144, Train: 98.85%, Valid: 55.93% Test: 67.57%\n",
      "Run: 07, Epoch: 23, Loss: 0.0990, Train: 98.85%, Valid: 55.93% Test: 67.57%\n",
      "Run: 07, Epoch: 24, Loss: 0.1093, Train: 98.85%, Valid: 55.93% Test: 70.27%\n",
      "Run: 07, Epoch: 25, Loss: 0.1198, Train: 98.85%, Valid: 55.93% Test: 70.27%\n",
      "Run: 07, Epoch: 26, Loss: 0.1063, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 27, Loss: 0.1439, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 28, Loss: 0.0848, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 29, Loss: 0.0953, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 30, Loss: 0.0814, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 31, Loss: 0.1000, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 32, Loss: 0.0742, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 33, Loss: 0.0665, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 34, Loss: 0.0751, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 35, Loss: 0.0444, Train: 100.00%, Valid: 57.63% Test: 70.27%\n",
      "Run: 07, Epoch: 36, Loss: 0.0449, Train: 100.00%, Valid: 59.32% Test: 70.27%\n",
      "Run: 07, Epoch: 37, Loss: 0.0533, Train: 100.00%, Valid: 59.32% Test: 70.27%\n",
      "Run: 07, Epoch: 38, Loss: 0.0627, Train: 100.00%, Valid: 59.32% Test: 70.27%\n",
      "Run: 07, Epoch: 39, Loss: 0.0718, Train: 100.00%, Valid: 59.32% Test: 70.27%\n",
      "Run: 07, Epoch: 40, Loss: 0.0539, Train: 100.00%, Valid: 59.32% Test: 70.27%\n",
      "Run: 07, Epoch: 41, Loss: 0.0453, Train: 100.00%, Valid: 59.32% Test: 67.57%\n",
      "Run: 07, Epoch: 42, Loss: 0.0566, Train: 100.00%, Valid: 59.32% Test: 64.86%\n",
      "Run: 07, Epoch: 43, Loss: 0.0562, Train: 100.00%, Valid: 59.32% Test: 64.86%\n",
      "Run: 07, Epoch: 44, Loss: 0.0284, Train: 100.00%, Valid: 59.32% Test: 64.86%\n",
      "Run: 07, Epoch: 45, Loss: 0.0466, Train: 100.00%, Valid: 57.63% Test: 64.86%\n",
      "Run: 07, Epoch: 46, Loss: 0.0486, Train: 100.00%, Valid: 57.63% Test: 64.86%\n",
      "Run: 07, Epoch: 47, Loss: 0.0465, Train: 100.00%, Valid: 59.32% Test: 64.86%\n",
      "Run: 07, Epoch: 48, Loss: 0.0503, Train: 100.00%, Valid: 59.32% Test: 64.86%\n",
      "Run: 07, Epoch: 49, Loss: 0.0432, Train: 100.00%, Valid: 59.32% Test: 64.86%\n",
      "Run: 07, Epoch: 50, Loss: 0.0205, Train: 100.00%, Valid: 59.32% Test: 64.86%\n",
      "Run: 07, Epoch: 51, Loss: 0.0494, Train: 100.00%, Valid: 59.32% Test: 64.86%\n",
      "Run: 07, Epoch: 52, Loss: 0.0232, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 53, Loss: 0.0307, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 54, Loss: 0.0390, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 55, Loss: 0.0546, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 56, Loss: 0.0295, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 57, Loss: 0.0569, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 58, Loss: 0.0259, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 59, Loss: 0.0275, Train: 100.00%, Valid: 62.71% Test: 67.57%\n",
      "Run: 07, Epoch: 60, Loss: 0.0284, Train: 100.00%, Valid: 62.71% Test: 67.57%\n",
      "Run: 07, Epoch: 61, Loss: 0.0261, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 62, Loss: 0.0345, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 63, Loss: 0.0192, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 07, Epoch: 64, Loss: 0.0132, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 07, Epoch: 65, Loss: 0.0246, Train: 100.00%, Valid: 64.41% Test: 64.86%\n",
      "Run: 07, Epoch: 66, Loss: 0.0144, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 67, Loss: 0.0351, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 68, Loss: 0.0627, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 69, Loss: 0.0246, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 70, Loss: 0.0236, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 71, Loss: 0.0143, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 72, Loss: 0.0221, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 73, Loss: 0.0387, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 74, Loss: 0.0258, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 75, Loss: 0.0196, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 76, Loss: 0.0233, Train: 100.00%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 77, Loss: 0.0426, Train: 100.00%, Valid: 62.71% Test: 67.57%\n",
      "Run: 07, Epoch: 78, Loss: 0.0260, Train: 100.00%, Valid: 62.71% Test: 67.57%\n",
      "Run: 07, Epoch: 79, Loss: 0.0422, Train: 100.00%, Valid: 62.71% Test: 67.57%\n",
      "Run: 07, Epoch: 80, Loss: 0.0147, Train: 100.00%, Valid: 62.71% Test: 67.57%\n",
      "Run: 07, Epoch: 81, Loss: 0.0230, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 82, Loss: 0.0163, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 83, Loss: 0.0288, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 84, Loss: 0.0221, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 85, Loss: 0.0309, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 86, Loss: 0.0271, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 87, Loss: 0.0144, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 88, Loss: 0.0276, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 89, Loss: 0.0344, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 90, Loss: 0.0117, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 91, Loss: 0.0076, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 92, Loss: 0.0116, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 93, Loss: 0.0169, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 94, Loss: 0.0122, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 95, Loss: 0.0218, Train: 100.00%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 96, Loss: 0.0115, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 97, Loss: 0.0162, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 98, Loss: 0.0242, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 99, Loss: 0.0093, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 100, Loss: 0.0106, Train: 100.00%, Valid: 62.71% Test: 64.86%\n",
      "Run 07:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 64.41\n",
      "  Final Train: 100.00\n",
      "   Final Test: 67.57\n",
      "Run: 08, Epoch: 01, Loss: 1.6680, Train: 55.17%, Valid: 38.98% Test: 43.24%\n",
      "Run: 08, Epoch: 02, Loss: 1.1239, Train: 82.76%, Valid: 62.71% Test: 54.05%\n",
      "Run: 08, Epoch: 03, Loss: 0.8870, Train: 83.91%, Valid: 57.63% Test: 45.95%\n",
      "Run: 08, Epoch: 04, Loss: 0.7950, Train: 90.80%, Valid: 59.32% Test: 48.65%\n",
      "Run: 08, Epoch: 05, Loss: 0.6802, Train: 91.95%, Valid: 57.63% Test: 54.05%\n",
      "Run: 08, Epoch: 06, Loss: 0.8018, Train: 91.95%, Valid: 57.63% Test: 56.76%\n",
      "Run: 08, Epoch: 07, Loss: 0.5154, Train: 91.95%, Valid: 59.32% Test: 59.46%\n",
      "Run: 08, Epoch: 08, Loss: 0.5927, Train: 94.25%, Valid: 62.71% Test: 59.46%\n",
      "Run: 08, Epoch: 09, Loss: 0.5025, Train: 94.25%, Valid: 62.71% Test: 59.46%\n",
      "Run: 08, Epoch: 10, Loss: 0.4110, Train: 95.40%, Valid: 62.71% Test: 59.46%\n",
      "Run: 08, Epoch: 11, Loss: 0.3983, Train: 94.25%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 12, Loss: 0.3958, Train: 94.25%, Valid: 67.80% Test: 62.16%\n",
      "Run: 08, Epoch: 13, Loss: 0.4177, Train: 94.25%, Valid: 69.49% Test: 62.16%\n",
      "Run: 08, Epoch: 14, Loss: 0.3029, Train: 95.40%, Valid: 67.80% Test: 64.86%\n",
      "Run: 08, Epoch: 15, Loss: 0.3088, Train: 97.70%, Valid: 67.80% Test: 64.86%\n",
      "Run: 08, Epoch: 16, Loss: 0.2647, Train: 97.70%, Valid: 69.49% Test: 64.86%\n",
      "Run: 08, Epoch: 17, Loss: 0.2796, Train: 97.70%, Valid: 69.49% Test: 64.86%\n",
      "Run: 08, Epoch: 18, Loss: 0.2497, Train: 98.85%, Valid: 69.49% Test: 64.86%\n",
      "Run: 08, Epoch: 19, Loss: 0.2080, Train: 98.85%, Valid: 72.88% Test: 64.86%\n",
      "Run: 08, Epoch: 20, Loss: 0.2209, Train: 98.85%, Valid: 72.88% Test: 64.86%\n",
      "Run: 08, Epoch: 21, Loss: 0.1489, Train: 98.85%, Valid: 71.19% Test: 64.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 22, Loss: 0.1418, Train: 98.85%, Valid: 69.49% Test: 64.86%\n",
      "Run: 08, Epoch: 23, Loss: 0.1874, Train: 98.85%, Valid: 67.80% Test: 62.16%\n",
      "Run: 08, Epoch: 24, Loss: 0.1248, Train: 98.85%, Valid: 67.80% Test: 62.16%\n",
      "Run: 08, Epoch: 25, Loss: 0.1521, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 08, Epoch: 26, Loss: 0.1791, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 08, Epoch: 27, Loss: 0.1305, Train: 100.00%, Valid: 67.80% Test: 62.16%\n",
      "Run: 08, Epoch: 28, Loss: 0.1193, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 08, Epoch: 29, Loss: 0.1352, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 08, Epoch: 30, Loss: 0.0933, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 08, Epoch: 31, Loss: 0.1374, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 08, Epoch: 32, Loss: 0.1109, Train: 100.00%, Valid: 69.49% Test: 64.86%\n",
      "Run: 08, Epoch: 33, Loss: 0.0727, Train: 100.00%, Valid: 66.10% Test: 59.46%\n",
      "Run: 08, Epoch: 34, Loss: 0.0847, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 35, Loss: 0.0921, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 36, Loss: 0.0884, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 37, Loss: 0.0724, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 38, Loss: 0.0693, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 39, Loss: 0.0767, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 40, Loss: 0.0735, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 41, Loss: 0.0748, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 42, Loss: 0.0526, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 43, Loss: 0.0391, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 44, Loss: 0.0836, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 45, Loss: 0.0669, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 46, Loss: 0.0741, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 47, Loss: 0.0382, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 48, Loss: 0.0192, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 49, Loss: 0.0416, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 50, Loss: 0.0380, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 51, Loss: 0.0683, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 52, Loss: 0.0732, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 53, Loss: 0.0315, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 08, Epoch: 54, Loss: 0.0505, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 08, Epoch: 55, Loss: 0.0248, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 08, Epoch: 56, Loss: 0.0614, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 08, Epoch: 57, Loss: 0.0359, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 08, Epoch: 58, Loss: 0.0230, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 08, Epoch: 59, Loss: 0.0278, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 08, Epoch: 60, Loss: 0.0324, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 08, Epoch: 61, Loss: 0.0327, Train: 100.00%, Valid: 67.80% Test: 64.86%\n",
      "Run: 08, Epoch: 62, Loss: 0.0254, Train: 100.00%, Valid: 66.10% Test: 64.86%\n",
      "Run: 08, Epoch: 63, Loss: 0.0578, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 64, Loss: 0.0419, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 65, Loss: 0.0557, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 66, Loss: 0.0357, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 67, Loss: 0.0195, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 68, Loss: 0.0376, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 69, Loss: 0.0445, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 70, Loss: 0.0385, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 71, Loss: 0.0390, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 72, Loss: 0.0634, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 73, Loss: 0.0224, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 74, Loss: 0.0485, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 75, Loss: 0.0406, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 76, Loss: 0.0139, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 77, Loss: 0.0517, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 78, Loss: 0.0426, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 79, Loss: 0.0230, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 80, Loss: 0.0318, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 81, Loss: 0.0266, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 82, Loss: 0.0112, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 83, Loss: 0.0384, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 84, Loss: 0.0187, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 85, Loss: 0.0505, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 86, Loss: 0.0581, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 87, Loss: 0.0171, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 88, Loss: 0.0148, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 89, Loss: 0.0339, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 90, Loss: 0.0289, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 91, Loss: 0.0170, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 92, Loss: 0.0315, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 93, Loss: 0.0340, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 94, Loss: 0.0384, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 95, Loss: 0.0257, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 96, Loss: 0.0223, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 97, Loss: 0.0692, Train: 100.00%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 98, Loss: 0.0478, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 99, Loss: 0.0195, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run: 08, Epoch: 100, Loss: 0.0129, Train: 100.00%, Valid: 66.10% Test: 62.16%\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 72.88\n",
      "  Final Train: 98.85\n",
      "   Final Test: 64.86\n",
      "Run: 09, Epoch: 01, Loss: 1.6587, Train: 71.26%, Valid: 42.37% Test: 62.16%\n",
      "Run: 09, Epoch: 02, Loss: 0.9117, Train: 75.86%, Valid: 44.07% Test: 64.86%\n",
      "Run: 09, Epoch: 03, Loss: 0.8203, Train: 80.46%, Valid: 52.54% Test: 64.86%\n",
      "Run: 09, Epoch: 04, Loss: 0.8098, Train: 82.76%, Valid: 52.54% Test: 64.86%\n",
      "Run: 09, Epoch: 05, Loss: 0.5927, Train: 88.51%, Valid: 52.54% Test: 64.86%\n",
      "Run: 09, Epoch: 06, Loss: 0.5847, Train: 89.66%, Valid: 49.15% Test: 64.86%\n",
      "Run: 09, Epoch: 07, Loss: 0.5788, Train: 89.66%, Valid: 47.46% Test: 64.86%\n",
      "Run: 09, Epoch: 08, Loss: 0.5047, Train: 91.95%, Valid: 47.46% Test: 62.16%\n",
      "Run: 09, Epoch: 09, Loss: 0.4403, Train: 91.95%, Valid: 47.46% Test: 62.16%\n",
      "Run: 09, Epoch: 10, Loss: 0.4411, Train: 94.25%, Valid: 50.85% Test: 62.16%\n",
      "Run: 09, Epoch: 11, Loss: 0.3609, Train: 94.25%, Valid: 57.63% Test: 62.16%\n",
      "Run: 09, Epoch: 12, Loss: 0.3899, Train: 94.25%, Valid: 61.02% Test: 64.86%\n",
      "Run: 09, Epoch: 13, Loss: 0.3354, Train: 95.40%, Valid: 62.71% Test: 64.86%\n",
      "Run: 09, Epoch: 14, Loss: 0.3024, Train: 96.55%, Valid: 67.80% Test: 64.86%\n",
      "Run: 09, Epoch: 15, Loss: 0.2700, Train: 97.70%, Valid: 69.49% Test: 67.57%\n",
      "Run: 09, Epoch: 16, Loss: 0.2505, Train: 98.85%, Valid: 71.19% Test: 64.86%\n",
      "Run: 09, Epoch: 17, Loss: 0.2614, Train: 98.85%, Valid: 71.19% Test: 64.86%\n",
      "Run: 09, Epoch: 18, Loss: 0.2347, Train: 98.85%, Valid: 69.49% Test: 64.86%\n",
      "Run: 09, Epoch: 19, Loss: 0.2232, Train: 98.85%, Valid: 69.49% Test: 59.46%\n",
      "Run: 09, Epoch: 20, Loss: 0.1906, Train: 98.85%, Valid: 69.49% Test: 59.46%\n",
      "Run: 09, Epoch: 21, Loss: 0.1927, Train: 98.85%, Valid: 71.19% Test: 59.46%\n",
      "Run: 09, Epoch: 22, Loss: 0.2189, Train: 98.85%, Valid: 69.49% Test: 59.46%\n",
      "Run: 09, Epoch: 23, Loss: 0.2314, Train: 98.85%, Valid: 71.19% Test: 59.46%\n",
      "Run: 09, Epoch: 24, Loss: 0.1384, Train: 98.85%, Valid: 71.19% Test: 59.46%\n",
      "Run: 09, Epoch: 25, Loss: 0.1292, Train: 98.85%, Valid: 69.49% Test: 56.76%\n",
      "Run: 09, Epoch: 26, Loss: 0.1371, Train: 98.85%, Valid: 69.49% Test: 56.76%\n",
      "Run: 09, Epoch: 27, Loss: 0.1975, Train: 98.85%, Valid: 69.49% Test: 56.76%\n",
      "Run: 09, Epoch: 28, Loss: 0.1687, Train: 98.85%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 29, Loss: 0.1180, Train: 98.85%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 30, Loss: 0.0732, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 31, Loss: 0.1599, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 32, Loss: 0.1271, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 33, Loss: 0.0879, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 34, Loss: 0.0830, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 35, Loss: 0.0943, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 36, Loss: 0.0840, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 37, Loss: 0.1091, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 38, Loss: 0.0636, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 39, Loss: 0.0651, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 40, Loss: 0.0435, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 41, Loss: 0.0618, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 42, Loss: 0.0743, Train: 100.00%, Valid: 69.49% Test: 62.16%\n",
      "Run: 09, Epoch: 43, Loss: 0.0373, Train: 100.00%, Valid: 71.19% Test: 62.16%\n",
      "Run: 09, Epoch: 44, Loss: 0.0500, Train: 100.00%, Valid: 71.19% Test: 62.16%\n",
      "Run: 09, Epoch: 45, Loss: 0.0620, Train: 100.00%, Valid: 71.19% Test: 62.16%\n",
      "Run: 09, Epoch: 46, Loss: 0.0552, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 09, Epoch: 47, Loss: 0.0643, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 09, Epoch: 48, Loss: 0.0357, Train: 100.00%, Valid: 71.19% Test: 64.86%\n",
      "Run: 09, Epoch: 49, Loss: 0.0430, Train: 100.00%, Valid: 71.19% Test: 62.16%\n",
      "Run: 09, Epoch: 50, Loss: 0.0548, Train: 100.00%, Valid: 71.19% Test: 62.16%\n",
      "Run: 09, Epoch: 51, Loss: 0.0444, Train: 100.00%, Valid: 71.19% Test: 62.16%\n",
      "Run: 09, Epoch: 52, Loss: 0.0711, Train: 100.00%, Valid: 71.19% Test: 62.16%\n",
      "Run: 09, Epoch: 53, Loss: 0.0320, Train: 100.00%, Valid: 71.19% Test: 62.16%\n",
      "Run: 09, Epoch: 54, Loss: 0.0277, Train: 100.00%, Valid: 71.19% Test: 62.16%\n",
      "Run: 09, Epoch: 55, Loss: 0.0518, Train: 100.00%, Valid: 71.19% Test: 62.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 56, Loss: 0.0589, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 09, Epoch: 57, Loss: 0.0675, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 09, Epoch: 58, Loss: 0.0224, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 59, Loss: 0.0211, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 60, Loss: 0.0582, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 09, Epoch: 61, Loss: 0.0511, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 09, Epoch: 62, Loss: 0.0395, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 09, Epoch: 63, Loss: 0.0489, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 64, Loss: 0.0143, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 65, Loss: 0.0198, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 66, Loss: 0.0599, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 67, Loss: 0.0267, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 68, Loss: 0.0452, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 69, Loss: 0.0351, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 70, Loss: 0.0223, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 71, Loss: 0.0340, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 72, Loss: 0.0468, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 73, Loss: 0.0163, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 09, Epoch: 74, Loss: 0.0178, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 09, Epoch: 75, Loss: 0.0202, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 09, Epoch: 76, Loss: 0.0130, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 09, Epoch: 77, Loss: 0.0351, Train: 100.00%, Valid: 72.88% Test: 62.16%\n",
      "Run: 09, Epoch: 78, Loss: 0.0224, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 79, Loss: 0.0276, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 80, Loss: 0.0427, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 81, Loss: 0.0362, Train: 100.00%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 82, Loss: 0.0235, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 09, Epoch: 83, Loss: 0.0645, Train: 100.00%, Valid: 77.97% Test: 62.16%\n",
      "Run: 09, Epoch: 84, Loss: 0.0165, Train: 100.00%, Valid: 77.97% Test: 62.16%\n",
      "Run: 09, Epoch: 85, Loss: 0.0241, Train: 100.00%, Valid: 77.97% Test: 62.16%\n",
      "Run: 09, Epoch: 86, Loss: 0.0450, Train: 100.00%, Valid: 77.97% Test: 62.16%\n",
      "Run: 09, Epoch: 87, Loss: 0.0280, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 09, Epoch: 88, Loss: 0.0186, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 89, Loss: 0.0317, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 90, Loss: 0.0332, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 91, Loss: 0.0257, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 92, Loss: 0.0210, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 93, Loss: 0.0075, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 94, Loss: 0.0304, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 09, Epoch: 95, Loss: 0.0311, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 96, Loss: 0.0198, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 97, Loss: 0.0186, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 98, Loss: 0.0053, Train: 100.00%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 99, Loss: 0.0507, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run: 09, Epoch: 100, Loss: 0.0355, Train: 100.00%, Valid: 76.27% Test: 62.16%\n",
      "Run 09:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 77.97\n",
      "  Final Train: 100.00\n",
      "   Final Test: 62.16\n",
      "Run: 10, Epoch: 01, Loss: 1.8636, Train: 58.62%, Valid: 50.85% Test: 48.65%\n",
      "Run: 10, Epoch: 02, Loss: 1.0158, Train: 74.71%, Valid: 61.02% Test: 48.65%\n",
      "Run: 10, Epoch: 03, Loss: 1.0677, Train: 86.21%, Valid: 69.49% Test: 51.35%\n",
      "Run: 10, Epoch: 04, Loss: 0.7605, Train: 87.36%, Valid: 71.19% Test: 56.76%\n",
      "Run: 10, Epoch: 05, Loss: 0.6288, Train: 88.51%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 06, Loss: 0.6046, Train: 94.25%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 07, Loss: 0.5595, Train: 94.25%, Valid: 72.88% Test: 54.05%\n",
      "Run: 10, Epoch: 08, Loss: 0.5172, Train: 94.25%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 09, Loss: 0.4325, Train: 94.25%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 10, Loss: 0.4139, Train: 95.40%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 11, Loss: 0.4856, Train: 96.55%, Valid: 76.27% Test: 56.76%\n",
      "Run: 10, Epoch: 12, Loss: 0.3572, Train: 96.55%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 13, Loss: 0.3321, Train: 96.55%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 14, Loss: 0.3250, Train: 96.55%, Valid: 76.27% Test: 56.76%\n",
      "Run: 10, Epoch: 15, Loss: 0.2459, Train: 97.70%, Valid: 76.27% Test: 56.76%\n",
      "Run: 10, Epoch: 16, Loss: 0.2272, Train: 97.70%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 17, Loss: 0.2978, Train: 98.85%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 18, Loss: 0.1987, Train: 98.85%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 19, Loss: 0.2535, Train: 98.85%, Valid: 79.66% Test: 56.76%\n",
      "Run: 10, Epoch: 20, Loss: 0.1650, Train: 98.85%, Valid: 79.66% Test: 56.76%\n",
      "Run: 10, Epoch: 21, Loss: 0.1280, Train: 98.85%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 22, Loss: 0.1869, Train: 98.85%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 23, Loss: 0.1657, Train: 98.85%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 24, Loss: 0.1707, Train: 98.85%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 25, Loss: 0.1582, Train: 98.85%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 26, Loss: 0.1084, Train: 98.85%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 27, Loss: 0.0856, Train: 98.85%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 28, Loss: 0.0849, Train: 98.85%, Valid: 77.97% Test: 56.76%\n",
      "Run: 10, Epoch: 29, Loss: 0.1409, Train: 98.85%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 30, Loss: 0.1146, Train: 98.85%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 31, Loss: 0.0764, Train: 98.85%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 32, Loss: 0.0622, Train: 100.00%, Valid: 74.58% Test: 54.05%\n",
      "Run: 10, Epoch: 33, Loss: 0.0750, Train: 100.00%, Valid: 74.58% Test: 54.05%\n",
      "Run: 10, Epoch: 34, Loss: 0.0933, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 35, Loss: 0.1372, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 36, Loss: 0.0627, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 37, Loss: 0.0859, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 38, Loss: 0.0648, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 39, Loss: 0.0565, Train: 100.00%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 40, Loss: 0.0712, Train: 100.00%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 41, Loss: 0.0552, Train: 100.00%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 42, Loss: 0.0593, Train: 100.00%, Valid: 74.58% Test: 59.46%\n",
      "Run: 10, Epoch: 43, Loss: 0.0707, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 44, Loss: 0.0427, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 45, Loss: 0.0454, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 46, Loss: 0.0476, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 47, Loss: 0.0582, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 48, Loss: 0.0357, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 49, Loss: 0.0728, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 50, Loss: 0.0439, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 51, Loss: 0.0829, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 52, Loss: 0.0497, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 53, Loss: 0.0226, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 54, Loss: 0.0328, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 55, Loss: 0.0435, Train: 100.00%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 56, Loss: 0.0503, Train: 100.00%, Valid: 71.19% Test: 56.76%\n",
      "Run: 10, Epoch: 57, Loss: 0.0507, Train: 100.00%, Valid: 71.19% Test: 56.76%\n",
      "Run: 10, Epoch: 58, Loss: 0.0362, Train: 100.00%, Valid: 71.19% Test: 56.76%\n",
      "Run: 10, Epoch: 59, Loss: 0.0529, Train: 100.00%, Valid: 71.19% Test: 56.76%\n",
      "Run: 10, Epoch: 60, Loss: 0.0202, Train: 100.00%, Valid: 71.19% Test: 56.76%\n",
      "Run: 10, Epoch: 61, Loss: 0.0183, Train: 100.00%, Valid: 71.19% Test: 56.76%\n",
      "Run: 10, Epoch: 62, Loss: 0.0215, Train: 100.00%, Valid: 69.49% Test: 56.76%\n",
      "Run: 10, Epoch: 63, Loss: 0.0380, Train: 100.00%, Valid: 69.49% Test: 56.76%\n",
      "Run: 10, Epoch: 64, Loss: 0.0207, Train: 100.00%, Valid: 69.49% Test: 56.76%\n",
      "Run: 10, Epoch: 65, Loss: 0.0480, Train: 100.00%, Valid: 71.19% Test: 56.76%\n",
      "Run: 10, Epoch: 66, Loss: 0.0243, Train: 100.00%, Valid: 69.49% Test: 56.76%\n",
      "Run: 10, Epoch: 67, Loss: 0.0296, Train: 100.00%, Valid: 69.49% Test: 56.76%\n",
      "Run: 10, Epoch: 68, Loss: 0.0550, Train: 100.00%, Valid: 69.49% Test: 56.76%\n",
      "Run: 10, Epoch: 69, Loss: 0.0262, Train: 100.00%, Valid: 69.49% Test: 56.76%\n",
      "Run: 10, Epoch: 70, Loss: 0.0348, Train: 100.00%, Valid: 69.49% Test: 56.76%\n",
      "Run: 10, Epoch: 71, Loss: 0.0163, Train: 100.00%, Valid: 69.49% Test: 56.76%\n",
      "Run: 10, Epoch: 72, Loss: 0.0311, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 10, Epoch: 73, Loss: 0.0468, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 10, Epoch: 74, Loss: 0.0139, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 10, Epoch: 75, Loss: 0.0244, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 10, Epoch: 76, Loss: 0.0268, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 10, Epoch: 77, Loss: 0.0086, Train: 100.00%, Valid: 67.80% Test: 59.46%\n",
      "Run: 10, Epoch: 78, Loss: 0.0305, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 10, Epoch: 79, Loss: 0.0100, Train: 100.00%, Valid: 69.49% Test: 59.46%\n",
      "Run: 10, Epoch: 80, Loss: 0.0147, Train: 100.00%, Valid: 71.19% Test: 59.46%\n",
      "Run: 10, Epoch: 81, Loss: 0.0276, Train: 100.00%, Valid: 71.19% Test: 59.46%\n",
      "Run: 10, Epoch: 82, Loss: 0.0194, Train: 100.00%, Valid: 71.19% Test: 59.46%\n",
      "Run: 10, Epoch: 83, Loss: 0.0108, Train: 100.00%, Valid: 71.19% Test: 59.46%\n",
      "Run: 10, Epoch: 84, Loss: 0.0228, Train: 100.00%, Valid: 71.19% Test: 59.46%\n",
      "Run: 10, Epoch: 85, Loss: 0.0362, Train: 100.00%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 86, Loss: 0.0077, Train: 100.00%, Valid: 74.58% Test: 59.46%\n",
      "Run: 10, Epoch: 87, Loss: 0.0209, Train: 100.00%, Valid: 74.58% Test: 59.46%\n",
      "Run: 10, Epoch: 88, Loss: 0.0219, Train: 100.00%, Valid: 74.58% Test: 56.76%\n",
      "Run: 10, Epoch: 89, Loss: 0.0429, Train: 100.00%, Valid: 76.27% Test: 59.46%\n",
      "Run: 10, Epoch: 90, Loss: 0.0334, Train: 100.00%, Valid: 74.58% Test: 59.46%\n",
      "Run: 10, Epoch: 91, Loss: 0.0195, Train: 100.00%, Valid: 74.58% Test: 59.46%\n",
      "Run: 10, Epoch: 92, Loss: 0.0121, Train: 100.00%, Valid: 74.58% Test: 59.46%\n",
      "Run: 10, Epoch: 93, Loss: 0.0191, Train: 100.00%, Valid: 74.58% Test: 59.46%\n",
      "Run: 10, Epoch: 94, Loss: 0.0183, Train: 100.00%, Valid: 74.58% Test: 59.46%\n",
      "Run: 10, Epoch: 95, Loss: 0.0102, Train: 100.00%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 96, Loss: 0.0150, Train: 100.00%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 97, Loss: 0.0159, Train: 100.00%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 98, Loss: 0.0245, Train: 100.00%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 99, Loss: 0.0242, Train: 100.00%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 100, Loss: 0.0150, Train: 100.00%, Valid: 72.88% Test: 59.46%\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 79.66\n",
      "  Final Train: 98.85\n",
      "   Final Test: 56.76\n",
      "All runs:\n",
      "Highest Train: 100.00 ± 0.00\n",
      "Highest Valid: 69.49 ± 7.19\n",
      "  Final Train: 94.71 ± 7.21\n",
      "   Final Test: 61.89 ± 5.47\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 32, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-6, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    dataset = WebKB(root='/tmp/Cornell', name='Cornell',transform=T.ToSparseTensor())\n",
    "    data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    #idx_train=[data.train_mask[i][0] for i in range(len(data.y))]\n",
    "    #train_idx = np.where(idx_train)[0]\n",
    "    #idx_val=[data.val_mask[i][0] for i in range(len(data.y))]\n",
    "    #valid_idx = np.where(idx_val)[0]\n",
    "    #idx_test=[data.test_mask[i][0] for i in range(len(data.y))]\n",
    "    #test_idx = np.where(idx_test)[0]\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52f151",
   "metadata": {},
   "source": [
    "# WISE EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a09514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=298])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Cornell', name='Cornell',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f82a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "      <th>1697</th>\n",
       "      <th>1698</th>\n",
       "      <th>1699</th>\n",
       "      <th>1700</th>\n",
       "      <th>1701</th>\n",
       "      <th>1702</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1704 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  1694  1695  1696  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   1.0   \n",
       "\n",
       "   1697  1698  1699  1700  1701  1702  class  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0      0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "\n",
       "[5 rows x 1704 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Domain_Fec=pd.DataFrame(data.x.numpy())\n",
    "label=pd.DataFrame(data.y.numpy(),columns =['class'])\n",
    "Data=pd.concat([Domain_Fec,label], axis=1)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2642b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_nodes=len(data.y)\n",
    "fe_len=len(data.x[0])\n",
    "catagories=Data['class'].to_numpy()\n",
    "data_by_class = {cls: Data.loc[Data['class'] == cls].drop(['class'], axis=1) for cls in range(max(catagories) + 1)}\n",
    "basis = [[max(df[i]) for i in range(len(df.columns))] for df in data_by_class.values()]\n",
    "sel_basis = [[int(list(df[i].to_numpy()).count(1) >= int(len(df[i].index)*0.1)) \n",
    "              for i in range(len(df.columns))]\n",
    "             for df in data_by_class.values()]\n",
    "feature_names = [ii for ii in range(fe_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12133154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It takes long time\n",
    "Fec=[]\n",
    "for i in range(23):\n",
    "    vec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=np.zeros(7)\n",
    "    for j in range(1433):\n",
    "        for i in range(max(catagories)+1):\n",
    "            if f[j]==1 and basis[i][j]==1:\n",
    "                count[i]=count[i]+1;\n",
    "\n",
    "    for i in range(max(catagories)+1):\n",
    "        vec.append(count[i])\n",
    "    f.clear()\n",
    "    Fec.append(vec)\n",
    "print(Fec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4db5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fec=[]\n",
    "for i in range(Number_nodes):\n",
    "    vec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=0\n",
    "    count1=0\n",
    "    count2=0\n",
    "    count3=0\n",
    "    count4=0\n",
    "    for j in range(fe_len):\n",
    "        if f[j]==1 and basis[0][j]==1:\n",
    "            count=count+1;\n",
    "        if f[j]==1 and basis[1][j]==1:\n",
    "            count1=count1+1;\n",
    "        if f[j]==1 and basis[2][j]==1:\n",
    "            count2=count2+1;\n",
    "        if f[j]==1 and basis[3][j]==1:\n",
    "            count3=count3+1;\n",
    "        if f[j]==1 and basis[4][j]==1:\n",
    "            count4=count4+1;\n",
    "    vec.append(count)\n",
    "    vec.append(count1)\n",
    "    vec.append(count2)\n",
    "    vec.append(count3)\n",
    "    vec.append(count4)\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    Fec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "084212fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 2, 3, 4, 4], [51, 44, 51, 54, 39], [35, 24, 32, 32, 24], [59, 47, 60, 70, 39], [53, 56, 63, 71, 55], [115, 93, 122, 132, 92], [129, 99, 131, 136, 156], [116, 161, 151, 147, 122], [136, 138, 175, 157, 145], [18, 17, 18, 18, 18], [42, 38, 45, 43, 48], [63, 57, 71, 86, 55], [54, 65, 64, 64, 69], [63, 59, 70, 82, 55], [43, 42, 45, 46, 36], [51, 47, 50, 62, 47], [97, 96, 129, 116, 85], [81, 95, 85, 87, 72], [34, 33, 36, 36, 33], [211, 159, 208, 206, 263], [22, 23, 21, 23, 24], [194, 175, 257, 222, 179], [165, 103, 139, 137, 97], [53, 49, 54, 58, 52], [61, 85, 79, 80, 73], [37, 28, 33, 33, 28], [36, 40, 40, 48, 29], [109, 93, 128, 114, 84], [131, 171, 155, 160, 131], [108, 147, 133, 129, 111], [105, 85, 125, 134, 91], [46, 31, 40, 40, 32], [203, 200, 276, 241, 173], [210, 133, 168, 177, 122], [54, 45, 62, 68, 48], [54, 41, 49, 51, 36], [32, 33, 31, 34, 28], [114, 104, 141, 122, 98], [41, 48, 45, 48, 41], [41, 41, 42, 50, 35], [42, 42, 45, 47, 34], [88, 70, 93, 99, 78], [108, 72, 91, 96, 79], [108, 95, 124, 130, 93], [33, 31, 29, 35, 23], [42, 49, 47, 48, 35], [59, 60, 82, 75, 58], [64, 65, 69, 79, 63], [67, 46, 64, 62, 51], [58, 54, 59, 64, 52], [74, 67, 83, 95, 68], [175, 114, 135, 150, 98], [49, 35, 40, 43, 34], [46, 48, 55, 53, 35], [121, 107, 139, 149, 107], [47, 44, 44, 52, 46], [80, 72, 86, 102, 67], [92, 68, 87, 88, 72], [56, 71, 67, 70, 60], [31, 33, 34, 33, 31], [59, 60, 68, 63, 48], [62, 58, 70, 79, 57], [51, 41, 47, 47, 36], [78, 74, 83, 81, 90], [94, 69, 82, 81, 67], [99, 64, 85, 85, 62], [187, 109, 148, 163, 110], [55, 44, 46, 50, 40], [168, 147, 184, 204, 147], [30, 31, 31, 32, 30], [17, 22, 16, 18, 15], [70, 75, 91, 105, 62], [101, 90, 125, 113, 94], [42, 32, 42, 39, 32], [63, 61, 67, 71, 47], [60, 53, 63, 71, 50], [114, 157, 149, 134, 109], [33, 31, 39, 39, 25], [106, 102, 133, 117, 91], [72, 73, 81, 99, 61], [82, 86, 106, 91, 71], [276, 159, 215, 228, 156], [54, 52, 68, 63, 48], [299, 173, 244, 240, 194], [134, 136, 164, 200, 120], [45, 31, 40, 42, 33], [93, 66, 75, 80, 60], [75, 48, 61, 66, 48], [78, 68, 86, 103, 66], [96, 79, 106, 120, 85], [161, 166, 211, 178, 160], [34, 29, 40, 46, 30], [58, 56, 61, 63, 50], [101, 80, 103, 120, 77], [51, 35, 46, 43, 32], [160, 148, 200, 178, 136], [65, 52, 82, 71, 53], [70, 52, 63, 61, 44], [35, 35, 37, 39, 30], [92, 91, 107, 111, 86], [86, 83, 99, 106, 80], [192, 167, 211, 209, 241], [18, 17, 20, 19, 20], [53, 52, 60, 56, 46], [178, 117, 151, 153, 103], [169, 172, 227, 202, 157], [71, 70, 90, 103, 69], [64, 56, 64, 70, 57], [70, 62, 74, 88, 60], [46, 44, 50, 50, 45], [62, 59, 66, 67, 56], [145, 131, 183, 158, 117], [19, 18, 19, 22, 18], [92, 100, 122, 105, 86], [114, 120, 160, 134, 94], [153, 93, 134, 135, 99], [76, 62, 72, 71, 62], [59, 43, 46, 52, 35], [53, 48, 52, 56, 43], [28, 26, 29, 29, 29], [1, 1, 1, 1, 1], [54, 56, 65, 71, 47], [50, 48, 54, 53, 57], [123, 156, 142, 141, 110], [39, 37, 42, 43, 34], [49, 41, 47, 55, 43], [46, 41, 41, 44, 38], [71, 90, 81, 79, 67], [53, 47, 55, 61, 43], [35, 38, 38, 40, 37], [51, 43, 57, 70, 41], [32, 26, 32, 36, 27], [33, 32, 35, 39, 31], [18, 22, 16, 19, 15], [47, 32, 37, 42, 27], [136, 124, 167, 152, 119], [65, 69, 78, 76, 80], [82, 103, 96, 93, 83], [79, 51, 64, 68, 51], [43, 45, 44, 50, 40], [88, 83, 103, 129, 74], [50, 38, 43, 48, 36], [108, 134, 122, 118, 89], [77, 49, 63, 67, 43], [56, 50, 58, 63, 48], [132, 126, 183, 158, 121], [93, 72, 82, 86, 66], [50, 43, 53, 55, 45], [81, 75, 94, 116, 68], [54, 40, 48, 51, 47], [106, 82, 116, 141, 87], [24, 23, 24, 24, 24], [91, 88, 114, 104, 84], [161, 145, 219, 186, 139], [82, 71, 85, 95, 76], [57, 49, 64, 68, 51], [124, 102, 137, 174, 112], [37, 33, 38, 41, 32], [150, 106, 160, 192, 106], [123, 112, 147, 143, 161], [81, 82, 93, 101, 72], [134, 93, 120, 119, 99], [150, 147, 196, 164, 120], [44, 38, 45, 48, 39], [58, 52, 59, 66, 52], [74, 63, 80, 90, 63], [34, 34, 36, 36, 32], [124, 150, 141, 137, 113], [33, 33, 36, 37, 31], [36, 35, 39, 37, 40], [26, 25, 27, 32, 25], [44, 39, 40, 42, 38], [46, 44, 52, 49, 53], [65, 52, 72, 79, 57], [34, 35, 38, 39, 35], [35, 39, 47, 48, 34], [66, 61, 72, 73, 78], [47, 40, 41, 44, 34], [40, 40, 46, 49, 35], [65, 71, 74, 71, 78], [69, 61, 79, 88, 59], [88, 85, 101, 94, 68], [168, 144, 232, 192, 115]]\n"
     ]
    }
   ],
   "source": [
    "print(Fec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a920e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFec=[]\n",
    "for i in range(Number_nodes):\n",
    "    Svec=[]\n",
    "    f=Data.loc[i, feature_names].values.flatten().tolist()\n",
    "    count=0\n",
    "    count1=0\n",
    "    count2=0\n",
    "    count3=0\n",
    "    count4=0\n",
    "    for j in range(fe_len):\n",
    "        if f[j]==1 and sel_basis[0][j]==1:\n",
    "            count=count+1;\n",
    "        if f[j]==1 and sel_basis[1][j]==1:\n",
    "            count1=count1+1;\n",
    "        if f[j]==1 and sel_basis[2][j]==1:\n",
    "            count2=count2+1;\n",
    "        if f[j]==1 and sel_basis[3][j]==1:\n",
    "            count3=count3+1;\n",
    "        if f[j]==1 and sel_basis[4][j]==1:\n",
    "            count4=count4+1;\n",
    "    Svec.append(count)\n",
    "    Svec.append(count1)\n",
    "    Svec.append(count2)\n",
    "    Svec.append(count3)\n",
    "    Svec.append(count4)\n",
    "    #print(f)\n",
    "    f.clear()\n",
    "    SFec.append(Svec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3715b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 2, 2, 2, 4], [40, 44, 42, 39, 39], [29, 24, 21, 15, 24], [42, 47, 49, 40, 39], [36, 56, 50, 41, 55], [85, 93, 94, 58, 92], [81, 99, 90, 47, 156], [75, 161, 114, 50, 122], [86, 138, 133, 64, 145], [16, 17, 17, 16, 18], [35, 38, 36, 27, 48], [43, 57, 50, 51, 55], [35, 65, 55, 20, 69], [46, 59, 55, 57, 55], [37, 42, 41, 37, 36], [38, 47, 42, 37, 47], [63, 96, 107, 54, 85], [60, 95, 70, 44, 72], [30, 33, 35, 34, 33], [123, 159, 140, 67, 263], [17, 23, 20, 19, 24], [115, 175, 190, 75, 179], [121, 103, 103, 55, 97], [38, 49, 45, 45, 52], [46, 85, 62, 47, 73], [34, 28, 27, 24, 28], [24, 40, 37, 32, 29], [70, 93, 105, 49, 84], [82, 171, 121, 66, 131], [71, 147, 111, 59, 111], [70, 85, 85, 79, 91], [43, 31, 32, 28, 32], [126, 200, 220, 72, 173], [149, 133, 107, 71, 122], [43, 45, 46, 42, 48], [50, 41, 39, 35, 36], [28, 33, 30, 31, 28], [62, 104, 113, 44, 98], [35, 48, 40, 37, 41], [33, 41, 34, 42, 35], [37, 42, 42, 35, 34], [70, 70, 72, 50, 78], [78, 72, 72, 45, 79], [64, 95, 94, 57, 93], [31, 31, 23, 27, 23], [40, 49, 43, 37, 35], [42, 60, 64, 39, 58], [43, 65, 53, 48, 63], [57, 46, 46, 38, 51], [47, 54, 50, 47, 52], [57, 67, 63, 59, 68], [131, 114, 92, 55, 98], [42, 35, 30, 29, 34], [35, 48, 51, 28, 35], [72, 107, 107, 51, 107], [40, 44, 39, 36, 46], [59, 72, 64, 67, 67], [68, 68, 67, 51, 72], [40, 71, 54, 41, 60], [31, 33, 33, 26, 31], [45, 60, 61, 33, 48], [39, 58, 55, 50, 57], [47, 41, 37, 34, 36], [55, 74, 65, 43, 90], [81, 69, 72, 41, 67], [80, 64, 51, 29, 62], [106, 109, 93, 50, 110], [52, 44, 41, 31, 40], [98, 147, 128, 71, 147], [27, 31, 29, 30, 30], [11, 22, 13, 9, 15], [49, 75, 70, 64, 62], [71, 90, 102, 51, 94], [38, 32, 33, 27, 32], [45, 61, 55, 51, 47], [47, 53, 51, 56, 50], [80, 157, 125, 51, 109], [26, 31, 33, 29, 25], [67, 102, 111, 38, 91], [56, 73, 61, 63, 61], [59, 86, 93, 37, 71], [191, 159, 138, 70, 156], [43, 52, 58, 43, 48], [202, 173, 169, 75, 194], [85, 136, 111, 83, 120], [38, 31, 32, 25, 33], [84, 66, 56, 34, 60], [64, 48, 44, 30, 48], [53, 68, 63, 60, 66], [58, 79, 71, 63, 85], [95, 166, 160, 66, 160], [25, 29, 29, 22, 30], [46, 56, 55, 46, 50], [65, 80, 75, 67, 77], [49, 35, 41, 27, 32], [97, 148, 157, 63, 136], [45, 52, 64, 35, 53], [48, 52, 50, 27, 44], [31, 35, 33, 37, 30], [71, 91, 82, 65, 86], [55, 83, 73, 56, 80], [107, 167, 143, 65, 241], [15, 17, 17, 16, 20], [44, 52, 49, 39, 46], [134, 117, 104, 59, 103], [104, 172, 180, 61, 157], [54, 70, 65, 57, 69], [44, 56, 54, 50, 57], [51, 62, 56, 63, 60], [34, 44, 42, 38, 45], [53, 59, 56, 58, 56], [87, 131, 134, 57, 117], [14, 18, 16, 17, 18], [63, 100, 109, 47, 86], [73, 120, 132, 45, 94], [118, 93, 93, 48, 99], [64, 62, 57, 35, 62], [53, 43, 39, 33, 35], [44, 48, 42, 42, 43], [25, 26, 28, 26, 29], [1, 1, 1, 1, 1], [37, 56, 55, 33, 47], [37, 48, 39, 28, 57], [78, 156, 108, 69, 110], [35, 37, 37, 37, 34], [42, 41, 40, 37, 43], [44, 41, 35, 35, 38], [49, 90, 72, 39, 67], [44, 47, 44, 42, 43], [32, 38, 35, 36, 37], [37, 43, 43, 46, 41], [25, 26, 24, 27, 27], [28, 32, 28, 30, 31], [11, 22, 13, 9, 15], [40, 32, 34, 24, 27], [95, 124, 140, 73, 119], [43, 69, 56, 37, 80], [59, 103, 74, 56, 83], [66, 51, 45, 32, 51], [36, 45, 40, 37, 40], [54, 83, 76, 65, 74], [47, 38, 36, 29, 36], [76, 134, 97, 58, 89], [67, 49, 47, 29, 43], [41, 50, 50, 58, 48], [83, 126, 140, 65, 121], [69, 72, 63, 43, 66], [40, 43, 43, 45, 45], [62, 75, 75, 64, 68], [46, 40, 34, 32, 47], [67, 82, 74, 63, 87], [22, 23, 23, 22, 24], [64, 88, 97, 51, 84], [83, 145, 158, 55, 139], [62, 71, 61, 51, 76], [45, 49, 53, 43, 51], [83, 102, 87, 74, 112], [29, 33, 34, 34, 32], [97, 106, 98, 76, 106], [62, 112, 95, 49, 161], [56, 82, 76, 55, 72], [90, 93, 85, 46, 99], [92, 147, 152, 52, 120], [37, 38, 36, 37, 39], [45, 52, 53, 51, 52], [52, 63, 63, 58, 63], [31, 34, 32, 29, 32], [87, 150, 107, 58, 113], [30, 33, 32, 30, 31], [30, 35, 35, 28, 40], [22, 25, 26, 25, 25], [42, 39, 36, 35, 38], [37, 44, 42, 36, 53], [41, 52, 51, 39, 57], [31, 35, 33, 36, 35], [23, 39, 38, 18, 34], [48, 61, 55, 37, 78], [43, 40, 33, 29, 34], [32, 40, 36, 37, 35], [50, 71, 60, 41, 78], [49, 61, 63, 55, 59], [61, 85, 90, 52, 68], [101, 144, 157, 68, 115]]\n"
     ]
    }
   ],
   "source": [
    "print(SFec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054ee569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  3.,   2.,   3.,  ...,   2.,   2.,   4.],\n",
      "        [ 51.,  44.,  51.,  ...,  42.,  39.,  39.],\n",
      "        [ 35.,  24.,  32.,  ...,  21.,  15.,  24.],\n",
      "        ...,\n",
      "        [ 69.,  61.,  79.,  ...,  63.,  55.,  59.],\n",
      "        [ 88.,  85., 101.,  ...,  90.,  52.,  68.],\n",
      "        [168., 144., 232.,  ..., 157.,  68., 115.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inc_fe=torch.tensor(Fec)\n",
    "sel_fe=torch.tensor(SFec)\n",
    "CC_domain=torch.cat((Inc_fe, sel_fe), 1).float()\n",
    "print(CC_domain)\n",
    "CC_domain.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f7d51",
   "metadata": {},
   "source": [
    "# W-GSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c6fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 10], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=298])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4763ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x16319f250>\n",
      "Run: 01, Epoch: 01, Loss: 1.7838, Train: 19.54%, Valid: 20.34% Test: 24.32%\n",
      "Run: 01, Epoch: 02, Loss: 1.5707, Train: 19.54%, Valid: 18.64% Test: 27.03%\n",
      "Run: 01, Epoch: 03, Loss: 1.3747, Train: 19.54%, Valid: 18.64% Test: 27.03%\n",
      "Run: 01, Epoch: 04, Loss: 1.3540, Train: 19.54%, Valid: 18.64% Test: 27.03%\n",
      "Run: 01, Epoch: 05, Loss: 1.3624, Train: 19.54%, Valid: 18.64% Test: 27.03%\n",
      "Run: 01, Epoch: 06, Loss: 1.2908, Train: 20.69%, Valid: 18.64% Test: 27.03%\n",
      "Run: 01, Epoch: 07, Loss: 1.1782, Train: 21.84%, Valid: 18.64% Test: 27.03%\n",
      "Run: 01, Epoch: 08, Loss: 1.1346, Train: 22.99%, Valid: 18.64% Test: 29.73%\n",
      "Run: 01, Epoch: 09, Loss: 1.1935, Train: 26.44%, Valid: 22.03% Test: 29.73%\n",
      "Run: 01, Epoch: 10, Loss: 1.1813, Train: 33.33%, Valid: 28.81% Test: 35.14%\n",
      "Run: 01, Epoch: 11, Loss: 1.0403, Train: 39.08%, Valid: 40.68% Test: 48.65%\n",
      "Run: 01, Epoch: 12, Loss: 1.0716, Train: 45.98%, Valid: 47.46% Test: 54.05%\n",
      "Run: 01, Epoch: 13, Loss: 0.9638, Train: 54.02%, Valid: 52.54% Test: 64.86%\n",
      "Run: 01, Epoch: 14, Loss: 1.0121, Train: 57.47%, Valid: 64.41% Test: 64.86%\n",
      "Run: 01, Epoch: 15, Loss: 1.0157, Train: 66.67%, Valid: 64.41% Test: 64.86%\n",
      "Run: 01, Epoch: 16, Loss: 0.8873, Train: 66.67%, Valid: 64.41% Test: 70.27%\n",
      "Run: 01, Epoch: 17, Loss: 0.8397, Train: 64.37%, Valid: 62.71% Test: 70.27%\n",
      "Run: 01, Epoch: 18, Loss: 0.8647, Train: 64.37%, Valid: 67.80% Test: 67.57%\n",
      "Run: 01, Epoch: 19, Loss: 0.8970, Train: 62.07%, Valid: 69.49% Test: 62.16%\n",
      "Run: 01, Epoch: 20, Loss: 0.7283, Train: 60.92%, Valid: 69.49% Test: 62.16%\n",
      "Run: 01, Epoch: 21, Loss: 0.7525, Train: 65.52%, Valid: 67.80% Test: 62.16%\n",
      "Run: 01, Epoch: 22, Loss: 0.7503, Train: 67.82%, Valid: 69.49% Test: 62.16%\n",
      "Run: 01, Epoch: 23, Loss: 0.6657, Train: 68.97%, Valid: 71.19% Test: 59.46%\n",
      "Run: 01, Epoch: 24, Loss: 0.7358, Train: 75.86%, Valid: 71.19% Test: 62.16%\n",
      "Run: 01, Epoch: 25, Loss: 0.7937, Train: 78.16%, Valid: 71.19% Test: 64.86%\n",
      "Run: 01, Epoch: 26, Loss: 0.7031, Train: 81.61%, Valid: 76.27% Test: 70.27%\n",
      "Run: 01, Epoch: 27, Loss: 0.6798, Train: 78.16%, Valid: 76.27% Test: 70.27%\n",
      "Run: 01, Epoch: 28, Loss: 0.5993, Train: 75.86%, Valid: 77.97% Test: 72.97%\n",
      "Run: 01, Epoch: 29, Loss: 0.6176, Train: 74.71%, Valid: 79.66% Test: 64.86%\n",
      "Run: 01, Epoch: 30, Loss: 0.6372, Train: 71.26%, Valid: 74.58% Test: 67.57%\n",
      "Run: 01, Epoch: 31, Loss: 0.5596, Train: 65.52%, Valid: 72.88% Test: 67.57%\n",
      "Run: 01, Epoch: 32, Loss: 0.6055, Train: 70.11%, Valid: 72.88% Test: 64.86%\n",
      "Run: 01, Epoch: 33, Loss: 0.6074, Train: 77.01%, Valid: 77.97% Test: 67.57%\n",
      "Run: 01, Epoch: 34, Loss: 0.5852, Train: 82.76%, Valid: 77.97% Test: 64.86%\n",
      "Run: 01, Epoch: 35, Loss: 0.5737, Train: 81.61%, Valid: 79.66% Test: 64.86%\n",
      "Run: 01, Epoch: 36, Loss: 0.5051, Train: 85.06%, Valid: 77.97% Test: 64.86%\n",
      "Run: 01, Epoch: 37, Loss: 0.5283, Train: 81.61%, Valid: 74.58% Test: 67.57%\n",
      "Run: 01, Epoch: 38, Loss: 0.5390, Train: 74.71%, Valid: 72.88% Test: 67.57%\n",
      "Run: 01, Epoch: 39, Loss: 0.4941, Train: 70.11%, Valid: 72.88% Test: 59.46%\n",
      "Run: 01, Epoch: 40, Loss: 0.4223, Train: 64.37%, Valid: 69.49% Test: 54.05%\n",
      "Run: 01, Epoch: 41, Loss: 0.4531, Train: 62.07%, Valid: 69.49% Test: 51.35%\n",
      "Run: 01, Epoch: 42, Loss: 0.4905, Train: 63.22%, Valid: 69.49% Test: 51.35%\n",
      "Run: 01, Epoch: 43, Loss: 0.4885, Train: 64.37%, Valid: 71.19% Test: 54.05%\n",
      "Run: 01, Epoch: 44, Loss: 0.3812, Train: 70.11%, Valid: 74.58% Test: 56.76%\n",
      "Run: 01, Epoch: 45, Loss: 0.4295, Train: 81.61%, Valid: 81.36% Test: 59.46%\n",
      "Run: 01, Epoch: 46, Loss: 0.4197, Train: 90.80%, Valid: 79.66% Test: 67.57%\n",
      "Run: 01, Epoch: 47, Loss: 0.4187, Train: 88.51%, Valid: 76.27% Test: 72.97%\n",
      "Run: 01, Epoch: 48, Loss: 0.3896, Train: 89.66%, Valid: 76.27% Test: 75.68%\n",
      "Run: 01, Epoch: 49, Loss: 0.4540, Train: 93.10%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 50, Loss: 0.3845, Train: 91.95%, Valid: 81.36% Test: 72.97%\n",
      "Run: 01, Epoch: 51, Loss: 0.3988, Train: 82.76%, Valid: 81.36% Test: 72.97%\n",
      "Run: 01, Epoch: 52, Loss: 0.3641, Train: 78.16%, Valid: 79.66% Test: 67.57%\n",
      "Run: 01, Epoch: 53, Loss: 0.3631, Train: 77.01%, Valid: 79.66% Test: 67.57%\n",
      "Run: 01, Epoch: 54, Loss: 0.4058, Train: 80.46%, Valid: 79.66% Test: 70.27%\n",
      "Run: 01, Epoch: 55, Loss: 0.3669, Train: 86.21%, Valid: 79.66% Test: 75.68%\n",
      "Run: 01, Epoch: 56, Loss: 0.3791, Train: 91.95%, Valid: 81.36% Test: 75.68%\n",
      "Run: 01, Epoch: 57, Loss: 0.3154, Train: 93.10%, Valid: 89.83% Test: 78.38%\n",
      "Run: 01, Epoch: 58, Loss: 0.3385, Train: 93.10%, Valid: 89.83% Test: 75.68%\n",
      "Run: 01, Epoch: 59, Loss: 0.3561, Train: 93.10%, Valid: 89.83% Test: 81.08%\n",
      "Run: 01, Epoch: 60, Loss: 0.3117, Train: 95.40%, Valid: 83.05% Test: 83.78%\n",
      "Run: 01, Epoch: 61, Loss: 0.4288, Train: 94.25%, Valid: 89.83% Test: 89.19%\n",
      "Run: 01, Epoch: 62, Loss: 0.4000, Train: 93.10%, Valid: 88.14% Test: 83.78%\n",
      "Run: 01, Epoch: 63, Loss: 0.3482, Train: 95.40%, Valid: 89.83% Test: 83.78%\n",
      "Run: 01, Epoch: 64, Loss: 0.2674, Train: 94.25%, Valid: 89.83% Test: 86.49%\n",
      "Run: 01, Epoch: 65, Loss: 0.2830, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 01, Epoch: 66, Loss: 0.2790, Train: 94.25%, Valid: 89.83% Test: 86.49%\n",
      "Run: 01, Epoch: 67, Loss: 0.3393, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 01, Epoch: 68, Loss: 0.4665, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 01, Epoch: 69, Loss: 0.3529, Train: 86.21%, Valid: 81.36% Test: 75.68%\n",
      "Run: 01, Epoch: 70, Loss: 0.3743, Train: 83.91%, Valid: 83.05% Test: 72.97%\n",
      "Run: 01, Epoch: 71, Loss: 0.3540, Train: 82.76%, Valid: 83.05% Test: 72.97%\n",
      "Run: 01, Epoch: 72, Loss: 0.3154, Train: 81.61%, Valid: 83.05% Test: 72.97%\n",
      "Run: 01, Epoch: 73, Loss: 0.3524, Train: 82.76%, Valid: 83.05% Test: 72.97%\n",
      "Run: 01, Epoch: 74, Loss: 0.3414, Train: 82.76%, Valid: 81.36% Test: 72.97%\n",
      "Run: 01, Epoch: 75, Loss: 0.3245, Train: 90.80%, Valid: 83.05% Test: 75.68%\n",
      "Run: 01, Epoch: 76, Loss: 0.3016, Train: 91.95%, Valid: 84.75% Test: 78.38%\n",
      "Run: 01, Epoch: 77, Loss: 0.3156, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 01, Epoch: 78, Loss: 0.3025, Train: 93.10%, Valid: 89.83% Test: 86.49%\n",
      "Run: 01, Epoch: 79, Loss: 0.2641, Train: 93.10%, Valid: 91.53% Test: 83.78%\n",
      "Run: 01, Epoch: 80, Loss: 0.3472, Train: 94.25%, Valid: 89.83% Test: 83.78%\n",
      "Run: 01, Epoch: 81, Loss: 0.3744, Train: 95.40%, Valid: 86.44% Test: 86.49%\n",
      "Run: 01, Epoch: 82, Loss: 0.3015, Train: 90.80%, Valid: 86.44% Test: 83.78%\n",
      "Run: 01, Epoch: 83, Loss: 0.3449, Train: 88.51%, Valid: 86.44% Test: 83.78%\n",
      "Run: 01, Epoch: 84, Loss: 0.2785, Train: 88.51%, Valid: 86.44% Test: 78.38%\n",
      "Run: 01, Epoch: 85, Loss: 0.3640, Train: 89.66%, Valid: 88.14% Test: 78.38%\n",
      "Run: 01, Epoch: 86, Loss: 0.2797, Train: 91.95%, Valid: 89.83% Test: 78.38%\n",
      "Run: 01, Epoch: 87, Loss: 0.3205, Train: 95.40%, Valid: 88.14% Test: 78.38%\n",
      "Run: 01, Epoch: 88, Loss: 0.3359, Train: 94.25%, Valid: 86.44% Test: 78.38%\n",
      "Run: 01, Epoch: 89, Loss: 0.2312, Train: 94.25%, Valid: 84.75% Test: 78.38%\n",
      "Run: 01, Epoch: 90, Loss: 0.3483, Train: 94.25%, Valid: 84.75% Test: 78.38%\n",
      "Run: 01, Epoch: 91, Loss: 0.2667, Train: 94.25%, Valid: 83.05% Test: 72.97%\n",
      "Run: 01, Epoch: 92, Loss: 0.2946, Train: 88.51%, Valid: 83.05% Test: 70.27%\n",
      "Run: 01, Epoch: 93, Loss: 0.3769, Train: 85.06%, Valid: 79.66% Test: 72.97%\n",
      "Run: 01, Epoch: 94, Loss: 0.3328, Train: 83.91%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 95, Loss: 0.2430, Train: 82.76%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 96, Loss: 0.2200, Train: 82.76%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 97, Loss: 0.2734, Train: 86.21%, Valid: 83.05% Test: 78.38%\n",
      "Run: 01, Epoch: 98, Loss: 0.3087, Train: 87.36%, Valid: 86.44% Test: 81.08%\n",
      "Run: 01, Epoch: 99, Loss: 0.2410, Train: 88.51%, Valid: 89.83% Test: 78.38%\n",
      "Run: 01, Epoch: 100, Loss: 0.2479, Train: 91.95%, Valid: 86.44% Test: 81.08%\n",
      "Run 01:\n",
      "Highest Train: 95.40\n",
      "Highest Valid: 91.53\n",
      "  Final Train: 93.10\n",
      "   Final Test: 83.78\n",
      "Run: 02, Epoch: 01, Loss: 1.8528, Train: 11.49%, Valid: 6.78% Test: 8.11%\n",
      "Run: 02, Epoch: 02, Loss: 1.6720, Train: 31.03%, Valid: 20.34% Test: 32.43%\n",
      "Run: 02, Epoch: 03, Loss: 1.4811, Train: 49.43%, Valid: 42.37% Test: 54.05%\n",
      "Run: 02, Epoch: 04, Loss: 1.3496, Train: 51.72%, Valid: 40.68% Test: 56.76%\n",
      "Run: 02, Epoch: 05, Loss: 1.2409, Train: 55.17%, Valid: 45.76% Test: 54.05%\n",
      "Run: 02, Epoch: 06, Loss: 1.1358, Train: 60.92%, Valid: 50.85% Test: 62.16%\n",
      "Run: 02, Epoch: 07, Loss: 1.1054, Train: 63.22%, Valid: 52.54% Test: 59.46%\n",
      "Run: 02, Epoch: 08, Loss: 1.0341, Train: 63.22%, Valid: 54.24% Test: 48.65%\n",
      "Run: 02, Epoch: 09, Loss: 1.0812, Train: 64.37%, Valid: 61.02% Test: 48.65%\n",
      "Run: 02, Epoch: 10, Loss: 0.9584, Train: 67.82%, Valid: 59.32% Test: 54.05%\n",
      "Run: 02, Epoch: 11, Loss: 0.9362, Train: 71.26%, Valid: 59.32% Test: 59.46%\n",
      "Run: 02, Epoch: 12, Loss: 0.9940, Train: 73.56%, Valid: 61.02% Test: 59.46%\n",
      "Run: 02, Epoch: 13, Loss: 0.8886, Train: 71.26%, Valid: 62.71% Test: 59.46%\n",
      "Run: 02, Epoch: 14, Loss: 0.7892, Train: 65.52%, Valid: 66.10% Test: 56.76%\n",
      "Run: 02, Epoch: 15, Loss: 0.8254, Train: 64.37%, Valid: 69.49% Test: 56.76%\n",
      "Run: 02, Epoch: 16, Loss: 0.7440, Train: 66.67%, Valid: 69.49% Test: 59.46%\n",
      "Run: 02, Epoch: 17, Loss: 0.6736, Train: 66.67%, Valid: 62.71% Test: 56.76%\n",
      "Run: 02, Epoch: 18, Loss: 0.7753, Train: 64.37%, Valid: 62.71% Test: 54.05%\n",
      "Run: 02, Epoch: 19, Loss: 0.6975, Train: 64.37%, Valid: 59.32% Test: 62.16%\n",
      "Run: 02, Epoch: 20, Loss: 0.6754, Train: 64.37%, Valid: 57.63% Test: 62.16%\n",
      "Run: 02, Epoch: 21, Loss: 0.6407, Train: 65.52%, Valid: 61.02% Test: 62.16%\n",
      "Run: 02, Epoch: 22, Loss: 0.6606, Train: 70.11%, Valid: 62.71% Test: 62.16%\n",
      "Run: 02, Epoch: 23, Loss: 0.6770, Train: 72.41%, Valid: 64.41% Test: 64.86%\n",
      "Run: 02, Epoch: 24, Loss: 0.6483, Train: 77.01%, Valid: 66.10% Test: 64.86%\n",
      "Run: 02, Epoch: 25, Loss: 0.5659, Train: 78.16%, Valid: 66.10% Test: 64.86%\n",
      "Run: 02, Epoch: 26, Loss: 0.6025, Train: 79.31%, Valid: 67.80% Test: 64.86%\n",
      "Run: 02, Epoch: 27, Loss: 0.5372, Train: 80.46%, Valid: 67.80% Test: 67.57%\n",
      "Run: 02, Epoch: 28, Loss: 0.5509, Train: 83.91%, Valid: 66.10% Test: 72.97%\n",
      "Run: 02, Epoch: 29, Loss: 0.4585, Train: 85.06%, Valid: 66.10% Test: 72.97%\n",
      "Run: 02, Epoch: 30, Loss: 0.5046, Train: 83.91%, Valid: 66.10% Test: 62.16%\n",
      "Run: 02, Epoch: 31, Loss: 0.4046, Train: 86.21%, Valid: 69.49% Test: 64.86%\n",
      "Run: 02, Epoch: 32, Loss: 0.4430, Train: 86.21%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 33, Loss: 0.5891, Train: 86.21%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 34, Loss: 0.4767, Train: 83.91%, Valid: 69.49% Test: 62.16%\n",
      "Run: 02, Epoch: 35, Loss: 0.4133, Train: 83.91%, Valid: 79.66% Test: 70.27%\n",
      "Run: 02, Epoch: 36, Loss: 0.4159, Train: 82.76%, Valid: 76.27% Test: 67.57%\n",
      "Run: 02, Epoch: 37, Loss: 0.3684, Train: 87.36%, Valid: 77.97% Test: 64.86%\n",
      "Run: 02, Epoch: 38, Loss: 0.4213, Train: 86.21%, Valid: 79.66% Test: 70.27%\n",
      "Run: 02, Epoch: 39, Loss: 0.3892, Train: 86.21%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 40, Loss: 0.4136, Train: 88.51%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 41, Loss: 0.3704, Train: 88.51%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 42, Loss: 0.3847, Train: 89.66%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 43, Loss: 0.3348, Train: 90.80%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 44, Loss: 0.4491, Train: 90.80%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 45, Loss: 0.3278, Train: 89.66%, Valid: 79.66% Test: 78.38%\n",
      "Run: 02, Epoch: 46, Loss: 0.3471, Train: 90.80%, Valid: 77.97% Test: 70.27%\n",
      "Run: 02, Epoch: 47, Loss: 0.3068, Train: 89.66%, Valid: 74.58% Test: 64.86%\n",
      "Run: 02, Epoch: 48, Loss: 0.2590, Train: 88.51%, Valid: 72.88% Test: 67.57%\n",
      "Run: 02, Epoch: 49, Loss: 0.2719, Train: 89.66%, Valid: 72.88% Test: 67.57%\n",
      "Run: 02, Epoch: 50, Loss: 0.3347, Train: 88.51%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 51, Loss: 0.3619, Train: 87.36%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 52, Loss: 0.2892, Train: 86.21%, Valid: 72.88% Test: 72.97%\n",
      "Run: 02, Epoch: 53, Loss: 0.3237, Train: 87.36%, Valid: 72.88% Test: 75.68%\n",
      "Run: 02, Epoch: 54, Loss: 0.2458, Train: 89.66%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 55, Loss: 0.2378, Train: 90.80%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 56, Loss: 0.3130, Train: 90.80%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 57, Loss: 0.2578, Train: 90.80%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 58, Loss: 0.3380, Train: 90.80%, Valid: 83.05% Test: 81.08%\n",
      "Run: 02, Epoch: 59, Loss: 0.2555, Train: 93.10%, Valid: 81.36% Test: 81.08%\n",
      "Run: 02, Epoch: 60, Loss: 0.2929, Train: 93.10%, Valid: 79.66% Test: 78.38%\n",
      "Run: 02, Epoch: 61, Loss: 0.2211, Train: 93.10%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 62, Loss: 0.2605, Train: 91.95%, Valid: 81.36% Test: 72.97%\n",
      "Run: 02, Epoch: 63, Loss: 0.2327, Train: 93.10%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 64, Loss: 0.2625, Train: 93.10%, Valid: 83.05% Test: 75.68%\n",
      "Run: 02, Epoch: 65, Loss: 0.2383, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 02, Epoch: 66, Loss: 0.2897, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 02, Epoch: 67, Loss: 0.2951, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 02, Epoch: 68, Loss: 0.2137, Train: 91.95%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 69, Loss: 0.2259, Train: 93.10%, Valid: 79.66% Test: 78.38%\n",
      "Run: 02, Epoch: 70, Loss: 0.1795, Train: 95.40%, Valid: 79.66% Test: 78.38%\n",
      "Run: 02, Epoch: 71, Loss: 0.2048, Train: 95.40%, Valid: 81.36% Test: 78.38%\n",
      "Run: 02, Epoch: 72, Loss: 0.2482, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 02, Epoch: 73, Loss: 0.1781, Train: 93.10%, Valid: 81.36% Test: 83.78%\n",
      "Run: 02, Epoch: 74, Loss: 0.1967, Train: 93.10%, Valid: 79.66% Test: 83.78%\n",
      "Run: 02, Epoch: 75, Loss: 0.2848, Train: 93.10%, Valid: 79.66% Test: 83.78%\n",
      "Run: 02, Epoch: 76, Loss: 0.2523, Train: 93.10%, Valid: 81.36% Test: 81.08%\n",
      "Run: 02, Epoch: 77, Loss: 0.2453, Train: 96.55%, Valid: 81.36% Test: 78.38%\n",
      "Run: 02, Epoch: 78, Loss: 0.2760, Train: 97.70%, Valid: 83.05% Test: 75.68%\n",
      "Run: 02, Epoch: 79, Loss: 0.1881, Train: 97.70%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 80, Loss: 0.2919, Train: 98.85%, Valid: 81.36% Test: 81.08%\n",
      "Run: 02, Epoch: 81, Loss: 0.1707, Train: 97.70%, Valid: 81.36% Test: 81.08%\n",
      "Run: 02, Epoch: 82, Loss: 0.2141, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 02, Epoch: 83, Loss: 0.1590, Train: 88.51%, Valid: 79.66% Test: 75.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 84, Loss: 0.2619, Train: 89.66%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 85, Loss: 0.2222, Train: 91.95%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 86, Loss: 0.1877, Train: 93.10%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 87, Loss: 0.2560, Train: 95.40%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 88, Loss: 0.2074, Train: 95.40%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 89, Loss: 0.2143, Train: 96.55%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 90, Loss: 0.1904, Train: 94.25%, Valid: 81.36% Test: 81.08%\n",
      "Run: 02, Epoch: 91, Loss: 0.1980, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 02, Epoch: 92, Loss: 0.1890, Train: 91.95%, Valid: 84.75% Test: 78.38%\n",
      "Run: 02, Epoch: 93, Loss: 0.2529, Train: 90.80%, Valid: 86.44% Test: 78.38%\n",
      "Run: 02, Epoch: 94, Loss: 0.2714, Train: 90.80%, Valid: 81.36% Test: 81.08%\n",
      "Run: 02, Epoch: 95, Loss: 0.2702, Train: 94.25%, Valid: 79.66% Test: 83.78%\n",
      "Run: 02, Epoch: 96, Loss: 0.2160, Train: 95.40%, Valid: 76.27% Test: 81.08%\n",
      "Run: 02, Epoch: 97, Loss: 0.1891, Train: 90.80%, Valid: 72.88% Test: 78.38%\n",
      "Run: 02, Epoch: 98, Loss: 0.2078, Train: 91.95%, Valid: 71.19% Test: 78.38%\n",
      "Run: 02, Epoch: 99, Loss: 0.2023, Train: 93.10%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 100, Loss: 0.2048, Train: 91.95%, Valid: 77.97% Test: 78.38%\n",
      "Run 02:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 86.44\n",
      "  Final Train: 90.80\n",
      "   Final Test: 78.38\n",
      "Run: 03, Epoch: 01, Loss: 1.8165, Train: 20.69%, Valid: 20.34% Test: 21.62%\n",
      "Run: 03, Epoch: 02, Loss: 1.5930, Train: 20.69%, Valid: 20.34% Test: 21.62%\n",
      "Run: 03, Epoch: 03, Loss: 1.4836, Train: 20.69%, Valid: 20.34% Test: 21.62%\n",
      "Run: 03, Epoch: 04, Loss: 1.3277, Train: 20.69%, Valid: 20.34% Test: 21.62%\n",
      "Run: 03, Epoch: 05, Loss: 1.2390, Train: 22.99%, Valid: 20.34% Test: 24.32%\n",
      "Run: 03, Epoch: 06, Loss: 1.1973, Train: 24.14%, Valid: 22.03% Test: 29.73%\n",
      "Run: 03, Epoch: 07, Loss: 1.2088, Train: 40.23%, Valid: 32.20% Test: 40.54%\n",
      "Run: 03, Epoch: 08, Loss: 1.1433, Train: 48.28%, Valid: 47.46% Test: 43.24%\n",
      "Run: 03, Epoch: 09, Loss: 1.1227, Train: 54.02%, Valid: 45.76% Test: 45.95%\n",
      "Run: 03, Epoch: 10, Loss: 1.0543, Train: 63.22%, Valid: 52.54% Test: 62.16%\n",
      "Run: 03, Epoch: 11, Loss: 1.1060, Train: 68.97%, Valid: 54.24% Test: 64.86%\n",
      "Run: 03, Epoch: 12, Loss: 0.9284, Train: 67.82%, Valid: 57.63% Test: 67.57%\n",
      "Run: 03, Epoch: 13, Loss: 1.0310, Train: 70.11%, Valid: 55.93% Test: 67.57%\n",
      "Run: 03, Epoch: 14, Loss: 0.7692, Train: 70.11%, Valid: 55.93% Test: 67.57%\n",
      "Run: 03, Epoch: 15, Loss: 0.7785, Train: 68.97%, Valid: 57.63% Test: 70.27%\n",
      "Run: 03, Epoch: 16, Loss: 0.8130, Train: 68.97%, Valid: 57.63% Test: 70.27%\n",
      "Run: 03, Epoch: 17, Loss: 0.7694, Train: 70.11%, Valid: 57.63% Test: 72.97%\n",
      "Run: 03, Epoch: 18, Loss: 0.7952, Train: 70.11%, Valid: 55.93% Test: 70.27%\n",
      "Run: 03, Epoch: 19, Loss: 0.7858, Train: 72.41%, Valid: 59.32% Test: 72.97%\n",
      "Run: 03, Epoch: 20, Loss: 0.7158, Train: 77.01%, Valid: 62.71% Test: 72.97%\n",
      "Run: 03, Epoch: 21, Loss: 0.5951, Train: 78.16%, Valid: 59.32% Test: 70.27%\n",
      "Run: 03, Epoch: 22, Loss: 0.6369, Train: 78.16%, Valid: 55.93% Test: 67.57%\n",
      "Run: 03, Epoch: 23, Loss: 0.5832, Train: 79.31%, Valid: 55.93% Test: 67.57%\n",
      "Run: 03, Epoch: 24, Loss: 0.6304, Train: 79.31%, Valid: 55.93% Test: 67.57%\n",
      "Run: 03, Epoch: 25, Loss: 0.5803, Train: 80.46%, Valid: 57.63% Test: 67.57%\n",
      "Run: 03, Epoch: 26, Loss: 0.6553, Train: 81.61%, Valid: 57.63% Test: 64.86%\n",
      "Run: 03, Epoch: 27, Loss: 0.5868, Train: 81.61%, Valid: 57.63% Test: 67.57%\n",
      "Run: 03, Epoch: 28, Loss: 0.5886, Train: 77.01%, Valid: 59.32% Test: 70.27%\n",
      "Run: 03, Epoch: 29, Loss: 0.4979, Train: 77.01%, Valid: 59.32% Test: 70.27%\n",
      "Run: 03, Epoch: 30, Loss: 0.4834, Train: 77.01%, Valid: 55.93% Test: 70.27%\n",
      "Run: 03, Epoch: 31, Loss: 0.5082, Train: 75.86%, Valid: 59.32% Test: 72.97%\n",
      "Run: 03, Epoch: 32, Loss: 0.4751, Train: 77.01%, Valid: 57.63% Test: 72.97%\n",
      "Run: 03, Epoch: 33, Loss: 0.5040, Train: 75.86%, Valid: 57.63% Test: 72.97%\n",
      "Run: 03, Epoch: 34, Loss: 0.4610, Train: 75.86%, Valid: 57.63% Test: 72.97%\n",
      "Run: 03, Epoch: 35, Loss: 0.5185, Train: 78.16%, Valid: 55.93% Test: 75.68%\n",
      "Run: 03, Epoch: 36, Loss: 0.4461, Train: 79.31%, Valid: 61.02% Test: 75.68%\n",
      "Run: 03, Epoch: 37, Loss: 0.4257, Train: 81.61%, Valid: 64.41% Test: 78.38%\n",
      "Run: 03, Epoch: 38, Loss: 0.4392, Train: 81.61%, Valid: 67.80% Test: 78.38%\n",
      "Run: 03, Epoch: 39, Loss: 0.4261, Train: 81.61%, Valid: 71.19% Test: 81.08%\n",
      "Run: 03, Epoch: 40, Loss: 0.4271, Train: 86.21%, Valid: 72.88% Test: 83.78%\n",
      "Run: 03, Epoch: 41, Loss: 0.4400, Train: 83.91%, Valid: 74.58% Test: 86.49%\n",
      "Run: 03, Epoch: 42, Loss: 0.3319, Train: 82.76%, Valid: 72.88% Test: 86.49%\n",
      "Run: 03, Epoch: 43, Loss: 0.3761, Train: 82.76%, Valid: 72.88% Test: 81.08%\n",
      "Run: 03, Epoch: 44, Loss: 0.4131, Train: 87.36%, Valid: 71.19% Test: 83.78%\n",
      "Run: 03, Epoch: 45, Loss: 0.4125, Train: 87.36%, Valid: 66.10% Test: 72.97%\n",
      "Run: 03, Epoch: 46, Loss: 0.4169, Train: 87.36%, Valid: 62.71% Test: 70.27%\n",
      "Run: 03, Epoch: 47, Loss: 0.3772, Train: 85.06%, Valid: 67.80% Test: 72.97%\n",
      "Run: 03, Epoch: 48, Loss: 0.4097, Train: 87.36%, Valid: 66.10% Test: 78.38%\n",
      "Run: 03, Epoch: 49, Loss: 0.3518, Train: 85.06%, Valid: 64.41% Test: 72.97%\n",
      "Run: 03, Epoch: 50, Loss: 0.3146, Train: 80.46%, Valid: 57.63% Test: 72.97%\n",
      "Run: 03, Epoch: 51, Loss: 0.3109, Train: 75.86%, Valid: 54.24% Test: 70.27%\n",
      "Run: 03, Epoch: 52, Loss: 0.4194, Train: 77.01%, Valid: 55.93% Test: 67.57%\n",
      "Run: 03, Epoch: 53, Loss: 0.3642, Train: 79.31%, Valid: 62.71% Test: 78.38%\n",
      "Run: 03, Epoch: 54, Loss: 0.3426, Train: 81.61%, Valid: 66.10% Test: 78.38%\n",
      "Run: 03, Epoch: 55, Loss: 0.2549, Train: 85.06%, Valid: 66.10% Test: 81.08%\n",
      "Run: 03, Epoch: 56, Loss: 0.3149, Train: 86.21%, Valid: 66.10% Test: 75.68%\n",
      "Run: 03, Epoch: 57, Loss: 0.3426, Train: 85.06%, Valid: 66.10% Test: 78.38%\n",
      "Run: 03, Epoch: 58, Loss: 0.3465, Train: 85.06%, Valid: 64.41% Test: 81.08%\n",
      "Run: 03, Epoch: 59, Loss: 0.3036, Train: 87.36%, Valid: 66.10% Test: 81.08%\n",
      "Run: 03, Epoch: 60, Loss: 0.3194, Train: 87.36%, Valid: 67.80% Test: 83.78%\n",
      "Run: 03, Epoch: 61, Loss: 0.2785, Train: 89.66%, Valid: 71.19% Test: 81.08%\n",
      "Run: 03, Epoch: 62, Loss: 0.3219, Train: 91.95%, Valid: 72.88% Test: 81.08%\n",
      "Run: 03, Epoch: 63, Loss: 0.3049, Train: 93.10%, Valid: 74.58% Test: 81.08%\n",
      "Run: 03, Epoch: 64, Loss: 0.2290, Train: 93.10%, Valid: 74.58% Test: 75.68%\n",
      "Run: 03, Epoch: 65, Loss: 0.3015, Train: 93.10%, Valid: 76.27% Test: 78.38%\n",
      "Run: 03, Epoch: 66, Loss: 0.3330, Train: 91.95%, Valid: 76.27% Test: 78.38%\n",
      "Run: 03, Epoch: 67, Loss: 0.2474, Train: 93.10%, Valid: 77.97% Test: 81.08%\n",
      "Run: 03, Epoch: 68, Loss: 0.3039, Train: 90.80%, Valid: 77.97% Test: 78.38%\n",
      "Run: 03, Epoch: 69, Loss: 0.1911, Train: 89.66%, Valid: 76.27% Test: 75.68%\n",
      "Run: 03, Epoch: 70, Loss: 0.2775, Train: 90.80%, Valid: 72.88% Test: 75.68%\n",
      "Run: 03, Epoch: 71, Loss: 0.3050, Train: 89.66%, Valid: 74.58% Test: 75.68%\n",
      "Run: 03, Epoch: 72, Loss: 0.2045, Train: 90.80%, Valid: 74.58% Test: 89.19%\n",
      "Run: 03, Epoch: 73, Loss: 0.3050, Train: 93.10%, Valid: 74.58% Test: 83.78%\n",
      "Run: 03, Epoch: 74, Loss: 0.2382, Train: 93.10%, Valid: 76.27% Test: 81.08%\n",
      "Run: 03, Epoch: 75, Loss: 0.2398, Train: 94.25%, Valid: 76.27% Test: 81.08%\n",
      "Run: 03, Epoch: 76, Loss: 0.2262, Train: 94.25%, Valid: 76.27% Test: 78.38%\n",
      "Run: 03, Epoch: 77, Loss: 0.2064, Train: 95.40%, Valid: 76.27% Test: 75.68%\n",
      "Run: 03, Epoch: 78, Loss: 0.2671, Train: 96.55%, Valid: 79.66% Test: 70.27%\n",
      "Run: 03, Epoch: 79, Loss: 0.2680, Train: 95.40%, Valid: 79.66% Test: 70.27%\n",
      "Run: 03, Epoch: 80, Loss: 0.2200, Train: 97.70%, Valid: 79.66% Test: 70.27%\n",
      "Run: 03, Epoch: 81, Loss: 0.1941, Train: 97.70%, Valid: 79.66% Test: 75.68%\n",
      "Run: 03, Epoch: 82, Loss: 0.2153, Train: 97.70%, Valid: 74.58% Test: 78.38%\n",
      "Run: 03, Epoch: 83, Loss: 0.2075, Train: 98.85%, Valid: 76.27% Test: 75.68%\n",
      "Run: 03, Epoch: 84, Loss: 0.1890, Train: 100.00%, Valid: 79.66% Test: 75.68%\n",
      "Run: 03, Epoch: 85, Loss: 0.1704, Train: 98.85%, Valid: 81.36% Test: 75.68%\n",
      "Run: 03, Epoch: 86, Loss: 0.1948, Train: 98.85%, Valid: 79.66% Test: 75.68%\n",
      "Run: 03, Epoch: 87, Loss: 0.3381, Train: 97.70%, Valid: 79.66% Test: 75.68%\n",
      "Run: 03, Epoch: 88, Loss: 0.2179, Train: 98.85%, Valid: 81.36% Test: 75.68%\n",
      "Run: 03, Epoch: 89, Loss: 0.2324, Train: 97.70%, Valid: 79.66% Test: 78.38%\n",
      "Run: 03, Epoch: 90, Loss: 0.2275, Train: 95.40%, Valid: 79.66% Test: 78.38%\n",
      "Run: 03, Epoch: 91, Loss: 0.2019, Train: 95.40%, Valid: 77.97% Test: 78.38%\n",
      "Run: 03, Epoch: 92, Loss: 0.1555, Train: 91.95%, Valid: 76.27% Test: 81.08%\n",
      "Run: 03, Epoch: 93, Loss: 0.1982, Train: 90.80%, Valid: 74.58% Test: 81.08%\n",
      "Run: 03, Epoch: 94, Loss: 0.2381, Train: 89.66%, Valid: 72.88% Test: 81.08%\n",
      "Run: 03, Epoch: 95, Loss: 0.2291, Train: 89.66%, Valid: 72.88% Test: 75.68%\n",
      "Run: 03, Epoch: 96, Loss: 0.1829, Train: 88.51%, Valid: 71.19% Test: 70.27%\n",
      "Run: 03, Epoch: 97, Loss: 0.1645, Train: 89.66%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 98, Loss: 0.1788, Train: 88.51%, Valid: 74.58% Test: 64.86%\n",
      "Run: 03, Epoch: 99, Loss: 0.1258, Train: 89.66%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 100, Loss: 0.1966, Train: 91.95%, Valid: 74.58% Test: 67.57%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 81.36\n",
      "  Final Train: 98.85\n",
      "   Final Test: 75.68\n",
      "Run: 04, Epoch: 01, Loss: 1.7649, Train: 16.09%, Valid: 20.34% Test: 10.81%\n",
      "Run: 04, Epoch: 02, Loss: 1.6752, Train: 17.24%, Valid: 25.42% Test: 21.62%\n",
      "Run: 04, Epoch: 03, Loss: 1.4313, Train: 21.84%, Valid: 32.20% Test: 29.73%\n",
      "Run: 04, Epoch: 04, Loss: 1.2880, Train: 35.63%, Valid: 45.76% Test: 37.84%\n",
      "Run: 04, Epoch: 05, Loss: 1.3105, Train: 48.28%, Valid: 45.76% Test: 40.54%\n",
      "Run: 04, Epoch: 06, Loss: 1.2076, Train: 59.77%, Valid: 49.15% Test: 45.95%\n",
      "Run: 04, Epoch: 07, Loss: 1.1521, Train: 59.77%, Valid: 52.54% Test: 45.95%\n",
      "Run: 04, Epoch: 08, Loss: 1.2253, Train: 59.77%, Valid: 54.24% Test: 43.24%\n",
      "Run: 04, Epoch: 09, Loss: 1.2453, Train: 64.37%, Valid: 52.54% Test: 45.95%\n",
      "Run: 04, Epoch: 10, Loss: 1.1014, Train: 68.97%, Valid: 54.24% Test: 48.65%\n",
      "Run: 04, Epoch: 11, Loss: 1.0521, Train: 65.52%, Valid: 57.63% Test: 48.65%\n",
      "Run: 04, Epoch: 12, Loss: 1.0329, Train: 63.22%, Valid: 50.85% Test: 51.35%\n",
      "Run: 04, Epoch: 13, Loss: 0.9397, Train: 63.22%, Valid: 50.85% Test: 51.35%\n",
      "Run: 04, Epoch: 14, Loss: 0.8249, Train: 63.22%, Valid: 52.54% Test: 51.35%\n",
      "Run: 04, Epoch: 15, Loss: 0.9154, Train: 63.22%, Valid: 54.24% Test: 54.05%\n",
      "Run: 04, Epoch: 16, Loss: 0.8377, Train: 64.37%, Valid: 55.93% Test: 56.76%\n",
      "Run: 04, Epoch: 17, Loss: 0.8402, Train: 67.82%, Valid: 55.93% Test: 59.46%\n",
      "Run: 04, Epoch: 18, Loss: 0.7324, Train: 67.82%, Valid: 57.63% Test: 59.46%\n",
      "Run: 04, Epoch: 19, Loss: 0.7406, Train: 70.11%, Valid: 57.63% Test: 59.46%\n",
      "Run: 04, Epoch: 20, Loss: 0.7062, Train: 71.26%, Valid: 54.24% Test: 56.76%\n",
      "Run: 04, Epoch: 21, Loss: 0.6415, Train: 72.41%, Valid: 54.24% Test: 70.27%\n",
      "Run: 04, Epoch: 22, Loss: 0.6367, Train: 73.56%, Valid: 54.24% Test: 70.27%\n",
      "Run: 04, Epoch: 23, Loss: 0.5834, Train: 74.71%, Valid: 55.93% Test: 75.68%\n",
      "Run: 04, Epoch: 24, Loss: 0.5045, Train: 77.01%, Valid: 62.71% Test: 72.97%\n",
      "Run: 04, Epoch: 25, Loss: 0.5362, Train: 77.01%, Valid: 62.71% Test: 72.97%\n",
      "Run: 04, Epoch: 26, Loss: 0.5247, Train: 79.31%, Valid: 62.71% Test: 70.27%\n",
      "Run: 04, Epoch: 27, Loss: 0.5711, Train: 79.31%, Valid: 61.02% Test: 72.97%\n",
      "Run: 04, Epoch: 28, Loss: 0.5281, Train: 78.16%, Valid: 61.02% Test: 70.27%\n",
      "Run: 04, Epoch: 29, Loss: 0.5046, Train: 75.86%, Valid: 55.93% Test: 67.57%\n",
      "Run: 04, Epoch: 30, Loss: 0.4488, Train: 72.41%, Valid: 54.24% Test: 67.57%\n",
      "Run: 04, Epoch: 31, Loss: 0.3926, Train: 73.56%, Valid: 55.93% Test: 67.57%\n",
      "Run: 04, Epoch: 32, Loss: 0.3376, Train: 77.01%, Valid: 59.32% Test: 67.57%\n",
      "Run: 04, Epoch: 33, Loss: 0.4040, Train: 80.46%, Valid: 64.41% Test: 67.57%\n",
      "Run: 04, Epoch: 34, Loss: 0.4344, Train: 86.21%, Valid: 72.88% Test: 70.27%\n",
      "Run: 04, Epoch: 35, Loss: 0.4085, Train: 87.36%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 36, Loss: 0.3735, Train: 87.36%, Valid: 71.19% Test: 75.68%\n",
      "Run: 04, Epoch: 37, Loss: 0.3315, Train: 88.51%, Valid: 76.27% Test: 75.68%\n",
      "Run: 04, Epoch: 38, Loss: 0.3141, Train: 88.51%, Valid: 74.58% Test: 78.38%\n",
      "Run: 04, Epoch: 39, Loss: 0.3987, Train: 89.66%, Valid: 76.27% Test: 78.38%\n",
      "Run: 04, Epoch: 40, Loss: 0.3951, Train: 90.80%, Valid: 79.66% Test: 78.38%\n",
      "Run: 04, Epoch: 41, Loss: 0.3382, Train: 89.66%, Valid: 76.27% Test: 78.38%\n",
      "Run: 04, Epoch: 42, Loss: 0.3291, Train: 89.66%, Valid: 76.27% Test: 78.38%\n",
      "Run: 04, Epoch: 43, Loss: 0.2784, Train: 89.66%, Valid: 76.27% Test: 83.78%\n",
      "Run: 04, Epoch: 44, Loss: 0.3541, Train: 88.51%, Valid: 76.27% Test: 83.78%\n",
      "Run: 04, Epoch: 45, Loss: 0.3984, Train: 87.36%, Valid: 77.97% Test: 83.78%\n",
      "Run: 04, Epoch: 46, Loss: 0.2688, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 47, Loss: 0.2650, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 48, Loss: 0.2805, Train: 91.95%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 49, Loss: 0.3247, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 50, Loss: 0.2623, Train: 94.25%, Valid: 83.05% Test: 81.08%\n",
      "Run: 04, Epoch: 51, Loss: 0.1727, Train: 94.25%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 52, Loss: 0.3029, Train: 95.40%, Valid: 76.27% Test: 81.08%\n",
      "Run: 04, Epoch: 53, Loss: 0.2157, Train: 95.40%, Valid: 79.66% Test: 83.78%\n",
      "Run: 04, Epoch: 54, Loss: 0.2348, Train: 95.40%, Valid: 77.97% Test: 86.49%\n",
      "Run: 04, Epoch: 55, Loss: 0.2405, Train: 94.25%, Valid: 74.58% Test: 83.78%\n",
      "Run: 04, Epoch: 56, Loss: 0.2556, Train: 94.25%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 57, Loss: 0.2434, Train: 89.66%, Valid: 69.49% Test: 70.27%\n",
      "Run: 04, Epoch: 58, Loss: 0.2819, Train: 85.06%, Valid: 71.19% Test: 67.57%\n",
      "Run: 04, Epoch: 59, Loss: 0.2553, Train: 86.21%, Valid: 71.19% Test: 72.97%\n",
      "Run: 04, Epoch: 60, Loss: 0.2368, Train: 87.36%, Valid: 76.27% Test: 75.68%\n",
      "Run: 04, Epoch: 61, Loss: 0.2284, Train: 88.51%, Valid: 76.27% Test: 75.68%\n",
      "Run: 04, Epoch: 62, Loss: 0.2134, Train: 88.51%, Valid: 76.27% Test: 86.49%\n",
      "Run: 04, Epoch: 63, Loss: 0.3296, Train: 90.80%, Valid: 77.97% Test: 86.49%\n",
      "Run: 04, Epoch: 64, Loss: 0.2280, Train: 94.25%, Valid: 83.05% Test: 83.78%\n",
      "Run: 04, Epoch: 65, Loss: 0.2327, Train: 94.25%, Valid: 86.44% Test: 81.08%\n",
      "Run: 04, Epoch: 66, Loss: 0.1597, Train: 94.25%, Valid: 84.75% Test: 81.08%\n",
      "Run: 04, Epoch: 67, Loss: 0.1812, Train: 96.55%, Valid: 84.75% Test: 81.08%\n",
      "Run: 04, Epoch: 68, Loss: 0.2360, Train: 97.70%, Valid: 83.05% Test: 81.08%\n",
      "Run: 04, Epoch: 69, Loss: 0.2841, Train: 95.40%, Valid: 83.05% Test: 81.08%\n",
      "Run: 04, Epoch: 70, Loss: 0.2379, Train: 96.55%, Valid: 83.05% Test: 81.08%\n",
      "Run: 04, Epoch: 71, Loss: 0.1846, Train: 95.40%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 72, Loss: 0.2502, Train: 95.40%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 73, Loss: 0.2690, Train: 94.25%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 74, Loss: 0.1517, Train: 95.40%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 75, Loss: 0.2375, Train: 94.25%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 76, Loss: 0.2044, Train: 96.55%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 77, Loss: 0.2306, Train: 95.40%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 78, Loss: 0.2039, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 79, Loss: 0.1544, Train: 87.36%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 80, Loss: 0.3290, Train: 88.51%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 81, Loss: 0.1687, Train: 90.80%, Valid: 77.97% Test: 86.49%\n",
      "Run: 04, Epoch: 82, Loss: 0.2827, Train: 89.66%, Valid: 76.27% Test: 86.49%\n",
      "Run: 04, Epoch: 83, Loss: 0.1965, Train: 88.51%, Valid: 76.27% Test: 86.49%\n",
      "Run: 04, Epoch: 84, Loss: 0.1671, Train: 88.51%, Valid: 76.27% Test: 86.49%\n",
      "Run: 04, Epoch: 85, Loss: 0.1712, Train: 90.80%, Valid: 76.27% Test: 86.49%\n",
      "Run: 04, Epoch: 86, Loss: 0.1349, Train: 91.95%, Valid: 77.97% Test: 86.49%\n",
      "Run: 04, Epoch: 87, Loss: 0.2136, Train: 91.95%, Valid: 79.66% Test: 83.78%\n",
      "Run: 04, Epoch: 88, Loss: 0.2415, Train: 94.25%, Valid: 81.36% Test: 70.27%\n",
      "Run: 04, Epoch: 89, Loss: 0.2353, Train: 96.55%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 90, Loss: 0.1973, Train: 96.55%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 91, Loss: 0.2447, Train: 96.55%, Valid: 79.66% Test: 78.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 92, Loss: 0.2038, Train: 94.25%, Valid: 81.36% Test: 75.68%\n",
      "Run: 04, Epoch: 93, Loss: 0.2161, Train: 94.25%, Valid: 81.36% Test: 75.68%\n",
      "Run: 04, Epoch: 94, Loss: 0.1763, Train: 94.25%, Valid: 81.36% Test: 75.68%\n",
      "Run: 04, Epoch: 95, Loss: 0.1739, Train: 95.40%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 96, Loss: 0.2058, Train: 95.40%, Valid: 84.75% Test: 81.08%\n",
      "Run: 04, Epoch: 97, Loss: 0.2774, Train: 95.40%, Valid: 83.05% Test: 83.78%\n",
      "Run: 04, Epoch: 98, Loss: 0.1534, Train: 96.55%, Valid: 83.05% Test: 83.78%\n",
      "Run: 04, Epoch: 99, Loss: 0.1522, Train: 96.55%, Valid: 81.36% Test: 83.78%\n",
      "Run: 04, Epoch: 100, Loss: 0.1474, Train: 97.70%, Valid: 84.75% Test: 81.08%\n",
      "Run 04:\n",
      "Highest Train: 97.70\n",
      "Highest Valid: 86.44\n",
      "  Final Train: 94.25\n",
      "   Final Test: 81.08\n",
      "Run: 05, Epoch: 01, Loss: 1.8041, Train: 18.39%, Valid: 11.86% Test: 13.51%\n",
      "Run: 05, Epoch: 02, Loss: 1.5532, Train: 27.59%, Valid: 25.42% Test: 45.95%\n",
      "Run: 05, Epoch: 03, Loss: 1.3647, Train: 43.68%, Valid: 35.59% Test: 43.24%\n",
      "Run: 05, Epoch: 04, Loss: 1.2146, Train: 49.43%, Valid: 40.68% Test: 48.65%\n",
      "Run: 05, Epoch: 05, Loss: 1.1079, Train: 56.32%, Valid: 44.07% Test: 48.65%\n",
      "Run: 05, Epoch: 06, Loss: 1.1006, Train: 62.07%, Valid: 45.76% Test: 48.65%\n",
      "Run: 05, Epoch: 07, Loss: 0.9858, Train: 65.52%, Valid: 45.76% Test: 48.65%\n",
      "Run: 05, Epoch: 08, Loss: 1.0303, Train: 67.82%, Valid: 45.76% Test: 51.35%\n",
      "Run: 05, Epoch: 09, Loss: 1.0130, Train: 70.11%, Valid: 50.85% Test: 56.76%\n",
      "Run: 05, Epoch: 10, Loss: 0.9503, Train: 72.41%, Valid: 52.54% Test: 56.76%\n",
      "Run: 05, Epoch: 11, Loss: 0.8490, Train: 74.71%, Valid: 55.93% Test: 59.46%\n",
      "Run: 05, Epoch: 12, Loss: 0.8765, Train: 75.86%, Valid: 57.63% Test: 62.16%\n",
      "Run: 05, Epoch: 13, Loss: 0.8314, Train: 74.71%, Valid: 55.93% Test: 64.86%\n",
      "Run: 05, Epoch: 14, Loss: 0.7426, Train: 74.71%, Valid: 57.63% Test: 67.57%\n",
      "Run: 05, Epoch: 15, Loss: 0.7741, Train: 75.86%, Valid: 59.32% Test: 67.57%\n",
      "Run: 05, Epoch: 16, Loss: 0.6804, Train: 75.86%, Valid: 59.32% Test: 64.86%\n",
      "Run: 05, Epoch: 17, Loss: 0.6884, Train: 75.86%, Valid: 61.02% Test: 64.86%\n",
      "Run: 05, Epoch: 18, Loss: 0.6905, Train: 74.71%, Valid: 61.02% Test: 64.86%\n",
      "Run: 05, Epoch: 19, Loss: 0.6566, Train: 74.71%, Valid: 61.02% Test: 64.86%\n",
      "Run: 05, Epoch: 20, Loss: 0.6247, Train: 75.86%, Valid: 59.32% Test: 67.57%\n",
      "Run: 05, Epoch: 21, Loss: 0.6209, Train: 75.86%, Valid: 55.93% Test: 70.27%\n",
      "Run: 05, Epoch: 22, Loss: 0.5659, Train: 75.86%, Valid: 57.63% Test: 70.27%\n",
      "Run: 05, Epoch: 23, Loss: 0.5779, Train: 75.86%, Valid: 54.24% Test: 70.27%\n",
      "Run: 05, Epoch: 24, Loss: 0.6367, Train: 77.01%, Valid: 54.24% Test: 70.27%\n",
      "Run: 05, Epoch: 25, Loss: 0.5268, Train: 78.16%, Valid: 55.93% Test: 70.27%\n",
      "Run: 05, Epoch: 26, Loss: 0.5681, Train: 79.31%, Valid: 55.93% Test: 70.27%\n",
      "Run: 05, Epoch: 27, Loss: 0.5230, Train: 79.31%, Valid: 57.63% Test: 70.27%\n",
      "Run: 05, Epoch: 28, Loss: 0.5106, Train: 79.31%, Valid: 61.02% Test: 70.27%\n",
      "Run: 05, Epoch: 29, Loss: 0.4836, Train: 79.31%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 30, Loss: 0.4712, Train: 77.01%, Valid: 64.41% Test: 64.86%\n",
      "Run: 05, Epoch: 31, Loss: 0.4224, Train: 77.01%, Valid: 64.41% Test: 64.86%\n",
      "Run: 05, Epoch: 32, Loss: 0.4306, Train: 77.01%, Valid: 64.41% Test: 64.86%\n",
      "Run: 05, Epoch: 33, Loss: 0.4215, Train: 77.01%, Valid: 66.10% Test: 64.86%\n",
      "Run: 05, Epoch: 34, Loss: 0.3639, Train: 78.16%, Valid: 66.10% Test: 64.86%\n",
      "Run: 05, Epoch: 35, Loss: 0.4008, Train: 78.16%, Valid: 64.41% Test: 64.86%\n",
      "Run: 05, Epoch: 36, Loss: 0.3397, Train: 77.01%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 37, Loss: 0.4214, Train: 75.86%, Valid: 64.41% Test: 64.86%\n",
      "Run: 05, Epoch: 38, Loss: 0.4034, Train: 75.86%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 39, Loss: 0.3704, Train: 78.16%, Valid: 61.02% Test: 67.57%\n",
      "Run: 05, Epoch: 40, Loss: 0.3318, Train: 78.16%, Valid: 61.02% Test: 67.57%\n",
      "Run: 05, Epoch: 41, Loss: 0.3087, Train: 79.31%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 42, Loss: 0.3296, Train: 80.46%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 43, Loss: 0.3976, Train: 81.61%, Valid: 66.10% Test: 70.27%\n",
      "Run: 05, Epoch: 44, Loss: 0.3686, Train: 85.06%, Valid: 69.49% Test: 72.97%\n",
      "Run: 05, Epoch: 45, Loss: 0.3144, Train: 85.06%, Valid: 69.49% Test: 72.97%\n",
      "Run: 05, Epoch: 46, Loss: 0.3082, Train: 86.21%, Valid: 67.80% Test: 72.97%\n",
      "Run: 05, Epoch: 47, Loss: 0.3218, Train: 87.36%, Valid: 67.80% Test: 72.97%\n",
      "Run: 05, Epoch: 48, Loss: 0.2939, Train: 88.51%, Valid: 69.49% Test: 78.38%\n",
      "Run: 05, Epoch: 49, Loss: 0.3485, Train: 87.36%, Valid: 69.49% Test: 78.38%\n",
      "Run: 05, Epoch: 50, Loss: 0.3003, Train: 86.21%, Valid: 71.19% Test: 78.38%\n",
      "Run: 05, Epoch: 51, Loss: 0.2507, Train: 86.21%, Valid: 71.19% Test: 78.38%\n",
      "Run: 05, Epoch: 52, Loss: 0.2601, Train: 87.36%, Valid: 77.97% Test: 81.08%\n",
      "Run: 05, Epoch: 53, Loss: 0.3023, Train: 83.91%, Valid: 77.97% Test: 78.38%\n",
      "Run: 05, Epoch: 54, Loss: 0.3131, Train: 82.76%, Valid: 77.97% Test: 78.38%\n",
      "Run: 05, Epoch: 55, Loss: 0.3070, Train: 85.06%, Valid: 77.97% Test: 78.38%\n",
      "Run: 05, Epoch: 56, Loss: 0.2305, Train: 87.36%, Valid: 76.27% Test: 78.38%\n",
      "Run: 05, Epoch: 57, Loss: 0.2453, Train: 86.21%, Valid: 76.27% Test: 78.38%\n",
      "Run: 05, Epoch: 58, Loss: 0.2650, Train: 85.06%, Valid: 74.58% Test: 78.38%\n",
      "Run: 05, Epoch: 59, Loss: 0.2306, Train: 85.06%, Valid: 71.19% Test: 75.68%\n",
      "Run: 05, Epoch: 60, Loss: 0.2835, Train: 85.06%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 61, Loss: 0.2184, Train: 86.21%, Valid: 71.19% Test: 75.68%\n",
      "Run: 05, Epoch: 62, Loss: 0.2182, Train: 85.06%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 63, Loss: 0.2194, Train: 85.06%, Valid: 71.19% Test: 75.68%\n",
      "Run: 05, Epoch: 64, Loss: 0.2198, Train: 85.06%, Valid: 72.88% Test: 75.68%\n",
      "Run: 05, Epoch: 65, Loss: 0.2473, Train: 88.51%, Valid: 72.88% Test: 75.68%\n",
      "Run: 05, Epoch: 66, Loss: 0.2694, Train: 88.51%, Valid: 74.58% Test: 81.08%\n",
      "Run: 05, Epoch: 67, Loss: 0.2174, Train: 90.80%, Valid: 74.58% Test: 83.78%\n",
      "Run: 05, Epoch: 68, Loss: 0.1459, Train: 90.80%, Valid: 76.27% Test: 83.78%\n",
      "Run: 05, Epoch: 69, Loss: 0.2360, Train: 91.95%, Valid: 76.27% Test: 83.78%\n",
      "Run: 05, Epoch: 70, Loss: 0.1985, Train: 93.10%, Valid: 77.97% Test: 81.08%\n",
      "Run: 05, Epoch: 71, Loss: 0.1639, Train: 93.10%, Valid: 74.58% Test: 83.78%\n",
      "Run: 05, Epoch: 72, Loss: 0.2059, Train: 94.25%, Valid: 76.27% Test: 86.49%\n",
      "Run: 05, Epoch: 73, Loss: 0.1562, Train: 94.25%, Valid: 76.27% Test: 86.49%\n",
      "Run: 05, Epoch: 74, Loss: 0.2114, Train: 96.55%, Valid: 77.97% Test: 89.19%\n",
      "Run: 05, Epoch: 75, Loss: 0.1800, Train: 94.25%, Valid: 77.97% Test: 89.19%\n",
      "Run: 05, Epoch: 76, Loss: 0.1913, Train: 91.95%, Valid: 76.27% Test: 83.78%\n",
      "Run: 05, Epoch: 77, Loss: 0.1697, Train: 91.95%, Valid: 72.88% Test: 81.08%\n",
      "Run: 05, Epoch: 78, Loss: 0.2150, Train: 88.51%, Valid: 72.88% Test: 81.08%\n",
      "Run: 05, Epoch: 79, Loss: 0.1802, Train: 88.51%, Valid: 74.58% Test: 83.78%\n",
      "Run: 05, Epoch: 80, Loss: 0.2239, Train: 91.95%, Valid: 72.88% Test: 78.38%\n",
      "Run: 05, Epoch: 81, Loss: 0.1377, Train: 94.25%, Valid: 77.97% Test: 89.19%\n",
      "Run: 05, Epoch: 82, Loss: 0.1424, Train: 96.55%, Valid: 79.66% Test: 89.19%\n",
      "Run: 05, Epoch: 83, Loss: 0.1769, Train: 95.40%, Valid: 79.66% Test: 86.49%\n",
      "Run: 05, Epoch: 84, Loss: 0.1135, Train: 91.95%, Valid: 77.97% Test: 81.08%\n",
      "Run: 05, Epoch: 85, Loss: 0.2590, Train: 88.51%, Valid: 74.58% Test: 78.38%\n",
      "Run: 05, Epoch: 86, Loss: 0.2067, Train: 85.06%, Valid: 72.88% Test: 72.97%\n",
      "Run: 05, Epoch: 87, Loss: 0.1693, Train: 82.76%, Valid: 67.80% Test: 64.86%\n",
      "Run: 05, Epoch: 88, Loss: 0.1497, Train: 88.51%, Valid: 74.58% Test: 72.97%\n",
      "Run: 05, Epoch: 89, Loss: 0.1817, Train: 93.10%, Valid: 76.27% Test: 78.38%\n",
      "Run: 05, Epoch: 90, Loss: 0.1712, Train: 93.10%, Valid: 76.27% Test: 81.08%\n",
      "Run: 05, Epoch: 91, Loss: 0.1999, Train: 89.66%, Valid: 72.88% Test: 83.78%\n",
      "Run: 05, Epoch: 92, Loss: 0.2090, Train: 88.51%, Valid: 72.88% Test: 78.38%\n",
      "Run: 05, Epoch: 93, Loss: 0.1698, Train: 86.21%, Valid: 71.19% Test: 72.97%\n",
      "Run: 05, Epoch: 94, Loss: 0.1539, Train: 85.06%, Valid: 69.49% Test: 72.97%\n",
      "Run: 05, Epoch: 95, Loss: 0.1596, Train: 85.06%, Valid: 71.19% Test: 75.68%\n",
      "Run: 05, Epoch: 96, Loss: 0.1608, Train: 83.91%, Valid: 71.19% Test: 72.97%\n",
      "Run: 05, Epoch: 97, Loss: 0.1894, Train: 85.06%, Valid: 71.19% Test: 75.68%\n",
      "Run: 05, Epoch: 98, Loss: 0.2181, Train: 90.80%, Valid: 71.19% Test: 78.38%\n",
      "Run: 05, Epoch: 99, Loss: 0.1489, Train: 91.95%, Valid: 72.88% Test: 81.08%\n",
      "Run: 05, Epoch: 100, Loss: 0.1412, Train: 93.10%, Valid: 74.58% Test: 86.49%\n",
      "Run 05:\n",
      "Highest Train: 96.55\n",
      "Highest Valid: 79.66\n",
      "  Final Train: 96.55\n",
      "   Final Test: 89.19\n",
      "Run: 06, Epoch: 01, Loss: 1.6174, Train: 44.83%, Valid: 49.15% Test: 40.54%\n",
      "Run: 06, Epoch: 02, Loss: 1.4523, Train: 56.32%, Valid: 54.24% Test: 48.65%\n",
      "Run: 06, Epoch: 03, Loss: 1.3988, Train: 57.47%, Valid: 54.24% Test: 48.65%\n",
      "Run: 06, Epoch: 04, Loss: 1.3154, Train: 55.17%, Valid: 52.54% Test: 48.65%\n",
      "Run: 06, Epoch: 05, Loss: 1.2194, Train: 54.02%, Valid: 50.85% Test: 45.95%\n",
      "Run: 06, Epoch: 06, Loss: 1.1876, Train: 50.57%, Valid: 50.85% Test: 45.95%\n",
      "Run: 06, Epoch: 07, Loss: 1.1646, Train: 50.57%, Valid: 50.85% Test: 45.95%\n",
      "Run: 06, Epoch: 08, Loss: 1.1321, Train: 50.57%, Valid: 49.15% Test: 45.95%\n",
      "Run: 06, Epoch: 09, Loss: 1.1020, Train: 54.02%, Valid: 50.85% Test: 48.65%\n",
      "Run: 06, Epoch: 10, Loss: 1.0690, Train: 62.07%, Valid: 52.54% Test: 48.65%\n",
      "Run: 06, Epoch: 11, Loss: 1.0365, Train: 63.22%, Valid: 61.02% Test: 51.35%\n",
      "Run: 06, Epoch: 12, Loss: 0.8750, Train: 71.26%, Valid: 64.41% Test: 59.46%\n",
      "Run: 06, Epoch: 13, Loss: 0.9133, Train: 64.37%, Valid: 64.41% Test: 67.57%\n",
      "Run: 06, Epoch: 14, Loss: 0.9075, Train: 64.37%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 15, Loss: 0.7900, Train: 62.07%, Valid: 64.41% Test: 67.57%\n",
      "Run: 06, Epoch: 16, Loss: 0.7563, Train: 62.07%, Valid: 62.71% Test: 72.97%\n",
      "Run: 06, Epoch: 17, Loss: 0.8336, Train: 63.22%, Valid: 64.41% Test: 72.97%\n",
      "Run: 06, Epoch: 18, Loss: 0.7131, Train: 65.52%, Valid: 69.49% Test: 72.97%\n",
      "Run: 06, Epoch: 19, Loss: 0.7475, Train: 72.41%, Valid: 72.88% Test: 72.97%\n",
      "Run: 06, Epoch: 20, Loss: 0.6828, Train: 77.01%, Valid: 74.58% Test: 75.68%\n",
      "Run: 06, Epoch: 21, Loss: 0.6130, Train: 77.01%, Valid: 71.19% Test: 75.68%\n",
      "Run: 06, Epoch: 22, Loss: 0.7008, Train: 78.16%, Valid: 72.88% Test: 75.68%\n",
      "Run: 06, Epoch: 23, Loss: 0.5968, Train: 78.16%, Valid: 76.27% Test: 75.68%\n",
      "Run: 06, Epoch: 24, Loss: 0.5613, Train: 75.86%, Valid: 76.27% Test: 75.68%\n",
      "Run: 06, Epoch: 25, Loss: 0.5698, Train: 77.01%, Valid: 76.27% Test: 75.68%\n",
      "Run: 06, Epoch: 26, Loss: 0.4991, Train: 80.46%, Valid: 76.27% Test: 72.97%\n",
      "Run: 06, Epoch: 27, Loss: 0.5211, Train: 78.16%, Valid: 76.27% Test: 72.97%\n",
      "Run: 06, Epoch: 28, Loss: 0.5326, Train: 78.16%, Valid: 74.58% Test: 72.97%\n",
      "Run: 06, Epoch: 29, Loss: 0.4956, Train: 78.16%, Valid: 76.27% Test: 75.68%\n",
      "Run: 06, Epoch: 30, Loss: 0.5442, Train: 78.16%, Valid: 76.27% Test: 72.97%\n",
      "Run: 06, Epoch: 31, Loss: 0.4915, Train: 78.16%, Valid: 77.97% Test: 72.97%\n",
      "Run: 06, Epoch: 32, Loss: 0.4609, Train: 79.31%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 33, Loss: 0.5465, Train: 82.76%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 34, Loss: 0.3689, Train: 82.76%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 35, Loss: 0.4730, Train: 82.76%, Valid: 74.58% Test: 72.97%\n",
      "Run: 06, Epoch: 36, Loss: 0.3984, Train: 82.76%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 37, Loss: 0.4184, Train: 82.76%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 38, Loss: 0.3872, Train: 83.91%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 39, Loss: 0.3988, Train: 83.91%, Valid: 76.27% Test: 75.68%\n",
      "Run: 06, Epoch: 40, Loss: 0.3605, Train: 83.91%, Valid: 76.27% Test: 72.97%\n",
      "Run: 06, Epoch: 41, Loss: 0.3152, Train: 81.61%, Valid: 77.97% Test: 75.68%\n",
      "Run: 06, Epoch: 42, Loss: 0.4120, Train: 81.61%, Valid: 77.97% Test: 78.38%\n",
      "Run: 06, Epoch: 43, Loss: 0.4019, Train: 81.61%, Valid: 74.58% Test: 78.38%\n",
      "Run: 06, Epoch: 44, Loss: 0.3681, Train: 82.76%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 45, Loss: 0.3723, Train: 82.76%, Valid: 77.97% Test: 78.38%\n",
      "Run: 06, Epoch: 46, Loss: 0.4032, Train: 83.91%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 47, Loss: 0.2560, Train: 87.36%, Valid: 83.05% Test: 78.38%\n",
      "Run: 06, Epoch: 48, Loss: 0.3600, Train: 88.51%, Valid: 79.66% Test: 78.38%\n",
      "Run: 06, Epoch: 49, Loss: 0.2587, Train: 88.51%, Valid: 76.27% Test: 81.08%\n",
      "Run: 06, Epoch: 50, Loss: 0.3563, Train: 86.21%, Valid: 76.27% Test: 78.38%\n",
      "Run: 06, Epoch: 51, Loss: 0.3193, Train: 86.21%, Valid: 77.97% Test: 81.08%\n",
      "Run: 06, Epoch: 52, Loss: 0.2795, Train: 86.21%, Valid: 77.97% Test: 81.08%\n",
      "Run: 06, Epoch: 53, Loss: 0.3372, Train: 87.36%, Valid: 81.36% Test: 83.78%\n",
      "Run: 06, Epoch: 54, Loss: 0.2327, Train: 85.06%, Valid: 81.36% Test: 83.78%\n",
      "Run: 06, Epoch: 55, Loss: 0.2747, Train: 83.91%, Valid: 81.36% Test: 81.08%\n",
      "Run: 06, Epoch: 56, Loss: 0.2616, Train: 83.91%, Valid: 79.66% Test: 86.49%\n",
      "Run: 06, Epoch: 57, Loss: 0.3296, Train: 86.21%, Valid: 83.05% Test: 86.49%\n",
      "Run: 06, Epoch: 58, Loss: 0.3004, Train: 88.51%, Valid: 81.36% Test: 86.49%\n",
      "Run: 06, Epoch: 59, Loss: 0.2688, Train: 89.66%, Valid: 84.75% Test: 86.49%\n",
      "Run: 06, Epoch: 60, Loss: 0.2804, Train: 89.66%, Valid: 86.44% Test: 86.49%\n",
      "Run: 06, Epoch: 61, Loss: 0.2166, Train: 88.51%, Valid: 84.75% Test: 86.49%\n",
      "Run: 06, Epoch: 62, Loss: 0.2972, Train: 86.21%, Valid: 83.05% Test: 86.49%\n",
      "Run: 06, Epoch: 63, Loss: 0.2597, Train: 90.80%, Valid: 83.05% Test: 86.49%\n",
      "Run: 06, Epoch: 64, Loss: 0.3626, Train: 91.95%, Valid: 83.05% Test: 89.19%\n",
      "Run: 06, Epoch: 65, Loss: 0.2104, Train: 96.55%, Valid: 83.05% Test: 83.78%\n",
      "Run: 06, Epoch: 66, Loss: 0.2080, Train: 94.25%, Valid: 83.05% Test: 83.78%\n",
      "Run: 06, Epoch: 67, Loss: 0.2877, Train: 96.55%, Valid: 81.36% Test: 86.49%\n",
      "Run: 06, Epoch: 68, Loss: 0.2396, Train: 96.55%, Valid: 81.36% Test: 86.49%\n",
      "Run: 06, Epoch: 69, Loss: 0.2526, Train: 95.40%, Valid: 84.75% Test: 86.49%\n",
      "Run: 06, Epoch: 70, Loss: 0.2629, Train: 93.10%, Valid: 88.14% Test: 83.78%\n",
      "Run: 06, Epoch: 71, Loss: 0.3060, Train: 91.95%, Valid: 88.14% Test: 83.78%\n",
      "Run: 06, Epoch: 72, Loss: 0.2629, Train: 88.51%, Valid: 86.44% Test: 78.38%\n",
      "Run: 06, Epoch: 73, Loss: 0.2642, Train: 88.51%, Valid: 86.44% Test: 78.38%\n",
      "Run: 06, Epoch: 74, Loss: 0.2625, Train: 86.21%, Valid: 86.44% Test: 75.68%\n",
      "Run: 06, Epoch: 75, Loss: 0.1812, Train: 82.76%, Valid: 83.05% Test: 81.08%\n",
      "Run: 06, Epoch: 76, Loss: 0.2550, Train: 85.06%, Valid: 84.75% Test: 83.78%\n",
      "Run: 06, Epoch: 77, Loss: 0.2058, Train: 86.21%, Valid: 84.75% Test: 86.49%\n",
      "Run: 06, Epoch: 78, Loss: 0.2522, Train: 88.51%, Valid: 86.44% Test: 86.49%\n",
      "Run: 06, Epoch: 79, Loss: 0.1996, Train: 88.51%, Valid: 84.75% Test: 86.49%\n",
      "Run: 06, Epoch: 80, Loss: 0.2333, Train: 87.36%, Valid: 83.05% Test: 86.49%\n",
      "Run: 06, Epoch: 81, Loss: 0.2506, Train: 87.36%, Valid: 83.05% Test: 86.49%\n",
      "Run: 06, Epoch: 82, Loss: 0.1965, Train: 83.91%, Valid: 81.36% Test: 86.49%\n",
      "Run: 06, Epoch: 83, Loss: 0.2093, Train: 83.91%, Valid: 79.66% Test: 86.49%\n",
      "Run: 06, Epoch: 84, Loss: 0.1822, Train: 83.91%, Valid: 81.36% Test: 86.49%\n",
      "Run: 06, Epoch: 85, Loss: 0.2299, Train: 85.06%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 86, Loss: 0.2696, Train: 83.91%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 87, Loss: 0.1458, Train: 86.21%, Valid: 86.44% Test: 75.68%\n",
      "Run: 06, Epoch: 88, Loss: 0.1898, Train: 86.21%, Valid: 86.44% Test: 70.27%\n",
      "Run: 06, Epoch: 89, Loss: 0.2010, Train: 88.51%, Valid: 83.05% Test: 70.27%\n",
      "Run: 06, Epoch: 90, Loss: 0.1726, Train: 90.80%, Valid: 83.05% Test: 70.27%\n",
      "Run: 06, Epoch: 91, Loss: 0.1505, Train: 91.95%, Valid: 81.36% Test: 72.97%\n",
      "Run: 06, Epoch: 92, Loss: 0.1496, Train: 93.10%, Valid: 81.36% Test: 75.68%\n",
      "Run: 06, Epoch: 93, Loss: 0.1440, Train: 94.25%, Valid: 81.36% Test: 81.08%\n",
      "Run: 06, Epoch: 94, Loss: 0.1743, Train: 95.40%, Valid: 81.36% Test: 86.49%\n",
      "Run: 06, Epoch: 95, Loss: 0.2245, Train: 97.70%, Valid: 84.75% Test: 89.19%\n",
      "Run: 06, Epoch: 96, Loss: 0.2033, Train: 95.40%, Valid: 88.14% Test: 86.49%\n",
      "Run: 06, Epoch: 97, Loss: 0.1491, Train: 89.66%, Valid: 86.44% Test: 83.78%\n",
      "Run: 06, Epoch: 98, Loss: 0.2171, Train: 89.66%, Valid: 86.44% Test: 86.49%\n",
      "Run: 06, Epoch: 99, Loss: 0.2027, Train: 91.95%, Valid: 84.75% Test: 86.49%\n",
      "Run: 06, Epoch: 100, Loss: 0.1759, Train: 95.40%, Valid: 89.83% Test: 89.19%\n",
      "Run 06:\n",
      "Highest Train: 97.70\n",
      "Highest Valid: 89.83\n",
      "  Final Train: 95.40\n",
      "   Final Test: 89.19\n",
      "Run: 07, Epoch: 01, Loss: 1.7826, Train: 8.05%, Valid: 11.86% Test: 8.11%\n",
      "Run: 07, Epoch: 02, Loss: 1.6126, Train: 19.54%, Valid: 15.25% Test: 24.32%\n",
      "Run: 07, Epoch: 03, Loss: 1.4153, Train: 27.59%, Valid: 32.20% Test: 32.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 04, Loss: 1.3173, Train: 63.22%, Valid: 55.93% Test: 51.35%\n",
      "Run: 07, Epoch: 05, Loss: 1.2988, Train: 58.62%, Valid: 55.93% Test: 37.84%\n",
      "Run: 07, Epoch: 06, Loss: 1.1460, Train: 57.47%, Valid: 50.85% Test: 37.84%\n",
      "Run: 07, Epoch: 07, Loss: 1.2084, Train: 56.32%, Valid: 50.85% Test: 40.54%\n",
      "Run: 07, Epoch: 08, Loss: 1.1614, Train: 57.47%, Valid: 50.85% Test: 43.24%\n",
      "Run: 07, Epoch: 09, Loss: 1.1479, Train: 59.77%, Valid: 54.24% Test: 48.65%\n",
      "Run: 07, Epoch: 10, Loss: 1.0828, Train: 62.07%, Valid: 55.93% Test: 45.95%\n",
      "Run: 07, Epoch: 11, Loss: 1.2067, Train: 63.22%, Valid: 55.93% Test: 51.35%\n",
      "Run: 07, Epoch: 12, Loss: 1.0803, Train: 65.52%, Valid: 55.93% Test: 51.35%\n",
      "Run: 07, Epoch: 13, Loss: 0.9927, Train: 66.67%, Valid: 55.93% Test: 51.35%\n",
      "Run: 07, Epoch: 14, Loss: 0.9304, Train: 67.82%, Valid: 54.24% Test: 56.76%\n",
      "Run: 07, Epoch: 15, Loss: 0.8931, Train: 68.97%, Valid: 61.02% Test: 54.05%\n",
      "Run: 07, Epoch: 16, Loss: 0.8729, Train: 72.41%, Valid: 64.41% Test: 59.46%\n",
      "Run: 07, Epoch: 17, Loss: 0.7659, Train: 73.56%, Valid: 62.71% Test: 62.16%\n",
      "Run: 07, Epoch: 18, Loss: 0.7478, Train: 73.56%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 19, Loss: 0.7439, Train: 71.26%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 20, Loss: 0.7288, Train: 70.11%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 21, Loss: 0.6814, Train: 67.82%, Valid: 64.41% Test: 64.86%\n",
      "Run: 07, Epoch: 22, Loss: 0.7101, Train: 68.97%, Valid: 66.10% Test: 64.86%\n",
      "Run: 07, Epoch: 23, Loss: 0.7086, Train: 68.97%, Valid: 64.41% Test: 64.86%\n",
      "Run: 07, Epoch: 24, Loss: 0.6314, Train: 71.26%, Valid: 66.10% Test: 62.16%\n",
      "Run: 07, Epoch: 25, Loss: 0.7138, Train: 74.71%, Valid: 66.10% Test: 62.16%\n",
      "Run: 07, Epoch: 26, Loss: 0.5542, Train: 78.16%, Valid: 67.80% Test: 67.57%\n",
      "Run: 07, Epoch: 27, Loss: 0.5353, Train: 77.01%, Valid: 67.80% Test: 70.27%\n",
      "Run: 07, Epoch: 28, Loss: 0.5888, Train: 77.01%, Valid: 61.02% Test: 67.57%\n",
      "Run: 07, Epoch: 29, Loss: 0.4791, Train: 73.56%, Valid: 61.02% Test: 62.16%\n",
      "Run: 07, Epoch: 30, Loss: 0.4514, Train: 73.56%, Valid: 62.71% Test: 59.46%\n",
      "Run: 07, Epoch: 31, Loss: 0.4870, Train: 74.71%, Valid: 62.71% Test: 54.05%\n",
      "Run: 07, Epoch: 32, Loss: 0.4826, Train: 74.71%, Valid: 62.71% Test: 54.05%\n",
      "Run: 07, Epoch: 33, Loss: 0.4605, Train: 74.71%, Valid: 61.02% Test: 56.76%\n",
      "Run: 07, Epoch: 34, Loss: 0.4188, Train: 73.56%, Valid: 61.02% Test: 54.05%\n",
      "Run: 07, Epoch: 35, Loss: 0.4832, Train: 73.56%, Valid: 62.71% Test: 54.05%\n",
      "Run: 07, Epoch: 36, Loss: 0.4186, Train: 74.71%, Valid: 62.71% Test: 62.16%\n",
      "Run: 07, Epoch: 37, Loss: 0.4774, Train: 75.86%, Valid: 61.02% Test: 67.57%\n",
      "Run: 07, Epoch: 38, Loss: 0.3557, Train: 78.16%, Valid: 59.32% Test: 70.27%\n",
      "Run: 07, Epoch: 39, Loss: 0.3888, Train: 78.16%, Valid: 61.02% Test: 70.27%\n",
      "Run: 07, Epoch: 40, Loss: 0.3716, Train: 79.31%, Valid: 62.71% Test: 75.68%\n",
      "Run: 07, Epoch: 41, Loss: 0.3761, Train: 81.61%, Valid: 66.10% Test: 81.08%\n",
      "Run: 07, Epoch: 42, Loss: 0.3410, Train: 87.36%, Valid: 67.80% Test: 86.49%\n",
      "Run: 07, Epoch: 43, Loss: 0.2932, Train: 87.36%, Valid: 71.19% Test: 86.49%\n",
      "Run: 07, Epoch: 44, Loss: 0.3298, Train: 89.66%, Valid: 69.49% Test: 89.19%\n",
      "Run: 07, Epoch: 45, Loss: 0.4211, Train: 89.66%, Valid: 67.80% Test: 89.19%\n",
      "Run: 07, Epoch: 46, Loss: 0.3551, Train: 87.36%, Valid: 67.80% Test: 86.49%\n",
      "Run: 07, Epoch: 47, Loss: 0.3833, Train: 88.51%, Valid: 69.49% Test: 83.78%\n",
      "Run: 07, Epoch: 48, Loss: 0.2921, Train: 90.80%, Valid: 72.88% Test: 83.78%\n",
      "Run: 07, Epoch: 49, Loss: 0.3444, Train: 90.80%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 50, Loss: 0.3286, Train: 91.95%, Valid: 74.58% Test: 81.08%\n",
      "Run: 07, Epoch: 51, Loss: 0.2596, Train: 90.80%, Valid: 72.88% Test: 78.38%\n",
      "Run: 07, Epoch: 52, Loss: 0.3613, Train: 87.36%, Valid: 72.88% Test: 75.68%\n",
      "Run: 07, Epoch: 53, Loss: 0.3043, Train: 85.06%, Valid: 72.88% Test: 64.86%\n",
      "Run: 07, Epoch: 54, Loss: 0.3270, Train: 86.21%, Valid: 71.19% Test: 64.86%\n",
      "Run: 07, Epoch: 55, Loss: 0.2753, Train: 87.36%, Valid: 69.49% Test: 72.97%\n",
      "Run: 07, Epoch: 56, Loss: 0.2649, Train: 89.66%, Valid: 69.49% Test: 78.38%\n",
      "Run: 07, Epoch: 57, Loss: 0.2679, Train: 91.95%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 58, Loss: 0.3273, Train: 93.10%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 59, Loss: 0.2904, Train: 93.10%, Valid: 76.27% Test: 83.78%\n",
      "Run: 07, Epoch: 60, Loss: 0.2301, Train: 91.95%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 61, Loss: 0.3218, Train: 90.80%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 62, Loss: 0.3401, Train: 93.10%, Valid: 67.80% Test: 86.49%\n",
      "Run: 07, Epoch: 63, Loss: 0.2769, Train: 91.95%, Valid: 69.49% Test: 86.49%\n",
      "Run: 07, Epoch: 64, Loss: 0.2667, Train: 91.95%, Valid: 72.88% Test: 89.19%\n",
      "Run: 07, Epoch: 65, Loss: 0.2134, Train: 91.95%, Valid: 72.88% Test: 86.49%\n",
      "Run: 07, Epoch: 66, Loss: 0.2880, Train: 90.80%, Valid: 72.88% Test: 86.49%\n",
      "Run: 07, Epoch: 67, Loss: 0.2516, Train: 90.80%, Valid: 74.58% Test: 89.19%\n",
      "Run: 07, Epoch: 68, Loss: 0.2411, Train: 91.95%, Valid: 72.88% Test: 94.59%\n",
      "Run: 07, Epoch: 69, Loss: 0.2044, Train: 91.95%, Valid: 74.58% Test: 94.59%\n",
      "Run: 07, Epoch: 70, Loss: 0.1942, Train: 93.10%, Valid: 74.58% Test: 89.19%\n",
      "Run: 07, Epoch: 71, Loss: 0.2036, Train: 93.10%, Valid: 76.27% Test: 86.49%\n",
      "Run: 07, Epoch: 72, Loss: 0.2191, Train: 93.10%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 73, Loss: 0.2215, Train: 91.95%, Valid: 76.27% Test: 86.49%\n",
      "Run: 07, Epoch: 74, Loss: 0.1615, Train: 93.10%, Valid: 72.88% Test: 89.19%\n",
      "Run: 07, Epoch: 75, Loss: 0.2974, Train: 94.25%, Valid: 72.88% Test: 89.19%\n",
      "Run: 07, Epoch: 76, Loss: 0.2271, Train: 96.55%, Valid: 74.58% Test: 81.08%\n",
      "Run: 07, Epoch: 77, Loss: 0.1921, Train: 96.55%, Valid: 74.58% Test: 81.08%\n",
      "Run: 07, Epoch: 78, Loss: 0.1349, Train: 95.40%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 79, Loss: 0.1992, Train: 94.25%, Valid: 72.88% Test: 83.78%\n",
      "Run: 07, Epoch: 80, Loss: 0.2285, Train: 94.25%, Valid: 72.88% Test: 86.49%\n",
      "Run: 07, Epoch: 81, Loss: 0.1519, Train: 94.25%, Valid: 72.88% Test: 83.78%\n",
      "Run: 07, Epoch: 82, Loss: 0.2101, Train: 95.40%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 83, Loss: 0.1375, Train: 91.95%, Valid: 67.80% Test: 75.68%\n",
      "Run: 07, Epoch: 84, Loss: 0.1937, Train: 89.66%, Valid: 69.49% Test: 78.38%\n",
      "Run: 07, Epoch: 85, Loss: 0.1465, Train: 91.95%, Valid: 69.49% Test: 78.38%\n",
      "Run: 07, Epoch: 86, Loss: 0.2073, Train: 91.95%, Valid: 67.80% Test: 75.68%\n",
      "Run: 07, Epoch: 87, Loss: 0.0987, Train: 91.95%, Valid: 66.10% Test: 75.68%\n",
      "Run: 07, Epoch: 88, Loss: 0.2148, Train: 93.10%, Valid: 69.49% Test: 75.68%\n",
      "Run: 07, Epoch: 89, Loss: 0.1973, Train: 94.25%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 90, Loss: 0.2334, Train: 95.40%, Valid: 71.19% Test: 81.08%\n",
      "Run: 07, Epoch: 91, Loss: 0.1889, Train: 93.10%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 92, Loss: 0.1432, Train: 89.66%, Valid: 66.10% Test: 78.38%\n",
      "Run: 07, Epoch: 93, Loss: 0.2448, Train: 89.66%, Valid: 62.71% Test: 78.38%\n",
      "Run: 07, Epoch: 94, Loss: 0.1526, Train: 90.80%, Valid: 67.80% Test: 75.68%\n",
      "Run: 07, Epoch: 95, Loss: 0.0818, Train: 90.80%, Valid: 69.49% Test: 75.68%\n",
      "Run: 07, Epoch: 96, Loss: 0.1803, Train: 94.25%, Valid: 67.80% Test: 78.38%\n",
      "Run: 07, Epoch: 97, Loss: 0.1089, Train: 94.25%, Valid: 72.88% Test: 83.78%\n",
      "Run: 07, Epoch: 98, Loss: 0.1763, Train: 95.40%, Valid: 77.97% Test: 89.19%\n",
      "Run: 07, Epoch: 99, Loss: 0.1687, Train: 95.40%, Valid: 77.97% Test: 89.19%\n",
      "Run: 07, Epoch: 100, Loss: 0.1547, Train: 96.55%, Valid: 79.66% Test: 89.19%\n",
      "Run 07:\n",
      "Highest Train: 96.55\n",
      "Highest Valid: 79.66\n",
      "  Final Train: 96.55\n",
      "   Final Test: 89.19\n",
      "Run: 08, Epoch: 01, Loss: 1.6434, Train: 24.14%, Valid: 16.95% Test: 8.11%\n",
      "Run: 08, Epoch: 02, Loss: 1.5037, Train: 31.03%, Valid: 22.03% Test: 29.73%\n",
      "Run: 08, Epoch: 03, Loss: 1.3849, Train: 36.78%, Valid: 25.42% Test: 27.03%\n",
      "Run: 08, Epoch: 04, Loss: 1.2831, Train: 39.08%, Valid: 33.90% Test: 27.03%\n",
      "Run: 08, Epoch: 05, Loss: 1.3120, Train: 41.38%, Valid: 37.29% Test: 27.03%\n",
      "Run: 08, Epoch: 06, Loss: 1.2035, Train: 52.87%, Valid: 50.85% Test: 51.35%\n",
      "Run: 08, Epoch: 07, Loss: 1.1659, Train: 57.47%, Valid: 52.54% Test: 62.16%\n",
      "Run: 08, Epoch: 08, Loss: 1.0757, Train: 58.62%, Valid: 52.54% Test: 59.46%\n",
      "Run: 08, Epoch: 09, Loss: 1.0655, Train: 63.22%, Valid: 57.63% Test: 64.86%\n",
      "Run: 08, Epoch: 10, Loss: 1.0800, Train: 64.37%, Valid: 57.63% Test: 59.46%\n",
      "Run: 08, Epoch: 11, Loss: 1.0128, Train: 65.52%, Valid: 59.32% Test: 59.46%\n",
      "Run: 08, Epoch: 12, Loss: 0.9324, Train: 63.22%, Valid: 55.93% Test: 59.46%\n",
      "Run: 08, Epoch: 13, Loss: 1.0436, Train: 63.22%, Valid: 55.93% Test: 59.46%\n",
      "Run: 08, Epoch: 14, Loss: 0.8821, Train: 59.77%, Valid: 54.24% Test: 62.16%\n",
      "Run: 08, Epoch: 15, Loss: 0.8373, Train: 65.52%, Valid: 55.93% Test: 67.57%\n",
      "Run: 08, Epoch: 16, Loss: 0.8043, Train: 70.11%, Valid: 55.93% Test: 67.57%\n",
      "Run: 08, Epoch: 17, Loss: 0.8127, Train: 74.71%, Valid: 66.10% Test: 70.27%\n",
      "Run: 08, Epoch: 18, Loss: 0.8222, Train: 73.56%, Valid: 69.49% Test: 70.27%\n",
      "Run: 08, Epoch: 19, Loss: 0.7190, Train: 73.56%, Valid: 67.80% Test: 67.57%\n",
      "Run: 08, Epoch: 20, Loss: 0.6879, Train: 75.86%, Valid: 69.49% Test: 67.57%\n",
      "Run: 08, Epoch: 21, Loss: 0.6807, Train: 77.01%, Valid: 74.58% Test: 64.86%\n",
      "Run: 08, Epoch: 22, Loss: 0.6218, Train: 77.01%, Valid: 74.58% Test: 70.27%\n",
      "Run: 08, Epoch: 23, Loss: 0.6042, Train: 75.86%, Valid: 76.27% Test: 70.27%\n",
      "Run: 08, Epoch: 24, Loss: 0.6523, Train: 78.16%, Valid: 76.27% Test: 67.57%\n",
      "Run: 08, Epoch: 25, Loss: 0.5582, Train: 78.16%, Valid: 76.27% Test: 67.57%\n",
      "Run: 08, Epoch: 26, Loss: 0.6093, Train: 77.01%, Valid: 74.58% Test: 67.57%\n",
      "Run: 08, Epoch: 27, Loss: 0.5362, Train: 78.16%, Valid: 74.58% Test: 67.57%\n",
      "Run: 08, Epoch: 28, Loss: 0.4922, Train: 77.01%, Valid: 74.58% Test: 67.57%\n",
      "Run: 08, Epoch: 29, Loss: 0.5318, Train: 78.16%, Valid: 74.58% Test: 67.57%\n",
      "Run: 08, Epoch: 30, Loss: 0.5296, Train: 77.01%, Valid: 72.88% Test: 67.57%\n",
      "Run: 08, Epoch: 31, Loss: 0.4087, Train: 79.31%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 32, Loss: 0.4605, Train: 80.46%, Valid: 72.88% Test: 67.57%\n",
      "Run: 08, Epoch: 33, Loss: 0.4943, Train: 80.46%, Valid: 74.58% Test: 67.57%\n",
      "Run: 08, Epoch: 34, Loss: 0.3371, Train: 81.61%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 35, Loss: 0.4400, Train: 79.31%, Valid: 74.58% Test: 70.27%\n",
      "Run: 08, Epoch: 36, Loss: 0.4057, Train: 79.31%, Valid: 72.88% Test: 70.27%\n",
      "Run: 08, Epoch: 37, Loss: 0.4313, Train: 77.01%, Valid: 66.10% Test: 70.27%\n",
      "Run: 08, Epoch: 38, Loss: 0.3586, Train: 74.71%, Valid: 66.10% Test: 67.57%\n",
      "Run: 08, Epoch: 39, Loss: 0.3628, Train: 73.56%, Valid: 66.10% Test: 67.57%\n",
      "Run: 08, Epoch: 40, Loss: 0.4520, Train: 80.46%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 41, Loss: 0.3526, Train: 83.91%, Valid: 74.58% Test: 75.68%\n",
      "Run: 08, Epoch: 42, Loss: 0.3232, Train: 86.21%, Valid: 72.88% Test: 72.97%\n",
      "Run: 08, Epoch: 43, Loss: 0.3586, Train: 86.21%, Valid: 77.97% Test: 72.97%\n",
      "Run: 08, Epoch: 44, Loss: 0.3848, Train: 83.91%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 45, Loss: 0.3155, Train: 85.06%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 46, Loss: 0.2520, Train: 80.46%, Valid: 74.58% Test: 70.27%\n",
      "Run: 08, Epoch: 47, Loss: 0.2661, Train: 78.16%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 48, Loss: 0.3321, Train: 78.16%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 49, Loss: 0.3039, Train: 78.16%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 50, Loss: 0.2950, Train: 78.16%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 51, Loss: 0.2764, Train: 80.46%, Valid: 72.88% Test: 70.27%\n",
      "Run: 08, Epoch: 52, Loss: 0.2956, Train: 88.51%, Valid: 84.75% Test: 75.68%\n",
      "Run: 08, Epoch: 53, Loss: 0.2292, Train: 89.66%, Valid: 88.14% Test: 75.68%\n",
      "Run: 08, Epoch: 54, Loss: 0.3388, Train: 90.80%, Valid: 88.14% Test: 75.68%\n",
      "Run: 08, Epoch: 55, Loss: 0.2763, Train: 90.80%, Valid: 88.14% Test: 75.68%\n",
      "Run: 08, Epoch: 56, Loss: 0.2378, Train: 89.66%, Valid: 88.14% Test: 75.68%\n",
      "Run: 08, Epoch: 57, Loss: 0.3053, Train: 88.51%, Valid: 88.14% Test: 75.68%\n",
      "Run: 08, Epoch: 58, Loss: 0.3989, Train: 90.80%, Valid: 88.14% Test: 75.68%\n",
      "Run: 08, Epoch: 59, Loss: 0.2212, Train: 89.66%, Valid: 88.14% Test: 75.68%\n",
      "Run: 08, Epoch: 60, Loss: 0.2676, Train: 90.80%, Valid: 88.14% Test: 72.97%\n",
      "Run: 08, Epoch: 61, Loss: 0.2993, Train: 94.25%, Valid: 86.44% Test: 78.38%\n",
      "Run: 08, Epoch: 62, Loss: 0.2395, Train: 95.40%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 63, Loss: 0.2680, Train: 97.70%, Valid: 81.36% Test: 75.68%\n",
      "Run: 08, Epoch: 64, Loss: 0.1803, Train: 97.70%, Valid: 81.36% Test: 75.68%\n",
      "Run: 08, Epoch: 65, Loss: 0.2028, Train: 96.55%, Valid: 81.36% Test: 75.68%\n",
      "Run: 08, Epoch: 66, Loss: 0.2859, Train: 90.80%, Valid: 81.36% Test: 72.97%\n",
      "Run: 08, Epoch: 67, Loss: 0.1853, Train: 87.36%, Valid: 83.05% Test: 70.27%\n",
      "Run: 08, Epoch: 68, Loss: 0.2434, Train: 88.51%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 69, Loss: 0.1987, Train: 89.66%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 70, Loss: 0.2548, Train: 89.66%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 71, Loss: 0.1678, Train: 89.66%, Valid: 81.36% Test: 75.68%\n",
      "Run: 08, Epoch: 72, Loss: 0.2858, Train: 89.66%, Valid: 84.75% Test: 75.68%\n",
      "Run: 08, Epoch: 73, Loss: 0.2494, Train: 90.80%, Valid: 84.75% Test: 75.68%\n",
      "Run: 08, Epoch: 74, Loss: 0.2211, Train: 94.25%, Valid: 84.75% Test: 75.68%\n",
      "Run: 08, Epoch: 75, Loss: 0.1927, Train: 94.25%, Valid: 86.44% Test: 75.68%\n",
      "Run: 08, Epoch: 76, Loss: 0.2591, Train: 93.10%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 77, Loss: 0.2373, Train: 95.40%, Valid: 86.44% Test: 75.68%\n",
      "Run: 08, Epoch: 78, Loss: 0.2610, Train: 94.25%, Valid: 84.75% Test: 75.68%\n",
      "Run: 08, Epoch: 79, Loss: 0.1841, Train: 94.25%, Valid: 86.44% Test: 72.97%\n",
      "Run: 08, Epoch: 80, Loss: 0.2314, Train: 93.10%, Valid: 84.75% Test: 75.68%\n",
      "Run: 08, Epoch: 81, Loss: 0.2043, Train: 90.80%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 82, Loss: 0.2428, Train: 87.36%, Valid: 81.36% Test: 70.27%\n",
      "Run: 08, Epoch: 83, Loss: 0.1877, Train: 85.06%, Valid: 77.97% Test: 64.86%\n",
      "Run: 08, Epoch: 84, Loss: 0.2027, Train: 82.76%, Valid: 77.97% Test: 64.86%\n",
      "Run: 08, Epoch: 85, Loss: 0.1955, Train: 82.76%, Valid: 77.97% Test: 67.57%\n",
      "Run: 08, Epoch: 86, Loss: 0.2460, Train: 87.36%, Valid: 79.66% Test: 64.86%\n",
      "Run: 08, Epoch: 87, Loss: 0.2201, Train: 87.36%, Valid: 81.36% Test: 67.57%\n",
      "Run: 08, Epoch: 88, Loss: 0.2384, Train: 87.36%, Valid: 83.05% Test: 67.57%\n",
      "Run: 08, Epoch: 89, Loss: 0.1985, Train: 94.25%, Valid: 81.36% Test: 72.97%\n",
      "Run: 08, Epoch: 90, Loss: 0.2550, Train: 97.70%, Valid: 83.05% Test: 78.38%\n",
      "Run: 08, Epoch: 91, Loss: 0.1062, Train: 98.85%, Valid: 83.05% Test: 78.38%\n",
      "Run: 08, Epoch: 92, Loss: 0.1644, Train: 100.00%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 93, Loss: 0.1361, Train: 98.85%, Valid: 84.75% Test: 72.97%\n",
      "Run: 08, Epoch: 94, Loss: 0.1802, Train: 96.55%, Valid: 86.44% Test: 72.97%\n",
      "Run: 08, Epoch: 95, Loss: 0.1843, Train: 96.55%, Valid: 86.44% Test: 72.97%\n",
      "Run: 08, Epoch: 96, Loss: 0.1569, Train: 93.10%, Valid: 86.44% Test: 70.27%\n",
      "Run: 08, Epoch: 97, Loss: 0.2253, Train: 88.51%, Valid: 88.14% Test: 70.27%\n",
      "Run: 08, Epoch: 98, Loss: 0.2008, Train: 89.66%, Valid: 89.83% Test: 72.97%\n",
      "Run: 08, Epoch: 99, Loss: 0.1453, Train: 91.95%, Valid: 89.83% Test: 72.97%\n",
      "Run: 08, Epoch: 100, Loss: 0.2077, Train: 89.66%, Valid: 88.14% Test: 75.68%\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 89.83\n",
      "  Final Train: 89.66\n",
      "   Final Test: 72.97\n",
      "Run: 09, Epoch: 01, Loss: 1.7404, Train: 21.84%, Valid: 18.64% Test: 10.81%\n",
      "Run: 09, Epoch: 02, Loss: 1.5361, Train: 24.14%, Valid: 15.25% Test: 21.62%\n",
      "Run: 09, Epoch: 03, Loss: 1.3364, Train: 27.59%, Valid: 18.64% Test: 21.62%\n",
      "Run: 09, Epoch: 04, Loss: 1.2991, Train: 27.59%, Valid: 16.95% Test: 21.62%\n",
      "Run: 09, Epoch: 05, Loss: 1.2451, Train: 26.44%, Valid: 15.25% Test: 21.62%\n",
      "Run: 09, Epoch: 06, Loss: 1.2013, Train: 27.59%, Valid: 15.25% Test: 21.62%\n",
      "Run: 09, Epoch: 07, Loss: 1.0910, Train: 28.74%, Valid: 20.34% Test: 21.62%\n",
      "Run: 09, Epoch: 08, Loss: 1.1177, Train: 31.03%, Valid: 18.64% Test: 29.73%\n",
      "Run: 09, Epoch: 09, Loss: 1.0504, Train: 33.33%, Valid: 22.03% Test: 29.73%\n",
      "Run: 09, Epoch: 10, Loss: 0.9732, Train: 41.38%, Valid: 23.73% Test: 29.73%\n",
      "Run: 09, Epoch: 11, Loss: 1.0059, Train: 45.98%, Valid: 28.81% Test: 35.14%\n",
      "Run: 09, Epoch: 12, Loss: 0.9563, Train: 56.32%, Valid: 45.76% Test: 43.24%\n",
      "Run: 09, Epoch: 13, Loss: 0.9492, Train: 63.22%, Valid: 55.93% Test: 48.65%\n",
      "Run: 09, Epoch: 14, Loss: 0.9093, Train: 64.37%, Valid: 64.41% Test: 51.35%\n",
      "Run: 09, Epoch: 15, Loss: 0.9377, Train: 70.11%, Valid: 64.41% Test: 54.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 16, Loss: 0.8759, Train: 72.41%, Valid: 67.80% Test: 62.16%\n",
      "Run: 09, Epoch: 17, Loss: 0.8737, Train: 73.56%, Valid: 72.88% Test: 64.86%\n",
      "Run: 09, Epoch: 18, Loss: 0.9334, Train: 72.41%, Valid: 72.88% Test: 62.16%\n",
      "Run: 09, Epoch: 19, Loss: 0.8430, Train: 72.41%, Valid: 72.88% Test: 59.46%\n",
      "Run: 09, Epoch: 20, Loss: 0.7526, Train: 71.26%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 21, Loss: 0.7388, Train: 70.11%, Valid: 76.27% Test: 51.35%\n",
      "Run: 09, Epoch: 22, Loss: 0.6544, Train: 73.56%, Valid: 76.27% Test: 54.05%\n",
      "Run: 09, Epoch: 23, Loss: 0.7611, Train: 73.56%, Valid: 76.27% Test: 56.76%\n",
      "Run: 09, Epoch: 24, Loss: 0.7581, Train: 74.71%, Valid: 76.27% Test: 59.46%\n",
      "Run: 09, Epoch: 25, Loss: 0.7321, Train: 77.01%, Valid: 76.27% Test: 62.16%\n",
      "Run: 09, Epoch: 26, Loss: 0.6259, Train: 77.01%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 27, Loss: 0.6969, Train: 77.01%, Valid: 72.88% Test: 62.16%\n",
      "Run: 09, Epoch: 28, Loss: 0.6979, Train: 77.01%, Valid: 72.88% Test: 59.46%\n",
      "Run: 09, Epoch: 29, Loss: 0.5604, Train: 77.01%, Valid: 74.58% Test: 62.16%\n",
      "Run: 09, Epoch: 30, Loss: 0.6606, Train: 77.01%, Valid: 74.58% Test: 64.86%\n",
      "Run: 09, Epoch: 31, Loss: 0.6682, Train: 75.86%, Valid: 76.27% Test: 64.86%\n",
      "Run: 09, Epoch: 32, Loss: 0.5742, Train: 78.16%, Valid: 81.36% Test: 64.86%\n",
      "Run: 09, Epoch: 33, Loss: 0.6206, Train: 79.31%, Valid: 79.66% Test: 67.57%\n",
      "Run: 09, Epoch: 34, Loss: 0.6584, Train: 80.46%, Valid: 79.66% Test: 64.86%\n",
      "Run: 09, Epoch: 35, Loss: 0.5383, Train: 80.46%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 36, Loss: 0.4970, Train: 81.61%, Valid: 86.44% Test: 75.68%\n",
      "Run: 09, Epoch: 37, Loss: 0.5786, Train: 83.91%, Valid: 89.83% Test: 75.68%\n",
      "Run: 09, Epoch: 38, Loss: 0.6179, Train: 85.06%, Valid: 88.14% Test: 78.38%\n",
      "Run: 09, Epoch: 39, Loss: 0.6212, Train: 85.06%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 40, Loss: 0.4756, Train: 83.91%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 41, Loss: 0.4716, Train: 83.91%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 42, Loss: 0.4800, Train: 83.91%, Valid: 84.75% Test: 75.68%\n",
      "Run: 09, Epoch: 43, Loss: 0.5330, Train: 86.21%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 44, Loss: 0.4739, Train: 89.66%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 45, Loss: 0.4278, Train: 87.36%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 46, Loss: 0.5029, Train: 86.21%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 47, Loss: 0.4239, Train: 86.21%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 48, Loss: 0.3687, Train: 82.76%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 49, Loss: 0.4678, Train: 85.06%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 50, Loss: 0.3784, Train: 83.91%, Valid: 84.75% Test: 75.68%\n",
      "Run: 09, Epoch: 51, Loss: 0.4282, Train: 83.91%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 52, Loss: 0.2903, Train: 83.91%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 53, Loss: 0.3666, Train: 82.76%, Valid: 86.44% Test: 81.08%\n",
      "Run: 09, Epoch: 54, Loss: 0.4051, Train: 85.06%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 55, Loss: 0.3812, Train: 87.36%, Valid: 84.75% Test: 81.08%\n",
      "Run: 09, Epoch: 56, Loss: 0.3406, Train: 87.36%, Valid: 79.66% Test: 78.38%\n",
      "Run: 09, Epoch: 57, Loss: 0.4146, Train: 86.21%, Valid: 79.66% Test: 75.68%\n",
      "Run: 09, Epoch: 58, Loss: 0.2989, Train: 86.21%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 59, Loss: 0.3612, Train: 86.21%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 60, Loss: 0.3277, Train: 90.80%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 61, Loss: 0.4053, Train: 91.95%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 62, Loss: 0.3200, Train: 83.91%, Valid: 88.14% Test: 78.38%\n",
      "Run: 09, Epoch: 63, Loss: 0.3587, Train: 85.06%, Valid: 86.44% Test: 75.68%\n",
      "Run: 09, Epoch: 64, Loss: 0.3387, Train: 83.91%, Valid: 89.83% Test: 78.38%\n",
      "Run: 09, Epoch: 65, Loss: 0.4220, Train: 85.06%, Valid: 91.53% Test: 78.38%\n",
      "Run: 09, Epoch: 66, Loss: 0.3352, Train: 87.36%, Valid: 89.83% Test: 83.78%\n",
      "Run: 09, Epoch: 67, Loss: 0.3560, Train: 89.66%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 68, Loss: 0.3162, Train: 89.66%, Valid: 91.53% Test: 86.49%\n",
      "Run: 09, Epoch: 69, Loss: 0.2799, Train: 90.80%, Valid: 88.14% Test: 86.49%\n",
      "Run: 09, Epoch: 70, Loss: 0.3048, Train: 91.95%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 71, Loss: 0.3662, Train: 91.95%, Valid: 89.83% Test: 83.78%\n",
      "Run: 09, Epoch: 72, Loss: 0.3307, Train: 95.40%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 73, Loss: 0.2871, Train: 91.95%, Valid: 86.44% Test: 78.38%\n",
      "Run: 09, Epoch: 74, Loss: 0.3651, Train: 93.10%, Valid: 88.14% Test: 78.38%\n",
      "Run: 09, Epoch: 75, Loss: 0.3866, Train: 93.10%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 76, Loss: 0.3795, Train: 93.10%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 77, Loss: 0.2593, Train: 93.10%, Valid: 88.14% Test: 78.38%\n",
      "Run: 09, Epoch: 78, Loss: 0.2611, Train: 91.95%, Valid: 88.14% Test: 78.38%\n",
      "Run: 09, Epoch: 79, Loss: 0.2687, Train: 93.10%, Valid: 86.44% Test: 78.38%\n",
      "Run: 09, Epoch: 80, Loss: 0.3426, Train: 91.95%, Valid: 88.14% Test: 78.38%\n",
      "Run: 09, Epoch: 81, Loss: 0.2939, Train: 89.66%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 82, Loss: 0.3443, Train: 89.66%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 83, Loss: 0.3426, Train: 88.51%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 84, Loss: 0.2942, Train: 91.95%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 85, Loss: 0.3015, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 09, Epoch: 86, Loss: 0.3102, Train: 93.10%, Valid: 86.44% Test: 83.78%\n",
      "Run: 09, Epoch: 87, Loss: 0.3358, Train: 93.10%, Valid: 86.44% Test: 83.78%\n",
      "Run: 09, Epoch: 88, Loss: 0.3174, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 09, Epoch: 89, Loss: 0.2307, Train: 90.80%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 90, Loss: 0.3277, Train: 87.36%, Valid: 83.05% Test: 86.49%\n",
      "Run: 09, Epoch: 91, Loss: 0.2630, Train: 83.91%, Valid: 83.05% Test: 86.49%\n",
      "Run: 09, Epoch: 92, Loss: 0.3492, Train: 83.91%, Valid: 86.44% Test: 78.38%\n",
      "Run: 09, Epoch: 93, Loss: 0.2876, Train: 86.21%, Valid: 86.44% Test: 78.38%\n",
      "Run: 09, Epoch: 94, Loss: 0.2975, Train: 88.51%, Valid: 84.75% Test: 83.78%\n",
      "Run: 09, Epoch: 95, Loss: 0.2836, Train: 93.10%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 96, Loss: 0.3048, Train: 91.95%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 97, Loss: 0.4009, Train: 89.66%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 98, Loss: 0.2385, Train: 87.36%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 99, Loss: 0.2570, Train: 82.76%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 100, Loss: 0.3052, Train: 85.06%, Valid: 83.05% Test: 83.78%\n",
      "Run 09:\n",
      "Highest Train: 95.40\n",
      "Highest Valid: 91.53\n",
      "  Final Train: 85.06\n",
      "   Final Test: 78.38\n",
      "Run: 10, Epoch: 01, Loss: 1.7368, Train: 31.03%, Valid: 49.15% Test: 40.54%\n",
      "Run: 10, Epoch: 02, Loss: 1.5749, Train: 39.08%, Valid: 52.54% Test: 48.65%\n",
      "Run: 10, Epoch: 03, Loss: 1.4529, Train: 44.83%, Valid: 50.85% Test: 43.24%\n",
      "Run: 10, Epoch: 04, Loss: 1.3668, Train: 47.13%, Valid: 35.59% Test: 32.43%\n",
      "Run: 10, Epoch: 05, Loss: 1.2811, Train: 29.89%, Valid: 27.12% Test: 24.32%\n",
      "Run: 10, Epoch: 06, Loss: 1.1462, Train: 28.74%, Valid: 25.42% Test: 27.03%\n",
      "Run: 10, Epoch: 07, Loss: 1.1178, Train: 32.18%, Valid: 27.12% Test: 29.73%\n",
      "Run: 10, Epoch: 08, Loss: 1.1196, Train: 37.93%, Valid: 33.90% Test: 40.54%\n",
      "Run: 10, Epoch: 09, Loss: 1.0350, Train: 51.72%, Valid: 45.76% Test: 45.95%\n",
      "Run: 10, Epoch: 10, Loss: 0.9410, Train: 57.47%, Valid: 49.15% Test: 48.65%\n",
      "Run: 10, Epoch: 11, Loss: 1.0537, Train: 65.52%, Valid: 52.54% Test: 45.95%\n",
      "Run: 10, Epoch: 12, Loss: 0.9567, Train: 65.52%, Valid: 64.41% Test: 51.35%\n",
      "Run: 10, Epoch: 13, Loss: 0.8829, Train: 66.67%, Valid: 67.80% Test: 56.76%\n",
      "Run: 10, Epoch: 14, Loss: 0.8736, Train: 67.82%, Valid: 72.88% Test: 56.76%\n",
      "Run: 10, Epoch: 15, Loss: 0.7680, Train: 62.07%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 16, Loss: 0.8450, Train: 59.77%, Valid: 71.19% Test: 59.46%\n",
      "Run: 10, Epoch: 17, Loss: 0.7699, Train: 65.52%, Valid: 71.19% Test: 56.76%\n",
      "Run: 10, Epoch: 18, Loss: 0.7241, Train: 67.82%, Valid: 76.27% Test: 59.46%\n",
      "Run: 10, Epoch: 19, Loss: 0.7393, Train: 70.11%, Valid: 74.58% Test: 62.16%\n",
      "Run: 10, Epoch: 20, Loss: 0.7010, Train: 70.11%, Valid: 74.58% Test: 67.57%\n",
      "Run: 10, Epoch: 21, Loss: 0.6501, Train: 75.86%, Valid: 79.66% Test: 67.57%\n",
      "Run: 10, Epoch: 22, Loss: 0.6714, Train: 78.16%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 23, Loss: 0.6246, Train: 81.61%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 24, Loss: 0.5614, Train: 81.61%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 25, Loss: 0.5569, Train: 81.61%, Valid: 79.66% Test: 67.57%\n",
      "Run: 10, Epoch: 26, Loss: 0.5811, Train: 78.16%, Valid: 81.36% Test: 64.86%\n",
      "Run: 10, Epoch: 27, Loss: 0.5179, Train: 73.56%, Valid: 79.66% Test: 64.86%\n",
      "Run: 10, Epoch: 28, Loss: 0.5454, Train: 72.41%, Valid: 77.97% Test: 64.86%\n",
      "Run: 10, Epoch: 29, Loss: 0.4891, Train: 81.61%, Valid: 77.97% Test: 67.57%\n",
      "Run: 10, Epoch: 30, Loss: 0.5237, Train: 88.51%, Valid: 79.66% Test: 70.27%\n",
      "Run: 10, Epoch: 31, Loss: 0.5422, Train: 90.80%, Valid: 86.44% Test: 75.68%\n",
      "Run: 10, Epoch: 32, Loss: 0.5234, Train: 90.80%, Valid: 86.44% Test: 78.38%\n",
      "Run: 10, Epoch: 33, Loss: 0.5153, Train: 90.80%, Valid: 88.14% Test: 78.38%\n",
      "Run: 10, Epoch: 34, Loss: 0.5285, Train: 90.80%, Valid: 86.44% Test: 81.08%\n",
      "Run: 10, Epoch: 35, Loss: 0.4695, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 10, Epoch: 36, Loss: 0.5040, Train: 91.95%, Valid: 84.75% Test: 81.08%\n",
      "Run: 10, Epoch: 37, Loss: 0.4457, Train: 91.95%, Valid: 89.83% Test: 81.08%\n",
      "Run: 10, Epoch: 38, Loss: 0.4738, Train: 90.80%, Valid: 93.22% Test: 81.08%\n",
      "Run: 10, Epoch: 39, Loss: 0.4887, Train: 93.10%, Valid: 93.22% Test: 86.49%\n",
      "Run: 10, Epoch: 40, Loss: 0.3879, Train: 93.10%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 41, Loss: 0.4046, Train: 91.95%, Valid: 88.14% Test: 81.08%\n",
      "Run: 10, Epoch: 42, Loss: 0.3535, Train: 91.95%, Valid: 83.05% Test: 78.38%\n",
      "Run: 10, Epoch: 43, Loss: 0.3633, Train: 88.51%, Valid: 83.05% Test: 78.38%\n",
      "Run: 10, Epoch: 44, Loss: 0.4656, Train: 88.51%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 45, Loss: 0.4828, Train: 83.91%, Valid: 81.36% Test: 72.97%\n",
      "Run: 10, Epoch: 46, Loss: 0.3820, Train: 83.91%, Valid: 84.75% Test: 72.97%\n",
      "Run: 10, Epoch: 47, Loss: 0.4184, Train: 82.76%, Valid: 86.44% Test: 78.38%\n",
      "Run: 10, Epoch: 48, Loss: 0.4067, Train: 85.06%, Valid: 88.14% Test: 81.08%\n",
      "Run: 10, Epoch: 49, Loss: 0.4084, Train: 88.51%, Valid: 89.83% Test: 81.08%\n",
      "Run: 10, Epoch: 50, Loss: 0.3748, Train: 90.80%, Valid: 89.83% Test: 78.38%\n",
      "Run: 10, Epoch: 51, Loss: 0.4362, Train: 90.80%, Valid: 89.83% Test: 81.08%\n",
      "Run: 10, Epoch: 52, Loss: 0.3519, Train: 90.80%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 53, Loss: 0.4531, Train: 90.80%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 54, Loss: 0.3498, Train: 90.80%, Valid: 89.83% Test: 81.08%\n",
      "Run: 10, Epoch: 55, Loss: 0.3501, Train: 91.95%, Valid: 91.53% Test: 81.08%\n",
      "Run: 10, Epoch: 56, Loss: 0.3194, Train: 91.95%, Valid: 91.53% Test: 81.08%\n",
      "Run: 10, Epoch: 57, Loss: 0.3501, Train: 91.95%, Valid: 91.53% Test: 81.08%\n",
      "Run: 10, Epoch: 58, Loss: 0.3927, Train: 89.66%, Valid: 89.83% Test: 81.08%\n",
      "Run: 10, Epoch: 59, Loss: 0.3706, Train: 85.06%, Valid: 81.36% Test: 78.38%\n",
      "Run: 10, Epoch: 60, Loss: 0.2816, Train: 79.31%, Valid: 79.66% Test: 70.27%\n",
      "Run: 10, Epoch: 61, Loss: 0.3158, Train: 81.61%, Valid: 76.27% Test: 70.27%\n",
      "Run: 10, Epoch: 62, Loss: 0.3159, Train: 86.21%, Valid: 77.97% Test: 70.27%\n",
      "Run: 10, Epoch: 63, Loss: 0.3900, Train: 89.66%, Valid: 79.66% Test: 75.68%\n",
      "Run: 10, Epoch: 64, Loss: 0.2948, Train: 91.95%, Valid: 86.44% Test: 81.08%\n",
      "Run: 10, Epoch: 65, Loss: 0.3075, Train: 90.80%, Valid: 89.83% Test: 78.38%\n",
      "Run: 10, Epoch: 66, Loss: 0.3218, Train: 90.80%, Valid: 88.14% Test: 78.38%\n",
      "Run: 10, Epoch: 67, Loss: 0.2681, Train: 90.80%, Valid: 89.83% Test: 78.38%\n",
      "Run: 10, Epoch: 68, Loss: 0.3277, Train: 91.95%, Valid: 88.14% Test: 81.08%\n",
      "Run: 10, Epoch: 69, Loss: 0.3234, Train: 93.10%, Valid: 84.75% Test: 81.08%\n",
      "Run: 10, Epoch: 70, Loss: 0.3542, Train: 90.80%, Valid: 83.05% Test: 78.38%\n",
      "Run: 10, Epoch: 71, Loss: 0.3929, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 10, Epoch: 72, Loss: 0.3029, Train: 93.10%, Valid: 84.75% Test: 83.78%\n",
      "Run: 10, Epoch: 73, Loss: 0.3256, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 10, Epoch: 74, Loss: 0.2700, Train: 95.40%, Valid: 86.44% Test: 81.08%\n",
      "Run: 10, Epoch: 75, Loss: 0.3553, Train: 89.66%, Valid: 84.75% Test: 78.38%\n",
      "Run: 10, Epoch: 76, Loss: 0.2974, Train: 88.51%, Valid: 86.44% Test: 78.38%\n",
      "Run: 10, Epoch: 77, Loss: 0.1979, Train: 83.91%, Valid: 86.44% Test: 72.97%\n",
      "Run: 10, Epoch: 78, Loss: 0.2442, Train: 79.31%, Valid: 86.44% Test: 72.97%\n",
      "Run: 10, Epoch: 79, Loss: 0.2570, Train: 78.16%, Valid: 84.75% Test: 72.97%\n",
      "Run: 10, Epoch: 80, Loss: 0.2560, Train: 83.91%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 81, Loss: 0.2274, Train: 88.51%, Valid: 86.44% Test: 75.68%\n",
      "Run: 10, Epoch: 82, Loss: 0.2785, Train: 94.25%, Valid: 88.14% Test: 81.08%\n",
      "Run: 10, Epoch: 83, Loss: 0.2792, Train: 95.40%, Valid: 86.44% Test: 86.49%\n",
      "Run: 10, Epoch: 84, Loss: 0.3672, Train: 96.55%, Valid: 84.75% Test: 83.78%\n",
      "Run: 10, Epoch: 85, Loss: 0.2406, Train: 96.55%, Valid: 84.75% Test: 81.08%\n",
      "Run: 10, Epoch: 86, Loss: 0.3604, Train: 95.40%, Valid: 84.75% Test: 83.78%\n",
      "Run: 10, Epoch: 87, Loss: 0.2450, Train: 96.55%, Valid: 86.44% Test: 83.78%\n",
      "Run: 10, Epoch: 88, Loss: 0.2393, Train: 95.40%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 89, Loss: 0.1866, Train: 91.95%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 90, Loss: 0.2471, Train: 90.80%, Valid: 88.14% Test: 81.08%\n",
      "Run: 10, Epoch: 91, Loss: 0.3187, Train: 90.80%, Valid: 88.14% Test: 78.38%\n",
      "Run: 10, Epoch: 92, Loss: 0.2418, Train: 91.95%, Valid: 89.83% Test: 78.38%\n",
      "Run: 10, Epoch: 93, Loss: 0.2933, Train: 91.95%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 94, Loss: 0.2858, Train: 93.10%, Valid: 91.53% Test: 86.49%\n",
      "Run: 10, Epoch: 95, Loss: 0.2030, Train: 93.10%, Valid: 91.53% Test: 89.19%\n",
      "Run: 10, Epoch: 96, Loss: 0.1997, Train: 94.25%, Valid: 86.44% Test: 86.49%\n",
      "Run: 10, Epoch: 97, Loss: 0.3225, Train: 94.25%, Valid: 86.44% Test: 86.49%\n",
      "Run: 10, Epoch: 98, Loss: 0.2849, Train: 94.25%, Valid: 89.83% Test: 89.19%\n",
      "Run: 10, Epoch: 99, Loss: 0.2617, Train: 93.10%, Valid: 89.83% Test: 86.49%\n",
      "Run: 10, Epoch: 100, Loss: 0.2592, Train: 94.25%, Valid: 89.83% Test: 89.19%\n",
      "Run 10:\n",
      "Highest Train: 96.55\n",
      "Highest Valid: 93.22\n",
      "  Final Train: 90.80\n",
      "   Final Test: 81.08\n",
      "All runs:\n",
      "Highest Train: 97.47 ± 1.70\n",
      "Highest Valid: 86.95 ± 5.12\n",
      "  Final Train: 93.10 ± 4.09\n",
      "   Final Test: 81.89 ± 5.85\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 32, 'dropout': 0.5, 'epochs': 100, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-6, 'lr': 0.01}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = WebKB(root='/tmp/Texas', name='Texas',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    #idx_train=[data.train_mask[i][0] for i in range(len(data.y))]\n",
    "    #train_idx = np.where(idx_train)[0]\n",
    "    #idx_val=[data.val_mask[i][0] for i in range(len(data.y))]\n",
    "    #valid_idx = np.where(idx_val)[0]\n",
    "    #idx_test=[data.test_mask[i][0] for i in range(len(data.y))]\n",
    "    #test_idx = np.where(idx_test)[0]\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model, data, train_idx, optimizer)\n",
    "            result = test(model, data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085c7fd",
   "metadata": {},
   "source": [
    "# Topological Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e47b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], edge_index=[2, 298], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Cornell', name='Cornell')\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607be4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1   2   2   6   6   8   8   8   8   8   9  10  10  10  10  12\n",
      "   13  18  19  20  20  20  20  20  21  21  21  21  22  22  24  24  24  24\n",
      "   24  24  24  25  25  27  27  27  28  28  29  31  33  35  41  41  42  43\n",
      "   48  48  52  53  53  57  57  57  57  57  57  57  57  57  57  57  57  57\n",
      "   57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57\n",
      "   57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57\n",
      "   57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57\n",
      "   57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57  57\n",
      "   57  57  57  57  57  57  57  57  62  62  63  64  65  65  66  66  66  66\n",
      "   66  66  66  66  66  67  67  67  67  67  67  67  67  69  70  70  72  72\n",
      "   73  74  78  78  82  83  83  83  83  83  83  83  85  87  89  91  94  95\n",
      "   96  96  96  97  97  97  97  97  99 101 101 101 101 102 104 104 105 109\n",
      "  109 109 110 110 115 116 117 120 120 120 121 122 122 122 125 125 126 128\n",
      "  129 133 133 133 134 135 135 135 137 138 138 138 138 138 146 146 146 146\n",
      "  146 146 146 147 149 149 149 151 151 153 154 155 159 160 161 162 162 167\n",
      "  167 168 168 169 169 171 171 171 171 171 171 172 173 174 175 176 176 176\n",
      "  176 176 176 176 176 176 176 177 179 180]\n",
      " [101 122  27  75 130 109 149  28 101 109 122 158 148   5 142 154 166   7\n",
      "  150  96 103   8  47 101 109 158  28  41 147 180  44  92   4  28  47  68\n",
      "   84 139 159  30  75   1  74  97  47  84 179 158  51  79  66  67 164 104\n",
      "   13 157  53   5  92   1   3   5   7  11  14  15  16  17  18  24  26  29\n",
      "   30  31  32  33  34  37  40  41  42  43  45  46  50  53  55  58  59  60\n",
      "   61  68  71  72  74  76  77  80  81  82  84  86  88  89  90  95  96  98\n",
      "   99 100 103 104 105 106 107 108 109 110 112 113 114 116 119 123 124 127\n",
      "  128 131 132 135 141 144 145 147 148 153 154 155 156 157 158 160 163 164\n",
      "  165 168 170 174 175 177 178 182  23 118  54 135   8 158   3  30  39  49\n",
      "   75 130 144 146 150  13  30  49  89 140 148 165 181  93  70  96 121 172\n",
      "   10  27  26 143  94   3  69  93 103 129 164 174  21 174 150  27  82  43\n",
      "   18 121 173   3  27 118 152 165 155   6   8 109 122  82  56  79  99   6\n",
      "  101 122  93 150  99 111 181   1 153 160  72   6   8 109  77 175 174 128\n",
      "   93  66 133 146  44   5  22  64  63  69  93 118 129 164   3  30  49  66\n",
      "   75 130 150 158 140 148 165  36 147 160   5  99 136 153   8   5 154  63\n",
      "  137  99 155  38 137  23  50  69  92  93 129  72  96  93  77   4   5  38\n",
      "   46  57  63 137 145 153 167 118  29  93]]\n"
     ]
    }
   ],
   "source": [
    "print(data.edge_index.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52514bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_nodes=len(data.y)\n",
    "Edge_idx=data.edge_index.numpy()\n",
    "Node=range(Number_nodes)\n",
    "Edgelist=[]\n",
    "for i in range(len(Edge_idx[1])):\n",
    "    Edgelist.append((Edge_idx[0][i],Edge_idx[1][i]))\n",
    "#print(Edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f9d236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a \"plain\" graph is undirected\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# give each a node a 'name', which is a letter in this case.\n",
    "#G.add_node('a')\n",
    "\n",
    "# the add_nodes_from method allows adding nodes from a sequence, in this case a list\n",
    "#nodes_to_add = ['b', 'c', 'd']\n",
    "G.add_nodes_from(Node)\n",
    "\n",
    "# add edge from 'a' to 'b'\n",
    "# since this graph is undirected, the order doesn't matter here\n",
    "#G.add_edge('a', 'b')\n",
    "\n",
    "# just like add_nodes_from, we can add edges from a sequence\n",
    "# edges should be specified as 2-tuples\n",
    "#edges_to_add = [('a', 'c'), ('b', 'c'), ('c', 'd')]\n",
    "G.add_edges_from(Edgelist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "781abc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n"
     ]
    }
   ],
   "source": [
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77abd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topological_Feature_subLevel(adj,filtration_fun, Filtration):\n",
    "        betti_0=[]\n",
    "        betti_1=[]\n",
    "        for p in range(len(Filtration)):\n",
    "            n_active = np.where(np.array(filtration_fun) <= Filtration[p])[0].tolist()\n",
    "            Active_node=np.unique(n_active)\n",
    "            if (len(Active_node)==0):\n",
    "                betti_0.append(0)\n",
    "                betti_1.append(0)\n",
    "            else:\n",
    "                b=adj[Active_node,:][:,Active_node]\n",
    "                my_flag=pyflagser.flagser_unweighted(b, min_dimension=0, max_dimension=2, directed=False, coeff=2, approximation=None)\n",
    "                x = my_flag[\"betti\"]\n",
    "                betti_0.append(x[0])\n",
    "                betti_1.append(x[1])\n",
    "            n_active.clear()\n",
    "        return betti_0,betti_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e40cacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Degree_list(Graph):\n",
    "    degree_list = [Graph.degree(node) for node in Graph.nodes]\n",
    "    return np.array(degree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "118b65fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  |  69 \n",
      "\n",
      "2  |  40 \n",
      "\n",
      "3  |  22 \n",
      "\n",
      "4  |  20 \n",
      "\n",
      "5  |  13 \n",
      "\n",
      "6  |  4 \n",
      "\n",
      "7  |  5 \n",
      "\n",
      "8  |  3 \n",
      "\n",
      "9  |  3 \n",
      "\n",
      "10  |  2 \n",
      "\n",
      "12  |  1 \n",
      "\n",
      "94  |  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "degree_list=Degree_list(G)\n",
    "unique_list=np.unique(degree_list)\n",
    "for d in unique_list:\n",
    "    count=0\n",
    "    for i in range(len(degree_list)):\n",
    "        if degree_list[i]==d:\n",
    "            count=count+1\n",
    "    print(int(d),\" | \",count,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7080881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 182 (100%)"
     ]
    }
   ],
   "source": [
    "import pyflagser\n",
    "Node_fil=[1,2,3,4,5,6,7,8,9,10,20,50]\n",
    "topo_betti_0=[]\n",
    "topo_betti_1=[]\n",
    "Node_Edge=[]\n",
    "for i in range(Number_nodes):\n",
    "    print(\"\\rProcessing file {} ({}%)\".format(i, 100*i//(Number_nodes-1)), end='', flush=True)\n",
    "    subgraph=ego_graph(G, i, radius=2, center=True, undirected=True, distance=None)\n",
    "    filt=Degree_list(subgraph)\n",
    "    A_sub = nx.to_numpy_array(subgraph)# adjacency matrix of subgraph\n",
    "    fe=Topological_Feature_subLevel(A_sub,filt,Node_fil)\n",
    "    topo_betti_0.append(fe[0])\n",
    "    topo_betti_1.append(fe[1])\n",
    "    Node_Edge.append([subgraph.number_of_nodes(),subgraph.number_of_edges()])\n",
    "    #topo_with_NE.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a5892bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 19], [99, 131], [6, 9], [111, 163], [18, 29], [109, 141], [12, 26], [96, 120], [18, 41], [5, 4], [11, 16], [95, 119], [3, 2], [16, 23], [95, 119], [95, 119], [95, 119], [95, 119], [98, 126], [4, 3], [16, 36], [16, 22], [10, 13], [9, 10], [104, 138], [8, 11], [97, 121], [11, 16], [22, 42], [96, 121], [108, 153], [98, 126], [95, 119], [96, 120], [95, 119], [3, 2], [3, 2], [95, 119], [12, 19], [12, 20], [95, 119], [111, 158], [97, 124], [97, 121], [5, 4], [95, 119], [100, 128], [15, 27], [6, 5], [19, 31], [101, 130], [3, 2], [5, 5], [101, 129], [5, 7], [95, 119], [5, 5], [152, 246], [95, 119], [95, 119], [95, 119], [95, 119], [7, 6], [13, 20], [5, 6], [12, 25], [22, 41], [21, 34], [100, 127], [16, 23], [6, 9], [95, 119], [97, 124], [6, 6], [98, 128], [14, 24], [95, 119], [96, 121], [4, 3], [6, 6], [95, 119], [95, 119], [97, 122], [20, 34], [102, 133], [6, 5], [95, 119], [6, 6], [95, 119], [103, 143], [95, 119], [5, 7], [14, 19], [21, 33], [4, 4], [95, 119], [98, 126], [18, 26], [95, 119], [96, 120], [95, 119], [14, 30], [4, 4], [100, 131], [98, 122], [96, 120], [95, 119], [95, 119], [95, 119], [106, 152], [106, 152], [3, 2], [95, 119], [95, 119], [95, 119], [6, 10], [96, 120], [3, 2], [15, 20], [95, 119], [7, 12], [8, 14], [13, 28], [95, 119], [95, 119], [4, 5], [6, 6], [95, 119], [95, 119], [16, 23], [13, 22], [95, 119], [95, 119], [12, 20], [3, 2], [101, 129], [3, 2], [13, 20], [16, 27], [9, 12], [12, 13], [95, 119], [6, 6], [3, 2], [103, 141], [100, 128], [21, 40], [104, 136], [103, 135], [12, 21], [19, 36], [6, 6], [6, 6], [101, 131], [100, 126], [96, 120], [95, 119], [97, 121], [105, 147], [10, 13], [96, 122], [9, 19], [8, 13], [95, 119], [101, 136], [106, 145], [6, 6], [13, 20], [96, 120], [6, 9], [95, 119], [16, 25], [4, 5], [6, 9], [104, 141], [96, 121], [105, 138], [99, 126], [95, 119], [3, 3], [14, 20], [11, 10], [95, 119]]\n"
     ]
    }
   ],
   "source": [
    "print( Node_Edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49a08a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=298])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Cornell', name='Cornell',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "445f9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_betti0=torch.tensor(topo_betti_0).float()\n",
    "topo_betti1=torch.tensor(topo_betti_1).float()\n",
    "NodeEdge=torch.tensor(Node_Edge).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbeea52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 10], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=298], topo=[183, 24])\n"
     ]
    }
   ],
   "source": [
    "data.x=CC_domain\n",
    "topo_fe=torch.cat((topo_betti0,topo_betti1),1)\n",
    "data.topo=topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9acd56",
   "metadata": {},
   "source": [
    "# TOPO_W_GSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd4668e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "        #return x.log_softmax(dim=-1)\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        #return torch.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "class MLP2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(MLP2, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters_mlp2(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = self.bns[i](x)\n",
    "            #x = F.relu(x)\n",
    "            x=F.sigmoid(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "    \n",
    "\n",
    "def train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2):\n",
    "    model.train()\n",
    "    mlp_model.train()\n",
    "    mlp_2.train()\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_mlp.zero_grad()\n",
    "    optimizer_mlp2.zero_grad()\n",
    "    gcn_embedding = model(data.x, data.adj_t)[train_idx]\n",
    "    #print(gcn_embedding)\n",
    "    mlp_embedding = mlp_model(data.topo[train_idx])\n",
    "    #print(mlp_embedding)\n",
    "    combined_embedding = torch.cat((gcn_embedding, mlp_embedding), dim=1)\n",
    "    #print(combined_embedding)\n",
    "    mlp_emb = mlp_2(combined_embedding)\n",
    "    #print(mlp_emb)\n",
    "    loss = F.nll_loss(mlp_emb, data.y.squeeze()[train_idx])\n",
    "    #loss = F.nll_loss(combined_embedding, data.y.squeeze()[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer_mlp2.step()\n",
    "    optimizer.step()\n",
    "    optimizer_mlp.step()\n",
    "    \n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ACC(Prediction, Label):\n",
    "    correct = Prediction.view(-1).eq(Label).sum().item()\n",
    "    total=len(Label)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx):\n",
    "    model.eval()\n",
    "    mlp_model.eval()\n",
    "    mlp_2.eval()\n",
    "\n",
    "    gcn_out = model(data.x, data.adj_t)\n",
    "    #print(gcn_out[0])\n",
    "    mlp_out=mlp_model(data.topo)\n",
    "    #print(mlp_out)\n",
    "    #out=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    Com=torch.cat((gcn_out,mlp_out),dim=1)\n",
    "    out=mlp_2(Com)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    #print(y_pred[0])\n",
    "    y_pred=y_pred.view(-1)\n",
    "    train_acc=ACC(data.y[train_idx],y_pred[train_idx])\n",
    "    valid_acc=ACC(data.y[valid_idx],y_pred[valid_idx])\n",
    "    test_acc =ACC(data.y[test_idx],y_pred[test_idx])\n",
    "    return train_acc, valid_acc, test_acc\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef21f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x163aa38b0>\n",
      "Run: 01, Epoch: 01, Loss: 1.5786, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 02, Loss: 1.5134, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 03, Loss: 1.4844, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 04, Loss: 1.4571, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 05, Loss: 1.4178, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 06, Loss: 1.4043, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 07, Loss: 1.3632, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 08, Loss: 1.3067, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 09, Loss: 1.2916, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 10, Loss: 1.2885, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 11, Loss: 1.2774, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 12, Loss: 1.2191, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 13, Loss: 1.1846, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 14, Loss: 1.2107, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 15, Loss: 1.1703, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 16, Loss: 1.1264, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 17, Loss: 1.1583, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 18, Loss: 1.0793, Train: 41.38%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 19, Loss: 1.0903, Train: 42.53%, Valid: 52.54% Test: 40.54%\n",
      "Run: 01, Epoch: 20, Loss: 1.0677, Train: 42.53%, Valid: 54.24% Test: 40.54%\n",
      "Run: 01, Epoch: 21, Loss: 1.0412, Train: 44.83%, Valid: 55.93% Test: 43.24%\n",
      "Run: 01, Epoch: 22, Loss: 1.0036, Train: 47.13%, Valid: 57.63% Test: 43.24%\n",
      "Run: 01, Epoch: 23, Loss: 1.0142, Train: 48.28%, Valid: 59.32% Test: 43.24%\n",
      "Run: 01, Epoch: 24, Loss: 1.0239, Train: 51.72%, Valid: 59.32% Test: 45.95%\n",
      "Run: 01, Epoch: 25, Loss: 1.0167, Train: 58.62%, Valid: 62.71% Test: 51.35%\n",
      "Run: 01, Epoch: 26, Loss: 0.9458, Train: 58.62%, Valid: 62.71% Test: 51.35%\n",
      "Run: 01, Epoch: 27, Loss: 0.9792, Train: 63.22%, Valid: 66.10% Test: 54.05%\n",
      "Run: 01, Epoch: 28, Loss: 1.0149, Train: 66.67%, Valid: 69.49% Test: 56.76%\n",
      "Run: 01, Epoch: 29, Loss: 0.9472, Train: 65.52%, Valid: 67.80% Test: 51.35%\n",
      "Run: 01, Epoch: 30, Loss: 0.9213, Train: 64.37%, Valid: 67.80% Test: 54.05%\n",
      "Run: 01, Epoch: 31, Loss: 0.9176, Train: 65.52%, Valid: 67.80% Test: 54.05%\n",
      "Run: 01, Epoch: 32, Loss: 0.8858, Train: 67.82%, Valid: 67.80% Test: 56.76%\n",
      "Run: 01, Epoch: 33, Loss: 0.8917, Train: 68.97%, Valid: 69.49% Test: 54.05%\n",
      "Run: 01, Epoch: 34, Loss: 0.8734, Train: 70.11%, Valid: 66.10% Test: 59.46%\n",
      "Run: 01, Epoch: 35, Loss: 0.9122, Train: 70.11%, Valid: 71.19% Test: 59.46%\n",
      "Run: 01, Epoch: 36, Loss: 0.8332, Train: 72.41%, Valid: 72.88% Test: 62.16%\n",
      "Run: 01, Epoch: 37, Loss: 0.8937, Train: 74.71%, Valid: 71.19% Test: 64.86%\n",
      "Run: 01, Epoch: 38, Loss: 0.8563, Train: 78.16%, Valid: 72.88% Test: 67.57%\n",
      "Run: 01, Epoch: 39, Loss: 0.8452, Train: 77.01%, Valid: 72.88% Test: 64.86%\n",
      "Run: 01, Epoch: 40, Loss: 0.8073, Train: 78.16%, Valid: 71.19% Test: 62.16%\n",
      "Run: 01, Epoch: 41, Loss: 0.8157, Train: 81.61%, Valid: 72.88% Test: 64.86%\n",
      "Run: 01, Epoch: 42, Loss: 0.8193, Train: 83.91%, Valid: 76.27% Test: 72.97%\n",
      "Run: 01, Epoch: 43, Loss: 0.8071, Train: 89.66%, Valid: 77.97% Test: 75.68%\n",
      "Run: 01, Epoch: 44, Loss: 0.7590, Train: 88.51%, Valid: 81.36% Test: 75.68%\n",
      "Run: 01, Epoch: 45, Loss: 0.7413, Train: 87.36%, Valid: 84.75% Test: 72.97%\n",
      "Run: 01, Epoch: 46, Loss: 0.7853, Train: 87.36%, Valid: 81.36% Test: 75.68%\n",
      "Run: 01, Epoch: 47, Loss: 0.7717, Train: 88.51%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 48, Loss: 0.7600, Train: 87.36%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 49, Loss: 0.8179, Train: 85.06%, Valid: 76.27% Test: 83.78%\n",
      "Run: 01, Epoch: 50, Loss: 0.7844, Train: 85.06%, Valid: 76.27% Test: 83.78%\n",
      "Run: 01, Epoch: 51, Loss: 0.7477, Train: 85.06%, Valid: 76.27% Test: 86.49%\n",
      "Run: 01, Epoch: 52, Loss: 0.6989, Train: 86.21%, Valid: 77.97% Test: 81.08%\n",
      "Run: 01, Epoch: 53, Loss: 0.7835, Train: 88.51%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 54, Loss: 0.7460, Train: 87.36%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 55, Loss: 0.7396, Train: 88.51%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 56, Loss: 0.7317, Train: 90.80%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 57, Loss: 0.7088, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 58, Loss: 0.6841, Train: 88.51%, Valid: 81.36% Test: 75.68%\n",
      "Run: 01, Epoch: 59, Loss: 0.7190, Train: 86.21%, Valid: 84.75% Test: 72.97%\n",
      "Run: 01, Epoch: 60, Loss: 0.6901, Train: 80.46%, Valid: 81.36% Test: 72.97%\n",
      "Run: 01, Epoch: 61, Loss: 0.7383, Train: 79.31%, Valid: 79.66% Test: 75.68%\n",
      "Run: 01, Epoch: 62, Loss: 0.6387, Train: 78.16%, Valid: 79.66% Test: 75.68%\n",
      "Run: 01, Epoch: 63, Loss: 0.6558, Train: 79.31%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 64, Loss: 0.6765, Train: 80.46%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 65, Loss: 0.7267, Train: 86.21%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 66, Loss: 0.6344, Train: 86.21%, Valid: 76.27% Test: 78.38%\n",
      "Run: 01, Epoch: 67, Loss: 0.6735, Train: 86.21%, Valid: 79.66% Test: 75.68%\n",
      "Run: 01, Epoch: 68, Loss: 0.6400, Train: 86.21%, Valid: 76.27% Test: 67.57%\n",
      "Run: 01, Epoch: 69, Loss: 0.5949, Train: 86.21%, Valid: 76.27% Test: 64.86%\n",
      "Run: 01, Epoch: 70, Loss: 0.6300, Train: 87.36%, Valid: 79.66% Test: 64.86%\n",
      "Run: 01, Epoch: 71, Loss: 0.6477, Train: 89.66%, Valid: 79.66% Test: 67.57%\n",
      "Run: 01, Epoch: 72, Loss: 0.6549, Train: 90.80%, Valid: 81.36% Test: 72.97%\n",
      "Run: 01, Epoch: 73, Loss: 0.6031, Train: 94.25%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 74, Loss: 0.6038, Train: 91.95%, Valid: 81.36% Test: 83.78%\n",
      "Run: 01, Epoch: 75, Loss: 0.5778, Train: 89.66%, Valid: 79.66% Test: 86.49%\n",
      "Run: 01, Epoch: 76, Loss: 0.5251, Train: 88.51%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 77, Loss: 0.5920, Train: 86.21%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 78, Loss: 0.6232, Train: 86.21%, Valid: 81.36% Test: 86.49%\n",
      "Run: 01, Epoch: 79, Loss: 0.6052, Train: 89.66%, Valid: 81.36% Test: 86.49%\n",
      "Run: 01, Epoch: 80, Loss: 0.5909, Train: 94.25%, Valid: 81.36% Test: 86.49%\n",
      "Run: 01, Epoch: 81, Loss: 0.5697, Train: 94.25%, Valid: 79.66% Test: 89.19%\n",
      "Run: 01, Epoch: 82, Loss: 0.5404, Train: 94.25%, Valid: 84.75% Test: 83.78%\n",
      "Run: 01, Epoch: 83, Loss: 0.6156, Train: 94.25%, Valid: 84.75% Test: 86.49%\n",
      "Run: 01, Epoch: 84, Loss: 0.5934, Train: 93.10%, Valid: 83.05% Test: 83.78%\n",
      "Run: 01, Epoch: 85, Loss: 0.5542, Train: 94.25%, Valid: 81.36% Test: 83.78%\n",
      "Run: 01, Epoch: 86, Loss: 0.5168, Train: 94.25%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 87, Loss: 0.5508, Train: 94.25%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 88, Loss: 0.5697, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 89, Loss: 0.5089, Train: 89.66%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 90, Loss: 0.5167, Train: 88.51%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 91, Loss: 0.5557, Train: 87.36%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 92, Loss: 0.5655, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 93, Loss: 0.5141, Train: 90.80%, Valid: 83.05% Test: 86.49%\n",
      "Run: 01, Epoch: 94, Loss: 0.5231, Train: 90.80%, Valid: 86.44% Test: 83.78%\n",
      "Run: 01, Epoch: 95, Loss: 0.5529, Train: 93.10%, Valid: 88.14% Test: 83.78%\n",
      "Run: 01, Epoch: 96, Loss: 0.4997, Train: 93.10%, Valid: 86.44% Test: 81.08%\n",
      "Run: 01, Epoch: 97, Loss: 0.5262, Train: 94.25%, Valid: 84.75% Test: 83.78%\n",
      "Run: 01, Epoch: 98, Loss: 0.5093, Train: 93.10%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 99, Loss: 0.5119, Train: 93.10%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 100, Loss: 0.5261, Train: 91.95%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 101, Loss: 0.4809, Train: 91.95%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 102, Loss: 0.4397, Train: 89.66%, Valid: 81.36% Test: 83.78%\n",
      "Run: 01, Epoch: 103, Loss: 0.5414, Train: 90.80%, Valid: 84.75% Test: 83.78%\n",
      "Run: 01, Epoch: 104, Loss: 0.4919, Train: 90.80%, Valid: 84.75% Test: 86.49%\n",
      "Run: 01, Epoch: 105, Loss: 0.4770, Train: 91.95%, Valid: 88.14% Test: 86.49%\n",
      "Run: 01, Epoch: 106, Loss: 0.4880, Train: 93.10%, Valid: 89.83% Test: 83.78%\n",
      "Run: 01, Epoch: 107, Loss: 0.5714, Train: 91.95%, Valid: 88.14% Test: 83.78%\n",
      "Run: 01, Epoch: 108, Loss: 0.4746, Train: 89.66%, Valid: 86.44% Test: 83.78%\n",
      "Run: 01, Epoch: 109, Loss: 0.4660, Train: 89.66%, Valid: 84.75% Test: 83.78%\n",
      "Run: 01, Epoch: 110, Loss: 0.4435, Train: 91.95%, Valid: 83.05% Test: 78.38%\n",
      "Run: 01, Epoch: 111, Loss: 0.4743, Train: 88.51%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 112, Loss: 0.4384, Train: 91.95%, Valid: 83.05% Test: 78.38%\n",
      "Run: 01, Epoch: 113, Loss: 0.4835, Train: 94.25%, Valid: 83.05% Test: 78.38%\n",
      "Run: 01, Epoch: 114, Loss: 0.4333, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 115, Loss: 0.4468, Train: 91.95%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 116, Loss: 0.4314, Train: 93.10%, Valid: 81.36% Test: 83.78%\n",
      "Run: 01, Epoch: 117, Loss: 0.4787, Train: 93.10%, Valid: 88.14% Test: 83.78%\n",
      "Run: 01, Epoch: 118, Loss: 0.4425, Train: 91.95%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 119, Loss: 0.4328, Train: 89.66%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 120, Loss: 0.4378, Train: 91.95%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 121, Loss: 0.5030, Train: 89.66%, Valid: 74.58% Test: 78.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 122, Loss: 0.4897, Train: 89.66%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 123, Loss: 0.4636, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 124, Loss: 0.3969, Train: 93.10%, Valid: 84.75% Test: 83.78%\n",
      "Run: 01, Epoch: 125, Loss: 0.4125, Train: 94.25%, Valid: 83.05% Test: 83.78%\n",
      "Run: 01, Epoch: 126, Loss: 0.4677, Train: 94.25%, Valid: 79.66% Test: 75.68%\n",
      "Run: 01, Epoch: 127, Loss: 0.4225, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 128, Loss: 0.4509, Train: 83.91%, Valid: 77.97% Test: 70.27%\n",
      "Run: 01, Epoch: 129, Loss: 0.5228, Train: 79.31%, Valid: 79.66% Test: 67.57%\n",
      "Run: 01, Epoch: 130, Loss: 0.4637, Train: 86.21%, Valid: 81.36% Test: 78.38%\n",
      "Run: 01, Epoch: 131, Loss: 0.3350, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 01, Epoch: 132, Loss: 0.4113, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 01, Epoch: 133, Loss: 0.4918, Train: 91.95%, Valid: 86.44% Test: 91.89%\n",
      "Run: 01, Epoch: 134, Loss: 0.3962, Train: 91.95%, Valid: 86.44% Test: 86.49%\n",
      "Run: 01, Epoch: 135, Loss: 0.4909, Train: 94.25%, Valid: 86.44% Test: 83.78%\n",
      "Run: 01, Epoch: 136, Loss: 0.4129, Train: 94.25%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 137, Loss: 0.4385, Train: 93.10%, Valid: 83.05% Test: 70.27%\n",
      "Run: 01, Epoch: 138, Loss: 0.4429, Train: 93.10%, Valid: 79.66% Test: 75.68%\n",
      "Run: 01, Epoch: 139, Loss: 0.4679, Train: 90.80%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 140, Loss: 0.3120, Train: 91.95%, Valid: 79.66% Test: 78.38%\n",
      "Run: 01, Epoch: 141, Loss: 0.3923, Train: 90.80%, Valid: 79.66% Test: 83.78%\n",
      "Run: 01, Epoch: 142, Loss: 0.3628, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 143, Loss: 0.4269, Train: 94.25%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 144, Loss: 0.3795, Train: 95.40%, Valid: 84.75% Test: 78.38%\n",
      "Run: 01, Epoch: 145, Loss: 0.3544, Train: 89.66%, Valid: 83.05% Test: 78.38%\n",
      "Run: 01, Epoch: 146, Loss: 0.4630, Train: 87.36%, Valid: 83.05% Test: 78.38%\n",
      "Run: 01, Epoch: 147, Loss: 0.4526, Train: 95.40%, Valid: 83.05% Test: 78.38%\n",
      "Run: 01, Epoch: 148, Loss: 0.4015, Train: 90.80%, Valid: 84.75% Test: 78.38%\n",
      "Run: 01, Epoch: 149, Loss: 0.4712, Train: 86.21%, Valid: 79.66% Test: 75.68%\n",
      "Run: 01, Epoch: 150, Loss: 0.3258, Train: 82.76%, Valid: 76.27% Test: 78.38%\n",
      "Run: 01, Epoch: 151, Loss: 0.3316, Train: 81.61%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 152, Loss: 0.4052, Train: 93.10%, Valid: 83.05% Test: 89.19%\n",
      "Run: 01, Epoch: 153, Loss: 0.3846, Train: 93.10%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 154, Loss: 0.4241, Train: 93.10%, Valid: 84.75% Test: 89.19%\n",
      "Run: 01, Epoch: 155, Loss: 0.3636, Train: 91.95%, Valid: 84.75% Test: 86.49%\n",
      "Run: 01, Epoch: 156, Loss: 0.3476, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 01, Epoch: 157, Loss: 0.3341, Train: 94.25%, Valid: 86.44% Test: 83.78%\n",
      "Run: 01, Epoch: 158, Loss: 0.4016, Train: 93.10%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 159, Loss: 0.4088, Train: 90.80%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 160, Loss: 0.3934, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 161, Loss: 0.4565, Train: 94.25%, Valid: 81.36% Test: 81.08%\n",
      "Run: 01, Epoch: 162, Loss: 0.3802, Train: 93.10%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 163, Loss: 0.4079, Train: 94.25%, Valid: 83.05% Test: 83.78%\n",
      "Run: 01, Epoch: 164, Loss: 0.3345, Train: 95.40%, Valid: 83.05% Test: 83.78%\n",
      "Run: 01, Epoch: 165, Loss: 0.3216, Train: 93.10%, Valid: 84.75% Test: 89.19%\n",
      "Run: 01, Epoch: 166, Loss: 0.3226, Train: 90.80%, Valid: 83.05% Test: 91.89%\n",
      "Run: 01, Epoch: 167, Loss: 0.4294, Train: 90.80%, Valid: 81.36% Test: 86.49%\n",
      "Run: 01, Epoch: 168, Loss: 0.4115, Train: 89.66%, Valid: 83.05% Test: 83.78%\n",
      "Run: 01, Epoch: 169, Loss: 0.3151, Train: 89.66%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 170, Loss: 0.3461, Train: 90.80%, Valid: 86.44% Test: 78.38%\n",
      "Run: 01, Epoch: 171, Loss: 0.3264, Train: 95.40%, Valid: 84.75% Test: 86.49%\n",
      "Run: 01, Epoch: 172, Loss: 0.3916, Train: 95.40%, Valid: 84.75% Test: 86.49%\n",
      "Run: 01, Epoch: 173, Loss: 0.3500, Train: 94.25%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 174, Loss: 0.3864, Train: 94.25%, Valid: 86.44% Test: 81.08%\n",
      "Run: 01, Epoch: 175, Loss: 0.3617, Train: 94.25%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 176, Loss: 0.3209, Train: 94.25%, Valid: 84.75% Test: 83.78%\n",
      "Run: 01, Epoch: 177, Loss: 0.3082, Train: 95.40%, Valid: 81.36% Test: 83.78%\n",
      "Run: 01, Epoch: 178, Loss: 0.2956, Train: 96.55%, Valid: 86.44% Test: 86.49%\n",
      "Run: 01, Epoch: 179, Loss: 0.3246, Train: 94.25%, Valid: 88.14% Test: 89.19%\n",
      "Run: 01, Epoch: 180, Loss: 0.3429, Train: 95.40%, Valid: 88.14% Test: 81.08%\n",
      "Run: 01, Epoch: 181, Loss: 0.4187, Train: 93.10%, Valid: 88.14% Test: 81.08%\n",
      "Run: 01, Epoch: 182, Loss: 0.3237, Train: 94.25%, Valid: 86.44% Test: 78.38%\n",
      "Run: 01, Epoch: 183, Loss: 0.3052, Train: 95.40%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 184, Loss: 0.3785, Train: 94.25%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 185, Loss: 0.3037, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 186, Loss: 0.3281, Train: 91.95%, Valid: 76.27% Test: 78.38%\n",
      "Run: 01, Epoch: 187, Loss: 0.4594, Train: 90.80%, Valid: 77.97% Test: 78.38%\n",
      "Run: 01, Epoch: 188, Loss: 0.3175, Train: 90.80%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 189, Loss: 0.3386, Train: 91.95%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 190, Loss: 0.3214, Train: 90.80%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 191, Loss: 0.2744, Train: 93.10%, Valid: 84.75% Test: 81.08%\n",
      "Run: 01, Epoch: 192, Loss: 0.4147, Train: 93.10%, Valid: 84.75% Test: 83.78%\n",
      "Run: 01, Epoch: 193, Loss: 0.3161, Train: 94.25%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 194, Loss: 0.3399, Train: 95.40%, Valid: 77.97% Test: 83.78%\n",
      "Run: 01, Epoch: 195, Loss: 0.3574, Train: 96.55%, Valid: 76.27% Test: 83.78%\n",
      "Run: 01, Epoch: 196, Loss: 0.4194, Train: 93.10%, Valid: 76.27% Test: 81.08%\n",
      "Run: 01, Epoch: 197, Loss: 0.3802, Train: 94.25%, Valid: 79.66% Test: 81.08%\n",
      "Run: 01, Epoch: 198, Loss: 0.3419, Train: 96.55%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 199, Loss: 0.3703, Train: 96.55%, Valid: 83.05% Test: 81.08%\n",
      "Run: 01, Epoch: 200, Loss: 0.3667, Train: 96.55%, Valid: 83.05% Test: 78.38%\n",
      "Run 01:\n",
      "Highest Train: 96.55\n",
      "Highest Valid: 89.83\n",
      "  Final Train: 93.10\n",
      "   Final Test: 83.78\n",
      "Run: 02, Epoch: 01, Loss: 1.7559, Train: 6.90%, Valid: 10.17% Test: 10.81%\n",
      "Run: 02, Epoch: 02, Loss: 1.7084, Train: 6.90%, Valid: 10.17% Test: 10.81%\n",
      "Run: 02, Epoch: 03, Loss: 1.6375, Train: 6.90%, Valid: 10.17% Test: 10.81%\n",
      "Run: 02, Epoch: 04, Loss: 1.5695, Train: 6.90%, Valid: 10.17% Test: 10.81%\n",
      "Run: 02, Epoch: 05, Loss: 1.5061, Train: 41.38%, Valid: 50.85% Test: 43.24%\n",
      "Run: 02, Epoch: 06, Loss: 1.4626, Train: 41.38%, Valid: 50.85% Test: 43.24%\n",
      "Run: 02, Epoch: 07, Loss: 1.3738, Train: 41.38%, Valid: 50.85% Test: 43.24%\n",
      "Run: 02, Epoch: 08, Loss: 1.3246, Train: 41.38%, Valid: 50.85% Test: 43.24%\n",
      "Run: 02, Epoch: 09, Loss: 1.2880, Train: 42.53%, Valid: 50.85% Test: 43.24%\n",
      "Run: 02, Epoch: 10, Loss: 1.2380, Train: 42.53%, Valid: 50.85% Test: 43.24%\n",
      "Run: 02, Epoch: 11, Loss: 1.2030, Train: 42.53%, Valid: 50.85% Test: 43.24%\n",
      "Run: 02, Epoch: 12, Loss: 1.1361, Train: 43.68%, Valid: 50.85% Test: 43.24%\n",
      "Run: 02, Epoch: 13, Loss: 1.1471, Train: 45.98%, Valid: 52.54% Test: 43.24%\n",
      "Run: 02, Epoch: 14, Loss: 1.0901, Train: 50.57%, Valid: 57.63% Test: 43.24%\n",
      "Run: 02, Epoch: 15, Loss: 1.0909, Train: 51.72%, Valid: 59.32% Test: 43.24%\n",
      "Run: 02, Epoch: 16, Loss: 1.0268, Train: 57.47%, Valid: 67.80% Test: 48.65%\n",
      "Run: 02, Epoch: 17, Loss: 1.0526, Train: 62.07%, Valid: 69.49% Test: 48.65%\n",
      "Run: 02, Epoch: 18, Loss: 1.0322, Train: 63.22%, Valid: 67.80% Test: 51.35%\n",
      "Run: 02, Epoch: 19, Loss: 1.0065, Train: 63.22%, Valid: 69.49% Test: 56.76%\n",
      "Run: 02, Epoch: 20, Loss: 0.9656, Train: 62.07%, Valid: 69.49% Test: 56.76%\n",
      "Run: 02, Epoch: 21, Loss: 0.9604, Train: 60.92%, Valid: 74.58% Test: 56.76%\n",
      "Run: 02, Epoch: 22, Loss: 0.9668, Train: 59.77%, Valid: 72.88% Test: 54.05%\n",
      "Run: 02, Epoch: 23, Loss: 0.9415, Train: 59.77%, Valid: 71.19% Test: 51.35%\n",
      "Run: 02, Epoch: 24, Loss: 0.9335, Train: 60.92%, Valid: 69.49% Test: 51.35%\n",
      "Run: 02, Epoch: 25, Loss: 0.9498, Train: 60.92%, Valid: 67.80% Test: 51.35%\n",
      "Run: 02, Epoch: 26, Loss: 0.9028, Train: 63.22%, Valid: 67.80% Test: 48.65%\n",
      "Run: 02, Epoch: 27, Loss: 0.9047, Train: 65.52%, Valid: 69.49% Test: 51.35%\n",
      "Run: 02, Epoch: 28, Loss: 0.8940, Train: 65.52%, Valid: 71.19% Test: 54.05%\n",
      "Run: 02, Epoch: 29, Loss: 0.9107, Train: 65.52%, Valid: 71.19% Test: 56.76%\n",
      "Run: 02, Epoch: 30, Loss: 0.8656, Train: 68.97%, Valid: 71.19% Test: 62.16%\n",
      "Run: 02, Epoch: 31, Loss: 0.8704, Train: 71.26%, Valid: 74.58% Test: 67.57%\n",
      "Run: 02, Epoch: 32, Loss: 0.8401, Train: 74.71%, Valid: 72.88% Test: 67.57%\n",
      "Run: 02, Epoch: 33, Loss: 0.8994, Train: 77.01%, Valid: 74.58% Test: 64.86%\n",
      "Run: 02, Epoch: 34, Loss: 0.8529, Train: 75.86%, Valid: 74.58% Test: 64.86%\n",
      "Run: 02, Epoch: 35, Loss: 0.8093, Train: 74.71%, Valid: 72.88% Test: 59.46%\n",
      "Run: 02, Epoch: 36, Loss: 0.8763, Train: 72.41%, Valid: 72.88% Test: 56.76%\n",
      "Run: 02, Epoch: 37, Loss: 0.8464, Train: 74.71%, Valid: 71.19% Test: 56.76%\n",
      "Run: 02, Epoch: 38, Loss: 0.7963, Train: 78.16%, Valid: 71.19% Test: 56.76%\n",
      "Run: 02, Epoch: 39, Loss: 0.8241, Train: 79.31%, Valid: 71.19% Test: 64.86%\n",
      "Run: 02, Epoch: 40, Loss: 0.7950, Train: 81.61%, Valid: 71.19% Test: 67.57%\n",
      "Run: 02, Epoch: 41, Loss: 0.7771, Train: 81.61%, Valid: 69.49% Test: 64.86%\n",
      "Run: 02, Epoch: 42, Loss: 0.7909, Train: 80.46%, Valid: 67.80% Test: 59.46%\n",
      "Run: 02, Epoch: 43, Loss: 0.8039, Train: 77.01%, Valid: 66.10% Test: 56.76%\n",
      "Run: 02, Epoch: 44, Loss: 0.7702, Train: 77.01%, Valid: 67.80% Test: 59.46%\n",
      "Run: 02, Epoch: 45, Loss: 0.8233, Train: 78.16%, Valid: 67.80% Test: 62.16%\n",
      "Run: 02, Epoch: 46, Loss: 0.7548, Train: 80.46%, Valid: 69.49% Test: 67.57%\n",
      "Run: 02, Epoch: 47, Loss: 0.7885, Train: 82.76%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 48, Loss: 0.7473, Train: 83.91%, Valid: 72.88% Test: 70.27%\n",
      "Run: 02, Epoch: 49, Loss: 0.7606, Train: 83.91%, Valid: 69.49% Test: 70.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 50, Loss: 0.7367, Train: 85.06%, Valid: 69.49% Test: 72.97%\n",
      "Run: 02, Epoch: 51, Loss: 0.7030, Train: 85.06%, Valid: 72.88% Test: 70.27%\n",
      "Run: 02, Epoch: 52, Loss: 0.7544, Train: 85.06%, Valid: 72.88% Test: 67.57%\n",
      "Run: 02, Epoch: 53, Loss: 0.7478, Train: 85.06%, Valid: 72.88% Test: 72.97%\n",
      "Run: 02, Epoch: 54, Loss: 0.7260, Train: 83.91%, Valid: 76.27% Test: 70.27%\n",
      "Run: 02, Epoch: 55, Loss: 0.6727, Train: 83.91%, Valid: 76.27% Test: 67.57%\n",
      "Run: 02, Epoch: 56, Loss: 0.7043, Train: 83.91%, Valid: 77.97% Test: 64.86%\n",
      "Run: 02, Epoch: 57, Loss: 0.6774, Train: 85.06%, Valid: 77.97% Test: 64.86%\n",
      "Run: 02, Epoch: 58, Loss: 0.6985, Train: 83.91%, Valid: 74.58% Test: 62.16%\n",
      "Run: 02, Epoch: 59, Loss: 0.7443, Train: 83.91%, Valid: 74.58% Test: 59.46%\n",
      "Run: 02, Epoch: 60, Loss: 0.6922, Train: 86.21%, Valid: 76.27% Test: 62.16%\n",
      "Run: 02, Epoch: 61, Loss: 0.7447, Train: 86.21%, Valid: 76.27% Test: 67.57%\n",
      "Run: 02, Epoch: 62, Loss: 0.7109, Train: 85.06%, Valid: 72.88% Test: 67.57%\n",
      "Run: 02, Epoch: 63, Loss: 0.6329, Train: 85.06%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 64, Loss: 0.6028, Train: 86.21%, Valid: 72.88% Test: 72.97%\n",
      "Run: 02, Epoch: 65, Loss: 0.6451, Train: 88.51%, Valid: 72.88% Test: 72.97%\n",
      "Run: 02, Epoch: 66, Loss: 0.6643, Train: 86.21%, Valid: 71.19% Test: 67.57%\n",
      "Run: 02, Epoch: 67, Loss: 0.6487, Train: 86.21%, Valid: 74.58% Test: 59.46%\n",
      "Run: 02, Epoch: 68, Loss: 0.6602, Train: 85.06%, Valid: 72.88% Test: 64.86%\n",
      "Run: 02, Epoch: 69, Loss: 0.5979, Train: 80.46%, Valid: 77.97% Test: 64.86%\n",
      "Run: 02, Epoch: 70, Loss: 0.5931, Train: 82.76%, Valid: 76.27% Test: 64.86%\n",
      "Run: 02, Epoch: 71, Loss: 0.6333, Train: 85.06%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 72, Loss: 0.6137, Train: 88.51%, Valid: 76.27% Test: 70.27%\n",
      "Run: 02, Epoch: 73, Loss: 0.6738, Train: 87.36%, Valid: 76.27% Test: 64.86%\n",
      "Run: 02, Epoch: 74, Loss: 0.5836, Train: 87.36%, Valid: 71.19% Test: 67.57%\n",
      "Run: 02, Epoch: 75, Loss: 0.6122, Train: 87.36%, Valid: 74.58% Test: 67.57%\n",
      "Run: 02, Epoch: 76, Loss: 0.6041, Train: 87.36%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 77, Loss: 0.6628, Train: 87.36%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 78, Loss: 0.5895, Train: 87.36%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 79, Loss: 0.5942, Train: 87.36%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 80, Loss: 0.6002, Train: 85.06%, Valid: 74.58% Test: 78.38%\n",
      "Run: 02, Epoch: 81, Loss: 0.5808, Train: 79.31%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 82, Loss: 0.6255, Train: 78.16%, Valid: 79.66% Test: 67.57%\n",
      "Run: 02, Epoch: 83, Loss: 0.5544, Train: 73.56%, Valid: 79.66% Test: 67.57%\n",
      "Run: 02, Epoch: 84, Loss: 0.5748, Train: 73.56%, Valid: 81.36% Test: 64.86%\n",
      "Run: 02, Epoch: 85, Loss: 0.5549, Train: 78.16%, Valid: 77.97% Test: 64.86%\n",
      "Run: 02, Epoch: 86, Loss: 0.6386, Train: 82.76%, Valid: 76.27% Test: 67.57%\n",
      "Run: 02, Epoch: 87, Loss: 0.5525, Train: 87.36%, Valid: 74.58% Test: 64.86%\n",
      "Run: 02, Epoch: 88, Loss: 0.6030, Train: 89.66%, Valid: 74.58% Test: 64.86%\n",
      "Run: 02, Epoch: 89, Loss: 0.5752, Train: 88.51%, Valid: 74.58% Test: 62.16%\n",
      "Run: 02, Epoch: 90, Loss: 0.5337, Train: 89.66%, Valid: 74.58% Test: 64.86%\n",
      "Run: 02, Epoch: 91, Loss: 0.6050, Train: 90.80%, Valid: 69.49% Test: 70.27%\n",
      "Run: 02, Epoch: 92, Loss: 0.5516, Train: 90.80%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 93, Loss: 0.5442, Train: 91.95%, Valid: 79.66% Test: 78.38%\n",
      "Run: 02, Epoch: 94, Loss: 0.5177, Train: 90.80%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 95, Loss: 0.5456, Train: 89.66%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 96, Loss: 0.5805, Train: 89.66%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 97, Loss: 0.5118, Train: 89.66%, Valid: 77.97% Test: 67.57%\n",
      "Run: 02, Epoch: 98, Loss: 0.5443, Train: 90.80%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 99, Loss: 0.4961, Train: 90.80%, Valid: 77.97% Test: 75.68%\n",
      "Run: 02, Epoch: 100, Loss: 0.5044, Train: 90.80%, Valid: 77.97% Test: 70.27%\n",
      "Run: 02, Epoch: 101, Loss: 0.5531, Train: 90.80%, Valid: 74.58% Test: 70.27%\n",
      "Run: 02, Epoch: 102, Loss: 0.4937, Train: 89.66%, Valid: 74.58% Test: 67.57%\n",
      "Run: 02, Epoch: 103, Loss: 0.4959, Train: 90.80%, Valid: 76.27% Test: 67.57%\n",
      "Run: 02, Epoch: 104, Loss: 0.4769, Train: 90.80%, Valid: 77.97% Test: 70.27%\n",
      "Run: 02, Epoch: 105, Loss: 0.5143, Train: 90.80%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 106, Loss: 0.5523, Train: 89.66%, Valid: 74.58% Test: 75.68%\n",
      "Run: 02, Epoch: 107, Loss: 0.5172, Train: 86.21%, Valid: 74.58% Test: 72.97%\n",
      "Run: 02, Epoch: 108, Loss: 0.5258, Train: 85.06%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 109, Loss: 0.5026, Train: 82.76%, Valid: 77.97% Test: 72.97%\n",
      "Run: 02, Epoch: 110, Loss: 0.5121, Train: 87.36%, Valid: 76.27% Test: 78.38%\n",
      "Run: 02, Epoch: 111, Loss: 0.5003, Train: 86.21%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 112, Loss: 0.4995, Train: 87.36%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 113, Loss: 0.4868, Train: 87.36%, Valid: 83.05% Test: 75.68%\n",
      "Run: 02, Epoch: 114, Loss: 0.4369, Train: 83.91%, Valid: 83.05% Test: 72.97%\n",
      "Run: 02, Epoch: 115, Loss: 0.4321, Train: 82.76%, Valid: 79.66% Test: 70.27%\n",
      "Run: 02, Epoch: 116, Loss: 0.4985, Train: 87.36%, Valid: 76.27% Test: 70.27%\n",
      "Run: 02, Epoch: 117, Loss: 0.4902, Train: 88.51%, Valid: 76.27% Test: 67.57%\n",
      "Run: 02, Epoch: 118, Loss: 0.4913, Train: 89.66%, Valid: 72.88% Test: 64.86%\n",
      "Run: 02, Epoch: 119, Loss: 0.5011, Train: 86.21%, Valid: 71.19% Test: 70.27%\n",
      "Run: 02, Epoch: 120, Loss: 0.4599, Train: 85.06%, Valid: 72.88% Test: 64.86%\n",
      "Run: 02, Epoch: 121, Loss: 0.5094, Train: 85.06%, Valid: 71.19% Test: 64.86%\n",
      "Run: 02, Epoch: 122, Loss: 0.4883, Train: 85.06%, Valid: 72.88% Test: 70.27%\n",
      "Run: 02, Epoch: 123, Loss: 0.4886, Train: 89.66%, Valid: 76.27% Test: 64.86%\n",
      "Run: 02, Epoch: 124, Loss: 0.4887, Train: 90.80%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 125, Loss: 0.4217, Train: 89.66%, Valid: 83.05% Test: 78.38%\n",
      "Run: 02, Epoch: 126, Loss: 0.5037, Train: 89.66%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 127, Loss: 0.4658, Train: 88.51%, Valid: 81.36% Test: 72.97%\n",
      "Run: 02, Epoch: 128, Loss: 0.4944, Train: 87.36%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 129, Loss: 0.4337, Train: 83.91%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 130, Loss: 0.4246, Train: 86.21%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 131, Loss: 0.5112, Train: 89.66%, Valid: 76.27% Test: 72.97%\n",
      "Run: 02, Epoch: 132, Loss: 0.4781, Train: 89.66%, Valid: 74.58% Test: 67.57%\n",
      "Run: 02, Epoch: 133, Loss: 0.4276, Train: 90.80%, Valid: 74.58% Test: 64.86%\n",
      "Run: 02, Epoch: 134, Loss: 0.4248, Train: 80.46%, Valid: 71.19% Test: 54.05%\n",
      "Run: 02, Epoch: 135, Loss: 0.4067, Train: 75.86%, Valid: 61.02% Test: 54.05%\n",
      "Run: 02, Epoch: 136, Loss: 0.4443, Train: 68.97%, Valid: 59.32% Test: 54.05%\n",
      "Run: 02, Epoch: 137, Loss: 0.3826, Train: 78.16%, Valid: 72.88% Test: 59.46%\n",
      "Run: 02, Epoch: 138, Loss: 0.4639, Train: 86.21%, Valid: 79.66% Test: 67.57%\n",
      "Run: 02, Epoch: 139, Loss: 0.4940, Train: 91.95%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 140, Loss: 0.4132, Train: 93.10%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 141, Loss: 0.4422, Train: 90.80%, Valid: 81.36% Test: 70.27%\n",
      "Run: 02, Epoch: 142, Loss: 0.4315, Train: 91.95%, Valid: 81.36% Test: 67.57%\n",
      "Run: 02, Epoch: 143, Loss: 0.4460, Train: 90.80%, Valid: 83.05% Test: 70.27%\n",
      "Run: 02, Epoch: 144, Loss: 0.4528, Train: 90.80%, Valid: 83.05% Test: 75.68%\n",
      "Run: 02, Epoch: 145, Loss: 0.4337, Train: 89.66%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 146, Loss: 0.4780, Train: 91.95%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 147, Loss: 0.4265, Train: 93.10%, Valid: 77.97% Test: 70.27%\n",
      "Run: 02, Epoch: 148, Loss: 0.4416, Train: 93.10%, Valid: 79.66% Test: 72.97%\n",
      "Run: 02, Epoch: 149, Loss: 0.3887, Train: 91.95%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 150, Loss: 0.4498, Train: 91.95%, Valid: 81.36% Test: 72.97%\n",
      "Run: 02, Epoch: 151, Loss: 0.4161, Train: 91.95%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 152, Loss: 0.4102, Train: 91.95%, Valid: 79.66% Test: 75.68%\n",
      "Run: 02, Epoch: 153, Loss: 0.4591, Train: 91.95%, Valid: 83.05% Test: 75.68%\n",
      "Run: 02, Epoch: 154, Loss: 0.4540, Train: 94.25%, Valid: 83.05% Test: 72.97%\n",
      "Run: 02, Epoch: 155, Loss: 0.3838, Train: 90.80%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 156, Loss: 0.3771, Train: 87.36%, Valid: 79.66% Test: 78.38%\n",
      "Run: 02, Epoch: 157, Loss: 0.3556, Train: 87.36%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 158, Loss: 0.4563, Train: 90.80%, Valid: 77.97% Test: 78.38%\n",
      "Run: 02, Epoch: 159, Loss: 0.3821, Train: 90.80%, Valid: 79.66% Test: 78.38%\n",
      "Run: 02, Epoch: 160, Loss: 0.3526, Train: 95.40%, Valid: 81.36% Test: 72.97%\n",
      "Run: 02, Epoch: 161, Loss: 0.3675, Train: 94.25%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 162, Loss: 0.3685, Train: 95.40%, Valid: 86.44% Test: 72.97%\n",
      "Run: 02, Epoch: 163, Loss: 0.3182, Train: 95.40%, Valid: 86.44% Test: 75.68%\n",
      "Run: 02, Epoch: 164, Loss: 0.3446, Train: 96.55%, Valid: 84.75% Test: 75.68%\n",
      "Run: 02, Epoch: 165, Loss: 0.4283, Train: 97.70%, Valid: 84.75% Test: 75.68%\n",
      "Run: 02, Epoch: 166, Loss: 0.3452, Train: 97.70%, Valid: 84.75% Test: 75.68%\n",
      "Run: 02, Epoch: 167, Loss: 0.3768, Train: 97.70%, Valid: 84.75% Test: 75.68%\n",
      "Run: 02, Epoch: 168, Loss: 0.3256, Train: 95.40%, Valid: 79.66% Test: 70.27%\n",
      "Run: 02, Epoch: 169, Loss: 0.4046, Train: 93.10%, Valid: 79.66% Test: 70.27%\n",
      "Run: 02, Epoch: 170, Loss: 0.3755, Train: 97.70%, Valid: 83.05% Test: 72.97%\n",
      "Run: 02, Epoch: 171, Loss: 0.3736, Train: 97.70%, Valid: 88.14% Test: 72.97%\n",
      "Run: 02, Epoch: 172, Loss: 0.4237, Train: 97.70%, Valid: 83.05% Test: 72.97%\n",
      "Run: 02, Epoch: 173, Loss: 0.3088, Train: 97.70%, Valid: 83.05% Test: 70.27%\n",
      "Run: 02, Epoch: 174, Loss: 0.3811, Train: 96.55%, Valid: 83.05% Test: 72.97%\n",
      "Run: 02, Epoch: 175, Loss: 0.3425, Train: 96.55%, Valid: 83.05% Test: 72.97%\n",
      "Run: 02, Epoch: 176, Loss: 0.3671, Train: 95.40%, Valid: 86.44% Test: 78.38%\n",
      "Run: 02, Epoch: 177, Loss: 0.3979, Train: 95.40%, Valid: 84.75% Test: 75.68%\n",
      "Run: 02, Epoch: 178, Loss: 0.3471, Train: 95.40%, Valid: 83.05% Test: 78.38%\n",
      "Run: 02, Epoch: 179, Loss: 0.4020, Train: 94.25%, Valid: 83.05% Test: 78.38%\n",
      "Run: 02, Epoch: 180, Loss: 0.3319, Train: 93.10%, Valid: 84.75% Test: 78.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 181, Loss: 0.4106, Train: 94.25%, Valid: 86.44% Test: 72.97%\n",
      "Run: 02, Epoch: 182, Loss: 0.3290, Train: 95.40%, Valid: 88.14% Test: 72.97%\n",
      "Run: 02, Epoch: 183, Loss: 0.3712, Train: 96.55%, Valid: 84.75% Test: 72.97%\n",
      "Run: 02, Epoch: 184, Loss: 0.2834, Train: 95.40%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 185, Loss: 0.3195, Train: 94.25%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 186, Loss: 0.3463, Train: 95.40%, Valid: 83.05% Test: 75.68%\n",
      "Run: 02, Epoch: 187, Loss: 0.3102, Train: 96.55%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 188, Loss: 0.3733, Train: 96.55%, Valid: 83.05% Test: 78.38%\n",
      "Run: 02, Epoch: 189, Loss: 0.3015, Train: 96.55%, Valid: 84.75% Test: 75.68%\n",
      "Run: 02, Epoch: 190, Loss: 0.2627, Train: 94.25%, Valid: 83.05% Test: 75.68%\n",
      "Run: 02, Epoch: 191, Loss: 0.3758, Train: 95.40%, Valid: 84.75% Test: 75.68%\n",
      "Run: 02, Epoch: 192, Loss: 0.3551, Train: 94.25%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 193, Loss: 0.3714, Train: 95.40%, Valid: 81.36% Test: 75.68%\n",
      "Run: 02, Epoch: 194, Loss: 0.3155, Train: 96.55%, Valid: 84.75% Test: 75.68%\n",
      "Run: 02, Epoch: 195, Loss: 0.3021, Train: 96.55%, Valid: 84.75% Test: 75.68%\n",
      "Run: 02, Epoch: 196, Loss: 0.3488, Train: 97.70%, Valid: 86.44% Test: 75.68%\n",
      "Run: 02, Epoch: 197, Loss: 0.2827, Train: 96.55%, Valid: 89.83% Test: 75.68%\n",
      "Run: 02, Epoch: 198, Loss: 0.3664, Train: 96.55%, Valid: 89.83% Test: 78.38%\n",
      "Run: 02, Epoch: 199, Loss: 0.3460, Train: 96.55%, Valid: 84.75% Test: 81.08%\n",
      "Run: 02, Epoch: 200, Loss: 0.3260, Train: 96.55%, Valid: 83.05% Test: 78.38%\n",
      "Run 02:\n",
      "Highest Train: 97.70\n",
      "Highest Valid: 89.83\n",
      "  Final Train: 96.55\n",
      "   Final Test: 75.68\n",
      "Run: 03, Epoch: 01, Loss: 1.6423, Train: 18.39%, Valid: 16.95% Test: 10.81%\n",
      "Run: 03, Epoch: 02, Loss: 1.5729, Train: 19.54%, Valid: 16.95% Test: 10.81%\n",
      "Run: 03, Epoch: 03, Loss: 1.5604, Train: 48.28%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 04, Loss: 1.4912, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 05, Loss: 1.4669, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 06, Loss: 1.4471, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 07, Loss: 1.4046, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 08, Loss: 1.3635, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 09, Loss: 1.3342, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 10, Loss: 1.2988, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 11, Loss: 1.2737, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 12, Loss: 1.2496, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 13, Loss: 1.2223, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 14, Loss: 1.2158, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 15, Loss: 1.1438, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 16, Loss: 1.1380, Train: 47.13%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 17, Loss: 1.1197, Train: 48.28%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 18, Loss: 1.1239, Train: 48.28%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 19, Loss: 1.0340, Train: 48.28%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 20, Loss: 1.0545, Train: 48.28%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 21, Loss: 1.0129, Train: 48.28%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 22, Loss: 1.0236, Train: 48.28%, Valid: 35.59% Test: 54.05%\n",
      "Run: 03, Epoch: 23, Loss: 0.9833, Train: 52.87%, Valid: 37.29% Test: 54.05%\n",
      "Run: 03, Epoch: 24, Loss: 0.9792, Train: 54.02%, Valid: 37.29% Test: 54.05%\n",
      "Run: 03, Epoch: 25, Loss: 0.9582, Train: 54.02%, Valid: 38.98% Test: 56.76%\n",
      "Run: 03, Epoch: 26, Loss: 0.9125, Train: 55.17%, Valid: 44.07% Test: 56.76%\n",
      "Run: 03, Epoch: 27, Loss: 0.8948, Train: 56.32%, Valid: 44.07% Test: 62.16%\n",
      "Run: 03, Epoch: 28, Loss: 0.8709, Train: 57.47%, Valid: 47.46% Test: 64.86%\n",
      "Run: 03, Epoch: 29, Loss: 0.8945, Train: 59.77%, Valid: 49.15% Test: 67.57%\n",
      "Run: 03, Epoch: 30, Loss: 0.8668, Train: 66.67%, Valid: 52.54% Test: 75.68%\n",
      "Run: 03, Epoch: 31, Loss: 0.8643, Train: 68.97%, Valid: 57.63% Test: 78.38%\n",
      "Run: 03, Epoch: 32, Loss: 0.8159, Train: 66.67%, Valid: 52.54% Test: 75.68%\n",
      "Run: 03, Epoch: 33, Loss: 0.8286, Train: 66.67%, Valid: 54.24% Test: 75.68%\n",
      "Run: 03, Epoch: 34, Loss: 0.8591, Train: 65.52%, Valid: 54.24% Test: 75.68%\n",
      "Run: 03, Epoch: 35, Loss: 0.7899, Train: 68.97%, Valid: 52.54% Test: 78.38%\n",
      "Run: 03, Epoch: 36, Loss: 0.8347, Train: 68.97%, Valid: 55.93% Test: 81.08%\n",
      "Run: 03, Epoch: 37, Loss: 0.7781, Train: 73.56%, Valid: 59.32% Test: 83.78%\n",
      "Run: 03, Epoch: 38, Loss: 0.8046, Train: 74.71%, Valid: 59.32% Test: 83.78%\n",
      "Run: 03, Epoch: 39, Loss: 0.7552, Train: 74.71%, Valid: 61.02% Test: 81.08%\n",
      "Run: 03, Epoch: 40, Loss: 0.7330, Train: 74.71%, Valid: 62.71% Test: 81.08%\n",
      "Run: 03, Epoch: 41, Loss: 0.7609, Train: 77.01%, Valid: 62.71% Test: 81.08%\n",
      "Run: 03, Epoch: 42, Loss: 0.7832, Train: 72.41%, Valid: 61.02% Test: 81.08%\n",
      "Run: 03, Epoch: 43, Loss: 0.7382, Train: 73.56%, Valid: 59.32% Test: 81.08%\n",
      "Run: 03, Epoch: 44, Loss: 0.7349, Train: 73.56%, Valid: 59.32% Test: 81.08%\n",
      "Run: 03, Epoch: 45, Loss: 0.7938, Train: 73.56%, Valid: 61.02% Test: 81.08%\n",
      "Run: 03, Epoch: 46, Loss: 0.6832, Train: 75.86%, Valid: 66.10% Test: 81.08%\n",
      "Run: 03, Epoch: 47, Loss: 0.7073, Train: 81.61%, Valid: 67.80% Test: 72.97%\n",
      "Run: 03, Epoch: 48, Loss: 0.6983, Train: 82.76%, Valid: 66.10% Test: 72.97%\n",
      "Run: 03, Epoch: 49, Loss: 0.6622, Train: 83.91%, Valid: 69.49% Test: 72.97%\n",
      "Run: 03, Epoch: 50, Loss: 0.7261, Train: 83.91%, Valid: 67.80% Test: 70.27%\n",
      "Run: 03, Epoch: 51, Loss: 0.6643, Train: 80.46%, Valid: 66.10% Test: 78.38%\n",
      "Run: 03, Epoch: 52, Loss: 0.6867, Train: 82.76%, Valid: 64.41% Test: 75.68%\n",
      "Run: 03, Epoch: 53, Loss: 0.6709, Train: 83.91%, Valid: 64.41% Test: 78.38%\n",
      "Run: 03, Epoch: 54, Loss: 0.6383, Train: 85.06%, Valid: 64.41% Test: 72.97%\n",
      "Run: 03, Epoch: 55, Loss: 0.6690, Train: 82.76%, Valid: 64.41% Test: 70.27%\n",
      "Run: 03, Epoch: 56, Loss: 0.6471, Train: 81.61%, Valid: 64.41% Test: 67.57%\n",
      "Run: 03, Epoch: 57, Loss: 0.6381, Train: 80.46%, Valid: 62.71% Test: 70.27%\n",
      "Run: 03, Epoch: 58, Loss: 0.6869, Train: 81.61%, Valid: 62.71% Test: 70.27%\n",
      "Run: 03, Epoch: 59, Loss: 0.6300, Train: 85.06%, Valid: 62.71% Test: 70.27%\n",
      "Run: 03, Epoch: 60, Loss: 0.6835, Train: 86.21%, Valid: 64.41% Test: 70.27%\n",
      "Run: 03, Epoch: 61, Loss: 0.6644, Train: 86.21%, Valid: 64.41% Test: 70.27%\n",
      "Run: 03, Epoch: 62, Loss: 0.5886, Train: 83.91%, Valid: 66.10% Test: 78.38%\n",
      "Run: 03, Epoch: 63, Loss: 0.6280, Train: 85.06%, Valid: 66.10% Test: 78.38%\n",
      "Run: 03, Epoch: 64, Loss: 0.6558, Train: 85.06%, Valid: 66.10% Test: 75.68%\n",
      "Run: 03, Epoch: 65, Loss: 0.5527, Train: 86.21%, Valid: 66.10% Test: 67.57%\n",
      "Run: 03, Epoch: 66, Loss: 0.6450, Train: 86.21%, Valid: 64.41% Test: 64.86%\n",
      "Run: 03, Epoch: 67, Loss: 0.6150, Train: 82.76%, Valid: 61.02% Test: 64.86%\n",
      "Run: 03, Epoch: 68, Loss: 0.5702, Train: 83.91%, Valid: 61.02% Test: 64.86%\n",
      "Run: 03, Epoch: 69, Loss: 0.6165, Train: 83.91%, Valid: 64.41% Test: 64.86%\n",
      "Run: 03, Epoch: 70, Loss: 0.5569, Train: 85.06%, Valid: 64.41% Test: 67.57%\n",
      "Run: 03, Epoch: 71, Loss: 0.6176, Train: 86.21%, Valid: 64.41% Test: 70.27%\n",
      "Run: 03, Epoch: 72, Loss: 0.5834, Train: 86.21%, Valid: 62.71% Test: 75.68%\n",
      "Run: 03, Epoch: 73, Loss: 0.5677, Train: 83.91%, Valid: 64.41% Test: 81.08%\n",
      "Run: 03, Epoch: 74, Loss: 0.5976, Train: 85.06%, Valid: 64.41% Test: 83.78%\n",
      "Run: 03, Epoch: 75, Loss: 0.5833, Train: 82.76%, Valid: 66.10% Test: 83.78%\n",
      "Run: 03, Epoch: 76, Loss: 0.6097, Train: 86.21%, Valid: 67.80% Test: 83.78%\n",
      "Run: 03, Epoch: 77, Loss: 0.5470, Train: 87.36%, Valid: 72.88% Test: 78.38%\n",
      "Run: 03, Epoch: 78, Loss: 0.5477, Train: 94.25%, Valid: 74.58% Test: 70.27%\n",
      "Run: 03, Epoch: 79, Loss: 0.5951, Train: 93.10%, Valid: 76.27% Test: 72.97%\n",
      "Run: 03, Epoch: 80, Loss: 0.5452, Train: 91.95%, Valid: 76.27% Test: 70.27%\n",
      "Run: 03, Epoch: 81, Loss: 0.5684, Train: 93.10%, Valid: 76.27% Test: 70.27%\n",
      "Run: 03, Epoch: 82, Loss: 0.5543, Train: 91.95%, Valid: 76.27% Test: 70.27%\n",
      "Run: 03, Epoch: 83, Loss: 0.5150, Train: 90.80%, Valid: 74.58% Test: 72.97%\n",
      "Run: 03, Epoch: 84, Loss: 0.5264, Train: 89.66%, Valid: 74.58% Test: 75.68%\n",
      "Run: 03, Epoch: 85, Loss: 0.5287, Train: 89.66%, Valid: 69.49% Test: 72.97%\n",
      "Run: 03, Epoch: 86, Loss: 0.5547, Train: 88.51%, Valid: 71.19% Test: 78.38%\n",
      "Run: 03, Epoch: 87, Loss: 0.4998, Train: 89.66%, Valid: 71.19% Test: 83.78%\n",
      "Run: 03, Epoch: 88, Loss: 0.5656, Train: 91.95%, Valid: 67.80% Test: 83.78%\n",
      "Run: 03, Epoch: 89, Loss: 0.5164, Train: 90.80%, Valid: 62.71% Test: 81.08%\n",
      "Run: 03, Epoch: 90, Loss: 0.5112, Train: 91.95%, Valid: 64.41% Test: 78.38%\n",
      "Run: 03, Epoch: 91, Loss: 0.5061, Train: 88.51%, Valid: 61.02% Test: 75.68%\n",
      "Run: 03, Epoch: 92, Loss: 0.5199, Train: 93.10%, Valid: 64.41% Test: 75.68%\n",
      "Run: 03, Epoch: 93, Loss: 0.4939, Train: 93.10%, Valid: 69.49% Test: 75.68%\n",
      "Run: 03, Epoch: 94, Loss: 0.5107, Train: 93.10%, Valid: 74.58% Test: 72.97%\n",
      "Run: 03, Epoch: 95, Loss: 0.5362, Train: 93.10%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 96, Loss: 0.4836, Train: 93.10%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 97, Loss: 0.4482, Train: 94.25%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 98, Loss: 0.4824, Train: 93.10%, Valid: 71.19% Test: 70.27%\n",
      "Run: 03, Epoch: 99, Loss: 0.4837, Train: 91.95%, Valid: 69.49% Test: 78.38%\n",
      "Run: 03, Epoch: 100, Loss: 0.4413, Train: 91.95%, Valid: 71.19% Test: 81.08%\n",
      "Run: 03, Epoch: 101, Loss: 0.5145, Train: 93.10%, Valid: 74.58% Test: 81.08%\n",
      "Run: 03, Epoch: 102, Loss: 0.4944, Train: 94.25%, Valid: 72.88% Test: 78.38%\n",
      "Run: 03, Epoch: 103, Loss: 0.5248, Train: 94.25%, Valid: 76.27% Test: 78.38%\n",
      "Run: 03, Epoch: 104, Loss: 0.4732, Train: 94.25%, Valid: 79.66% Test: 81.08%\n",
      "Run: 03, Epoch: 105, Loss: 0.4291, Train: 95.40%, Valid: 76.27% Test: 81.08%\n",
      "Run: 03, Epoch: 106, Loss: 0.4696, Train: 91.95%, Valid: 71.19% Test: 89.19%\n",
      "Run: 03, Epoch: 107, Loss: 0.4864, Train: 91.95%, Valid: 72.88% Test: 91.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 03, Epoch: 108, Loss: 0.4776, Train: 90.80%, Valid: 72.88% Test: 83.78%\n",
      "Run: 03, Epoch: 109, Loss: 0.4420, Train: 90.80%, Valid: 74.58% Test: 78.38%\n",
      "Run: 03, Epoch: 110, Loss: 0.4840, Train: 91.95%, Valid: 72.88% Test: 72.97%\n",
      "Run: 03, Epoch: 111, Loss: 0.4025, Train: 93.10%, Valid: 74.58% Test: 70.27%\n",
      "Run: 03, Epoch: 112, Loss: 0.4644, Train: 91.95%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 113, Loss: 0.4091, Train: 90.80%, Valid: 76.27% Test: 72.97%\n",
      "Run: 03, Epoch: 114, Loss: 0.4265, Train: 91.95%, Valid: 76.27% Test: 70.27%\n",
      "Run: 03, Epoch: 115, Loss: 0.4223, Train: 91.95%, Valid: 76.27% Test: 72.97%\n",
      "Run: 03, Epoch: 116, Loss: 0.5087, Train: 90.80%, Valid: 72.88% Test: 72.97%\n",
      "Run: 03, Epoch: 117, Loss: 0.4657, Train: 86.21%, Valid: 66.10% Test: 72.97%\n",
      "Run: 03, Epoch: 118, Loss: 0.4835, Train: 83.91%, Valid: 67.80% Test: 75.68%\n",
      "Run: 03, Epoch: 119, Loss: 0.4447, Train: 83.91%, Valid: 66.10% Test: 72.97%\n",
      "Run: 03, Epoch: 120, Loss: 0.4649, Train: 86.21%, Valid: 64.41% Test: 64.86%\n",
      "Run: 03, Epoch: 121, Loss: 0.4370, Train: 86.21%, Valid: 64.41% Test: 64.86%\n",
      "Run: 03, Epoch: 122, Loss: 0.4529, Train: 83.91%, Valid: 55.93% Test: 62.16%\n",
      "Run: 03, Epoch: 123, Loss: 0.4008, Train: 65.52%, Valid: 54.24% Test: 54.05%\n",
      "Run: 03, Epoch: 124, Loss: 0.4172, Train: 58.62%, Valid: 54.24% Test: 48.65%\n",
      "Run: 03, Epoch: 125, Loss: 0.4910, Train: 63.22%, Valid: 59.32% Test: 48.65%\n",
      "Run: 03, Epoch: 126, Loss: 0.5506, Train: 80.46%, Valid: 66.10% Test: 64.86%\n",
      "Run: 03, Epoch: 127, Loss: 0.4094, Train: 96.55%, Valid: 83.05% Test: 72.97%\n",
      "Run: 03, Epoch: 128, Loss: 0.4879, Train: 97.70%, Valid: 81.36% Test: 78.38%\n",
      "Run: 03, Epoch: 129, Loss: 0.4532, Train: 97.70%, Valid: 81.36% Test: 72.97%\n",
      "Run: 03, Epoch: 130, Loss: 0.4392, Train: 95.40%, Valid: 81.36% Test: 75.68%\n",
      "Run: 03, Epoch: 131, Loss: 0.4097, Train: 94.25%, Valid: 81.36% Test: 70.27%\n",
      "Run: 03, Epoch: 132, Loss: 0.4332, Train: 91.95%, Valid: 79.66% Test: 75.68%\n",
      "Run: 03, Epoch: 133, Loss: 0.4407, Train: 94.25%, Valid: 77.97% Test: 70.27%\n",
      "Run: 03, Epoch: 134, Loss: 0.3991, Train: 91.95%, Valid: 74.58% Test: 70.27%\n",
      "Run: 03, Epoch: 135, Loss: 0.3793, Train: 91.95%, Valid: 71.19% Test: 70.27%\n",
      "Run: 03, Epoch: 136, Loss: 0.3882, Train: 91.95%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 137, Loss: 0.3908, Train: 83.91%, Valid: 61.02% Test: 62.16%\n",
      "Run: 03, Epoch: 138, Loss: 0.4466, Train: 68.97%, Valid: 55.93% Test: 56.76%\n",
      "Run: 03, Epoch: 139, Loss: 0.3816, Train: 64.37%, Valid: 52.54% Test: 51.35%\n",
      "Run: 03, Epoch: 140, Loss: 0.3946, Train: 58.62%, Valid: 54.24% Test: 51.35%\n",
      "Run: 03, Epoch: 141, Loss: 0.4133, Train: 64.37%, Valid: 55.93% Test: 54.05%\n",
      "Run: 03, Epoch: 142, Loss: 0.4205, Train: 71.26%, Valid: 57.63% Test: 56.76%\n",
      "Run: 03, Epoch: 143, Loss: 0.4167, Train: 91.95%, Valid: 67.80% Test: 67.57%\n",
      "Run: 03, Epoch: 144, Loss: 0.3624, Train: 94.25%, Valid: 71.19% Test: 75.68%\n",
      "Run: 03, Epoch: 145, Loss: 0.3987, Train: 94.25%, Valid: 81.36% Test: 81.08%\n",
      "Run: 03, Epoch: 146, Loss: 0.3962, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 03, Epoch: 147, Loss: 0.3950, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 03, Epoch: 148, Loss: 0.4524, Train: 91.95%, Valid: 81.36% Test: 70.27%\n",
      "Run: 03, Epoch: 149, Loss: 0.3864, Train: 90.80%, Valid: 69.49% Test: 54.05%\n",
      "Run: 03, Epoch: 150, Loss: 0.3213, Train: 78.16%, Valid: 61.02% Test: 54.05%\n",
      "Run: 03, Epoch: 151, Loss: 0.3812, Train: 70.11%, Valid: 55.93% Test: 48.65%\n",
      "Run: 03, Epoch: 152, Loss: 0.4463, Train: 72.41%, Valid: 57.63% Test: 54.05%\n",
      "Run: 03, Epoch: 153, Loss: 0.4123, Train: 74.71%, Valid: 62.71% Test: 56.76%\n",
      "Run: 03, Epoch: 154, Loss: 0.3489, Train: 83.91%, Valid: 69.49% Test: 62.16%\n",
      "Run: 03, Epoch: 155, Loss: 0.4246, Train: 88.51%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 156, Loss: 0.3526, Train: 91.95%, Valid: 76.27% Test: 70.27%\n",
      "Run: 03, Epoch: 157, Loss: 0.4064, Train: 96.55%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 158, Loss: 0.2956, Train: 96.55%, Valid: 77.97% Test: 75.68%\n",
      "Run: 03, Epoch: 159, Loss: 0.3931, Train: 97.70%, Valid: 79.66% Test: 75.68%\n",
      "Run: 03, Epoch: 160, Loss: 0.3103, Train: 97.70%, Valid: 77.97% Test: 83.78%\n",
      "Run: 03, Epoch: 161, Loss: 0.2860, Train: 91.95%, Valid: 77.97% Test: 86.49%\n",
      "Run: 03, Epoch: 162, Loss: 0.4124, Train: 94.25%, Valid: 76.27% Test: 86.49%\n",
      "Run: 03, Epoch: 163, Loss: 0.3787, Train: 94.25%, Valid: 74.58% Test: 86.49%\n",
      "Run: 03, Epoch: 164, Loss: 0.4019, Train: 93.10%, Valid: 76.27% Test: 86.49%\n",
      "Run: 03, Epoch: 165, Loss: 0.3126, Train: 94.25%, Valid: 76.27% Test: 86.49%\n",
      "Run: 03, Epoch: 166, Loss: 0.3258, Train: 95.40%, Valid: 77.97% Test: 86.49%\n",
      "Run: 03, Epoch: 167, Loss: 0.2933, Train: 96.55%, Valid: 77.97% Test: 83.78%\n",
      "Run: 03, Epoch: 168, Loss: 0.2982, Train: 96.55%, Valid: 77.97% Test: 78.38%\n",
      "Run: 03, Epoch: 169, Loss: 0.4573, Train: 97.70%, Valid: 76.27% Test: 75.68%\n",
      "Run: 03, Epoch: 170, Loss: 0.3778, Train: 97.70%, Valid: 77.97% Test: 78.38%\n",
      "Run: 03, Epoch: 171, Loss: 0.3992, Train: 96.55%, Valid: 81.36% Test: 75.68%\n",
      "Run: 03, Epoch: 172, Loss: 0.3392, Train: 96.55%, Valid: 83.05% Test: 72.97%\n",
      "Run: 03, Epoch: 173, Loss: 0.2764, Train: 96.55%, Valid: 79.66% Test: 70.27%\n",
      "Run: 03, Epoch: 174, Loss: 0.3496, Train: 96.55%, Valid: 76.27% Test: 67.57%\n",
      "Run: 03, Epoch: 175, Loss: 0.3233, Train: 90.80%, Valid: 71.19% Test: 62.16%\n",
      "Run: 03, Epoch: 176, Loss: 0.3324, Train: 85.06%, Valid: 71.19% Test: 62.16%\n",
      "Run: 03, Epoch: 177, Loss: 0.3086, Train: 82.76%, Valid: 71.19% Test: 62.16%\n",
      "Run: 03, Epoch: 178, Loss: 0.3191, Train: 85.06%, Valid: 71.19% Test: 62.16%\n",
      "Run: 03, Epoch: 179, Loss: 0.3413, Train: 83.91%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 180, Loss: 0.2848, Train: 86.21%, Valid: 72.88% Test: 67.57%\n",
      "Run: 03, Epoch: 181, Loss: 0.4062, Train: 91.95%, Valid: 74.58% Test: 67.57%\n",
      "Run: 03, Epoch: 182, Loss: 0.3057, Train: 91.95%, Valid: 81.36% Test: 70.27%\n",
      "Run: 03, Epoch: 183, Loss: 0.3419, Train: 93.10%, Valid: 81.36% Test: 70.27%\n",
      "Run: 03, Epoch: 184, Loss: 0.2636, Train: 94.25%, Valid: 77.97% Test: 72.97%\n",
      "Run: 03, Epoch: 185, Loss: 0.3283, Train: 95.40%, Valid: 81.36% Test: 75.68%\n",
      "Run: 03, Epoch: 186, Loss: 0.2841, Train: 97.70%, Valid: 79.66% Test: 78.38%\n",
      "Run: 03, Epoch: 187, Loss: 0.3066, Train: 98.85%, Valid: 81.36% Test: 78.38%\n",
      "Run: 03, Epoch: 188, Loss: 0.3258, Train: 98.85%, Valid: 86.44% Test: 81.08%\n",
      "Run: 03, Epoch: 189, Loss: 0.3214, Train: 100.00%, Valid: 86.44% Test: 78.38%\n",
      "Run: 03, Epoch: 190, Loss: 0.3127, Train: 100.00%, Valid: 88.14% Test: 78.38%\n",
      "Run: 03, Epoch: 191, Loss: 0.2755, Train: 100.00%, Valid: 88.14% Test: 81.08%\n",
      "Run: 03, Epoch: 192, Loss: 0.3021, Train: 100.00%, Valid: 86.44% Test: 86.49%\n",
      "Run: 03, Epoch: 193, Loss: 0.3320, Train: 97.70%, Valid: 88.14% Test: 83.78%\n",
      "Run: 03, Epoch: 194, Loss: 0.3051, Train: 97.70%, Valid: 88.14% Test: 83.78%\n",
      "Run: 03, Epoch: 195, Loss: 0.2866, Train: 96.55%, Valid: 84.75% Test: 83.78%\n",
      "Run: 03, Epoch: 196, Loss: 0.2625, Train: 93.10%, Valid: 79.66% Test: 78.38%\n",
      "Run: 03, Epoch: 197, Loss: 0.3400, Train: 89.66%, Valid: 69.49% Test: 72.97%\n",
      "Run: 03, Epoch: 198, Loss: 0.3986, Train: 93.10%, Valid: 74.58% Test: 72.97%\n",
      "Run: 03, Epoch: 199, Loss: 0.2318, Train: 94.25%, Valid: 79.66% Test: 72.97%\n",
      "Run: 03, Epoch: 200, Loss: 0.2522, Train: 94.25%, Valid: 79.66% Test: 81.08%\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 88.14\n",
      "  Final Train: 94.25\n",
      "   Final Test: 86.49\n",
      "Run: 04, Epoch: 01, Loss: 1.7675, Train: 8.05%, Valid: 10.17% Test: 8.11%\n",
      "Run: 04, Epoch: 02, Loss: 1.6934, Train: 8.05%, Valid: 10.17% Test: 8.11%\n",
      "Run: 04, Epoch: 03, Loss: 1.6321, Train: 8.05%, Valid: 10.17% Test: 8.11%\n",
      "Run: 04, Epoch: 04, Loss: 1.5806, Train: 8.05%, Valid: 10.17% Test: 8.11%\n",
      "Run: 04, Epoch: 05, Loss: 1.5327, Train: 8.05%, Valid: 10.17% Test: 8.11%\n",
      "Run: 04, Epoch: 06, Loss: 1.4816, Train: 18.39%, Valid: 18.64% Test: 18.92%\n",
      "Run: 04, Epoch: 07, Loss: 1.4191, Train: 54.02%, Valid: 38.98% Test: 37.84%\n",
      "Run: 04, Epoch: 08, Loss: 1.3891, Train: 50.57%, Valid: 42.37% Test: 40.54%\n",
      "Run: 04, Epoch: 09, Loss: 1.3607, Train: 50.57%, Valid: 42.37% Test: 37.84%\n",
      "Run: 04, Epoch: 10, Loss: 1.3278, Train: 50.57%, Valid: 42.37% Test: 37.84%\n",
      "Run: 04, Epoch: 11, Loss: 1.2324, Train: 51.72%, Valid: 42.37% Test: 37.84%\n",
      "Run: 04, Epoch: 12, Loss: 1.1991, Train: 51.72%, Valid: 42.37% Test: 37.84%\n",
      "Run: 04, Epoch: 13, Loss: 1.1592, Train: 51.72%, Valid: 42.37% Test: 37.84%\n",
      "Run: 04, Epoch: 14, Loss: 1.1187, Train: 52.87%, Valid: 44.07% Test: 37.84%\n",
      "Run: 04, Epoch: 15, Loss: 1.1653, Train: 52.87%, Valid: 44.07% Test: 37.84%\n",
      "Run: 04, Epoch: 16, Loss: 1.1288, Train: 52.87%, Valid: 44.07% Test: 40.54%\n",
      "Run: 04, Epoch: 17, Loss: 1.0667, Train: 51.72%, Valid: 42.37% Test: 40.54%\n",
      "Run: 04, Epoch: 18, Loss: 0.9807, Train: 51.72%, Valid: 44.07% Test: 40.54%\n",
      "Run: 04, Epoch: 19, Loss: 1.0629, Train: 51.72%, Valid: 44.07% Test: 43.24%\n",
      "Run: 04, Epoch: 20, Loss: 1.0172, Train: 55.17%, Valid: 44.07% Test: 45.95%\n",
      "Run: 04, Epoch: 21, Loss: 0.9421, Train: 55.17%, Valid: 44.07% Test: 45.95%\n",
      "Run: 04, Epoch: 22, Loss: 0.9127, Train: 55.17%, Valid: 44.07% Test: 45.95%\n",
      "Run: 04, Epoch: 23, Loss: 0.9363, Train: 56.32%, Valid: 44.07% Test: 45.95%\n",
      "Run: 04, Epoch: 24, Loss: 0.9239, Train: 57.47%, Valid: 45.76% Test: 45.95%\n",
      "Run: 04, Epoch: 25, Loss: 0.8963, Train: 56.32%, Valid: 45.76% Test: 43.24%\n",
      "Run: 04, Epoch: 26, Loss: 0.8996, Train: 57.47%, Valid: 45.76% Test: 43.24%\n",
      "Run: 04, Epoch: 27, Loss: 0.8842, Train: 60.92%, Valid: 44.07% Test: 56.76%\n",
      "Run: 04, Epoch: 28, Loss: 0.9082, Train: 66.67%, Valid: 45.76% Test: 62.16%\n",
      "Run: 04, Epoch: 29, Loss: 0.8871, Train: 71.26%, Valid: 52.54% Test: 72.97%\n",
      "Run: 04, Epoch: 30, Loss: 0.8646, Train: 73.56%, Valid: 59.32% Test: 78.38%\n",
      "Run: 04, Epoch: 31, Loss: 0.7692, Train: 73.56%, Valid: 57.63% Test: 78.38%\n",
      "Run: 04, Epoch: 32, Loss: 0.8503, Train: 74.71%, Valid: 57.63% Test: 78.38%\n",
      "Run: 04, Epoch: 33, Loss: 0.8323, Train: 70.11%, Valid: 55.93% Test: 72.97%\n",
      "Run: 04, Epoch: 34, Loss: 0.8011, Train: 71.26%, Valid: 59.32% Test: 67.57%\n",
      "Run: 04, Epoch: 35, Loss: 0.7962, Train: 73.56%, Valid: 59.32% Test: 67.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 36, Loss: 0.8340, Train: 73.56%, Valid: 66.10% Test: 70.27%\n",
      "Run: 04, Epoch: 37, Loss: 0.7630, Train: 79.31%, Valid: 61.02% Test: 64.86%\n",
      "Run: 04, Epoch: 38, Loss: 0.7632, Train: 79.31%, Valid: 55.93% Test: 59.46%\n",
      "Run: 04, Epoch: 39, Loss: 0.8204, Train: 80.46%, Valid: 59.32% Test: 59.46%\n",
      "Run: 04, Epoch: 40, Loss: 0.6833, Train: 79.31%, Valid: 62.71% Test: 62.16%\n",
      "Run: 04, Epoch: 41, Loss: 0.7778, Train: 77.01%, Valid: 61.02% Test: 64.86%\n",
      "Run: 04, Epoch: 42, Loss: 0.8114, Train: 75.86%, Valid: 57.63% Test: 64.86%\n",
      "Run: 04, Epoch: 43, Loss: 0.7360, Train: 75.86%, Valid: 57.63% Test: 67.57%\n",
      "Run: 04, Epoch: 44, Loss: 0.6452, Train: 77.01%, Valid: 55.93% Test: 64.86%\n",
      "Run: 04, Epoch: 45, Loss: 0.7382, Train: 72.41%, Valid: 62.71% Test: 75.68%\n",
      "Run: 04, Epoch: 46, Loss: 0.7357, Train: 74.71%, Valid: 61.02% Test: 78.38%\n",
      "Run: 04, Epoch: 47, Loss: 0.7516, Train: 74.71%, Valid: 62.71% Test: 81.08%\n",
      "Run: 04, Epoch: 48, Loss: 0.7761, Train: 77.01%, Valid: 66.10% Test: 81.08%\n",
      "Run: 04, Epoch: 49, Loss: 0.6882, Train: 79.31%, Valid: 71.19% Test: 81.08%\n",
      "Run: 04, Epoch: 50, Loss: 0.7016, Train: 82.76%, Valid: 72.88% Test: 78.38%\n",
      "Run: 04, Epoch: 51, Loss: 0.6786, Train: 83.91%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 52, Loss: 0.6362, Train: 86.21%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 53, Loss: 0.7538, Train: 89.66%, Valid: 76.27% Test: 78.38%\n",
      "Run: 04, Epoch: 54, Loss: 0.6278, Train: 90.80%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 55, Loss: 0.6816, Train: 89.66%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 56, Loss: 0.7031, Train: 88.51%, Valid: 76.27% Test: 75.68%\n",
      "Run: 04, Epoch: 57, Loss: 0.6287, Train: 87.36%, Valid: 76.27% Test: 75.68%\n",
      "Run: 04, Epoch: 58, Loss: 0.6803, Train: 83.91%, Valid: 79.66% Test: 78.38%\n",
      "Run: 04, Epoch: 59, Loss: 0.6417, Train: 83.91%, Valid: 77.97% Test: 75.68%\n",
      "Run: 04, Epoch: 60, Loss: 0.6653, Train: 86.21%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 61, Loss: 0.6275, Train: 89.66%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 62, Loss: 0.6273, Train: 90.80%, Valid: 76.27% Test: 83.78%\n",
      "Run: 04, Epoch: 63, Loss: 0.6671, Train: 93.10%, Valid: 76.27% Test: 83.78%\n",
      "Run: 04, Epoch: 64, Loss: 0.5910, Train: 93.10%, Valid: 76.27% Test: 81.08%\n",
      "Run: 04, Epoch: 65, Loss: 0.5819, Train: 89.66%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 66, Loss: 0.5715, Train: 86.21%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 67, Loss: 0.5842, Train: 86.21%, Valid: 79.66% Test: 72.97%\n",
      "Run: 04, Epoch: 68, Loss: 0.6348, Train: 87.36%, Valid: 79.66% Test: 78.38%\n",
      "Run: 04, Epoch: 69, Loss: 0.5758, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 70, Loss: 0.6495, Train: 94.25%, Valid: 81.36% Test: 83.78%\n",
      "Run: 04, Epoch: 71, Loss: 0.5811, Train: 93.10%, Valid: 74.58% Test: 83.78%\n",
      "Run: 04, Epoch: 72, Loss: 0.6369, Train: 94.25%, Valid: 77.97% Test: 83.78%\n",
      "Run: 04, Epoch: 73, Loss: 0.5472, Train: 94.25%, Valid: 77.97% Test: 83.78%\n",
      "Run: 04, Epoch: 74, Loss: 0.5286, Train: 91.95%, Valid: 79.66% Test: 83.78%\n",
      "Run: 04, Epoch: 75, Loss: 0.6071, Train: 94.25%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 76, Loss: 0.5827, Train: 90.80%, Valid: 79.66% Test: 78.38%\n",
      "Run: 04, Epoch: 77, Loss: 0.5419, Train: 88.51%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 78, Loss: 0.6109, Train: 88.51%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 79, Loss: 0.5325, Train: 83.91%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 80, Loss: 0.5156, Train: 85.06%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 81, Loss: 0.5402, Train: 85.06%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 82, Loss: 0.5209, Train: 87.36%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 83, Loss: 0.4858, Train: 86.21%, Valid: 76.27% Test: 70.27%\n",
      "Run: 04, Epoch: 84, Loss: 0.4854, Train: 86.21%, Valid: 74.58% Test: 72.97%\n",
      "Run: 04, Epoch: 85, Loss: 0.5730, Train: 89.66%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 86, Loss: 0.5627, Train: 94.25%, Valid: 79.66% Test: 78.38%\n",
      "Run: 04, Epoch: 87, Loss: 0.5135, Train: 96.55%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 88, Loss: 0.5079, Train: 97.70%, Valid: 76.27% Test: 83.78%\n",
      "Run: 04, Epoch: 89, Loss: 0.4742, Train: 97.70%, Valid: 71.19% Test: 83.78%\n",
      "Run: 04, Epoch: 90, Loss: 0.4872, Train: 94.25%, Valid: 72.88% Test: 83.78%\n",
      "Run: 04, Epoch: 91, Loss: 0.5116, Train: 94.25%, Valid: 71.19% Test: 83.78%\n",
      "Run: 04, Epoch: 92, Loss: 0.5653, Train: 91.95%, Valid: 67.80% Test: 78.38%\n",
      "Run: 04, Epoch: 93, Loss: 0.4840, Train: 88.51%, Valid: 67.80% Test: 78.38%\n",
      "Run: 04, Epoch: 94, Loss: 0.4527, Train: 90.80%, Valid: 66.10% Test: 78.38%\n",
      "Run: 04, Epoch: 95, Loss: 0.4681, Train: 91.95%, Valid: 62.71% Test: 83.78%\n",
      "Run: 04, Epoch: 96, Loss: 0.5601, Train: 96.55%, Valid: 74.58% Test: 83.78%\n",
      "Run: 04, Epoch: 97, Loss: 0.4697, Train: 95.40%, Valid: 79.66% Test: 83.78%\n",
      "Run: 04, Epoch: 98, Loss: 0.4715, Train: 94.25%, Valid: 79.66% Test: 83.78%\n",
      "Run: 04, Epoch: 99, Loss: 0.4948, Train: 94.25%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 100, Loss: 0.5245, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 101, Loss: 0.5033, Train: 93.10%, Valid: 79.66% Test: 83.78%\n",
      "Run: 04, Epoch: 102, Loss: 0.4251, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 103, Loss: 0.4149, Train: 93.10%, Valid: 83.05% Test: 78.38%\n",
      "Run: 04, Epoch: 104, Loss: 0.4568, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 105, Loss: 0.5274, Train: 95.40%, Valid: 83.05% Test: 81.08%\n",
      "Run: 04, Epoch: 106, Loss: 0.4482, Train: 95.40%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 107, Loss: 0.4493, Train: 96.55%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 108, Loss: 0.4622, Train: 91.95%, Valid: 76.27% Test: 70.27%\n",
      "Run: 04, Epoch: 109, Loss: 0.4618, Train: 90.80%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 110, Loss: 0.4239, Train: 93.10%, Valid: 76.27% Test: 70.27%\n",
      "Run: 04, Epoch: 111, Loss: 0.5265, Train: 95.40%, Valid: 76.27% Test: 78.38%\n",
      "Run: 04, Epoch: 112, Loss: 0.4387, Train: 93.10%, Valid: 76.27% Test: 75.68%\n",
      "Run: 04, Epoch: 113, Loss: 0.4308, Train: 94.25%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 114, Loss: 0.4531, Train: 93.10%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 115, Loss: 0.4354, Train: 94.25%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 116, Loss: 0.4130, Train: 94.25%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 117, Loss: 0.4565, Train: 94.25%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 118, Loss: 0.5250, Train: 93.10%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 119, Loss: 0.4740, Train: 93.10%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 120, Loss: 0.4016, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 121, Loss: 0.5190, Train: 93.10%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 122, Loss: 0.4503, Train: 93.10%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 123, Loss: 0.4794, Train: 94.25%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 124, Loss: 0.5118, Train: 93.10%, Valid: 76.27% Test: 81.08%\n",
      "Run: 04, Epoch: 125, Loss: 0.4713, Train: 93.10%, Valid: 76.27% Test: 78.38%\n",
      "Run: 04, Epoch: 126, Loss: 0.4288, Train: 83.91%, Valid: 71.19% Test: 70.27%\n",
      "Run: 04, Epoch: 127, Loss: 0.4495, Train: 68.97%, Valid: 57.63% Test: 56.76%\n",
      "Run: 04, Epoch: 128, Loss: 0.4254, Train: 72.41%, Valid: 62.71% Test: 59.46%\n",
      "Run: 04, Epoch: 129, Loss: 0.4816, Train: 80.46%, Valid: 69.49% Test: 67.57%\n",
      "Run: 04, Epoch: 130, Loss: 0.3939, Train: 95.40%, Valid: 81.36% Test: 83.78%\n",
      "Run: 04, Epoch: 131, Loss: 0.4379, Train: 98.85%, Valid: 72.88% Test: 86.49%\n",
      "Run: 04, Epoch: 132, Loss: 0.3681, Train: 96.55%, Valid: 72.88% Test: 83.78%\n",
      "Run: 04, Epoch: 133, Loss: 0.4356, Train: 95.40%, Valid: 76.27% Test: 81.08%\n",
      "Run: 04, Epoch: 134, Loss: 0.3664, Train: 95.40%, Valid: 76.27% Test: 75.68%\n",
      "Run: 04, Epoch: 135, Loss: 0.4850, Train: 95.40%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 136, Loss: 0.3132, Train: 94.25%, Valid: 81.36% Test: 75.68%\n",
      "Run: 04, Epoch: 137, Loss: 0.4155, Train: 95.40%, Valid: 81.36% Test: 75.68%\n",
      "Run: 04, Epoch: 138, Loss: 0.3934, Train: 91.95%, Valid: 81.36% Test: 70.27%\n",
      "Run: 04, Epoch: 139, Loss: 0.3832, Train: 89.66%, Valid: 79.66% Test: 70.27%\n",
      "Run: 04, Epoch: 140, Loss: 0.3537, Train: 91.95%, Valid: 77.97% Test: 72.97%\n",
      "Run: 04, Epoch: 141, Loss: 0.3897, Train: 91.95%, Valid: 79.66% Test: 78.38%\n",
      "Run: 04, Epoch: 142, Loss: 0.3825, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 04, Epoch: 143, Loss: 0.3950, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 144, Loss: 0.4440, Train: 94.25%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 145, Loss: 0.3983, Train: 95.40%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 146, Loss: 0.4046, Train: 95.40%, Valid: 79.66% Test: 83.78%\n",
      "Run: 04, Epoch: 147, Loss: 0.4452, Train: 95.40%, Valid: 77.97% Test: 83.78%\n",
      "Run: 04, Epoch: 148, Loss: 0.3155, Train: 95.40%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 149, Loss: 0.4311, Train: 81.61%, Valid: 72.88% Test: 70.27%\n",
      "Run: 04, Epoch: 150, Loss: 0.3335, Train: 71.26%, Valid: 64.41% Test: 59.46%\n",
      "Run: 04, Epoch: 151, Loss: 0.3746, Train: 72.41%, Valid: 66.10% Test: 62.16%\n",
      "Run: 04, Epoch: 152, Loss: 0.3992, Train: 86.21%, Valid: 74.58% Test: 70.27%\n",
      "Run: 04, Epoch: 153, Loss: 0.3791, Train: 95.40%, Valid: 76.27% Test: 81.08%\n",
      "Run: 04, Epoch: 154, Loss: 0.3105, Train: 97.70%, Valid: 79.66% Test: 83.78%\n",
      "Run: 04, Epoch: 155, Loss: 0.3731, Train: 97.70%, Valid: 77.97% Test: 83.78%\n",
      "Run: 04, Epoch: 156, Loss: 0.4640, Train: 98.85%, Valid: 76.27% Test: 81.08%\n",
      "Run: 04, Epoch: 157, Loss: 0.4039, Train: 95.40%, Valid: 72.88% Test: 81.08%\n",
      "Run: 04, Epoch: 158, Loss: 0.3659, Train: 94.25%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 159, Loss: 0.4145, Train: 94.25%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 160, Loss: 0.3284, Train: 95.40%, Valid: 76.27% Test: 72.97%\n",
      "Run: 04, Epoch: 161, Loss: 0.4104, Train: 96.55%, Valid: 76.27% Test: 75.68%\n",
      "Run: 04, Epoch: 162, Loss: 0.4366, Train: 97.70%, Valid: 76.27% Test: 81.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 04, Epoch: 163, Loss: 0.3666, Train: 97.70%, Valid: 74.58% Test: 78.38%\n",
      "Run: 04, Epoch: 164, Loss: 0.4707, Train: 94.25%, Valid: 76.27% Test: 81.08%\n",
      "Run: 04, Epoch: 165, Loss: 0.2931, Train: 93.10%, Valid: 76.27% Test: 83.78%\n",
      "Run: 04, Epoch: 166, Loss: 0.3319, Train: 91.95%, Valid: 76.27% Test: 83.78%\n",
      "Run: 04, Epoch: 167, Loss: 0.4298, Train: 94.25%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 168, Loss: 0.3829, Train: 94.25%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 169, Loss: 0.3012, Train: 96.55%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 170, Loss: 0.3617, Train: 96.55%, Valid: 81.36% Test: 83.78%\n",
      "Run: 04, Epoch: 171, Loss: 0.3323, Train: 96.55%, Valid: 77.97% Test: 83.78%\n",
      "Run: 04, Epoch: 172, Loss: 0.3218, Train: 96.55%, Valid: 72.88% Test: 83.78%\n",
      "Run: 04, Epoch: 173, Loss: 0.3289, Train: 98.85%, Valid: 74.58% Test: 83.78%\n",
      "Run: 04, Epoch: 174, Loss: 0.3999, Train: 91.95%, Valid: 76.27% Test: 83.78%\n",
      "Run: 04, Epoch: 175, Loss: 0.3623, Train: 86.21%, Valid: 71.19% Test: 81.08%\n",
      "Run: 04, Epoch: 176, Loss: 0.2853, Train: 86.21%, Valid: 69.49% Test: 75.68%\n",
      "Run: 04, Epoch: 177, Loss: 0.4488, Train: 91.95%, Valid: 74.58% Test: 75.68%\n",
      "Run: 04, Epoch: 178, Loss: 0.3573, Train: 97.70%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 179, Loss: 0.3905, Train: 95.40%, Valid: 72.88% Test: 78.38%\n",
      "Run: 04, Epoch: 180, Loss: 0.2787, Train: 95.40%, Valid: 72.88% Test: 78.38%\n",
      "Run: 04, Epoch: 181, Loss: 0.3516, Train: 95.40%, Valid: 74.58% Test: 78.38%\n",
      "Run: 04, Epoch: 182, Loss: 0.3231, Train: 96.55%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 183, Loss: 0.3121, Train: 97.70%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 184, Loss: 0.3045, Train: 97.70%, Valid: 79.66% Test: 78.38%\n",
      "Run: 04, Epoch: 185, Loss: 0.3496, Train: 97.70%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 186, Loss: 0.2930, Train: 96.55%, Valid: 76.27% Test: 83.78%\n",
      "Run: 04, Epoch: 187, Loss: 0.3769, Train: 96.55%, Valid: 76.27% Test: 83.78%\n",
      "Run: 04, Epoch: 188, Loss: 0.3469, Train: 96.55%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 189, Loss: 0.2801, Train: 95.40%, Valid: 77.97% Test: 81.08%\n",
      "Run: 04, Epoch: 190, Loss: 0.2756, Train: 95.40%, Valid: 81.36% Test: 83.78%\n",
      "Run: 04, Epoch: 191, Loss: 0.2688, Train: 95.40%, Valid: 79.66% Test: 83.78%\n",
      "Run: 04, Epoch: 192, Loss: 0.3092, Train: 96.55%, Valid: 79.66% Test: 81.08%\n",
      "Run: 04, Epoch: 193, Loss: 0.3111, Train: 95.40%, Valid: 76.27% Test: 81.08%\n",
      "Run: 04, Epoch: 194, Loss: 0.3339, Train: 96.55%, Valid: 72.88% Test: 81.08%\n",
      "Run: 04, Epoch: 195, Loss: 0.2897, Train: 95.40%, Valid: 76.27% Test: 78.38%\n",
      "Run: 04, Epoch: 196, Loss: 0.3319, Train: 96.55%, Valid: 76.27% Test: 78.38%\n",
      "Run: 04, Epoch: 197, Loss: 0.2731, Train: 97.70%, Valid: 76.27% Test: 78.38%\n",
      "Run: 04, Epoch: 198, Loss: 0.3312, Train: 97.70%, Valid: 77.97% Test: 78.38%\n",
      "Run: 04, Epoch: 199, Loss: 0.3157, Train: 97.70%, Valid: 81.36% Test: 81.08%\n",
      "Run: 04, Epoch: 200, Loss: 0.3302, Train: 95.40%, Valid: 81.36% Test: 81.08%\n",
      "Run 04:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 83.05\n",
      "  Final Train: 93.10\n",
      "   Final Test: 78.38\n",
      "Run: 05, Epoch: 01, Loss: 1.7045, Train: 4.60%, Valid: 15.25% Test: 8.11%\n",
      "Run: 05, Epoch: 02, Loss: 1.6309, Train: 4.60%, Valid: 15.25% Test: 8.11%\n",
      "Run: 05, Epoch: 03, Loss: 1.5893, Train: 26.44%, Valid: 38.98% Test: 40.54%\n",
      "Run: 05, Epoch: 04, Loss: 1.5589, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 05, Loss: 1.4752, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 06, Loss: 1.4542, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 07, Loss: 1.3985, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 08, Loss: 1.3446, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 09, Loss: 1.3129, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 10, Loss: 1.2839, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 11, Loss: 1.2314, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 12, Loss: 1.2098, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 13, Loss: 1.1910, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 14, Loss: 1.1471, Train: 44.83%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 15, Loss: 1.1148, Train: 44.83%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 16, Loss: 1.0659, Train: 45.98%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 17, Loss: 1.0662, Train: 47.13%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 18, Loss: 1.0479, Train: 49.43%, Valid: 47.46% Test: 45.95%\n",
      "Run: 05, Epoch: 19, Loss: 1.0076, Train: 50.57%, Valid: 47.46% Test: 48.65%\n",
      "Run: 05, Epoch: 20, Loss: 1.0027, Train: 54.02%, Valid: 52.54% Test: 62.16%\n",
      "Run: 05, Epoch: 21, Loss: 0.9711, Train: 62.07%, Valid: 57.63% Test: 62.16%\n",
      "Run: 05, Epoch: 22, Loss: 0.9768, Train: 65.52%, Valid: 61.02% Test: 62.16%\n",
      "Run: 05, Epoch: 23, Loss: 0.9523, Train: 67.82%, Valid: 59.32% Test: 62.16%\n",
      "Run: 05, Epoch: 24, Loss: 0.9113, Train: 66.67%, Valid: 55.93% Test: 62.16%\n",
      "Run: 05, Epoch: 25, Loss: 0.9106, Train: 66.67%, Valid: 55.93% Test: 62.16%\n",
      "Run: 05, Epoch: 26, Loss: 0.8562, Train: 65.52%, Valid: 55.93% Test: 62.16%\n",
      "Run: 05, Epoch: 27, Loss: 0.8952, Train: 65.52%, Valid: 57.63% Test: 62.16%\n",
      "Run: 05, Epoch: 28, Loss: 0.8468, Train: 67.82%, Valid: 59.32% Test: 62.16%\n",
      "Run: 05, Epoch: 29, Loss: 0.8457, Train: 68.97%, Valid: 64.41% Test: 62.16%\n",
      "Run: 05, Epoch: 30, Loss: 0.8423, Train: 74.71%, Valid: 62.71% Test: 64.86%\n",
      "Run: 05, Epoch: 31, Loss: 0.8443, Train: 77.01%, Valid: 62.71% Test: 67.57%\n",
      "Run: 05, Epoch: 32, Loss: 0.8363, Train: 75.86%, Valid: 61.02% Test: 67.57%\n",
      "Run: 05, Epoch: 33, Loss: 0.8020, Train: 75.86%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 34, Loss: 0.8153, Train: 77.01%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 35, Loss: 0.7896, Train: 80.46%, Valid: 66.10% Test: 70.27%\n",
      "Run: 05, Epoch: 36, Loss: 0.8399, Train: 80.46%, Valid: 66.10% Test: 70.27%\n",
      "Run: 05, Epoch: 37, Loss: 0.7627, Train: 80.46%, Valid: 66.10% Test: 70.27%\n",
      "Run: 05, Epoch: 38, Loss: 0.7380, Train: 81.61%, Valid: 62.71% Test: 70.27%\n",
      "Run: 05, Epoch: 39, Loss: 0.7937, Train: 80.46%, Valid: 62.71% Test: 70.27%\n",
      "Run: 05, Epoch: 40, Loss: 0.7644, Train: 79.31%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 41, Loss: 0.7661, Train: 79.31%, Valid: 64.41% Test: 67.57%\n",
      "Run: 05, Epoch: 42, Loss: 0.7464, Train: 77.01%, Valid: 64.41% Test: 64.86%\n",
      "Run: 05, Epoch: 43, Loss: 0.7342, Train: 77.01%, Valid: 66.10% Test: 64.86%\n",
      "Run: 05, Epoch: 44, Loss: 0.7384, Train: 80.46%, Valid: 66.10% Test: 67.57%\n",
      "Run: 05, Epoch: 45, Loss: 0.7255, Train: 81.61%, Valid: 66.10% Test: 67.57%\n",
      "Run: 05, Epoch: 46, Loss: 0.7748, Train: 85.06%, Valid: 67.80% Test: 67.57%\n",
      "Run: 05, Epoch: 47, Loss: 0.6936, Train: 82.76%, Valid: 67.80% Test: 70.27%\n",
      "Run: 05, Epoch: 48, Loss: 0.7079, Train: 85.06%, Valid: 69.49% Test: 72.97%\n",
      "Run: 05, Epoch: 49, Loss: 0.7180, Train: 83.91%, Valid: 69.49% Test: 72.97%\n",
      "Run: 05, Epoch: 50, Loss: 0.7086, Train: 85.06%, Valid: 69.49% Test: 72.97%\n",
      "Run: 05, Epoch: 51, Loss: 0.7230, Train: 83.91%, Valid: 67.80% Test: 72.97%\n",
      "Run: 05, Epoch: 52, Loss: 0.6764, Train: 83.91%, Valid: 66.10% Test: 67.57%\n",
      "Run: 05, Epoch: 53, Loss: 0.7274, Train: 85.06%, Valid: 66.10% Test: 67.57%\n",
      "Run: 05, Epoch: 54, Loss: 0.6760, Train: 82.76%, Valid: 67.80% Test: 70.27%\n",
      "Run: 05, Epoch: 55, Loss: 0.6684, Train: 80.46%, Valid: 67.80% Test: 70.27%\n",
      "Run: 05, Epoch: 56, Loss: 0.6698, Train: 80.46%, Valid: 69.49% Test: 67.57%\n",
      "Run: 05, Epoch: 57, Loss: 0.7111, Train: 82.76%, Valid: 67.80% Test: 67.57%\n",
      "Run: 05, Epoch: 58, Loss: 0.6713, Train: 86.21%, Valid: 66.10% Test: 72.97%\n",
      "Run: 05, Epoch: 59, Loss: 0.7141, Train: 87.36%, Valid: 64.41% Test: 72.97%\n",
      "Run: 05, Epoch: 60, Loss: 0.6860, Train: 83.91%, Valid: 61.02% Test: 72.97%\n",
      "Run: 05, Epoch: 61, Loss: 0.6688, Train: 81.61%, Valid: 59.32% Test: 64.86%\n",
      "Run: 05, Epoch: 62, Loss: 0.6640, Train: 74.71%, Valid: 57.63% Test: 62.16%\n",
      "Run: 05, Epoch: 63, Loss: 0.6467, Train: 78.16%, Valid: 55.93% Test: 64.86%\n",
      "Run: 05, Epoch: 64, Loss: 0.6723, Train: 80.46%, Valid: 62.71% Test: 70.27%\n",
      "Run: 05, Epoch: 65, Loss: 0.6955, Train: 83.91%, Valid: 67.80% Test: 70.27%\n",
      "Run: 05, Epoch: 66, Loss: 0.6503, Train: 83.91%, Valid: 66.10% Test: 67.57%\n",
      "Run: 05, Epoch: 67, Loss: 0.6398, Train: 83.91%, Valid: 64.41% Test: 70.27%\n",
      "Run: 05, Epoch: 68, Loss: 0.6008, Train: 80.46%, Valid: 66.10% Test: 72.97%\n",
      "Run: 05, Epoch: 69, Loss: 0.5987, Train: 83.91%, Valid: 66.10% Test: 72.97%\n",
      "Run: 05, Epoch: 70, Loss: 0.5562, Train: 86.21%, Valid: 66.10% Test: 72.97%\n",
      "Run: 05, Epoch: 71, Loss: 0.6050, Train: 86.21%, Valid: 67.80% Test: 75.68%\n",
      "Run: 05, Epoch: 72, Loss: 0.6046, Train: 89.66%, Valid: 67.80% Test: 75.68%\n",
      "Run: 05, Epoch: 73, Loss: 0.5794, Train: 90.80%, Valid: 67.80% Test: 78.38%\n",
      "Run: 05, Epoch: 74, Loss: 0.6134, Train: 89.66%, Valid: 71.19% Test: 81.08%\n",
      "Run: 05, Epoch: 75, Loss: 0.5944, Train: 90.80%, Valid: 69.49% Test: 78.38%\n",
      "Run: 05, Epoch: 76, Loss: 0.5702, Train: 87.36%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 77, Loss: 0.5896, Train: 86.21%, Valid: 66.10% Test: 75.68%\n",
      "Run: 05, Epoch: 78, Loss: 0.5781, Train: 85.06%, Valid: 62.71% Test: 72.97%\n",
      "Run: 05, Epoch: 79, Loss: 0.5743, Train: 81.61%, Valid: 64.41% Test: 72.97%\n",
      "Run: 05, Epoch: 80, Loss: 0.5843, Train: 83.91%, Valid: 66.10% Test: 70.27%\n",
      "Run: 05, Epoch: 81, Loss: 0.5689, Train: 85.06%, Valid: 67.80% Test: 67.57%\n",
      "Run: 05, Epoch: 82, Loss: 0.5813, Train: 87.36%, Valid: 69.49% Test: 70.27%\n",
      "Run: 05, Epoch: 83, Loss: 0.5833, Train: 88.51%, Valid: 69.49% Test: 72.97%\n",
      "Run: 05, Epoch: 84, Loss: 0.5698, Train: 87.36%, Valid: 69.49% Test: 72.97%\n",
      "Run: 05, Epoch: 85, Loss: 0.5560, Train: 87.36%, Valid: 69.49% Test: 72.97%\n",
      "Run: 05, Epoch: 86, Loss: 0.5293, Train: 87.36%, Valid: 69.49% Test: 72.97%\n",
      "Run: 05, Epoch: 87, Loss: 0.5339, Train: 83.91%, Valid: 64.41% Test: 72.97%\n",
      "Run: 05, Epoch: 88, Loss: 0.5961, Train: 83.91%, Valid: 64.41% Test: 70.27%\n",
      "Run: 05, Epoch: 89, Loss: 0.5526, Train: 80.46%, Valid: 64.41% Test: 70.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 05, Epoch: 90, Loss: 0.5536, Train: 81.61%, Valid: 64.41% Test: 72.97%\n",
      "Run: 05, Epoch: 91, Loss: 0.5260, Train: 82.76%, Valid: 66.10% Test: 75.68%\n",
      "Run: 05, Epoch: 92, Loss: 0.5446, Train: 85.06%, Valid: 67.80% Test: 78.38%\n",
      "Run: 05, Epoch: 93, Loss: 0.5640, Train: 89.66%, Valid: 67.80% Test: 75.68%\n",
      "Run: 05, Epoch: 94, Loss: 0.5076, Train: 91.95%, Valid: 67.80% Test: 78.38%\n",
      "Run: 05, Epoch: 95, Loss: 0.4925, Train: 90.80%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 96, Loss: 0.5801, Train: 90.80%, Valid: 66.10% Test: 75.68%\n",
      "Run: 05, Epoch: 97, Loss: 0.4851, Train: 91.95%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 98, Loss: 0.5055, Train: 93.10%, Valid: 71.19% Test: 78.38%\n",
      "Run: 05, Epoch: 99, Loss: 0.4959, Train: 90.80%, Valid: 71.19% Test: 83.78%\n",
      "Run: 05, Epoch: 100, Loss: 0.5426, Train: 93.10%, Valid: 74.58% Test: 81.08%\n",
      "Run: 05, Epoch: 101, Loss: 0.5582, Train: 91.95%, Valid: 74.58% Test: 81.08%\n",
      "Run: 05, Epoch: 102, Loss: 0.5052, Train: 93.10%, Valid: 72.88% Test: 83.78%\n",
      "Run: 05, Epoch: 103, Loss: 0.5278, Train: 93.10%, Valid: 69.49% Test: 81.08%\n",
      "Run: 05, Epoch: 104, Loss: 0.4856, Train: 90.80%, Valid: 69.49% Test: 78.38%\n",
      "Run: 05, Epoch: 105, Loss: 0.4898, Train: 90.80%, Valid: 69.49% Test: 78.38%\n",
      "Run: 05, Epoch: 106, Loss: 0.5106, Train: 88.51%, Valid: 69.49% Test: 81.08%\n",
      "Run: 05, Epoch: 107, Loss: 0.4679, Train: 89.66%, Valid: 69.49% Test: 83.78%\n",
      "Run: 05, Epoch: 108, Loss: 0.4895, Train: 89.66%, Valid: 69.49% Test: 81.08%\n",
      "Run: 05, Epoch: 109, Loss: 0.4736, Train: 88.51%, Valid: 67.80% Test: 78.38%\n",
      "Run: 05, Epoch: 110, Loss: 0.4996, Train: 87.36%, Valid: 67.80% Test: 78.38%\n",
      "Run: 05, Epoch: 111, Loss: 0.4554, Train: 87.36%, Valid: 67.80% Test: 78.38%\n",
      "Run: 05, Epoch: 112, Loss: 0.4536, Train: 87.36%, Valid: 66.10% Test: 78.38%\n",
      "Run: 05, Epoch: 113, Loss: 0.4594, Train: 87.36%, Valid: 66.10% Test: 75.68%\n",
      "Run: 05, Epoch: 114, Loss: 0.4748, Train: 87.36%, Valid: 66.10% Test: 75.68%\n",
      "Run: 05, Epoch: 115, Loss: 0.4652, Train: 89.66%, Valid: 67.80% Test: 81.08%\n",
      "Run: 05, Epoch: 116, Loss: 0.4840, Train: 89.66%, Valid: 69.49% Test: 78.38%\n",
      "Run: 05, Epoch: 117, Loss: 0.4446, Train: 87.36%, Valid: 66.10% Test: 78.38%\n",
      "Run: 05, Epoch: 118, Loss: 0.4511, Train: 81.61%, Valid: 66.10% Test: 75.68%\n",
      "Run: 05, Epoch: 119, Loss: 0.4597, Train: 85.06%, Valid: 66.10% Test: 78.38%\n",
      "Run: 05, Epoch: 120, Loss: 0.5202, Train: 89.66%, Valid: 67.80% Test: 81.08%\n",
      "Run: 05, Epoch: 121, Loss: 0.5033, Train: 91.95%, Valid: 71.19% Test: 78.38%\n",
      "Run: 05, Epoch: 122, Loss: 0.4541, Train: 90.80%, Valid: 71.19% Test: 75.68%\n",
      "Run: 05, Epoch: 123, Loss: 0.4947, Train: 90.80%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 124, Loss: 0.4093, Train: 89.66%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 125, Loss: 0.4659, Train: 89.66%, Valid: 69.49% Test: 78.38%\n",
      "Run: 05, Epoch: 126, Loss: 0.4265, Train: 90.80%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 127, Loss: 0.4226, Train: 88.51%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 128, Loss: 0.5079, Train: 87.36%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 129, Loss: 0.4486, Train: 88.51%, Valid: 67.80% Test: 75.68%\n",
      "Run: 05, Epoch: 130, Loss: 0.4498, Train: 90.80%, Valid: 67.80% Test: 75.68%\n",
      "Run: 05, Epoch: 131, Loss: 0.4319, Train: 91.95%, Valid: 67.80% Test: 75.68%\n",
      "Run: 05, Epoch: 132, Loss: 0.4593, Train: 94.25%, Valid: 69.49% Test: 78.38%\n",
      "Run: 05, Epoch: 133, Loss: 0.3935, Train: 95.40%, Valid: 71.19% Test: 83.78%\n",
      "Run: 05, Epoch: 134, Loss: 0.4309, Train: 93.10%, Valid: 69.49% Test: 81.08%\n",
      "Run: 05, Epoch: 135, Loss: 0.4773, Train: 93.10%, Valid: 72.88% Test: 75.68%\n",
      "Run: 05, Epoch: 136, Loss: 0.4304, Train: 90.80%, Valid: 71.19% Test: 72.97%\n",
      "Run: 05, Epoch: 137, Loss: 0.4263, Train: 85.06%, Valid: 67.80% Test: 72.97%\n",
      "Run: 05, Epoch: 138, Loss: 0.4530, Train: 88.51%, Valid: 71.19% Test: 75.68%\n",
      "Run: 05, Epoch: 139, Loss: 0.3869, Train: 91.95%, Valid: 72.88% Test: 81.08%\n",
      "Run: 05, Epoch: 140, Loss: 0.3912, Train: 93.10%, Valid: 72.88% Test: 81.08%\n",
      "Run: 05, Epoch: 141, Loss: 0.4393, Train: 89.66%, Valid: 69.49% Test: 83.78%\n",
      "Run: 05, Epoch: 142, Loss: 0.4077, Train: 88.51%, Valid: 64.41% Test: 83.78%\n",
      "Run: 05, Epoch: 143, Loss: 0.4768, Train: 87.36%, Valid: 64.41% Test: 83.78%\n",
      "Run: 05, Epoch: 144, Loss: 0.4146, Train: 91.95%, Valid: 67.80% Test: 86.49%\n",
      "Run: 05, Epoch: 145, Loss: 0.3774, Train: 94.25%, Valid: 71.19% Test: 86.49%\n",
      "Run: 05, Epoch: 146, Loss: 0.4629, Train: 94.25%, Valid: 69.49% Test: 81.08%\n",
      "Run: 05, Epoch: 147, Loss: 0.4075, Train: 94.25%, Valid: 71.19% Test: 83.78%\n",
      "Run: 05, Epoch: 148, Loss: 0.4049, Train: 90.80%, Valid: 69.49% Test: 81.08%\n",
      "Run: 05, Epoch: 149, Loss: 0.4037, Train: 89.66%, Valid: 69.49% Test: 78.38%\n",
      "Run: 05, Epoch: 150, Loss: 0.4225, Train: 85.06%, Valid: 67.80% Test: 75.68%\n",
      "Run: 05, Epoch: 151, Loss: 0.4570, Train: 86.21%, Valid: 67.80% Test: 78.38%\n",
      "Run: 05, Epoch: 152, Loss: 0.4588, Train: 89.66%, Valid: 69.49% Test: 81.08%\n",
      "Run: 05, Epoch: 153, Loss: 0.3686, Train: 89.66%, Valid: 69.49% Test: 81.08%\n",
      "Run: 05, Epoch: 154, Loss: 0.4504, Train: 88.51%, Valid: 71.19% Test: 81.08%\n",
      "Run: 05, Epoch: 155, Loss: 0.3728, Train: 86.21%, Valid: 71.19% Test: 78.38%\n",
      "Run: 05, Epoch: 156, Loss: 0.3844, Train: 85.06%, Valid: 71.19% Test: 78.38%\n",
      "Run: 05, Epoch: 157, Loss: 0.3433, Train: 87.36%, Valid: 69.49% Test: 78.38%\n",
      "Run: 05, Epoch: 158, Loss: 0.4299, Train: 87.36%, Valid: 67.80% Test: 75.68%\n",
      "Run: 05, Epoch: 159, Loss: 0.4345, Train: 87.36%, Valid: 64.41% Test: 72.97%\n",
      "Run: 05, Epoch: 160, Loss: 0.3814, Train: 83.91%, Valid: 55.93% Test: 70.27%\n",
      "Run: 05, Epoch: 161, Loss: 0.4384, Train: 86.21%, Valid: 52.54% Test: 70.27%\n",
      "Run: 05, Epoch: 162, Loss: 0.3887, Train: 90.80%, Valid: 61.02% Test: 75.68%\n",
      "Run: 05, Epoch: 163, Loss: 0.4079, Train: 95.40%, Valid: 74.58% Test: 81.08%\n",
      "Run: 05, Epoch: 164, Loss: 0.3387, Train: 94.25%, Valid: 72.88% Test: 83.78%\n",
      "Run: 05, Epoch: 165, Loss: 0.3503, Train: 87.36%, Valid: 67.80% Test: 81.08%\n",
      "Run: 05, Epoch: 166, Loss: 0.3718, Train: 85.06%, Valid: 66.10% Test: 81.08%\n",
      "Run: 05, Epoch: 167, Loss: 0.3949, Train: 86.21%, Valid: 66.10% Test: 78.38%\n",
      "Run: 05, Epoch: 168, Loss: 0.3798, Train: 86.21%, Valid: 66.10% Test: 75.68%\n",
      "Run: 05, Epoch: 169, Loss: 0.3583, Train: 89.66%, Valid: 66.10% Test: 78.38%\n",
      "Run: 05, Epoch: 170, Loss: 0.3801, Train: 90.80%, Valid: 67.80% Test: 78.38%\n",
      "Run: 05, Epoch: 171, Loss: 0.3518, Train: 90.80%, Valid: 67.80% Test: 83.78%\n",
      "Run: 05, Epoch: 172, Loss: 0.3144, Train: 95.40%, Valid: 69.49% Test: 81.08%\n",
      "Run: 05, Epoch: 173, Loss: 0.3174, Train: 96.55%, Valid: 69.49% Test: 81.08%\n",
      "Run: 05, Epoch: 174, Loss: 0.2948, Train: 96.55%, Valid: 74.58% Test: 83.78%\n",
      "Run: 05, Epoch: 175, Loss: 0.3868, Train: 91.95%, Valid: 74.58% Test: 83.78%\n",
      "Run: 05, Epoch: 176, Loss: 0.4151, Train: 89.66%, Valid: 74.58% Test: 83.78%\n",
      "Run: 05, Epoch: 177, Loss: 0.3461, Train: 88.51%, Valid: 74.58% Test: 83.78%\n",
      "Run: 05, Epoch: 178, Loss: 0.4276, Train: 91.95%, Valid: 72.88% Test: 86.49%\n",
      "Run: 05, Epoch: 179, Loss: 0.3174, Train: 95.40%, Valid: 71.19% Test: 89.19%\n",
      "Run: 05, Epoch: 180, Loss: 0.3643, Train: 94.25%, Valid: 69.49% Test: 86.49%\n",
      "Run: 05, Epoch: 181, Loss: 0.3762, Train: 93.10%, Valid: 71.19% Test: 78.38%\n",
      "Run: 05, Epoch: 182, Loss: 0.3482, Train: 89.66%, Valid: 66.10% Test: 78.38%\n",
      "Run: 05, Epoch: 183, Loss: 0.3267, Train: 90.80%, Valid: 66.10% Test: 75.68%\n",
      "Run: 05, Epoch: 184, Loss: 0.3745, Train: 90.80%, Valid: 67.80% Test: 75.68%\n",
      "Run: 05, Epoch: 185, Loss: 0.3741, Train: 93.10%, Valid: 69.49% Test: 75.68%\n",
      "Run: 05, Epoch: 186, Loss: 0.3191, Train: 93.10%, Valid: 71.19% Test: 81.08%\n",
      "Run: 05, Epoch: 187, Loss: 0.3298, Train: 97.70%, Valid: 72.88% Test: 81.08%\n",
      "Run: 05, Epoch: 188, Loss: 0.3620, Train: 97.70%, Valid: 77.97% Test: 86.49%\n",
      "Run: 05, Epoch: 189, Loss: 0.3088, Train: 96.55%, Valid: 81.36% Test: 89.19%\n",
      "Run: 05, Epoch: 190, Loss: 0.3680, Train: 94.25%, Valid: 83.05% Test: 91.89%\n",
      "Run: 05, Epoch: 191, Loss: 0.3709, Train: 94.25%, Valid: 77.97% Test: 89.19%\n",
      "Run: 05, Epoch: 192, Loss: 0.3831, Train: 93.10%, Valid: 77.97% Test: 86.49%\n",
      "Run: 05, Epoch: 193, Loss: 0.3208, Train: 94.25%, Valid: 77.97% Test: 83.78%\n",
      "Run: 05, Epoch: 194, Loss: 0.3462, Train: 94.25%, Valid: 79.66% Test: 83.78%\n",
      "Run: 05, Epoch: 195, Loss: 0.3843, Train: 96.55%, Valid: 76.27% Test: 78.38%\n",
      "Run: 05, Epoch: 196, Loss: 0.3138, Train: 96.55%, Valid: 72.88% Test: 81.08%\n",
      "Run: 05, Epoch: 197, Loss: 0.3547, Train: 94.25%, Valid: 69.49% Test: 83.78%\n",
      "Run: 05, Epoch: 198, Loss: 0.3096, Train: 93.10%, Valid: 69.49% Test: 83.78%\n",
      "Run: 05, Epoch: 199, Loss: 0.3346, Train: 95.40%, Valid: 69.49% Test: 83.78%\n",
      "Run: 05, Epoch: 200, Loss: 0.2856, Train: 94.25%, Valid: 69.49% Test: 83.78%\n",
      "Run 05:\n",
      "Highest Train: 97.70\n",
      "Highest Valid: 83.05\n",
      "  Final Train: 94.25\n",
      "   Final Test: 91.89\n",
      "Run: 06, Epoch: 01, Loss: 1.6437, Train: 8.05%, Valid: 8.47% Test: 13.51%\n",
      "Run: 06, Epoch: 02, Loss: 1.5806, Train: 45.98%, Valid: 40.68% Test: 43.24%\n",
      "Run: 06, Epoch: 03, Loss: 1.5373, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 04, Loss: 1.4539, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 05, Loss: 1.4300, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 06, Loss: 1.4043, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 07, Loss: 1.3411, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 08, Loss: 1.3237, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 09, Loss: 1.2413, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 10, Loss: 1.2259, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 11, Loss: 1.2373, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 12, Loss: 1.1875, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 13, Loss: 1.1006, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 14, Loss: 1.0827, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 15, Loss: 1.0868, Train: 47.13%, Valid: 40.68% Test: 45.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 16, Loss: 1.0578, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 17, Loss: 1.0265, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 18, Loss: 1.0078, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 19, Loss: 1.0119, Train: 47.13%, Valid: 40.68% Test: 45.95%\n",
      "Run: 06, Epoch: 20, Loss: 0.9646, Train: 47.13%, Valid: 42.37% Test: 45.95%\n",
      "Run: 06, Epoch: 21, Loss: 1.0170, Train: 47.13%, Valid: 42.37% Test: 45.95%\n",
      "Run: 06, Epoch: 22, Loss: 0.9869, Train: 49.43%, Valid: 44.07% Test: 48.65%\n",
      "Run: 06, Epoch: 23, Loss: 0.9638, Train: 49.43%, Valid: 45.76% Test: 48.65%\n",
      "Run: 06, Epoch: 24, Loss: 0.9925, Train: 49.43%, Valid: 47.46% Test: 48.65%\n",
      "Run: 06, Epoch: 25, Loss: 0.9010, Train: 52.87%, Valid: 49.15% Test: 48.65%\n",
      "Run: 06, Epoch: 26, Loss: 0.9013, Train: 52.87%, Valid: 49.15% Test: 48.65%\n",
      "Run: 06, Epoch: 27, Loss: 0.9260, Train: 54.02%, Valid: 52.54% Test: 59.46%\n",
      "Run: 06, Epoch: 28, Loss: 0.9285, Train: 58.62%, Valid: 54.24% Test: 62.16%\n",
      "Run: 06, Epoch: 29, Loss: 0.9643, Train: 60.92%, Valid: 61.02% Test: 67.57%\n",
      "Run: 06, Epoch: 30, Loss: 0.8856, Train: 62.07%, Valid: 64.41% Test: 67.57%\n",
      "Run: 06, Epoch: 31, Loss: 0.8891, Train: 65.52%, Valid: 66.10% Test: 67.57%\n",
      "Run: 06, Epoch: 32, Loss: 0.8234, Train: 68.97%, Valid: 66.10% Test: 67.57%\n",
      "Run: 06, Epoch: 33, Loss: 0.8397, Train: 70.11%, Valid: 69.49% Test: 70.27%\n",
      "Run: 06, Epoch: 34, Loss: 0.8386, Train: 70.11%, Valid: 72.88% Test: 70.27%\n",
      "Run: 06, Epoch: 35, Loss: 0.8281, Train: 70.11%, Valid: 69.49% Test: 70.27%\n",
      "Run: 06, Epoch: 36, Loss: 0.8079, Train: 68.97%, Valid: 64.41% Test: 70.27%\n",
      "Run: 06, Epoch: 37, Loss: 0.8439, Train: 65.52%, Valid: 62.71% Test: 64.86%\n",
      "Run: 06, Epoch: 38, Loss: 0.8137, Train: 66.67%, Valid: 61.02% Test: 64.86%\n",
      "Run: 06, Epoch: 39, Loss: 0.8105, Train: 70.11%, Valid: 69.49% Test: 62.16%\n",
      "Run: 06, Epoch: 40, Loss: 0.8143, Train: 72.41%, Valid: 72.88% Test: 62.16%\n",
      "Run: 06, Epoch: 41, Loss: 0.8152, Train: 77.01%, Valid: 74.58% Test: 67.57%\n",
      "Run: 06, Epoch: 42, Loss: 0.7718, Train: 78.16%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 43, Loss: 0.8118, Train: 80.46%, Valid: 72.88% Test: 70.27%\n",
      "Run: 06, Epoch: 44, Loss: 0.7754, Train: 79.31%, Valid: 71.19% Test: 70.27%\n",
      "Run: 06, Epoch: 45, Loss: 0.7807, Train: 78.16%, Valid: 71.19% Test: 70.27%\n",
      "Run: 06, Epoch: 46, Loss: 0.7815, Train: 78.16%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 47, Loss: 0.7803, Train: 78.16%, Valid: 72.88% Test: 70.27%\n",
      "Run: 06, Epoch: 48, Loss: 0.7567, Train: 81.61%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 49, Loss: 0.6962, Train: 80.46%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 50, Loss: 0.7332, Train: 80.46%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 51, Loss: 0.6917, Train: 78.16%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 52, Loss: 0.7522, Train: 78.16%, Valid: 72.88% Test: 70.27%\n",
      "Run: 06, Epoch: 53, Loss: 0.7436, Train: 75.86%, Valid: 76.27% Test: 72.97%\n",
      "Run: 06, Epoch: 54, Loss: 0.7014, Train: 74.71%, Valid: 76.27% Test: 72.97%\n",
      "Run: 06, Epoch: 55, Loss: 0.7368, Train: 73.56%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 56, Loss: 0.6884, Train: 72.41%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 57, Loss: 0.7321, Train: 73.56%, Valid: 71.19% Test: 70.27%\n",
      "Run: 06, Epoch: 58, Loss: 0.6668, Train: 73.56%, Valid: 71.19% Test: 70.27%\n",
      "Run: 06, Epoch: 59, Loss: 0.7463, Train: 74.71%, Valid: 69.49% Test: 67.57%\n",
      "Run: 06, Epoch: 60, Loss: 0.6824, Train: 75.86%, Valid: 69.49% Test: 67.57%\n",
      "Run: 06, Epoch: 61, Loss: 0.6813, Train: 75.86%, Valid: 71.19% Test: 67.57%\n",
      "Run: 06, Epoch: 62, Loss: 0.7019, Train: 75.86%, Valid: 71.19% Test: 70.27%\n",
      "Run: 06, Epoch: 63, Loss: 0.6014, Train: 74.71%, Valid: 72.88% Test: 70.27%\n",
      "Run: 06, Epoch: 64, Loss: 0.7176, Train: 72.41%, Valid: 74.58% Test: 70.27%\n",
      "Run: 06, Epoch: 65, Loss: 0.7220, Train: 73.56%, Valid: 76.27% Test: 70.27%\n",
      "Run: 06, Epoch: 66, Loss: 0.6240, Train: 71.26%, Valid: 72.88% Test: 70.27%\n",
      "Run: 06, Epoch: 67, Loss: 0.6635, Train: 75.86%, Valid: 72.88% Test: 72.97%\n",
      "Run: 06, Epoch: 68, Loss: 0.6483, Train: 80.46%, Valid: 76.27% Test: 75.68%\n",
      "Run: 06, Epoch: 69, Loss: 0.6052, Train: 81.61%, Valid: 77.97% Test: 75.68%\n",
      "Run: 06, Epoch: 70, Loss: 0.5693, Train: 85.06%, Valid: 79.66% Test: 78.38%\n",
      "Run: 06, Epoch: 71, Loss: 0.5901, Train: 85.06%, Valid: 83.05% Test: 75.68%\n",
      "Run: 06, Epoch: 72, Loss: 0.6709, Train: 89.66%, Valid: 83.05% Test: 72.97%\n",
      "Run: 06, Epoch: 73, Loss: 0.6418, Train: 89.66%, Valid: 83.05% Test: 75.68%\n",
      "Run: 06, Epoch: 74, Loss: 0.6351, Train: 90.80%, Valid: 81.36% Test: 75.68%\n",
      "Run: 06, Epoch: 75, Loss: 0.6201, Train: 88.51%, Valid: 81.36% Test: 75.68%\n",
      "Run: 06, Epoch: 76, Loss: 0.5846, Train: 86.21%, Valid: 79.66% Test: 70.27%\n",
      "Run: 06, Epoch: 77, Loss: 0.5580, Train: 87.36%, Valid: 77.97% Test: 70.27%\n",
      "Run: 06, Epoch: 78, Loss: 0.6208, Train: 87.36%, Valid: 79.66% Test: 70.27%\n",
      "Run: 06, Epoch: 79, Loss: 0.5747, Train: 87.36%, Valid: 79.66% Test: 72.97%\n",
      "Run: 06, Epoch: 80, Loss: 0.6410, Train: 83.91%, Valid: 79.66% Test: 75.68%\n",
      "Run: 06, Epoch: 81, Loss: 0.5656, Train: 83.91%, Valid: 79.66% Test: 75.68%\n",
      "Run: 06, Epoch: 82, Loss: 0.5744, Train: 85.06%, Valid: 81.36% Test: 75.68%\n",
      "Run: 06, Epoch: 83, Loss: 0.5412, Train: 88.51%, Valid: 83.05% Test: 70.27%\n",
      "Run: 06, Epoch: 84, Loss: 0.5564, Train: 87.36%, Valid: 81.36% Test: 72.97%\n",
      "Run: 06, Epoch: 85, Loss: 0.5349, Train: 88.51%, Valid: 81.36% Test: 72.97%\n",
      "Run: 06, Epoch: 86, Loss: 0.5932, Train: 88.51%, Valid: 81.36% Test: 72.97%\n",
      "Run: 06, Epoch: 87, Loss: 0.5334, Train: 80.46%, Valid: 79.66% Test: 72.97%\n",
      "Run: 06, Epoch: 88, Loss: 0.5742, Train: 77.01%, Valid: 69.49% Test: 70.27%\n",
      "Run: 06, Epoch: 89, Loss: 0.5717, Train: 72.41%, Valid: 71.19% Test: 67.57%\n",
      "Run: 06, Epoch: 90, Loss: 0.5222, Train: 71.26%, Valid: 69.49% Test: 67.57%\n",
      "Run: 06, Epoch: 91, Loss: 0.5433, Train: 72.41%, Valid: 71.19% Test: 67.57%\n",
      "Run: 06, Epoch: 92, Loss: 0.6059, Train: 77.01%, Valid: 79.66% Test: 72.97%\n",
      "Run: 06, Epoch: 93, Loss: 0.5680, Train: 82.76%, Valid: 83.05% Test: 72.97%\n",
      "Run: 06, Epoch: 94, Loss: 0.5953, Train: 89.66%, Valid: 76.27% Test: 72.97%\n",
      "Run: 06, Epoch: 95, Loss: 0.5485, Train: 89.66%, Valid: 77.97% Test: 72.97%\n",
      "Run: 06, Epoch: 96, Loss: 0.5115, Train: 90.80%, Valid: 76.27% Test: 67.57%\n",
      "Run: 06, Epoch: 97, Loss: 0.4825, Train: 95.40%, Valid: 77.97% Test: 78.38%\n",
      "Run: 06, Epoch: 98, Loss: 0.4438, Train: 96.55%, Valid: 79.66% Test: 83.78%\n",
      "Run: 06, Epoch: 99, Loss: 0.5214, Train: 94.25%, Valid: 83.05% Test: 83.78%\n",
      "Run: 06, Epoch: 100, Loss: 0.4749, Train: 90.80%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 101, Loss: 0.5220, Train: 87.36%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 102, Loss: 0.4892, Train: 88.51%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 103, Loss: 0.5374, Train: 87.36%, Valid: 83.05% Test: 75.68%\n",
      "Run: 06, Epoch: 104, Loss: 0.5341, Train: 87.36%, Valid: 79.66% Test: 78.38%\n",
      "Run: 06, Epoch: 105, Loss: 0.5182, Train: 88.51%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 106, Loss: 0.5241, Train: 88.51%, Valid: 81.36% Test: 75.68%\n",
      "Run: 06, Epoch: 107, Loss: 0.4850, Train: 89.66%, Valid: 79.66% Test: 72.97%\n",
      "Run: 06, Epoch: 108, Loss: 0.4412, Train: 89.66%, Valid: 79.66% Test: 72.97%\n",
      "Run: 06, Epoch: 109, Loss: 0.4758, Train: 89.66%, Valid: 79.66% Test: 72.97%\n",
      "Run: 06, Epoch: 110, Loss: 0.4595, Train: 89.66%, Valid: 79.66% Test: 75.68%\n",
      "Run: 06, Epoch: 111, Loss: 0.5055, Train: 86.21%, Valid: 79.66% Test: 72.97%\n",
      "Run: 06, Epoch: 112, Loss: 0.4925, Train: 86.21%, Valid: 81.36% Test: 75.68%\n",
      "Run: 06, Epoch: 113, Loss: 0.5002, Train: 87.36%, Valid: 83.05% Test: 78.38%\n",
      "Run: 06, Epoch: 114, Loss: 0.4062, Train: 90.80%, Valid: 84.75% Test: 75.68%\n",
      "Run: 06, Epoch: 115, Loss: 0.4331, Train: 90.80%, Valid: 88.14% Test: 78.38%\n",
      "Run: 06, Epoch: 116, Loss: 0.4405, Train: 90.80%, Valid: 86.44% Test: 78.38%\n",
      "Run: 06, Epoch: 117, Loss: 0.4315, Train: 93.10%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 118, Loss: 0.4883, Train: 94.25%, Valid: 81.36% Test: 75.68%\n",
      "Run: 06, Epoch: 119, Loss: 0.4591, Train: 95.40%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 120, Loss: 0.4250, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 06, Epoch: 121, Loss: 0.4641, Train: 88.51%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 122, Loss: 0.4931, Train: 79.31%, Valid: 83.05% Test: 72.97%\n",
      "Run: 06, Epoch: 123, Loss: 0.4396, Train: 81.61%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 124, Loss: 0.4384, Train: 80.46%, Valid: 79.66% Test: 78.38%\n",
      "Run: 06, Epoch: 125, Loss: 0.4086, Train: 81.61%, Valid: 79.66% Test: 78.38%\n",
      "Run: 06, Epoch: 126, Loss: 0.4421, Train: 88.51%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 127, Loss: 0.4666, Train: 89.66%, Valid: 84.75% Test: 75.68%\n",
      "Run: 06, Epoch: 128, Loss: 0.3767, Train: 90.80%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 129, Loss: 0.4937, Train: 90.80%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 130, Loss: 0.3919, Train: 91.95%, Valid: 83.05% Test: 78.38%\n",
      "Run: 06, Epoch: 131, Loss: 0.3812, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 06, Epoch: 132, Loss: 0.3974, Train: 93.10%, Valid: 84.75% Test: 83.78%\n",
      "Run: 06, Epoch: 133, Loss: 0.5082, Train: 91.95%, Valid: 84.75% Test: 83.78%\n",
      "Run: 06, Epoch: 134, Loss: 0.4244, Train: 93.10%, Valid: 79.66% Test: 81.08%\n",
      "Run: 06, Epoch: 135, Loss: 0.4855, Train: 94.25%, Valid: 79.66% Test: 83.78%\n",
      "Run: 06, Epoch: 136, Loss: 0.4551, Train: 94.25%, Valid: 81.36% Test: 83.78%\n",
      "Run: 06, Epoch: 137, Loss: 0.4039, Train: 93.10%, Valid: 83.05% Test: 83.78%\n",
      "Run: 06, Epoch: 138, Loss: 0.4740, Train: 93.10%, Valid: 83.05% Test: 81.08%\n",
      "Run: 06, Epoch: 139, Loss: 0.3984, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 06, Epoch: 140, Loss: 0.4275, Train: 96.55%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 141, Loss: 0.4544, Train: 96.55%, Valid: 84.75% Test: 83.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 06, Epoch: 142, Loss: 0.4673, Train: 95.40%, Valid: 83.05% Test: 78.38%\n",
      "Run: 06, Epoch: 143, Loss: 0.4100, Train: 89.66%, Valid: 76.27% Test: 75.68%\n",
      "Run: 06, Epoch: 144, Loss: 0.4343, Train: 89.66%, Valid: 74.58% Test: 72.97%\n",
      "Run: 06, Epoch: 145, Loss: 0.3156, Train: 90.80%, Valid: 74.58% Test: 72.97%\n",
      "Run: 06, Epoch: 146, Loss: 0.3973, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 06, Epoch: 147, Loss: 0.3825, Train: 93.10%, Valid: 81.36% Test: 81.08%\n",
      "Run: 06, Epoch: 148, Loss: 0.4515, Train: 93.10%, Valid: 86.44% Test: 86.49%\n",
      "Run: 06, Epoch: 149, Loss: 0.4194, Train: 90.80%, Valid: 84.75% Test: 86.49%\n",
      "Run: 06, Epoch: 150, Loss: 0.3699, Train: 90.80%, Valid: 83.05% Test: 83.78%\n",
      "Run: 06, Epoch: 151, Loss: 0.3473, Train: 91.95%, Valid: 84.75% Test: 83.78%\n",
      "Run: 06, Epoch: 152, Loss: 0.3306, Train: 91.95%, Valid: 81.36% Test: 83.78%\n",
      "Run: 06, Epoch: 153, Loss: 0.4223, Train: 91.95%, Valid: 83.05% Test: 86.49%\n",
      "Run: 06, Epoch: 154, Loss: 0.4305, Train: 94.25%, Valid: 81.36% Test: 86.49%\n",
      "Run: 06, Epoch: 155, Loss: 0.3928, Train: 94.25%, Valid: 79.66% Test: 83.78%\n",
      "Run: 06, Epoch: 156, Loss: 0.3737, Train: 94.25%, Valid: 77.97% Test: 83.78%\n",
      "Run: 06, Epoch: 157, Loss: 0.3527, Train: 95.40%, Valid: 77.97% Test: 78.38%\n",
      "Run: 06, Epoch: 158, Loss: 0.3571, Train: 96.55%, Valid: 77.97% Test: 78.38%\n",
      "Run: 06, Epoch: 159, Loss: 0.3970, Train: 94.25%, Valid: 79.66% Test: 78.38%\n",
      "Run: 06, Epoch: 160, Loss: 0.3722, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 06, Epoch: 161, Loss: 0.4033, Train: 94.25%, Valid: 84.75% Test: 81.08%\n",
      "Run: 06, Epoch: 162, Loss: 0.3540, Train: 95.40%, Valid: 84.75% Test: 81.08%\n",
      "Run: 06, Epoch: 163, Loss: 0.3907, Train: 96.55%, Valid: 88.14% Test: 81.08%\n",
      "Run: 06, Epoch: 164, Loss: 0.3944, Train: 96.55%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 165, Loss: 0.3501, Train: 93.10%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 166, Loss: 0.3786, Train: 93.10%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 167, Loss: 0.3180, Train: 90.80%, Valid: 88.14% Test: 78.38%\n",
      "Run: 06, Epoch: 168, Loss: 0.3589, Train: 90.80%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 169, Loss: 0.3370, Train: 91.95%, Valid: 84.75% Test: 83.78%\n",
      "Run: 06, Epoch: 170, Loss: 0.4047, Train: 93.10%, Valid: 84.75% Test: 83.78%\n",
      "Run: 06, Epoch: 171, Loss: 0.2939, Train: 93.10%, Valid: 83.05% Test: 86.49%\n",
      "Run: 06, Epoch: 172, Loss: 0.3901, Train: 94.25%, Valid: 86.44% Test: 91.89%\n",
      "Run: 06, Epoch: 173, Loss: 0.3699, Train: 94.25%, Valid: 86.44% Test: 89.19%\n",
      "Run: 06, Epoch: 174, Loss: 0.3903, Train: 98.85%, Valid: 86.44% Test: 89.19%\n",
      "Run: 06, Epoch: 175, Loss: 0.4038, Train: 97.70%, Valid: 84.75% Test: 86.49%\n",
      "Run: 06, Epoch: 176, Loss: 0.3134, Train: 95.40%, Valid: 84.75% Test: 86.49%\n",
      "Run: 06, Epoch: 177, Loss: 0.2868, Train: 95.40%, Valid: 86.44% Test: 86.49%\n",
      "Run: 06, Epoch: 178, Loss: 0.3852, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 06, Epoch: 179, Loss: 0.3106, Train: 91.95%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 180, Loss: 0.4008, Train: 91.95%, Valid: 86.44% Test: 78.38%\n",
      "Run: 06, Epoch: 181, Loss: 0.3087, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 06, Epoch: 182, Loss: 0.3437, Train: 91.95%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 183, Loss: 0.2567, Train: 94.25%, Valid: 84.75% Test: 78.38%\n",
      "Run: 06, Epoch: 184, Loss: 0.3384, Train: 93.10%, Valid: 84.75% Test: 81.08%\n",
      "Run: 06, Epoch: 185, Loss: 0.3439, Train: 93.10%, Valid: 86.44% Test: 83.78%\n",
      "Run: 06, Epoch: 186, Loss: 0.3474, Train: 94.25%, Valid: 86.44% Test: 83.78%\n",
      "Run: 06, Epoch: 187, Loss: 0.3355, Train: 95.40%, Valid: 84.75% Test: 83.78%\n",
      "Run: 06, Epoch: 188, Loss: 0.3446, Train: 93.10%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 189, Loss: 0.2762, Train: 91.95%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 190, Loss: 0.3473, Train: 91.95%, Valid: 84.75% Test: 81.08%\n",
      "Run: 06, Epoch: 191, Loss: 0.2974, Train: 90.80%, Valid: 81.36% Test: 81.08%\n",
      "Run: 06, Epoch: 192, Loss: 0.3774, Train: 90.80%, Valid: 77.97% Test: 81.08%\n",
      "Run: 06, Epoch: 193, Loss: 0.3585, Train: 90.80%, Valid: 77.97% Test: 81.08%\n",
      "Run: 06, Epoch: 194, Loss: 0.3636, Train: 91.95%, Valid: 77.97% Test: 81.08%\n",
      "Run: 06, Epoch: 195, Loss: 0.3683, Train: 94.25%, Valid: 79.66% Test: 81.08%\n",
      "Run: 06, Epoch: 196, Loss: 0.3212, Train: 97.70%, Valid: 83.05% Test: 86.49%\n",
      "Run: 06, Epoch: 197, Loss: 0.2902, Train: 97.70%, Valid: 84.75% Test: 89.19%\n",
      "Run: 06, Epoch: 198, Loss: 0.3046, Train: 97.70%, Valid: 88.14% Test: 89.19%\n",
      "Run: 06, Epoch: 199, Loss: 0.3801, Train: 96.55%, Valid: 86.44% Test: 81.08%\n",
      "Run: 06, Epoch: 200, Loss: 0.3385, Train: 95.40%, Valid: 84.75% Test: 86.49%\n",
      "Run 06:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 88.14\n",
      "  Final Train: 90.80\n",
      "   Final Test: 78.38\n",
      "Run: 07, Epoch: 01, Loss: 1.7766, Train: 10.34%, Valid: 8.47% Test: 5.41%\n",
      "Run: 07, Epoch: 02, Loss: 1.6767, Train: 10.34%, Valid: 8.47% Test: 5.41%\n",
      "Run: 07, Epoch: 03, Loss: 1.6272, Train: 10.34%, Valid: 8.47% Test: 5.41%\n",
      "Run: 07, Epoch: 04, Loss: 1.5521, Train: 10.34%, Valid: 8.47% Test: 5.41%\n",
      "Run: 07, Epoch: 05, Loss: 1.5337, Train: 10.34%, Valid: 8.47% Test: 5.41%\n",
      "Run: 07, Epoch: 06, Loss: 1.4493, Train: 37.93%, Valid: 30.51% Test: 35.14%\n",
      "Run: 07, Epoch: 07, Loss: 1.4089, Train: 51.72%, Valid: 45.76% Test: 29.73%\n",
      "Run: 07, Epoch: 08, Loss: 1.3614, Train: 50.57%, Valid: 45.76% Test: 35.14%\n",
      "Run: 07, Epoch: 09, Loss: 1.2974, Train: 50.57%, Valid: 42.37% Test: 35.14%\n",
      "Run: 07, Epoch: 10, Loss: 1.2695, Train: 50.57%, Valid: 44.07% Test: 35.14%\n",
      "Run: 07, Epoch: 11, Loss: 1.2208, Train: 50.57%, Valid: 44.07% Test: 35.14%\n",
      "Run: 07, Epoch: 12, Loss: 1.1514, Train: 50.57%, Valid: 42.37% Test: 35.14%\n",
      "Run: 07, Epoch: 13, Loss: 1.1338, Train: 51.72%, Valid: 42.37% Test: 35.14%\n",
      "Run: 07, Epoch: 14, Loss: 1.1287, Train: 51.72%, Valid: 42.37% Test: 35.14%\n",
      "Run: 07, Epoch: 15, Loss: 1.1041, Train: 51.72%, Valid: 42.37% Test: 35.14%\n",
      "Run: 07, Epoch: 16, Loss: 1.0471, Train: 51.72%, Valid: 42.37% Test: 35.14%\n",
      "Run: 07, Epoch: 17, Loss: 1.0130, Train: 51.72%, Valid: 42.37% Test: 35.14%\n",
      "Run: 07, Epoch: 18, Loss: 1.0258, Train: 51.72%, Valid: 42.37% Test: 35.14%\n",
      "Run: 07, Epoch: 19, Loss: 0.9966, Train: 51.72%, Valid: 44.07% Test: 35.14%\n",
      "Run: 07, Epoch: 20, Loss: 0.9536, Train: 51.72%, Valid: 44.07% Test: 35.14%\n",
      "Run: 07, Epoch: 21, Loss: 0.9528, Train: 51.72%, Valid: 44.07% Test: 35.14%\n",
      "Run: 07, Epoch: 22, Loss: 0.8991, Train: 52.87%, Valid: 47.46% Test: 35.14%\n",
      "Run: 07, Epoch: 23, Loss: 0.9181, Train: 58.62%, Valid: 49.15% Test: 35.14%\n",
      "Run: 07, Epoch: 24, Loss: 0.8516, Train: 58.62%, Valid: 54.24% Test: 37.84%\n",
      "Run: 07, Epoch: 25, Loss: 0.9496, Train: 63.22%, Valid: 55.93% Test: 45.95%\n",
      "Run: 07, Epoch: 26, Loss: 0.8583, Train: 66.67%, Valid: 55.93% Test: 51.35%\n",
      "Run: 07, Epoch: 27, Loss: 0.8900, Train: 65.52%, Valid: 54.24% Test: 51.35%\n",
      "Run: 07, Epoch: 28, Loss: 0.8483, Train: 65.52%, Valid: 54.24% Test: 51.35%\n",
      "Run: 07, Epoch: 29, Loss: 0.8409, Train: 66.67%, Valid: 57.63% Test: 54.05%\n",
      "Run: 07, Epoch: 30, Loss: 0.8504, Train: 67.82%, Valid: 57.63% Test: 54.05%\n",
      "Run: 07, Epoch: 31, Loss: 0.7949, Train: 72.41%, Valid: 57.63% Test: 54.05%\n",
      "Run: 07, Epoch: 32, Loss: 0.8032, Train: 72.41%, Valid: 61.02% Test: 62.16%\n",
      "Run: 07, Epoch: 33, Loss: 0.8445, Train: 72.41%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 34, Loss: 0.7882, Train: 73.56%, Valid: 59.32% Test: 67.57%\n",
      "Run: 07, Epoch: 35, Loss: 0.8282, Train: 74.71%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 36, Loss: 0.8323, Train: 74.71%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 37, Loss: 0.7832, Train: 74.71%, Valid: 62.71% Test: 64.86%\n",
      "Run: 07, Epoch: 38, Loss: 0.7672, Train: 75.86%, Valid: 64.41% Test: 62.16%\n",
      "Run: 07, Epoch: 39, Loss: 0.7611, Train: 73.56%, Valid: 64.41% Test: 64.86%\n",
      "Run: 07, Epoch: 40, Loss: 0.7824, Train: 73.56%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 41, Loss: 0.7529, Train: 74.71%, Valid: 61.02% Test: 67.57%\n",
      "Run: 07, Epoch: 42, Loss: 0.7598, Train: 74.71%, Valid: 61.02% Test: 70.27%\n",
      "Run: 07, Epoch: 43, Loss: 0.7509, Train: 79.31%, Valid: 61.02% Test: 70.27%\n",
      "Run: 07, Epoch: 44, Loss: 0.7376, Train: 80.46%, Valid: 66.10% Test: 75.68%\n",
      "Run: 07, Epoch: 45, Loss: 0.7693, Train: 82.76%, Valid: 66.10% Test: 78.38%\n",
      "Run: 07, Epoch: 46, Loss: 0.7642, Train: 82.76%, Valid: 67.80% Test: 81.08%\n",
      "Run: 07, Epoch: 47, Loss: 0.7053, Train: 80.46%, Valid: 64.41% Test: 75.68%\n",
      "Run: 07, Epoch: 48, Loss: 0.7250, Train: 77.01%, Valid: 64.41% Test: 72.97%\n",
      "Run: 07, Epoch: 49, Loss: 0.7408, Train: 77.01%, Valid: 62.71% Test: 70.27%\n",
      "Run: 07, Epoch: 50, Loss: 0.7476, Train: 77.01%, Valid: 62.71% Test: 70.27%\n",
      "Run: 07, Epoch: 51, Loss: 0.6985, Train: 78.16%, Valid: 62.71% Test: 70.27%\n",
      "Run: 07, Epoch: 52, Loss: 0.6857, Train: 79.31%, Valid: 61.02% Test: 72.97%\n",
      "Run: 07, Epoch: 53, Loss: 0.6538, Train: 79.31%, Valid: 64.41% Test: 72.97%\n",
      "Run: 07, Epoch: 54, Loss: 0.6592, Train: 80.46%, Valid: 64.41% Test: 78.38%\n",
      "Run: 07, Epoch: 55, Loss: 0.6548, Train: 80.46%, Valid: 64.41% Test: 72.97%\n",
      "Run: 07, Epoch: 56, Loss: 0.7078, Train: 81.61%, Valid: 66.10% Test: 75.68%\n",
      "Run: 07, Epoch: 57, Loss: 0.7028, Train: 80.46%, Valid: 67.80% Test: 78.38%\n",
      "Run: 07, Epoch: 58, Loss: 0.6755, Train: 82.76%, Valid: 66.10% Test: 83.78%\n",
      "Run: 07, Epoch: 59, Loss: 0.6916, Train: 81.61%, Valid: 66.10% Test: 78.38%\n",
      "Run: 07, Epoch: 60, Loss: 0.7330, Train: 81.61%, Valid: 67.80% Test: 78.38%\n",
      "Run: 07, Epoch: 61, Loss: 0.5937, Train: 79.31%, Valid: 66.10% Test: 78.38%\n",
      "Run: 07, Epoch: 62, Loss: 0.6622, Train: 80.46%, Valid: 69.49% Test: 78.38%\n",
      "Run: 07, Epoch: 63, Loss: 0.6402, Train: 82.76%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 64, Loss: 0.6517, Train: 85.06%, Valid: 71.19% Test: 78.38%\n",
      "Run: 07, Epoch: 65, Loss: 0.6690, Train: 85.06%, Valid: 67.80% Test: 83.78%\n",
      "Run: 07, Epoch: 66, Loss: 0.6313, Train: 83.91%, Valid: 69.49% Test: 75.68%\n",
      "Run: 07, Epoch: 67, Loss: 0.6696, Train: 83.91%, Valid: 67.80% Test: 75.68%\n",
      "Run: 07, Epoch: 68, Loss: 0.6604, Train: 85.06%, Valid: 67.80% Test: 78.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 69, Loss: 0.6139, Train: 85.06%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 70, Loss: 0.5795, Train: 85.06%, Valid: 67.80% Test: 75.68%\n",
      "Run: 07, Epoch: 71, Loss: 0.6117, Train: 81.61%, Valid: 66.10% Test: 78.38%\n",
      "Run: 07, Epoch: 72, Loss: 0.5800, Train: 82.76%, Valid: 66.10% Test: 75.68%\n",
      "Run: 07, Epoch: 73, Loss: 0.5816, Train: 82.76%, Valid: 69.49% Test: 78.38%\n",
      "Run: 07, Epoch: 74, Loss: 0.5924, Train: 82.76%, Valid: 69.49% Test: 78.38%\n",
      "Run: 07, Epoch: 75, Loss: 0.5501, Train: 85.06%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 76, Loss: 0.5652, Train: 83.91%, Valid: 74.58% Test: 86.49%\n",
      "Run: 07, Epoch: 77, Loss: 0.6126, Train: 86.21%, Valid: 76.27% Test: 83.78%\n",
      "Run: 07, Epoch: 78, Loss: 0.5502, Train: 87.36%, Valid: 76.27% Test: 83.78%\n",
      "Run: 07, Epoch: 79, Loss: 0.6048, Train: 88.51%, Valid: 76.27% Test: 83.78%\n",
      "Run: 07, Epoch: 80, Loss: 0.5561, Train: 86.21%, Valid: 77.97% Test: 86.49%\n",
      "Run: 07, Epoch: 81, Loss: 0.5889, Train: 86.21%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 82, Loss: 0.5749, Train: 86.21%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 83, Loss: 0.5307, Train: 87.36%, Valid: 72.88% Test: 83.78%\n",
      "Run: 07, Epoch: 84, Loss: 0.5210, Train: 90.80%, Valid: 71.19% Test: 86.49%\n",
      "Run: 07, Epoch: 85, Loss: 0.5655, Train: 89.66%, Valid: 67.80% Test: 81.08%\n",
      "Run: 07, Epoch: 86, Loss: 0.5511, Train: 89.66%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 87, Loss: 0.5393, Train: 86.21%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 88, Loss: 0.5538, Train: 86.21%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 89, Loss: 0.5295, Train: 87.36%, Valid: 72.88% Test: 81.08%\n",
      "Run: 07, Epoch: 90, Loss: 0.5263, Train: 89.66%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 91, Loss: 0.5174, Train: 90.80%, Valid: 77.97% Test: 89.19%\n",
      "Run: 07, Epoch: 92, Loss: 0.5631, Train: 89.66%, Valid: 77.97% Test: 89.19%\n",
      "Run: 07, Epoch: 93, Loss: 0.5251, Train: 93.10%, Valid: 77.97% Test: 89.19%\n",
      "Run: 07, Epoch: 94, Loss: 0.4781, Train: 91.95%, Valid: 74.58% Test: 86.49%\n",
      "Run: 07, Epoch: 95, Loss: 0.5093, Train: 88.51%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 96, Loss: 0.5476, Train: 88.51%, Valid: 71.19% Test: 83.78%\n",
      "Run: 07, Epoch: 97, Loss: 0.4890, Train: 87.36%, Valid: 71.19% Test: 83.78%\n",
      "Run: 07, Epoch: 98, Loss: 0.5152, Train: 90.80%, Valid: 74.58% Test: 86.49%\n",
      "Run: 07, Epoch: 99, Loss: 0.4576, Train: 93.10%, Valid: 72.88% Test: 91.89%\n",
      "Run: 07, Epoch: 100, Loss: 0.4985, Train: 90.80%, Valid: 67.80% Test: 89.19%\n",
      "Run: 07, Epoch: 101, Loss: 0.5786, Train: 93.10%, Valid: 71.19% Test: 86.49%\n",
      "Run: 07, Epoch: 102, Loss: 0.4393, Train: 93.10%, Valid: 71.19% Test: 86.49%\n",
      "Run: 07, Epoch: 103, Loss: 0.5526, Train: 89.66%, Valid: 69.49% Test: 83.78%\n",
      "Run: 07, Epoch: 104, Loss: 0.5219, Train: 88.51%, Valid: 67.80% Test: 83.78%\n",
      "Run: 07, Epoch: 105, Loss: 0.5384, Train: 85.06%, Valid: 62.71% Test: 75.68%\n",
      "Run: 07, Epoch: 106, Loss: 0.4834, Train: 82.76%, Valid: 61.02% Test: 64.86%\n",
      "Run: 07, Epoch: 107, Loss: 0.4210, Train: 85.06%, Valid: 61.02% Test: 56.76%\n",
      "Run: 07, Epoch: 108, Loss: 0.4957, Train: 87.36%, Valid: 64.41% Test: 67.57%\n",
      "Run: 07, Epoch: 109, Loss: 0.4713, Train: 88.51%, Valid: 69.49% Test: 78.38%\n",
      "Run: 07, Epoch: 110, Loss: 0.4498, Train: 95.40%, Valid: 76.27% Test: 86.49%\n",
      "Run: 07, Epoch: 111, Loss: 0.4147, Train: 95.40%, Valid: 81.36% Test: 91.89%\n",
      "Run: 07, Epoch: 112, Loss: 0.4440, Train: 95.40%, Valid: 79.66% Test: 89.19%\n",
      "Run: 07, Epoch: 113, Loss: 0.4377, Train: 94.25%, Valid: 76.27% Test: 89.19%\n",
      "Run: 07, Epoch: 114, Loss: 0.4707, Train: 91.95%, Valid: 77.97% Test: 91.89%\n",
      "Run: 07, Epoch: 115, Loss: 0.4638, Train: 91.95%, Valid: 77.97% Test: 91.89%\n",
      "Run: 07, Epoch: 116, Loss: 0.4412, Train: 91.95%, Valid: 79.66% Test: 91.89%\n",
      "Run: 07, Epoch: 117, Loss: 0.4830, Train: 93.10%, Valid: 81.36% Test: 89.19%\n",
      "Run: 07, Epoch: 118, Loss: 0.4451, Train: 91.95%, Valid: 81.36% Test: 89.19%\n",
      "Run: 07, Epoch: 119, Loss: 0.4446, Train: 93.10%, Valid: 74.58% Test: 89.19%\n",
      "Run: 07, Epoch: 120, Loss: 0.4228, Train: 93.10%, Valid: 74.58% Test: 86.49%\n",
      "Run: 07, Epoch: 121, Loss: 0.5152, Train: 91.95%, Valid: 71.19% Test: 83.78%\n",
      "Run: 07, Epoch: 122, Loss: 0.4909, Train: 90.80%, Valid: 71.19% Test: 83.78%\n",
      "Run: 07, Epoch: 123, Loss: 0.4113, Train: 93.10%, Valid: 71.19% Test: 81.08%\n",
      "Run: 07, Epoch: 124, Loss: 0.4930, Train: 95.40%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 125, Loss: 0.4455, Train: 98.85%, Valid: 72.88% Test: 83.78%\n",
      "Run: 07, Epoch: 126, Loss: 0.4406, Train: 98.85%, Valid: 74.58% Test: 86.49%\n",
      "Run: 07, Epoch: 127, Loss: 0.3891, Train: 97.70%, Valid: 76.27% Test: 86.49%\n",
      "Run: 07, Epoch: 128, Loss: 0.3538, Train: 97.70%, Valid: 77.97% Test: 89.19%\n",
      "Run: 07, Epoch: 129, Loss: 0.4115, Train: 95.40%, Valid: 74.58% Test: 91.89%\n",
      "Run: 07, Epoch: 130, Loss: 0.4476, Train: 96.55%, Valid: 76.27% Test: 91.89%\n",
      "Run: 07, Epoch: 131, Loss: 0.4447, Train: 95.40%, Valid: 76.27% Test: 91.89%\n",
      "Run: 07, Epoch: 132, Loss: 0.4466, Train: 95.40%, Valid: 74.58% Test: 91.89%\n",
      "Run: 07, Epoch: 133, Loss: 0.3582, Train: 95.40%, Valid: 74.58% Test: 89.19%\n",
      "Run: 07, Epoch: 134, Loss: 0.3755, Train: 96.55%, Valid: 76.27% Test: 89.19%\n",
      "Run: 07, Epoch: 135, Loss: 0.4509, Train: 96.55%, Valid: 76.27% Test: 89.19%\n",
      "Run: 07, Epoch: 136, Loss: 0.3347, Train: 96.55%, Valid: 72.88% Test: 89.19%\n",
      "Run: 07, Epoch: 137, Loss: 0.3355, Train: 95.40%, Valid: 77.97% Test: 89.19%\n",
      "Run: 07, Epoch: 138, Loss: 0.4306, Train: 95.40%, Valid: 79.66% Test: 89.19%\n",
      "Run: 07, Epoch: 139, Loss: 0.3451, Train: 94.25%, Valid: 77.97% Test: 91.89%\n",
      "Run: 07, Epoch: 140, Loss: 0.3734, Train: 95.40%, Valid: 81.36% Test: 89.19%\n",
      "Run: 07, Epoch: 141, Loss: 0.4107, Train: 96.55%, Valid: 77.97% Test: 89.19%\n",
      "Run: 07, Epoch: 142, Loss: 0.4318, Train: 95.40%, Valid: 76.27% Test: 86.49%\n",
      "Run: 07, Epoch: 143, Loss: 0.3825, Train: 95.40%, Valid: 72.88% Test: 86.49%\n",
      "Run: 07, Epoch: 144, Loss: 0.4276, Train: 95.40%, Valid: 74.58% Test: 86.49%\n",
      "Run: 07, Epoch: 145, Loss: 0.3611, Train: 94.25%, Valid: 72.88% Test: 86.49%\n",
      "Run: 07, Epoch: 146, Loss: 0.3543, Train: 94.25%, Valid: 72.88% Test: 81.08%\n",
      "Run: 07, Epoch: 147, Loss: 0.3481, Train: 90.80%, Valid: 72.88% Test: 81.08%\n",
      "Run: 07, Epoch: 148, Loss: 0.3912, Train: 88.51%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 149, Loss: 0.3516, Train: 90.80%, Valid: 74.58% Test: 86.49%\n",
      "Run: 07, Epoch: 150, Loss: 0.3570, Train: 94.25%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 151, Loss: 0.3581, Train: 96.55%, Valid: 66.10% Test: 83.78%\n",
      "Run: 07, Epoch: 152, Loss: 0.3534, Train: 91.95%, Valid: 66.10% Test: 86.49%\n",
      "Run: 07, Epoch: 153, Loss: 0.3894, Train: 91.95%, Valid: 67.80% Test: 83.78%\n",
      "Run: 07, Epoch: 154, Loss: 0.4229, Train: 97.70%, Valid: 67.80% Test: 86.49%\n",
      "Run: 07, Epoch: 155, Loss: 0.3384, Train: 97.70%, Valid: 67.80% Test: 86.49%\n",
      "Run: 07, Epoch: 156, Loss: 0.3764, Train: 97.70%, Valid: 69.49% Test: 81.08%\n",
      "Run: 07, Epoch: 157, Loss: 0.3924, Train: 94.25%, Valid: 71.19% Test: 78.38%\n",
      "Run: 07, Epoch: 158, Loss: 0.3435, Train: 90.80%, Valid: 71.19% Test: 81.08%\n",
      "Run: 07, Epoch: 159, Loss: 0.3099, Train: 94.25%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 160, Loss: 0.3638, Train: 94.25%, Valid: 79.66% Test: 89.19%\n",
      "Run: 07, Epoch: 161, Loss: 0.4149, Train: 95.40%, Valid: 81.36% Test: 89.19%\n",
      "Run: 07, Epoch: 162, Loss: 0.2891, Train: 95.40%, Valid: 83.05% Test: 86.49%\n",
      "Run: 07, Epoch: 163, Loss: 0.3319, Train: 97.70%, Valid: 84.75% Test: 89.19%\n",
      "Run: 07, Epoch: 164, Loss: 0.4148, Train: 97.70%, Valid: 83.05% Test: 89.19%\n",
      "Run: 07, Epoch: 165, Loss: 0.3261, Train: 95.40%, Valid: 81.36% Test: 89.19%\n",
      "Run: 07, Epoch: 166, Loss: 0.3868, Train: 97.70%, Valid: 81.36% Test: 89.19%\n",
      "Run: 07, Epoch: 167, Loss: 0.3648, Train: 98.85%, Valid: 74.58% Test: 89.19%\n",
      "Run: 07, Epoch: 168, Loss: 0.3259, Train: 97.70%, Valid: 74.58% Test: 89.19%\n",
      "Run: 07, Epoch: 169, Loss: 0.4222, Train: 90.80%, Valid: 72.88% Test: 86.49%\n",
      "Run: 07, Epoch: 170, Loss: 0.2851, Train: 89.66%, Valid: 72.88% Test: 83.78%\n",
      "Run: 07, Epoch: 171, Loss: 0.3117, Train: 93.10%, Valid: 72.88% Test: 78.38%\n",
      "Run: 07, Epoch: 172, Loss: 0.3240, Train: 94.25%, Valid: 71.19% Test: 81.08%\n",
      "Run: 07, Epoch: 173, Loss: 0.3116, Train: 95.40%, Valid: 72.88% Test: 81.08%\n",
      "Run: 07, Epoch: 174, Loss: 0.3460, Train: 95.40%, Valid: 72.88% Test: 83.78%\n",
      "Run: 07, Epoch: 175, Loss: 0.3661, Train: 95.40%, Valid: 74.58% Test: 83.78%\n",
      "Run: 07, Epoch: 176, Loss: 0.3523, Train: 95.40%, Valid: 74.58% Test: 86.49%\n",
      "Run: 07, Epoch: 177, Loss: 0.3036, Train: 91.95%, Valid: 76.27% Test: 83.78%\n",
      "Run: 07, Epoch: 178, Loss: 0.3500, Train: 90.80%, Valid: 76.27% Test: 83.78%\n",
      "Run: 07, Epoch: 179, Loss: 0.2982, Train: 93.10%, Valid: 79.66% Test: 86.49%\n",
      "Run: 07, Epoch: 180, Loss: 0.3876, Train: 97.70%, Valid: 77.97% Test: 89.19%\n",
      "Run: 07, Epoch: 181, Loss: 0.3139, Train: 98.85%, Valid: 76.27% Test: 89.19%\n",
      "Run: 07, Epoch: 182, Loss: 0.2617, Train: 96.55%, Valid: 76.27% Test: 86.49%\n",
      "Run: 07, Epoch: 183, Loss: 0.3478, Train: 96.55%, Valid: 79.66% Test: 86.49%\n",
      "Run: 07, Epoch: 184, Loss: 0.2955, Train: 96.55%, Valid: 79.66% Test: 86.49%\n",
      "Run: 07, Epoch: 185, Loss: 0.2730, Train: 96.55%, Valid: 79.66% Test: 86.49%\n",
      "Run: 07, Epoch: 186, Loss: 0.2989, Train: 98.85%, Valid: 81.36% Test: 86.49%\n",
      "Run: 07, Epoch: 187, Loss: 0.3718, Train: 97.70%, Valid: 83.05% Test: 86.49%\n",
      "Run: 07, Epoch: 188, Loss: 0.2924, Train: 97.70%, Valid: 83.05% Test: 91.89%\n",
      "Run: 07, Epoch: 189, Loss: 0.3057, Train: 97.70%, Valid: 83.05% Test: 89.19%\n",
      "Run: 07, Epoch: 190, Loss: 0.3217, Train: 97.70%, Valid: 81.36% Test: 86.49%\n",
      "Run: 07, Epoch: 191, Loss: 0.2476, Train: 98.85%, Valid: 81.36% Test: 86.49%\n",
      "Run: 07, Epoch: 192, Loss: 0.2618, Train: 97.70%, Valid: 83.05% Test: 86.49%\n",
      "Run: 07, Epoch: 193, Loss: 0.3579, Train: 96.55%, Valid: 81.36% Test: 86.49%\n",
      "Run: 07, Epoch: 194, Loss: 0.2569, Train: 97.70%, Valid: 83.05% Test: 86.49%\n",
      "Run: 07, Epoch: 195, Loss: 0.2471, Train: 97.70%, Valid: 81.36% Test: 89.19%\n",
      "Run: 07, Epoch: 196, Loss: 0.2701, Train: 98.85%, Valid: 81.36% Test: 89.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 07, Epoch: 197, Loss: 0.3062, Train: 98.85%, Valid: 81.36% Test: 89.19%\n",
      "Run: 07, Epoch: 198, Loss: 0.4200, Train: 97.70%, Valid: 76.27% Test: 89.19%\n",
      "Run: 07, Epoch: 199, Loss: 0.2592, Train: 97.70%, Valid: 77.97% Test: 89.19%\n",
      "Run: 07, Epoch: 200, Loss: 0.2799, Train: 97.70%, Valid: 74.58% Test: 86.49%\n",
      "Run 07:\n",
      "Highest Train: 98.85\n",
      "Highest Valid: 84.75\n",
      "  Final Train: 97.70\n",
      "   Final Test: 89.19\n",
      "Run: 08, Epoch: 01, Loss: 1.5544, Train: 9.20%, Valid: 11.86% Test: 13.51%\n",
      "Run: 08, Epoch: 02, Loss: 1.5089, Train: 43.68%, Valid: 49.15% Test: 43.24%\n",
      "Run: 08, Epoch: 03, Loss: 1.4700, Train: 45.98%, Valid: 49.15% Test: 45.95%\n",
      "Run: 08, Epoch: 04, Loss: 1.4245, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 05, Loss: 1.4144, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 06, Loss: 1.3496, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 07, Loss: 1.3037, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 08, Loss: 1.2858, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 09, Loss: 1.2570, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 10, Loss: 1.2415, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 11, Loss: 1.1852, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 12, Loss: 1.1626, Train: 42.53%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 13, Loss: 1.1306, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 14, Loss: 1.0836, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 15, Loss: 1.1389, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 16, Loss: 1.0300, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 17, Loss: 1.0324, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 18, Loss: 0.9875, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 19, Loss: 0.9741, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 20, Loss: 1.0231, Train: 43.68%, Valid: 47.46% Test: 45.95%\n",
      "Run: 08, Epoch: 21, Loss: 0.9359, Train: 44.83%, Valid: 47.46% Test: 48.65%\n",
      "Run: 08, Epoch: 22, Loss: 0.9364, Train: 45.98%, Valid: 47.46% Test: 48.65%\n",
      "Run: 08, Epoch: 23, Loss: 0.9313, Train: 49.43%, Valid: 47.46% Test: 48.65%\n",
      "Run: 08, Epoch: 24, Loss: 0.8822, Train: 49.43%, Valid: 50.85% Test: 48.65%\n",
      "Run: 08, Epoch: 25, Loss: 0.9188, Train: 54.02%, Valid: 52.54% Test: 54.05%\n",
      "Run: 08, Epoch: 26, Loss: 0.8806, Train: 59.77%, Valid: 54.24% Test: 54.05%\n",
      "Run: 08, Epoch: 27, Loss: 0.8772, Train: 60.92%, Valid: 55.93% Test: 56.76%\n",
      "Run: 08, Epoch: 28, Loss: 0.8241, Train: 60.92%, Valid: 55.93% Test: 56.76%\n",
      "Run: 08, Epoch: 29, Loss: 0.8692, Train: 62.07%, Valid: 55.93% Test: 56.76%\n",
      "Run: 08, Epoch: 30, Loss: 0.8437, Train: 63.22%, Valid: 57.63% Test: 56.76%\n",
      "Run: 08, Epoch: 31, Loss: 0.8452, Train: 63.22%, Valid: 59.32% Test: 56.76%\n",
      "Run: 08, Epoch: 32, Loss: 0.8056, Train: 64.37%, Valid: 57.63% Test: 56.76%\n",
      "Run: 08, Epoch: 33, Loss: 0.8559, Train: 64.37%, Valid: 57.63% Test: 56.76%\n",
      "Run: 08, Epoch: 34, Loss: 0.8015, Train: 63.22%, Valid: 57.63% Test: 56.76%\n",
      "Run: 08, Epoch: 35, Loss: 0.8580, Train: 65.52%, Valid: 62.71% Test: 59.46%\n",
      "Run: 08, Epoch: 36, Loss: 0.8370, Train: 64.37%, Valid: 62.71% Test: 59.46%\n",
      "Run: 08, Epoch: 37, Loss: 0.7645, Train: 64.37%, Valid: 62.71% Test: 62.16%\n",
      "Run: 08, Epoch: 38, Loss: 0.7984, Train: 68.97%, Valid: 62.71% Test: 67.57%\n",
      "Run: 08, Epoch: 39, Loss: 0.7684, Train: 72.41%, Valid: 64.41% Test: 67.57%\n",
      "Run: 08, Epoch: 40, Loss: 0.7781, Train: 74.71%, Valid: 64.41% Test: 62.16%\n",
      "Run: 08, Epoch: 41, Loss: 0.7349, Train: 75.86%, Valid: 66.10% Test: 64.86%\n",
      "Run: 08, Epoch: 42, Loss: 0.7252, Train: 77.01%, Valid: 67.80% Test: 67.57%\n",
      "Run: 08, Epoch: 43, Loss: 0.7472, Train: 78.16%, Valid: 66.10% Test: 67.57%\n",
      "Run: 08, Epoch: 44, Loss: 0.7389, Train: 78.16%, Valid: 66.10% Test: 67.57%\n",
      "Run: 08, Epoch: 45, Loss: 0.7143, Train: 77.01%, Valid: 66.10% Test: 67.57%\n",
      "Run: 08, Epoch: 46, Loss: 0.7502, Train: 79.31%, Valid: 66.10% Test: 67.57%\n",
      "Run: 08, Epoch: 47, Loss: 0.6799, Train: 79.31%, Valid: 67.80% Test: 67.57%\n",
      "Run: 08, Epoch: 48, Loss: 0.7424, Train: 80.46%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 49, Loss: 0.6917, Train: 81.61%, Valid: 71.19% Test: 67.57%\n",
      "Run: 08, Epoch: 50, Loss: 0.6701, Train: 81.61%, Valid: 72.88% Test: 67.57%\n",
      "Run: 08, Epoch: 51, Loss: 0.7006, Train: 81.61%, Valid: 67.80% Test: 70.27%\n",
      "Run: 08, Epoch: 52, Loss: 0.6875, Train: 78.16%, Valid: 66.10% Test: 70.27%\n",
      "Run: 08, Epoch: 53, Loss: 0.7256, Train: 78.16%, Valid: 66.10% Test: 70.27%\n",
      "Run: 08, Epoch: 54, Loss: 0.7753, Train: 79.31%, Valid: 67.80% Test: 70.27%\n",
      "Run: 08, Epoch: 55, Loss: 0.6990, Train: 81.61%, Valid: 69.49% Test: 70.27%\n",
      "Run: 08, Epoch: 56, Loss: 0.6595, Train: 83.91%, Valid: 74.58% Test: 70.27%\n",
      "Run: 08, Epoch: 57, Loss: 0.6493, Train: 86.21%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 58, Loss: 0.7110, Train: 87.36%, Valid: 77.97% Test: 67.57%\n",
      "Run: 08, Epoch: 59, Loss: 0.6298, Train: 87.36%, Valid: 76.27% Test: 70.27%\n",
      "Run: 08, Epoch: 60, Loss: 0.6678, Train: 86.21%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 61, Loss: 0.6738, Train: 82.76%, Valid: 76.27% Test: 67.57%\n",
      "Run: 08, Epoch: 62, Loss: 0.6465, Train: 80.46%, Valid: 74.58% Test: 64.86%\n",
      "Run: 08, Epoch: 63, Loss: 0.6625, Train: 81.61%, Valid: 74.58% Test: 64.86%\n",
      "Run: 08, Epoch: 64, Loss: 0.6333, Train: 81.61%, Valid: 74.58% Test: 67.57%\n",
      "Run: 08, Epoch: 65, Loss: 0.6309, Train: 80.46%, Valid: 74.58% Test: 70.27%\n",
      "Run: 08, Epoch: 66, Loss: 0.6245, Train: 81.61%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 67, Loss: 0.6080, Train: 82.76%, Valid: 72.88% Test: 70.27%\n",
      "Run: 08, Epoch: 68, Loss: 0.6389, Train: 83.91%, Valid: 76.27% Test: 70.27%\n",
      "Run: 08, Epoch: 69, Loss: 0.6146, Train: 87.36%, Valid: 79.66% Test: 70.27%\n",
      "Run: 08, Epoch: 70, Loss: 0.5922, Train: 90.80%, Valid: 79.66% Test: 72.97%\n",
      "Run: 08, Epoch: 71, Loss: 0.6492, Train: 88.51%, Valid: 81.36% Test: 70.27%\n",
      "Run: 08, Epoch: 72, Loss: 0.6398, Train: 88.51%, Valid: 79.66% Test: 70.27%\n",
      "Run: 08, Epoch: 73, Loss: 0.5304, Train: 88.51%, Valid: 79.66% Test: 67.57%\n",
      "Run: 08, Epoch: 74, Loss: 0.6493, Train: 81.61%, Valid: 74.58% Test: 59.46%\n",
      "Run: 08, Epoch: 75, Loss: 0.5712, Train: 81.61%, Valid: 71.19% Test: 59.46%\n",
      "Run: 08, Epoch: 76, Loss: 0.5885, Train: 80.46%, Valid: 72.88% Test: 59.46%\n",
      "Run: 08, Epoch: 77, Loss: 0.5601, Train: 80.46%, Valid: 72.88% Test: 62.16%\n",
      "Run: 08, Epoch: 78, Loss: 0.5862, Train: 83.91%, Valid: 77.97% Test: 64.86%\n",
      "Run: 08, Epoch: 79, Loss: 0.5774, Train: 86.21%, Valid: 79.66% Test: 64.86%\n",
      "Run: 08, Epoch: 80, Loss: 0.5954, Train: 88.51%, Valid: 81.36% Test: 67.57%\n",
      "Run: 08, Epoch: 81, Loss: 0.5956, Train: 88.51%, Valid: 79.66% Test: 67.57%\n",
      "Run: 08, Epoch: 82, Loss: 0.5693, Train: 90.80%, Valid: 79.66% Test: 64.86%\n",
      "Run: 08, Epoch: 83, Loss: 0.5898, Train: 88.51%, Valid: 76.27% Test: 67.57%\n",
      "Run: 08, Epoch: 84, Loss: 0.5555, Train: 83.91%, Valid: 76.27% Test: 67.57%\n",
      "Run: 08, Epoch: 85, Loss: 0.5706, Train: 86.21%, Valid: 74.58% Test: 67.57%\n",
      "Run: 08, Epoch: 86, Loss: 0.5478, Train: 87.36%, Valid: 76.27% Test: 72.97%\n",
      "Run: 08, Epoch: 87, Loss: 0.6102, Train: 85.06%, Valid: 74.58% Test: 72.97%\n",
      "Run: 08, Epoch: 88, Loss: 0.5600, Train: 83.91%, Valid: 74.58% Test: 75.68%\n",
      "Run: 08, Epoch: 89, Loss: 0.6228, Train: 83.91%, Valid: 76.27% Test: 75.68%\n",
      "Run: 08, Epoch: 90, Loss: 0.5094, Train: 87.36%, Valid: 77.97% Test: 72.97%\n",
      "Run: 08, Epoch: 91, Loss: 0.5140, Train: 87.36%, Valid: 79.66% Test: 70.27%\n",
      "Run: 08, Epoch: 92, Loss: 0.5285, Train: 88.51%, Valid: 79.66% Test: 70.27%\n",
      "Run: 08, Epoch: 93, Loss: 0.5084, Train: 87.36%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 94, Loss: 0.4836, Train: 83.91%, Valid: 74.58% Test: 70.27%\n",
      "Run: 08, Epoch: 95, Loss: 0.5347, Train: 87.36%, Valid: 76.27% Test: 70.27%\n",
      "Run: 08, Epoch: 96, Loss: 0.5042, Train: 87.36%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 97, Loss: 0.5714, Train: 89.66%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 98, Loss: 0.5346, Train: 91.95%, Valid: 79.66% Test: 72.97%\n",
      "Run: 08, Epoch: 99, Loss: 0.5148, Train: 94.25%, Valid: 83.05% Test: 72.97%\n",
      "Run: 08, Epoch: 100, Loss: 0.4788, Train: 91.95%, Valid: 83.05% Test: 67.57%\n",
      "Run: 08, Epoch: 101, Loss: 0.4623, Train: 90.80%, Valid: 83.05% Test: 72.97%\n",
      "Run: 08, Epoch: 102, Loss: 0.4628, Train: 89.66%, Valid: 81.36% Test: 70.27%\n",
      "Run: 08, Epoch: 103, Loss: 0.5373, Train: 86.21%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 104, Loss: 0.4765, Train: 80.46%, Valid: 71.19% Test: 70.27%\n",
      "Run: 08, Epoch: 105, Loss: 0.4478, Train: 82.76%, Valid: 71.19% Test: 72.97%\n",
      "Run: 08, Epoch: 106, Loss: 0.4414, Train: 88.51%, Valid: 79.66% Test: 72.97%\n",
      "Run: 08, Epoch: 107, Loss: 0.4811, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 08, Epoch: 108, Loss: 0.4484, Train: 95.40%, Valid: 81.36% Test: 78.38%\n",
      "Run: 08, Epoch: 109, Loss: 0.5130, Train: 97.70%, Valid: 83.05% Test: 81.08%\n",
      "Run: 08, Epoch: 110, Loss: 0.5418, Train: 97.70%, Valid: 83.05% Test: 86.49%\n",
      "Run: 08, Epoch: 111, Loss: 0.4322, Train: 96.55%, Valid: 83.05% Test: 81.08%\n",
      "Run: 08, Epoch: 112, Loss: 0.4561, Train: 94.25%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 113, Loss: 0.5496, Train: 91.95%, Valid: 81.36% Test: 72.97%\n",
      "Run: 08, Epoch: 114, Loss: 0.5276, Train: 89.66%, Valid: 79.66% Test: 72.97%\n",
      "Run: 08, Epoch: 115, Loss: 0.4281, Train: 90.80%, Valid: 77.97% Test: 72.97%\n",
      "Run: 08, Epoch: 116, Loss: 0.4765, Train: 89.66%, Valid: 79.66% Test: 72.97%\n",
      "Run: 08, Epoch: 117, Loss: 0.4490, Train: 91.95%, Valid: 83.05% Test: 72.97%\n",
      "Run: 08, Epoch: 118, Loss: 0.4428, Train: 93.10%, Valid: 86.44% Test: 72.97%\n",
      "Run: 08, Epoch: 119, Loss: 0.4129, Train: 93.10%, Valid: 88.14% Test: 70.27%\n",
      "Run: 08, Epoch: 120, Loss: 0.4824, Train: 91.95%, Valid: 86.44% Test: 72.97%\n",
      "Run: 08, Epoch: 121, Loss: 0.4093, Train: 88.51%, Valid: 84.75% Test: 72.97%\n",
      "Run: 08, Epoch: 122, Loss: 0.4536, Train: 87.36%, Valid: 83.05% Test: 70.27%\n",
      "Run: 08, Epoch: 123, Loss: 0.4110, Train: 89.66%, Valid: 83.05% Test: 70.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 08, Epoch: 124, Loss: 0.4206, Train: 93.10%, Valid: 84.75% Test: 67.57%\n",
      "Run: 08, Epoch: 125, Loss: 0.3562, Train: 95.40%, Valid: 79.66% Test: 75.68%\n",
      "Run: 08, Epoch: 126, Loss: 0.4277, Train: 93.10%, Valid: 79.66% Test: 72.97%\n",
      "Run: 08, Epoch: 127, Loss: 0.3526, Train: 89.66%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 128, Loss: 0.3827, Train: 91.95%, Valid: 77.97% Test: 70.27%\n",
      "Run: 08, Epoch: 129, Loss: 0.4743, Train: 91.95%, Valid: 81.36% Test: 72.97%\n",
      "Run: 08, Epoch: 130, Loss: 0.4137, Train: 93.10%, Valid: 84.75% Test: 70.27%\n",
      "Run: 08, Epoch: 131, Loss: 0.4348, Train: 95.40%, Valid: 83.05% Test: 72.97%\n",
      "Run: 08, Epoch: 132, Loss: 0.4557, Train: 96.55%, Valid: 84.75% Test: 78.38%\n",
      "Run: 08, Epoch: 133, Loss: 0.3999, Train: 96.55%, Valid: 84.75% Test: 78.38%\n",
      "Run: 08, Epoch: 134, Loss: 0.3994, Train: 96.55%, Valid: 84.75% Test: 78.38%\n",
      "Run: 08, Epoch: 135, Loss: 0.4162, Train: 94.25%, Valid: 86.44% Test: 83.78%\n",
      "Run: 08, Epoch: 136, Loss: 0.3916, Train: 91.95%, Valid: 84.75% Test: 75.68%\n",
      "Run: 08, Epoch: 137, Loss: 0.3667, Train: 88.51%, Valid: 83.05% Test: 72.97%\n",
      "Run: 08, Epoch: 138, Loss: 0.3717, Train: 90.80%, Valid: 81.36% Test: 72.97%\n",
      "Run: 08, Epoch: 139, Loss: 0.3664, Train: 94.25%, Valid: 84.75% Test: 70.27%\n",
      "Run: 08, Epoch: 140, Loss: 0.4233, Train: 93.10%, Valid: 81.36% Test: 72.97%\n",
      "Run: 08, Epoch: 141, Loss: 0.4101, Train: 93.10%, Valid: 79.66% Test: 75.68%\n",
      "Run: 08, Epoch: 142, Loss: 0.3774, Train: 93.10%, Valid: 77.97% Test: 75.68%\n",
      "Run: 08, Epoch: 143, Loss: 0.3937, Train: 91.95%, Valid: 79.66% Test: 78.38%\n",
      "Run: 08, Epoch: 144, Loss: 0.3397, Train: 91.95%, Valid: 79.66% Test: 75.68%\n",
      "Run: 08, Epoch: 145, Loss: 0.4400, Train: 94.25%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 146, Loss: 0.4080, Train: 95.40%, Valid: 83.05% Test: 81.08%\n",
      "Run: 08, Epoch: 147, Loss: 0.4885, Train: 96.55%, Valid: 88.14% Test: 81.08%\n",
      "Run: 08, Epoch: 148, Loss: 0.3580, Train: 96.55%, Valid: 86.44% Test: 78.38%\n",
      "Run: 08, Epoch: 149, Loss: 0.3846, Train: 96.55%, Valid: 84.75% Test: 75.68%\n",
      "Run: 08, Epoch: 150, Loss: 0.4145, Train: 95.40%, Valid: 86.44% Test: 67.57%\n",
      "Run: 08, Epoch: 151, Loss: 0.3932, Train: 94.25%, Valid: 86.44% Test: 72.97%\n",
      "Run: 08, Epoch: 152, Loss: 0.4026, Train: 94.25%, Valid: 88.14% Test: 72.97%\n",
      "Run: 08, Epoch: 153, Loss: 0.4420, Train: 95.40%, Valid: 89.83% Test: 81.08%\n",
      "Run: 08, Epoch: 154, Loss: 0.3982, Train: 95.40%, Valid: 89.83% Test: 83.78%\n",
      "Run: 08, Epoch: 155, Loss: 0.3679, Train: 93.10%, Valid: 86.44% Test: 81.08%\n",
      "Run: 08, Epoch: 156, Loss: 0.3449, Train: 93.10%, Valid: 84.75% Test: 81.08%\n",
      "Run: 08, Epoch: 157, Loss: 0.3023, Train: 91.95%, Valid: 84.75% Test: 75.68%\n",
      "Run: 08, Epoch: 158, Loss: 0.3417, Train: 90.80%, Valid: 86.44% Test: 78.38%\n",
      "Run: 08, Epoch: 159, Loss: 0.3686, Train: 94.25%, Valid: 86.44% Test: 81.08%\n",
      "Run: 08, Epoch: 160, Loss: 0.3474, Train: 95.40%, Valid: 86.44% Test: 86.49%\n",
      "Run: 08, Epoch: 161, Loss: 0.3594, Train: 97.70%, Valid: 83.05% Test: 81.08%\n",
      "Run: 08, Epoch: 162, Loss: 0.3420, Train: 96.55%, Valid: 81.36% Test: 86.49%\n",
      "Run: 08, Epoch: 163, Loss: 0.3459, Train: 95.40%, Valid: 81.36% Test: 78.38%\n",
      "Run: 08, Epoch: 164, Loss: 0.3957, Train: 95.40%, Valid: 81.36% Test: 78.38%\n",
      "Run: 08, Epoch: 165, Loss: 0.3668, Train: 94.25%, Valid: 81.36% Test: 75.68%\n",
      "Run: 08, Epoch: 166, Loss: 0.3443, Train: 94.25%, Valid: 79.66% Test: 75.68%\n",
      "Run: 08, Epoch: 167, Loss: 0.3304, Train: 93.10%, Valid: 79.66% Test: 75.68%\n",
      "Run: 08, Epoch: 168, Loss: 0.3086, Train: 93.10%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 169, Loss: 0.3534, Train: 96.55%, Valid: 86.44% Test: 78.38%\n",
      "Run: 08, Epoch: 170, Loss: 0.2472, Train: 98.85%, Valid: 84.75% Test: 81.08%\n",
      "Run: 08, Epoch: 171, Loss: 0.2758, Train: 97.70%, Valid: 86.44% Test: 83.78%\n",
      "Run: 08, Epoch: 172, Loss: 0.3201, Train: 94.25%, Valid: 84.75% Test: 81.08%\n",
      "Run: 08, Epoch: 173, Loss: 0.3957, Train: 89.66%, Valid: 81.36% Test: 81.08%\n",
      "Run: 08, Epoch: 174, Loss: 0.3315, Train: 96.55%, Valid: 86.44% Test: 81.08%\n",
      "Run: 08, Epoch: 175, Loss: 0.3497, Train: 100.00%, Valid: 89.83% Test: 86.49%\n",
      "Run: 08, Epoch: 176, Loss: 0.3630, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 08, Epoch: 177, Loss: 0.2992, Train: 93.10%, Valid: 86.44% Test: 81.08%\n",
      "Run: 08, Epoch: 178, Loss: 0.3229, Train: 93.10%, Valid: 86.44% Test: 78.38%\n",
      "Run: 08, Epoch: 179, Loss: 0.3330, Train: 94.25%, Valid: 88.14% Test: 81.08%\n",
      "Run: 08, Epoch: 180, Loss: 0.3418, Train: 95.40%, Valid: 88.14% Test: 81.08%\n",
      "Run: 08, Epoch: 181, Loss: 0.3186, Train: 96.55%, Valid: 86.44% Test: 81.08%\n",
      "Run: 08, Epoch: 182, Loss: 0.2371, Train: 96.55%, Valid: 84.75% Test: 83.78%\n",
      "Run: 08, Epoch: 183, Loss: 0.3497, Train: 97.70%, Valid: 84.75% Test: 81.08%\n",
      "Run: 08, Epoch: 184, Loss: 0.3361, Train: 97.70%, Valid: 84.75% Test: 83.78%\n",
      "Run: 08, Epoch: 185, Loss: 0.2900, Train: 97.70%, Valid: 86.44% Test: 83.78%\n",
      "Run: 08, Epoch: 186, Loss: 0.3504, Train: 96.55%, Valid: 86.44% Test: 86.49%\n",
      "Run: 08, Epoch: 187, Loss: 0.3071, Train: 94.25%, Valid: 86.44% Test: 83.78%\n",
      "Run: 08, Epoch: 188, Loss: 0.2951, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 08, Epoch: 189, Loss: 0.3085, Train: 93.10%, Valid: 83.05% Test: 83.78%\n",
      "Run: 08, Epoch: 190, Loss: 0.3271, Train: 95.40%, Valid: 83.05% Test: 81.08%\n",
      "Run: 08, Epoch: 191, Loss: 0.3383, Train: 97.70%, Valid: 86.44% Test: 86.49%\n",
      "Run: 08, Epoch: 192, Loss: 0.3020, Train: 97.70%, Valid: 84.75% Test: 86.49%\n",
      "Run: 08, Epoch: 193, Loss: 0.2827, Train: 96.55%, Valid: 83.05% Test: 83.78%\n",
      "Run: 08, Epoch: 194, Loss: 0.2778, Train: 94.25%, Valid: 84.75% Test: 78.38%\n",
      "Run: 08, Epoch: 195, Loss: 0.3945, Train: 91.95%, Valid: 83.05% Test: 78.38%\n",
      "Run: 08, Epoch: 196, Loss: 0.2807, Train: 93.10%, Valid: 81.36% Test: 78.38%\n",
      "Run: 08, Epoch: 197, Loss: 0.3159, Train: 93.10%, Valid: 83.05% Test: 72.97%\n",
      "Run: 08, Epoch: 198, Loss: 0.2982, Train: 94.25%, Valid: 83.05% Test: 72.97%\n",
      "Run: 08, Epoch: 199, Loss: 0.2704, Train: 94.25%, Valid: 83.05% Test: 75.68%\n",
      "Run: 08, Epoch: 200, Loss: 0.4045, Train: 95.40%, Valid: 84.75% Test: 75.68%\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 89.83\n",
      "  Final Train: 95.40\n",
      "   Final Test: 81.08\n",
      "Run: 09, Epoch: 01, Loss: 1.7300, Train: 5.75%, Valid: 13.56% Test: 8.11%\n",
      "Run: 09, Epoch: 02, Loss: 1.6988, Train: 25.29%, Valid: 15.25% Test: 18.92%\n",
      "Run: 09, Epoch: 03, Loss: 1.6383, Train: 25.29%, Valid: 15.25% Test: 18.92%\n",
      "Run: 09, Epoch: 04, Loss: 1.5773, Train: 25.29%, Valid: 15.25% Test: 18.92%\n",
      "Run: 09, Epoch: 05, Loss: 1.5561, Train: 25.29%, Valid: 15.25% Test: 18.92%\n",
      "Run: 09, Epoch: 06, Loss: 1.5246, Train: 25.29%, Valid: 15.25% Test: 18.92%\n",
      "Run: 09, Epoch: 07, Loss: 1.4706, Train: 25.29%, Valid: 15.25% Test: 18.92%\n",
      "Run: 09, Epoch: 08, Loss: 1.4207, Train: 25.29%, Valid: 15.25% Test: 18.92%\n",
      "Run: 09, Epoch: 09, Loss: 1.3939, Train: 25.29%, Valid: 15.25% Test: 18.92%\n",
      "Run: 09, Epoch: 10, Loss: 1.3349, Train: 25.29%, Valid: 15.25% Test: 18.92%\n",
      "Run: 09, Epoch: 11, Loss: 1.2851, Train: 31.03%, Valid: 25.42% Test: 18.92%\n",
      "Run: 09, Epoch: 12, Loss: 1.2327, Train: 52.87%, Valid: 54.24% Test: 35.14%\n",
      "Run: 09, Epoch: 13, Loss: 1.1932, Train: 58.62%, Valid: 61.02% Test: 43.24%\n",
      "Run: 09, Epoch: 14, Loss: 1.1772, Train: 57.47%, Valid: 62.71% Test: 45.95%\n",
      "Run: 09, Epoch: 15, Loss: 1.1386, Train: 59.77%, Valid: 66.10% Test: 45.95%\n",
      "Run: 09, Epoch: 16, Loss: 1.0607, Train: 62.07%, Valid: 67.80% Test: 45.95%\n",
      "Run: 09, Epoch: 17, Loss: 1.0765, Train: 59.77%, Valid: 69.49% Test: 48.65%\n",
      "Run: 09, Epoch: 18, Loss: 1.0829, Train: 60.92%, Valid: 67.80% Test: 51.35%\n",
      "Run: 09, Epoch: 19, Loss: 0.9956, Train: 63.22%, Valid: 67.80% Test: 54.05%\n",
      "Run: 09, Epoch: 20, Loss: 1.0196, Train: 62.07%, Valid: 67.80% Test: 45.95%\n",
      "Run: 09, Epoch: 21, Loss: 1.0455, Train: 62.07%, Valid: 67.80% Test: 45.95%\n",
      "Run: 09, Epoch: 22, Loss: 0.9989, Train: 59.77%, Valid: 67.80% Test: 48.65%\n",
      "Run: 09, Epoch: 23, Loss: 0.9456, Train: 58.62%, Valid: 67.80% Test: 45.95%\n",
      "Run: 09, Epoch: 24, Loss: 0.9551, Train: 55.17%, Valid: 66.10% Test: 51.35%\n",
      "Run: 09, Epoch: 25, Loss: 0.9367, Train: 56.32%, Valid: 67.80% Test: 51.35%\n",
      "Run: 09, Epoch: 26, Loss: 0.9478, Train: 59.77%, Valid: 69.49% Test: 54.05%\n",
      "Run: 09, Epoch: 27, Loss: 0.9357, Train: 64.37%, Valid: 69.49% Test: 56.76%\n",
      "Run: 09, Epoch: 28, Loss: 0.9022, Train: 62.07%, Valid: 69.49% Test: 51.35%\n",
      "Run: 09, Epoch: 29, Loss: 0.8627, Train: 59.77%, Valid: 69.49% Test: 51.35%\n",
      "Run: 09, Epoch: 30, Loss: 0.9019, Train: 59.77%, Valid: 69.49% Test: 51.35%\n",
      "Run: 09, Epoch: 31, Loss: 0.8843, Train: 65.52%, Valid: 69.49% Test: 51.35%\n",
      "Run: 09, Epoch: 32, Loss: 0.8698, Train: 70.11%, Valid: 72.88% Test: 64.86%\n",
      "Run: 09, Epoch: 33, Loss: 0.8598, Train: 70.11%, Valid: 72.88% Test: 67.57%\n",
      "Run: 09, Epoch: 34, Loss: 0.8091, Train: 71.26%, Valid: 74.58% Test: 67.57%\n",
      "Run: 09, Epoch: 35, Loss: 0.8312, Train: 72.41%, Valid: 76.27% Test: 70.27%\n",
      "Run: 09, Epoch: 36, Loss: 0.8471, Train: 74.71%, Valid: 77.97% Test: 67.57%\n",
      "Run: 09, Epoch: 37, Loss: 0.8115, Train: 74.71%, Valid: 77.97% Test: 67.57%\n",
      "Run: 09, Epoch: 38, Loss: 0.8097, Train: 75.86%, Valid: 79.66% Test: 72.97%\n",
      "Run: 09, Epoch: 39, Loss: 0.8147, Train: 79.31%, Valid: 79.66% Test: 72.97%\n",
      "Run: 09, Epoch: 40, Loss: 0.7593, Train: 79.31%, Valid: 77.97% Test: 75.68%\n",
      "Run: 09, Epoch: 41, Loss: 0.8125, Train: 77.01%, Valid: 77.97% Test: 78.38%\n",
      "Run: 09, Epoch: 42, Loss: 0.8069, Train: 75.86%, Valid: 79.66% Test: 78.38%\n",
      "Run: 09, Epoch: 43, Loss: 0.7438, Train: 75.86%, Valid: 81.36% Test: 78.38%\n",
      "Run: 09, Epoch: 44, Loss: 0.7810, Train: 73.56%, Valid: 79.66% Test: 67.57%\n",
      "Run: 09, Epoch: 45, Loss: 0.7616, Train: 74.71%, Valid: 79.66% Test: 64.86%\n",
      "Run: 09, Epoch: 46, Loss: 0.7378, Train: 77.01%, Valid: 79.66% Test: 70.27%\n",
      "Run: 09, Epoch: 47, Loss: 0.7473, Train: 81.61%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 48, Loss: 0.7427, Train: 86.21%, Valid: 81.36% Test: 78.38%\n",
      "Run: 09, Epoch: 49, Loss: 0.7314, Train: 88.51%, Valid: 81.36% Test: 78.38%\n",
      "Run: 09, Epoch: 50, Loss: 0.7433, Train: 88.51%, Valid: 83.05% Test: 81.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 51, Loss: 0.7400, Train: 88.51%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 52, Loss: 0.6916, Train: 83.91%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 53, Loss: 0.6888, Train: 77.01%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 54, Loss: 0.7038, Train: 77.01%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 55, Loss: 0.7056, Train: 80.46%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 56, Loss: 0.6679, Train: 79.31%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 57, Loss: 0.6719, Train: 75.86%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 58, Loss: 0.6876, Train: 74.71%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 59, Loss: 0.7194, Train: 79.31%, Valid: 81.36% Test: 78.38%\n",
      "Run: 09, Epoch: 60, Loss: 0.6408, Train: 81.61%, Valid: 81.36% Test: 78.38%\n",
      "Run: 09, Epoch: 61, Loss: 0.6623, Train: 87.36%, Valid: 81.36% Test: 72.97%\n",
      "Run: 09, Epoch: 62, Loss: 0.6761, Train: 87.36%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 63, Loss: 0.6444, Train: 86.21%, Valid: 79.66% Test: 78.38%\n",
      "Run: 09, Epoch: 64, Loss: 0.6880, Train: 86.21%, Valid: 79.66% Test: 78.38%\n",
      "Run: 09, Epoch: 65, Loss: 0.6146, Train: 87.36%, Valid: 81.36% Test: 78.38%\n",
      "Run: 09, Epoch: 66, Loss: 0.6536, Train: 87.36%, Valid: 81.36% Test: 81.08%\n",
      "Run: 09, Epoch: 67, Loss: 0.7313, Train: 88.51%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 68, Loss: 0.6523, Train: 90.80%, Valid: 83.05% Test: 83.78%\n",
      "Run: 09, Epoch: 69, Loss: 0.6592, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 70, Loss: 0.6148, Train: 83.91%, Valid: 81.36% Test: 78.38%\n",
      "Run: 09, Epoch: 71, Loss: 0.6427, Train: 81.61%, Valid: 79.66% Test: 81.08%\n",
      "Run: 09, Epoch: 72, Loss: 0.6218, Train: 79.31%, Valid: 79.66% Test: 81.08%\n",
      "Run: 09, Epoch: 73, Loss: 0.6618, Train: 79.31%, Valid: 81.36% Test: 81.08%\n",
      "Run: 09, Epoch: 74, Loss: 0.6115, Train: 87.36%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 75, Loss: 0.6214, Train: 89.66%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 76, Loss: 0.6640, Train: 90.80%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 77, Loss: 0.6386, Train: 88.51%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 78, Loss: 0.6152, Train: 88.51%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 79, Loss: 0.5597, Train: 86.21%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 80, Loss: 0.6105, Train: 86.21%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 81, Loss: 0.6205, Train: 85.06%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 82, Loss: 0.5757, Train: 83.91%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 83, Loss: 0.6461, Train: 82.76%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 84, Loss: 0.5630, Train: 82.76%, Valid: 81.36% Test: 81.08%\n",
      "Run: 09, Epoch: 85, Loss: 0.6481, Train: 85.06%, Valid: 81.36% Test: 81.08%\n",
      "Run: 09, Epoch: 86, Loss: 0.6236, Train: 88.51%, Valid: 81.36% Test: 81.08%\n",
      "Run: 09, Epoch: 87, Loss: 0.6011, Train: 89.66%, Valid: 81.36% Test: 81.08%\n",
      "Run: 09, Epoch: 88, Loss: 0.6278, Train: 90.80%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 89, Loss: 0.5968, Train: 90.80%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 90, Loss: 0.5924, Train: 89.66%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 91, Loss: 0.5975, Train: 88.51%, Valid: 84.75% Test: 75.68%\n",
      "Run: 09, Epoch: 92, Loss: 0.5500, Train: 89.66%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 93, Loss: 0.6227, Train: 89.66%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 94, Loss: 0.5628, Train: 89.66%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 95, Loss: 0.5565, Train: 89.66%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 96, Loss: 0.5268, Train: 93.10%, Valid: 84.75% Test: 81.08%\n",
      "Run: 09, Epoch: 97, Loss: 0.6206, Train: 87.36%, Valid: 83.05% Test: 83.78%\n",
      "Run: 09, Epoch: 98, Loss: 0.5956, Train: 85.06%, Valid: 81.36% Test: 83.78%\n",
      "Run: 09, Epoch: 99, Loss: 0.5865, Train: 85.06%, Valid: 81.36% Test: 83.78%\n",
      "Run: 09, Epoch: 100, Loss: 0.5944, Train: 86.21%, Valid: 81.36% Test: 83.78%\n",
      "Run: 09, Epoch: 101, Loss: 0.5372, Train: 90.80%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 102, Loss: 0.5478, Train: 90.80%, Valid: 84.75% Test: 81.08%\n",
      "Run: 09, Epoch: 103, Loss: 0.5598, Train: 90.80%, Valid: 84.75% Test: 81.08%\n",
      "Run: 09, Epoch: 104, Loss: 0.4975, Train: 90.80%, Valid: 84.75% Test: 81.08%\n",
      "Run: 09, Epoch: 105, Loss: 0.5280, Train: 88.51%, Valid: 81.36% Test: 78.38%\n",
      "Run: 09, Epoch: 106, Loss: 0.5432, Train: 89.66%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 107, Loss: 0.4628, Train: 90.80%, Valid: 83.05% Test: 75.68%\n",
      "Run: 09, Epoch: 108, Loss: 0.4878, Train: 89.66%, Valid: 83.05% Test: 72.97%\n",
      "Run: 09, Epoch: 109, Loss: 0.4946, Train: 88.51%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 110, Loss: 0.5395, Train: 90.80%, Valid: 81.36% Test: 78.38%\n",
      "Run: 09, Epoch: 111, Loss: 0.5416, Train: 93.10%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 112, Loss: 0.5254, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 113, Loss: 0.5495, Train: 90.80%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 114, Loss: 0.4839, Train: 89.66%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 115, Loss: 0.5215, Train: 89.66%, Valid: 79.66% Test: 81.08%\n",
      "Run: 09, Epoch: 116, Loss: 0.4909, Train: 90.80%, Valid: 83.05% Test: 78.38%\n",
      "Run: 09, Epoch: 117, Loss: 0.5013, Train: 91.95%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 118, Loss: 0.5592, Train: 90.80%, Valid: 84.75% Test: 75.68%\n",
      "Run: 09, Epoch: 119, Loss: 0.5251, Train: 91.95%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 120, Loss: 0.5099, Train: 94.25%, Valid: 86.44% Test: 81.08%\n",
      "Run: 09, Epoch: 121, Loss: 0.5186, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 09, Epoch: 122, Loss: 0.4640, Train: 89.66%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 123, Loss: 0.4517, Train: 93.10%, Valid: 84.75% Test: 81.08%\n",
      "Run: 09, Epoch: 124, Loss: 0.4803, Train: 94.25%, Valid: 86.44% Test: 81.08%\n",
      "Run: 09, Epoch: 125, Loss: 0.5462, Train: 91.95%, Valid: 84.75% Test: 81.08%\n",
      "Run: 09, Epoch: 126, Loss: 0.4869, Train: 91.95%, Valid: 84.75% Test: 81.08%\n",
      "Run: 09, Epoch: 127, Loss: 0.4802, Train: 89.66%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 128, Loss: 0.4728, Train: 88.51%, Valid: 81.36% Test: 75.68%\n",
      "Run: 09, Epoch: 129, Loss: 0.4750, Train: 85.06%, Valid: 81.36% Test: 72.97%\n",
      "Run: 09, Epoch: 130, Loss: 0.4809, Train: 85.06%, Valid: 81.36% Test: 78.38%\n",
      "Run: 09, Epoch: 131, Loss: 0.4914, Train: 87.36%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 132, Loss: 0.5152, Train: 89.66%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 133, Loss: 0.4806, Train: 90.80%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 134, Loss: 0.4943, Train: 90.80%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 135, Loss: 0.4615, Train: 93.10%, Valid: 86.44% Test: 78.38%\n",
      "Run: 09, Epoch: 136, Loss: 0.4306, Train: 91.95%, Valid: 77.97% Test: 75.68%\n",
      "Run: 09, Epoch: 137, Loss: 0.4438, Train: 90.80%, Valid: 77.97% Test: 78.38%\n",
      "Run: 09, Epoch: 138, Loss: 0.5467, Train: 91.95%, Valid: 79.66% Test: 81.08%\n",
      "Run: 09, Epoch: 139, Loss: 0.4385, Train: 91.95%, Valid: 77.97% Test: 83.78%\n",
      "Run: 09, Epoch: 140, Loss: 0.4628, Train: 93.10%, Valid: 81.36% Test: 83.78%\n",
      "Run: 09, Epoch: 141, Loss: 0.3821, Train: 94.25%, Valid: 86.44% Test: 83.78%\n",
      "Run: 09, Epoch: 142, Loss: 0.4856, Train: 94.25%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 143, Loss: 0.4715, Train: 94.25%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 144, Loss: 0.4451, Train: 93.10%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 145, Loss: 0.4497, Train: 91.95%, Valid: 88.14% Test: 86.49%\n",
      "Run: 09, Epoch: 146, Loss: 0.4307, Train: 90.80%, Valid: 86.44% Test: 83.78%\n",
      "Run: 09, Epoch: 147, Loss: 0.4979, Train: 91.95%, Valid: 86.44% Test: 89.19%\n",
      "Run: 09, Epoch: 148, Loss: 0.4492, Train: 93.10%, Valid: 89.83% Test: 89.19%\n",
      "Run: 09, Epoch: 149, Loss: 0.4646, Train: 93.10%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 150, Loss: 0.5053, Train: 93.10%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 151, Loss: 0.4495, Train: 93.10%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 152, Loss: 0.4878, Train: 90.80%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 153, Loss: 0.4470, Train: 90.80%, Valid: 86.44% Test: 86.49%\n",
      "Run: 09, Epoch: 154, Loss: 0.4290, Train: 91.95%, Valid: 91.53% Test: 86.49%\n",
      "Run: 09, Epoch: 155, Loss: 0.4300, Train: 95.40%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 156, Loss: 0.4333, Train: 95.40%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 157, Loss: 0.4674, Train: 90.80%, Valid: 86.44% Test: 78.38%\n",
      "Run: 09, Epoch: 158, Loss: 0.3905, Train: 90.80%, Valid: 86.44% Test: 78.38%\n",
      "Run: 09, Epoch: 159, Loss: 0.4159, Train: 91.95%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 160, Loss: 0.4264, Train: 91.95%, Valid: 84.75% Test: 78.38%\n",
      "Run: 09, Epoch: 161, Loss: 0.4212, Train: 90.80%, Valid: 86.44% Test: 83.78%\n",
      "Run: 09, Epoch: 162, Loss: 0.4277, Train: 89.66%, Valid: 89.83% Test: 83.78%\n",
      "Run: 09, Epoch: 163, Loss: 0.4666, Train: 89.66%, Valid: 91.53% Test: 83.78%\n",
      "Run: 09, Epoch: 164, Loss: 0.4003, Train: 90.80%, Valid: 91.53% Test: 86.49%\n",
      "Run: 09, Epoch: 165, Loss: 0.3719, Train: 89.66%, Valid: 91.53% Test: 86.49%\n",
      "Run: 09, Epoch: 166, Loss: 0.3864, Train: 88.51%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 167, Loss: 0.4703, Train: 94.25%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 168, Loss: 0.3785, Train: 93.10%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 169, Loss: 0.4421, Train: 94.25%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 170, Loss: 0.4188, Train: 94.25%, Valid: 91.53% Test: 86.49%\n",
      "Run: 09, Epoch: 171, Loss: 0.4288, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 09, Epoch: 172, Loss: 0.4637, Train: 94.25%, Valid: 89.83% Test: 83.78%\n",
      "Run: 09, Epoch: 173, Loss: 0.5328, Train: 94.25%, Valid: 89.83% Test: 81.08%\n",
      "Run: 09, Epoch: 174, Loss: 0.3349, Train: 90.80%, Valid: 89.83% Test: 83.78%\n",
      "Run: 09, Epoch: 175, Loss: 0.4641, Train: 88.51%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 176, Loss: 0.4438, Train: 89.66%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 177, Loss: 0.4106, Train: 89.66%, Valid: 91.53% Test: 86.49%\n",
      "Run: 09, Epoch: 178, Loss: 0.4251, Train: 90.80%, Valid: 93.22% Test: 86.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 09, Epoch: 179, Loss: 0.4470, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 09, Epoch: 180, Loss: 0.3646, Train: 96.55%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 181, Loss: 0.3639, Train: 94.25%, Valid: 86.44% Test: 81.08%\n",
      "Run: 09, Epoch: 182, Loss: 0.4182, Train: 94.25%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 183, Loss: 0.3895, Train: 95.40%, Valid: 89.83% Test: 83.78%\n",
      "Run: 09, Epoch: 184, Loss: 0.4141, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 09, Epoch: 185, Loss: 0.3797, Train: 95.40%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 186, Loss: 0.3862, Train: 96.55%, Valid: 91.53% Test: 83.78%\n",
      "Run: 09, Epoch: 187, Loss: 0.4293, Train: 95.40%, Valid: 91.53% Test: 83.78%\n",
      "Run: 09, Epoch: 188, Loss: 0.3776, Train: 95.40%, Valid: 93.22% Test: 83.78%\n",
      "Run: 09, Epoch: 189, Loss: 0.3731, Train: 95.40%, Valid: 93.22% Test: 86.49%\n",
      "Run: 09, Epoch: 190, Loss: 0.4384, Train: 95.40%, Valid: 93.22% Test: 86.49%\n",
      "Run: 09, Epoch: 191, Loss: 0.3835, Train: 95.40%, Valid: 93.22% Test: 86.49%\n",
      "Run: 09, Epoch: 192, Loss: 0.4128, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 09, Epoch: 193, Loss: 0.4121, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 09, Epoch: 194, Loss: 0.3367, Train: 94.25%, Valid: 91.53% Test: 83.78%\n",
      "Run: 09, Epoch: 195, Loss: 0.3391, Train: 93.10%, Valid: 91.53% Test: 83.78%\n",
      "Run: 09, Epoch: 196, Loss: 0.3900, Train: 94.25%, Valid: 88.14% Test: 83.78%\n",
      "Run: 09, Epoch: 197, Loss: 0.3474, Train: 90.80%, Valid: 91.53% Test: 81.08%\n",
      "Run: 09, Epoch: 198, Loss: 0.3298, Train: 88.51%, Valid: 89.83% Test: 83.78%\n",
      "Run: 09, Epoch: 199, Loss: 0.3789, Train: 88.51%, Valid: 88.14% Test: 81.08%\n",
      "Run: 09, Epoch: 200, Loss: 0.3911, Train: 88.51%, Valid: 88.14% Test: 83.78%\n",
      "Run 09:\n",
      "Highest Train: 96.55\n",
      "Highest Valid: 93.22\n",
      "  Final Train: 90.80\n",
      "   Final Test: 86.49\n",
      "Run: 10, Epoch: 01, Loss: 1.6536, Train: 27.59%, Valid: 18.64% Test: 29.73%\n",
      "Run: 10, Epoch: 02, Loss: 1.5850, Train: 22.99%, Valid: 15.25% Test: 24.32%\n",
      "Run: 10, Epoch: 03, Loss: 1.5405, Train: 33.33%, Valid: 33.90% Test: 32.43%\n",
      "Run: 10, Epoch: 04, Loss: 1.5094, Train: 49.43%, Valid: 59.32% Test: 48.65%\n",
      "Run: 10, Epoch: 05, Loss: 1.4534, Train: 43.68%, Valid: 55.93% Test: 48.65%\n",
      "Run: 10, Epoch: 06, Loss: 1.4221, Train: 40.23%, Valid: 55.93% Test: 48.65%\n",
      "Run: 10, Epoch: 07, Loss: 1.3758, Train: 37.93%, Valid: 55.93% Test: 45.95%\n",
      "Run: 10, Epoch: 08, Loss: 1.3397, Train: 37.93%, Valid: 55.93% Test: 45.95%\n",
      "Run: 10, Epoch: 09, Loss: 1.3108, Train: 37.93%, Valid: 55.93% Test: 43.24%\n",
      "Run: 10, Epoch: 10, Loss: 1.2623, Train: 37.93%, Valid: 55.93% Test: 43.24%\n",
      "Run: 10, Epoch: 11, Loss: 1.2341, Train: 37.93%, Valid: 55.93% Test: 43.24%\n",
      "Run: 10, Epoch: 12, Loss: 1.2197, Train: 37.93%, Valid: 55.93% Test: 43.24%\n",
      "Run: 10, Epoch: 13, Loss: 1.1828, Train: 37.93%, Valid: 55.93% Test: 45.95%\n",
      "Run: 10, Epoch: 14, Loss: 1.1249, Train: 37.93%, Valid: 55.93% Test: 45.95%\n",
      "Run: 10, Epoch: 15, Loss: 1.1189, Train: 39.08%, Valid: 55.93% Test: 45.95%\n",
      "Run: 10, Epoch: 16, Loss: 1.1230, Train: 39.08%, Valid: 55.93% Test: 45.95%\n",
      "Run: 10, Epoch: 17, Loss: 1.0704, Train: 41.38%, Valid: 55.93% Test: 48.65%\n",
      "Run: 10, Epoch: 18, Loss: 1.0470, Train: 41.38%, Valid: 55.93% Test: 48.65%\n",
      "Run: 10, Epoch: 19, Loss: 1.0639, Train: 41.38%, Valid: 55.93% Test: 48.65%\n",
      "Run: 10, Epoch: 20, Loss: 1.0627, Train: 41.38%, Valid: 55.93% Test: 48.65%\n",
      "Run: 10, Epoch: 21, Loss: 1.0044, Train: 42.53%, Valid: 57.63% Test: 51.35%\n",
      "Run: 10, Epoch: 22, Loss: 1.0051, Train: 48.28%, Valid: 61.02% Test: 51.35%\n",
      "Run: 10, Epoch: 23, Loss: 0.9907, Train: 54.02%, Valid: 67.80% Test: 54.05%\n",
      "Run: 10, Epoch: 24, Loss: 0.9515, Train: 55.17%, Valid: 71.19% Test: 56.76%\n",
      "Run: 10, Epoch: 25, Loss: 0.9367, Train: 59.77%, Valid: 71.19% Test: 59.46%\n",
      "Run: 10, Epoch: 26, Loss: 0.9882, Train: 60.92%, Valid: 72.88% Test: 59.46%\n",
      "Run: 10, Epoch: 27, Loss: 0.9309, Train: 62.07%, Valid: 72.88% Test: 64.86%\n",
      "Run: 10, Epoch: 28, Loss: 0.9526, Train: 66.67%, Valid: 74.58% Test: 67.57%\n",
      "Run: 10, Epoch: 29, Loss: 0.9022, Train: 66.67%, Valid: 77.97% Test: 64.86%\n",
      "Run: 10, Epoch: 30, Loss: 0.9213, Train: 64.37%, Valid: 76.27% Test: 64.86%\n",
      "Run: 10, Epoch: 31, Loss: 0.8637, Train: 64.37%, Valid: 76.27% Test: 64.86%\n",
      "Run: 10, Epoch: 32, Loss: 0.8708, Train: 63.22%, Valid: 76.27% Test: 64.86%\n",
      "Run: 10, Epoch: 33, Loss: 0.8895, Train: 66.67%, Valid: 79.66% Test: 67.57%\n",
      "Run: 10, Epoch: 34, Loss: 0.8743, Train: 66.67%, Valid: 79.66% Test: 67.57%\n",
      "Run: 10, Epoch: 35, Loss: 0.8988, Train: 65.52%, Valid: 77.97% Test: 62.16%\n",
      "Run: 10, Epoch: 36, Loss: 0.8354, Train: 64.37%, Valid: 74.58% Test: 67.57%\n",
      "Run: 10, Epoch: 37, Loss: 0.8557, Train: 62.07%, Valid: 72.88% Test: 64.86%\n",
      "Run: 10, Epoch: 38, Loss: 0.8670, Train: 67.82%, Valid: 74.58% Test: 70.27%\n",
      "Run: 10, Epoch: 39, Loss: 0.8302, Train: 68.97%, Valid: 83.05% Test: 70.27%\n",
      "Run: 10, Epoch: 40, Loss: 0.8240, Train: 81.61%, Valid: 84.75% Test: 70.27%\n",
      "Run: 10, Epoch: 41, Loss: 0.7724, Train: 81.61%, Valid: 84.75% Test: 72.97%\n",
      "Run: 10, Epoch: 42, Loss: 0.7735, Train: 77.01%, Valid: 79.66% Test: 70.27%\n",
      "Run: 10, Epoch: 43, Loss: 0.8579, Train: 72.41%, Valid: 81.36% Test: 70.27%\n",
      "Run: 10, Epoch: 44, Loss: 0.7988, Train: 68.97%, Valid: 79.66% Test: 70.27%\n",
      "Run: 10, Epoch: 45, Loss: 0.8216, Train: 66.67%, Valid: 76.27% Test: 67.57%\n",
      "Run: 10, Epoch: 46, Loss: 0.7731, Train: 68.97%, Valid: 76.27% Test: 70.27%\n",
      "Run: 10, Epoch: 47, Loss: 0.7975, Train: 77.01%, Valid: 81.36% Test: 75.68%\n",
      "Run: 10, Epoch: 48, Loss: 0.7705, Train: 83.91%, Valid: 81.36% Test: 72.97%\n",
      "Run: 10, Epoch: 49, Loss: 0.7095, Train: 83.91%, Valid: 79.66% Test: 67.57%\n",
      "Run: 10, Epoch: 50, Loss: 0.7219, Train: 78.16%, Valid: 74.58% Test: 64.86%\n",
      "Run: 10, Epoch: 51, Loss: 0.7757, Train: 77.01%, Valid: 74.58% Test: 67.57%\n",
      "Run: 10, Epoch: 52, Loss: 0.7585, Train: 83.91%, Valid: 76.27% Test: 70.27%\n",
      "Run: 10, Epoch: 53, Loss: 0.7709, Train: 88.51%, Valid: 79.66% Test: 72.97%\n",
      "Run: 10, Epoch: 54, Loss: 0.7939, Train: 86.21%, Valid: 83.05% Test: 78.38%\n",
      "Run: 10, Epoch: 55, Loss: 0.7643, Train: 85.06%, Valid: 86.44% Test: 78.38%\n",
      "Run: 10, Epoch: 56, Loss: 0.7242, Train: 79.31%, Valid: 84.75% Test: 78.38%\n",
      "Run: 10, Epoch: 57, Loss: 0.7558, Train: 85.06%, Valid: 86.44% Test: 78.38%\n",
      "Run: 10, Epoch: 58, Loss: 0.7294, Train: 89.66%, Valid: 83.05% Test: 78.38%\n",
      "Run: 10, Epoch: 59, Loss: 0.7505, Train: 87.36%, Valid: 84.75% Test: 78.38%\n",
      "Run: 10, Epoch: 60, Loss: 0.7452, Train: 87.36%, Valid: 84.75% Test: 78.38%\n",
      "Run: 10, Epoch: 61, Loss: 0.7078, Train: 83.91%, Valid: 84.75% Test: 72.97%\n",
      "Run: 10, Epoch: 62, Loss: 0.6730, Train: 82.76%, Valid: 83.05% Test: 70.27%\n",
      "Run: 10, Epoch: 63, Loss: 0.7042, Train: 80.46%, Valid: 83.05% Test: 70.27%\n",
      "Run: 10, Epoch: 64, Loss: 0.7145, Train: 80.46%, Valid: 83.05% Test: 70.27%\n",
      "Run: 10, Epoch: 65, Loss: 0.7007, Train: 80.46%, Valid: 81.36% Test: 70.27%\n",
      "Run: 10, Epoch: 66, Loss: 0.6754, Train: 82.76%, Valid: 81.36% Test: 72.97%\n",
      "Run: 10, Epoch: 67, Loss: 0.6454, Train: 82.76%, Valid: 84.75% Test: 72.97%\n",
      "Run: 10, Epoch: 68, Loss: 0.6492, Train: 85.06%, Valid: 86.44% Test: 72.97%\n",
      "Run: 10, Epoch: 69, Loss: 0.7270, Train: 87.36%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 70, Loss: 0.6552, Train: 86.21%, Valid: 84.75% Test: 75.68%\n",
      "Run: 10, Epoch: 71, Loss: 0.6690, Train: 86.21%, Valid: 84.75% Test: 81.08%\n",
      "Run: 10, Epoch: 72, Loss: 0.6104, Train: 88.51%, Valid: 84.75% Test: 78.38%\n",
      "Run: 10, Epoch: 73, Loss: 0.6087, Train: 87.36%, Valid: 83.05% Test: 83.78%\n",
      "Run: 10, Epoch: 74, Loss: 0.6827, Train: 83.91%, Valid: 83.05% Test: 75.68%\n",
      "Run: 10, Epoch: 75, Loss: 0.6560, Train: 86.21%, Valid: 83.05% Test: 75.68%\n",
      "Run: 10, Epoch: 76, Loss: 0.6260, Train: 89.66%, Valid: 86.44% Test: 83.78%\n",
      "Run: 10, Epoch: 77, Loss: 0.6163, Train: 90.80%, Valid: 89.83% Test: 81.08%\n",
      "Run: 10, Epoch: 78, Loss: 0.5976, Train: 88.51%, Valid: 89.83% Test: 78.38%\n",
      "Run: 10, Epoch: 79, Loss: 0.6530, Train: 82.76%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 80, Loss: 0.6186, Train: 79.31%, Valid: 79.66% Test: 75.68%\n",
      "Run: 10, Epoch: 81, Loss: 0.5867, Train: 81.61%, Valid: 81.36% Test: 75.68%\n",
      "Run: 10, Epoch: 82, Loss: 0.5551, Train: 82.76%, Valid: 83.05% Test: 75.68%\n",
      "Run: 10, Epoch: 83, Loss: 0.6847, Train: 87.36%, Valid: 89.83% Test: 78.38%\n",
      "Run: 10, Epoch: 84, Loss: 0.5956, Train: 90.80%, Valid: 91.53% Test: 81.08%\n",
      "Run: 10, Epoch: 85, Loss: 0.6020, Train: 91.95%, Valid: 91.53% Test: 75.68%\n",
      "Run: 10, Epoch: 86, Loss: 0.5690, Train: 90.80%, Valid: 88.14% Test: 78.38%\n",
      "Run: 10, Epoch: 87, Loss: 0.5274, Train: 90.80%, Valid: 88.14% Test: 78.38%\n",
      "Run: 10, Epoch: 88, Loss: 0.5218, Train: 89.66%, Valid: 84.75% Test: 72.97%\n",
      "Run: 10, Epoch: 89, Loss: 0.5851, Train: 87.36%, Valid: 83.05% Test: 70.27%\n",
      "Run: 10, Epoch: 90, Loss: 0.6007, Train: 83.91%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 91, Loss: 0.5990, Train: 85.06%, Valid: 83.05% Test: 75.68%\n",
      "Run: 10, Epoch: 92, Loss: 0.5915, Train: 87.36%, Valid: 84.75% Test: 72.97%\n",
      "Run: 10, Epoch: 93, Loss: 0.5874, Train: 90.80%, Valid: 86.44% Test: 81.08%\n",
      "Run: 10, Epoch: 94, Loss: 0.5332, Train: 89.66%, Valid: 84.75% Test: 81.08%\n",
      "Run: 10, Epoch: 95, Loss: 0.5697, Train: 89.66%, Valid: 86.44% Test: 83.78%\n",
      "Run: 10, Epoch: 96, Loss: 0.5564, Train: 90.80%, Valid: 84.75% Test: 81.08%\n",
      "Run: 10, Epoch: 97, Loss: 0.5526, Train: 91.95%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 98, Loss: 0.4899, Train: 88.51%, Valid: 83.05% Test: 83.78%\n",
      "Run: 10, Epoch: 99, Loss: 0.6003, Train: 88.51%, Valid: 83.05% Test: 81.08%\n",
      "Run: 10, Epoch: 100, Loss: 0.5411, Train: 87.36%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 101, Loss: 0.5446, Train: 87.36%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 102, Loss: 0.6062, Train: 88.51%, Valid: 86.44% Test: 70.27%\n",
      "Run: 10, Epoch: 103, Loss: 0.5173, Train: 87.36%, Valid: 89.83% Test: 72.97%\n",
      "Run: 10, Epoch: 104, Loss: 0.5137, Train: 87.36%, Valid: 83.05% Test: 75.68%\n",
      "Run: 10, Epoch: 105, Loss: 0.5521, Train: 89.66%, Valid: 83.05% Test: 75.68%\n",
      "Run: 10, Epoch: 106, Loss: 0.5914, Train: 89.66%, Valid: 84.75% Test: 75.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10, Epoch: 107, Loss: 0.5445, Train: 87.36%, Valid: 86.44% Test: 75.68%\n",
      "Run: 10, Epoch: 108, Loss: 0.5033, Train: 87.36%, Valid: 83.05% Test: 72.97%\n",
      "Run: 10, Epoch: 109, Loss: 0.4976, Train: 88.51%, Valid: 83.05% Test: 75.68%\n",
      "Run: 10, Epoch: 110, Loss: 0.4474, Train: 90.80%, Valid: 81.36% Test: 75.68%\n",
      "Run: 10, Epoch: 111, Loss: 0.5124, Train: 88.51%, Valid: 81.36% Test: 75.68%\n",
      "Run: 10, Epoch: 112, Loss: 0.4878, Train: 89.66%, Valid: 83.05% Test: 78.38%\n",
      "Run: 10, Epoch: 113, Loss: 0.5224, Train: 90.80%, Valid: 86.44% Test: 81.08%\n",
      "Run: 10, Epoch: 114, Loss: 0.4633, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 10, Epoch: 115, Loss: 0.5296, Train: 94.25%, Valid: 84.75% Test: 81.08%\n",
      "Run: 10, Epoch: 116, Loss: 0.5199, Train: 91.95%, Valid: 81.36% Test: 81.08%\n",
      "Run: 10, Epoch: 117, Loss: 0.5578, Train: 87.36%, Valid: 81.36% Test: 75.68%\n",
      "Run: 10, Epoch: 118, Loss: 0.4604, Train: 91.95%, Valid: 84.75% Test: 78.38%\n",
      "Run: 10, Epoch: 119, Loss: 0.4629, Train: 91.95%, Valid: 91.53% Test: 83.78%\n",
      "Run: 10, Epoch: 120, Loss: 0.4419, Train: 93.10%, Valid: 91.53% Test: 86.49%\n",
      "Run: 10, Epoch: 121, Loss: 0.4648, Train: 91.95%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 122, Loss: 0.5438, Train: 89.66%, Valid: 89.83% Test: 78.38%\n",
      "Run: 10, Epoch: 123, Loss: 0.4733, Train: 91.95%, Valid: 89.83% Test: 81.08%\n",
      "Run: 10, Epoch: 124, Loss: 0.4220, Train: 93.10%, Valid: 88.14% Test: 83.78%\n",
      "Run: 10, Epoch: 125, Loss: 0.4813, Train: 93.10%, Valid: 88.14% Test: 86.49%\n",
      "Run: 10, Epoch: 126, Loss: 0.4664, Train: 88.51%, Valid: 88.14% Test: 86.49%\n",
      "Run: 10, Epoch: 127, Loss: 0.5905, Train: 85.06%, Valid: 83.05% Test: 81.08%\n",
      "Run: 10, Epoch: 128, Loss: 0.4858, Train: 82.76%, Valid: 76.27% Test: 78.38%\n",
      "Run: 10, Epoch: 129, Loss: 0.4319, Train: 82.76%, Valid: 76.27% Test: 75.68%\n",
      "Run: 10, Epoch: 130, Loss: 0.4950, Train: 83.91%, Valid: 76.27% Test: 75.68%\n",
      "Run: 10, Epoch: 131, Loss: 0.4604, Train: 87.36%, Valid: 79.66% Test: 75.68%\n",
      "Run: 10, Epoch: 132, Loss: 0.5604, Train: 90.80%, Valid: 84.75% Test: 81.08%\n",
      "Run: 10, Epoch: 133, Loss: 0.4540, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 10, Epoch: 134, Loss: 0.4609, Train: 91.95%, Valid: 83.05% Test: 81.08%\n",
      "Run: 10, Epoch: 135, Loss: 0.5124, Train: 93.10%, Valid: 84.75% Test: 75.68%\n",
      "Run: 10, Epoch: 136, Loss: 0.5231, Train: 91.95%, Valid: 86.44% Test: 75.68%\n",
      "Run: 10, Epoch: 137, Loss: 0.4387, Train: 93.10%, Valid: 84.75% Test: 78.38%\n",
      "Run: 10, Epoch: 138, Loss: 0.4169, Train: 90.80%, Valid: 84.75% Test: 81.08%\n",
      "Run: 10, Epoch: 139, Loss: 0.4823, Train: 89.66%, Valid: 86.44% Test: 78.38%\n",
      "Run: 10, Epoch: 140, Loss: 0.5023, Train: 89.66%, Valid: 84.75% Test: 78.38%\n",
      "Run: 10, Epoch: 141, Loss: 0.4366, Train: 88.51%, Valid: 86.44% Test: 78.38%\n",
      "Run: 10, Epoch: 142, Loss: 0.3804, Train: 88.51%, Valid: 88.14% Test: 81.08%\n",
      "Run: 10, Epoch: 143, Loss: 0.4836, Train: 90.80%, Valid: 88.14% Test: 83.78%\n",
      "Run: 10, Epoch: 144, Loss: 0.3878, Train: 90.80%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 145, Loss: 0.4354, Train: 90.80%, Valid: 89.83% Test: 81.08%\n",
      "Run: 10, Epoch: 146, Loss: 0.3953, Train: 89.66%, Valid: 91.53% Test: 81.08%\n",
      "Run: 10, Epoch: 147, Loss: 0.4526, Train: 88.51%, Valid: 91.53% Test: 83.78%\n",
      "Run: 10, Epoch: 148, Loss: 0.4019, Train: 91.95%, Valid: 86.44% Test: 81.08%\n",
      "Run: 10, Epoch: 149, Loss: 0.4473, Train: 91.95%, Valid: 86.44% Test: 83.78%\n",
      "Run: 10, Epoch: 150, Loss: 0.4741, Train: 90.80%, Valid: 83.05% Test: 81.08%\n",
      "Run: 10, Epoch: 151, Loss: 0.4884, Train: 91.95%, Valid: 84.75% Test: 78.38%\n",
      "Run: 10, Epoch: 152, Loss: 0.5441, Train: 94.25%, Valid: 86.44% Test: 83.78%\n",
      "Run: 10, Epoch: 153, Loss: 0.4375, Train: 95.40%, Valid: 86.44% Test: 83.78%\n",
      "Run: 10, Epoch: 154, Loss: 0.4274, Train: 95.40%, Valid: 88.14% Test: 83.78%\n",
      "Run: 10, Epoch: 155, Loss: 0.4292, Train: 95.40%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 156, Loss: 0.4742, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 10, Epoch: 157, Loss: 0.4733, Train: 95.40%, Valid: 91.53% Test: 89.19%\n",
      "Run: 10, Epoch: 158, Loss: 0.4411, Train: 94.25%, Valid: 93.22% Test: 89.19%\n",
      "Run: 10, Epoch: 159, Loss: 0.3481, Train: 89.66%, Valid: 93.22% Test: 86.49%\n",
      "Run: 10, Epoch: 160, Loss: 0.4816, Train: 88.51%, Valid: 93.22% Test: 89.19%\n",
      "Run: 10, Epoch: 161, Loss: 0.4219, Train: 88.51%, Valid: 89.83% Test: 86.49%\n",
      "Run: 10, Epoch: 162, Loss: 0.3950, Train: 89.66%, Valid: 89.83% Test: 86.49%\n",
      "Run: 10, Epoch: 163, Loss: 0.4372, Train: 97.70%, Valid: 91.53% Test: 86.49%\n",
      "Run: 10, Epoch: 164, Loss: 0.3988, Train: 97.70%, Valid: 88.14% Test: 83.78%\n",
      "Run: 10, Epoch: 165, Loss: 0.4277, Train: 96.55%, Valid: 88.14% Test: 86.49%\n",
      "Run: 10, Epoch: 166, Loss: 0.4045, Train: 91.95%, Valid: 84.75% Test: 86.49%\n",
      "Run: 10, Epoch: 167, Loss: 0.3993, Train: 89.66%, Valid: 83.05% Test: 83.78%\n",
      "Run: 10, Epoch: 168, Loss: 0.4584, Train: 89.66%, Valid: 81.36% Test: 75.68%\n",
      "Run: 10, Epoch: 169, Loss: 0.3865, Train: 86.21%, Valid: 81.36% Test: 81.08%\n",
      "Run: 10, Epoch: 170, Loss: 0.4499, Train: 87.36%, Valid: 81.36% Test: 75.68%\n",
      "Run: 10, Epoch: 171, Loss: 0.4040, Train: 86.21%, Valid: 84.75% Test: 78.38%\n",
      "Run: 10, Epoch: 172, Loss: 0.4290, Train: 86.21%, Valid: 81.36% Test: 75.68%\n",
      "Run: 10, Epoch: 173, Loss: 0.4493, Train: 93.10%, Valid: 84.75% Test: 83.78%\n",
      "Run: 10, Epoch: 174, Loss: 0.3927, Train: 94.25%, Valid: 88.14% Test: 86.49%\n",
      "Run: 10, Epoch: 175, Loss: 0.4651, Train: 96.55%, Valid: 86.44% Test: 86.49%\n",
      "Run: 10, Epoch: 176, Loss: 0.3409, Train: 94.25%, Valid: 89.83% Test: 89.19%\n",
      "Run: 10, Epoch: 177, Loss: 0.3863, Train: 91.95%, Valid: 89.83% Test: 89.19%\n",
      "Run: 10, Epoch: 178, Loss: 0.3797, Train: 88.51%, Valid: 86.44% Test: 81.08%\n",
      "Run: 10, Epoch: 179, Loss: 0.4176, Train: 87.36%, Valid: 86.44% Test: 78.38%\n",
      "Run: 10, Epoch: 180, Loss: 0.4285, Train: 88.51%, Valid: 91.53% Test: 86.49%\n",
      "Run: 10, Epoch: 181, Loss: 0.4447, Train: 93.10%, Valid: 91.53% Test: 86.49%\n",
      "Run: 10, Epoch: 182, Loss: 0.4022, Train: 96.55%, Valid: 88.14% Test: 86.49%\n",
      "Run: 10, Epoch: 183, Loss: 0.4248, Train: 94.25%, Valid: 81.36% Test: 81.08%\n",
      "Run: 10, Epoch: 184, Loss: 0.3134, Train: 94.25%, Valid: 79.66% Test: 78.38%\n",
      "Run: 10, Epoch: 185, Loss: 0.4313, Train: 88.51%, Valid: 81.36% Test: 70.27%\n",
      "Run: 10, Epoch: 186, Loss: 0.4446, Train: 89.66%, Valid: 77.97% Test: 78.38%\n",
      "Run: 10, Epoch: 187, Loss: 0.3682, Train: 93.10%, Valid: 83.05% Test: 86.49%\n",
      "Run: 10, Epoch: 188, Loss: 0.4211, Train: 96.55%, Valid: 88.14% Test: 86.49%\n",
      "Run: 10, Epoch: 189, Loss: 0.4717, Train: 95.40%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 190, Loss: 0.3328, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 10, Epoch: 191, Loss: 0.3493, Train: 95.40%, Valid: 89.83% Test: 86.49%\n",
      "Run: 10, Epoch: 192, Loss: 0.3969, Train: 95.40%, Valid: 91.53% Test: 89.19%\n",
      "Run: 10, Epoch: 193, Loss: 0.3755, Train: 95.40%, Valid: 91.53% Test: 86.49%\n",
      "Run: 10, Epoch: 194, Loss: 0.3932, Train: 96.55%, Valid: 91.53% Test: 86.49%\n",
      "Run: 10, Epoch: 195, Loss: 0.3327, Train: 96.55%, Valid: 91.53% Test: 86.49%\n",
      "Run: 10, Epoch: 196, Loss: 0.3655, Train: 96.55%, Valid: 89.83% Test: 83.78%\n",
      "Run: 10, Epoch: 197, Loss: 0.3848, Train: 96.55%, Valid: 88.14% Test: 83.78%\n",
      "Run: 10, Epoch: 198, Loss: 0.3823, Train: 93.10%, Valid: 89.83% Test: 86.49%\n",
      "Run: 10, Epoch: 199, Loss: 0.3185, Train: 93.10%, Valid: 88.14% Test: 83.78%\n",
      "Run: 10, Epoch: 200, Loss: 0.3817, Train: 93.10%, Valid: 89.83% Test: 86.49%\n",
      "Run 10:\n",
      "Highest Train: 97.70\n",
      "Highest Valid: 93.22\n",
      "  Final Train: 94.25\n",
      "   Final Test: 89.19\n",
      "All runs:\n",
      "Highest Train: 98.28 ± 1.24\n",
      "Highest Valid: 88.31 ± 3.70\n",
      "  Final Train: 94.02 ± 2.22\n",
      "   Final Test: 84.05 ± 5.47\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.5,'num_layers_mlp': 3}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 5,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(15, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        \n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.001)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                print(f'Run: {run + 1:02d}, '\n",
    "                      f'Epoch: {epoch:02d}, '\n",
    "                      f'Loss: {loss:.4f}, '\n",
    "                      f'Train: {100 * train_acc:.2f}%, '\n",
    "                      f'Valid: {100 * valid_acc:.2f}% '\n",
    "                      f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5b0336",
   "metadata": {},
   "source": [
    "# TOPO-GSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceda79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10], adj_t=[183, 183, nnz=298], topo=[183, 24])\n"
     ]
    }
   ],
   "source": [
    "dataset = WebKB(root='/tmp/Cornell', name='Cornell',transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "topo_fe=torch.cat((topo_betti0,topo_betti1),1)\n",
    "data.topo=topo_fe\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fafd35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.objectview object at 0x15f079e40>\n",
      "Run 01:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 72.88\n",
      "  Final Train: 97.70\n",
      "   Final Test: 70.27\n",
      "Run 02:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 64.41\n",
      "  Final Train: 77.01\n",
      "   Final Test: 56.76\n",
      "Run 03:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 71.19\n",
      "  Final Train: 96.55\n",
      "   Final Test: 59.46\n",
      "Run 04:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 59.32\n",
      "  Final Train: 93.10\n",
      "   Final Test: 62.16\n",
      "Run 05:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 64.41\n",
      "  Final Train: 90.80\n",
      "   Final Test: 56.76\n",
      "Run 06:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 69.49\n",
      "  Final Train: 100.00\n",
      "   Final Test: 62.16\n",
      "Run 07:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 67.80\n",
      "  Final Train: 100.00\n",
      "   Final Test: 72.97\n",
      "Run 08:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 74.58\n",
      "  Final Train: 97.70\n",
      "   Final Test: 59.46\n",
      "Run 09:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 69.49\n",
      "  Final Train: 80.46\n",
      "   Final Test: 62.16\n",
      "Run 10:\n",
      "Highest Train: 100.00\n",
      "Highest Valid: 77.97\n",
      "  Final Train: 90.80\n",
      "   Final Test: 54.05\n",
      "All runs:\n",
      "Highest Train: 100.00 ± 0.00\n",
      "Highest Valid: 69.15 ± 5.47\n",
      "  Final Train: 92.41 ± 7.99\n",
      "   Final Test: 61.62 ± 5.95\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args={'model_type': 'GCN', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
    "         'batch_size': 32, 'hidden_channels': 16, 'dropout': 0.5, 'epochs': 200, \n",
    "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0,'runs':10, 'log_steps':1,\n",
    "         'weight_decay': 5e-4, 'lr': 0.01,'hidden_channels_mlp': 20,'dropout_mlp': 0.5,'num_layers_mlp': 3}\n",
    "\n",
    "    args = objectview(args)\n",
    "    print(args)\n",
    "    # call the dataset here with x,y,train_mask,test_mask,Val_mask, and Adj\n",
    "    # To add extra feature we can simply update data.x=new fev tensor or we can add new feature\n",
    "    #dataset = Planetoid(root='/tmp/cora', name='Cora',transform=T.ToSparseTensor())\n",
    "    #data = dataset[0]\n",
    "    X = data.topo\n",
    "    y_true = data.y\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    \n",
    "    model = SAGE(data.num_features, args.hidden_channels,10, args.num_layers,args.dropout)\n",
    "    mlp_model = MLP(X.size(-1), args.hidden_channels_mlp, 5,args.num_layers_mlp, args.dropout_mlp)\n",
    "    #print(mlp_model.parameters())\n",
    "    mlp_2 = MLP2(15, 100, dataset.num_classes,3, 0.0)\n",
    "\n",
    "    logger = Logger(args.runs, args)\n",
    "\n",
    "    for run in range(args.runs):\n",
    "        idx_train=[data.train_mask[i][run] for i in range(len(data.y))]\n",
    "        train_idx = np.where(idx_train)[0]\n",
    "        idx_val=[data.val_mask[i][run] for i in range(len(data.y))]\n",
    "        valid_idx = np.where(idx_val)[0]\n",
    "        idx_test=[data.test_mask[i][run] for i in range(len(data.y))]\n",
    "        test_idx = np.where(idx_test)[0]\n",
    "        \n",
    "        model.reset_parameters()\n",
    "        mlp_model.reset_parameters_mlp()\n",
    "        mlp_2.reset_parameters_mlp2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        optimizer_mlp=torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "        optimizer_mlp2=torch.optim.Adam(mlp_2.parameters(), lr=0.01)\n",
    "        for epoch in range(1, 1 + args.epochs):\n",
    "            loss = train(model,mlp_model,mlp_2,data, train_idx, optimizer,optimizer_mlp,optimizer_mlp2)\n",
    "            result = test(model,mlp_model,mlp_2,data, train_idx,valid_idx,test_idx)\n",
    "            logger.add_result(run, result)\n",
    "\n",
    "            if epoch % args.log_steps == 0:\n",
    "                train_acc, valid_acc, test_acc = result\n",
    "                #print(f'Run: {run + 1:02d}, 'f'Epoch: {epoch:02d}, 'f'Loss: {loss:.4f}, ' f'Train: {100 * train_acc:.2f}%, '\n",
    "                 #     f'Valid: {100 * valid_acc:.2f}% '\n",
    "                  #    f'Test: {100 * test_acc:.2f}%')\n",
    "\n",
    "        logger.print_statistics(run)\n",
    "    logger.print_statistics()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e82a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
